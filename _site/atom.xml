<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Optimization in Data Science</title>
 <link href="http://localhost:4000/optimization-for-data-science-iuh-2025/atom.xml" rel="self"/>
 <link href="http://localhost:4000/optimization-for-data-science-iuh-2025/"/>
 <updated>2025-09-13T11:28:32+07:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Nguyen Le Linh</name>
   <email>nglelinh@gmail.com</email>
 </author>

 
 <entry>
   <title>author details</title>
   <link href="http://localhost:4000/home/author-details/"/>
   <updated>2021-05-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/home/author-details</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>17 Primal-Dual Interior-Point Methods</title>
   <link href="http://localhost:4000/contents/vi/chapter17/17_primal_dual_interior_point_method/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter17/17_primal_dual_interior_point_method</id>
   <content type="html">&lt;p&gt;In this chapter, we will examine the &lt;strong&gt;Primal-Dual Interior-Point Method&lt;/strong&gt;, which improves performance by reducing the centering step of the Barrier method we learned earlier to a single step.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Primal-Dual Interior-Point Method&lt;/strong&gt; relaxes the constraint that the centering step must be feasible and uses the root finding version of Newton’s Method to approximate nonlinear equations with linear equations to find solutions, making it faster and more accurate than the Barrier method.&lt;/p&gt;

&lt;h2 id=&quot;references-and-further-readings&quot;&gt;References and further readings&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;S. Boyd and L. Vandenberghe (2004), “Convex optimization,” Chapter 11&lt;/li&gt;
  &lt;li&gt;S. Wright (1997), “Primal-dual interior-point methods,” Chapters 5 and 6&lt;/li&gt;
  &lt;li&gt;J. Renegar (2001), “A mathematical view of interior-point methods”&lt;/li&gt;
  &lt;li&gt;Y. Nesterov and M. Todd (1998), “Primal-dual interior-point methods for self-scaled cones.” SIAM J. Optim.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>17-05 Optimality conditions for semidefinite programming</title>
   <link href="http://localhost:4000/contents/vi/chapter17/17_05_optimality_conditions_for_semidefinite_programming/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter17/17_05_optimality_conditions_for_semidefinite_programming</id>
   <content type="html">&lt;p&gt;In this section, we want to look at an example of the Primal-Dual method for SDP (semidefinite programming) problems.&lt;/p&gt;

&lt;h2 id=&quot;sdp-semidefinite-programming&quot;&gt;SDP (semidefinite programming)&lt;/h2&gt;
&lt;p&gt;The primal problem of SDP is defined as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp; {C \cdot X} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {A_i \cdot X = b_i, i = 1,...,m} \\\\
   &amp;amp; &amp;amp;&amp;amp;{X \succeq 0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The dual problem of SDP is defined as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\max_{y} &amp;amp;&amp;amp; {b^Ty} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {\sum^m_{X_i=1} y_iA_i + S = C} \\\\
   &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For reference, the trace inner product of \(\mathbb{S}^n\) is denoted as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[X \cdot S = \text{trace}(XS)\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;optimality-conditions-for-sdp&quot;&gt;Optimality conditions for SDP&lt;/h2&gt;
&lt;p&gt;The primal and dual problems of SDP can be defined using linear maps as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp; {C \cdot X} &amp;amp; \qquad \qquad \qquad &amp;amp; \max_{y,S}  &amp;amp;&amp;amp; {b^Ty} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {\mathcal{A}(X) = b} &amp;amp; \qquad \qquad \qquad &amp;amp; \text{subject to } &amp;amp;&amp;amp; {\mathcal{A}^{∗}(y) + S = C} \\\\\
   &amp;amp; &amp;amp;&amp;amp;{X \succeq 0} &amp;amp; \qquad \qquad \qquad &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here \(\mathcal{A}: \mathbb{S}^n \to \mathbb{R}^m\) means a linear map.&lt;/p&gt;

&lt;p&gt;Assuming strong duality is satisfied, \(X^{\star}\) and \((y^{\star}, S^{\star})\) where \((X^{\star}, y^{\star}, S^{\star})\) is a solution are optimal solutions for primal and dual, and vice versa.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{array}{rcl}
\mathcal{A}^∗(y) + S &amp;amp; = &amp;amp; C \\\
\mathcal{A}(X) &amp;amp; = &amp;amp; b \\\
XS &amp;amp; = &amp;amp; 0 \\\
X,S &amp;amp; \succeq &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;central-path-for-sdp&quot;&gt;Central path for SDP&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Primal barrier problem&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp; {C \cdot X−τ \log(det(X))} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {A(X) = b} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Dual barrier problem&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\max_{y, S} &amp;amp;&amp;amp; {b^Ty + τ \log(det(S))} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {\mathcal{A}^∗(y) + S = C} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Primal &amp;amp; dual을 위한 Optimality conditions&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
\mathcal{A}^∗(y) + S &amp;amp; = &amp;amp; C \\\
\mathcal{A}(X) &amp;amp; = &amp;amp; b \\\
XS &amp;amp; = &amp;amp; τI \\\
X,S &amp;amp; \succ &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;newton-step&quot;&gt;Newton step&lt;/h2&gt;
&lt;p&gt;Primal central path equations&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
\mathcal{A}^∗(y) + \tau X^{−1} &amp;amp; = &amp;amp; C \\\
\mathcal{A}(X) &amp;amp; = &amp;amp; b \\\
X &amp;amp; \succ &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;Newton equations&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(τX^{−1}\Delta XX^{−1} +\mathcal{A}^∗(\Delta y) = −(\mathcal{A}^∗(y) + \tau X^{−1} −C)\)
\(\mathcal{A}(\Delta X) = −(\mathcal{A}(X)−b)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The central path equation and Newton equation for the dual are similarly defined including \((y,S)\).&lt;/p&gt;

&lt;h2 id=&quot;primal-dual-newton-step&quot;&gt;Primal-dual Newton step&lt;/h2&gt;
&lt;p&gt;Primal central path equations&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{bmatrix}
\mathcal{A}^∗(y) + S - C  \\\
\mathcal{A}(X) - b \\\
XS
\end{bmatrix} =
\begin{bmatrix}
0 \\\
0 \\\
τI
\end{bmatrix}
, X, S \succ 0\]
&lt;/blockquote&gt;

&lt;p&gt;Newton step:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{bmatrix}
0 &amp;amp; \mathcal{A}^∗ &amp;amp; I \\\
\mathcal{A} &amp;amp; 0 &amp;amp; 0 \\\
S &amp;amp; 0 &amp;amp; X 
\end{bmatrix}
\begin{bmatrix}
\Delta X \\\
\Delta y \\\
\Delta S
\end{bmatrix}= −
\begin{bmatrix}
\mathcal{A}^∗(y) + s−c \\\
\mathcal{A}(x) − b \\\
XS − \tau I 
\end{bmatrix}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>17-04 Special case, linear programming</title>
   <link href="http://localhost:4000/contents/vi/chapter17/17_04_special_case_linear_programming/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter17/17_04_special_case_linear_programming</id>
   <content type="html">&lt;p&gt;In this section, let’s look at an example of the Primal-Dual method for LP (linear programming) problems.&lt;/p&gt;

&lt;h2 id=&quot;linear-programming&quot;&gt;Linear programming&lt;/h2&gt;
&lt;p&gt;Consider the following primal LP problem.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp; {c^Tx} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {Ax = b} \\\\
   &amp;amp; &amp;amp;&amp;amp;{x ≥ 0} \\\
\end{align}\]

\[\text{for } c ∈R^n, A ∈R^{m×n}, b ∈R^m\]
&lt;/blockquote&gt;

&lt;p&gt;The dual problem of the above primal LP problem is as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\max_{y,s}  &amp;amp;&amp;amp; {b^Ty} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {A^Ty + s = c} \\\\
   &amp;amp; &amp;amp;&amp;amp;{s ≥ 0} \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;optimality-conditions-and-central-path-equations&quot;&gt;Optimality conditions and central path equations&lt;/h2&gt;
&lt;p&gt;The following shows the optimality conditions (KKT Conditions) for the primal-dual problem of the previous LP.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
A^Ty + s &amp;amp; = &amp;amp; c \\\
Ax &amp;amp; = &amp;amp; b \\\
XS\mathbb{1} &amp;amp; = &amp;amp; 0 \\\
x,s  &amp;amp; \succeq &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;Central path equations&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
A^Ty + s &amp;amp; = &amp;amp; c \\\
Ax &amp;amp; = &amp;amp; b \\\
XS\mathbb{1} &amp;amp; = &amp;amp; τ\mathbb{1} \\\
x,s  &amp;amp; &amp;gt; &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;primal-dual-method-vs-barrier-method&quot;&gt;Primal-dual method vs. barrier method&lt;/h2&gt;
&lt;h3 id=&quot;newton-steps-for-primer-dual-method&quot;&gt;Newton steps for primer-dual method&lt;/h3&gt;
&lt;p&gt;The following is the Newton equation for the primal-dual method for LP problems.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{bmatrix}
0 &amp;amp; A^T &amp;amp; I \\\
A &amp;amp; 0 &amp;amp; 0 \\\
S &amp;amp; 0 &amp;amp; X 
\end{bmatrix}
\begin{bmatrix}
∆x \\\
∆y \\\
∆s 
\end{bmatrix}= −
\begin{bmatrix}
A^Ty + s−c \\\
Ax−b \\\
XS\mathbb{1}−τ\mathbb{1} 
\end{bmatrix}\]
&lt;/blockquote&gt;

&lt;p&gt;From the optimal condition, we can know the following relationship.&lt;/p&gt;

\[XS\mathbb{1} = \tau \mathbb{1} \iff s = \tau X^{−1}\mathbb{1} \iff x = \tau S^{−1}\mathbb{1}\]

&lt;p&gt;Accordingly, we can obtain optimal conditions for the primal barrier problem by removing \(s\), or obtain optimal conditions for the dual barrier problem by removing \(x\).&lt;/p&gt;

&lt;h3 id=&quot;newton-steps-for-barrier-problems&quot;&gt;Newton steps for barrier problems&lt;/h3&gt;
&lt;p&gt;The following are the primal and dual central path equations for the barrier problem. (Left is primal, right is dual)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcr}
A^Ty + τX^{−1}1 &amp;amp; = &amp;amp; c &amp;amp; \qquad \qquad &amp;amp; A^Ty + s &amp;amp; = &amp;amp; c \\\
Ax &amp;amp; = &amp;amp; b &amp;amp; \qquad \qquad &amp;amp; τAS^{−1}\mathbb{1} &amp;amp; = &amp;amp; b\\\
x &amp;amp; &amp;gt; &amp;amp; 0 &amp;amp; \qquad \qquad &amp;amp; s &amp;amp; &amp;gt; &amp;amp; 0
\end{array}\]

&lt;/blockquote&gt;

&lt;p&gt;Using the above central path equations, the Newton steps for primal and dual are as follows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Primal Newton step&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{bmatrix}
τX^{−2} &amp;amp; A^T \\\
A &amp;amp; 0
\end{bmatrix}
\begin{bmatrix}
∆x \\\
∆y
\end{bmatrix}= −
\begin{bmatrix}
A^Ty + τX^{−1}\mathbb{1}−c \\\
Ax−b 
\end{bmatrix}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Dual Newton step&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{bmatrix}
A^T &amp;amp; I \\\
0 &amp;amp; τAS^{−2}
\end{bmatrix}
\begin{bmatrix}
∆y \\\
∆s
\end{bmatrix}= −
\begin{bmatrix}
A^Ty + s −c \\\
τAS^{−1}\mathbb{1}−b
\end{bmatrix}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;example-barrier-versus-primal-dual&quot;&gt;Example: barrier versus primal-dual&lt;/h2&gt;
&lt;h3 id=&quot;standard-lp--n--50-m--100&quot;&gt;Standard LP : \(n = 50\), \(m = 100\)&lt;/h3&gt;
&lt;p&gt;To verify the performance of the Primal-dual method, let’s look at an example of a standard LP problem with \(n = 50\) variables and \(m = 100\) equality constraints. (Example from B &amp;amp; V 11.3.2 and 11.7.4)&lt;/p&gt;

&lt;p&gt;The Barrier method used various \(\mu\) values (2, 50, 150) while the primal-dual method fixed \(\mu\) at 10.
Both methods used \(\alpha = 0.01, \beta = 0.5\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter17/barrier_vs_primal_dual.png&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Duality gap (Barrier vs. Primal-dual) [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;As can be seen from the graph, primal-dual converges quickly while showing high accuracy.&lt;/p&gt;

&lt;h3 id=&quot;sequence-of-problem--n--2m-and-n-growing&quot;&gt;Sequence of problem : \(n = 2m\) and \(n\) growing.&lt;/h3&gt;
&lt;p&gt;Now let’s look at the performance for a series of problems where \(n = 2m\) and \(n\) gradually increases.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The Barrier method used \(\mu = 100\) and the outer loop was performed only about 2 times. (The duality gap was reduced to \(10^4\))&lt;/li&gt;
  &lt;li&gt;The Primal-dual method used \(\mu = 10\) and stopped execution when the duality gap and feasibility gap were approximately \(10^{-8}\).&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter17/barrier_vs_primal_dual2.png&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Newton iteration (Barrier vs. Primal-dual) [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;As can be seen from the above figure, the Primal-dual method finds solutions with higher accuracy but requires some additional iterations.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>17-03 Some history</title>
   <link href="http://localhost:4000/contents/vi/chapter17/17_03_some_history/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter17/17_03_some_history</id>
   <content type="html">&lt;p&gt;Generally, modern state-of-the-art LP Solvers use both Simplex method and interior-point method.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Dantzig (1940s): Simplex method, the first method to solve the general form of LP, obtaining exact solutions without iteration. It remains one of the best-known and most studied algorithms for LP to this day.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Klee and Minty (1972): A pathological LP with \(n\) variables and \(2n\) constraints. Solving with the Simplex method requires \(2^n\) iterations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Khachiyan (1979): A polynomial-time algorithm for LP based on the ellipsoid method of Nemirovski and Yudin (1976), which is theoretically strong but not so in practice.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Karmarkar (1984): An interior-point polynomial-time LP method that is quite effective and became a breakthrough research. (US Patent 4,744,026, expired in 2006).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Renegar (1988): Newton-based interior-point algorithm for LP. It had the theoretically best computational complexity until the latest research by Lee-Sidford emerged.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>17-02 Primal-dual interior-point method</title>
   <link href="http://localhost:4000/contents/vi/chapter17/17_02_primal_dual_interior_point_method/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter17/17_02_primal_dual_interior_point_method</id>
   <content type="html">&lt;p&gt;Like the barrier method, the &lt;strong&gt;primal-dual interior-point method&lt;/strong&gt; also aims to (approximately) compute points on the central path. However, the two methods have several differences.&lt;/p&gt;

&lt;h2 id=&quot;differences-between-primal-dual-interior-point-method-and-barrier-method&quot;&gt;Differences between Primal-dual interior-point method and barrier method&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Generally performs &lt;strong&gt;one Newton step&lt;/strong&gt; per iteration. (That is, there is no additional loop for the centering step.)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Does not necessarily need to be feasible&lt;/strong&gt;. (Pushes toward feasible regions through backtracking line search.)&lt;/li&gt;
  &lt;li&gt;Generally &lt;strong&gt;more effective&lt;/strong&gt;. Particularly shows superior performance compared to linear convergence under appropriate conditions.&lt;/li&gt;
  &lt;li&gt;Somewhat less intuitive compared to the barrier method.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>17-02-03 Primal-Dual Algorithm</title>
   <link href="http://localhost:4000/contents/vi/chapter17/17_02_03_primal_dual_algorithm/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter17/17_02_03_primal_dual_algorithm</id>
   <content type="html">&lt;p&gt;To define the Primal-Dual algorithm, let’s first define \(\tau(x,u)\) as follows&lt;/p&gt;
&lt;blockquote&gt;
\[\tau(x,u) := -\frac{h(x)^Tu}{m} \quad \text{with} \quad h (x) \le 0, u \ge 0\]
&lt;/blockquote&gt;

&lt;p&gt;For reference, \(t\) and \(\mu\) in the Barrier method are redefined and denoted as \(\tau\) and \(\sigma\) in the Primal-Dual algorithm.&lt;/p&gt;
&lt;blockquote&gt;
\[\tau = \frac{1}{t}, \quad \sigma = \frac{1}{\mu}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;primal-dual-algorithm&quot;&gt;Primal-Dual Algorithm&lt;/h2&gt;
&lt;p&gt;The Primal-Dual algorithm is as follows.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Choose \(\sigma\) (\(\sigma ∈ (0,1)\))&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;Choose \((x^0,u^0,v^0)\) \((h(x^0) &amp;lt; 0\). \(u^0 &amp;gt; 0\))&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;Repeat the following steps (\(k = 0,1,...\))&lt;br /&gt;
\(\quad\) * Calculate Newton step :&lt;br /&gt;
\(\qquad \quad (x,u,v) = (x^k,u^k,v^k)\) &lt;br /&gt;
\(\qquad \quad \tau := \sigma \tau(x^k,u^k)\) 계산&lt;br /&gt;
\(\qquad \quad \tau\)에 대해 \((\Delta x,\Delta u,\Delta v)\) 계산&lt;br /&gt;
\(\quad\) * Select step length \(θ_k\) with Backtracking&lt;br /&gt;
\(\quad\) * Primal-Dual update :&lt;br /&gt;
\(\qquad \quad (x^{k+1},u^{k+1},v^{k+1}) := (x^k,u^k,v^k) + \theta_k(\Delta x,\Delta u,\Delta v)\)&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;Termination condition : Stop if the conditions \(-h(x^{k+1})^Tu \le \epsilon\) and \((\parallel r_{prim} \parallel^2_2 + \parallel r_{dual} \parallel^2_2)^{1/2} \le \epsilon\) are satisfied &lt;br /&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;The algorithm calculates \((\Delta x,\Delta u,\Delta v)\) by executing Newton step at each stage and obtains \((x^{k+1},u^{k+1},v^{k+1})\) by performing Primal-Dual updates. However, \(\theta_k\) is selected through Backtracking line search so that the Primal-Dual variables become feasible. The algorithm terminates when the surrogate duality gap and primal and dual residuals become smaller than \(\epsilon\).&lt;/p&gt;

&lt;h2 id=&quot;backtracking-line-search&quot;&gt;Backtracking line search&lt;/h2&gt;
&lt;p&gt;Since the Primal-Dual algorithm executes Newton step only once, it can be viewed as finding the direction of the solution rather than finding the exact solution. Therefore, an appropriate step length must be found so that moving in that direction can enter the feasible set.&lt;/p&gt;

&lt;p&gt;That is, at each step of the algorithm, \(θ\) is obtained to update the primal-dual variables.&lt;/p&gt;

&lt;blockquote&gt;
\[x^+ = x + θ\Delta x, \quad  u^+ = u + θ\Delta u, \quad v^+ = v + θ\Delta v\]
&lt;/blockquote&gt;

&lt;p&gt;This process has two main objectives.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Maintaining the condition \(h(x) &amp;lt; 0, u &amp;gt; 0\)&lt;/li&gt;
  &lt;li&gt;Decreasing \(\parallel r(x,u,v) \parallel\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this purpose, &lt;strong&gt;multi-stage backtracking line search&lt;/strong&gt; is used.&lt;/p&gt;

&lt;h3 id=&quot;stage-1-dual-feasibility-u-gt-0&quot;&gt;Stage 1: dual feasibility \(u \gt 0\)&lt;/h3&gt;
&lt;p&gt;Initially, we start with the largest step \(\theta_{max} \leq 1\) that satisfies \(u + \theta \Delta u \geq 0\).&lt;/p&gt;

&lt;blockquote&gt;
\[\theta_{\max} = \min \Biggl\{1,\  \min \Bigl\{ −\frac{u_i}{\Delta u_i} : ∆u_i &amp;lt; 0 \Bigr\} \Biggr\}\]
&lt;/blockquote&gt;

&lt;p&gt;The above equation is derived as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;u + \theta \Delta u &amp;amp;&amp;amp; \ge 0  \\\\
\Leftrightarrow \quad &amp;amp;u &amp;amp;&amp;amp; \ge -\theta \Delta u \\\\
\Leftrightarrow \quad &amp;amp;- u/\Delta u &amp;amp;&amp;amp; \ge \theta \quad  \text{ such that }-\Delta u \gt 0  \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This is the process of making \(u\) feasible.&lt;/p&gt;

&lt;h3 id=&quot;stage-2-primal-feasibility-hx-lt-0&quot;&gt;Stage 2: primal feasibility \(h(x) \lt 0\)&lt;/h3&gt;
&lt;p&gt;Next, with parameters \(\alpha, \beta \in (0,1)\) and \(\theta\) set to \(0.99\theta_{max}\), the following update is performed.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Update \(\theta = \beta\theta\) until \(h_i(x^+) &amp;lt; 0, i = 1,...m\) is satisfied &lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is the process of making \(x\) feasible.&lt;/p&gt;

&lt;h3 id=&quot;stage-3--reduce-parallel-rxuv-parallel&quot;&gt;Stage 3 : reduce \(\parallel r(x,u,v) \parallel\)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Update \(\theta = \beta \theta\) until \(\| r(x^+,u^+,v^+) \| \leq (1−\alpha \theta) \| r(x,u,v) \|\) is satisfied&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The update equation in Stage 3 is the same as the existing backtracking line search algorithm.&lt;/p&gt;

&lt;p&gt;The right-hand side of the above equation can be derived as follows. First, we obtain the following result from Newton’s method.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\Delta w = (\Delta x, \Delta u, \Delta v) &amp;amp;\approx -r^{&apos;}(w)^{-1} r(w) \\\\
\Leftrightarrow r(w)  &amp;amp;\approx  -r^{&apos;}(w) \Delta w \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Since \(r^{&apos;}(w) \Delta w \approx -r(w)\) in the above equation, we substitute this into the first-order Taylor approximation below.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
r(w + \theta \Delta w) &amp;amp; \approx r(w) +  r^{&apos;}(w) (\theta \Delta w) \\\\
&amp;amp;\approx (1-\theta) r(w) \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;As a result, we get \(r(w + \alpha \theta \Delta w) \approx (1-\alpha  \theta) r(w)\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>17-02-02 Surrogate duality gap, residuals</title>
   <link href="http://localhost:4000/contents/vi/chapter17/17_02_02_surrogate_duality_gap_residuals/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter17/17_02_02_surrogate_duality_gap_residuals</id>
   <content type="html">&lt;p&gt;To define the Primal-Dual algorithm, let’s first define three types of residuals and the surrogate duality gap. Residuals and surrogate duality gap are the objectives to be minimized in the Primal-Dual algorithm.&lt;/p&gt;

&lt;h2 id=&quot;residuals&quot;&gt;Residuals&lt;/h2&gt;
&lt;p&gt;The dual, central, and primal residuals at \((x,u,v)\) are defined as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(r_{dual} = \nabla f(x) +\nabla h(x)u + A^Tv\\\)
\(r_{cent} =  Uh(x) + τ\mathbb{1} \\\) 
\(r_{prim} = Ax−b\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;These correspond to each row of the function \(r(x,u,v)\). The &lt;strong&gt;Primal-dual interior point method&lt;/strong&gt; executes in the direction of satisfying 0 rather than continuously making these three residuals equal to 0. This means that it is not necessary to be feasible during the execution process.&lt;/p&gt;

&lt;p&gt;The reason \(r_{dual}\) is called the dual residual is that, as shown in the equation below, if \(r_{dual} = 0\), it guarantees that \(u, v\) are in the domain of \(g\), which means dual feasible.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; r_{dual} = \nabla f(x) +\nabla h(x)u + A^Tv = 0 \\\\
&amp;amp; \iff \min_{x} L(x,u.v) = g(u,v) \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Similarly, satisfying \(r_{prim}=0\) means primal feasible, so \(r_{prim}\) is called the primal residual.&lt;/p&gt;

&lt;h2 id=&quot;surrogate-duality-gap&quot;&gt;Surrogate duality gap&lt;/h2&gt;
&lt;p&gt;While the barrier method has a duality gap because it is feasible, the primal-dual interior-point method uses &lt;strong&gt;surrogate duality gap&lt;/strong&gt; because it doesn’t necessarily need to be feasible. &lt;strong&gt;Surrogate duality gap&lt;/strong&gt; is defined by the following equation.&lt;/p&gt;

&lt;blockquote&gt;
\[−h(x)^Tu  \quad \text{for} \quad h(x) \le 0, u \ge 0\]
&lt;/blockquote&gt;

&lt;p&gt;If \(r_{dual} = 0\) and \(r_{prim} = 0\), then the surrogate duality gap becomes the true duality gap. In other words, if primal and dual feasible, the surrogate duality gap becomes equal to the actual duality gap \(\frac{m}{t}\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Reference] Perturbed KKT conditions and parameter t&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In the perturbed KKT conditions, the parameter t is \(t = −\frac{m}{h(x)^Tu}\).&lt;/li&gt;
  &lt;li&gt;For detailed information, see &lt;a href=&quot;/contents/en/chapter15/chapter16/15_03_01_perturbed_kkt_conditions/&quot;&gt;15-03-01 Perturbed KKT conditions&lt;/a&gt; and &lt;a href=&quot;/contents/en/chapter15/15_03_02_suboptimality_gap/&quot;&gt;15-03-02 Suboptimality gap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Furthermore, if \(u &amp;gt; 0,h(x) &amp;lt; 0\) and the following condition is satisfied, then \((x,u,v)\) exists on the central path.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(r(x,u,v) = 0\) for \(\tau = -\frac{h(x)^Tu}{m}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In other words, the residual is 0 at points existing on the central path.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>17-02-01 Central path equations and Newton step</title>
   <link href="http://localhost:4000/contents/vi/chapter17/17_02_01_central_path_equations_and_newton_step/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter17/17_02_01_central_path_equations_and_newton_step</id>
   <content type="html">&lt;p&gt;The &lt;strong&gt;Primal-dual interior-point method&lt;/strong&gt; is a method that finds solutions by finding the central path, similar to the barrier method. To do this, it defines perturbed KKT conditions as residual functions and finds solutions that make them zero. This section aims to explain this approach.&lt;/p&gt;

&lt;h2 id=&quot;central-path-equations&quot;&gt;Central path equations&lt;/h2&gt;
&lt;p&gt;By moving the right-hand side to the left-hand side in the central path equations explained in the previous &lt;a href=&quot;/contents/vi/chapter17/17_01_barrier_method_duality_optimality_revisited/&quot;&gt;17-01 Optimality conditions&lt;/a&gt;, we can organize them as follows. (The optimality conditions of central path equations are also called perturbed KKT conditions.)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
∇f(x) +∇h(x)u + A^Tv &amp;amp; = &amp;amp; 0 \\\
 Uh(x) + \tau\mathbb{1}  &amp;amp; = &amp;amp; 0 \\\
Ax−b &amp;amp; = &amp;amp; 0 \\\
u,−h(x)  &amp;amp; &amp;gt; &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;Note that the complementary slackness and inequality constraints in the KKT conditions for the original problem differ from those in the perturbed KKT conditions. For the original problem, \(Uh(x) = 0\) and \(u,−h(x)  \ge 0\), but in the perturbed KKT conditions, \(Uh(x) = - \tau\mathbb{1}\) and \(u,−h(x)  \gt 0\).&lt;/p&gt;

&lt;p&gt;These organized nonlinear equations, the perturbed KKT conditions, can be solved by approximating them as linear equations using the root finding version of Newton’s method.&lt;/p&gt;

&lt;h2 id=&quot;newton-step&quot;&gt;Newton step&lt;/h2&gt;
&lt;p&gt;Now let’s learn about the method of finding solutions by linearly approximating the perturbed KKT conditions. The perturbed KKT conditions equation can be defined as the following residual function \(r(x, u, v) = 0\). (The reason for naming it residual is that these values must be 0 to be optimal.)&lt;/p&gt;

&lt;blockquote&gt;
\[r(x,u,v) :=
\begin{bmatrix}
∇f(x) +∇h(x)u + A^Tv \\\
Uh(x) + τ\mathbb{1} \\\
Ax−b
\end{bmatrix}, H(x) = \text{Diag}(h(x))\]
&lt;/blockquote&gt;

&lt;p&gt;To find the roots of the function, approximating \(r(x, u, v)\) with a first-order Taylor expansion gives us the following. (This process approximates non-linear equations to linear equations. For detailed information, see &lt;a href=&quot;/contents/vi/chapter14/14_01_newton_method/&quot;&gt;14-02-01 Root finding&lt;/a&gt;)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
0 &amp;amp; = r(x + \Delta x, u + \Delta u, r + \Delta v)  \\\\
  &amp;amp; \approx r(x, u, v) + \nabla r(x, u, v) 
\begin{pmatrix}
\Delta x \\\\
\Delta u \\\\
\Delta v \\\\
\end{pmatrix} \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Accordingly, the function \(r(x, u, v)\) can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\nabla r(x, u, v) 
\begin{pmatrix}
\Delta x \\\\
\Delta u \\\\
\Delta v \\\\
\end{pmatrix} = -r(x, u, v) \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;By differentiating \(r(x, u, v)\) with respect to \(x, u, v\) to obtain the Jacobian matrix \(\nabla r(x, u, v)\) and substituting the above equation, we get the following.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{bmatrix}
\nabla^2f(x) + \sum_i u_i \nabla^2h_i(x) &amp;amp; \nabla h(x) &amp;amp; A^T \\\
 U \nabla  h(x)^T &amp;amp; H(x) &amp;amp; 0 \\\
A &amp;amp; 0 &amp;amp; 0
\end{bmatrix}
\begin{bmatrix}
\Delta x \\\
\Delta u \\\
\Delta v
\end{bmatrix} = −r(x,u,v)\)
where
\(r(x,u,v) :=
\begin{bmatrix}
\nabla f(x) +\nabla h(x)u + A^Tv \\\
Uh(x) + τ\mathbb{1} \\\
Ax−b
\end{bmatrix}, H(x) = \text{Diag}(h(x))\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The solution \((\Delta x, \Delta u, \Delta v)\) to this equation is the update direction for the primal and dual variables. The reason why the method introduced in this chapter is called the &lt;strong&gt;Primal-Dual&lt;/strong&gt; interior point method is that it simultaneously updates primal and dual variables using residual functions.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>17-01 Barrier method & duality & optimality revisited</title>
   <link href="http://localhost:4000/contents/vi/chapter17/17_01_barrier_method_duality_optimality_revisited/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter17/17_01_barrier_method_duality_optimality_revisited</id>
   <content type="html">&lt;p&gt;In Chapter 15, we examined the barrier method, and in Chapters 13 and 16, we looked at duality.
Before covering the content of this chapter, we want to briefly review the barrier method and duality.&lt;/p&gt;

&lt;h2 id=&quot;barrier-method&quot;&gt;Barrier method&lt;/h2&gt;
&lt;p&gt;When the following primal problem is convex and \(f, h_i , i = 1, . . . m\) are differentiable,&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp; f(x) \\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;h_{i}(x) \leq 0, i = 1, \dotsc, m \\
&amp;amp;&amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Using the log barrier function, the primal problem can be transformed into a barrier problem as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \min_{x} &amp;amp;&amp;amp; f(x) + \frac{1}{t} \phi(x) &amp;amp; \qquad &amp;amp; \min_{x} &amp;amp;&amp;amp; tf(x) + \phi(x) \\
&amp;amp; \text{subject to } &amp;amp;&amp;amp; Ax = b &amp;amp; \iff \qquad &amp;amp; \text{subject to } &amp;amp;&amp;amp; Ax = b \\
&amp;amp; \text{where } &amp;amp;&amp;amp; \phi(x) = - \sum_{i=1}^{m} \log(-h_i(x))
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The algorithm starts with \(t = t^{(0)}\) satisfying \(t &amp;gt; 0\) and increases until \(\frac{m}{t}\) becomes less than or equal to \(\epsilon\). At this time, Newton’s method is used to find \(x^{\star}(t)\) for the initial value \(x^{(0)}\), and the process of finding \(x^{(k+1)} = x^{\star}(t)\) at each step for \(k = 1, 2, 3, . . .\) is repeated.&lt;/p&gt;

&lt;p&gt;The algorithm can be briefly summarized as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Choose \(t^{(0)} \gt 0\) and \(k := 0\).&lt;/li&gt;
  &lt;li&gt;Solve the barrier problem at \(t = t^{(0)}\) to find \(x^{(0)} = x^{\star}(t)\).&lt;/li&gt;
  &lt;li&gt;While \(m/t \gt \epsilon\) &lt;br /&gt;
  3-1. Update \(t^{(k+1)} = µt\) where \((µ &amp;gt; 1)\) &lt;br /&gt;
  3-2. Initialize Newton’s method with \(x^{(k)}\) (warm start)&lt;br /&gt;
     Solve the barrier problem at \(t = t^{(k+1)}\) to find \(x^{(k+1)} = x^{\star}(t)\).&lt;br /&gt;
  end while&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, see &lt;a href=&quot;/contents/vi/chapter15/15_01_02_log_barrier_function_and_barrier_method/&quot;&gt;15-01-02 Log barrier function &amp;amp; barrier method&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;duality&quot;&gt;Duality&lt;/h2&gt;
&lt;p&gt;When the following primal problem is given:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad f(x) \\\\
   \text{subject to} &amp;amp;\quad f Ax = b \\\\
   &amp;amp;\quad h(x) \le 0
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This can be transformed into Lagrangian form as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[L(x,u,v) = f(x) + u^Th(x) + v^T(Ax - b)\]
&lt;/blockquote&gt;

&lt;p&gt;Using the Lagrangian defined in this way, primal and dual problems can be redefined in the following form. Please refer to Chapter 16 for detailed information.&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;primal-problem&quot;&gt;Primal Problem&lt;/h3&gt;
&lt;blockquote&gt;
\[\min_x \mathop{\max_{u,v}}_{u \geq 0} L(x,u,v)\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;dual-problem&quot;&gt;Dual problem&lt;/h3&gt;
&lt;blockquote&gt;
\[\mathop{\max_{u,v}}_{u \geq 0} \min_x L(x,u,v)\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;optimality-conditions&quot;&gt;Optimality conditions&lt;/h2&gt;

&lt;p&gt;When \(f,h_1,...h_m\) are convex and differentiable, and the given problem satisfies strong duality, the KKT optimality conditions for this problem are as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{array}{rcl}
∇f(x) +∇h(x)u + A^Tv &amp;amp; = &amp;amp; 0 &amp;amp; \text{(Stationarity)}\\\
 Uh(x) &amp;amp; = &amp;amp; 0 &amp;amp; \text{(Complementary Slackness)} \\\
Ax &amp;amp; = &amp;amp; b &amp;amp; \text{(Primal Feasibility)}\\\
u,−h(x)  &amp;amp; ≥ &amp;amp; 0 &amp;amp; \text{(Dual Feasibility)}
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(U\) means \(\text{diag}(u)\), and \(∇h(x)\) means \([ ∇h_1(x) ··· ∇h_m(x) ]\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, see &lt;a href=&quot;/contents/vi/chapter12/12_00_KKT_conditions/&quot;&gt;Chapter 12 KKT conditions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;central-path-equations&quot;&gt;Central path equations&lt;/h2&gt;
&lt;p&gt;The function \(f(x)\) can be redefined as a barrier problem as follows.&lt;br /&gt;
In the equation below, \(τ\) is \(\frac{1}{t}\), and by making \(τ\) gradually approach 0 and iteratively finding solutions, we ultimately obtain the solution to the original problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp; {f(x) + τ\phi(x)} \\\\
&amp;amp; &amp;amp;&amp;amp;{Ax = b} \\\
&amp;amp; \text{where } &amp;amp;&amp;amp; \phi(x) = −\sum_{i=1}^m \log(−h_i(x)).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;That is, in the above equation, differences from the primal problem occur depending on \(τ\), and the trajectory generated according to \(τ\), i.e., the set of solutions to the barrier problem, is called the central path.&lt;/p&gt;

&lt;p&gt;And the optimality conditions for this barrier problem are as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
∇f(x) +∇h(x)u + A^Tv  &amp;amp; = &amp;amp; 0 \\\
Uh(x) &amp;amp; = &amp;amp; −τ\mathbb{1} \\\
Ax &amp;amp; = &amp;amp; b \\\
u,−h(x)  &amp;amp; &amp;gt; &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, see &lt;a href=&quot;/contents/vi/chapter16/16_02_optimality_conditions/&quot;&gt;16-02 Optimality conditions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;strong&gt;Primal-Dual interior point method&lt;/strong&gt; introduced in this chapter is a method that defines the first three equations above as residuals and finds solutions by reducing them to \(0\).&lt;/p&gt;

&lt;h4 id=&quot;useful-fact&quot;&gt;Useful fact&lt;/h4&gt;
&lt;p&gt;The solution \((x(τ),u(τ),v(τ))\) has a duality gap of size \(mτ\), i.e., \(\frac{m}{t}\), as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[f(x(τ))−\min_x L(x,u(τ),v(τ)) = mτ= \frac{m}{t}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>17 Primal-Dual Interior-Point Methods</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_primal_dual_interior_point_method/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter17/17_primal_dual_interior_point_method</id>
   <content type="html">&lt;p&gt;In this chapter, we will examine the &lt;strong&gt;Primal-Dual Interior-Point Method&lt;/strong&gt;, which improves performance by reducing the centering step of the Barrier method we learned earlier to a single step.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Primal-Dual Interior-Point Method&lt;/strong&gt; relaxes the constraint that the centering step must be feasible and uses the root finding version of Newton’s Method to approximate nonlinear equations with linear equations to find solutions, making it faster and more accurate than the Barrier method.&lt;/p&gt;

&lt;h2 id=&quot;references-and-further-readings&quot;&gt;References and further readings&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;S. Boyd and L. Vandenberghe (2004), “Convex optimization,” Chapter 11&lt;/li&gt;
  &lt;li&gt;S. Wright (1997), “Primal-dual interior-point methods,” Chapters 5 and 6&lt;/li&gt;
  &lt;li&gt;J. Renegar (2001), “A mathematical view of interior-point methods”&lt;/li&gt;
  &lt;li&gt;Y. Nesterov and M. Todd (1998), “Primal-dual interior-point methods for self-scaled cones.” SIAM J. Optim.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>17-05 Optimality conditions for semidefinite programming</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_05_optimality_conditions_for_semidefinite_programming/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter17/17_05_optimality_conditions_for_semidefinite_programming</id>
   <content type="html">&lt;p&gt;In this section, we want to look at an example of the Primal-Dual method for SDP (semidefinite programming) problems.&lt;/p&gt;

&lt;h2 id=&quot;sdp-semidefinite-programming&quot;&gt;SDP (semidefinite programming)&lt;/h2&gt;
&lt;p&gt;The primal problem of SDP is defined as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp; {C \cdot X} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {A_i \cdot X = b_i, i = 1,...,m} \\\\
   &amp;amp; &amp;amp;&amp;amp;{X \succeq 0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The dual problem of SDP is defined as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\max_{y} &amp;amp;&amp;amp; {b^Ty} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {\sum^m_{X_i=1} y_iA_i + S = C} \\\\
   &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For reference, the trace inner product of \(\mathbb{S}^n\) is denoted as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[X \cdot S = \text{trace}(XS)\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;optimality-conditions-for-sdp&quot;&gt;Optimality conditions for SDP&lt;/h2&gt;
&lt;p&gt;The primal and dual problems of SDP can be defined using linear maps as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp; {C \cdot X} &amp;amp; \qquad \qquad \qquad &amp;amp; \max_{y,S}  &amp;amp;&amp;amp; {b^Ty} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {\mathcal{A}(X) = b} &amp;amp; \qquad \qquad \qquad &amp;amp; \text{subject to } &amp;amp;&amp;amp; {\mathcal{A}^{∗}(y) + S = C} \\\\\
   &amp;amp; &amp;amp;&amp;amp;{X \succeq 0} &amp;amp; \qquad \qquad \qquad &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here \(\mathcal{A}: \mathbb{S}^n \to \mathbb{R}^m\) means a linear map.&lt;/p&gt;

&lt;p&gt;Assuming strong duality is satisfied, \(X^{\star}\) and \((y^{\star}, S^{\star})\) where \((X^{\star}, y^{\star}, S^{\star})\) is a solution are optimal solutions for primal and dual, and vice versa.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{array}{rcl}
\mathcal{A}^∗(y) + S &amp;amp; = &amp;amp; C \\\
\mathcal{A}(X) &amp;amp; = &amp;amp; b \\\
XS &amp;amp; = &amp;amp; 0 \\\
X,S &amp;amp; \succeq &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;central-path-for-sdp&quot;&gt;Central path for SDP&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Primal barrier problem&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp; {C \cdot X−τ \log(det(X))} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {A(X) = b} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Dual barrier problem&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\max_{y, S} &amp;amp;&amp;amp; {b^Ty + τ \log(det(S))} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {\mathcal{A}^∗(y) + S = C} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Primal &amp;amp; dual을 위한 Optimality conditions&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
\mathcal{A}^∗(y) + S &amp;amp; = &amp;amp; C \\\
\mathcal{A}(X) &amp;amp; = &amp;amp; b \\\
XS &amp;amp; = &amp;amp; τI \\\
X,S &amp;amp; \succ &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;newton-step&quot;&gt;Newton step&lt;/h2&gt;
&lt;p&gt;Primal central path equations&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
\mathcal{A}^∗(y) + \tau X^{−1} &amp;amp; = &amp;amp; C \\\
\mathcal{A}(X) &amp;amp; = &amp;amp; b \\\
X &amp;amp; \succ &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;Newton equations&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(τX^{−1}\Delta XX^{−1} +\mathcal{A}^∗(\Delta y) = −(\mathcal{A}^∗(y) + \tau X^{−1} −C)\)
\(\mathcal{A}(\Delta X) = −(\mathcal{A}(X)−b)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The central path equation and Newton equation for the dual are similarly defined including \((y,S)\).&lt;/p&gt;

&lt;h2 id=&quot;primal-dual-newton-step&quot;&gt;Primal-dual Newton step&lt;/h2&gt;
&lt;p&gt;Primal central path equations&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{bmatrix}
\mathcal{A}^∗(y) + S - C  \\\
\mathcal{A}(X) - b \\\
XS
\end{bmatrix} =
\begin{bmatrix}
0 \\\
0 \\\
τI
\end{bmatrix}
, X, S \succ 0\]
&lt;/blockquote&gt;

&lt;p&gt;Newton step:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{bmatrix}
0 &amp;amp; \mathcal{A}^∗ &amp;amp; I \\\
\mathcal{A} &amp;amp; 0 &amp;amp; 0 \\\
S &amp;amp; 0 &amp;amp; X 
\end{bmatrix}
\begin{bmatrix}
\Delta X \\\
\Delta y \\\
\Delta S
\end{bmatrix}= −
\begin{bmatrix}
\mathcal{A}^∗(y) + s−c \\\
\mathcal{A}(x) − b \\\
XS − \tau I 
\end{bmatrix}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>17-04 Special case, linear programming</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_04_special_case_linear_programming/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter17/17_04_special_case_linear_programming</id>
   <content type="html">&lt;p&gt;In this section, let’s look at an example of the Primal-Dual method for LP (linear programming) problems.&lt;/p&gt;

&lt;h2 id=&quot;linear-programming&quot;&gt;Linear programming&lt;/h2&gt;
&lt;p&gt;Consider the following primal LP problem.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp; {c^Tx} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {Ax = b} \\\\
   &amp;amp; &amp;amp;&amp;amp;{x ≥ 0} \\\
\end{align}\]

\[\text{for } c ∈R^n, A ∈R^{m×n}, b ∈R^m\]
&lt;/blockquote&gt;

&lt;p&gt;The dual problem of the above primal LP problem is as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\max_{y,s}  &amp;amp;&amp;amp; {b^Ty} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp; {A^Ty + s = c} \\\\
   &amp;amp; &amp;amp;&amp;amp;{s ≥ 0} \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;optimality-conditions-and-central-path-equations&quot;&gt;Optimality conditions and central path equations&lt;/h2&gt;
&lt;p&gt;The following shows the optimality conditions (KKT Conditions) for the primal-dual problem of the previous LP.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
A^Ty + s &amp;amp; = &amp;amp; c \\\
Ax &amp;amp; = &amp;amp; b \\\
XS\mathbb{1} &amp;amp; = &amp;amp; 0 \\\
x,s  &amp;amp; \succeq &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;Central path equations&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
A^Ty + s &amp;amp; = &amp;amp; c \\\
Ax &amp;amp; = &amp;amp; b \\\
XS\mathbb{1} &amp;amp; = &amp;amp; τ\mathbb{1} \\\
x,s  &amp;amp; &amp;gt; &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;primal-dual-method-vs-barrier-method&quot;&gt;Primal-dual method vs. barrier method&lt;/h2&gt;
&lt;h3 id=&quot;newton-steps-for-primer-dual-method&quot;&gt;Newton steps for primer-dual method&lt;/h3&gt;
&lt;p&gt;The following is the Newton equation for the primal-dual method for LP problems.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{bmatrix}
0 &amp;amp; A^T &amp;amp; I \\\
A &amp;amp; 0 &amp;amp; 0 \\\
S &amp;amp; 0 &amp;amp; X 
\end{bmatrix}
\begin{bmatrix}
∆x \\\
∆y \\\
∆s 
\end{bmatrix}= −
\begin{bmatrix}
A^Ty + s−c \\\
Ax−b \\\
XS\mathbb{1}−τ\mathbb{1} 
\end{bmatrix}\]
&lt;/blockquote&gt;

&lt;p&gt;From the optimal condition, we can know the following relationship.&lt;/p&gt;

\[XS\mathbb{1} = \tau \mathbb{1} \iff s = \tau X^{−1}\mathbb{1} \iff x = \tau S^{−1}\mathbb{1}\]

&lt;p&gt;Accordingly, we can obtain optimal conditions for the primal barrier problem by removing \(s\), or obtain optimal conditions for the dual barrier problem by removing \(x\).&lt;/p&gt;

&lt;h3 id=&quot;newton-steps-for-barrier-problems&quot;&gt;Newton steps for barrier problems&lt;/h3&gt;
&lt;p&gt;The following are the primal and dual central path equations for the barrier problem. (Left is primal, right is dual)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcr}
A^Ty + τX^{−1}1 &amp;amp; = &amp;amp; c &amp;amp; \qquad \qquad &amp;amp; A^Ty + s &amp;amp; = &amp;amp; c \\\
Ax &amp;amp; = &amp;amp; b &amp;amp; \qquad \qquad &amp;amp; τAS^{−1}\mathbb{1} &amp;amp; = &amp;amp; b\\\
x &amp;amp; &amp;gt; &amp;amp; 0 &amp;amp; \qquad \qquad &amp;amp; s &amp;amp; &amp;gt; &amp;amp; 0
\end{array}\]

&lt;/blockquote&gt;

&lt;p&gt;Using the above central path equations, the Newton steps for primal and dual are as follows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Primal Newton step&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{bmatrix}
τX^{−2} &amp;amp; A^T \\\
A &amp;amp; 0
\end{bmatrix}
\begin{bmatrix}
∆x \\\
∆y
\end{bmatrix}= −
\begin{bmatrix}
A^Ty + τX^{−1}\mathbb{1}−c \\\
Ax−b 
\end{bmatrix}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Dual Newton step&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{bmatrix}
A^T &amp;amp; I \\\
0 &amp;amp; τAS^{−2}
\end{bmatrix}
\begin{bmatrix}
∆y \\\
∆s
\end{bmatrix}= −
\begin{bmatrix}
A^Ty + s −c \\\
τAS^{−1}\mathbb{1}−b
\end{bmatrix}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;example-barrier-versus-primal-dual&quot;&gt;Example: barrier versus primal-dual&lt;/h2&gt;
&lt;h3 id=&quot;standard-lp--n--50-m--100&quot;&gt;Standard LP : \(n = 50\), \(m = 100\)&lt;/h3&gt;
&lt;p&gt;To verify the performance of the Primal-dual method, let’s look at an example of a standard LP problem with \(n = 50\) variables and \(m = 100\) equality constraints. (Example from B &amp;amp; V 11.3.2 and 11.7.4)&lt;/p&gt;

&lt;p&gt;The Barrier method used various \(\mu\) values (2, 50, 150) while the primal-dual method fixed \(\mu\) at 10.
Both methods used \(\alpha = 0.01, \beta = 0.5\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter17/barrier_vs_primal_dual.png&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Duality gap (Barrier vs. Primal-dual) [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;As can be seen from the graph, primal-dual converges quickly while showing high accuracy.&lt;/p&gt;

&lt;h3 id=&quot;sequence-of-problem--n--2m-and-n-growing&quot;&gt;Sequence of problem : \(n = 2m\) and \(n\) growing.&lt;/h3&gt;
&lt;p&gt;Now let’s look at the performance for a series of problems where \(n = 2m\) and \(n\) gradually increases.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The Barrier method used \(\mu = 100\) and the outer loop was performed only about 2 times. (The duality gap was reduced to \(10^4\))&lt;/li&gt;
  &lt;li&gt;The Primal-dual method used \(\mu = 10\) and stopped execution when the duality gap and feasibility gap were approximately \(10^{-8}\).&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter17/barrier_vs_primal_dual2.png&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Newton iteration (Barrier vs. Primal-dual) [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;As can be seen from the above figure, the Primal-dual method finds solutions with higher accuracy but requires some additional iterations.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>17-03 Some history</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_03_some_history/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter17/17_03_some_history</id>
   <content type="html">&lt;p&gt;Generally, modern state-of-the-art LP Solvers use both Simplex method and interior-point method.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Dantzig (1940s): Simplex method, the first method to solve the general form of LP, obtaining exact solutions without iteration. It remains one of the best-known and most studied algorithms for LP to this day.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Klee and Minty (1972): A pathological LP with \(n\) variables and \(2n\) constraints. Solving with the Simplex method requires \(2^n\) iterations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Khachiyan (1979): A polynomial-time algorithm for LP based on the ellipsoid method of Nemirovski and Yudin (1976), which is theoretically strong but not so in practice.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Karmarkar (1984): An interior-point polynomial-time LP method that is quite effective and became a breakthrough research. (US Patent 4,744,026, expired in 2006).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Renegar (1988): Newton-based interior-point algorithm for LP. It had the theoretically best computational complexity until the latest research by Lee-Sidford emerged.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>17-02 Primal-dual interior-point method</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_02_primal_dual_interior_point_method/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter17/17_02_primal_dual_interior_point_method</id>
   <content type="html">&lt;p&gt;Like the barrier method, the &lt;strong&gt;primal-dual interior-point method&lt;/strong&gt; also aims to (approximately) compute points on the central path. However, the two methods have several differences.&lt;/p&gt;

&lt;h2 id=&quot;differences-between-primal-dual-interior-point-method-and-barrier-method&quot;&gt;Differences between Primal-dual interior-point method and barrier method&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Generally performs &lt;strong&gt;one Newton step&lt;/strong&gt; per iteration. (That is, there is no additional loop for the centering step.)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Does not necessarily need to be feasible&lt;/strong&gt;. (Pushes toward feasible regions through backtracking line search.)&lt;/li&gt;
  &lt;li&gt;Generally &lt;strong&gt;more effective&lt;/strong&gt;. Particularly shows superior performance compared to linear convergence under appropriate conditions.&lt;/li&gt;
  &lt;li&gt;Somewhat less intuitive compared to the barrier method.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>17-02-03 Primal-Dual Algorithm</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_02_03_primal_dual_algorithm/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter17/17_02_03_primal_dual_algorithm</id>
   <content type="html">&lt;p&gt;To define the Primal-Dual algorithm, let’s first define \(\tau(x,u)\) as follows&lt;/p&gt;
&lt;blockquote&gt;
\[\tau(x,u) := -\frac{h(x)^Tu}{m} \quad \text{with} \quad h (x) \le 0, u \ge 0\]
&lt;/blockquote&gt;

&lt;p&gt;For reference, \(t\) and \(\mu\) in the Barrier method are redefined and denoted as \(\tau\) and \(\sigma\) in the Primal-Dual algorithm.&lt;/p&gt;
&lt;blockquote&gt;
\[\tau = \frac{1}{t}, \quad \sigma = \frac{1}{\mu}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;primal-dual-algorithm&quot;&gt;Primal-Dual Algorithm&lt;/h2&gt;
&lt;p&gt;The Primal-Dual algorithm is as follows.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Choose \(\sigma\) (\(\sigma ∈ (0,1)\))&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;Choose \((x^0,u^0,v^0)\) \((h(x^0) &amp;lt; 0\). \(u^0 &amp;gt; 0\))&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;Repeat the following steps (\(k = 0,1,...\))&lt;br /&gt;
\(\quad\) * Calculate Newton step :&lt;br /&gt;
\(\qquad \quad (x,u,v) = (x^k,u^k,v^k)\) &lt;br /&gt;
\(\qquad \quad \tau := \sigma \tau(x^k,u^k)\) 계산&lt;br /&gt;
\(\qquad \quad \tau\)에 대해 \((\Delta x,\Delta u,\Delta v)\) 계산&lt;br /&gt;
\(\quad\) * Select step length \(θ_k\) with Backtracking&lt;br /&gt;
\(\quad\) * Primal-Dual update :&lt;br /&gt;
\(\qquad \quad (x^{k+1},u^{k+1},v^{k+1}) := (x^k,u^k,v^k) + \theta_k(\Delta x,\Delta u,\Delta v)\)&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;Termination condition : Stop if the conditions \(-h(x^{k+1})^Tu \le \epsilon\) and \((\parallel r_{prim} \parallel^2_2 + \parallel r_{dual} \parallel^2_2)^{1/2} \le \epsilon\) are satisfied &lt;br /&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;The algorithm calculates \((\Delta x,\Delta u,\Delta v)\) by executing Newton step at each stage and obtains \((x^{k+1},u^{k+1},v^{k+1})\) by performing Primal-Dual updates. However, \(\theta_k\) is selected through Backtracking line search so that the Primal-Dual variables become feasible. The algorithm terminates when the surrogate duality gap and primal and dual residuals become smaller than \(\epsilon\).&lt;/p&gt;

&lt;h2 id=&quot;backtracking-line-search&quot;&gt;Backtracking line search&lt;/h2&gt;
&lt;p&gt;Since the Primal-Dual algorithm executes Newton step only once, it can be viewed as finding the direction of the solution rather than finding the exact solution. Therefore, an appropriate step length must be found so that moving in that direction can enter the feasible set.&lt;/p&gt;

&lt;p&gt;That is, at each step of the algorithm, \(θ\) is obtained to update the primal-dual variables.&lt;/p&gt;

&lt;blockquote&gt;
\[x^+ = x + θ\Delta x, \quad  u^+ = u + θ\Delta u, \quad v^+ = v + θ\Delta v\]
&lt;/blockquote&gt;

&lt;p&gt;This process has two main objectives.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Maintaining the condition \(h(x) &amp;lt; 0, u &amp;gt; 0\)&lt;/li&gt;
  &lt;li&gt;Decreasing \(\parallel r(x,u,v) \parallel\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this purpose, &lt;strong&gt;multi-stage backtracking line search&lt;/strong&gt; is used.&lt;/p&gt;

&lt;h3 id=&quot;stage-1-dual-feasibility-u-gt-0&quot;&gt;Stage 1: dual feasibility \(u \gt 0\)&lt;/h3&gt;
&lt;p&gt;Initially, we start with the largest step \(\theta_{max} \leq 1\) that satisfies \(u + \theta \Delta u \geq 0\).&lt;/p&gt;

&lt;blockquote&gt;
\[\theta_{\max} = \min \Biggl\{1,\  \min \Bigl\{ −\frac{u_i}{\Delta u_i} : ∆u_i &amp;lt; 0 \Bigr\} \Biggr\}\]
&lt;/blockquote&gt;

&lt;p&gt;The above equation is derived as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;u + \theta \Delta u &amp;amp;&amp;amp; \ge 0  \\\\
\Leftrightarrow \quad &amp;amp;u &amp;amp;&amp;amp; \ge -\theta \Delta u \\\\
\Leftrightarrow \quad &amp;amp;- u/\Delta u &amp;amp;&amp;amp; \ge \theta \quad  \text{ such that }-\Delta u \gt 0  \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This is the process of making \(u\) feasible.&lt;/p&gt;

&lt;h3 id=&quot;stage-2-primal-feasibility-hx-lt-0&quot;&gt;Stage 2: primal feasibility \(h(x) \lt 0\)&lt;/h3&gt;
&lt;p&gt;Next, with parameters \(\alpha, \beta \in (0,1)\) and \(\theta\) set to \(0.99\theta_{max}\), the following update is performed.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Update \(\theta = \beta\theta\) until \(h_i(x^+) &amp;lt; 0, i = 1,...m\) is satisfied &lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is the process of making \(x\) feasible.&lt;/p&gt;

&lt;h3 id=&quot;stage-3--reduce-parallel-rxuv-parallel&quot;&gt;Stage 3 : reduce \(\parallel r(x,u,v) \parallel\)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Update \(\theta = \beta \theta\) until \(\| r(x^+,u^+,v^+) \| \leq (1−\alpha \theta) \| r(x,u,v) \|\) is satisfied&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The update equation in Stage 3 is the same as the existing backtracking line search algorithm.&lt;/p&gt;

&lt;p&gt;The right-hand side of the above equation can be derived as follows. First, we obtain the following result from Newton’s method.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\Delta w = (\Delta x, \Delta u, \Delta v) &amp;amp;\approx -r^{&apos;}(w)^{-1} r(w) \\\\
\Leftrightarrow r(w)  &amp;amp;\approx  -r^{&apos;}(w) \Delta w \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Since \(r^{&apos;}(w) \Delta w \approx -r(w)\) in the above equation, we substitute this into the first-order Taylor approximation below.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
r(w + \theta \Delta w) &amp;amp; \approx r(w) +  r^{&apos;}(w) (\theta \Delta w) \\\\
&amp;amp;\approx (1-\theta) r(w) \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;As a result, we get \(r(w + \alpha \theta \Delta w) \approx (1-\alpha  \theta) r(w)\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>17-02-02 Surrogate duality gap, residuals</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_02_02_surrogate_duality_gap_residuals/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter17/17_02_02_surrogate_duality_gap_residuals</id>
   <content type="html">&lt;p&gt;To define the Primal-Dual algorithm, let’s first define three types of residuals and the surrogate duality gap. Residuals and surrogate duality gap are the objectives to be minimized in the Primal-Dual algorithm.&lt;/p&gt;

&lt;h2 id=&quot;residuals&quot;&gt;Residuals&lt;/h2&gt;
&lt;p&gt;The dual, central, and primal residuals at \((x,u,v)\) are defined as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(r_{dual} = \nabla f(x) +\nabla h(x)u + A^Tv\\\)
\(r_{cent} =  Uh(x) + τ\mathbb{1} \\\) 
\(r_{prim} = Ax−b\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;These correspond to each row of the function \(r(x,u,v)\). The &lt;strong&gt;Primal-dual interior point method&lt;/strong&gt; executes in the direction of satisfying 0 rather than continuously making these three residuals equal to 0. This means that it is not necessary to be feasible during the execution process.&lt;/p&gt;

&lt;p&gt;The reason \(r_{dual}\) is called the dual residual is that, as shown in the equation below, if \(r_{dual} = 0\), it guarantees that \(u, v\) are in the domain of \(g\), which means dual feasible.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; r_{dual} = \nabla f(x) +\nabla h(x)u + A^Tv = 0 \\\\
&amp;amp; \iff \min_{x} L(x,u.v) = g(u,v) \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Similarly, satisfying \(r_{prim}=0\) means primal feasible, so \(r_{prim}\) is called the primal residual.&lt;/p&gt;

&lt;h2 id=&quot;surrogate-duality-gap&quot;&gt;Surrogate duality gap&lt;/h2&gt;
&lt;p&gt;While the barrier method has a duality gap because it is feasible, the primal-dual interior-point method uses &lt;strong&gt;surrogate duality gap&lt;/strong&gt; because it doesn’t necessarily need to be feasible. &lt;strong&gt;Surrogate duality gap&lt;/strong&gt; is defined by the following equation.&lt;/p&gt;

&lt;blockquote&gt;
\[−h(x)^Tu  \quad \text{for} \quad h(x) \le 0, u \ge 0\]
&lt;/blockquote&gt;

&lt;p&gt;If \(r_{dual} = 0\) and \(r_{prim} = 0\), then the surrogate duality gap becomes the true duality gap. In other words, if primal and dual feasible, the surrogate duality gap becomes equal to the actual duality gap \(\frac{m}{t}\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Reference] Perturbed KKT conditions and parameter t&lt;/strong&gt; &lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In the perturbed KKT conditions, the parameter t is \(t = −\frac{m}{h(x)^Tu}\).&lt;/li&gt;
  &lt;li&gt;For detailed information, see &lt;a href=&quot;/contents/en/chapter15/chapter16/15_03_01_perturbed_kkt_conditions/&quot;&gt;15-03-01 Perturbed KKT conditions&lt;/a&gt; and &lt;a href=&quot;/contents/en/chapter15/15_03_02_suboptimality_gap/&quot;&gt;15-03-02 Suboptimality gap&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Furthermore, if \(u &amp;gt; 0,h(x) &amp;lt; 0\) and the following condition is satisfied, then \((x,u,v)\) exists on the central path.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(r(x,u,v) = 0\) for \(\tau = -\frac{h(x)^Tu}{m}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In other words, the residual is 0 at points existing on the central path.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>17-02-01 Central path equations and Newton step</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_02_01_central_path_equations_and_newton_step/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter17/17_02_01_central_path_equations_and_newton_step</id>
   <content type="html">&lt;p&gt;The &lt;strong&gt;Primal-dual interior-point method&lt;/strong&gt; is a method that finds solutions by finding the central path, similar to the barrier method. To do this, it defines perturbed KKT conditions as residual functions and finds solutions that make them zero. This section aims to explain this approach.&lt;/p&gt;

&lt;h2 id=&quot;central-path-equations&quot;&gt;Central path equations&lt;/h2&gt;
&lt;p&gt;By moving the right-hand side to the left-hand side in the central path equations explained in the previous &lt;a href=&quot;/contents/en/chapter17/17_01_barrier_method_duality_optimality_revisited/&quot;&gt;17-01 Optimality conditions&lt;/a&gt;, we can organize them as follows. (The optimality conditions of central path equations are also called perturbed KKT conditions.)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
∇f(x) +∇h(x)u + A^Tv &amp;amp; = &amp;amp; 0 \\\
 Uh(x) + \tau\mathbb{1}  &amp;amp; = &amp;amp; 0 \\\
Ax−b &amp;amp; = &amp;amp; 0 \\\
u,−h(x)  &amp;amp; &amp;gt; &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;Note that the complementary slackness and inequality constraints in the KKT conditions for the original problem differ from those in the perturbed KKT conditions. For the original problem, \(Uh(x) = 0\) and \(u,−h(x)  \ge 0\), but in the perturbed KKT conditions, \(Uh(x) = - \tau\mathbb{1}\) and \(u,−h(x)  \gt 0\).&lt;/p&gt;

&lt;p&gt;These organized nonlinear equations, the perturbed KKT conditions, can be solved by approximating them as linear equations using the root finding version of Newton’s method.&lt;/p&gt;

&lt;h2 id=&quot;newton-step&quot;&gt;Newton step&lt;/h2&gt;
&lt;p&gt;Now let’s learn about the method of finding solutions by linearly approximating the perturbed KKT conditions. The perturbed KKT conditions equation can be defined as the following residual function \(r(x, u, v) = 0\). (The reason for naming it residual is that these values must be 0 to be optimal.)&lt;/p&gt;

&lt;blockquote&gt;
\[r(x,u,v) :=
\begin{bmatrix}
∇f(x) +∇h(x)u + A^Tv \\\
Uh(x) + τ\mathbb{1} \\\
Ax−b
\end{bmatrix}, H(x) = \text{Diag}(h(x))\]
&lt;/blockquote&gt;

&lt;p&gt;To find the roots of the function, approximating \(r(x, u, v)\) with a first-order Taylor expansion gives us the following. (This process approximates non-linear equations to linear equations. For detailed information, see &lt;a href=&quot;/contents/en/chapter14/14_01_newton_method/&quot;&gt;14-02-01 Root finding&lt;/a&gt;)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
0 &amp;amp; = r(x + \Delta x, u + \Delta u, r + \Delta v)  \\\\
  &amp;amp; \approx r(x, u, v) + \nabla r(x, u, v) 
\begin{pmatrix}
\Delta x \\\\
\Delta u \\\\
\Delta v \\\\
\end{pmatrix} \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Accordingly, the function \(r(x, u, v)\) can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\nabla r(x, u, v) 
\begin{pmatrix}
\Delta x \\\\
\Delta u \\\\
\Delta v \\\\
\end{pmatrix} = -r(x, u, v) \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;By differentiating \(r(x, u, v)\) with respect to \(x, u, v\) to obtain the Jacobian matrix \(\nabla r(x, u, v)\) and substituting the above equation, we get the following.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{bmatrix}
\nabla^2f(x) + \sum_i u_i \nabla^2h_i(x) &amp;amp; \nabla h(x) &amp;amp; A^T \\\
 U \nabla  h(x)^T &amp;amp; H(x) &amp;amp; 0 \\\
A &amp;amp; 0 &amp;amp; 0
\end{bmatrix}
\begin{bmatrix}
\Delta x \\\
\Delta u \\\
\Delta v
\end{bmatrix} = −r(x,u,v)\)
where
\(r(x,u,v) :=
\begin{bmatrix}
\nabla f(x) +\nabla h(x)u + A^Tv \\\
Uh(x) + τ\mathbb{1} \\\
Ax−b
\end{bmatrix}, H(x) = \text{Diag}(h(x))\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The solution \((\Delta x, \Delta u, \Delta v)\) to this equation is the update direction for the primal and dual variables. The reason why the method introduced in this chapter is called the &lt;strong&gt;Primal-Dual&lt;/strong&gt; interior point method is that it simultaneously updates primal and dual variables using residual functions.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>17-01 Barrier method & duality & optimality revisited</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_01_barrier_method_duality_optimality_revisited/"/>
   <updated>2021-05-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter17/17_01_barrier_method_duality_optimality_revisited</id>
   <content type="html">&lt;p&gt;In Chapter 15, we examined the barrier method, and in Chapters 13 and 16, we looked at duality.
Before covering the content of this chapter, we want to briefly review the barrier method and duality.&lt;/p&gt;

&lt;h2 id=&quot;barrier-method&quot;&gt;Barrier method&lt;/h2&gt;
&lt;p&gt;When the following primal problem is convex and \(f, h_i , i = 1, . . . m\) are differentiable,&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp; f(x) \\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;h_{i}(x) \leq 0, i = 1, \dotsc, m \\
&amp;amp;&amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Using the log barrier function, the primal problem can be transformed into a barrier problem as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \min_{x} &amp;amp;&amp;amp; f(x) + \frac{1}{t} \phi(x) &amp;amp; \qquad &amp;amp; \min_{x} &amp;amp;&amp;amp; tf(x) + \phi(x) \\
&amp;amp; \text{subject to } &amp;amp;&amp;amp; Ax = b &amp;amp; \iff \qquad &amp;amp; \text{subject to } &amp;amp;&amp;amp; Ax = b \\
&amp;amp; \text{where } &amp;amp;&amp;amp; \phi(x) = - \sum_{i=1}^{m} \log(-h_i(x))
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The algorithm starts with \(t = t^{(0)}\) satisfying \(t &amp;gt; 0\) and increases until \(\frac{m}{t}\) becomes less than or equal to \(\epsilon\). At this time, Newton’s method is used to find \(x^{\star}(t)\) for the initial value \(x^{(0)}\), and the process of finding \(x^{(k+1)} = x^{\star}(t)\) at each step for \(k = 1, 2, 3, . . .\) is repeated.&lt;/p&gt;

&lt;p&gt;The algorithm can be briefly summarized as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Choose \(t^{(0)} \gt 0\) and \(k := 0\).&lt;/li&gt;
  &lt;li&gt;Solve the barrier problem at \(t = t^{(0)}\) to find \(x^{(0)} = x^{\star}(t)\).&lt;/li&gt;
  &lt;li&gt;While \(m/t \gt \epsilon\) &lt;br /&gt;
  3-1. Update \(t^{(k+1)} = µt\) where \((µ &amp;gt; 1)\) &lt;br /&gt;
  3-2. Initialize Newton’s method with \(x^{(k)}\) (warm start)&lt;br /&gt;
     Solve the barrier problem at \(t = t^{(k+1)}\) to find \(x^{(k+1)} = x^{\star}(t)\).&lt;br /&gt;
  end while&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, see &lt;a href=&quot;/contents/en/chapter15/15_01_02_log_barrier_function_and_barrier_method/&quot;&gt;15-01-02 Log barrier function &amp;amp; barrier method&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;duality&quot;&gt;Duality&lt;/h2&gt;
&lt;p&gt;When the following primal problem is given:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad f(x) \\\\
   \text{subject to} &amp;amp;\quad f Ax = b \\\\
   &amp;amp;\quad h(x) \le 0
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This can be transformed into Lagrangian form as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[L(x,u,v) = f(x) + u^Th(x) + v^T(Ax - b)\]
&lt;/blockquote&gt;

&lt;p&gt;Using the Lagrangian defined in this way, primal and dual problems can be redefined in the following form. Please refer to Chapter 16 for detailed information.&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;primal-problem&quot;&gt;Primal Problem&lt;/h3&gt;
&lt;blockquote&gt;
\[\min_x \mathop{\max_{u,v}}_{u \geq 0} L(x,u,v)\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;dual-problem&quot;&gt;Dual problem&lt;/h3&gt;
&lt;blockquote&gt;
\[\mathop{\max_{u,v}}_{u \geq 0} \min_x L(x,u,v)\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;optimality-conditions&quot;&gt;Optimality conditions&lt;/h2&gt;

&lt;p&gt;When \(f,h_1,...h_m\) are convex and differentiable, and the given problem satisfies strong duality, the KKT optimality conditions for this problem are as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{array}{rcl}
∇f(x) +∇h(x)u + A^Tv &amp;amp; = &amp;amp; 0 &amp;amp; \text{(Stationarity)}\\\
 Uh(x) &amp;amp; = &amp;amp; 0 &amp;amp; \text{(Complementary Slackness)} \\\
Ax &amp;amp; = &amp;amp; b &amp;amp; \text{(Primal Feasibility)}\\\
u,−h(x)  &amp;amp; ≥ &amp;amp; 0 &amp;amp; \text{(Dual Feasibility)}
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(U\) means \(\text{diag}(u)\), and \(∇h(x)\) means \([ ∇h_1(x) ··· ∇h_m(x) ]\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, see &lt;a href=&quot;/contents/en/chapter12/12_00_KKT_conditions/&quot;&gt;Chapter 12 KKT conditions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;central-path-equations&quot;&gt;Central path equations&lt;/h2&gt;
&lt;p&gt;The function \(f(x)\) can be redefined as a barrier problem as follows.&lt;br /&gt;
In the equation below, \(τ\) is \(\frac{1}{t}\), and by making \(τ\) gradually approach 0 and iteratively finding solutions, we ultimately obtain the solution to the original problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp; {f(x) + τ\phi(x)} \\\\
&amp;amp; &amp;amp;&amp;amp;{Ax = b} \\\
&amp;amp; \text{where } &amp;amp;&amp;amp; \phi(x) = −\sum_{i=1}^m \log(−h_i(x)).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;That is, in the above equation, differences from the primal problem occur depending on \(τ\), and the trajectory generated according to \(τ\), i.e., the set of solutions to the barrier problem, is called the central path.&lt;/p&gt;

&lt;p&gt;And the optimality conditions for this barrier problem are as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
∇f(x) +∇h(x)u + A^Tv  &amp;amp; = &amp;amp; 0 \\\
Uh(x) &amp;amp; = &amp;amp; −τ\mathbb{1} \\\
Ax &amp;amp; = &amp;amp; b \\\
u,−h(x)  &amp;amp; &amp;gt; &amp;amp; 0
\end{array}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, see &lt;a href=&quot;/contents/en/chapter16/16_02_optimality_conditions/&quot;&gt;16-02 Optimality conditions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;strong&gt;Primal-Dual interior point method&lt;/strong&gt; introduced in this chapter is a method that defines the first three equations above as residuals and finds solutions by reducing them to \(0\).&lt;/p&gt;

&lt;h4 id=&quot;useful-fact&quot;&gt;Useful fact&lt;/h4&gt;
&lt;p&gt;The solution \((x(τ),u(τ),v(τ))\) has a duality gap of size \(mτ\), i.e., \(\frac{m}{t}\), as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[f(x(τ))−\min_x L(x,u(τ),v(τ)) = mτ= \frac{m}{t}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>13 Ứng dụng của đối ngẫu và các tương ứng</title>
   <link href="http://localhost:4000/contents/vi/chapter13/13_Duality_uses_and_correspondences/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/13_Duality_uses_and_correspondences</id>
   <content type="html">&lt;p&gt;Trong chương này, chúng ta sẽ học về các ứng dụng của Đối ngẫu (Duality) và các tương ứng liên quan thông qua các ví dụ.&lt;/p&gt;

&lt;h3 id=&quot;lưu-ý&quot;&gt;[Lưu ý]&lt;/h3&gt;

&lt;p&gt;Trong chương này, nghiệm tối ưu \(x^{\star}\) và hàm liên hợp \(x^{*}\) của \(x\) được phân biệt và ký hiệu như vậy.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13-06 Tinh tế đối ngẫu & Đối ngẫu kép</title>
   <link href="http://localhost:4000/contents/vi/chapter13/13_06_Dual_subtleties_Double_dual/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/13_06_Dual_subtleties_Double_dual</id>
   <content type="html">&lt;h2 id=&quot;tinh-tế-đối-ngẫu&quot;&gt;Tinh tế đối ngẫu&lt;/h2&gt;
&lt;p&gt;• Đôi khi chúng ta có thể biến đổi các bài toán đối ngẫu thành các bài toán tương đương và vẫn gọi chúng là bài toán đối ngẫu. Ngoài ra, trong đối ngẫu mạnh, chúng ta có thể sử dụng nghiệm của các bài toán đối ngẫu đã biến đổi để phân tích hoặc tính toán các đặc trưng của nghiệm nguyên thủy.&lt;/p&gt;

&lt;h4 id=&quot;lưu-ý&quot;&gt;[Lưu ý]&lt;/h4&gt;
&lt;p&gt;Giá trị tối ưu của một bài toán đối ngẫu đã biến đổi không nhất thiết là giá trị tối ưu của nguyên thủy.&lt;/p&gt;

&lt;p&gt;• Một cách phổ biến để suy dẫn các bài toán đối ngẫu cho các bài toán không ràng buộc là đầu tiên biến đổi nguyên thủy bằng cách thêm các biến giả và ràng buộc đẳng thức.&lt;/p&gt;

&lt;p&gt;Nói chung, cách thực hiện điều này là mơ hồ. Các lựa chọn khác nhau có thể dẫn đến các bài toán đối ngẫu khác nhau.&lt;/p&gt;

&lt;h2 id=&quot;đối-ngẫu-kép&quot;&gt;Đối ngẫu kép&lt;/h2&gt;
&lt;p&gt;Hãy xem xét một bài toán tối thiểu hóa tổng quát với ràng buộc tuyến tính:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_x f(x) \text{ với điều kiện } Ax ≤ b, Cx = d\]
&lt;/blockquote&gt;

&lt;p&gt;Lagrangian như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[L(x,u,v) = f(x) + (A^Tu + C^Tv)^Tx−b^Tu−d^Tv\]
&lt;/blockquote&gt;

&lt;p&gt;Do đó, bài toán đối ngẫu như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\max_{u,v} −f^∗(−A^Tu−C^Tv)−b^Tu−d^Tv \text{ với điều kiện } u ≥ 0\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;nhắc-lại-tính-chất&quot;&gt;Nhắc lại tính chất&lt;/h4&gt;
&lt;p&gt;Nếu \(f\) đóng và lồi, chúng ta đã giải thích trước đó rằng đối ngẫu của đối ngẫu là nguyên thủy trong trường hợp này (\(f^{∗∗} = f\)).&lt;/p&gt;

&lt;p&gt;Trên thực tế, mối liên hệ (giữa đối ngẫu và liên hợp đối ngẫu) đi sâu hơn nhiều ngoài các ràng buộc tuyến tính.
Xem xét điều sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \min_x &amp;amp;&amp;amp; f(x) \\
&amp;amp;\text{ với điều kiện } &amp;amp;&amp;amp; h_i(x) ≤ 0, i = 1,...m \\
&amp;amp;&amp;amp;&amp;amp;l_j(x) = 0, j = 1,...r
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Nếu \(f\) và \(h_1,...h_m\) đóng và lồi, và \(l_1,...l_r\) là affine, thì đối ngẫu của đối ngẫu là nguyên thủy.&lt;/p&gt;

&lt;p&gt;Điều này được cung cấp như một bài toán tối thiểu hóa từ góc độ của các hàm hai biến.&lt;/p&gt;

&lt;p&gt;(để biết thêm, đọc Chương 29 và 30 của Rockafellar)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13-05 Nón đối ngẫu</title>
   <link href="http://localhost:4000/contents/vi/chapter13/13_05_Dual_cones/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/13_05_Dual_cones</id>
   <content type="html">&lt;h2 id=&quot;nón-đối-ngẫu&quot;&gt;Nón đối ngẫu&lt;/h2&gt;
&lt;p&gt;Tồn tại một nón \(K ⊆ \mathbb{R}^n\).
(Nhắc lại nội dung đã đề cập trước đó trong &lt;a href=&quot;/contents/vi/chapter02/02_06_01_Dual_cones/&quot;&gt;02-06-01&lt;/a&gt;, điều này có nghĩa là \(x \in K, t ≥ 0 \to tx \in K\).)&lt;/p&gt;
&lt;blockquote&gt;
\[K∗ = \{ y : y^Tx ≥ 0 \text{ với mọi } x \in K \}\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này được gọi là &lt;strong&gt;nón đối ngẫu&lt;/strong&gt;, và nó luôn là một nón lồi (ngay cả khi \(K\) không lồi).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter13/dual_cone.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig3] Dual Cones [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h5 id=&quot;lưu-ý&quot;&gt;[Lưu ý]&lt;/h5&gt;
&lt;p&gt;\(y \in K∗ \iff \text{ nửa không gian } \{ x : y^Tx ≥ 0 \} \text { chứa } K\)
(Từ B &amp;amp; V trang 52)&lt;/p&gt;

&lt;p&gt;Một tính chất quan trọng ở đây là nếu \(K\) đóng và là nón lồi, thì \(K^{∗∗} = K\).&lt;/p&gt;

&lt;h4 id=&quot;ví-dụ&quot;&gt;Ví dụ:&lt;/h4&gt;
&lt;p&gt;• Nón đối ngẫu của không gian con tuyến tính \(V\) là \(V^{⊥}\), tức là phần bù trực giao.
Ví dụ, \((row(A))^{∗} = null(A)\)&lt;/p&gt;

&lt;p&gt;• Nón đối ngẫu của nón chuẩn \(K = \{ (x,t) \in \mathbb{R}^n+1 : \| x \|≤ t \}\) là nón chuẩn của chuẩn đối ngẫu của nó \(K^{∗} = \{ (y,s) \in \mathbb{R}^{n+1} : \| y \|_{∗} ≤ s \}\).&lt;/p&gt;

&lt;p&gt;• Nón nửa xác định dương \(\mathbb{S}^n_+\) là một nón lồi tự đối ngẫu, có nghĩa là \((\mathbb{S}^n_+)^{∗} = \mathbb{S}^n_+\).&lt;/p&gt;

&lt;p&gt;Tại sao lại như vậy? Hãy xác minh:&lt;/p&gt;
&lt;blockquote&gt;
\[Y \succeq 0 \iff tr(Y X) ≥ 0 \text{ với mọi } X \succeq 0\]
&lt;/blockquote&gt;

&lt;p&gt;Phân tích trị riêng của \(X\)&lt;/p&gt;

&lt;h2 id=&quot;nón-đối-ngẫu-và-bài-toán-đối-ngẫu&quot;&gt;Nón đối ngẫu và bài toán đối ngẫu&lt;/h2&gt;
&lt;p&gt;Xem xét bài toán có ràng buộc nón:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_x f(x) \text{ với điều kiện } Ax \in K\]
&lt;/blockquote&gt;

&lt;p&gt;Khi \(I^{∗}_K(y) = \max_{z\in K} z^Ty\) là hàm hỗ trợ của \(K\),
bài toán đối ngẫu của biểu thức trên như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u −f^∗(A^Tu)−I^∗_K(−u)\]
&lt;/blockquote&gt;

&lt;p&gt;Khi \(K\) là một nón, điều này có thể được định nghĩa dễ dàng như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u −f^∗(A^Tu) \text{ với điều kiện } u \in K^{∗}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây \(K^{∗}\) là nón đối ngẫu của \(K\). vì \(= I_K^{*}(-u) \ I_{K^{*}}(−u)\)&lt;/p&gt;

&lt;p&gt;Điều này khá hữu ích vì nhiều loại ràng buộc khác nhau có thể xuất hiện dưới dạng ràng buộc nón.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>13-04 Hàm liên hợp</title>
   <link href="http://localhost:4000/contents/vi/chapter13/13_04_Conjugate_function/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/13_04_Conjugate_function</id>
   <content type="html">&lt;p&gt;Với một hàm cho trước \(f : \mathbb{R}^n → \mathbb{R}\), hàm liên hợp \(f^{∗} : \mathbb{R}^n → \mathbb{R}\) được định nghĩa như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[f^{∗}(y) = \max_x y^Tx−f(x)\]
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter13/conjugate_function.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Illustration of conjugate function [1]&lt;/figcaption&gt;
&lt;/p&gt;


### [Lưu ý] 
$$f^{∗}$$ luôn là hàm lồi vì nó là cực đại điểm của các hàm lồi (affine) $$y^Tx - f(x)$$.
(Ở đây, $$f$$ không nhất thiết phải là hàm lồi.)
$$f^{∗}(y)$$ là khoảng cách cực đại giữa hàm tuyến tính $$y^Tx$$ và $$f(x)$$.
(Từ B &amp;amp; V trang 91)

Phép liên hợp cho $$f$$ khả vi được gọi là biến đổi Legendre.

#### Tính chất: 
• Bất đẳng thức Fenchel: với mọi $$x,y, f(x) + f^{∗}(y) ≥ x^Ty$$
&amp;gt; $$f(x) + f^{∗}(y) ≥ x^Ty \iff f^{*}(y) \ge x^Ty - f(x)$$
&amp;gt; $$ f^{*}(y) = \max_z z^Ty - f(x)$$

• Hàm liên hợp của hàm liên hợp là $$f^{∗∗}$$, do đó $$f^{∗∗} ≤ f$$ luôn đúng.&lt;br /&gt;
• Nếu $$f$$ đóng và lồi, thì $$f^{∗∗} = f$$. &lt;br /&gt;
• Nếu $$f$$ đóng và lồi, thì với mọi $$x,y$$, điều sau đây đúng:&lt;br /&gt;
&amp;gt; $$\begin{align}
&amp;gt; x ∈ ∂f^{∗}(y) &amp;amp;\iff y ∈ ∂f(x) \\\
&amp;gt; &amp;amp;\iff f(x) + f^{∗}(y) = x^Ty \\\
&amp;gt; \end{align}$$

• Nếu $$f(u,v) = f_1(u) + f_2(v)$$, thì $$f^{∗}(w,z) = f_1^{∗}(w) + f_2^{∗}(z)$$ đúng. 



#### Ví dụ: 
• Hãy xem xét trường hợp $$f(x)$$ là một hàm bậc hai đơn giản như sau:
&amp;gt; $$f(x) = \frac{1}{2}x^TQx$$, trong đó $$Q \succ 0$$

Khi đó $$y^Tx− \frac{1}{2}x^TQx$$ là hàm lõm chặt theo $$y$$ và đạt cực đại tại $$x = Q^{−1}y$$. Tức là, $$f^{∗}(y) = \frac{1}{2}y^TQ^{−1}y$$. 



### [Chứng minh]
&amp;gt; $$\begin{align}
&amp;gt; f^{*}(y) &amp;amp; =  \max_x \left( y^Tx -\frac{1}{2}x^TQx \right) \\\
&amp;gt; &amp;amp; = -\min_x \left(\frac{1}{2}x^TQx- y^Tx \right), x^{\star} = Q^{-1}y  \\\
&amp;gt; &amp;amp; = -\frac{1}{2}y^TQ^{-1}QQ^{-1}y + y^TQ^{-1}y \\\
&amp;gt; &amp;amp; = \frac{1}{2}y^TQ^{-1}y  \\\
&amp;gt; \end{align}$$

&amp;gt; Bất đẳng thức Fenchel: với mọi $$x, y$$
&amp;gt; $$\frac{1}{2} x^TQx + \frac{1}{2} y^TQ^{-1}y \ge x^Ty$$

• Hàm chỉ thị: Nếu $$f(x) = I_C(x)$$, thì hàm liên hợp của nó như sau:

&amp;gt; $$f^{∗}(y) = I^{∗}_C(y) = \max_{x ∈ C} y^Tx$$ được gọi là **hàm hỗ trợ** của $$C$$

• Chuẩn: Nếu $$f(x) = \|x\|$$, thì hàm liên hợp của nó như sau:
&amp;gt; $$f^{∗}(y) = I_{\\{ z : \rVert z \rVert_{∗} ≤ 1 \\}}(y)$$ trong đó $$\rVert · \rVert_{∗}$$ là chuẩn đối ngẫu của $$\rVert · \rVert$$ 

&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>13-04-03 Dịch chuyển biến đổi tuyến tính</title>
   <link href="http://localhost:4000/contents/vi/chapter13/13_04_03_Shifting_linear_transformations/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/13_04_03_Shifting_linear_transformations</id>
   <content type="html">&lt;p&gt;Công thức đối ngẫu giúp dịch chuyển các biến đổi tuyến tính giữa các phần của hàm mục tiêu và các miền khác.&lt;/p&gt;

&lt;p&gt;Hãy xem xét điều sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) + g(Ax)\]
&lt;/blockquote&gt;

&lt;p&gt;Biểu thức sau tương đương:&lt;/p&gt;
&lt;blockquote&gt;
\[min_{x,z} f(x) + g(z) \text { với điều kiện } Ax = z\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này dẫn đến quá trình đối ngẫu sau:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\text {g(u)} = \min_{x,z} f(x) + g(z) + u^T(z - Ax)\)
\(\qquad  = -\max_{x} (A^T u)^T x - f(x) - \max_{z} (-u)^T z - g(z)\)
\(\qquad = -\ f^* (A^T u) - g^* (-u)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Và đối ngẫu là:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u -f^*(A^Tu) - g^*(-u)\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;ví-dụ&quot;&gt;[Ví dụ]&lt;/h4&gt;
&lt;p&gt;Chuẩn và chuẩn đối ngẫu của chúng có mối quan hệ như sau: \(\| \cdot \|, \| \cdot \|^*\), các bài toán&lt;/p&gt;

&lt;blockquote&gt;
\[\min_x f(x) +\| Ax \|\]

\[\max_u -f^*(A^Tu) \text{ với điều kiện } \| u \|^* \leq 1\]
&lt;/blockquote&gt;

&lt;p&gt;Biểu thức đầu tiên là nguyên thủy, và biểu thức thứ hai là đối ngẫu, có thể được giải trực tiếp.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13-04-02 Hàm liên hợp và bài toán đối ngẫu</title>
   <link href="http://localhost:4000/contents/vi/chapter13/13_04_02_Conjugates_and_dual_problems/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/13_04_02_Conjugates_and_dual_problems</id>
   <content type="html">&lt;p&gt;Hàm liên hợp thường có thể được biểu diễn thông qua việc suy dẫn các bài toán đối ngẫu cho các bài toán tối thiểu hóa Lagrangian như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[−f^{∗}(u) = \min_x f(x)−u^Tx\]
&lt;/blockquote&gt;

&lt;p&gt;Ví dụ, hãy xem xét biểu thức sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_x  f(x) + g(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Biểu thức sau đây có thêm ràng buộc vào biểu thức trên và tương đương với nó:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x,z} f(x) + g(z) \text{ với điều kiện } x = z\]
&lt;/blockquote&gt;

&lt;p&gt;Chuyển đổi điều này thành hàm đối ngẫu Lagrange cho:&lt;/p&gt;

&lt;blockquote&gt;
\[g(u) = \min_{x,z} f(x) + g(z) + u^T(z−x) = −f^{∗}(u)−g^{∗}(−u)\]
&lt;/blockquote&gt;

&lt;p&gt;Do đó, bài toán đối ngẫu của biểu thức gốc có thể được định nghĩa như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u −f^{∗}(u)−g^{∗}(−u)\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;ví-dụ&quot;&gt;[Ví dụ]&lt;/h4&gt;
&lt;p&gt;• Hàm chỉ thị: Đối ngẫu của \(\min_x f(x) + I_C(x)\) như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u −f^{∗}(u)−I^{∗}_C(−u)\]

  &lt;p&gt;trong đó \(I^{∗}_C\) là hàm hỗ trợ của \(C\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;• Chuẩn:&lt;/p&gt;

&lt;p&gt;Đối ngẫu của \(\min_x f(x) + \rVert x \rVert\) như sau:
\(\max_u −f^{∗}(u) \text{ với điều kiện } \rVert u \rVert^{∗} ≤ 1 \text{ trong đó } \rVert · \rVert_{∗} \text{ là chuẩn đối ngẫu của } \rVert · \rVert\)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13-04-01 Ví dỡ đối ngẫu lasso</title>
   <link href="http://localhost:4000/contents/vi/chapter13/13_04_01_Example_lasso_dual/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/13_04_01_Example_lasso_dual</id>
   <content type="html">&lt;p&gt;Hãy xem xét bài toán lasso với \(y \in \mathbb{R}^n, X \in \mathbb{R}^{n\times p}\):&lt;/p&gt;

&lt;blockquote&gt;
\[\min_\beta \frac{1}{2} \| y-X\beta \|^2_2 + \lambda\| \beta \|_1\]

\[f(\beta) = \frac{1}{2} \| y - X\beta \|^2_2 +  \lambda\| \beta \|_1\]

\[L(\beta) = f(\beta)\]

\[\min_\beta L(\beta) = f^{\star}\]
&lt;/blockquote&gt;

&lt;p&gt;Hàm đối ngẫu của bài toán trên là hằng số (= \(f^*\)). Do đó, chúng ta có thể biến đổi bài toán nguyên thủy như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{\beta,z} \frac{1}{2} \| y-z \|^2_2 + \lambda \| \beta \|_1 \text{ với điều kiện } z = X\beta\]
&lt;/blockquote&gt;

&lt;p&gt;Hàm đối ngẫu của bài toán đã biến đổi là:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
g(u) &amp;amp;= \min_{\beta,z} \frac{1}{2} \| y-z \|^2_2 + \lambda \| \beta \|_1 + u^T(z-X\beta) \\
&amp;amp;= \frac{1}{2} \| y \|^2_2 - \frac{1}{2} \| y-u \|^2_2 - I_{\{ v : \| v \|_\infty \leq 1 \}}(X^Tu/\lambda) \\
\end{align}\]

&lt;/blockquote&gt;

&lt;h4 id=&quot;chứng-minh&quot;&gt;[Chứng minh]&lt;/h4&gt;
&lt;blockquote&gt;
\[\begin{align}
g(u) &amp;amp;= \min_{\beta,z} \frac{1}{2} \| y-z \|^2_2 + \lambda \| \beta \|_1 + u^T(z-X\beta) \\
&amp;amp;= \underbrace{ \left( \min_z \frac{1}{2} \| y - z \|^2_2 + u^Tz \right)}_{(1)} + \underbrace{\left( \min_\beta  \lambda \| \beta \|_1 + u^TX\beta \right)}_{(2)} \\
\end{align}\]

\[z^{\star} = y - u\]

  &lt;p&gt;\(\begin{align}
(1) \cdots \left( \min_z \frac{1}{2} \| y - z \|^2_2 + u^Tz \right)
&amp;amp;= \frac{1}{2} \| u \|^2_2 + u^T(y - u) \\
&amp;amp;= -\frac{1}{2} \| y - u \|^2_2 + \frac{1}{2} \| y \|^2_2 \\
\end{align}\)
\(\begin{align}
(2) \cdots \left( \min_\beta  \lambda \| \beta \|_1 + u^TX\beta \right) 
&amp;amp;= - \lambda \max_\beta \frac{u^Tx}{\lambda} \beta - \| \beta \|_2 \\
&amp;amp;= - \lambda \left( \| \frac{u^Tx}{\lambda} \|_\infty \leq 1 \right) \\
&amp;amp;= - \lambda \left( \| u^Tx \|_\infty \leq \lambda \right) \\
\end{align}\)
\therefore g(u) = -\frac{1}{2} | y - u |^2&lt;em&gt;2 + \frac{1}{2} | y |^2_2 + - \lambda \left( | u^Tx |&lt;/em&gt;\infty \leq \lambda \right)
= \frac{1}{2} | y |^2&lt;em&gt;2 - \frac{1}{2} | y-u |^2_2 - I&lt;/em&gt;{{ v : | v |_\infty \leq 1 }}(X^Tu/\lambda)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Do đó, bài toán đối ngẫu lasso là:&lt;/p&gt;

&lt;blockquote&gt;
\[\max_u \frac{1}{2} ( \| y \|^2_2 - \| y-u \|^2_2 ) \text{ với điều kiện } \| X^Tu \|_\infty \leq \lambda\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này tương đương với:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_u \| y-u \|^2_2 \text{ với điều kiện } \| X^Tu \|_\infty \leq \lambda\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;kiểm-tra&quot;&gt;[Kiểm tra]&lt;/h3&gt;
&lt;p&gt;Điều kiện Slater được thỏa mãn, do đó đối ngẫu mạnh đúng.&lt;/p&gt;
&lt;blockquote&gt;
\[\text{đối ngẫu mạnh } \implies (\beta^{\star}, z^{\star})\]

\[\text{ phải tối thiểu hóa  } L( \beta, z, u^{\star} ) \text{ trên } -u, \beta, z\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;lưu-ý&quot;&gt;[Lưu ý]&lt;/h3&gt;
&lt;p&gt;Giá trị tối ưu trong bài toán trước không phải là giá trị mục tiêu lasso tối ưu.
Tuy nhiên, nghiệm đối ngẫu \(u\) và nghiệm lasso \(\beta\) thỏa mãn \(X\beta = y-u\).&lt;/p&gt;

&lt;p&gt;Điều này được thỏa mãn bởi điều kiện dừng KKT \(z\) (tức là, \(z-y + \beta = 0\)).&lt;/p&gt;

&lt;p&gt;Do đó, lasso thỏa mãn phần dư đối ngẫu.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter13/Conjugate_LassoDual_Example.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Lasso Dual [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>13-03 Chuẩn đối ngẫu</title>
   <link href="http://localhost:4000/contents/vi/chapter13/13_03_Dual_norms/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/13_03_Dual_norms</id>
   <content type="html">&lt;p&gt;Hãy xem xét một &lt;strong&gt;chuẩn&lt;/strong&gt; tùy ý \(\| x \|\):&lt;/p&gt;

&lt;blockquote&gt;
\[\text{Chuẩn } l_p\text{: } \lVert x \rVert_p = (\sum^n_{i=1} \rVert x_i \rVert_p)^{1/p}, \text{ với } p ≥ 1\]

\[\text{Chuẩn vết: } \lVert X \rVert_{tr} = \sum^r_{i=1} σ_i(X)\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Chuẩn đối ngẫu&lt;/strong&gt; của chuẩn \(\lVert x \rVert\) được ký hiệu là \(\lVert x \rVert_{∗}\) và được định nghĩa như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\lVert x \rVert_{∗} = \max_{\lVert z \rVert ≤1} z^Tx\]
&lt;/blockquote&gt;

&lt;p&gt;Giả sử tồn tại một \(y\) tùy ý nào đó. Khi đó khi ta đặt \(z = \frac{y}{\rVert y \rVert}\), ta có \(\rVert z \rVert = 1\). Ngoài ra, \(\rVert z^Tx \rVert \le \rVert x \rVert_{*}\) đúng,
do đó một dạng tương tự như &lt;em&gt;bất đẳng thức Cauchy-Schwartz&lt;/em&gt; \(\rVert y^Tx \rVert \le \rVert y \rVert \rVert x \rVert_{*}\) được thiết lập.&lt;/p&gt;

&lt;p&gt;Hãy xem xét các ví dụ về chuẩn đối ngẫu trong các điều kiện cụ thể:&lt;/p&gt;
&lt;blockquote&gt;
\[\text{Đối ngẫu chuẩn } l_p\text{: } (\lVert x \rVert_p)_{*} = \lVert x \rVert_{q}, \text{ trong đó } 1/p + 1/q = 1\]

\[\text{Đối ngẫu chuẩn vết: } (\lVert X \rVert_{tr})_{*} = \lVert X \rVert_{op}) = σ_1(X)\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;chứng-minh&quot;&gt;[Chứng minh]&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;Hãy chứng minh rằng điều sau đây đúng cho đối ngẫu chuẩn \(l_p\):&lt;/p&gt;

\[(\lVert x \rVert_p)_{*} = \lVert x \rVert_{q}, \text{ trong đó } 1/p + 1/q = 1 \qquad \text{(1)}\]

  &lt;p&gt;&lt;em&gt;Chứng minh&lt;/em&gt;&lt;/p&gt;

\[(\lVert x \rVert_p)_{*} = \sup \{ z^Tx : x \in \mathbb{R}^n, \rVert x \rVert_q \le 1 \} \qquad  \text{(2)}\]

  &lt;p&gt;Trong khi đó, theo bất đẳng thức Holder, điều sau đây đúng:&lt;/p&gt;

\[z^T x ≤ \rVert z^tx \rVert 1 ≤ \rVert z \rVert_p \rVert x \rVert_q (\text{ trong đó }, 1/p + 1/q = 1)\qquad \text{(3)}\]

  &lt;p&gt;Từ (1) ở trên, mối quan hệ sau đây đúng:&lt;/p&gt;

\[(\rVert z \rVert_q)_∗ ≤ \rVert z \rVert_p\qquad \text{(4)}\]

  &lt;p&gt;Do đó, nếu ta tìm được \(x\) sao cho \(\rVert x \rVert_q ≤ 1\) và \(z^Tx\) thỏa mãn \(\rVert z \rVert_p\), ta có thể thấy rằng \((\rVert z \rVert_q)_∗ = \rVert z \rVert\rVert_p\) đúng.&lt;/p&gt;

  &lt;p&gt;Trong khi đó, nếu ta đặt \(y := sign(z) \rVert z\rVert^{p−1} \left( y_i = sign(z_i)\rVert z_i\rVert^{p−1} \right)\) và \(x = y\), thì \(\rVert y \rVert_q\)
thỏa mãn \(\rVert x \rVert_q =1\), và ta có thể xác nhận rằng \(z^Tx = \rVert z \rVert_p\).&lt;/p&gt;

  &lt;p&gt;Do đó, điều sau đây đúng:&lt;/p&gt;

\[( \rVert z \rVert_ q)_∗ = \rVert z \rVert_p, (1/p+1/q=1)\qquad \text{(5)}\]
&lt;/blockquote&gt;

&lt;p&gt;Chuẩn đối ngẫu của chuẩn đối ngẫu trở thành chuẩn gốc.&lt;/p&gt;
&lt;blockquote&gt;
\[\lVert x \rVert_{**} = \lVert x \rVert\]
&lt;/blockquote&gt;

&lt;p&gt;Hãy xem xét bài toán sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_y \lVert y \rVert \qquad \text{ với điều kiện } y = x\]
&lt;/blockquote&gt;

&lt;p&gt;Khi giá trị tối ưu là \(\rVert x \rVert\), Lagrangian được biểu diễn như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[L(y,u) = \rVert y \rVert+ u^T(x−y) = \rVert y \rVert − y^Tu + x^Tu\]
&lt;/blockquote&gt;

&lt;p&gt;Khi biểu diễn theo chuẩn đối ngẫu \((\lVert · \rVert_{∗})\), nó trở thành:&lt;/p&gt;
&lt;blockquote&gt;
\[\text{Nếu } \rVert u \rVert_{∗} ≤ 1,\text{ thì}  \qquad \min_y \{ \rVert y \rVert − y^Tu \} = 0\]

\[\text{Nếu } \rVert u \rVert_{∗} &amp;gt; 1, \text{ thì}  \qquad \min_y \{ \rVert y \rVert − y^Tu \} = −∞\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;note&quot;&gt;[Note]&lt;/h3&gt;
&lt;blockquote&gt;
\[\text{If } \rVert u \rVert_{∗} ≤ 1, \text{ then}  \qquad \min_y \{ \rVert y \rVert − y^Tu \} = 0\]

\[\max_y (y^Tu - \rVert y \rVert ) = 0\]

\[y^Tu \le \rVert y \rVert \rVert u \rVert_* \le \rVert y \rVert\]

\[\text{If } \rVert u \rVert_{∗} &amp;gt; 1, \text{ then}  \qquad \min_y \{ \rVert y \rVert − y^Tu \} = −∞\]

  &lt;p&gt;\(\text{Can always find} \qquad\) \(z\)  with \(\rVert z \rVert = 1 \qquad \text{ subject to }\qquad z^Tu = \rVert u \rVert_{*} \qquad ( argmax_{\rVert z \rVert \le 1}  z^Tu )\)&lt;/p&gt;

  &lt;p&gt;\(\text{take}\) \(y = t \cdot z, \qquad t &amp;gt; 0\)&lt;/p&gt;

\[y^Tu = t \cdot \rVert u \rVert_{*}\]

\[\text{ for this } y, \qquad y^Tu - \rVert y \rVert = t \cdot \rVert u \rVert_{*} - t \rightarrow ∞ \text{ as } t \rightarrow ∞\]

\[\text{ so therefore }  g(u) = \min_y L(y, u) = x^Tu - I(\rVert u \rVert_{*} \le 1)\]

  &lt;p&gt;dual problem&lt;/p&gt;

\[\max_u g(u) \iff \max_{\rVert u \rVert_{*} \le 1} x^Tu\]
&lt;/blockquote&gt;

&lt;p&gt;Do đó, bài toán đối ngẫu Lagrange như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\max_u u^Tx \qquad \text{ với điều kiện }\qquad \rVert u \rVert_{∗} ≤ 1\]
&lt;/blockquote&gt;

&lt;p&gt;Vì không có ràng buộc bất đẳng thức, điều kiện Slater được thỏa mãn, và theo đối ngẫu mạnh, \(f^{\star} = g^{\star}\).
Tức là, \(\rVert x \rVert = \rVert x \rVert_{∗∗}\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13-02 Giải bài toán nguyên thủy thông qua đối ngẫu</title>
   <link href="http://localhost:4000/contents/vi/chapter13/13_02_Solving_the_primal_via_the_dual/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/13_02_Solving_the_primal_via_the_dual</id>
   <content type="html">&lt;h3 id=&quot;một-hệ-quả-quan-trọng-của-điều-kiện-dừng&quot;&gt;Một hệ quả quan trọng của điều kiện dừng&lt;/h3&gt;
&lt;p&gt;Trong điều kiện đối ngẫu mạnh, khi nghiệm đối ngẫu \(u^{\star}, v^{\star}\) được cho, nghiệm nguyên thủy \(x^{\star}\) có thể được tìm bằng cách giải Lagrangian sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_x f(x) + \sum_{i=1}^m u_i^{\star} h_i(x) + \sum_{j=1}^r v^{\star}_i l_j(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Thông thường, nghiệm của các bài toán không ràng buộc như vậy có thể được biểu diễn bằng cách thể hiện rõ ràng các đặc điểm của nghiệm nguyên thủy thông qua nghiệm đối ngẫu.&lt;/p&gt;

&lt;p&gt;Hơn nữa, nếu nghiệm của bài toán này là duy nhất, nghiệm đối ngẫu trở thành nghiệm nguyên thủy \(x^{\star}\).
Điều này rất hữu ích khi việc giải bài toán đối ngẫu dễ dàng hơn việc giải trực tiếp bài toán nguyên thủy.&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-từ-b--v-trang-249&quot;&gt;Ví dụ từ B &amp;amp; V trang 249:&lt;/h3&gt;
&lt;blockquote&gt;
\[\min_x \sum_{i=1}^n f_i(x_i) \qquad \text{ với điều kiện }\qquad a^Tx = b\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[\begin{align}
g(v) &amp;amp;= \min_x \sum_{i=1}^n f_i(x_i) + v(b−a^Tx) \\\
&amp;amp;= bv + \min_x \sum_{i=1}^n f_i(x_i) −va^Tx \\\
&amp;amp;= bv + \min_x \sum_{i=1}^n f_i(x_i) −v \sum_{i=1}^n a_ix_i \\\
&amp;amp;= bv + \sum_{i=1}^n (\underbrace{\min_{x_i} \{ f_i(x_i) − a_ivx_i \}}_{-f^{*}_i(a_iv)}) \\\
&amp;amp;= bv − \sum_{i=1}^n f^{*}_i (a_iv)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây \(f^{*}\) biểu thị hàm liên hợp của \(f_i\).&lt;/p&gt;

&lt;p&gt;Do đó, bài toán đối ngẫu có thể được biểu diễn như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_v bv − \sum^n_{i=1} f^{*}_i (a_iv)\]
&lt;/blockquote&gt;

&lt;p&gt;Ngoài ra, bằng cách nhân với dấu âm (-), bài toán cực đại có thể được biểu diễn thành bài toán cực tiểu sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_v \sum^n_{i=1} f^{*}_i (a_iv) − bv\]
&lt;/blockquote&gt;

&lt;p&gt;Đây là một bài toán tối ưu hóa lồi với các biến vô hướng có thể được giải dễ dàng hơn nhiều so với bài toán nguyên thủy.&lt;/p&gt;

&lt;p&gt;Khi \(v^{\star}\) được cho, nghiệm nguyên thủy \(x^{\star}\) có thể được giải như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_{x} \sum^n_{i=1} (f_i(x_i) − a_iv^{\star}x_i)\]
&lt;/blockquote&gt;

&lt;p&gt;Tính lồi chặt của mỗi \(f_i\) có nghĩa là bài toán này có nghiệm duy nhất.
Tức là, \(x^{\star}\) được thu được thông qua tính toán \(∇f_i(x_i) = a_iv^{\star}\) cho mỗi \(i\).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>13-01 Ứng dụng của đối ngẫu</title>
   <link href="http://localhost:4000/contents/vi/chapter13/13_01_Uses_of_duality/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/13_01_Uses_of_duality</id>
   <content type="html">&lt;h3 id=&quot;hai-ứng-dụng-chính-của-đối-ngẫu&quot;&gt;Hai ứng dụng chính của đối ngẫu&lt;/h3&gt;
&lt;p&gt;Hãy cùng xem lại hai đặc điểm chính của đối ngẫu đã được đề cập trong Chương 11.&lt;/p&gt;

&lt;p&gt;• Khi \(x\) là khả thi nguyên thủy và \(u,v\) là khả thi đối ngẫu, hiệu số giữa bài toán nguyên thủy \(f(x)\) và bài toán đối ngẫu \(g(u,v)\) được gọi là &lt;strong&gt;khoảng cách đối ngẫu&lt;/strong&gt; (duality gap) giữa \(x\) và \(u,v\).&lt;/p&gt;
&lt;blockquote&gt;
\[f(x)-f^{\star}  \le f(x)-g(u, v)\]
&lt;/blockquote&gt;

&lt;p&gt;Khi khoảng cách đối ngẫu bằng 0, điều này được gọi là khoảng cách đối ngẫu bằng không, có nghĩa là nghiệm của bài toán đối ngẫu là tối ưu.
Ngoài ra, cận trên \(g(u, v)\) luôn nhỏ hơn hoặc bằng giá trị tối ưu \(f^{\star}\). Để biết lý do chi tiết, vui lòng tham khảo nội dung trong &lt;a href=&quot;/contents/vi/chapter11/11_00_Duality_in_General_Programs/&quot;&gt;[Chương 11]&lt;/a&gt;.
Do đó, có thể thực hiện suy luận sau đây.&lt;/p&gt;

&lt;h4 id=&quot;chứng-minh&quot;&gt;[Chứng minh]&lt;/h4&gt;
&lt;blockquote&gt;
\[\begin{align*}
f^{\star} &amp;amp;\ge g(u, v) \\
-f^{\star} &amp;amp;\le -g(u, v) \\
f(x)-f^{\star} &amp;amp;\le \underbrace{f(x)-g(u, v)}_{\text{khoảng cách đối ngẫu}}\\
g^{\star}-g(x) &amp;amp;\le \underbrace{f(x)-g(u, v)}_{\text{khoảng cách đối ngẫu}}\\
\end{align*}\]
&lt;/blockquote&gt;

&lt;p&gt;Hơn nữa, khoảng cách đối ngẫu có thể được sử dụng làm tiêu chí dừng cho các thuật toán.
• Khi nghiệm đối ngẫu tối ưu \(u^{\star}, v^{\star}\) được cho, trong điều kiện đối ngẫu mạnh, nghiệm nguyên thủy tối thiểu hóa Lagrangian \(L (x, u^{\star}, v^{\star})\) cho tất cả \(x\) (tức là thỏa mãn điều kiện dừng).&lt;/p&gt;

&lt;p&gt;Điều này có thể được sử dụng để tính toán nghiệm nguyên thủy.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13 Duality uses and correspondences</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_Duality_uses_and_correspondences/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter13/13_Duality_uses_and_correspondences</id>
   <content type="html">&lt;p&gt;In this chapter, we will learn about the uses of Duality and related correspondences through examples.&lt;/p&gt;

&lt;h3 id=&quot;notice&quot;&gt;[Notice]&lt;/h3&gt;

&lt;p&gt;In this chapter, the optimal solution \(x^{\star}\) and the conjugate \(x^{*}\) of \(x\) are distinguished and denoted as such.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13-06 Dual subtleties & Double dual</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_06_Dual_subtleties_Double_dual/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter13/13_06_Dual_subtleties_Double_dual</id>
   <content type="html">&lt;h2 id=&quot;dual-subtleties&quot;&gt;Dual subtleties&lt;/h2&gt;
&lt;p&gt;• Sometimes we can transform dual problems into equivalent problems and still call them dual problems. Also, in strong duality, we can use solutions of transformed dual problems for analyzing or computing characteristics of primal solutions.&lt;/p&gt;

&lt;h4 id=&quot;note&quot;&gt;[Note]&lt;/h4&gt;
&lt;p&gt;The optimal value of a transformed dual problem is not necessarily the optimal value of the primal.&lt;/p&gt;

&lt;p&gt;• A common way to derive dual problems for unconstrained problems is to first transform the primal by adding dummy variables and equality constraints.&lt;/p&gt;

&lt;p&gt;Generally, how to do this is ambiguous. Different choices can lead to different dual problems.&lt;/p&gt;

&lt;h2 id=&quot;double-dual&quot;&gt;Double dual&lt;/h2&gt;
&lt;p&gt;Let’s consider a general minimization problem with linear constraints:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_x f(x) \text{ subject to } Ax ≤ b, Cx = d\]
&lt;/blockquote&gt;

&lt;p&gt;The Lagrangian is as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[L(x,u,v) = f(x) + (A^Tu + C^Tv)^Tx−b^Tu−d^Tv\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, the dual problem is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\max_{u,v} −f^∗(−A^Tu−C^Tv)−b^Tu−d^Tv \text{ subject to } u ≥ 0\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;recall-property&quot;&gt;Recall property&lt;/h4&gt;
&lt;p&gt;If \(f\) is closed and convex, we explained earlier that the dual of the dual is the primal in this case (\(f^{∗∗} = f\)).&lt;/p&gt;

&lt;p&gt;In fact, the connection (between dual and dual conjugate) goes much deeper beyond linear constraints.
Consider the following:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \min_x &amp;amp;&amp;amp; f(x) \\
&amp;amp;\text{ subject to } &amp;amp;&amp;amp; h_i(x) ≤ 0, i = 1,...m \\
&amp;amp;&amp;amp;&amp;amp;l_j(x) = 0, j = 1,...r
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If \(f\) and \(h_1,...h_m\) are closed and convex, and \(l_1,...l_r\) are affine, then the dual of the dual is the primal.&lt;/p&gt;

&lt;p&gt;This is provided as a minimization problem from the perspective of bifunctions.&lt;/p&gt;

&lt;p&gt;(for more, read Chapters 29 and 30 of Rockafellar)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13-05 Dual cones</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_05_Dual_cones/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter13/13_05_Dual_cones</id>
   <content type="html">&lt;h2 id=&quot;dual-cones&quot;&gt;Dual cones&lt;/h2&gt;
&lt;p&gt;There exists a cone \(K ⊆ \mathbb{R}^n\).
(Recalling the content covered earlier in &lt;a href=&quot;/contents/en/chapter02/02_06_01_Dual_cones/&quot;&gt;02-06-01&lt;/a&gt;, this means \(x \in K, t ≥ 0 \to tx \in K\).)&lt;/p&gt;
&lt;blockquote&gt;
\[K∗ = \{ y : y^Tx ≥ 0 \text{ for all } x \in K \}\]
&lt;/blockquote&gt;

&lt;p&gt;This is called a &lt;strong&gt;dual cone&lt;/strong&gt;, and it is always a convex cone (even when \(K\) is not convex).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter13/dual_cone.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig3] Dual Cones [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h5 id=&quot;note&quot;&gt;[Note]&lt;/h5&gt;
&lt;p&gt;\(y \in K∗ \iff \text{ the halfspace } \{ x : y^Tx ≥ 0 \} \text { contains } K\)
(From B &amp;amp; V page 52)&lt;/p&gt;

&lt;p&gt;An important property here is that if \(K\) is closed and a convex cone, then \(K^{∗∗} = K\).&lt;/p&gt;

&lt;h4 id=&quot;examples&quot;&gt;Examples:&lt;/h4&gt;
&lt;p&gt;• The dual cone of a linear subspace \(V\) is \(V^{⊥}\), i.e., the orthogonal complement.
E.g., \((row(A))^{∗} = null(A)\)&lt;/p&gt;

&lt;p&gt;• The dual cone of the norm cone \(K = \{ (x,t) \in \mathbb{R}^n+1 : \| x \|≤ t \}\) is the norm cone of its dual norm \(K^{∗} = \{ (y,s) \in \mathbb{R}^{n+1} : \| y \|_{∗} ≤ s \}\).&lt;/p&gt;

&lt;p&gt;• The positive semidefinite cone \(\mathbb{S}^n_+\) is a self-dual convex cone, meaning \((\mathbb{S}^n_+)^{∗} = \mathbb{S}^n_+\).&lt;/p&gt;

&lt;p&gt;Why is this the case? Let’s verify:&lt;/p&gt;
&lt;blockquote&gt;
\[Y \succeq 0 \iff tr(Y X) ≥ 0 \text{ for all } X \succeq 0\]
&lt;/blockquote&gt;

&lt;p&gt;\(X\)’s eigenvalue decomposition&lt;/p&gt;

&lt;h2 id=&quot;dual-cones-and-dual-problems&quot;&gt;Dual cones and dual problems&lt;/h2&gt;
&lt;p&gt;Consider the cone constrained problem:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_x f(x) \text{ subject to } Ax \in K\]
&lt;/blockquote&gt;

&lt;p&gt;When \(I^{∗}_K(y) = \max_{z\in K} z^Ty\) is the support function of \(K\),
the dual problem of the above expression is as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u −f^∗(A^Tu)−I^∗_K(−u)\]
&lt;/blockquote&gt;

&lt;p&gt;When \(K\) is a cone, this can be easily defined as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u −f^∗(A^Tu) \text{ subject to } u \in K^{∗}\]
&lt;/blockquote&gt;

&lt;p&gt;Here \(K^{∗}\) is the dual cone of \(K\). because \(= I_K^{*}(-u) \ I_{K^{*}}(−u)\)&lt;/p&gt;

&lt;p&gt;This is quite useful because many different types of constraints can appear as cone constraints.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>13-04 Conjugate function</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_04_Conjugate_function/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter13/13_04_Conjugate_function</id>
   <content type="html">&lt;p&gt;For a given function \(f : \mathbb{R}^n → \mathbb{R}\), the conjugate \(f^{∗} : \mathbb{R}^n → \mathbb{R}\) is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[f^{∗}(y) = \max_x y^Tx−f(x)\]
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter13/conjugate_function.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Illustration of conjugate function [1]&lt;/figcaption&gt;
&lt;/p&gt;


### [Note] 
$$f^{∗}$$ is always convex since it is the pointwise maximum of convex (affine) functions $$y^Tx - f(x)$$.
(Here, $$f$$ does not necessarily need to be convex.)
$$f^{∗}(y)$$ is the maximum gap between the linear function $$y^Tx$$ and $$f(x)$$.
(From B &amp;amp; V page 91)

Conjugation for differentiable $$f$$ is called the Legendre transform.

#### Properties: 
• Fenchel’s inequality: for any $$x,y, f(x) + f^{∗}(y) ≥ x^Ty$$
&amp;gt; $$f(x) + f^{∗}(y) ≥ x^Ty \iff f^{*}(y) \ge x^Ty - f(x)$$
&amp;gt; $$ f^{*}(y) = \max_z z^Ty - f(x)$$

• The conjugate of a conjugate is $$f^{∗∗}$$, so $$f^{∗∗} ≤ f$$ holds.&lt;br /&gt;
• If $$f$$ is closed and convex, then $$f^{∗∗} = f$$. &lt;br /&gt;
• If $$f$$ is closed and convex, then for all $$x,y$$, the following holds:&lt;br /&gt;
&amp;gt; $$\begin{align}
&amp;gt; x ∈ ∂f^{∗}(y) &amp;amp;\iff y ∈ ∂f(x) \\\
&amp;gt; &amp;amp;\iff f(x) + f^{∗}(y) = x^Ty \\\
&amp;gt; \end{align}$$

• If $$f(u,v) = f_1(u) + f_2(v)$$, then $$f^{∗}(w,z) = f_1^{∗}(w) + f_2^{∗}(z)$$ holds. 



#### Examples: 
• Let&apos;s examine the case where $$f(x)$$ is a simple quadratic as follows:
&amp;gt; $$f(x) = \frac{1}{2}x^TQx$$, where $$Q \succ 0$$

Then $$y^Tx− \frac{1}{2}x^TQx$$ is strictly concave in $$y$$ and reaches its maximum at $$x = Q^{−1}y$$. That is, $$f^{∗}(y) = \frac{1}{2}y^TQ^{−1}y$$. 



### [Proof]
&amp;gt; $$\begin{align}
&amp;gt; f^{*}(y) &amp;amp; =  \max_x \left( y^Tx -\frac{1}{2}x^TQx \right) \\\
&amp;gt; &amp;amp; = -\min_x \left(\frac{1}{2}x^TQx- y^Tx \right), x^{\star} = Q^{-1}y  \\\
&amp;gt; &amp;amp; = -\frac{1}{2}y^TQ^{-1}QQ^{-1}y + y^TQ^{-1}y \\\
&amp;gt; &amp;amp; = \frac{1}{2}y^TQ^{-1}y  \\\
&amp;gt; \end{align}$$

&amp;gt; Fenchel&apos;s inequality: for any $$x, y$$
&amp;gt; $$\frac{1}{2} x^TQx + \frac{1}{2} y^TQ^{-1}y \ge x^Ty$$

• Indicator function: If $$f(x) = I_C(x)$$, then its conjugate is as follows:

&amp;gt; $$f^{∗}(y) = I^{∗}_C(y) = \max_{x ∈ C} y^Tx$$ called the **support function** of $$C$$

• Norm: If $$f(x) = \|x\|$$, then its conjugate is as follows:
&amp;gt; $$f^{∗}(y) = I_{\\{ z : \rVert z \rVert_{∗} ≤ 1 \\}}(y)$$ where $$\rVert · \rVert_{∗}$$ is the dual norm of $$\rVert · \rVert$$ 

&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>13-04-03 Shifting linear transformations</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_04_03_Shifting_linear_transformations/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter13/13_04_03_Shifting_linear_transformations</id>
   <content type="html">&lt;p&gt;The dual formulation helps with shifting linear transformations between parts of the objective function and other domains.&lt;/p&gt;

&lt;p&gt;Let’s look at the following:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) + g(Ax)\]
&lt;/blockquote&gt;

&lt;p&gt;The following expression is equivalent:&lt;/p&gt;
&lt;blockquote&gt;
\[min_{x,z} f(x) + g(z) \text { subject to } Ax = z\]
&lt;/blockquote&gt;

&lt;p&gt;This leads to the following dual process:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\text {g(u)} = \min_{x,z} f(x) + g(z) + u^T(z - Ax)\)
\(\qquad  = -\max_{x} (A^T u)^T x - f(x) - \max_{z} (-u)^T z - g(z)\)
\(\qquad = -\ f^* (A^T u) - g^* (-u)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And the dual is:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u -f^*(A^Tu) - g^*(-u)\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;example&quot;&gt;[Example]&lt;/h4&gt;
&lt;p&gt;Norms and their dual norms are related as follows: \(\| \cdot \|, \| \cdot \|^*\), the problems&lt;/p&gt;

&lt;blockquote&gt;
\[\min_x f(x) +\| Ax \|\]

\[\max_u -f^*(A^Tu) \text{ subject to } \| u \|^* \leq 1\]
&lt;/blockquote&gt;

&lt;p&gt;The first expression is the primal, and the second is the dual, which can be solved directly.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13-04-02 Conjugates and dual problems</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_04_02_Conjugates_and_dual_problems/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter13/13_04_02_Conjugates_and_dual_problems</id>
   <content type="html">&lt;p&gt;Conjugates can often be represented through the derivation of dual problems for Lagrangian minimization problems as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[−f^{∗}(u) = \min_x f(x)−u^Tx\]
&lt;/blockquote&gt;

&lt;p&gt;For example, consider the following expression:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_x  f(x) + g(x)\]
&lt;/blockquote&gt;

&lt;p&gt;The following expression has constraints added to the above expression and is equivalent to it:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x,z} f(x) + g(z) \text{ subject to } x = z\]
&lt;/blockquote&gt;

&lt;p&gt;Converting this to a Lagrange dual function gives:&lt;/p&gt;

&lt;blockquote&gt;
\[g(u) = \min_{x,z} f(x) + g(z) + u^T(z−x) = −f^{∗}(u)−g^{∗}(−u)\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, the dual problem of the original expression can be defined as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u −f^{∗}(u)−g^{∗}(−u)\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;examples&quot;&gt;[Examples]&lt;/h4&gt;
&lt;p&gt;• Indicator function: The dual of \(\min_x f(x) + I_C(x)\) is as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u −f^{∗}(u)−I^{∗}_C(−u)\]

  &lt;p&gt;where \(I^{∗}_C\) is the support function of \(C\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;• Norms:&lt;/p&gt;

&lt;p&gt;The dual of \(\min_x f(x) + \rVert x \rVert\) is as follows:
\(\max_u −f^{∗}(u) \text{ subject to } \rVert u \rVert^{∗} ≤ 1 \text{ where } \rVert · \rVert_{∗} \text{ is the dual norm of } \rVert · \rVert\)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13-04-01 Example lasso dual</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_04_01_Example_lasso_dual/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter13/13_04_01_Example_lasso_dual</id>
   <content type="html">&lt;p&gt;Let’s look at the lasso problem for \(y \in \mathbb{R}^n, X \in \mathbb{R}^{n\times p}\):&lt;/p&gt;

&lt;blockquote&gt;
\[\min_\beta \frac{1}{2} \| y-X\beta \|^2_2 + \lambda\| \beta \|_1\]

\[f(\beta) = \frac{1}{2} \| y - X\beta \|^2_2 +  \lambda\| \beta \|_1\]

\[L(\beta) = f(\beta)\]

\[\min_\beta L(\beta) = f^{\star}\]
&lt;/blockquote&gt;

&lt;p&gt;The dual function of the above is constant (= \(f^*\)). Therefore, we can transform the primal problem as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{\beta,z} \frac{1}{2} \| y-z \|^2_2 + \lambda \| \beta \|_1 \text{ subject to } z = X\beta\]
&lt;/blockquote&gt;

&lt;p&gt;The dual function of the transformed problem is:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
g(u) &amp;amp;= \min_{\beta,z} \frac{1}{2} \| y-z \|^2_2 + \lambda \| \beta \|_1 + u^T(z-X\beta) \\
&amp;amp;= \frac{1}{2} \| y \|^2_2 - \frac{1}{2} \| y-u \|^2_2 - I_{\{ v : \| v \|_\infty \leq 1 \}}(X^Tu/\lambda) \\
\end{align}\]

&lt;/blockquote&gt;

&lt;h4 id=&quot;proof&quot;&gt;[Proof]&lt;/h4&gt;
&lt;blockquote&gt;
\[\begin{align}
g(u) &amp;amp;= \min_{\beta,z} \frac{1}{2} \| y-z \|^2_2 + \lambda \| \beta \|_1 + u^T(z-X\beta) \\
&amp;amp;= \underbrace{ \left( \min_z \frac{1}{2} \| y - z \|^2_2 + u^Tz \right)}_{(1)} + \underbrace{\left( \min_\beta  \lambda \| \beta \|_1 + u^TX\beta \right)}_{(2)} \\
\end{align}\]

\[z^{\star} = y - u\]

  &lt;p&gt;\(\begin{align}
(1) \cdots \left( \min_z \frac{1}{2} \| y - z \|^2_2 + u^Tz \right)
&amp;amp;= \frac{1}{2} \| u \|^2_2 + u^T(y - u) \\
&amp;amp;= -\frac{1}{2} \| y - u \|^2_2 + \frac{1}{2} \| y \|^2_2 \\
\end{align}\)
\(\begin{align}
(2) \cdots \left( \min_\beta  \lambda \| \beta \|_1 + u^TX\beta \right) 
&amp;amp;= - \lambda \max_\beta \frac{u^Tx}{\lambda} \beta - \| \beta \|_2 \\
&amp;amp;= - \lambda \left( \| \frac{u^Tx}{\lambda} \|_\infty \leq 1 \right) \\
&amp;amp;= - \lambda \left( \| u^Tx \|_\infty \leq \lambda \right) \\
\end{align}\)
\therefore g(u) = -\frac{1}{2} | y - u |^2&lt;em&gt;2 + \frac{1}{2} | y |^2_2 + - \lambda \left( | u^Tx |&lt;/em&gt;\infty \leq \lambda \right)
= \frac{1}{2} | y |^2&lt;em&gt;2 - \frac{1}{2} | y-u |^2_2 - I&lt;/em&gt;{{ v : | v |_\infty \leq 1 }}(X^Tu/\lambda)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Therefore, the lasso dual problem is:&lt;/p&gt;

&lt;blockquote&gt;
\[\max_u \frac{1}{2} ( \| y \|^2_2 - \| y-u \|^2_2 ) \text{ subject to } \| X^Tu \|_\infty \leq \lambda\]
&lt;/blockquote&gt;

&lt;p&gt;This is equivalent to:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_u \| y-u \|^2_2 \text{ subject to } \| X^Tu \|_\infty \leq \lambda\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;check&quot;&gt;[Check]&lt;/h3&gt;
&lt;p&gt;Slater’s condition is satisfied, so strong duality holds.&lt;/p&gt;
&lt;blockquote&gt;
\[\text{strong duality } \implies (\beta^{\star}, z^{\star})\]

\[\text{ must minimize  } L( \beta, z, u^{\star} ) \text{ over } -u, \beta, z\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;note&quot;&gt;[note]&lt;/h3&gt;
&lt;p&gt;The optimal value in the previous problem is not the optimal lasso objective value.
However, the dual solution \(u\) and the lasso solution \(\beta\) satisfy \(X\beta = y-u\).&lt;/p&gt;

&lt;p&gt;This is satisfied by the KKT stationarity condition \(z\) (i.e., \(z-y + \beta = 0\)).&lt;/p&gt;

&lt;p&gt;Therefore, lasso satisfies the dual residual.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter13/Conjugate_LassoDual_Example.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Lasso Dual [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>13-03 Dual norms</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_03_Dual_norms/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter13/13_03_Dual_norms</id>
   <content type="html">&lt;p&gt;Let’s examine an arbitrary &lt;strong&gt;norm&lt;/strong&gt; \(\| x \|\):&lt;/p&gt;

&lt;blockquote&gt;
\[l_p \text{ norm: } \lVert x \rVert_p = (\sum^n_{i=1} \rVert x_i \rVert_p)^{1/p}, \text{ for } p ≥ 1\]

\[\text{Trace norm: } \lVert X \rVert_{tr} = \sum^r_{i=1} σ_i(X)\]
&lt;/blockquote&gt;

&lt;p&gt;The &lt;strong&gt;dual norm&lt;/strong&gt; of norm \(\lVert x \rVert\) is denoted as \(\lVert x \rVert_{∗}\) and is defined as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\lVert x \rVert_{∗} = \max_{\lVert z \rVert ≤1} z^Tx\]
&lt;/blockquote&gt;

&lt;p&gt;Suppose there exists some arbitrary \(y\). Then when we let \(z = \frac{y}{\rVert y \rVert}\), we have \(\rVert z \rVert = 1\). Also, \(\rVert z^Tx \rVert \le \rVert x \rVert_{*}\) holds,
therefore a form similar to the &lt;em&gt;Cauchy-Schwartz inequality&lt;/em&gt; \(\rVert y^Tx \rVert \le \rVert y \rVert \rVert x \rVert_{*}\) is established.&lt;/p&gt;

&lt;p&gt;Let’s examine examples of dual norms under specific conditions:&lt;/p&gt;
&lt;blockquote&gt;
\[l_p \text{ norm dual: } (\lVert x \rVert_p)_{*} = \lVert x \rVert_{q}, \text{ where } 1/p + 1/q = 1\]

\[\text{Trace norm dual: } (\lVert X \rVert_{tr})_{*} = \lVert X \rVert_{op}) = σ_1(X)\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;proof&quot;&gt;[Proof]&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;Let’s prove that the following holds for the \(l_p\) norm dual:&lt;/p&gt;

\[(\lVert x \rVert_p)_{*} = \lVert x \rVert_{q}, \text{ where } 1/p + 1/q = 1 \qquad \text{(1)}\]

  &lt;p&gt;&lt;em&gt;Proof&lt;/em&gt;&lt;/p&gt;

\[(\lVert x \rVert_p)_{*} = \sup \{ z^Tx : x \in \mathbb{R}^n, \rVert x \rVert_q \le 1 \} \qquad  \text{(2)}\]

  &lt;p&gt;Meanwhile, by Holder’s inequality, the following holds:&lt;/p&gt;

\[z^T x ≤ \rVert z^tx \rVert 1 ≤ \rVert z \rVert_p \rVert x \rVert_q (\text{ where }, 1/p + 1/q = 1)\qquad \text{(3)}\]

  &lt;p&gt;From (1) above, the following relationship holds:&lt;/p&gt;

\[(\rVert z \rVert_q)_∗ ≤ \rVert z \rVert_p\qquad \text{(4)}\]

  &lt;p&gt;Therefore, if we find \(x\) such that \(\rVert x \rVert_q ≤ 1\) and \(z^Tx\) satisfies \(\rVert z \rVert_p\), we can see that \((\rVert z \rVert_q)_∗ = \rVert z \rVert\rVert_p\) holds.&lt;/p&gt;

  &lt;p&gt;Meanwhile, if we set \(y := sign(z) \rVert z\rVert^{p−1} \left( y_i = sign(z_i)\rVert z_i\rVert^{p−1} \right)\) and \(x = y\), then \(\rVert y \rVert_q\)
satisfies \(\rVert x \rVert_q =1\), and we can confirm that \(z^Tx = \rVert z \rVert_p\).&lt;/p&gt;

  &lt;p&gt;Therefore, the following holds:&lt;/p&gt;

\[( \rVert z \rVert_ q)_∗ = \rVert z \rVert_p, (1/p+1/q=1)\qquad \text{(5)}\]
&lt;/blockquote&gt;

&lt;p&gt;The dual norm of a dual norm becomes the original norm again.&lt;/p&gt;
&lt;blockquote&gt;
\[\lVert x \rVert_{**} = \lVert x \rVert\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s examine the following problem:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_y \lVert y \rVert \qquad \text{ subject to } y = x\]
&lt;/blockquote&gt;

&lt;p&gt;When the optimal value is \(\rVert x \rVert\), the Lagrangian is expressed as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[L(y,u) = \rVert y \rVert+ u^T(x−y) = \rVert y \rVert − y^Tu + x^Tu\]
&lt;/blockquote&gt;

&lt;p&gt;When expressed in terms of the dual norm \((\lVert · \rVert_{∗})\), it becomes:&lt;/p&gt;
&lt;blockquote&gt;
\[\text{If } \rVert u \rVert_{∗} ≤ 1,\text{ then}  \qquad \min_y \{ \rVert y \rVert − y^Tu \} = 0\]

\[\text{If } \rVert u \rVert_{∗} &amp;gt; 1, \text{ then}  \qquad \min_y \{ \rVert y \rVert − y^Tu \} = −∞\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;note&quot;&gt;[Note]&lt;/h3&gt;
&lt;blockquote&gt;
\[\text{If } \rVert u \rVert_{∗} ≤ 1, \text{ then}  \qquad \min_y \{ \rVert y \rVert − y^Tu \} = 0\]

\[\max_y (y^Tu - \rVert y \rVert ) = 0\]

\[y^Tu \le \rVert y \rVert \rVert u \rVert_* \le \rVert y \rVert\]

\[\text{If } \rVert u \rVert_{∗} &amp;gt; 1, \text{ then}  \qquad \min_y \{ \rVert y \rVert − y^Tu \} = −∞\]

  &lt;p&gt;\(\text{Can always find} \qquad\) \(z\)  with \(\rVert z \rVert = 1 \qquad \text{ subject to }\qquad z^Tu = \rVert u \rVert_{*} \qquad ( argmax_{\rVert z \rVert \le 1}  z^Tu )\)&lt;/p&gt;

  &lt;p&gt;\(\text{take}\) \(y = t \cdot z, \qquad t &amp;gt; 0\)&lt;/p&gt;

\[y^Tu = t \cdot \rVert u \rVert_{*}\]

\[\text{ for this } y, \qquad y^Tu - \rVert y \rVert = t \cdot \rVert u \rVert_{*} - t \rightarrow ∞ \text{ as } t \rightarrow ∞\]

\[\text{ so therefore }  g(u) = \min_y L(y, u) = x^Tu - I(\rVert u \rVert_{*} \le 1)\]

  &lt;p&gt;dual problem&lt;/p&gt;

\[\max_u g(u) \iff \max_{\rVert u \rVert_{*} \le 1} x^Tu\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, the Lagrange dual problem is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\max_u u^Tx \qquad \text{ subject to }\qquad \rVert u \rVert_{∗} ≤ 1\]
&lt;/blockquote&gt;

&lt;p&gt;Since there are no inequality constraints, Slater’s condition is satisfied, and according to strong duality, \(f^{\star} = g^{\star}\).
That is, \(\rVert x \rVert = \rVert x \rVert_{∗∗}\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>13-02 Solving the primal via the dual</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_02_Solving_the_primal_via_the_dual/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter13/13_02_Solving_the_primal_via_the_dual</id>
   <content type="html">&lt;h3 id=&quot;an-important-consequence-of-stationarity&quot;&gt;An important consequence of stationarity&lt;/h3&gt;
&lt;p&gt;Under the condition of strong duality, when dual solution \(u^{\star}, v^{\star}\) is given, the primal solution \(x^{\star}\) can be found by solving the following Lagrangian:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_x f(x) + \sum_{i=1}^m u_i^{\star} h_i(x) + \sum_{j=1}^r v^{\star}_i l_j(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Often, the solution to such unconstrained problems can be represented by explicitly bringing the characteristics of the primal solution through the dual solution.&lt;/p&gt;

&lt;p&gt;Moreover, if the solution to this problem is unique, the dual solution becomes the primal solution \(x^{\star}\).
This is very useful when solving the dual problem is easier than solving the primal problem directly.&lt;/p&gt;

&lt;h3 id=&quot;example-from-b--v-page-249&quot;&gt;Example from B &amp;amp; V page 249:&lt;/h3&gt;
&lt;blockquote&gt;
\[\min_x \sum_{i=1}^n f_i(x_i) \qquad \text{ subject to }\qquad a^Tx = b\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[\begin{align}
g(v) &amp;amp;= \min_x \sum_{i=1}^n f_i(x_i) + v(b−a^Tx) \\\
&amp;amp;= bv + \min_x \sum_{i=1}^n f_i(x_i) −va^Tx \\\
&amp;amp;= bv + \min_x \sum_{i=1}^n f_i(x_i) −v \sum_{i=1}^n a_ix_i \\\
&amp;amp;= bv + \sum_{i=1}^n (\underbrace{\min_{x_i} \{ f_i(x_i) − a_ivx_i \}}_{-f^{*}_i(a_iv)}) \\\
&amp;amp;= bv − \sum_{i=1}^n f^{*}_i (a_iv)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here \(f^{*}\) denotes the conjugate of \(f_i\).&lt;/p&gt;

&lt;p&gt;Therefore, the dual problem can be represented as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\max_v bv − \sum^n_{i=1} f^{*}_i (a_iv)\]
&lt;/blockquote&gt;

&lt;p&gt;Also, by multiplying by minus (-), the maximum problem can be represented as the following minimum problem:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_v \sum^n_{i=1} f^{*}_i (a_iv) − bv\]
&lt;/blockquote&gt;

&lt;p&gt;This is a convex minimization problem in scalar variables that can be solved much more easily than the primal problem.&lt;/p&gt;

&lt;p&gt;When \(v^{\star}\) is given, the primal solution \(x^{\star}\) can be solved as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_{x} \sum^n_{i=1} (f_i(x_i) − a_iv^{\star}x_i)\]
&lt;/blockquote&gt;

&lt;p&gt;The strict convexity of each \(f_i\) means that this has a unique solution.
That is, \(x^{\star}\) is obtained through the calculation of \(∇f_i(x_i) = a_iv^{\star}\) for each \(i\).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>13-01 Uses of duality</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_01_Uses_of_duality/"/>
   <updated>2021-04-05T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter13/13_01_Uses_of_duality</id>
   <content type="html">&lt;h3 id=&quot;two-key-uses-of-duality&quot;&gt;Two key uses of duality&lt;/h3&gt;
&lt;p&gt;Let’s revisit the two key characteristics of duality covered in Chapter 11.&lt;/p&gt;

&lt;p&gt;• When \(x\) is primal feasible and \(u,v\) are dual feasible, the difference between the primal problem \(f(x)\) and the dual problem \(g(u,v)\) is called the &lt;strong&gt;duality gap&lt;/strong&gt; between \(x\) and \(u,v\).&lt;/p&gt;
&lt;blockquote&gt;
\[f(x)-f^{\star}  \le f(x)-g(u, v)\]
&lt;/blockquote&gt;

&lt;p&gt;When the duality gap is 0, this is called zero duality gap, which means that the solution to the dual problem is optimal.
Also, the upper bound \(g(u, v)\) is always less than or equal to the optimal value \(f^{\star}\). For detailed reasons, please refer to the content in &lt;a href=&quot;/contents/en/chapter11/11_00_Duality_in_General_Programs/&quot;&gt;[Chapter 11]&lt;/a&gt;.
Therefore, the following derivation is possible.&lt;/p&gt;

&lt;h4 id=&quot;proof&quot;&gt;[Proof]&lt;/h4&gt;
&lt;blockquote&gt;
\[\begin{align*}
f^{\star} &amp;amp;\ge g(u, v) \\
-f^{\star} &amp;amp;\le -g(u, v) \\
f(x)-f^{\star} &amp;amp;\le \underbrace{f(x)-g(u, v)}_{\text{duality gap}}\\
g^{\star}-g(x) &amp;amp;\le \underbrace{f(x)-g(u, v)}_{\text{duality gap}}\\
\end{align*}\]
&lt;/blockquote&gt;

&lt;p&gt;Moreover, the duality gap can be used as a stopping criterion for algorithms.
• When dual optimal \(u^{\star}, v^{\star}\) are given, under the condition of strong duality, the primal solution minimizes the Lagrangian \(L (x, u^{\star}, v^{\star})\) for all \(x\) (i.e., satisfies the stationarity condition).&lt;/p&gt;

&lt;p&gt;This can be used for computing the primal solution.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>12-06 Tính duy nhất trong các bài toán phạt L1</title>
   <link href="http://localhost:4000/contents/vi/chapter12/12_06_Uniqueness_in_L1_penalized_problems/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter12/12_06_Uniqueness_in_L1_penalized_problems</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Bài toán hồi quy tuyến tính có phạt \(L1\) sau đây cũng được biết đến rộng rãi như bài toán lasso.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;&amp;amp;&amp;amp;\hat{\beta} \in \text{argmin}_{\beta \in \mathbb{R}^p} \frac{1}{2} \| y - X\beta \|^2_2 + \lambda \|\beta\|_1, \qquad \\\\
&amp;amp;&amp;amp; \text{ --- (1) } &amp;amp;\text{cho trước } y \in \mathbb{R}^n, \\\\
&amp;amp;&amp;amp;&amp;amp; \text{ một ma trận } X \in \mathbb{R}^{n \text{ x } p} \ \text{ của các biến dự đoán,} \\\\
&amp;amp;&amp;amp;&amp;amp; \text{và tham số điều chỉnh} \lambda \ge 0.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán Lasso ở trên có một nghiệm duy nhất khi nó là lồi chặt chẽ, tức là, khi \(rank(X) = p\). Mặt khác, khi \(rank(X) &amp;lt; p\) (khi nó không lồi chặt chẽ), nó có thể có vô số nghiệm (Tham khảo: &lt;a href=&quot;https://en.wikipedia.org/wiki/Underdetermined_system&quot;&gt;Hệ thống thiếu xác định&lt;/a&gt;). - Lưu ý rằng nếu số biến (p) lớn hơn số quan sát (n), thì \(rank(X)\) nhất thiết nhỏ hơn p.&lt;br /&gt;
Thú vị là, trong một số trường hợp đặc biệt, bài toán Lasso được đảm bảo có một nghiệm duy nhất bất kể chiều của \(X\) [13].&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Định lý:&lt;/strong&gt; Khi hàm \(f\) khả vi và lồi chặt chẽ, \(\lambda &amp;gt; 0\), và \(X \in \mathbb{R}^{n \times p}\) tuân theo một phân phối xác suất liên tục nào đó trên \(\mathbb{R}^{np}\), bài toán tối ưu hóa sau luôn có một nghiệm duy nhất. Hơn nữa, nghiệm bao gồm nhiều nhất \(min\{n,p\}\) thành phần khác không. Không có hạn chế nào về chiều của \(X\). (Tức là, nó hợp lệ ngay cả khi p » n)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;các-sự-thật-cơ-bản-và-các-điều-kiện-kkt&quot;&gt;Các sự thật cơ bản và các điều kiện KKT&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Bổ đề 1.&lt;/strong&gt; Đối với \(y, X, \lambda \ge 0\) tùy ý, bài toán lasso (1) có các tính chất sau.&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;Nó có hoặc một nghiệm duy nhất hoặc vô số nghiệm.&lt;/li&gt;
    &lt;li&gt;Tất cả các nghiệm lasso \(\hat{\beta}\) có cùng giá trị \(X\hat{\beta}\).&lt;/li&gt;
    &lt;li&gt;Khi \(\lambda &amp;gt; 0\), tất cả các nghiệm lasso \(\hat{\beta}\) có cùng chuẩn \(l_1\) (\(\|\hat{\beta}\|_1\)).&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

\[\text{ }\]

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Chứng minh.&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;Nếu (1) có hai nghiệm \(\hat{\beta}^{(1)}\), \(\hat{\beta}^{(2)}\), thì với bất kỳ \(0 &amp;lt; \alpha &amp;lt; 1\), \(\alpha \hat{\beta}^{(1)} + (1 - \alpha) \hat{\beta}^{(2)}\) cũng là một nghiệm, vì vậy tồn tại vô số nghiệm.&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;&amp;amp; 3. Giả sử có hai nghiệm \(\hat{\beta}^{(1)}\), \(\hat{\beta}^{(2)}\). Gọi giá trị tối ưu là \(c^\star\). Khi đó với bất kỳ nghiệm \(\alpha \hat{\beta}^{(1)} + (1 - \alpha) \hat{\beta}^{(2)}\) (\(0 &amp;lt; \alpha &amp;lt; 1\)), đẳng thức sau phải luôn được giữ.&lt;/li&gt;
  &lt;/ol&gt;

\[\begin{align}
&amp;amp;\frac{1}{2} \| y - X(\alpha \hat{\beta}^{(1)} + (1 - \alpha) \hat{\beta}^{(2)}) \|_2^2 + \lambda \| \alpha \hat{\beta}^{(1)} + (1 - \alpha) \hat{\beta}^{(2)} \|_1 \\
&amp;amp; = \alpha c^\star + (1-\alpha) c^\star = c^\star
\end{align}\]

  &lt;p&gt;Để thỏa mãn đẳng thức này, \(X\hat{\beta}\) phải luôn có cùng giá trị cho bất kỳ nghiệm \(\hat{\beta}\), và khi \(\lambda &amp;gt; 0\), \(\|\hat{\beta}\|_1\) cũng phải luôn giống nhau.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Trở lại ban đầu, các điều kiện KKT cho bài toán lasso (1) như sau.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;&amp;amp;X^T (y - X\hat{\beta}) = \lambda \gamma, \qquad \text{ --- (2)} \\\\
&amp;amp;&amp;amp;\gamma_i \in 
\begin{cases}
\{ sign(\hat{\beta_i}) \} &amp;amp; \text{nếu } \hat{\beta_i} \neq 0 \\\\
[-1, 1] &amp;amp; \text{nếu } \hat{\beta_i} = 0,
\end{cases} \\\\
&amp;amp;&amp;amp;\text{với } i = 1, \dots, p. \text{ --- (3)} \\\\
&amp;amp;&amp;amp;\text{Ở đây } \gamma \in \mathbb{R}^p \text{ được gọi là subgradient của hàm } \\
&amp;amp;&amp;amp;f(x) = \| x \|_1 \text{ được đánh giá tại } x = \hat{\beta}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Tức là, nghiệm \(\hat{\beta}\) của (1) thỏa mãn (2) và (3) cho một \(\gamma\) nào đó.&lt;/p&gt;

&lt;p&gt;위에서 얻은 KKT conditions를 이용하여 lasso solution에 대한 조건을 좀 더 명시적인 형태로 변환해보도록 하자. 이후의 진행에서는 유도의 간결함을 위해 \(\lambda &amp;gt; 0\)를 가정하도록 한다. 우선 equicorrelation set \(\mathcal{E}\)을 다음과 같이 정의한다. \(\mathcal{E}\)는 \(\hat{\beta}_i \neq 0\)인 모든 인덱스 \(i\)와 \(\hat{\beta}_j = 0\)이면서 \(\vert\gamma_j\vert = 1\)인 모든 인덱스 \(j\)를 원소로 가진 집합이다.&lt;/p&gt;

\[\mathcal{E} = \{ i \in \{1, \dots, p \}  : \vert X_i^T (y - X\hat{\beta}) \vert = \lambda \}. \qquad \text{ --- (4)}\]

&lt;p&gt;또한 equicorrelation sign \(s\)를 다음과 같이 정의한다. 여기서 \(X_\mathcal{E}\)는 행렬 X에서 \(i \in \mathcal{E}\)인 column \(i\) 외의 모든 column을 0 벡터로 교체한 행렬을 의미한다.&lt;/p&gt;

\[s = sign(X^T_\mathcal{E} (y -X\hat{\beta}). \qquad \text{ --- (5)}\]

&lt;p&gt;여기서 \(\mathcal{E}, s\)는 \(\gamma\)에 대해 다음과 같이 표현할 수 있다: \(\mathcal{E} = \{i \in \{1, \dots, p \} : \vert \gamma_i \vert = 1 \}\) and \(s = \gamma_{\mathcal{E}}\). 또한 Lemma1-2에 의해 \(X\hat{\beta}\)는 유일한 값을 가지므로 이는 \(\mathcal{E}\), \(s\)이 유일함을 암시한다.&lt;/p&gt;

&lt;p&gt;(3)의 subgradient \(\gamma\)에 대한 정의에 의해 모든 lasso solution \(\hat{\beta}\)에 대해 \(\hat{\beta}_{-\mathcal{E}} = 0\)임을 알 수 있다. 그러므로 (2)를 \(\mathcal{E}\) 블록에 대해 표현하면 다음과 같다.&lt;/p&gt;

\[X^T_\mathcal{E} ( y - X_\mathcal{E} \hat{\beta_\mathcal{E}} ) = \lambda \gamma_\mathcal{E}=  \lambda s. \qquad \text{ --- (6)}\]

&lt;p&gt;(6)의 양변에 \(X^T_\mathcal{E} (X^T_\mathcal{E})^+\)를 곱하면 다음과 같이 정리된다 (\((X^T_\mathcal{E})^+\)는 \(X^T_\mathcal{E}\)의 pseudoinverse matrix).&lt;/p&gt;

\[\begin{align}
&amp;amp; X^T_\mathcal{E} X_\mathcal{E} \hat{\beta_\mathcal{E}} = X^T_\mathcal{E} ( y - (X^T_\mathcal{E})^+  \lambda s) \\\\
\Leftrightarrow
&amp;amp; X_\mathcal{E} \hat{\beta_\mathcal{E}} = X^T_\mathcal{E} (X^T_\mathcal{E})^+ ( y - (X^T_\mathcal{E})^+  \lambda s).
\end{align}\]

&lt;p&gt;\(X\hat{\beta} = X_\mathcal{E} \hat{\beta_\mathcal{E}}\)이므로 위 등식은 곧 아래와 같다.&lt;/p&gt;

\[X \hat{\beta} = X^T_\mathcal{E} (X^T_\mathcal{E})^+ ( y - (X^T_\mathcal{E})^+  \lambda s), \qquad \text{ --- (7)}\]

&lt;p&gt;그리고 임의의 lasso solution \(\hat{\beta}\)는 다음과 같다.&lt;/p&gt;

\[\begin{align}
&amp;amp; \hat{\beta_{-\mathcal{E}}} = 0 \text{ and } \hat{\beta_{\mathcal{E}}} = (X^T_\mathcal{E})^+ ( y - (X^T_\mathcal{E}) + b, \qquad \text{ --- (8)} \\\\
&amp;amp; \text{where } b \in null(X_\mathcal{E}).
\end{align}\]

&lt;h2 id=&quot;sufficient-conditions-for-uniqueness&quot;&gt;Sufficient conditions for uniqueness&lt;/h2&gt;

&lt;p&gt;(8)의 \(\hat{\beta_{\mathcal{E}}}\)의 유일함이 보장되기 위해서는 \(b=0\)이 되어야 한다 ( \((X^T_\mathcal{E})^+ ( y - (X^T_\mathcal{E})\)은 유일하기 때문에). \(b=0\)이어야 함을 주지하고 (8)의 등식을 변형하면 다음의 결론을 얻게 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lemma 2.&lt;/strong&gt; 임의의 \(y, X, \lambda &amp;gt; 0\)에 대해, 만약 \(null(X_\mathcal{E}) = {0}\), 또는 \(rank(X_\mathcal{E}) = \vert\mathcal{E}\vert\) (&lt;a href=&quot;https://www.quora.com/When-the-null-space-of-a-matrix-is-the-zero-vector-the-matrix-is-in\vertible-Why/answer/Alexander-Farrugia&quot;&gt;참고&lt;/a&gt;),이면 lasso solution은 유일(unique)해지며, 이는 곧 다음과도 같다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;&amp;amp; \hat{\beta_{-\mathcal{E}}} = 0 \text{ and } \hat{\beta_{\mathcal{E}}} = (X^T_\mathcal{E}X^T_\mathcal{E})^{-1} ( X^T_\mathcal{E} y - \lambda s), \qquad \text{ --- (9)} \\\\
&amp;amp;&amp;amp; \text{where } \mathcal{E} \text{ and } s \text{ are the equicorrelation set and signs as defined in (4) and (5)}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;참고로 이 solution은 많아 봐야 \(min\{n, p\}\)의 nonzero components로 구성된다.&lt;/p&gt;

&lt;p&gt;그렇다면 \(null(X_\mathcal{E}) = {0}\)을 암시하는 (\(X\)에 대한) 좀 더 자연스러운 조건에 대해 알아보도록 하자. 이를 알아보기에 앞서 우선 \(null(X_\mathcal{E}) \neq {0}\)이라 가정해보겠다. 이 경우, 어떤 \(i \in \mathcal{E}\)에 대해 다음과 같은 등식을 만족한다.&lt;/p&gt;

\[X_i = \sum_{j \in \mathcal{E} \backslash \{i\} } c_j X_j,\\\\
\text{where } c_j \in \mathbb{R}, j \in \mathcal{E}.\]

&lt;p&gt;위 등식의 양변에 \(s_i\)를 곱해주고, 우항에 \(s_j s_j = 1\)을 곱해준다.&lt;/p&gt;

\[s_i X_i = \sum_{j \in \mathcal{E} \backslash \{i\} } (s_i s_j c_j) \cdot (s_j X_j). \qquad \text{ --- (10)}\]

&lt;p&gt;\(r = y - X \hat{\beta}\)로 r(lasso residual)을 정의하면 임의의 \(j \in \mathcal{E}\)에 대해 \(X_j^T r = s_j \lambda\)를 만족한다. r을 위 (10)의 양변에 곱해주면 \(\lambda\)에 대한 부등식을 얻을 수 있다. (\(\lambda &amp;gt; 0\)이라 가정)&lt;/p&gt;

\[\lambda = \sum_{j \in \mathcal{E} \backslash \{i\} } (s_i s_j c_j) \lambda \quad \text{ and } \quad \sum_{j \in \mathcal{E} \backslash \{i\} } (s_i s_j c_j) = 1.\]

&lt;p&gt;즉, \(null(X_\mathcal{E}) \neq {0}\)이면, 어떤 \(i \in \mathcal{E}\)에 대해 다음 등식이 성립한다.&lt;/p&gt;

\[s_iX_i = \sum_{j \in \mathcal{E} \backslash \{i\} } a_j \cdot s_j X_j, \text{ with } \sum_{j \in \mathcal{E} \backslash \{i\} } a_j = 1.\]

&lt;p&gt;위 등식은 \(s_iX_i\)이 \(s_j X_j, j \in \mathcal{E} \backslash \{i\}\)의 affine span 위에 존재한다는 의미와도 같다. 또한 이는 어떤 k+2개의 원소를 포함한 subset으로는 최대 k dimensional affine space만을 표현할 수 있다는 것과도 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter12/l1_uniqueness.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] 4 elements on 2-dimensional affine space [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;우리가 원하는 것은 행렬 \(X \in \mathbb{R}^{n \text{ x } p}\)가 \(null(X_\mathcal{E}) = {0}\)을 만족하는 것이며, 이는 곧 행렬 \(X\)의 column들이 &lt;a href=&quot;https://en.wikipedia.org/wiki/General_position&quot;&gt;general position&lt;/a&gt;에 있는 것과도 같다. 바꿔말하면, 그 어떤 k-dimensional affine subspace도 set 안의 k+1개보다 더 많은 element를 포함하지 않는다는 것이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lemma 3.&lt;/strong&gt; 만약 행렬 \(X\)의 column들이 general position에 있으면, 임의의 \(y\)와 \(\lambda &amp;gt; 0\)에 대한 lasso solution은 유일(unique)하며 또한 이 solution은 (9)를 만족한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그렇다면 어떤 행렬 \(X\)가 항상 위 조건을 만족할 수 있을까? 결론부터 말하자면 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lemma 4.&lt;/strong&gt; 행렬 \(X \in \mathbb{R}^{n \text{ x } p}\)의 모든 원소가 \(\mathbb{R}^{np}\) 상의 continuous probability distribution을 따른다면, 임의의 \(y\)와 \(\lambda &amp;gt; 0\)에 대해 lasso solution은 unique하고 항상 (9)를 만족한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;왜냐하면 continuous probability distribution을 따를때, 모든 column vector들은 linearly independent하기 때문이다. (&lt;a href=&quot;https://math.stackexchange.com/questions/432447/probability-that-n-vectors-drawn-randomly-from-mathbbrn-are-linearly-ind?rq=1&quot;&gt;참고&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&quot;general-convex-loss-functions&quot;&gt;General convex loss functions&lt;/h2&gt;

&lt;p&gt;좀 더 일반적인 lasso problem에 대해서도 같은 내용을 적용할 수 있다 [13].&lt;/p&gt;

\[\hat{\beta} \in \text{argmin}_{\beta \in \mathbb{R}^p} f(X\beta) + \lambda \|\beta\|_1, \qquad \text{ --- (11) }\]

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lemma 5.&lt;/strong&gt; 만약 행렬 \(X \in \mathbb{R}^{n \text{ x } p}\)의 모든 원소가 \(\mathbb{R}^{np}\) 상의 continuous probability distribution을 따를때, 미분 가능하고 strictly convex인 임의의 함수 \(f\)는 임의의 \(\lambda &amp;gt; 0\)에 대해 (11)의 문제에서 항상 유일(unique)한 solution을 보장한다. 이 solution은 많아봐야 \(min\{n,p\}\)개의 nonzero components로 구성된다.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>12-05 Dạng ràng buộc và dạng Lagrange</title>
   <link href="http://localhost:4000/contents/vi/chapter12/12_05_Constrained_and_Lagrange_forms/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter12/12_05_Constrained_and_Lagrange_forms</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Trong thống kê và học máy, chúng ta thường chuyển đổi giữa &lt;strong&gt;dạng ràng buộc&lt;/strong&gt; và &lt;strong&gt;dạng Lagrange&lt;/strong&gt;. Hãy định nghĩa dạng ràng buộc và dạng Lagrangian như sau.&lt;/p&gt;

&lt;h3 id=&quot;dạng-ràng-buộc-c-sau-đây&quot;&gt;Dạng Ràng buộc ((C) sau đây)&lt;/h3&gt;
&lt;blockquote&gt;
\[\min_x \: f(x) \quad \text{ với điều kiện } h(x) \le t,\\\\
\text{trong đó } t \in \mathbb{R} \text{ là tham số điều chỉnh.}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;dạng-lagrange-l-sau-đây&quot;&gt;Dạng Lagrange ((L) sau đây)&lt;/h3&gt;
&lt;blockquote&gt;
\[\min_x \: f(x) + \lambda \cdot h(x),\\\\
\text{trong đó } \lambda \ge 0 \text{ là tham số điều chỉnh.}\]
&lt;/blockquote&gt;

&lt;p&gt;Khi \(f, h\) là lồi, hãy xem xét các trường hợp mà hai bài toán cho cùng một nghiệm.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;(C) đến (L):&lt;/strong&gt; Khi (C) là khả thi chặt chẽ (thỏa mãn điều kiện Slater) và thỏa mãn tính đối ngẫu mạnh, nếu tồn tại một nghiệm đối ngẫu \(\lambda^\star \ge 0\) tối thiểu hóa hàm mục tiêu sau đây cho nghiệm \(x^\star\) của (C), thì \(x^\star\) cũng là nghiệm của (L).&lt;/li&gt;
&lt;/ol&gt;

\[f(x) + \lambda \cdot (h(x) - t)\]

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;(L) đến (C):&lt;/strong&gt; Nếu \(x^\star\) là nghiệm của (L) và (C) với \(t = h(x^\star)\) thỏa mãn các điều kiện KKT, thì \(x^\star\) cũng là nghiệm của (C). Điều này là vì \(\lambda^\star, x^\star\) thỏa mãn các điều kiện KKT của (L) cũng thỏa mãn các điều kiện KKT của (C) với \(t = h(x^\star)\).&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;\(\rightarrow\) (L)의 KKT conditions:&lt;/strong&gt;&lt;/p&gt;

\[\begin{align}
\nabla_x f(x^\star) + \lambda^\star \nabla_x h(x^\star) &amp;amp;= 0\\\\
\lambda^\star &amp;amp;\ge 0\\\\
\end{align}\]

  &lt;p&gt;&lt;strong&gt;\(\rightarrow\) \(t = h(x^\star)\)인 (C)의 KKT conditions:&lt;/strong&gt;&lt;/p&gt;

\[\begin{align}
\nabla_x f(x^\star) + \lambda^\star \nabla_x h(x^\star) &amp;amp;= 0\\\\
\lambda^\star &amp;amp;\ge 0\\\\
\lambda^\star (\underbrace{h(x^\star) - h(x^\star)}_{=0}) &amp;amp;= 0
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Tóm lại, 1 và 2 lần lượt cho thấy các mối quan hệ sau.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter12/conclusion.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Kết luận [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Vậy, trong những hoàn cảnh nào (C) và (L) thể hiện sự tương đương hoàn hảo?&lt;br /&gt;
Ví dụ, khi \(h(x) \ge 0\) (như chuẩn), \(t = 0\), và \(\lambda = \infty\), sự tương đương hoàn hảo được thể hiện. Do các điều kiện đã cho, ràng buộc trong (C) trở thành \(h(x) = 0\), và bằng cách đặt \(\lambda\) thành \(\infty\), (L) cũng áp đặt cùng một ràng buộc (\(h(x) = 0\)).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>12-04 Ví dụ máy vector hỗ trợ</title>
   <link href="http://localhost:4000/contents/vi/chapter12/12_04_Example_support_vector_machines/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter12/12_04_Example_support_vector_machines</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Bài toán máy vector hỗ trợ cho các tập không tách được như sau.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{\beta, \beta-0, \xi} &amp;amp;&amp;amp;{\frac{1}{2} \rVert\beta\rVert_2^2 + C\sum_{i=1}^n \xi_i} \\\\
   &amp;amp;\text{với điều kiện} &amp;amp;&amp;amp;{\xi_i \ge 0, \quad i = 1, \dots, n}\\\\
   &amp;amp; &amp;amp;&amp;amp; y_i (x_i^T \beta + \beta-0) \ge 1 - \xi_i, \quad i = 1, \dots, n,\\\\
&amp;amp;&amp;amp;&amp;amp;\text{cho trước } y \in \{-1, 1\}^n \text{ và } X \in \mathbb{R}^{n \times p}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Khi các nhân tử Lagrange cho hai ràng buộc bất đẳng thức của bài toán đã cho lần lượt là \(v^\star, w^\star \geq 0\), hàm Lagrangian như sau.&lt;/p&gt;
&lt;blockquote&gt;
\[L(\beta, \beta-0, \xi, v^\star, w^\star) = \frac{1}{2} \rVert\beta\rVert_2^2 + C\sum_{i=1}^n \xi_i - \sum_{i=1}^n v_i^\star \xi_i + \sum_{i=1}^n w_i^\star (1 - \xi_i - y_i ( x_i^T \beta + \beta_0))\]
&lt;/blockquote&gt;

&lt;p&gt;Sử dụng hàm Lagrangian ở trên, chúng ta có thể tìm các điều kiện sau đây làm cho bài toán này thỏa mãn điều kiện tính dừng KKT. (Suy ra các điều kiện mà hàm Lagrangian trở thành 0 khi đạo hàm theo \(\beta, \beta_0, \xi\) tương ứng)&lt;/p&gt;
&lt;blockquote&gt;
\[0 = \sum_{i=1}^n w_i^\star y_i, \quad \beta = \sum_{i=1}^n w_i^\star y_i x_i, \quad w^\star = C \cdot 1 - v^\star\]
&lt;/blockquote&gt;

&lt;p&gt;Cũng vậy, bù yếu cho hai ràng buộc bất đẳng thức như sau.&lt;/p&gt;
&lt;blockquote&gt;
\[v_i^\star \xi_i = 0, \quad w_i^\star (1 - \xi_i - y_i (x_i^T \beta + \beta-0)) =0, \quad i = 1, \dots, n.\]
&lt;/blockquote&gt;

&lt;p&gt;Tức là, tại điểm tối ưu, \(\beta^\star = \sum_{i=1}^n w_i^\star y_i x_i\) được thỏa mãn, và khi \(y_i (x_i^T \beta^\star + \beta-0^\star) = 1 - \xi_i^\star\), \(w_i^\star\) trở thành khác không, và điểm i như vậy được gọi là &lt;strong&gt;điểm hỗ trợ&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Đối với điểm hỗ trợ i mà \(\xi_i^\star = 0\), \(x_i\) nằm trên siêu phẳng và \(w_i^\star \in (0, C]\).&lt;/li&gt;
  &lt;li&gt;Đối với điểm hỗ trợ i mà \(\xi_i^\star \neq 0\), \(x_i\) nằm ở phía đối diện của siêu phẳng và \(w_i^\star = C\).&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter12/svm.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$ \text{[Fig1] Illustration of support points with }\ \xi^\star \neq 0 \text{ [3]}$$ &lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Trước khi tối ưu hóa bài toán SVM, chúng ta có thể sử dụng phương pháp trên để lọc ra các điểm không hỗ trợ (bằng cách lọc ra các điểm không hỗ trợ, chúng ta có thể tăng hiệu quả tính toán). Thực tế, các điều kiện KKT không đóng vai trò trực tiếp trong việc đưa ra nghiệm của bài toán này, nhưng chúng ta có thể thu được trực giác để hiểu rõ hơn về bài toán SVM thông qua chúng [3].&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>12-03 Ví dụ thuật toán water-filling</title>
   <link href="http://localhost:4000/contents/vi/chapter12/12_03_Example_water_filling/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter12/12_03_Example_water_filling</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Giả sử chúng ta có bài toán tối ưu hóa lồi sau đây.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp;{- \sum_{i=1}^n \log(\alpha_i + x_i)} \\\\
   &amp;amp;\text{với điều kiện} &amp;amp;&amp;amp;{x \succeq 0, 1^Tx = 1},\\\\
&amp;amp;\text{trong đó } \alpha_i &amp;gt; 0.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán này liên quan đến việc phân bổ công suất cho n kênh truyền thông và xuất hiện trong lý thuyết thông tin. Biến \(x_i\) biểu diễn công suất đầu ra của máy phát được phân bổ cho kênh thứ i, và \(\log(\alpha_i + x_i)\) biểu diễn dung lượng hoặc tốc độ truyền thông của kênh đó. Tức là, bài toán này là xác định bao nhiêu công suất nên được phân bổ cho mỗi kênh để tối đa hóa tổng tốc độ truyền thông [1].&lt;/p&gt;

&lt;p&gt;Gọi các nhân tử Lagrange cho ràng buộc bất đẳng thức \(x^\star \succeq 0\) và ràng buộc đẳng thức \(1^Tx^\star = 1\) lần lượt là \(\lambda^\star \in \mathbb{R}^n\) và \(\nu^\star \in \mathbb{R}\). Các điều kiện KKT cho bài toán đã cho như sau.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^\star \succeq 0, \\\\
1^Tx^\star = 1, \\\\
\lambda^\star \succeq 0, \\\\
\lambda_i^\star x_i^\star = 0, \text{    } i = 1, \dots, n, \\\\
-1 / (\alpha_i + x_i^\star) - \lambda_i^\star + \nu^\star = 0,  \text{    } i= 1, \dots, n.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Sử dụng các phương trình thu được từ các điều kiện KKT, chúng ta có thể tìm \(x^\star, \lambda^\star, \nu^\star\) một cách giải tích. Đầu tiên, chúng ta loại bỏ \(\lambda^\star\) khỏi các phương trình bằng cách sử dụng nó như một biến slack.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^\star \succeq 0, \\\\
1^Tx^\star = 1, \\\\
x_i^\star(\nu^\star - 1 / (\alpha_i + x_i^\star)) = 0, \text{    } i = 1, \dots, n, \\\\
\nu^\star \ge 1/(\alpha_i + x_i^\star),  \text{    } i= 1, \dots, n.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này được sắp xếp như sau bởi tính dừng và bù yếu.&lt;/p&gt;
&lt;blockquote&gt;
\[x_i^\star = 
\begin{cases}
1 / \nu^\star - \alpha_i &amp;amp;\nu^\star &amp;lt; 1/\alpha_i \ \\\\
0 &amp;amp;\nu^\star \ge 1/\alpha_i\\\\
\end{cases}
= \max\{0, 1/\nu^\star - \alpha_i \}, \quad i = 1, \dots, n.\]
&lt;/blockquote&gt;

&lt;p&gt;Cũng vậy, theo điều kiện \(1^T x^\star = 1\), \(x_i^\star, i = 1, \dots, n\) có tổng bằng 1.&lt;/p&gt;
&lt;blockquote&gt;
\[\sum_{i=1}^n \max\{0, 1/\nu^\star - \alpha_i \} = 1.\]
&lt;/blockquote&gt;

&lt;p&gt;Vế trái của phương trình là một hàm tuyến tính từng khoảng tăng của \(1/\nu^\star\), vì vậy phương trình này có một nghiệm duy nhất cho \(\alpha_i\) cố định.&lt;/p&gt;

&lt;p&gt;Phương pháp giải này được gọi là water-filling (đổ nước). Khi \(\alpha_i\) là mức độ nền cho vùng \(i\), bài toán này có thể được nghĩ như việc đổ nước vào mỗi vùng sao cho mực nước trở thành \(1/\nu^\star\) như được hiển thị trong hình dưới đây. Chúng ta đổ nước cho đến khi tổng lượng nước trở thành 1.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter12/water-fill.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Minh họa thuật toán water-filling [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>12-02 Ví dụ bài toán bậc hai với ràng buộc đẳng thức</title>
   <link href="http://localhost:4000/contents/vi/chapter12/12_02_Example_quadratic_with_equality_constraints/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter12/12_02_Example_quadratic_with_equality_constraints</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Một &lt;a href=&quot;&quot;&gt;chương trình bậc hai&lt;/a&gt; chỉ với các ràng buộc đẳng thức như sau.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp;{(1/2)x^T P x + q^T x + r} \\\\
   &amp;amp;\text{với điều kiện} &amp;amp;&amp;amp;{Ax = b},\\\\
&amp;amp;\text{trong đó } &amp;amp;&amp;amp;P \in \mathbb{S}_{+}^n \text{ và } A \in \mathbb{R}^{\text{p x n}}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán này là lồi và không có ràng buộc bất đẳng thức, vì vậy nó thỏa mãn điều kiện Slater (Tính đối ngẫu mạnh). Nếu các nghiệm nguyên thủy &amp;amp; đối ngẫu là \(x^\star, \nu^\star\), thì theo các điều kiện KKT, chúng thỏa mãn các điều kiện sau [1].&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tính dừng: \(Px^\star + q + A^T\nu^\star = 0\)&lt;/li&gt;
  &lt;li&gt;Bù yếu: Vì không có ràng buộc bất đẳng thức, điều này không cần được xem xét.&lt;/li&gt;
  &lt;li&gt;Tính khả thi nguyên thủy &amp;amp; đối ngẫu: \(Ax^\star = b\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Những điều kiện này có thể được biểu diễn một cách ngắn gọn bằng cách sử dụng ma trận khối, được gọi là ma trận KKT [3].&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{bmatrix}
    P       &amp;amp; A^T  \\\\
    A       &amp;amp; 0  \\\\
\end{bmatrix}
\begin{bmatrix}
    x^\star  \\\\
    \nu^\star  \\\\
\end{bmatrix}
=
\begin{bmatrix}
    -q  \\\\
    b  \\\\
\end{bmatrix}\]
&lt;/blockquote&gt;

&lt;p&gt;Giải phương trình ma trận này cho ta các nghiệm nguyên thủy &amp;amp; đối ngẫu cho bài toán đã cho.&lt;/p&gt;

&lt;p&gt;Một sự thật thú vị là bài toán này cũng có thể được xem như việc tính toán bước Newton cho một bài toán có ràng buộc đẳng thức [3]. Đối với bài toán \(min_x f(x) \text{ với điều kiện } Ax = b\), nếu chúng ta đặt P, q, r như sau, thì hàm mục tiêu của chương trình bậc hai trở nên giống hệt với khai triển Taylor bậc hai của \(f(x)\).&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(P = \nabla^2 f(x^{(k-1)})\), \(q = \nabla f(x^{(k-1)})\), \(r = f(x^{(k-1)})\)&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>12-01 Điều kiện Karush-Kuhn-Tucker</title>
   <link href="http://localhost:4000/contents/vi/chapter12/12_01_Karush_Kuhn_Tucker_conditions/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter12/12_01_Karush_Kuhn_Tucker_conditions</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Hãy xem xét bài toán tối ưu hóa tổng quát sau đây.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp;{f(x)} \\\\
   &amp;amp;\text{với điều kiện } &amp;amp;&amp;amp;{h_i(x) \le 0, \text{ } i=1,\dots,m} \\\\
   &amp;amp; &amp;amp;&amp;amp;{l_j(x) = 0, \text{ } j=1,\dots,r}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Điều kiện Karush–Kuhn–Tucker (KKT)&lt;/strong&gt; hoặc &lt;strong&gt;điều kiện KKT&lt;/strong&gt; bao gồm các điều kiện sau [3].&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(0 \in \partial \big( f(x) + \sum_{i=1}^{m} \lambda_i h_i(x) + \sum_{j=1}^{r} \nu_j l_j(x) \big)\) (Tính dừng): Khi \(\lambda, \nu\) được cố định, subdifferential theo \(x\) chứa 0.&lt;/li&gt;
  &lt;li&gt;\(\lambda_i \cdot h_i(x) = 0 \text{ với mọi } i\) (Bù yếu): Ít nhất một trong \(\lambda_i\) và \(h_i\) có giá trị 0.&lt;/li&gt;
  &lt;li&gt;\(h_i(x) \le 0, l_j(x) = 0 \text{ với mọi } i, j\) (Tính khả thi Nguyên thủy): Chỉ ra liệu các ràng buộc của bài toán nguyên thủy có được thỏa mãn hay không.&lt;/li&gt;
  &lt;li&gt;\(\lambda_i \ge 0 \text{ với mọi } i\) (Tính khả thi Đối ngẫu): Chỉ ra liệu các ràng buộc của bài toán đối ngẫu có được thỏa mãn hay không.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tính-đủ&quot;&gt;Tính đủ&lt;/h2&gt;
&lt;p&gt;Đối với một bài toán nguyên thủy lồi, khi tồn tại \(x^\star, \lambda^\star, \nu^\star\) thỏa mãn các điều kiện KKT, quá trình sau đây chỉ ra rằng \(x^\star, \lambda^\star, \nu^\star\) là nghiệm nguyên thủy &amp;amp; đối ngẫu với độ lệch đối ngẫu bằng không.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   g(\lambda^\star, \nu^\star) &amp;amp;= \min_x L(x, \lambda^\star, \nu^\star) \\\\
                               &amp;amp;= L(x^\star, \lambda^\star, \nu^\star) \\\\
                               &amp;amp;= f(x^\star) + \sum_{i=1}^m \lambda_i^\star h_i(x^\star) + \sum_{j=1}^r \nu_j^\star l_j(x^\star) \\\\
                               &amp;amp;= f(x^\star)
\end{align}\]
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;\(L(x,\lambda^\star,\nu^\star) = f(x) + \sum_{i=1}^{m} \lambda_i^\star h_i(x) + \sum_{j=1}^{r} \nu_j^\star l_j(x)\) là một hàm lồi. (tổng của các hàm lồi)&lt;/li&gt;
  &lt;li&gt;\(0 \in \partial \big( f(x^\star) + \sum_{i=1}^{m} \lambda_i^\star h_i(x^\star) + \sum_{j=1}^{r} \nu_j^\star l_j(x^\star) \big)\) do đó \(\min_x L(x, \lambda^\star, \nu^\star) = L(x^\star, \lambda^\star, \nu^\star)\).&lt;/li&gt;
  &lt;li&gt;Bởi bù yếu và tính khả thi nguyên thủy, \(f(x^\star) + \sum_{i=1}^m \lambda_i^\star h_i(x^\star) + \sum_{j=1}^r \nu_j^\star l_j(x^\star) = f(x^\star)\).&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;tính-cần-thiết&quot;&gt;Tính cần thiết&lt;/h2&gt;
&lt;p&gt;Khi \(x^\star, \lambda^\star, \nu^\star\) là nghiệm nguyên thủy &amp;amp; đối ngẫu với độ lệch đối ngẫu bằng không (ví dụ, thỏa mãn điều kiện Slater), tất cả các bất đẳng thức dưới đây trở thành đẳng thức, vì vậy trong bài toán này \(x^\star, \lambda^\star, \nu^\star\) thỏa mãn các điều kiện KKT.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   f(x^\star) &amp;amp;= g(\lambda^\star, \nu^\star) \\\\
                  &amp;amp;= \min_x  \big( f(x) + \sum_{i=1}^{m} \lambda_i^\star h_i(x) + \sum_{j=1}^{r} \nu_j^\star l_j(x) \big) \\\\
                  &amp;amp;\le f(x^\star) + \sum_{i=1}^m \lambda_i^\star h_i(x^\star) + \sum_{j=1}^r \nu_j^\star l_j(x^\star) \\\\
                  &amp;amp;\le f(x^\star)
\end{align}\]
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;\(f(x^\star) = g(\lambda^\star, \nu^\star)\) có nghĩa là độ lệch đối ngẫu bằng không.&lt;/li&gt;
  &lt;li&gt;Để thỏa mãn \(f(x^\star) + \sum_{i=1}^m \underbrace{\lambda_i^\star h_i(x^\star)}_{0} + \sum_{j=1}^r \underbrace{\nu_j^\star l_j(x^\star)}_{0} = f(x^\star)\), bù yếu và tính khả thi nguyên thủy phải được thỏa mãn.&lt;/li&gt;
  &lt;li&gt;Nếu \(f(x^\star) + \sum_{i=1}^m \lambda_i^\star h_i(x^\star) + \sum_{j=1}^r \nu_j^\star l_j(x^\star) = f(x^\star)\) được thỏa mãn, tất cả các bất đẳng thức trong suy dẫn trên trở thành đẳng thức.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;tổng-hợp&quot;&gt;Tổng hợp&lt;/h2&gt;
&lt;p&gt;Tóm lại, các điều kiện KKT là:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Điều kiện đủ cho nghiệm nguyên thủy &amp;amp; đối ngẫu với độ lệch đối ngẫu bằng không.&lt;/li&gt;
  &lt;li&gt;Nếu tính đối ngẫu mạnh được giữ, chúng trở thành điều kiện cần thiết cho nghiệm nguyên thủy &amp;amp; đối ngẫu.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tức là, đối với các bài toán thỏa mãn tính đối ngẫu mạnh, mối quan hệ sau được giữ.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   x^\star, \lambda^\star, \nu^\star \text{ là nghiệm nguyên thủy và đối ngẫu} \\\\
   \Leftrightarrow x^\star, \lambda^\star, \nu^\star \text{ thỏa mãn các điều kiện KKT} \\\\
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>12 KKT Conditions</title>
   <link href="http://localhost:4000/contents/vi/chapter12/12_00_KKT_conditions/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter12/12_00_KKT_conditions</id>
   <content type="html">&lt;p&gt;Khi bài toán nguyên thủy là lồi, các điều kiện Karush–Kuhn–Tucker (KKT) trở thành điều kiện đủ cho các điểm tối ưu nguyên thủy &amp;amp; đối ngẫu với độ lệch đối ngẫu bằng không. Ngoài ra, khi hàm mục tiêu và các hàm ràng buộc của bài toán nguyên thủy khả vi và thỏa mãn tính đối ngẫu mạnh, các điểm tối ưu nguyên thủy &amp;amp; đối ngẫu luôn thỏa mãn các điều kiện KKT. Các điều kiện KKT giữ một vị trí rất quan trọng trong tối ưu hóa. Những điều kiện này cho phép một số bài toán đặc biệt được giải một cách giải tích, và nhiều thuật toán tối ưu hóa lồi có thể được hiểu như các phương pháp để giải các điều kiện KKT [1]. Trong chương này, chúng ta sẽ tìm hiểu về định nghĩa và tính chất của các điều kiện KKT và xem xét một số ví dụ dựa trên chúng.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Như một ghi chú bên lề&lt;/em&gt;, các điều kiện KKT ban đầu được Harold W. Kuhn và Albert W. Tucker giới thiệu với thế giới vào năm 1951, và vào thời điểm đó chúng được gọi là điều kiện KT (Kuhn-Tucker). Sau đó, các học giả phát hiện ra rằng các điều kiện cần thiết cho bài toán này đã được William Karush đề cập trong luận văn thạc sĩ của ông vào năm 1939, và từ đó trở đi, tên của Karush được bao gồm và chúng được biết đến như các điều kiện KKT (Karush–Kuhn–Tucker) [3].&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>12-06 Uniqueness in L1 penalized problems</title>
   <link href="http://localhost:4000/contents/en/chapter12/12_06_Uniqueness_in_L1_penalized_problems/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter12/12_06_Uniqueness_in_L1_penalized_problems</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;The following \(L1\) penalized linear regression problem is also well known as the lasso problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;&amp;amp;&amp;amp;\hat{\beta} \in \text{argmin}_{\beta \in \mathbb{R}^p} \frac{1}{2} \| y - X\beta \|^2_2 + \lambda \|\beta\|_1, \qquad \\\\
&amp;amp;&amp;amp; \text{ --- (1) } &amp;amp;\text{given } y \in \mathbb{R}^n, \\\\
&amp;amp;&amp;amp;&amp;amp; \text{ a matrix } X \in \mathbb{R}^{n \text{ x } p} \ \text{ of predictor variables,} \\\\
&amp;amp;&amp;amp;&amp;amp; \text{and a tuning parameter} \lambda \ge 0.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The above Lasso problem has a unique solution when it is strictly convex, i.e., when \(rank(X) = p\). On the other hand, when \(rank(X) &amp;lt; p\) (when it is not strictly convex), it may have infinitely many solutions (Reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Underdetermined_system&quot;&gt;Underdetermined system&lt;/a&gt;). - Note that if the number of variables (p) is greater than the number of observations (n), then \(rank(X)\) is necessarily less than p.&lt;br /&gt;
Interestingly, in some special cases, the Lasso problem is guaranteed to have a unique solution regardless of the dimension of \(X\) [13].&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Theorem:&lt;/strong&gt; When the function \(f\) is differentiable and strictly convex, \(\lambda &amp;gt; 0\), and \(X \in \mathbb{R}^{n \times p}\) follows some continuous probability distribution on \(\mathbb{R}^{np}\), the following optimization problem always has a unique solution. Moreover, the solution consists of at most \(min\{n,p\}\) nonzero components. There are no restrictions on the dimension of \(X\). (That is, it is valid even when p » n)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;basic-facts-and-the-kkt-conditions&quot;&gt;Basic facts and the KKT conditions&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lemma 1.&lt;/strong&gt; For arbitrary \(y, X, \lambda \ge 0\), the lasso problem (1) has the following properties.&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;It has either a unique solution or infinitely many solutions.&lt;/li&gt;
    &lt;li&gt;All lasso solutions \(\hat{\beta}\) have the same \(X\hat{\beta}\) value.&lt;/li&gt;
    &lt;li&gt;When \(\lambda &amp;gt; 0\), all lasso solutions \(\hat{\beta}\) have the same \(l_1\) norm (\(\|\hat{\beta}\|_1\)).&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

\[\text{ }\]

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;If (1) has two solutions \(\hat{\beta}^{(1)}\), \(\hat{\beta}^{(2)}\), then for any \(0 &amp;lt; \alpha &amp;lt; 1\), \(\alpha \hat{\beta}^{(1)} + (1 - \alpha) \hat{\beta}^{(2)}\) is also a solution, so infinitely many solutions exist.&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;&amp;amp; 3. Suppose there are two solutions \(\hat{\beta}^{(1)}\), \(\hat{\beta}^{(2)}\). Let the optimal value be \(c^\star\). Then for any solution \(\alpha \hat{\beta}^{(1)} + (1 - \alpha) \hat{\beta}^{(2)}\) (\(0 &amp;lt; \alpha &amp;lt; 1\)), the following equality must always hold.&lt;/li&gt;
  &lt;/ol&gt;

\[\begin{align}
&amp;amp;\frac{1}{2} \| y - X(\alpha \hat{\beta}^{(1)} + (1 - \alpha) \hat{\beta}^{(2)}) \|_2^2 + \lambda \| \alpha \hat{\beta}^{(1)} + (1 - \alpha) \hat{\beta}^{(2)} \|_1 \\
&amp;amp; = \alpha c^\star + (1-\alpha) c^\star = c^\star
\end{align}\]

  &lt;p&gt;To satisfy this equality, \(X\hat{\beta}\) must always have the same value for any solution \(\hat{\beta}\), and when \(\lambda &amp;gt; 0\), \(\|\hat{\beta}\|_1\) must also always be the same.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Returning to the beginning, the KKT conditions for the lasso problem (1) are as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;&amp;amp;X^T (y - X\hat{\beta}) = \lambda \gamma, \qquad \text{ --- (2)} \\\\
&amp;amp;&amp;amp;\gamma_i \in 
\begin{cases}
\{ sign(\hat{\beta_i}) \} &amp;amp; if \hat{\beta_i} \neq 0 \\\\
[-1, 1] &amp;amp; if \hat{\beta_i} = 0,
\end{cases} \\\\
&amp;amp;&amp;amp;\text{for } i = 1, \dots, p. \text{ --- (3)} \\\\
&amp;amp;&amp;amp;\text{Here } \gamma \in \mathbb{R}^p \text{ is called a subgradient of the function } \\
&amp;amp;&amp;amp;f(x) = \| x \|_1 \text{ evaluated at } x = \hat{\beta}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;즉, (1)의 solution인 \(\hat{\beta}\)는 어떤 \(\gamma\)에 대해 (2) 와 (3)을 만족한다.&lt;/p&gt;

&lt;p&gt;위에서 얻은 KKT conditions를 이용하여 lasso solution에 대한 조건을 좀 더 명시적인 형태로 변환해보도록 하자. 이후의 진행에서는 유도의 간결함을 위해 \(\lambda &amp;gt; 0\)를 가정하도록 한다. 우선 equicorrelation set \(\mathcal{E}\)을 다음과 같이 정의한다. \(\mathcal{E}\)는 \(\hat{\beta}_i \neq 0\)인 모든 인덱스 \(i\)와 \(\hat{\beta}_j = 0\)이면서 \(\vert\gamma_j\vert = 1\)인 모든 인덱스 \(j\)를 원소로 가진 집합이다.&lt;/p&gt;

\[\mathcal{E} = \{ i \in \{1, \dots, p \}  : \vert X_i^T (y - X\hat{\beta}) \vert = \lambda \}. \qquad \text{ --- (4)}\]

&lt;p&gt;또한 equicorrelation sign \(s\)를 다음과 같이 정의한다. 여기서 \(X_\mathcal{E}\)는 행렬 X에서 \(i \in \mathcal{E}\)인 column \(i\) 외의 모든 column을 0 벡터로 교체한 행렬을 의미한다.&lt;/p&gt;

\[s = sign(X^T_\mathcal{E} (y -X\hat{\beta}). \qquad \text{ --- (5)}\]

&lt;p&gt;여기서 \(\mathcal{E}, s\)는 \(\gamma\)에 대해 다음과 같이 표현할 수 있다: \(\mathcal{E} = \{i \in \{1, \dots, p \} : \vert \gamma_i \vert = 1 \}\) and \(s = \gamma_{\mathcal{E}}\). 또한 Lemma1-2에 의해 \(X\hat{\beta}\)는 유일한 값을 가지므로 이는 \(\mathcal{E}\), \(s\)이 유일함을 암시한다.&lt;/p&gt;

&lt;p&gt;(3)의 subgradient \(\gamma\)에 대한 정의에 의해 모든 lasso solution \(\hat{\beta}\)에 대해 \(\hat{\beta}_{-\mathcal{E}} = 0\)임을 알 수 있다. 그러므로 (2)를 \(\mathcal{E}\) 블록에 대해 표현하면 다음과 같다.&lt;/p&gt;

\[X^T_\mathcal{E} ( y - X_\mathcal{E} \hat{\beta_\mathcal{E}} ) = \lambda \gamma_\mathcal{E}=  \lambda s. \qquad \text{ --- (6)}\]

&lt;p&gt;(6)의 양변에 \(X^T_\mathcal{E} (X^T_\mathcal{E})^+\)를 곱하면 다음과 같이 정리된다 (\((X^T_\mathcal{E})^+\)는 \(X^T_\mathcal{E}\)의 pseudoinverse matrix).&lt;/p&gt;

\[\begin{align}
&amp;amp; X^T_\mathcal{E} X_\mathcal{E} \hat{\beta_\mathcal{E}} = X^T_\mathcal{E} ( y - (X^T_\mathcal{E})^+  \lambda s) \\\\
\Leftrightarrow
&amp;amp; X_\mathcal{E} \hat{\beta_\mathcal{E}} = X^T_\mathcal{E} (X^T_\mathcal{E})^+ ( y - (X^T_\mathcal{E})^+  \lambda s).
\end{align}\]

&lt;p&gt;\(X\hat{\beta} = X_\mathcal{E} \hat{\beta_\mathcal{E}}\)이므로 위 등식은 곧 아래와 같다.&lt;/p&gt;

\[X \hat{\beta} = X^T_\mathcal{E} (X^T_\mathcal{E})^+ ( y - (X^T_\mathcal{E})^+  \lambda s), \qquad \text{ --- (7)}\]

&lt;p&gt;그리고 임의의 lasso solution \(\hat{\beta}\)는 다음과 같다.&lt;/p&gt;

\[\begin{align}
&amp;amp; \hat{\beta_{-\mathcal{E}}} = 0 \text{ and } \hat{\beta_{\mathcal{E}}} = (X^T_\mathcal{E})^+ ( y - (X^T_\mathcal{E}) + b, \qquad \text{ --- (8)} \\\\
&amp;amp; \text{where } b \in null(X_\mathcal{E}).
\end{align}\]

&lt;h2 id=&quot;sufficient-conditions-for-uniqueness&quot;&gt;Sufficient conditions for uniqueness&lt;/h2&gt;

&lt;p&gt;(8)의 \(\hat{\beta_{\mathcal{E}}}\)의 유일함이 보장되기 위해서는 \(b=0\)이 되어야 한다 ( \((X^T_\mathcal{E})^+ ( y - (X^T_\mathcal{E})\)은 유일하기 때문에). \(b=0\)이어야 함을 주지하고 (8)의 등식을 변형하면 다음의 결론을 얻게 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lemma 2.&lt;/strong&gt; 임의의 \(y, X, \lambda &amp;gt; 0\)에 대해, 만약 \(null(X_\mathcal{E}) = {0}\), 또는 \(rank(X_\mathcal{E}) = \vert\mathcal{E}\vert\) (&lt;a href=&quot;https://www.quora.com/When-the-null-space-of-a-matrix-is-the-zero-vector-the-matrix-is-in\vertible-Why/answer/Alexander-Farrugia&quot;&gt;참고&lt;/a&gt;),이면 lasso solution은 유일(unique)해지며, 이는 곧 다음과도 같다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;&amp;amp; \hat{\beta_{-\mathcal{E}}} = 0 \text{ and } \hat{\beta_{\mathcal{E}}} = (X^T_\mathcal{E}X^T_\mathcal{E})^{-1} ( X^T_\mathcal{E} y - \lambda s), \qquad \text{ --- (9)} \\\\
&amp;amp;&amp;amp; \text{where } \mathcal{E} \text{ and } s \text{ are the equicorrelation set and signs as defined in (4) and (5)}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;참고로 이 solution은 많아 봐야 \(min\{n, p\}\)의 nonzero components로 구성된다.&lt;/p&gt;

&lt;p&gt;그렇다면 \(null(X_\mathcal{E}) = {0}\)을 암시하는 (\(X\)에 대한) 좀 더 자연스러운 조건에 대해 알아보도록 하자. 이를 알아보기에 앞서 우선 \(null(X_\mathcal{E}) \neq {0}\)이라 가정해보겠다. 이 경우, 어떤 \(i \in \mathcal{E}\)에 대해 다음과 같은 등식을 만족한다.&lt;/p&gt;

\[X_i = \sum_{j \in \mathcal{E} \backslash \{i\} } c_j X_j,\\\\
\text{where } c_j \in \mathbb{R}, j \in \mathcal{E}.\]

&lt;p&gt;위 등식의 양변에 \(s_i\)를 곱해주고, 우항에 \(s_j s_j = 1\)을 곱해준다.&lt;/p&gt;

\[s_i X_i = \sum_{j \in \mathcal{E} \backslash \{i\} } (s_i s_j c_j) \cdot (s_j X_j). \qquad \text{ --- (10)}\]

&lt;p&gt;\(r = y - X \hat{\beta}\)로 r(lasso residual)을 정의하면 임의의 \(j \in \mathcal{E}\)에 대해 \(X_j^T r = s_j \lambda\)를 만족한다. r을 위 (10)의 양변에 곱해주면 \(\lambda\)에 대한 부등식을 얻을 수 있다. (\(\lambda &amp;gt; 0\)이라 가정)&lt;/p&gt;

\[\lambda = \sum_{j \in \mathcal{E} \backslash \{i\} } (s_i s_j c_j) \lambda \quad \text{ and } \quad \sum_{j \in \mathcal{E} \backslash \{i\} } (s_i s_j c_j) = 1.\]

&lt;p&gt;즉, \(null(X_\mathcal{E}) \neq {0}\)이면, 어떤 \(i \in \mathcal{E}\)에 대해 다음 등식이 성립한다.&lt;/p&gt;

\[s_iX_i = \sum_{j \in \mathcal{E} \backslash \{i\} } a_j \cdot s_j X_j, \text{ with } \sum_{j \in \mathcal{E} \backslash \{i\} } a_j = 1.\]

&lt;p&gt;위 등식은 \(s_iX_i\)이 \(s_j X_j, j \in \mathcal{E} \backslash \{i\}\)의 affine span 위에 존재한다는 의미와도 같다. 또한 이는 어떤 k+2개의 원소를 포함한 subset으로는 최대 k dimensional affine space만을 표현할 수 있다는 것과도 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter12/l1_uniqueness.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] 4 elements on 2-dimensional affine space [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;우리가 원하는 것은 행렬 \(X \in \mathbb{R}^{n \text{ x } p}\)가 \(null(X_\mathcal{E}) = {0}\)을 만족하는 것이며, 이는 곧 행렬 \(X\)의 column들이 &lt;a href=&quot;https://en.wikipedia.org/wiki/General_position&quot;&gt;general position&lt;/a&gt;에 있는 것과도 같다. 바꿔말하면, 그 어떤 k-dimensional affine subspace도 set 안의 k+1개보다 더 많은 element를 포함하지 않는다는 것이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lemma 3.&lt;/strong&gt; 만약 행렬 \(X\)의 column들이 general position에 있으면, 임의의 \(y\)와 \(\lambda &amp;gt; 0\)에 대한 lasso solution은 유일(unique)하며 또한 이 solution은 (9)를 만족한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그렇다면 어떤 행렬 \(X\)가 항상 위 조건을 만족할 수 있을까? 결론부터 말하자면 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lemma 4.&lt;/strong&gt; 행렬 \(X \in \mathbb{R}^{n \text{ x } p}\)의 모든 원소가 \(\mathbb{R}^{np}\) 상의 continuous probability distribution을 따른다면, 임의의 \(y\)와 \(\lambda &amp;gt; 0\)에 대해 lasso solution은 unique하고 항상 (9)를 만족한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;왜냐하면 continuous probability distribution을 따를때, 모든 column vector들은 linearly independent하기 때문이다. (&lt;a href=&quot;https://math.stackexchange.com/questions/432447/probability-that-n-vectors-drawn-randomly-from-mathbbrn-are-linearly-ind?rq=1&quot;&gt;참고&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&quot;general-convex-loss-functions&quot;&gt;General convex loss functions&lt;/h2&gt;

&lt;p&gt;좀 더 일반적인 lasso problem에 대해서도 같은 내용을 적용할 수 있다 [13].&lt;/p&gt;

\[\hat{\beta} \in \text{argmin}_{\beta \in \mathbb{R}^p} f(X\beta) + \lambda \|\beta\|_1, \qquad \text{ --- (11) }\]

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lemma 5.&lt;/strong&gt; 만약 행렬 \(X \in \mathbb{R}^{n \text{ x } p}\)의 모든 원소가 \(\mathbb{R}^{np}\) 상의 continuous probability distribution을 따를때, 미분 가능하고 strictly convex인 임의의 함수 \(f\)는 임의의 \(\lambda &amp;gt; 0\)에 대해 (11)의 문제에서 항상 유일(unique)한 solution을 보장한다. 이 solution은 많아봐야 \(min\{n,p\}\)개의 nonzero components로 구성된다.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>12-05 Constrained and Lagrange forms</title>
   <link href="http://localhost:4000/contents/en/chapter12/12_05_Constrained_and_Lagrange_forms/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter12/12_05_Constrained_and_Lagrange_forms</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In statistics and machine learning, we often move between &lt;strong&gt;constrained form&lt;/strong&gt; and &lt;strong&gt;Lagrange form&lt;/strong&gt;. Let us define the constrained form and Lagrangian form as follows.&lt;/p&gt;

&lt;h3 id=&quot;constrained-form-c-hereafter&quot;&gt;Constrained Form ((C) hereafter)&lt;/h3&gt;
&lt;blockquote&gt;
\[\min_x \: f(x) \quad \text{ subject to } h(x) \le t,\\\\
\text{where } t \in \mathbb{R} \text{ is a tuning parameter.}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;lagrange-form-l-hereafter&quot;&gt;Lagrange Form ((L) hereafter)&lt;/h3&gt;
&lt;blockquote&gt;
\[\min_x \: f(x) + \lambda \cdot h(x),\\\\
\text{where } \lambda \ge 0 \text{ is a tuning parameter.}\]
&lt;/blockquote&gt;

&lt;p&gt;When \(f, h\) are convex, let us examine the cases where the two problems yield the same solution.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;(C) to (L):&lt;/strong&gt; When (C) is strictly feasible (satisfies Slater’s condition) and satisfies strong duality, if there exists a dual solution \(\lambda^\star \ge 0\) that minimizes the following objective function for the solution \(x^\star\) of (C), then \(x^\star\) is also a solution of (L).&lt;/li&gt;
&lt;/ol&gt;

\[f(x) + \lambda \cdot (h(x) - t)\]

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;(L) to (C):&lt;/strong&gt; If \(x^\star\) is a solution of (L) and (C) with \(t = h(x^\star)\) satisfies the KKT conditions, then \(x^\star\) is also a solution of (C). This is because \(\lambda^\star, x^\star\) that satisfy the KKT conditions of (L) also satisfy the KKT conditions of (C) with \(t = h(x^\star)\).&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;\(\rightarrow\) (L)의 KKT conditions:&lt;/strong&gt;&lt;/p&gt;

\[\begin{align}
\nabla_x f(x^\star) + \lambda^\star \nabla_x h(x^\star) &amp;amp;= 0\\\\
\lambda^\star &amp;amp;\ge 0\\\\
\end{align}\]

  &lt;p&gt;&lt;strong&gt;\(\rightarrow\) \(t = h(x^\star)\)인 (C)의 KKT conditions:&lt;/strong&gt;&lt;/p&gt;

\[\begin{align}
\nabla_x f(x^\star) + \lambda^\star \nabla_x h(x^\star) &amp;amp;= 0\\\\
\lambda^\star &amp;amp;\ge 0\\\\
\lambda^\star (\underbrace{h(x^\star) - h(x^\star)}_{=0}) &amp;amp;= 0
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In conclusion, 1 and 2 show the following relationships respectively.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter12/conclusion.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Conclusion [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;So, under what circumstances do (C) and (L) show perfect equivalence?&lt;br /&gt;
For example, when \(h(x) \ge 0\) (such as norm), \(t = 0\), and \(\lambda = \infty\), perfect equivalence is shown. Due to the given conditions, the constraint in (C) becomes \(h(x) = 0\), and by setting \(\lambda\) to \(\infty\), (L) also imposes the same constraint (\(h(x) = 0\)).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>12-04 Example support vector machines</title>
   <link href="http://localhost:4000/contents/en/chapter12/12_04_Example_support_vector_machines/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter12/12_04_Example_support_vector_machines</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;The support vector machine problem for non-separable sets is as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{\beta, \beta-0, \xi} &amp;amp;&amp;amp;{\frac{1}{2} \rVert\beta\rVert_2^2 + C\sum_{i=1}^n \xi_i} \\\\
   &amp;amp;\text{subject to} &amp;amp;&amp;amp;{\xi_i \ge 0, \quad i = 1, \dots, n}\\\\
   &amp;amp; &amp;amp;&amp;amp; y_i (x_i^T \beta + \beta-0) \ge 1 - \xi_i, \quad i = 1, \dots, n,\\\\
&amp;amp;&amp;amp;&amp;amp;\text{given } y \in \{-1, 1\}^n \text{ and } X \in \mathbb{R}^{n \times p}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;When the Lagrange multipliers for the two inequality constraints of the given problem are \(v^\star, w^\star \geq 0\) respectively, the Lagrangian function is as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[L(\beta, \beta-0, \xi, v^\star, w^\star) = \frac{1}{2} \rVert\beta\rVert_2^2 + C\sum_{i=1}^n \xi_i - \sum_{i=1}^n v_i^\star \xi_i + \sum_{i=1}^n w_i^\star (1 - \xi_i - y_i ( x_i^T \beta + \beta_0))\]
&lt;/blockquote&gt;

&lt;p&gt;Using the above Lagrangian function, we can find the following conditions that make this problem satisfy the KKT stationarity condition. (Derive the conditions where the Lagrangian function becomes 0 when differentiated with respect to \(\beta, \beta_0, \xi\) respectively)&lt;/p&gt;
&lt;blockquote&gt;
\[0 = \sum_{i=1}^n w_i^\star y_i, \quad \beta = \sum_{i=1}^n w_i^\star y_i x_i, \quad w^\star = C \cdot 1 - v^\star\]
&lt;/blockquote&gt;

&lt;p&gt;Also, complementary slackness for the two inequality constraints is as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[v_i^\star \xi_i = 0, \quad w_i^\star (1 - \xi_i - y_i (x_i^T \beta + \beta-0)) =0, \quad 1 = 1, \dots, n.\]
&lt;/blockquote&gt;

&lt;p&gt;That is, at optimality, \(\beta^\star = \sum_{i=1}^n w_i^\star y_i x_i\) is satisfied, and when \(y_i (x_i^T \beta^\star + \beta-0^\star) = 1 - \xi_i^\star\), \(w_i^\star\) becomes nonzero, and such point i is called &lt;strong&gt;support points&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For a support point i where \(\xi_i^\star = 0\), \(x_i\) is located on the hyperplane and \(w_i^\star \in (0, C]\).&lt;/li&gt;
  &lt;li&gt;For a support point i where \(\xi_i^\star \neq 0\), \(x_i\) is located on the opposite side of the hyperplane and \(w_i^\star = C\).&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter12/svm.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$ \text{[Fig1] Illustration of support points with }\ \xi^\star \neq 0 \text{ [3]}$$ &lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;SVM문제를 최적화 하기 전, non-support points를 걸러내는데 위 방법을 이용할 수 있다 (non-support points를 걸러냄으로써 계산 효율을 높일 수 있다). 사실 KKT conditions는 이 문제의 solution을 도출하기 위한 직접적인 역할을 하지는 않지만, 우리는 이를 통해 SVM 문제를 더 잘 이해하기 위한 직관을 얻을 수 있다 [3].&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>12-03 Example water-filling</title>
   <link href="http://localhost:4000/contents/en/chapter12/12_03_Example_water_filling/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter12/12_03_Example_water_filling</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Suppose we have the following convex optimization problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp;{- \sum_{i=1}^n \log(\alpha_i + x_i)} \\\\
   &amp;amp;\text{subject to} &amp;amp;&amp;amp;{x \succeq 0, 1^Tx = 1},\\\\
&amp;amp;\text{where } \alpha_i &amp;gt; 0.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This problem is about allocating power to n communication channels and arose in information theory. The variable \(x_i\) represents the output of the transmitter allocated to the i-th channel, and \(\log(\alpha_i + x_i)\) represents the capacity or communication rate of that channel. That is, this problem is to determine how much power should be allocated to each channel to maximize the total communication rate [1].&lt;/p&gt;

&lt;p&gt;Let the Lagrange multipliers for the inequality constraint \(x^\star \succeq 0\) and equality constraint \(1^Tx^\star = 1\) be \(\lambda^\star \in \mathbb{R}^n\) and \(\nu^\star \in \mathbb{R}\) respectively. The KKT conditions for the given problem are as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^\star \succeq 0, \\\\
1^Tx^\star = 1, \\\\
\lambda^\star \succeq 0, \\\\
\lambda_i^\star x_i^\star = 0, \text{    } i = 1, \dots, n, \\\\
-1 / (\alpha_i + x_i^\star) - \lambda_i^\star + \nu^\star = 0,  \text{    } i= 1, \dots, n.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Using the equations obtained from KKT conditions, we can find \(x^\star, \lambda^\star, \nu^\star\) analytically. First, we eliminate \(\lambda^\star\) from the equations using it as a slack variable.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^\star \succeq 0, \\\\
1^Tx^\star = 1, \\\\
x_i^\star(\nu^\star - 1 / (\alpha_i + x_i^\star)) = 0, \text{    } i = 1, \dots, n, \\\\
\nu^\star \ge 1/(\alpha_i + x_i^\star),  \text{    } i= 1, \dots, n.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This is organized as follows by stationarity and complementary slackness.&lt;/p&gt;
&lt;blockquote&gt;
\[x_i^\star = 
\begin{cases}
1 / \nu^\star - \alpha_i &amp;amp;\nu^\star &amp;lt; 1/\alpha_i \ \\\\
0 &amp;amp;\nu^\star \ge 1/\alpha_i\\\\
\end{cases}
= \max\{0, 1/\nu^\star - \alpha_i \}, \quad i = 1, \dots, n.\]
&lt;/blockquote&gt;

&lt;p&gt;Also, by the condition \(1^T x^\star = 1\), \(x_i^\star, i = 1, \dots, n\) sum to 1.&lt;/p&gt;
&lt;blockquote&gt;
\[\sum_{i=1}^n \max\{0, 1/\nu^\star - \alpha_i \} = 1.\]
&lt;/blockquote&gt;

&lt;p&gt;The left side of the equation is a piecewise-linear increasing function of \(1/\nu^\star\), so this equation has a unique solution for fixed \(\alpha_i\).&lt;/p&gt;

&lt;p&gt;This solution method is called water-filling. When \(\alpha_i\) is the ground level for patch \(i\), this problem can be thought of as pouring water into each region so that the water level becomes \(1/\nu^\star\) as shown in the figure below. We pour water until the total amount of water becomes 1.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter12/water-fill.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Illustration of water-filling algorithm [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>12-02 Example quadratic with equality constraints</title>
   <link href="http://localhost:4000/contents/en/chapter12/12_02_Example_quadratic_with_equality_constraints/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter12/12_02_Example_quadratic_with_equality_constraints</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;A &lt;a href=&quot;&quot;&gt;quadratic program&lt;/a&gt; with only equality constraints is as follows.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp;{(1/2)x^T P x + q^T x + r} \\\\
   &amp;amp;\text{subject to} &amp;amp;&amp;amp;{Ax = b},\\\\
&amp;amp;\text{where } &amp;amp;&amp;amp;P \in \mathbb{S}_{+}^n \text{ and } A \in \mathbb{R}^{\text{p x n}}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This problem is convex and has no inequality constraints, so it satisfies Slater’s condition (Strong duality). If the primal &amp;amp; dual solutions are \(x^\star, \nu^\star\), then by KKT conditions they satisfy the following conditions [1].&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Stationarity: \(Px^\star + q + A^T\nu^\star = 0\)&lt;/li&gt;
  &lt;li&gt;Complementary Slackness: Since there are no inequality constraints, this does not need to be considered.&lt;/li&gt;
  &lt;li&gt;Primal &amp;amp; dual feasibility: \(Ax^\star = b\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These conditions can be concisely expressed using a block matrix, which is called the KKT matrix [3].&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{bmatrix}
    P       &amp;amp; A^T  \\\\
    A       &amp;amp; 0  \\\\
\end{bmatrix}
\begin{bmatrix}
    x^\star  \\\\
    \nu^\star  \\\\
\end{bmatrix}
=
\begin{bmatrix}
    -q  \\\\
    b  \\\\
\end{bmatrix}\]
&lt;/blockquote&gt;

&lt;p&gt;Solving this matrix equation gives the primal &amp;amp; dual solutions for the given problem.&lt;/p&gt;

&lt;p&gt;An interesting fact is that this problem can also be seen as computing the Newton step for an equality constrained problem [3]. For the problem \(min_x f(x) \text{ subject to } Ax = b\), if we set P, q, r as follows, then the objective function of the quadratic program becomes identical to the second-order Taylor expansion of \(f(x)\).&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(P = \nabla^2 f(x^{(k-1)})\), \(q = \nabla f(x^{(k-1)})\), \(r = f(x^{(k-1)})\)&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>12-01 Karush-Kuhn-Tucker conditions</title>
   <link href="http://localhost:4000/contents/en/chapter12/12_01_Karush_Kuhn_Tucker_conditions/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter12/12_01_Karush_Kuhn_Tucker_conditions</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Let us consider the following general optimization problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} &amp;amp;&amp;amp;{f(x)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{h_i(x) \le 0, \text{ } i=1,\dots,m} \\\\
   &amp;amp; &amp;amp;&amp;amp;{l_j(x) = 0, \text{ } j=1,\dots,r}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The &lt;strong&gt;Karush–Kuhn–Tucker (KKT) conditions&lt;/strong&gt; or &lt;strong&gt;KKT conditions&lt;/strong&gt; consist of the following conditions [3].&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(0 \in \partial \big( f(x) + \sum_{i=1}^{m} \lambda_i h_i(x) + \sum_{j=1}^{r} \nu_j l_j(x) \big)\) (Stationarity): When \(\lambda, \nu\) are fixed, the subdifferential with respect to \(x\) contains 0.&lt;/li&gt;
  &lt;li&gt;\(\lambda_i \cdot h_i(x) = 0 \text{ for all } i\) (Complementary Slackness):  At least one of \(\lambda_i\) and \(h_i\) has value 0.&lt;/li&gt;
  &lt;li&gt;\(h_i(x) \le 0, l_j(x) = 0 \text{ for all } i, j\) (Primal Feasibility): Indicates whether the constraints of the primal problem are satisfied.&lt;/li&gt;
  &lt;li&gt;\(\lambda_i \ge 0 \text{ for all } i\) (Dual Feasibility): Indicates whether the constraints of the dual problem are satisfied.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sufficiency&quot;&gt;Sufficiency&lt;/h2&gt;
&lt;p&gt;For a convex primal problem, when there exist \(x^\star, \lambda^\star, \nu^\star\) that satisfy the KKT conditions, the following process shows that \(x^\star, \lambda^\star, \nu^\star\) are primal &amp;amp; dual solutions with zero duality gap.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   g(\lambda^\star, \nu^\star) &amp;amp;= \min_x L(x, \lambda^\star, \nu^\star) \\\\
                               &amp;amp;= L(x^\star, \lambda^\star, \nu^\star) \\\\
                               &amp;amp;= f(x^\star) + \sum_{i=1}^m \lambda_i^\star h_i(x^\star) + \sum_{j=1}^r \nu_j^\star l_j(x^\star) \\\\
                               &amp;amp;= f(x^\star)
\end{align}\]
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;\(L(x,\lambda^\star,\nu^\star) = f(x) + \sum_{i=1}^{m} \lambda_i^\star h_i(x) + \sum_{j=1}^{r} \nu_j^\star l_j(x)\) is a convex function. (sum of convex functions)&lt;/li&gt;
  &lt;li&gt;\(0 \in \partial \big( f(x^\star) + \sum_{i=1}^{m} \lambda_i^\star h_i(x^\star) + \sum_{j=1}^{r} \nu_j^\star l_j(x^\star) \big)\)therefore \(\min_x L(x, \lambda^\star, \nu^\star) = L(x^\star, \lambda^\star, \nu^\star)\).&lt;/li&gt;
  &lt;li&gt;By complementary slackness and primal feasibility, \(f(x^\star) + \sum_{i=1}^m \lambda_i^\star h_i(x^\star) + \sum_{j=1}^r \nu_j^\star l_j(x^\star) = f(x^\star)\).&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;necessity&quot;&gt;Necessity&lt;/h2&gt;
&lt;p&gt;When \(x^\star, \lambda^\star, \nu^\star\) are primal &amp;amp; dual solutions with zero duality gap (for example, satisfying Slater’s condition), all the inequalities below become equalities, so in this problem \(x^\star, \lambda^\star, \nu^\star\) satisfy the KKT conditions.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   f(x^\star) &amp;amp;= g(\lambda^\star, \nu^\star) \\\\
                  &amp;amp;= \min_x  \big( f(x) + \sum_{i=1}^{m} \lambda_i^\star h_i(x) + \sum_{j=1}^{r} \nu_j^\star l_j(x) \big) \\\\
                  &amp;amp;\le f(x^\star) + \sum_{i=1}^m \lambda_i^\star h_i(x^\star) + \sum_{j=1}^r \nu_j^\star l_j(x^\star) \\\\
                  &amp;amp;\le f(x^\star)
\end{align}\]
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;\(f(x^\star) = g(\lambda^\star, \nu^\star)\) means zero duality gap.&lt;/li&gt;
  &lt;li&gt;To satisfy \(f(x^\star) + \sum_{i=1}^m \underbrace{\lambda_i^\star h_i(x^\star)}_{0} + \sum_{j=1}^r \underbrace{\nu_j^\star l_j(x^\star)}_{0} = f(x^\star)\), complementary slackness and primal feasibility must be satisfied.&lt;/li&gt;
  &lt;li&gt;If \(f(x^\star) + \sum_{i=1}^m \lambda_i^\star h_i(x^\star) + \sum_{j=1}^r \nu_j^\star l_j(x^\star) = f(x^\star)\) is satisfied, all inequalities in the above derivation become equalities.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;putting-it-together&quot;&gt;Putting it together&lt;/h2&gt;
&lt;p&gt;In summary, KKT conditions are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sufficient conditions for primal &amp;amp; dual solutions with zero duality gap.&lt;/li&gt;
  &lt;li&gt;If strong duality holds, they become necessary conditions for primal &amp;amp; dual solutions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That is, for problems that satisfy strong duality, the following relationship holds.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   x^\star, \lambda^\star, \nu^\star \text{ are primal and dual solutions} \\\\
   \Leftrightarrow x^\star, \lambda^\star, \nu^\star \text{ satisfy the KKT conditions} \\\\
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>12 KKT Conditions</title>
   <link href="http://localhost:4000/contents/en/chapter12/12_00_KKT_conditions/"/>
   <updated>2021-04-02T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter12/12_00_KKT_conditions</id>
   <content type="html">&lt;p&gt;When the primal problem is convex, the Karush–Kuhn–Tucker (KKT) conditions become sufficient conditions for primal &amp;amp; dual optimal points with zero duality gap. Additionally, when the objective function and constraint functions of the primal problem are differentiable and satisfy strong duality, the primal &amp;amp; dual optimal points always satisfy the KKT conditions. KKT conditions hold a very important position in optimization. These conditions allow some special problems to be solved analytically, and many convex optimization algorithms can be interpreted as methods for solving KKT conditions [1]. In this chapter, we will learn about the definition and properties of KKT conditions and look at some examples based on them.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;As a side note&lt;/em&gt;, KKT conditions were originally introduced to the world by Harold W. Kuhn and Albert W. Tucker in 1951, and at that time they were called KT (Kuhn-Tucker) conditions. Later, scholars discovered that the necessary conditions for this problem had been addressed by William Karush’s master’s thesis in 1939, and from then on, Karush’s name was included and they became known as KKT (Karush–Kuhn–Tucker) conditions [3].&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>16_duality_revisited</title>
   <link href="http://localhost:4000/contents/vi/chapter16/16_duality_revisited/"/>
   <updated>2021-03-31T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter16/16_duality_revisited</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>16-03 Tính đối ngẫu Fenchel</title>
   <link href="http://localhost:4000/contents/vi/chapter16/16_03_fenchel_duality/"/>
   <updated>2021-03-31T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter16/16_03_fenchel_duality</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Trong &lt;a href=&quot;/contents/vi/chapter13/13_04_Conjugate_function/&quot;&gt;13-04 Hàm liên hợp&lt;/a&gt;, chúng ta đã học cách suy ra các bài toán đối ngẫu bằng cách sử dụng các hàm liên hợp. Tính đối ngẫu Fenchel đề cập đến các bài toán đối ngẫu được suy ra từ các hàm liên hợp có dạng sau:&lt;/p&gt;

\[\max_{v} -f^*(A^Tv) - g^*(-v)\]

&lt;p&gt;Hãy khám phá xem dạng bài toán này được suy ra từ đâu.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy&quot;&gt;Bài toán nguyên thủy&lt;/h3&gt;

&lt;blockquote&gt;
\[\min_{x} \quad f(x) + g(Ax)\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán đã cho có thể được định nghĩa lại với một ràng buộc đẳng thức được thêm vào.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy-được-viết-lại&quot;&gt;Bài toán nguyên thủy được viết lại&lt;/h3&gt;
&lt;blockquote&gt;

\[\begin{align}
 &amp;amp;\min_{x,z} \        &amp;amp;&amp;amp; f(x) + g(z)\\
 &amp;amp;\text{subject to} \ &amp;amp;&amp;amp; Ax = z.
 \end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Hãy suy ra bài toán đối ngẫu của bài toán nguyên thủy được định nghĩa lại bằng cách sử dụng các hàm liên hợp. &lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Nhắc lại:&lt;/strong&gt; \(f^*(s) \doteq  \max_{x} \big( s^Tx - f(x) \big) = \min_{x} \big( f(x) - s^Tx \big)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
\(\begin{align}
&amp;amp;\max_{v} \min_{x, z} \quad L(x,z,v)\\\\
= &amp;amp;\max_{v} \min_{x, z} \quad f(x) + g(z) + v^T (z - Ax) \\\\
= &amp;amp;\max_{v} \min_{x, z} \quad v^Tz + g(z) - (A^Tv)^Tx + f(x)\\\\
= &amp;amp;\max_{v} \quad  -f^*(A^Tv) - g^*(-v)\\\\
\end{align}\)&lt;/p&gt;

&lt;h3 id=&quot;tính-đối-ngẫu-fenchel&quot;&gt;Tính đối ngẫu Fenchel&lt;/h3&gt;
&lt;blockquote&gt;
\[\max_{v} -f^*(A^Tv) - g^*(-v)\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tính chất tốt:&lt;/strong&gt; Nếu \(f, g\) là lồi và đóng, đối ngẫu của đối ngẫu lại trở thành nguyên thủy. (Đối xứng)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ví-dụ-quy-hoạch-cônic&quot;&gt;Ví dụ: quy hoạch cônic&lt;/h2&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy-của-cp-dạng-chuẩn&quot;&gt;Bài toán nguyên thủy của CP dạng chuẩn&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
    \mathop{\text{minimize}}_x &amp;amp;\quad c^Tx \\\\
    \text{subject to} &amp;amp;\quad Ax = b \\\\
    &amp;amp;\quad x \in K
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán trên có thể được định nghĩa lại bằng cách sử dụng hai hàm \(f(x) = c^Tx + I_K(x)\) và \(g(z) = I_{\{b\}}(z)\).&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Lưu ý:&lt;/strong&gt; \(\begin{equation}
  f(x) + g(Ax) = 
  \begin{cases}
    0, &amp;amp; \text{nếu}\ Ax=b, x \in K \\\\
    \infty, &amp;amp; \text{trường hợp khác}
  \end{cases}
\end{equation}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy-của-cp-được-viết-lại&quot;&gt;Bài toán nguyên thủy của CP được viết lại&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, z}       \ &amp;amp;&amp;amp;  f(x) + g(z)\\\
&amp;amp;\text{subject to} \ &amp;amp;&amp;amp; z  =Ax \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;suy-ra-bài-toán-đối-ngẫu-của-cp&quot;&gt;Suy ra bài toán đối ngẫu của CP&lt;/h3&gt;

&lt;p&gt;Hãy suy ra bài toán đối ngẫu từ bài toán nguyên thủy CP được định nghĩa lại. Đầu tiên, mở rộng các hàm \(f\) và \(g\) cho chúng ta:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \min_{x, z} &amp;amp;&amp;amp; \; c^Tx + I_K(x) + I_{\{b\}}(z)  \\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp; \;  z   =Ax \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Hãy mở rộng bài toán bằng cách sử dụng các hàm liên hợp từ định nghĩa của bài toán đối ngẫu.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \max_{y} \; \min_{x, z} \;  L(x, z, y) \\\
= \; &amp;amp; \max_{y} \; \min_{x, z} \;  c^Tx + I_K(x) + I_{\{b\}}(z) + y^T(z-Ax) \\\
= \; &amp;amp; \max_{y}  \;\min_{x, z} \; (c - A^Ty)^Tx  + I_K(x) \;+ \;  y^Tz + I_{\{b\}}(z) \\\
= \; &amp;amp; \max_{y} \;  \min_{x, z} \; -( (A^Ty - c)^Tx  - I_K(x)) \;  - \; ( - y^Tz - I_{\{b\}}(z) ) \\\
= \; &amp;amp; \max_{y} \; - I_K^*(A^Ty - c)  -  I_{\{b\}}^*(-y)  \\\
= \; &amp;amp; \max_{y} \; - I_{-K^*}(A^Ty - c)  - I_{\{b\}}^*(-y)  \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(I_{-K^*}(A^Ty - c)\) có thể được biểu diễn như một ràng buộc.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
A^Ty - c &amp;amp; = -s, \; -s \in -K^* \\\
\Leftrightarrow A^Ty + s &amp;amp; = c, \; s \in K^* \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Vì \(I_{\{b\}}^*(-y) = \max_{b} -b^Ty - I_{\{b\}}(b)\), bài toán có thể được tổ chức như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{y, s} \ &amp;amp;&amp;amp; -(-b^Ty - I_{\{b\}}(b)) \\\
&amp;amp;\text{subject to} \ &amp;amp;&amp;amp; y^TA + s = c \\\
&amp;amp;  \; s \in K^* \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Vì \(I_{\{b\}}(b) = 0\), nó có thể được loại bỏ khỏi bài toán.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-đối-ngẫu-của-cp&quot;&gt;Bài toán đối ngẫu của CP&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{y, s} \ &amp;amp;&amp;amp;  \;  b^Ty  \\\
&amp;amp;\text{subject to} \ &amp;amp;&amp;amp; y^TA + s = c \\\
&amp;amp;  \; s \in K^* \\
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Nếu bài toán nguyên thủy hoặc bài toán đối ngẫu khả thi nghiêm ngặt, thì tính đối ngẫu mạnh được thỏa mãn.&lt;/li&gt;
  &lt;li&gt;Nếu cả bài toán nguyên thủy và bài toán đối ngẫu đều khả thi nghiêm ngặt, thì tính đối ngẫu mạnh được thỏa mãn và tồn tại nghiệm tối ưu nguyên thủy &amp;amp; đối ngẫu.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ví-dụ-quy-hoạch-nửa-xác-định&quot;&gt;Ví dụ: quy hoạch nửa xác định&lt;/h2&gt;
&lt;p&gt;Hãy xem xét các dạng của bài toán nguyên thủy &amp;amp; đối ngẫu cho SDP và các bài toán nguyên thủy &amp;amp; đối ngẫu cho bài toán barrier của SDP.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy-của-sdp&quot;&gt;Bài toán nguyên thủy của SDP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\mathop{\text{minimize}}_{X} &amp;amp;&amp;amp;{tr(CX)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{tr(A_iX) = b_i, \phantom{5} i=1,\dotsc,p} \\\\
   &amp;amp; &amp;amp;&amp;amp;{X \succeq 0},\\\\
\end{align}\]

\[\text{trong đó } C, A_1, \dotsc, A_p \in \mathbb{S}^n.\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Nhắc lại:&lt;/strong&gt; \(tr(CX) = \sum_{i,j=1}^n C_{ij}X_{ij}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lưu ý:&lt;/strong&gt; Không giống như LP, SDP không luôn thỏa mãn tính đối ngẫu mạnh.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bài-toán-đối-ngẫu-của-sdp&quot;&gt;Bài toán đối ngẫu của SDP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\mathop{\text{maximize}}_{y} &amp;amp;&amp;amp;{b^Ty} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\sum_{i=1}^m y_i A_i + S = C} \\\\
   &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Lưu ý:&lt;/strong&gt; Nón nửa xác định dương là một nón tự đối ngẫu. (\((\mathbb{S}_{+}^n)^* = \mathbb{S}_{+}^n\))&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy-của-bài-toán-barrier-cho-sdp&quot;&gt;Bài toán nguyên thủy của bài toán Barrier cho SDP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\mathop{\text{minimize}}_{X} &amp;amp;&amp;amp;{tr(CX) - \tau \log \big( det(X) \big)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{tr(A_iX) = b_i, \phantom{5} i=1,\dotsc,p} \\\\
\end{align}\]

\[\text{trong đó } C, A_1, \dotsc, A_p \in \mathbb{S}^n.\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;bài-toán-đối-ngẫu-của-bài-toán-barrier-cho-sdp&quot;&gt;Bài toán đối ngẫu của bài toán Barrier cho SDP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\mathop{\text{maximize}}_{y, S} &amp;amp;&amp;amp;{b^Ty +  \tau \log \big( det(S) \big)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\sum_{i=1}^m y_i A_i + S = C}.
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>16-02 Điều kiện tối ưu</title>
   <link href="http://localhost:4000/contents/vi/chapter16/16_02_optimality_conditions/"/>
   <updated>2021-03-31T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter16/16_02_optimality_conditions</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Trong phần này, chúng ta sẽ xem xét các điều kiện tối ưu KKT cho các bài toán nguyên thủy và các bài toán barrier tương ứng, và sau đó so sánh sự khác biệt của chúng.
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;điều-kiện-tối-ưu-kkt&quot;&gt;Điều kiện tối ưu KKT&lt;/h2&gt;

&lt;p&gt;Hãy xem lại các điều kiện KKT mà chúng ta đã đề cập trong Chương 12. Điều kiện KKT được sử dụng như các điều kiện để xác định tính tối ưu.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy&quot;&gt;Bài toán nguyên thủy&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad f(x) \\\\
   \text{subject to} &amp;amp;\quad h_i(x) \leq 0, i = 1, \ldots, m \\\\
   &amp;amp;\quad l_j(x) = 0, j = 1, \ldots, r
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Khi bài toán nguyên thủy đã cho là lồi, các điều kiện KKT trở thành điều kiện đủ cho tính tối ưu nguyên thủy &amp;amp; đối ngẫu. Có nghĩa là, khi \(f, h_1, \dots, h_m\) là lồi và \(l_1, \dots, l_r\) là affine, nếu \(x^\star, u^\star, v^\star\) thỏa mãn các điều kiện KKT sau, thì \(x^\star\) và \((u^\star, v^\star)\) là tối ưu nguyên thủy &amp;amp; đối ngẫu với khoảng cách đối ngẫu bằng không. (Chúng ta giả sử rằng \(f, h_1, \dots, h_m, l_1, \dots, l_r\) có thể vi phân.) &lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tham khảo: &lt;a href=&quot;/contents/vi/chapter12/12_00_KKT_conditions/&quot;&gt;12-01 Điều kiện KKT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;điều-kiện-kkt-cho-bài-toán-nguyên-thủy-đã-cho&quot;&gt;Điều kiện KKT cho bài toán nguyên thủy đã cho&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
l_i &amp;amp;= 0, \quad i=1, \dots, r\\\\
u_i^\star, -h_i(x^\star) &amp;amp;\ge 0, \quad i=1, \dots, m\\\\
u_i^\star h_i(x^\star) &amp;amp;= 0, \quad i=1, \dots, m\\\\
\nabla f(x^\star) + \sum_{i=1}^m \nabla h_i(x^\star) u^\star_i + \sum_{i=1}^r \nabla l_i(x^\star) v_i^\star &amp;amp;= 0.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;phương-trình-đường-dẫn-trung-tâm&quot;&gt;Phương trình đường dẫn trung tâm&lt;/h2&gt;

&lt;p&gt;Hãy cũng xem xét các điều kiện để xác định tính tối ưu của các bài toán barrier.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-barrier&quot;&gt;Bài toán barrier&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
    \mathop{\text{minimize}}_x &amp;amp;\quad f(x) + \tau \phi(x) \\\\
    &amp;amp;\quad l_j(x) = 0, j = 1, \ldots, r  \\\\
\end{align}\]

\[\text{trong đó } \phi(x) = - \sum_{i=1}^m \log \big( -h_i(x) \big).\]
&lt;/blockquote&gt;

&lt;p&gt;Bằng cách tổ chức các điều kiện KKT cho các bài toán barrier, chúng ta có thể suy ra các điều kiện tối ưu sau. Lưu ý sự khác biệt trong ràng buộc bất đẳng thức và các điều kiện bổ sung so với các điều kiện tối ưu KKT cho các bài toán nguyên thủy đã xem xét trước đó. (Tham khảo: &lt;a href=&quot;/contents/en/chapter15/chapter16/15_03_01_perturbed_kkt_conditions/&quot;&gt;15-03-01 Điều kiện KKT bị nhiễu&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&quot;điều-kiện-tối-ưu-cho-bài-toán-barrier-và-đối-ngẫu-của-nó&quot;&gt;Điều kiện tối ưu cho bài toán barrier (và đối ngẫu của nó)&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
l_i &amp;amp;= 0, \quad i=1, \dots, r\\\\
u_i(t), -h_i(x^\star(t)) &amp;amp;\gt 0, \quad i=1, \dots, m\\\\
u_i(t) h_i(x^\star(t)) &amp;amp;= -\tau, \quad i=1, \dots, m\\\\
\nabla f(x^\star(t)) + \sum_{i=1}^m \nabla h_i(x^\star(t)) u_i(t) + \sum_{i=1}^r \nabla l_i(x^\star(t)) \hat{v}_i^\star &amp;amp;= 0,\\\\
\end{align} \\\\\]

\[\text{trong đó } \tau = \frac{1}{t}, u_i(t) = - \frac{1}{t h_i(x^\star(t))}, \quad \hat{v} = \frac{1}{t}v.\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;trường-hợp-đặc-biệt-quy-hoạch-tuyến-tính&quot;&gt;Trường hợp đặc biệt: quy hoạch tuyến tính&lt;/h2&gt;

&lt;h3 id=&quot;nhắc-lại-bài-toán-nguyên-thủy-của-lp-dạng-chuẩn&quot;&gt;Nhắc lại: Bài toán nguyên thủy của LP dạng chuẩn&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad c^Tx \\\\
   \text{subject to} &amp;amp;\quad Ax = b \\\\
   &amp;amp;\quad x \ge 0
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;nhắc-lại-bài-toán-đối-ngẫu-của-lp&quot;&gt;Nhắc lại: Bài toán đối ngẫu của LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{maximize}}_{s,y} &amp;amp;\quad b^Ty \\\\
   \text{subject to} &amp;amp;\quad A^Ty +  s = c \\\\
   &amp;amp;\quad s \ge 0
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Quy hoạch tuyến tính có tính chất tốt là luôn thỏa mãn tính đối ngẫu mạnh do điều kiện Slater được làm tế, vì các ràng buộc bất đẳng thức là affine. Các điều kiện tối ưu cho LP như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
A^T y^\star + s^\star &amp;amp;= c\\\\
Ax^\star &amp;amp;= b\\\\
X S \mathbb{1} &amp;amp;= 0\\\\
x^\star, s^\star &amp;amp;\ge 0,\\\\
\end{align}\]

\[\text{trong đó }X = Diag(x^\star), S = Diag(s^\star)\]
&lt;/blockquote&gt;

&lt;p&gt;Lưu ý rằng \(X S \mathbb{1} = 0\) tương đương với \(Xs^\star=(x_1^\star s_1^\star, \dots, x_n^\star s_n^\star)=0\). Chúng ta sử dụng ký hiệu \(X, S\) để thuận tiện trong các thuật toán sẽ được giới thiệu sau này.&lt;/p&gt;

&lt;h3 id=&quot;thuật-toán-cho-quy-hoạch-tuyến-tính&quot;&gt;Thuật toán cho quy hoạch tuyến tính&lt;/h3&gt;

&lt;p&gt;Chúng ta giới thiệu hai phương pháp đại diện để giải LP bằng cách sử dụng các điều kiện tối ưu.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Simplex: Một phương pháp duy trì các điều kiện 1, 2, và 3 trong khi dần dần thỏa mãn điều kiện 4.&lt;/li&gt;
  &lt;li&gt;Phương pháp điểm trong: Một phương pháp duy trì điều kiện 4 trong khi dần dần thỏa mãn các điều kiện 1, 2, và 3. Điều này sẽ được đề cập trong chương tiếp theo.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;đường-dẫn-trung-tâm-cho-quy-hoạch-tuyến-tính&quot;&gt;Đường dẫn trung tâm cho quy hoạch tuyến tính&lt;/h2&gt;

&lt;h3 id=&quot;nhắc-lại-bài-toán-barrier-cho-lp&quot;&gt;Nhắc lại: Bài toán barrier cho LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
    \mathop{\text{minimize}}_x &amp;amp;\quad c^Tx - \tau \sum_{i=1}^n \log(x_i)\\\\
    \text{subject to} &amp;amp;\quad Ax = b, \\\\
    \text{trong đó}  &amp;amp;\quad \tau &amp;gt; 0
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;nhắc-lại-bài-toán-đối-ngẫu-của-bài-toán-barrier-cho-lp&quot;&gt;Nhắc lại: Bài toán đối ngẫu của bài toán Barrier cho LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{maximize}}_{s,y} &amp;amp;\quad b^Ty + \tau \sum_{i=1}^n log(s_i)\\\\
   \text{subject to} &amp;amp;\quad A^Ty +  s = c \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Các điều kiện tối ưu cho bài toán barrier của LP như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
A^T y^\star + s^\star &amp;amp;= c\\\\
Ax^\star &amp;amp;= b\\\\
X S \mathbb{1} &amp;amp;= \tau \mathbb{1}\\\\
x^\star, s^\star &amp;amp;\gt 0,\\\\
\text{trong đó} &amp;amp;\quad X = Diag(x^\star), S = Diag(s^\star)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Các điều kiện 3 và 4 cho thấy sự khác biệt so với các điều kiện KKT của LP nguyên thủy.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>16-01 Tính đối ngẫu Lagrangian - nhìn lại</title>
   <link href="http://localhost:4000/contents/vi/chapter16/16_01_lagrangian_duality_revisited/"/>
   <updated>2021-03-31T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter16/16_01_lagrangian_duality_revisited</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Trong phần này, chúng ta sẽ cho thấy rằng các bài toán nguyên thủy và đối ngẫu có thể được định nghĩa bằng cách sử dụng Lagrangian, và sử dụng định nghĩa này để suy ra các bài toán đối ngẫu cho quy hoạch tuyến tính dạng chuẩn và quy hoạch bậc hai. Hơn nữa, chúng ta sẽ suy ra bài toán đối ngẫu cho quy hoạch tuyến tính với bài toán barrier được áp dụng, cho thấy rằng dạng của nó giống với bài toán barrier cho bài toán đối ngẫu của quy hoạch tuyến tính.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
Đầu tiên, hãy định nghĩa bài toán nguyên thủy và Lagrangian như sau.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy&quot;&gt;Bài toán nguyên thủy&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad f(x) \\\\
   \text{subject to} &amp;amp;\quad h_i(x) \leq 0, i = 1, \ldots, m \\\\
   &amp;amp;\quad l_j(x) = 0, j = 1, \ldots, r
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;lagrangian&quot;&gt;Lagrangian&lt;/h3&gt;
&lt;blockquote&gt;
\[L(x,u,v) = f(x) + \sum_{i=1}^m u_i h_i (x) + \sum_{j=1}^r v_j l_j (x)\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;
Tại thời điểm này, bài toán nguyên thủy và bài toán đối ngẫu có thể được định nghĩa lại thành các bài toán liên quan đến Lagrangian.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy-được-viết-lại&quot;&gt;Bài toán nguyên thủy được viết lại&lt;/h3&gt;
&lt;blockquote&gt;
\[\min_x \mathop{\max_{u,v}}_{u \geq 0} L(x,u,v)\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán nguyên thủy được định nghĩa lại không nêu rõ ràng các ràng buộc, nhưng nó có tác dụng như một hàm chỉ thị cho bất kỳ \(x\) không khả thi nào vi phạm các ràng buộc.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Nếu \(h_i(\hat{x}) \gt 0\) cho một số \(i \in [1, m]\), thì \(\hat{x}\) là một điểm không khả thi. Trong trường hợp này, \(u_i h_i(\hat{x})\) phân kỳ về \(\infty\) do \(\max_{u,v}\), vì vậy nó hoạt động như một hàm chỉ thị cho bất kỳ \(\hat{x}\) nào vi phạm ràng buộc bất đẳng thức.&lt;/li&gt;
  &lt;li&gt;Nếu \(l_i(\hat{x}) \neq 0\) cho một số \(i \in [1, r]\), thì \(\hat{x}\) là một điểm không khả thi. Trong trường hợp này, \(v_i l_i(\hat{x})\) phân kỳ về \(\infty\) do \(\max_{u,v}\), vì vậy nó hoạt động như một hàm chỉ thị cho bất kỳ \(\hat{x}\) nào vi phạm ràng buộc đẳng thức.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;bài-toán-đối-ngẫu-được-viết-lại&quot;&gt;Bài toán đối ngẫu được viết lại&lt;/h3&gt;
&lt;blockquote&gt;
\[\mathop{\max_{u,v}}_{u \geq 0} \min_x L(x,u,v)\]
&lt;/blockquote&gt;

&lt;p&gt;Trong bài toán đối ngẫu, việc nới lỏng miền là cần thiết, vì vậy nó không nên hoạt động như một hàm chỉ thị cho các ràng buộc của bài toán nguyên thủy. Vì việc lấy \(\min_x\) cho \(u, v\) cố định không thể thực thi các ràng buộc của bài toán nguyên thủy, bài toán đối ngẫu được định nghĩa lại cũng có tác dụng nới lỏng miền. (Tham khảo: &lt;a href=&quot;/contents/vi/chapter11/11_02_Lagrange_dual_function/&quot;&gt;11-02 Hàm đối ngẫu Lagrange&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&quot;tính-đối-ngẫu-yếu-và-mạnh&quot;&gt;Tính đối ngẫu yếu và mạnh&lt;/h2&gt;
&lt;p&gt;Hãy xem xét lại tính đối ngẫu yếu và tính đối ngẫu mạnh.&lt;/p&gt;

&lt;h3 id=&quot;định-lý-tính-đối-ngẫu-yếu&quot;&gt;Định lý: tính đối ngẫu yếu&lt;/h3&gt;
&lt;p&gt;Khi \(p\) và \(d\) là các giá trị tối ưu cho bài toán nguyên thủy và bài toán đối ngẫu tương ứng, điều sau luôn được thỏa mãn:&lt;/p&gt;

\[p \ge d\]

&lt;h3 id=&quot;định-lý-tính-đối-ngẫu-mạnh-điều-kiện-slater-được-làm-tế&quot;&gt;Định lý: tính đối ngẫu mạnh (điều kiện Slater được làm tế)&lt;/h3&gt;
&lt;p&gt;Đối với tập miền \(D\), giả sử rằng \(f, h_1, \dots, h_p\) là lồi và \(h_{p+1}, \dots, h_m, l_1, \dots, l_r\) là affine. Nếu tồn tại \(\hat{x} \in \text{relint}(D)\) thỏa mãn điều sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
h_i(\hat{x}) \ &amp;amp; \lt 0, \ &amp;amp;&amp;amp; i=1, \dots, p \\
h_i(\hat{x}) \ &amp;amp; \le 0, \ &amp;amp;&amp;amp; i=p+1, \dots, m \\
l_j(\hat{x}) \ &amp;amp; = 0, \ &amp;amp;&amp;amp; j = 1, \dots, r
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;thì \(p = d\) được đảm bảo cho các giá trị tối ưu \(p, d\) của bài toán nguyên thủy và bài toán đối ngẫu.&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ-quy-hoạch-tuyến-tính&quot;&gt;Ví dụ: quy hoạch tuyến tính&lt;/h2&gt;
&lt;p&gt;Hãy suy ra bài toán đối ngẫu của quy hoạch tuyến tính bằng cách sử dụng bài toán đối ngẫu đã định nghĩa trước đó.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy-của-lp-dạng-chuẩn&quot;&gt;Bài toán nguyên thủy của LP dạng chuẩn&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad c^Tx \\\\
   \text{subject to} &amp;amp;\quad Ax = b \\\\
   &amp;amp;\quad x \ge 0
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Theo định nghĩa trước đó, bài toán đối ngẫu của bài toán trên như sau:&lt;/p&gt;

\[\mathop{\max_{s,y}}_{s\ge0} \min_{x} \: L(x,s,y) = \mathop{\max_{s,y}}_{s\ge0} \min_{x} \: c^Tx - s^Tx + (b-Ax)^T y\]

&lt;p&gt;Chúng ta thay thế mối quan hệ \(c=A^Ty +s\) thu được bằng cách giải \(\nabla_x L = 0\) vào bài toán đối ngẫu.&lt;/p&gt;

\[\mathop{\max_{s,y}}_{s\ge0} \: (A^Ty + s)^Tx - s^Tx + (b-Ax)^Ty \quad \text{ s.t. } c=A^Ty +s\]

&lt;p&gt;Điều này có thể được tổ chức như sau:&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-đối-ngẫu-của-lp&quot;&gt;Bài toán đối ngẫu của LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{maximize}}_{s,y} &amp;amp;\quad b^Ty \\\\
   \text{subject to} &amp;amp;\quad A^Ty +  s = c \\\\
   &amp;amp;\quad s \ge 0
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;ví-dụ-quy-hoạch-bậc-hai-lồi&quot;&gt;Ví dụ: quy hoạch bậc hai lồi&lt;/h2&gt;
&lt;p&gt;Bây giờ hãy suy ra bài toán đối ngẫu của quy hoạch bậc hai bằng cách sử dụng bài toán đối ngẫu đã định nghĩa trước đó.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-nguyên-thủy-của-qp-dạng-chuẩn&quot;&gt;Bài toán nguyên thủy của QP dạng chuẩn&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad \frac{1}{2} x^T Q x + c^Tx \\
   \text{subject to} &amp;amp;\quad Ax = b \\
   &amp;amp;\quad x \ge 0, \\

\end{align}\]

\[\text{trong đó } Q \text{ là đối xứng và nửa xác định dương.}\]
&lt;/blockquote&gt;

&lt;p&gt;Theo định nghĩa trước đó, bài toán đối ngẫu của bài toán trên như sau:&lt;/p&gt;

\[\mathop{\max_{s,y}}_{s\ge0} \min_{x} \: L(x,s,y) = \mathop{\max_{s,y}}_{s\ge0} \min_{x} \:  \frac{1}{2} x^T Q x + c^Tx - s^Tx + (b-Ax)^T y\]

&lt;p&gt;Chúng ta thay thế mối quan hệ \(Qx = A^Ty +s - c\) thu được bằng cách giải \(\nabla_x L = 0\) vào bài toán đối ngẫu.&lt;/p&gt;

\[\begin{align}
&amp;amp;\mathop{\max_{s,y,x}}_{s\ge0} \: \frac{1}{2} x^T (A^Ty +s - c) + c^Tx - s^Tx + (b-Ax)^T y \quad \text{ s.t. } Qx = A^Ty +s - c\\\\
&amp;amp;= \mathop{\max_{s,y,x}}_{s\ge0} \: x^T (A^Ty +s - c) + c^Tx - s^Tx + (b-Ax)^T y -  \frac{1}{2} x^T (A^Ty +s - c) \quad \text{ s.t. } Qx = A^Ty +s - c\\\\
&amp;amp;= \mathop{\max_{s,y,x}}_{s\ge0}  \: b^Ty - \frac{1}{2} x^T (A^Ty +s - c) \quad  \text{ s.t. } Qx = A^Ty +s - c\\\\
&amp;amp;= \mathop{\max_{s,y,x}}_{s\ge0}  \: b^Ty - \frac{1}{2} x^T Q x \quad \text{ s.t. } Qx = A^Ty +s - c
\end{align}\]

&lt;p&gt;Điều này có thể được tổ chức như sau:&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-đối-ngẫu-của-qp&quot;&gt;Bài toán đối ngẫu của QP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{maximize}}_{s,y,x} &amp;amp;\quad b^Ty - \frac{1}{2} x^T Q x\\\\
   \text{subject to} &amp;amp;\quad A^Ty +  s - c = Qx \\\\
   &amp;amp;\quad s \ge 0
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán đối ngẫu của một bài toán bậc hai cũng là một bài toán bậc hai.&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ-bài-toán-barrier-cho-quy-hoạch-tuyến-tính&quot;&gt;Ví dụ: bài toán barrier cho quy hoạch tuyến tính&lt;/h2&gt;
&lt;p&gt;Bài toán barrier cho quy hoạch tuyến tính được định nghĩa như sau:&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-barrier-cho-lp&quot;&gt;Bài toán barrier cho LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad c^Tx - \tau \sum_{i=1}^n \log(x_i)\\
   \text{subject to} &amp;amp;\quad Ax = b, \\
\end{align}\]

\[\text{trong đó }\tau &amp;gt; 0.\]
&lt;/blockquote&gt;

&lt;p&gt;Theo định nghĩa trước đó, bài toán đối ngẫu của bài toán trên như sau:
\(\begin{align}
\max_{y} \min_{x} \: L(x,y) &amp;amp;= \max_{y} \min_{x} \:  c^Tx - \tau \sum_{i=1}^n \log(x_i) + (b-Ax)^T y\\\\
&amp;amp;=  \max_{y} \min_{x} \:  \underbrace{(c-A^Ty)}_{s \doteq c-A^Ty}x - \tau \sum_{i=1}^n \log(x_i) + b^Ty\\\\
&amp;amp;= \max_{y} \min_{x} \: \sum_{i=1}^n \big( s_i^Tx_i - \tau  \log(x_i) \big) + b^Ty  \quad \text{ s.t. } A^Ty +s = c
\end{align}\)&lt;/p&gt;

&lt;p&gt;Ở đây, \(\sum_{i=1}^n \big( s_i^Tx_i - \tau  \log(x_i) \big) + b^Ty\) sẽ được tối thiểu hóa khi \(x_i = \frac{\tau}{s_i}\). Do đó, hãy thay thế \(\frac{\tau}{s_i}\) cho \(x_i\) trong bài toán đối ngẫu.&lt;/p&gt;

\[\begin{align}
&amp;amp;\max_{s,y} \: b^Ty + n\tau - \tau \sum_{i=1}^n log(\frac{\tau}{s_i}) \quad \text{ s.t. } A^Ty +s = c\\\\
&amp;amp;= \max_{s,y} \: b^Ty + \tau \sum_{i=1}^n log(s_i) + n\tau - n\tau\log(\tau) \quad \text{ s.t. } A^Ty +s = c\\\\
\end{align}\]

&lt;p&gt;Vì \(n\tau - n\tau\log(\tau)\) có thể được bỏ qua khỏi bài toán, bài toán đối ngẫu có thể được tổ chức như sau:&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-đối-ngẫu-của-bài-toán-barrier-cho-lp&quot;&gt;Bài toán đối ngẫu của bài toán Barrier cho LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{maximize}}_{s,y} &amp;amp;\quad b^Ty + \tau \sum_{i=1}^n log(s_i)\\\\
   \text{subject to} &amp;amp;\quad A^Ty +  s = c \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Chúng ta có thể thấy rằng bài toán này giống hệt với bài toán barrier cho bài toán đối ngẫu của quy hoạch tuyến tính.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>16 Duality Revisited</title>
   <link href="http://localhost:4000/contents/en/chapter16/16_duality_revisited/"/>
   <updated>2021-03-31T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter16/16_duality_revisited</id>
   <content type="html">&lt;p&gt;In this chapter, we organize essential background knowledge about duality before covering the Primal-Dual Interior-Point method. The Primal-Dual Interior-Point method can be viewed as an extension of the Barrier method, and the concept of duality emerges as a key topic in the process of developing the content.&lt;/p&gt;

&lt;h2 id=&quot;references-and-further-readings&quot;&gt;References and further readings&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;O. Guler (2010), “Foundations of Optimization”, Chapter 11.&lt;/li&gt;
  &lt;li&gt;J. Renegar (2001), “A mathematical view of interior-point methods in convex optimization,” Chapters 2 and 3.&lt;/li&gt;
  &lt;li&gt;S. Wright (1997), “Primal-dual interior-point methods”, Chapters 5 and 6.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>16-03 Fenchel duality</title>
   <link href="http://localhost:4000/contents/en/chapter16/16_03_fenchel_duality/"/>
   <updated>2021-03-31T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter16/16_03_fenchel_duality</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In &lt;a href=&quot;/contents/en/chapter13/13_04_Conjugate_function/&quot;&gt;13-04 Conjugate function&lt;/a&gt;, we learned how to derive dual problems using conjugate functions. Fenchel duality refers to dual problems derived from conjugate functions that have the following form:&lt;/p&gt;

\[\max_{v} -f^*(A^Tv) - g^*(-v)\]

&lt;p&gt;Let’s explore where this form of problem is derived from.&lt;/p&gt;

&lt;h3 id=&quot;primal-problem&quot;&gt;Primal problem&lt;/h3&gt;

&lt;blockquote&gt;
\[\min_{x} \quad f(x) + g(Ax)\]
&lt;/blockquote&gt;

&lt;p&gt;The given problem can be redefined with an added equality constraint.&lt;/p&gt;

&lt;h3 id=&quot;primal-problem-rewritten&quot;&gt;Primal problem rewritten&lt;/h3&gt;
&lt;blockquote&gt;

\[\begin{align}
 &amp;amp;\min_{x,z} \        &amp;amp;&amp;amp; f(x) + g(z)\\
 &amp;amp;\text{subject to} \ &amp;amp;&amp;amp; Ax = z.
 \end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s derive the dual problem of the redefined primal problem using conjugate functions. &lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Recall:&lt;/strong&gt; \(f^*(s) \doteq  \max_{x} \big( s^Tx - f(x) \big) = \min_{x} \big( f(x) - s^Tx \big)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
\(\begin{align}
&amp;amp;\max_{v} \min_{x, z} \quad L(x,z,v)\\\\
= &amp;amp;\max_{v} \min_{x, z} \quad f(x) + g(z) + v^T (z - Ax) \\\\
= &amp;amp;\max_{v} \min_{x, z} \quad v^Tz + g(z) - (A^Tv)^Tx + f(x)\\\\
= &amp;amp;\max_{v} \quad  -f^*(A^Tv) - g^*(-v)\\\\
\end{align}\)&lt;/p&gt;

&lt;h3 id=&quot;fenchel-duality&quot;&gt;Fenchel duality&lt;/h3&gt;
&lt;blockquote&gt;
\[\max_{v} -f^*(A^Tv) - g^*(-v)\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Nice Property:&lt;/strong&gt; If \(f, g\) are convex and closed, the dual of the dual becomes the primal again. (Symmetric)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;example-conic-programming&quot;&gt;Example: conic programming&lt;/h2&gt;

&lt;h3 id=&quot;primal-problem-of-cp-in-standard-form&quot;&gt;Primal problem of CP in standard form&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
    \mathop{\text{minimize}}_x &amp;amp;\quad c^Tx \\\\
    \text{subject to} &amp;amp;\quad Ax = b \\\\
    &amp;amp;\quad x \in K
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The above problem can be redefined using two functions \(f(x) = c^Tx + I_K(x)\) and \(g(z) = I_{\{b\}}(z)\).&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; \(\begin{equation}
  f(x) + g(Ax) = 
  \begin{cases}
    0, &amp;amp; \text{if}\ Ax=b, x \in K \\\\
    \infty, &amp;amp; \text{otherwise}
  \end{cases}
\end{equation}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;primal-problem-of-cp-rewritten&quot;&gt;Primal problem of CP rewritten&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, z}       \ &amp;amp;&amp;amp;  f(x) + g(z)\\\
&amp;amp;\text{subject to} \ &amp;amp;&amp;amp; z  =Ax \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;deriving-dual-problem-of-cp&quot;&gt;Deriving dual problem of CP&lt;/h3&gt;

&lt;p&gt;Let’s derive the dual problem from the redefined CP primal problem. First, expanding functions \(f\) and \(g\) gives us the following:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \min_{x, z} &amp;amp;&amp;amp; \; c^Tx + I_K(x) + I_{\{b\}}(z)  \\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp; \;  z   =Ax \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s expand the problem using conjugate functions from the definition of the dual problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \max_{y} \; \min_{x, z} \;  L(x, z, y) \\\
= \; &amp;amp; \max_{y} \; \min_{x, z} \;  c^Tx + I_K(x) + I_{\{b\}}(z) + y^T(z-Ax) \\\
= \; &amp;amp; \max_{y}  \;\min_{x, z} \; (c - A^Ty)^Tx  + I_K(x) \;+ \;  y^Tz + I_{\{b\}}(z) \\\
= \; &amp;amp; \max_{y} \;  \min_{x, z} \; -( (A^Ty - c)^Tx  - I_K(x)) \;  - \; ( - y^Tz - I_{\{b\}}(z) ) \\\
= \; &amp;amp; \max_{y} \; - I_K^*(A^Ty - c)  -  I_{\{b\}}^*(-y)  \\\
= \; &amp;amp; \max_{y} \; - I_{-K^*}(A^Ty - c)  - I_{\{b\}}^*(-y)  \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(I_{-K^*}(A^Ty - c)\) can be expressed as a constraint.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
A^Ty - c &amp;amp; = -s, \; -s \in -K^* \\\
\Leftrightarrow A^Ty + s &amp;amp; = c, \; s \in K^* \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Since \(I_{\{b\}}^*(-y) = \max_{b} -b^Ty - I_{\{b\}}(b)\), the problem can be organized as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{y, s} \ &amp;amp;&amp;amp; -(-b^Ty - I_{\{b\}}(b)) \\\
&amp;amp;\text{subject to} \ &amp;amp;&amp;amp; y^TA + s = c \\\
&amp;amp;  \; s \in K^* \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Since \(I_{\{b\}}(b) = 0\), it can be removed from the problem.&lt;/p&gt;

&lt;h3 id=&quot;dual-problem-of-cp&quot;&gt;Dual problem of CP&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{y, s} \ &amp;amp;&amp;amp;  \;  b^Ty  \\\
&amp;amp;\text{subject to} \ &amp;amp;&amp;amp; y^TA + s = c \\\
&amp;amp;  \; s \in K^* \\
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;If either the primal problem or dual problem is strictly feasible, then strong duality is satisfied.&lt;/li&gt;
  &lt;li&gt;If both the primal problem and dual problem are strictly feasible, then strong duality is satisfied and primal &amp;amp; dual optima exist.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;example-semidefinite-programming&quot;&gt;Example: semidefinite programming&lt;/h2&gt;
&lt;p&gt;Let’s examine the forms of primal &amp;amp; dual problems for SDP and the primal &amp;amp; dual problems for SDP’s barrier problem.&lt;/p&gt;

&lt;h3 id=&quot;primal-problem-of-sdp&quot;&gt;Primal problem of SDP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\mathop{\text{minimize}}_{X} &amp;amp;&amp;amp;{tr(CX)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{tr(A_iX) = b_i, \phantom{5} i=1,\dotsc,p} \\\\
   &amp;amp; &amp;amp;&amp;amp;{X \succeq 0},\\\\
\end{align}\]

\[\text{where } C, A_1, \dotsc, A_p \in \mathbb{S}^n.\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Recall:&lt;/strong&gt; \(tr(CX) = \sum_{i,j=1}^n C_{ij}X_{ij}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; Unlike LP, SDP does not always satisfy strong duality.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dual-problem-of-sdp&quot;&gt;Dual problem of SDP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\mathop{\text{minimize}}_{y} &amp;amp;&amp;amp;{b^Ty} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\sum_{i=1}^m y_i A_i + S = C} \\\\
   &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; The positive semidefinite cone is a self-dual cone. (\((\mathbb{S}_{+}^n)^* = \mathbb{S}_{+}^n\))&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;primal-problem-of-barrier-problem-for-sdp&quot;&gt;Primal problem of Barrier problem for SDP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\mathop{\text{minimize}}_{X} &amp;amp;&amp;amp;{tr(CX) - \tau \log \big( det(X) \big)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{tr(A_iX) = b_i, \phantom{5} i=1,\dotsc,p} \\\\
\end{align}\]

\[\text{where } C, A_1, \dotsc, A_p \in \mathbb{S}^n.\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;dual-problem-of-barrier-problem-for-sdp&quot;&gt;Dual problem of Barrier problem for SDP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\mathop{\text{minimize}}_{y, S} &amp;amp;&amp;amp;{b^Ty +  \tau \log \big( det(S) \big)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\sum_{i=1}^m y_i A_i + S = C}.
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>16-02 Optimality conditions</title>
   <link href="http://localhost:4000/contents/en/chapter16/16_02_optimality_conditions/"/>
   <updated>2021-03-31T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter16/16_02_optimality_conditions</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In this section, we will examine the KKT optimality conditions for primal problems and barrier problems respectively, and then compare their differences.
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;kkt-optimality-conditions&quot;&gt;KKT optimality conditions&lt;/h2&gt;

&lt;p&gt;Let’s review the KKT conditions that we covered in Chapter 12. KKT conditions are used as conditions for determining optimality.&lt;/p&gt;

&lt;h3 id=&quot;primal-problem&quot;&gt;Primal problem&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad f(x) \\\\
   \text{subject to} &amp;amp;\quad h_i(x) \leq 0, i = 1, \ldots, m \\\\
   &amp;amp;\quad l_j(x) = 0, j = 1, \ldots, r
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;When the given primal problem is convex, KKT conditions become sufficient conditions for primal &amp;amp; dual optimality. That is, when \(f, h_1, \dots, h_m\) are convex and \(l_1, \dots, l_r\) are affine, if \(x^\star, u^\star, v^\star\) satisfy the following KKT conditions, then \(x^\star\) and \((u^\star, v^\star)\) are primal &amp;amp; dual optimal with zero duality gap. (We assume that \(f, h_1, \dots, h_m, l_1, \dots, l_r\) are differentiable.) &lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;참고: &lt;a href=&quot;/contents/en/chapter12/12_00_KKT_conditions/&quot;&gt;12-01 KKT conditions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;kkt-conditions-for-the-given-primal-problem&quot;&gt;KKT conditions for the given primal problem&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
l_i &amp;amp;= 0, \quad i=1, \dots, r\\\\
u_i^\star, -h_i(x^\star) &amp;amp;\ge 0, \quad i=1, \dots, m\\\\
u_i^\star h_i(x^\star) &amp;amp;= 0, \quad i=1, \dots, m\\\\
\nabla f(x^\star) + \sum_{i=1}^m \nabla h_i(x^\star) u^\star_i + \sum_{i=1}^r \nabla l_i(x^\star) v_i^\star &amp;amp;= 0.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;central-path-equations&quot;&gt;Central path equations&lt;/h2&gt;

&lt;p&gt;Let’s also examine the conditions for determining the optimality of barrier problems.&lt;/p&gt;

&lt;h3 id=&quot;barrier-problem&quot;&gt;Barrier problem&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
    \mathop{\text{minimize}}_x &amp;amp;\quad f(x) + \tau \phi(x) \\\\
    &amp;amp;\quad l_j(x) = 0, j = 1, \ldots, r  \\\\
\end{align}\]

\[\text{where } \phi(x) = - \sum_{i=1}^m \log \big( -h_i(x) \big).\]
&lt;/blockquote&gt;

&lt;p&gt;By organizing the KKT conditions for barrier problems, we can derive the following optimality conditions. Note the differences in the inequality constraint and complementary slackness conditions compared to the KKT optimality conditions for primal problems examined earlier. (Reference: &lt;a href=&quot;/contents/en/chapter15/chapter16/15_03_01_perturbed_kkt_conditions/&quot;&gt;15-03-01 Perturbed KKT conditions&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&quot;optimality-conditions-for-barrier-problem-and-its-dual&quot;&gt;Optimality conditions for barrier problem (and its dual)&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
l_i &amp;amp;= 0, \quad i=1, \dots, r\\\\
u_i(t), -h_i(x^\star(t)) &amp;amp;\gt 0, \quad i=1, \dots, m\\\\
u_i(t) h_i(x^\star(t)) &amp;amp;= -\tau, \quad i=1, \dots, m\\\\
\nabla f(x^\star(t)) + \sum_{i=1}^m \nabla h_i(x^\star(t)) u_i(t) + \sum_{i=1}^r \nabla l_i(x^\star(t)) \hat{v}_i^\star &amp;amp;= 0,\\\\
\end{align} \\\\\]

\[\text{where } \tau = \frac{1}{t}, u_i(t) = - \frac{1}{t h_i(x^\star(t))}, \quad \hat{v} = \frac{1}{t}v.\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;special-case-linear-programming&quot;&gt;Special case: linear programming&lt;/h2&gt;

&lt;h3 id=&quot;recall-primal-problem-of-lp-in-standard-form&quot;&gt;Recall: Primal problem of LP in standard form&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad c^Tx \\\\
   \text{subject to} &amp;amp;\quad Ax = b \\\\
   &amp;amp;\quad x \ge 0
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;recall-dual-problem-of-lp&quot;&gt;Recall: Dual problem of LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{maximize}}_{s,y} &amp;amp;\quad b^Ty \\\\
   \text{subject to} &amp;amp;\quad A^Ty +  s = c \\\\
   &amp;amp;\quad s \ge 0
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Linear programming has the nice property of always satisfying strong duality due to the refined Slater’s condition, since the inequality constraints are affine. The optimality conditions for LP are as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
A^T y^\star + s^\star &amp;amp;= c\\\\
Ax^\star &amp;amp;= b\\\\
X S \mathbb{1} &amp;amp;= 0\\\\
x^\star, s^\star &amp;amp;\ge 0,\\\\
\end{align}\]

\[text{where }X = Diag(x^\star), S = Diag(s^\star)\]
&lt;/blockquote&gt;

&lt;p&gt;Note that \(X S \mathbb{1} = 0\) is equivalent to \(Xs^\star=(x_1^\star s_1^\star, \dots, x_n^\star s_n^\star)=0\). We use \(X, S\) notation for convenience in algorithms that will be introduced later.&lt;/p&gt;

&lt;h3 id=&quot;algorithms-for-linear-programming&quot;&gt;Algorithms for linear programming&lt;/h3&gt;

&lt;p&gt;We introduce two representative methods for solving LP using optimality conditions.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Simplex: A method that maintains conditions 1, 2, and 3 while gradually satisfying condition 4.&lt;/li&gt;
  &lt;li&gt;Interior-point methods: A method that maintains condition 4 while gradually satisfying conditions 1, 2, and 3. This will be covered in the next chapter.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;central-path-for-linear-programming&quot;&gt;Central path for linear programming&lt;/h2&gt;

&lt;h3 id=&quot;recall-barrier-problem-for-lp&quot;&gt;Recall: Barrier problem for LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
    \mathop{\text{minimize}}_x &amp;amp;\quad c^Tx - \tau \sum_{i=1}^n \log(x_i)\\\\
    \text{subject to} &amp;amp;\quad Ax = b, \\\\
    \text{where}  &amp;amp;\quad \tau &amp;gt; 0
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;recall-dual-problem-of-barrier-problem-for-lp&quot;&gt;Recall: Dual problem of Barrier problem for LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{maximize}}_{s,y} &amp;amp;\quad b^Ty + \tau \sum_{i=1}^n log(s_i)\\\\
   \text{subject to} &amp;amp;\quad A^Ty +  s = c \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The optimality conditions for the barrier problem of LP are as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
A^T y^\star + s^\star &amp;amp;= c\\\\
Ax^\star &amp;amp;= b\\\\
X S \mathbb{1} &amp;amp;= \tau \mathbb{1}\\\\
x^\star, s^\star &amp;amp;\gt 0,\\\\
\text{where} &amp;amp;\quad X = Diag(x^\star), S = Diag(s^\star)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Conditions 3 and 4 show differences from the KKT conditions of the primal LP.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>16-01 Lagrangian duality revisited</title>
   <link href="http://localhost:4000/contents/en/chapter16/16_01_lagrangian_duality_revisited/"/>
   <updated>2021-03-31T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter16/16_01_lagrangian_duality_revisited</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In this section, we will show that primal and dual problems can be defined using the Lagrangian, and use this definition to derive dual problems for standard form linear programming and quadratic programming. Furthermore, we will derive the dual problem for linear programming with barrier problems applied, showing that its form is the same as the barrier problem for the dual problem of linear programming.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
First, let’s define the primal problem and Lagrangian as follows.&lt;/p&gt;

&lt;h3 id=&quot;primal-problem&quot;&gt;Primal problem&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad f(x) \\\\
   \text{subject to} &amp;amp;\quad h_i(x) \leq 0, i = 1, \ldots, m \\\\
   &amp;amp;\quad l_j(x) = 0, j = 1, \ldots, r
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;lagrangian&quot;&gt;Lagrangian&lt;/h3&gt;
&lt;blockquote&gt;
\[L(x,u,v) = f(x) + \sum_{i=1}^m u_i h_i (x) + \sum_{j=1}^r v_j l_j (x)\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;
At this point, the primal problem and dual problem can be redefined as problems involving the Lagrangian.&lt;/p&gt;

&lt;h3 id=&quot;rewritten-primal-problem&quot;&gt;Rewritten primal problem&lt;/h3&gt;
&lt;blockquote&gt;
\[\min_x \mathop{\max_{u,v}}_{u \geq 0} L(x,u,v)\]
&lt;/blockquote&gt;

&lt;p&gt;The redefined primal problem does not explicitly state constraints, but it has the effect of acting like an indicator function for any infeasible \(x\) that violates the constraints.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If \(h_i(\hat{x}) \gt 0\) for some \(i \in [1, m]\), then \(\hat{x}\) is an infeasible point. In this case, \(u_i h_i(\hat{x})\) diverges to \(\infty\) due to \(\max_{u,v}\), so it acts as an indicator function for any \(\hat{x}\) that violates the inequality constraint.&lt;/li&gt;
  &lt;li&gt;If \(l_i(\hat{x}) \neq 0\) for some \(i \in [1, r]\), then \(\hat{x}\) is an infeasible point. In this case, \(v_i l_i(\hat{x})\) diverges to \(\infty\) due to \(\max_{u,v}\), so it acts as an indicator function for any \(\hat{x}\) that violates the equality constraint.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;rewritten-dual-problem&quot;&gt;Rewritten dual problem&lt;/h3&gt;
&lt;blockquote&gt;
\[\mathop{\max_{u,v}}_{u \geq 0} \min_x L(x,u,v)\]
&lt;/blockquote&gt;

&lt;p&gt;In the dual problem, relaxation of the domain is necessary, so it should not act as an indicator function for the constraints of the primal problem. Since taking \(\min_x\) for fixed \(u, v\) cannot enforce the constraints of the primal problem, the redefined dual problem also has the effect of relaxing the domain. (Reference: &lt;a href=&quot;/contents/en/chapter11/11_02_Lagrange_dual_function/&quot;&gt;11-02 Lagrange dual function&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&quot;weak-and-strong-duality&quot;&gt;Weak and strong duality&lt;/h2&gt;
&lt;p&gt;Let’s revisit weak duality and strong duality.&lt;/p&gt;

&lt;h3 id=&quot;theorem-weak-duality&quot;&gt;Theorem: weak duality&lt;/h3&gt;
&lt;p&gt;When \(p\) and \(d\) are the optimal values for the primal problem and dual problem respectively, the following is always satisfied:&lt;/p&gt;

\[p \ge d\]

&lt;h3 id=&quot;theorem-strong-duality-refined-slaters-condition&quot;&gt;Theorem: strong duality (refined Slater’s condition)&lt;/h3&gt;
&lt;p&gt;For the domain set \(D\), assume that \(f, h_1, \dots, h_p\) are convex and \(h_{p+1}, \dots, h_m, l_1, \dots, l_r\) are affine. If there exists \(\hat{x} \in \text{relint}(D)\) that satisfies the following:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
h_i(\hat{x}) \ &amp;amp; \lt 0, \ &amp;amp;&amp;amp; i=1, \dots, p \\
h_i(\hat{x}) \ &amp;amp; \le 0, \ &amp;amp;&amp;amp; i=p+1, \dots, m \\
l_j(\hat{x}) \ &amp;amp; = 0, \ &amp;amp;&amp;amp; j = 1, \dots, r
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;then \(p = d\) is guaranteed for the optimal values \(p, d\) of the primal problem and dual problem.&lt;/p&gt;

&lt;h2 id=&quot;example-linear-programming&quot;&gt;Example: linear programming&lt;/h2&gt;
&lt;p&gt;Let’s derive the dual problem of linear programming using the dual problem defined earlier.&lt;/p&gt;

&lt;h3 id=&quot;primal-problem-of-lp-in-standard-form&quot;&gt;Primal problem of LP in standard form&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad c^Tx \\\\
   \text{subject to} &amp;amp;\quad Ax = b \\\\
   &amp;amp;\quad x \ge 0
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;According to the previous definition, the dual problem of the above problem is as follows:&lt;/p&gt;

\[\mathop{\max_{s,y}}_{s\ge0} \min_{x} \: L(x,s,y) = \mathop{\max_{s,y}}_{s\ge0} \min_{x} \: c^Tx - s^Tx + (b-Ax)^T y\]

&lt;p&gt;We substitute the relationship \(c=A^Ty +s\) obtained by solving \(\nabla_x L = 0\) into the dual problem.&lt;/p&gt;

\[\mathop{\max_{s,y}}_{s\ge0} \: (A^Ty + s)^Tx - s^Tx + (b-Ax)^Ty \quad \text{ s.t. } c=A^Ty +s\]

&lt;p&gt;This can be organized as follows:&lt;/p&gt;

&lt;h3 id=&quot;dual-problem-of-lp&quot;&gt;Dual problem of LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{maximize}}_{s,y} &amp;amp;\quad b^Ty \\\\
   \text{subject to} &amp;amp;\quad A^Ty +  s = 0 \\\\
   &amp;amp;\quad s \ge 0
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;example-convex-quadratic-programming&quot;&gt;Example: convex quadratic programming&lt;/h2&gt;
&lt;p&gt;Now let’s derive the dual problem of quadratic programming using the dual problem defined earlier.&lt;/p&gt;

&lt;h3 id=&quot;primal-problem-of-qp-in-standard-form&quot;&gt;Primal problem of QP in standard form&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad \frac{1}{2} x^T Q x + c^Tx \\
   \text{subject to} &amp;amp;\quad Ax = b \\
   &amp;amp;\quad x \ge 0, \\

\end{align}\]

\[\text{where } Q \text{ is symmetric and positive semidefinite.}\]
&lt;/blockquote&gt;

&lt;p&gt;According to the previous definition, the dual problem of the above problem is as follows:&lt;/p&gt;

\[\mathop{\max_{s,y}}_{s\ge0} \min_{x} \: L(x,s,y) = \mathop{\max_{s,y}}_{s\ge0} \min_{x} \:  \frac{1}{2} x^T Q x + c^Tx - s^Tx + (b-Ax)^T y\]

&lt;p&gt;We substitute the relationship \(Qx = A^Ty +s - c\) obtained by solving \(\nabla_x L = 0\) into the dual problem.&lt;/p&gt;

\[\begin{align}
&amp;amp;\mathop{\max_{s,y,x}}_{s\ge0} \: \frac{1}{2} x^T (A^Ty +s - c) + c^Tx - s^Tx + (b-Ax)^T y \quad \text{ s.t. } Qx = A^Ty +s - c\\\\
&amp;amp;= \mathop{\max_{s,y,x}}_{s\ge0} \: x^T (A^Ty +s - c) + c^Tx - s^Tx + (b-Ax)^T y -  \frac{1}{2} x^T (A^Ty +s - c) \quad \text{ s.t. } Qx = A^Ty +s - c\\\\
&amp;amp;= \mathop{\max_{s,y,x}}_{s\ge0}  \: b^Ty - \frac{1}{2} x^T (A^Ty +s - c) \quad  \text{ s.t. } Qx = A^Ty +s - c\\\\
&amp;amp;= \mathop{\max_{s,y,x}}_{s\ge0}  \: b^Ty - \frac{1}{2} x^T Q x \quad \text{ s.t. } Qx = A^Ty +s - c
\end{align}\]

&lt;p&gt;This can be organized as follows:&lt;/p&gt;

&lt;h3 id=&quot;dual-problem-of-qp&quot;&gt;Dual problem of QP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{maximize}}_{s,y,x} &amp;amp;\quad b^Ty - \frac{1}{2} x^T Q x\\\\
   \text{subject to} &amp;amp;\quad A^Ty +  s - c = Qx \\\\
   &amp;amp;\quad s \ge 0
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The dual problem of a quadratic problem is also a quadratic problem.&lt;/p&gt;

&lt;h2 id=&quot;example-barrier-problem-for-linear-programming&quot;&gt;Example: barrier problem for linear programming&lt;/h2&gt;
&lt;p&gt;The barrier problem for linear programming is defined as follows:&lt;/p&gt;

&lt;h3 id=&quot;barrier-problem-for-lp&quot;&gt;Barrier problem for LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{minimize}}_x &amp;amp;\quad c^Tx - \tau \sum_{i=1}^n \log(x_i)\\
   \text{subject to} &amp;amp;\quad Ax = b, \\
\end{align}\]

\[\text{where }\tau &amp;gt; 0.\]
&lt;/blockquote&gt;

&lt;p&gt;According to the previous definition, the dual problem of the above problem is as follows:
\(\begin{align}
\max_{y} \min_{x} \: L(x,y) &amp;amp;= \max_{y} \min_{x} \:  c^Tx - \tau \sum_{i=1}^n \log(x_i) + (b-Ax)^T y\\\\
&amp;amp;=  \max_{y} \min_{x} \:  \underbrace{(c-A^Ty)}_{s \doteq c-A^Ty}x - \tau \sum_{i=1}^n \log(x_i) + b^Ty\\\\
&amp;amp;= \max_{y} \min_{x} \: \sum_{i=1}^n \big( s_i^Tx_i - \tau  \log(x_i) \big) + b^Ty  \quad \text{ s.t. } A^Ty +s = c
\end{align}\)&lt;/p&gt;

&lt;p&gt;Here, \(\sum_{i=1}^n \big( s_i^Tx_i - \tau  \log(x_i) \big) + b^Ty\) will be minimized when \(x_i = \frac{\tau}{s_i}\). Therefore, let’s substitute \(\frac{\tau}{s_i}\) for \(x_i\) in the dual problem.&lt;/p&gt;

\[\begin{align}
&amp;amp;\max_{s,y} \: b^Ty + n\tau - \tau \sum_{i=1}^n log(\frac{\tau}{s_i}) \quad \text{ s.t. } A^Ty +s = c\\\\
&amp;amp;= \max_{s,y} \: b^Ty + \tau \sum_{i=1}^n log(s_i) + n\tau - n\tau\log(\tau) \quad \text{ s.t. } A^Ty +s = c\\\\
\end{align}\]

&lt;p&gt;Since \(n\tau - n\tau\log(\tau)\) can be omitted from the problem, the dual problem can be organized as follows:&lt;/p&gt;

&lt;h3 id=&quot;dual-problem-of-barrier-problem-for-lp&quot;&gt;Dual problem of Barrier problem for LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   \mathop{\text{maximize}}_{s,y} &amp;amp;\quad b^Ty + \tau \sum_{i=1}^n log(s_i)\\\\
   \text{subject to} &amp;amp;\quad A^Ty +  s = c \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;We can see that this problem is identical to the barrier problem for the dual problem of linear programming.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>21-06 Faster convergence with subprogram parametrization - example of the 2d fused lasso problem</title>
   <link href="http://localhost:4000/contents/vi/chapter21/21_06_Faster_convergence_with_subprogram_parametrization_-_example_of_the_2d_fused_lasso_problem/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter21/21_06_Faster_convergence_with_subprogram_parametrization_:_example_of_the_2d_fused_lasso_problem</id>
   <content type="html">&lt;h1 id=&quot;faster-convergence-with-subprogram-parametrization&quot;&gt;Faster Convergence with Subprogram Parametrization&lt;/h1&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;One very interesting property of ADMM is that when solving problems, if we parametrize the small subproblems in a special way, it can show much faster convergence performance than general methods. In the previous consensus ADMM example, the updates optimize over blocks of variables, which is similar to block coordinate descent. Therefore, ADMM can also achieve fast convergence by updating blocks of variables in nearly orthogonal directions.&lt;/p&gt;

&lt;h2 id=&quot;2d-fused-lasso-example&quot;&gt;2D Fused Lasso Example&lt;/h2&gt;

&lt;p&gt;In this section, we will demonstrate the above concepts through examples, designing auxiliary constraints so that the primal updates are in de-correlated directions.&lt;/p&gt;

&lt;p&gt;For detailed information, see [RT16], [WSK14], [BS14].&lt;/p&gt;

&lt;p&gt;Let’s examine the 2D fused lasso or 2D total variation denoising problem, which was one of the examples we looked at in &lt;a href=&quot;/contents/vi/chapter01/01_01_optimization_problems/&quot;&gt;Chapter 1&lt;/a&gt;. Given an image \(Y\in \mathbb{R}^{d\times d}\), the problem is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{\Theta}\frac{1}{2}||Y-\Theta||^{2}_{F}+\lambda \sum_{i,j}(|\Theta_{i,j}-\Theta_{i+1,j}|+|\Theta_{i,j}-\Theta_{\Theta_{i,j+1}}|).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In this problem, there is a parameter for each pixel of the image, and this parameter matrix is \(\Theta\in \mathbb{R}^{d\times d}\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/2dfussed.png&quot; alt=&quot;[Fig 1] Interpretation of the penalty term in 2d fussed lasso[3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Interpretation of the penalty term in 2d fussed lasso[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;[Fig 1] visually shows the penalty term, which is the second term of the objective function. As can be seen from the defined problem, it aims to reduce the differences between a pixel and its adjacent horizontal and vertical pixels. That is, this penalty term makes the values of neighboring adjacent pixels similar.&lt;/p&gt;

&lt;h2 id=&quot;vector-form&quot;&gt;Vector Form&lt;/h2&gt;

&lt;p&gt;Summarizing the penalty term as an operator, the problem becomes:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\min_{\theta}\frac{1}{2}||y-\theta||^{2}_{F} + \lambda||D\theta||_{1}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(D\in \mathbb{R}^{m\times n}\) is the 2D difference operator corresponding to the original equation.&lt;/p&gt;

&lt;h2 id=&quot;forms-of-admm-updates-for-the-2d-fused-lasso-problem&quot;&gt;Forms of ADMM updates for the 2d fused lasso problem&lt;/h2&gt;
&lt;h2 id=&quot;forms-of-admm-updates-for-the-2d-fused-lasso-problem-1&quot;&gt;Forms of ADMM Updates for the 2D Fused Lasso Problem&lt;/h2&gt;

&lt;p&gt;Now we want to create ADMM steps in two ways by applying auxiliary constraints.&lt;/p&gt;

&lt;p&gt;The first approach is to derive ADMM from the vector form created through the 2D difference operator.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{\theta, z}\frac{1}{2}||y-\theta||^{2}_{2}+\lambda||z||_{1} \qquad \text{subject to   }z = D\theta,
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The ADMM steps are then derived as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\theta^{(k)} &amp;amp;= (I+\rho D^{T}D)^{-1}(y+\rho D^{T}(z^{(k-1)}+w^{(k-1)}))\\\\
z^{(k)} &amp;amp;= S_{\frac{\lambda}{\rho}}(D\theta^{(k)}-w^{(k-1)})\\\\
w^{(k)} &amp;amp;= w^{(k-1)}+z^{(k-1)}-D\theta ^{(k)}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;computational-complexity---vector-form&quot;&gt;Computational Complexity - Vector Form&lt;/h2&gt;

&lt;p&gt;Solving for \(\theta\) is equivalent to solving the linear system \((I+\rho D^{T}D)^{-1}\). Here, \(D^{T}D\) becomes the Laplacian matrix \(L=D^{T}D\) of the 2D grid, which can be solved in \(O(n)\) operations. The \(z\) update also requires \(O(n)\) operations since it involves applying the soft thresholding operator \(S_{t}\). Therefore, solving ADMM in vector form takes \(O(n)\) time.&lt;/p&gt;

&lt;h2 id=&quot;matrix-form-admm&quot;&gt;Matrix Form ADMM&lt;/h2&gt;

&lt;p&gt;The second approach is to derive ADMM in matrix form, identical to the original problem definition.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{\Theta, Z} &amp;amp;&amp;amp;\frac{1}{2}||Y-\Theta||^{2}_{F}+\lambda\sum_{i,j}(|\Theta_{i,j}-\Theta_{i+1,j}+|Z_{i+1,j}-Z_{i,j+1}|)\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;\Theta = Z
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The ADMM steps are as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
\Theta_{\cdot \\ , j}^{(k)} &amp;amp;= FL^{1d}_{ \frac{\lambda}{(1+\rho)} } \bigg( \frac{ Y+\rho( Z^{(k-1)}_{\cdot \\ , j}-W_{\cdot \\ ,j}^{(k-1)} ) } {1+\rho} \bigg),\qquad j=1,...,d\\\\
Z_{i, \cdot}^{(k)} &amp;amp;= FL^{1d}_{\frac{\lambda}{\rho}} \bigg(\Theta_{i, \cdot}^{(k)} + W_{i, \cdot}^{(k-1)} \bigg), \qquad j=1,...,d\\\\
W^{(k)} &amp;amp;= W^{(k-1)} + \Theta^{(k)} - Z^{(k)} \\\\
\end{align}\)
where \(FL_{\tau}^{1d}(a)\) is the 1D fused lasso defined as \(FL_{\tau}^{1d}(a) = \underset{x}{\operatorname{argmin}}\frac{1}{2}||a-x||^{2}_{2}+\tau\sum_{i=1}^{d-1}|x_{i}-x_{i+1}|\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;computational-complexity---matrix-form&quot;&gt;Computational Complexity - Matrix Form&lt;/h2&gt;

&lt;p&gt;The matrix form ADMM can also be performed with \(O(n)\) time complexity. Both \(\Theta\) and \(Z\) are in the form of 1D fused lasso, which has \(O(n)\) time complexity.&lt;/p&gt;

&lt;p&gt;[Fig 2] shows how the original penalty term is separated into 1D fused lasso problems.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/2dfussedlasso.png&quot; alt=&quot;[Fig 2]  Interpretation of the matrix form ADMM updates for 2d fused lasso[3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2]  Interpretation of the matrix form ADMM updates for 2d fused lasso[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;image-denoising-experiments&quot;&gt;Image denoising experiments&lt;/h2&gt;
&lt;h2 id=&quot;image-denoising-experiments-1&quot;&gt;Image Denoising Experiments&lt;/h2&gt;

&lt;p&gt;Now let’s revisit the image denoising problem we examined in Chapter 1.&lt;/p&gt;

&lt;p&gt;[Fig 3] shows the data and denoised images. [Fig 4] shows a comparison of the two ADMM methods. The “specialized” ADMM in matrix form, which defines constraints by decomposing in vertical/horizontal directions, shows much faster convergence performance than the “standard ADMM” derived in vector form.&lt;/p&gt;

&lt;p&gt;[Fig 5] shows the image quality according to ADMM iterations.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/ll1.png&quot; alt=&quot;[Fig 3]  Data, exact solution image(300x200 image : n = 60,000).  
left : original image before denoising, right : the exact solution of denoised image[3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 3]  Data, exact solution image(300x200 image : n = 60,000).
left : original image before denoising, right : the exact solution of denoised image[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/ll2.png&quot; alt=&quot;[Fig 4]  Convergence curves of two ADMM algorithms. black : standard(vector form), red : specialized(matrix form) [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 4]  Convergence curves of two ADMM algorithms. black : standard(vector form), red : specialized(matrix form) [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/admm_iteration_visualized.png&quot; alt=&quot;[Fig 5]  ADMM iterates visualized after k = 10, 30, 50, 100 iterations [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 5]  ADMM iterates visualized after k = 10, 30, 50, 100 iterations [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>21-05 Consensus ADMM</title>
   <link href="http://localhost:4000/contents/vi/chapter21/21_05_Consensus_ADMM/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter21/21_05_Consensus_ADMM</id>
   <content type="html">&lt;h1 id=&quot;consensus-admm&quot;&gt;Consensus ADMM&lt;/h1&gt;

&lt;h2 id=&quot;basic-consensus-admm&quot;&gt;Basic Consensus ADMM&lt;/h2&gt;

&lt;p&gt;Consider the following problem:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\min_{x}\sum^{B}_{i=1} f_{i}(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;To solve this problem with ADMM, we need to introduce constraints. Here, we want to transform the equation into a form that is easy to operate in parallel. This approach, called consensus ADMM, reparametrizes the equation as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x_{1},...,x_{B},x} &amp;amp;&amp;amp;\sum^{B}_{i=1} f_{i}(x_{i})\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;x_{i}=x, i = 1,...B
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-algorithm&quot;&gt;ADMM Algorithm&lt;/h2&gt;

&lt;p&gt;This allows us to compute decomposable ADMM steps:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x^{(k)}_{i} &amp;amp;= \underset{x_{i}}{\operatorname{argmin}} f_{i}(x_{i})+\frac{\rho}{2}||x_{i}-x^{(k-1)}+w_{i}^{(k-1)}||_{2}^{2}, i=1,...B\\\\
x^{(k)} &amp;amp;=\frac{1}{B}\sum_{i=1}^{B}(x_{i}^{(k)}+w_{i}^{(k-1)})\\\\
w_{i}^{(k)} &amp;amp;=w_{i}^{(k-1)}+x_{i}^{(k)}-x^{(k)}, i=1,...,B
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;simplified-form&quot;&gt;Simplified Form&lt;/h2&gt;

&lt;p&gt;Additionally, we can define \(\overline{x}=\frac{1}{B}\sum_{i=1}^{B}x_{i}, \overline{w}=\frac{1}{B}\sum_{i=1}^{B}w_{i}\). With this, we can easily verify that \(\overline{w}^{(k)}=0\) for iterations \(k&amp;gt;1\), and the second equation of the ADMM update simplifies to \(x^{(k)}=\overline{x}^{(k)}\). Therefore, we can simplify the ADMM update equations as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x^{(k)}_{i} &amp;amp;= \underset{x_{i}}{\operatorname{argmin}} f_{i}(x_{i})+\frac{\rho}{2}||x_{i}-\overline{x}^{(k-1)}+w_{i}^{(k-1)}||_{2}^{2},  i=1,...B\\\\
w_{i}^{(k)} &amp;amp;=w_{i}^{(k-1)}+x_{i}^{(k)}-\overline{x}^{(k)},  i=1,...,B.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;intuition&quot;&gt;Intuition&lt;/h2&gt;

&lt;p&gt;The \(x_{i}\) updates for \(i = 1,...,B\) can be computed in parallel.&lt;/p&gt;

&lt;p&gt;From the simplified equations, we can gain intuition about consensus ADMM. Each \(x_{i}\) update tries to minimize \(f_{i}(x_{i})\) while simultaneously using \(l_{2}\) regularization to align each \(x_{i}\) with the average \(\overline{x}\). If \(x_{i}\) becomes larger than the average, \(w_{i}\) increases. Therefore, the regularization in the next step will reduce the enlarged \(x_{i}\).&lt;/p&gt;

&lt;h2 id=&quot;general-consensus-admm&quot;&gt;General consensus ADMM&lt;/h2&gt;
&lt;h2 id=&quot;general-consensus-admm-1&quot;&gt;General Consensus ADMM&lt;/h2&gt;

&lt;p&gt;Consensus ADMM can be generalized to a more general form. Let’s look at the form of problems with affine transformations of \(x\) and arbitrary function \(g\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{x}\sum_{i=1}^{B} f_{i}(a^{T}_{i}x+b_{i})+g(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For this equation as well, we reparameterize by adding constraints:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x_{1},..x_{B},x} &amp;amp;&amp;amp;\sum^{B}_{i=1}f_{i}(a_{i}^{T}x+b)+g(x)\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;x_{i} = x, i=1,...B
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;We can then derive decomposable ADMM updates:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x_{i}^{(k)} &amp;amp;= \underset{x_{i}}{\operatorname{argmin}}f_{i}(a_{i}^{T}x+b_{i})+\frac{\rho}{2}||x_{i}-x^{(k-1)}+w_{i}^{(k-1)}||^{2}_{2}+g(x)\\\\
x^{(k)}&amp;amp;=\underset{x}{\operatorname{argmin}} \frac{B\rho}{2}||x-\overline{x}^{(k)}-\overline{w}^{(k-1)}||^{2}_{2}+g(x)\\\\
w_{i}^{(k)}&amp;amp;=w_{i}^{(k-1)}+x_{i}^{(k)}-x^{(k)}, i=1,...B
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;key-differences&quot;&gt;Key Differences&lt;/h2&gt;

&lt;p&gt;The differences between generalized consensus ADMM and the consensus ADMM derived above can be summarized as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Because the ADMM step equations do not simplify, \(\overline{w}^{(k)}=0\) is no longer satisfied.&lt;/li&gt;
  &lt;li&gt;\(x_{i}, i=1,...,B\) can be updated in parallel.&lt;/li&gt;
  &lt;li&gt;Each \(x_{i}\) update can be thought of as minimizing the corresponding partial loss with \(l_2\) regularization.&lt;/li&gt;
  &lt;li&gt;The \(x\) update is a proximal operation for the arbitrary function \(g\) (generally a regularizer).&lt;/li&gt;
  &lt;li&gt;Different ADMM algorithms are derived depending on how the reparameterization is done.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more detailed information, see the &lt;a href=&quot;/contents/vi/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;reference papers&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>21-04 Example - Sparse subspace estimation and sparse plus low rank decomposition</title>
   <link href="http://localhost:4000/contents/vi/chapter21/21_04_Example_-_Sparse_subspace_estimation_and_sparse_plus_low_rank_decomposition/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter21/21_04_Example_:_Sparse_subspace_estimation_and_sparse_plus_low_rank_decomposition</id>
   <content type="html">&lt;h1 id=&quot;example-sparse-subspace-estimation-and-sparse-plus-low-rank-decomposition&quot;&gt;Example: Sparse Subspace Estimation and Sparse Plus Low Rank Decomposition&lt;/h1&gt;

&lt;h2 id=&quot;sparse-subspace-estimation&quot;&gt;Sparse Subspace Estimation&lt;/h2&gt;

&lt;p&gt;Given \(S=X^{T}X, X\in \mathbb{R}^{n\times p}\), consider the problem of finding a projection that minimizes the Frobenius norm distance between the original \(X\) and the projected \(X\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{P} &amp;amp;&amp;amp;||X-XP||^{2}_{F}\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;\text{rank(P)=k where P is a projection matrix}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This problem is non-convex because the set of projection matrices is not a convex set. However, it is known to be equivalent to the following convex problem [&lt;a href=&quot;/contents/vi/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;VCLR13&lt;/a&gt;]. This is also called the subspace estimation problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{Y} &amp;amp;&amp;amp;tr(SY)\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;Y\in F_{k} = \left\{Y\in \mathbb{S}^{p} : 0 \preceq Y \preceq I, tr(Y) = k \right\}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;[VCLR13] discusses solving the sparse version (with added L1 norm) of the subspace estimation problem. For detailed derivation, please refer to the corresponding paper.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{Y} &amp;amp;&amp;amp;tr(SY)-\lambda ||Y||_{1}\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;Y\in F_{k} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(F_{k}\) is the Fantope of order k, as defined in the equation above.&lt;/p&gt;

&lt;p&gt;When \(\lambda = 0\), the above problem is equivalent to standard PCA.&lt;/p&gt;

&lt;p&gt;This problem has an SDP form and can be solved using interior point methods. However, this approach is complex to implement and becomes very slow as the problem size increases.&lt;/p&gt;

&lt;h2 id=&quot;admm-formulation&quot;&gt;ADMM Formulation&lt;/h2&gt;

&lt;p&gt;To solve this problem with ADMM, we reformulate it as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{Y,Z} &amp;amp;&amp;amp;-tr(SY)+I_{F_{k}}(Y) + \lambda||Z||_{1}\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;Y = Z.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-algorithm&quot;&gt;ADMM Algorithm&lt;/h2&gt;

&lt;p&gt;Summarizing the problem, the ADMM steps are as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
Y^{+} &amp;amp;=  \underset{Y}{\operatorname{argmin}} -tr(SY) + I_{F_{k}}(Y)+\frac{\rho}{2}||Y-Z+W||^{2}_{F}\\\\
&amp;amp;=\underset{Y\in F_{k}}{\operatorname{argmin}} \frac{1}{2}||Y-Z+W-\frac{S}{\rho}||^{2}_{F}\\\\
&amp;amp;=P_{F_{k}}(Z-W+\frac{S}{\rho})\\\\
Z^{+} &amp;amp; = \underset{Z}{\operatorname{argmin}}\lambda||Z||_{1}+\frac{\rho}{2}||Y^{+}-Z+W||^{2}_{F}\\\\
&amp;amp;=S_{\frac{\lambda}{\rho}}(Y^{+}+W)\\\\
W^{+} &amp;amp;=W+Y^{+}-Z^{+}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(P_{F_{k}}\) is the fantope projection operator. This is defined by clipping the eigendecomposition \(A= U\Sigma U^{T}, \Sigma = diag(\sigma_{1},...\sigma_{p})\) [&lt;a href=&quot;/contents/vi/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;VCLR13&lt;/a&gt;]:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
P_{F_{k}}(A) = U\Sigma_{\theta}U^{T}, \: \Sigma_{\theta} = diag(\sigma_{1}(\theta),...\sigma_{p}(\theta))
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where each \(\sigma_{i}(\theta) = \min\left\{\max\left\{\sigma_{i}-\theta,0\right\},1\right\}\) and \(\sum^{p}_{i=1}\sigma_{i}(\theta)=k\).&lt;/p&gt;

&lt;h2 id=&quot;sparse-plus-low-rank-decomposition&quot;&gt;Sparse plus low rank decomposition&lt;/h2&gt;
&lt;p&gt;Given \(M\in \mathbb{R}^{n\times m}\), the sparse plus low rank decomposition problem is as follows [&lt;a href=&quot;/contents/vi/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;CLMW09&lt;/a&gt;]:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{L,S} &amp;amp;&amp;amp;||L||_{tr}+\lambda||S||_{1}\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;L+S=M
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;problem-description&quot;&gt;Problem Description&lt;/h2&gt;

&lt;p&gt;The goal of this problem is to decompose the observed matrix \(M\) into a low rank matrix \(L\) and a sparse matrix \(S\). The first term of the objective function is the trace penalty of \(L\), which minimizes the sum of singular values of \(L\). The second term uses the \(l_{1}\) norm on matrix \(S\) to induce sparsity in \(S\). \(\lambda\) is a tuning parameter that balances these two terms. Both the trace norm and \(l_{1}\) norm are non-smooth, and generally the trace norm is known to be difficult to optimize. Like the sparse subspace estimation problem, this problem has an SDP form and can be solved using interior point methods, but this is also complex and slow. For this problem, ADMM provides somewhat easier update steps.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
L^{+} &amp;amp;= S^{tr}_{\frac{1}{\rho}}(M-S+W)\\\\
S^{+} &amp;amp;= S^{l_{1}}_{\frac{\lambda}{\rho}}(M-L^{+}+W)\\\\
W^{+} &amp;amp;= W+M-L^{+}-S^{+}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(S^{tr}_{\frac{1}{\rho}}\) is matrix soft-thresholding and \(S^{l_{1}}_{\frac{\lambda}{\rho}}\) is elementwise soft-thresholding.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/candes.png&quot; alt=&quot;[Fig 1] Example of sparse plue low rank decomposition on surveliance camera[3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Example of sparse plue low rank decomposition on surveliance camera[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;application-example&quot;&gt;Application Example&lt;/h2&gt;

&lt;p&gt;[Fig 1] shows an example of applying sparse plus low rank decomposition to surveillance camera video analysis. From surveillance cameras that film a fixed area for a long time, we can easily separate the low rank part that shares most frames, and the sparse part extracts characteristic parts from specific frames. For example, in [Fig 1], the middle column represents the low rank part and the right column represents the sparse part. As can be confirmed, the low rank part contains background information that appears in almost all frames, and the sparse part contains only characteristic parts that appear only in specific frames.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>21-03 Example - Lasso regression and group lasso Regression</title>
   <link href="http://localhost:4000/contents/vi/chapter21/21_03_Example_-_Lasso_regression_and_group_lasso_Regression/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter21/21_03_Example_:_Lasso_regression_and_group_lasso_Regression</id>
   <content type="html">&lt;h2 id=&quot;lasso-regression&quot;&gt;Lasso regression&lt;/h2&gt;
&lt;p&gt;Let’s solve the Lasso regression problem using ADMM.&lt;/p&gt;

&lt;p&gt;Given \(y\in \mathbb{R}^{n}, X\in \mathbb{R}^{n\times p}\), the Lasso problem is:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\min_{\beta}\frac{1}{2}||y-X\beta||^{2}_{2}+\lambda||\beta||_{1}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In previous chapters, we have solved the Lasso problem using various methods, including &lt;a href=&quot;/contents/vi/chapter09/09_01_proximal_gradient_descent/&quot;&gt;proximal gradient descent (ISTA)&lt;/a&gt;, &lt;a href=&quot;/contents/vi/chapter09/09_05_03_example_FISTA/&quot;&gt;accelerated proximal gradient descent (FISTA)&lt;/a&gt;, &lt;a href=&quot;/contents/en/chapter15/chapter16/15_barrier_method/&quot;&gt;barrier method&lt;/a&gt;, and &lt;a href=&quot;/contents/vi/chapter17/17_primal_dual_interior_point_method/&quot;&gt;primal-dual interior-point method&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As with deriving the dual formulation, the performance of the ADMM algorithm depends on how we set up the auxiliary variables. Among many ways to set auxiliary variables, the following form is known to be one of the most effective:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{\beta, \alpha} &amp;amp;&amp;amp;||y-X\beta||^{2}_{2}+\lambda||\alpha||_{1}\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;\beta-\alpha= 0.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-updates&quot;&gt;ADMM Updates&lt;/h2&gt;

&lt;p&gt;The ADMM updates for this formulation are derived as follows. The \(\beta\) update involves a quadratic function, so we can find the minimum by differentiation. The \(\alpha\) update is similar to the problem covered in &lt;a href=&quot;/contents/vi/chapter07/07_03_04_example_soft-thresholding/&quot;&gt;Chapter 7 (07-03-04)&lt;/a&gt;, which has a soft-thresholding solution.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\beta^{+} &amp;amp;= \underset{\beta}{\operatorname{argmin}}\frac{1}{2}||y-X\beta||^{2}_{2}+\frac{\rho}{2}||\beta-\alpha+w||^{2}_{2}\\\\
&amp;amp;= (X^{T}X+\rho I)^{-1}(X^{T}y+\rho (\alpha-w))\\\\
\alpha^{+} &amp;amp;= \underset{\alpha}{\operatorname{argmin}}\lambda||\alpha||_{1}+\frac{\rho}{2}||\beta^{+}-\alpha+w||^{2}_{2}\\\\
&amp;amp;= S_{\frac{\lambda}{\rho}}(\beta^{+}+w)\\\\
w^{+} &amp;amp;=w+\beta^{+}-\alpha^{+}
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;key-properties&quot;&gt;Key Properties&lt;/h2&gt;

&lt;p&gt;This result has the following characteristics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The matrix \(X^{T}X+\rho I\) is always invertible regardless of \(X\) since \(\rho&amp;gt;0\).&lt;/li&gt;
  &lt;li&gt;If we precompute the factorization (typically Cholesky factorization) in \(O(p^{3})\) flops, then the \(\beta\) update takes \(O(p^{2})\) flops.&lt;/li&gt;
  &lt;li&gt;The \(\alpha\) update applies the soft-thresholding operator \(S_{t}\), which is identical to the content in &lt;a href=&quot;/contents/vi/chapter07/07_03_04_example_soft-thresholding/&quot;&gt;07-03-04&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The ADMM steps are “almost” equivalent to repeatedly soft-thresholding ridge regression coefficients.&lt;/li&gt;
  &lt;li&gt;Different values of \(\rho\) produce different results.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/lasso.png&quot; alt=&quot;[Fig 1] Comparison of various algorithms for lasso regression (50 instances with n = 100, p = 20) [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Comparison of various algorithms for lasso regression (50 instances with n = 100, p = 20) [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;performance-comparison&quot;&gt;Performance Comparison&lt;/h2&gt;

&lt;p&gt;[Fig 1] compares the convergence of various algorithms for the Lasso regression problem. All algorithms have the same computational complexity per iteration. As can be seen from the convergence speed in the graph, ADMM has similar convergence speed to proximal gradient descent (black). Accelerated proximal gradient descent (red) has “Nesterov ripples” but shows slightly faster convergence speed. We can also confirm that ADMM shows different convergence speeds according to the \(\rho\) value. Coordinate descent (green), which will be discussed later in &lt;a href=&quot;/contents/vi/chapter23/23_Coordinate_Descent/&quot;&gt;Chapter 23&lt;/a&gt;, uses more information about the problem and therefore has faster convergence speed compared to other methods. The disadvantage of coordinate descent is that there are conditions required for its application.&lt;/p&gt;

&lt;p&gt;If the \(\rho\) value is set too large, the weight of minimizing the objective function \(f+g\) becomes small, and if the \(\rho\) value is set too small, feasibility decreases. Therefore, setting an appropriate \(\rho\) value is important. For detailed information, see [BPCPE] discussed in the &lt;a href=&quot;/contents/vi/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;Chapter 21 reference papers&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;group-lasso-regression&quot;&gt;Group Lasso Regression&lt;/h2&gt;

&lt;p&gt;Similarly, let’s examine solving the Group Lasso regression problem with ADMM. The Group Lasso regression problem is defined as follows for \(y\in \mathbb{R}^{n}, X\in \mathbb{R}^{n \times p}\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{\beta}\frac{1}{2}||y-X\beta||^{2}_{2}+\lambda\sum^{G}_{g=1} c_{g}||\beta_{(g)}||_{2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;As with Lasso regression, we can reformulate the problem:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{\beta,\alpha} &amp;amp;&amp;amp;\frac{1}{2}||y-X\beta||^{2}_{2}+\lambda\sum^{G}_{g=1} c_{g}||\alpha_{(g)}||_{2}\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;\beta-\alpha=0.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The ADMM steps are as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\beta^{+} &amp;amp;= (X^{T}X+\rho I)^{-1}(X^{T}y+\rho (\alpha-w))\\\\
\alpha^{+} &amp;amp;= R_{c_{g}\frac{\lambda}{\rho}}(\beta^{+}_{(g)}+w_{(g)})\qquad \text{g = 1,...G}\\\\
w^{+} &amp;amp;=w+\beta^{+}-\alpha^{+}
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;properties-of-group-lasso-admm&quot;&gt;Properties of Group Lasso ADMM&lt;/h2&gt;

&lt;p&gt;This result has the following characteristics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The matrix \(X^{T}X+\rho I\) is always invertible regardless of \(X\) since \(\rho&amp;gt;0\).&lt;/li&gt;
  &lt;li&gt;If we precompute the factorization (typically Cholesky factorization) in \(O(p^{3})\) flops, then the \(\beta\) update takes \(O(p^{2})\) flops.&lt;/li&gt;
  &lt;li&gt;The \(\alpha\) update applies the group soft-thresholding operator \(R_{t}\), which is defined as follows:&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
R_{t}(x) = (1-\frac{x}{\lVert x \rVert_{2}})_{+}x
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>21-02 Connection to proximal operators</title>
   <link href="http://localhost:4000/contents/vi/chapter21/21_02_Connection_to_proximal_operators/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter21/21_02_Connection_to_proximal_operators</id>
   <content type="html">&lt;h1 id=&quot;connection-to-proximal-operators&quot;&gt;Connection to Proximal Operators&lt;/h1&gt;

&lt;p&gt;Consider an optimization problem with a single variable that separates into two functions:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\min_{x} f(x)+g(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This can also be expressed by adding a constraint:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\min_{x, z} f(x)+g(z) \qquad \text{subject to  }x=z
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-steps-in-proximal-form&quot;&gt;ADMM Steps in Proximal Form&lt;/h2&gt;

&lt;p&gt;The ADMM steps for this problem are:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;x^{(k)} = {\operatorname{prox}}_{f,\frac{1}{\rho}}(z^{(k-1)}-w^{(k-1)})\\\\
&amp;amp;z^{(k)} = {\operatorname{prox}}_{g,\frac{1}{\rho}}(x^{(k)}+w^{(k-1)})\\\\
&amp;amp;w^{(k)}=w^{(k-1)}+x^{(k)}-z^{(k)}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where \({\operatorname{prox}}_{f,\frac{1}{\rho}}\) and \({\operatorname{prox}}_{g,\frac{1}{\rho}}\) are the proximal operators of \(f\) and \(g\) respectively, with parameter \(\frac{1}{\rho}\).&lt;/p&gt;

&lt;h2 id=&quot;proximal-operator-definition&quot;&gt;Proximal Operator Definition&lt;/h2&gt;

&lt;p&gt;Recall that for a convex function \(f\), the &lt;a href=&quot;/contents/vi/chapter19/19_01_01_Reminder-_proximal_gradient_descent/&quot;&gt;proximal operator&lt;/a&gt; is defined as:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
{\operatorname{prox}}_{f, \lambda}(v) = \underset{x}{\operatorname{argmin}}\left(f(x)+\frac{1}{2\lambda}||x-v||_{2}^{2}\right). 
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;derivation-of-proximal-updates&quot;&gt;Derivation of Proximal Updates&lt;/h2&gt;

&lt;p&gt;The process of deriving ADMM updates in terms of proximal operators is as follows.&lt;/p&gt;

&lt;p&gt;Let \(x^{+}, z^{+}, w^{+}\) be the updated values of \(x, z, w\) after one step.&lt;/p&gt;

&lt;h3 id=&quot;update-for-x&quot;&gt;Update for x:&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
x^{+}&amp;amp; = \underset{x}{\operatorname{argmin}}f(x)+\frac{\rho}{2}||x-z+w||^{2}_{2}\\\\
&amp;amp; =\underset{x}{\operatorname{argmin}}\frac{1}{2\cdot\frac{1}{\rho}}||(z-w)-x||^{2}_{2}+f(x)\\\\
&amp;amp; ={\operatorname{prox}}_{f,\frac{1}{\rho}}(z-w)
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;update-for-z&quot;&gt;Update for z:&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
z^{+}&amp;amp; = \underset{z}{\operatorname{argmin}}g(z)+\frac{\rho}{2}||x^{+}-z+w||^{2}_{2}\\\\
&amp;amp; =\underset{z}{\operatorname{argmin}}\frac{1}{2\cdot\frac{1}{\rho}}||(x^{+}+w)-z||^{2}_{2}+g(z)\\\\
&amp;amp; ={\operatorname{prox}}_{g,\frac{1}{\rho}}(x^{+}+w)
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;key-insight&quot;&gt;Key Insight&lt;/h2&gt;

&lt;p&gt;The original ADMM constraint is \(Ax+Bz = c\), while here the constraint is \(x=z\). That is, when the linear transformation relationship between \(x\) and \(z\) is the identity, we can transform the original ADMM updates into proximal updates.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>21-01 Last time - Dual method, Augmented Lagrangian method, ADMM, ADMM in scaled form</title>
   <link href="http://localhost:4000/contents/vi/chapter21/21_01_Last_time_Dual_method,_Augmented_Lagrangian_method,_ADMM,_ADMM_in_scaled_form/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter21/21_01_Last_time_Dual_method,_Augmented_Lagrangian_method,_ADMM,_ADMM_in_scaled_form</id>
   <content type="html">&lt;p&gt;before, 20장at, 우리는 Dual methods, ADMMabout, 살펴보았다. 여기선 ADMM의 응용을 살펴보기to, 앞서, Dual methodsand, Augmented Lagrangian method, ADMM, ADMM in scaled formabout, 정리하고자 한다.&lt;/p&gt;

&lt;h2 id=&quot;dual-method&quot;&gt;Dual method&lt;/h2&gt;
&lt;p&gt;아래의 problem를 let’s look at.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\\\
&amp;amp;\text{ subject to } &amp;amp;&amp;amp;Ax = b
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 $f$는 strictly convex하고 닫혀있다고 하자. 이 problem의 Lagrangian은 아래and, 같다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
L(x,u) = f(x)+u^{T}(Ax-b)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;위 problem의 dual problem는 아래and, 같다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{equation}
\max_u -f^{\ast}(-A^T u) - b^T u
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;여기at,의 u는 dual variable이다.&lt;/p&gt;

&lt;p&gt;이 식to, about, dual gradient ascent는 아래의 식을 iteration적with, computation한다.($k=1,2,3,…$)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^{(k)}&amp;amp;=\underset{x}{\operatorname{argmin}} L(x,u^{(k-1)}) \\\\
u^{(k)}&amp;amp;= u^{(k-1)} +t_{k}(Ax^{(k)}-b)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(t_{k}\)는 k번째 iteration의 step size이다.&lt;/p&gt;

&lt;p&gt;이 dual methodat,는, primal variable \(x\)는 첫번째 식처럼 before, 스텝at, 주어진 \(u^{(k-1)}\)at,의 Lagrangian을 minimization하는 \(x\)값with, 업데이트되고, dual variable \(u\)는 \(Ax-b\)이 gradient direction인 gradient ascent의 형태to, 업데이트가 된다.&lt;/p&gt;

&lt;p&gt;이 method의 장점은 \(f\)가 B개의 problemto, 분할이 가능할 when,(decomposable), \(x\) also, B개의 블록with, 분할하고\(( x =(x_{1}, ...,x_{B})\in \mathbb{R}^{n}, \text{ where }x_{i}\in \mathbb{R}^{n_{i}})\), matrix A also, B개의 sub-matrix 블록with, decompose가 가능solution서\((A = [A_{1}, ..., A_{B}] \text{ where }A_{i} \in \mathbb{R}^{m \times n_{i}})\), 쉽게 병렬화 or, 확장이 가능하여 computation이 용이하다. but, 단점은 convergence성를 보장하기 for, 까다to,운 condition,이 필요하다 ; primal의 feasible을 보장하기 for,, \(f\)가 strongly convex하다는 condition,이 필요하다.&lt;a href=&quot;/contents/vi/chapter20/20_01_01_Convergence_Analysis/&quot;&gt;[20-01-01]&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;augmented-lagrangian-method&quot;&gt;Augmented Lagrangian method&lt;/h2&gt;
&lt;p&gt;Method of multipliers라고도 불리는 Augmented Lagrangian method는 primal problemto, 추가 항을 더하여 computation한다. 이렇게 하면 iteration을 iteration되면서 점difference KKT의 conditions을 만족하게 된다. Dual methodand, comparing, convergence성to, about, condition,(f가 strongly convex)을 완화시킨다. instead of, problem의 분solution(decompose)가 불가능solution지는 단점이 있다. Primal problem의 정의는 as follows:.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x)+\frac{\rho}{2}||Ax-b||_{2}^{2}&amp;amp;\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;Ax=b
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\rho&amp;gt;0\)이다. 이 problem의 Lagrangian은 아래and, 같다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
L_{\rho}(x,u)=f(x)+u^{T}(Ax-b)+\frac{\rho}{2}||Ax-b||_{2}^{2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Dual gradient ascent는 다음을 iteration한다. (\(k=1,2,3,...\))&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^{(k)}&amp;amp;=\underset{x}{\operatorname{argmin}} L_{\rho}(x,u^{(k-1)}) \\\\
u^{(k)}&amp;amp;= u^{(k-1)} +\rho(Ax^{(k)}-b)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이 method의 장점은 위at, 언급하였듯, dual methodto, 비하여 더 나은 convergence condition,을 가진다. 단점은 제product 항이 추가되는 탓to, 분solution가능한 성질(decomposability)을 잃게 된다.&lt;/p&gt;

&lt;h2 id=&quot;alternating-direction-method-of-multipliersadmm&quot;&gt;Alternating direction method of multipliers(ADMM)&lt;/h2&gt;
&lt;p&gt;ADMM은 dual methodand, augmented Lagrangian method의 장점을 섞은 method이다. problem가 아래의 형태to, 정의 되어있다고 하자.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{x} f(x)+g(z) \qquad \text{subject to  }Ax+Bz=c
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이 식to, \(\rho&amp;gt;0\)인 augmented Lagrangian을 정의할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;L_{\rho} (x,z,u) = f(x)+g(z)+u^{T}(Ax+Bz-c)+\frac{\rho}{2}||Ax+Bz-c||_{2}^{2}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이어서 아래를 iteration하여 variable를 업데이트한다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{for k = 1,2,3,...}\\\\
&amp;amp;x^{(k)}=\underset{x}{\operatorname{argmin}} L_{\rho}(x,z^{(k-1)},u^{(k-1)})\\\\
&amp;amp;z^{(k)}=\underset{z}{\operatorname{argmin}} L_{\rho}(x^{(k)},z,u^{(k-1)})\\\\
&amp;amp;u^{(k)}=u^{(k-1)}+\rho(Ax^{(k)}+Bz^{(k)}-c)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;ADMMat,는 primal variable인 \(x, z\)를 함께 업데이트하지 않고, 순difference적with, 각각 업데이트 한다. and, 순difference적with, 업데이트할 when,는 다른 variable는 가장 최근의 값을 이용한다. that is,, k번째 iterationat, \(z\)를 업데이트 할when,to,는 before, iteration의 값 \(x^{(k-1)}\)이 아닌 \(x^{(k)}\)를 이용하고, u를 업데이트 할when, also, 현재 iterationat, 구한 primal variable \(x^{(k)}, z^{(k)}\)를 바to, 이용한다.&lt;/p&gt;

&lt;h2 id=&quot;alternating-direction-method-of-multipliersadmm-1&quot;&gt;Alternating direction method of multipliers(ADMM)&lt;/h2&gt;
&lt;p&gt;ADMM은 제약식 내의 Aand, B가 full rank라는 가정 없이, \(f\)and, \(g\)to, about, 큰 제약 없이(under modeset assumption) 모든 \(\rho &amp;gt; 0\)about, 다음을 만족한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Residual convergence: \(k\)가 \(\infty\)to, 갈 when,, \(r^{(k)} = A x^{(k)} - B z^{(k)} - c \to 0\), that is, primal iteration이 feasibilityto, 접근한다.&lt;/li&gt;
  &lt;li&gt;Objective convergence: \(f(x^{(k)}) + g(x^{(k)}) \to f^{\star} + g^{\star}\), 여기서 \(f^{\star} + g^{\star}\)는 최적의 primal objective 값이다.&lt;/li&gt;
  &lt;li&gt;Dual convergence: \(u^{(k)} \to u^{\star}\), 여기서 \(u^{\star}\)는 dual solution 이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Convergence rateabout,서는 아직 generally, informing,지진 않았고, 연구가 이루어지고있다. Convergenceto, about, reference문헌은 &lt;a href=&quot;/contents/vi/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;21장 소개파트&lt;/a&gt;to, 서술되어있다.&lt;/p&gt;

&lt;h2 id=&quot;admm-in-scaled-form&quot;&gt;ADMM in scaled form&lt;/h2&gt;
&lt;p&gt;We can express ADMM in scaled form by changing the dual variable \(u\) to the scaled variable \(w=u/\rho\). In summary, the ADMM steps can be represented as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;x^{(k)} = \underset{x}{\operatorname{argmin}} f(x) + \frac{\rho}{2} ||Ax + Bz^{(k-1)} - c + w^{(k-1)} ||_2^2 \\\\
&amp;amp;z^{(k)} = \arg\min_z g(x) + \frac{\rho}{2} || Ax^{(k)} + Bz - c + w^{(k-1)} ||_2^2  \\\\
&amp;amp;w^{(k)} = w^{(k-1)} + Ax^{(k)} + Bz^{(k)} - c 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(w^{(k)}\) can also be expressed as the sum of residuals up to the \(k\)-th iteration as shown below.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
w^{(k)} = w^{(0)} + \sum_{i=1}^k (Ax^{(i)} + Bz^{(i)} - c) 
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>21 Alternating Direction Method of Multipliers</title>
   <link href="http://localhost:4000/contents/vi/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter21/21_00_Alternating_Direction_Method_of_Multipliers</id>
   <content type="html">&lt;p&gt;This chapter aims to examine ADMM, which was covered in &lt;a href=&quot;/contents/vi/chapter20/20_00_Dual_Methods/&quot;&gt;Chapter 20&lt;/a&gt;, in more detail. The basic concepts are not significantly different in depth from what was covered in Chapter 20, and we will mainly look at application cases.&lt;/p&gt;

&lt;h3 id=&quot;reference-papers&quot;&gt;Reference Papers&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Boyd, Stephen, et al. [BPCPE11] “Distributed optimization and statistical learning via the alternating direction method of multipliers.” Foundations and Trends® in Machine learning 3.1 (2011): 1-122.&lt;/li&gt;
  &lt;li&gt;Hong, Mingyi, and Zhi-Quan Luo. [HL12] “On the linear convergence of the alternating direction method of multipliers.” Mathematical Programming 162.1-2 (2017): 165-199.&lt;/li&gt;
  &lt;li&gt;Deng, Wei, and Wotao Yin. [DY16] “On the global and linear convergence of the generalized alternating direction method of multipliers.” Journal of Scientific Computing 66.3 (2016): 889-916.&lt;/li&gt;
  &lt;li&gt;Iutzeler, Franck, et al. [IBCH14] “Linear convergence rate for distributed optimization with the alternating direction method of multipliers.” 53rd IEEE Conference on Decision and Control. IEEE, 2014.&lt;/li&gt;
  &lt;li&gt;Nishihara, Robert, et al. [NLRPJ15] “A general analysis of the convergence of ADMM.” arXiv preprint arXiv:1502.02009 (2015).&lt;/li&gt;
  &lt;li&gt;Parikh, Neal, and Stephen Boyd. [NB13] “Proximal algorithms.” Foundations and Trends® in Optimization 1.3 (2014): 127-239.&lt;/li&gt;
  &lt;li&gt;Vu, Vincent Q., et al. [VCLR13] “Fantope projection and selection: A near-optimal convex relaxation of sparse PCA.” Advances in neural information processing systems. 2013.&lt;/li&gt;
  &lt;li&gt;Candès, Emmanuel J., et al. [CLMW09] “Robust principal component analysis?.” Journal of the ACM (JACM) 58.3 (2011): 11.&lt;/li&gt;
  &lt;li&gt;Ramdas, Aaditya, and Ryan J. Tibshirani. [RT16] “Fast and flexible ADMM algorithms for trend filtering.” Journal of Computational and Graphical Statistics 25.3 (2016): 839-858.&lt;/li&gt;
  &lt;li&gt;Wytock, Matt, Suvrit Sra, and Jeremy Z. Kolter. [WSK14] “Fast Newton methods for the group fused lasso.” UAI. 2014.&lt;/li&gt;
  &lt;li&gt;Barbero, Alvaro, and Suvrit Sra. [BS14] “Modular proximal optimization for multidimensional total-variation regularization.” arXiv preprint arXiv:1411.0589 (2014).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ADMM convergence relation, : [BPCPE11], [HL12], [DY16], [IBCH14], [NLRPJ15]&lt;br /&gt;
Sparse subspace estimation : [VCLR13]&lt;br /&gt;
Sparse plus low rank decomposition : [CLMW09]&lt;br /&gt;
Consensus ADMM : [BPCPE11], [NB13]&lt;br /&gt;
Subprogram parameterization : [RT16], [WSK14], [BS14]&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>21-06 Faster convergence with subprogram parametrization - example of the 2d fused lasso problem</title>
   <link href="http://localhost:4000/contents/en/chapter21/21_06_Faster_convergence_with_subprogram_parametrization_-_example_of_the_2d_fused_lasso_problem/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter21/21_06_Faster_convergence_with_subprogram_parametrization_:_example_of_the_2d_fused_lasso_problem</id>
   <content type="html">&lt;h1 id=&quot;faster-convergence-with-subprogram-parametrization&quot;&gt;Faster Convergence with Subprogram Parametrization&lt;/h1&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;One very interesting property of ADMM is that when solving problems, if we parametrize the small subproblems in a special way, it can show much faster convergence performance than general methods. In the previous consensus ADMM example, the updates optimize over blocks of variables, which is similar to block coordinate descent. Therefore, ADMM can also achieve fast convergence by updating blocks of variables in nearly orthogonal directions.&lt;/p&gt;

&lt;h2 id=&quot;2d-fused-lasso-example&quot;&gt;2D Fused Lasso Example&lt;/h2&gt;

&lt;p&gt;In this section, we will demonstrate the above concepts through examples, designing auxiliary constraints so that the primal updates are in de-correlated directions.&lt;/p&gt;

&lt;p&gt;For detailed information, see [RT16], [WSK14], [BS14].&lt;/p&gt;

&lt;p&gt;Let’s examine the 2D fused lasso or 2D total variation denoising problem, which was one of the examples we looked at in &lt;a href=&quot;/contents/en/chapter01/01_01_optimization_problems/&quot;&gt;Chapter 1&lt;/a&gt;. Given an image \(Y\in \mathbb{R}^{d\times d}\), the problem is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{\Theta}\frac{1}{2}||Y-\Theta||^{2}_{F}+\lambda \sum_{i,j}(|\Theta_{i,j}-\Theta_{i+1,j}|+|\Theta_{i,j}-\Theta_{\Theta_{i,j+1}}|).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In this problem, there is a parameter for each pixel of the image, and this parameter matrix is \(\Theta\in \mathbb{R}^{d\times d}\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/2dfussed.png&quot; alt=&quot;[Fig 1] Interpretation of the penalty term in 2d fussed lasso[3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Interpretation of the penalty term in 2d fussed lasso[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;[Fig 1] visually shows the penalty term, which is the second term of the objective function. As can be seen from the defined problem, it aims to reduce the differences between a pixel and its adjacent horizontal and vertical pixels. That is, this penalty term makes the values of neighboring adjacent pixels similar.&lt;/p&gt;

&lt;h2 id=&quot;vector-form&quot;&gt;Vector Form&lt;/h2&gt;

&lt;p&gt;Summarizing the penalty term as an operator, the problem becomes:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\min_{\theta}\frac{1}{2}||y-\theta||^{2}_{F} + \lambda||D\theta||_{1}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(D\in \mathbb{R}^{m\times n}\) is the 2D difference operator corresponding to the original equation.&lt;/p&gt;

&lt;h2 id=&quot;forms-of-admm-updates-for-the-2d-fused-lasso-problem&quot;&gt;Forms of ADMM updates for the 2d fused lasso problem&lt;/h2&gt;
&lt;h2 id=&quot;forms-of-admm-updates-for-the-2d-fused-lasso-problem-1&quot;&gt;Forms of ADMM Updates for the 2D Fused Lasso Problem&lt;/h2&gt;

&lt;p&gt;Now we want to create ADMM steps in two ways by applying auxiliary constraints.&lt;/p&gt;

&lt;p&gt;The first approach is to derive ADMM from the vector form created through the 2D difference operator.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{\theta, z}\frac{1}{2}||y-\theta||^{2}_{2}+\lambda||z||_{1} \qquad \text{subject to   }z = D\theta,
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The ADMM steps are then derived as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\theta^{(k)} &amp;amp;= (I+\rho D^{T}D)^{-1}(y+\rho D^{T}(z^{(k-1)}+w^{(k-1)}))\\\\
z^{(k)} &amp;amp;= S_{\frac{\lambda}{\rho}}(D\theta^{(k)}-w^{(k-1)})\\\\
w^{(k)} &amp;amp;= w^{(k-1)}+z^{(k-1)}-D\theta ^{(k)}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;computational-complexity---vector-form&quot;&gt;Computational Complexity - Vector Form&lt;/h2&gt;

&lt;p&gt;Solving for \(\theta\) is equivalent to solving the linear system \((I+\rho D^{T}D)^{-1}\). Here, \(D^{T}D\) becomes the Laplacian matrix \(L=D^{T}D\) of the 2D grid, which can be solved in \(O(n)\) operations. The \(z\) update also requires \(O(n)\) operations since it involves applying the soft thresholding operator \(S_{t}\). Therefore, solving ADMM in vector form takes \(O(n)\) time.&lt;/p&gt;

&lt;h2 id=&quot;matrix-form-admm&quot;&gt;Matrix Form ADMM&lt;/h2&gt;

&lt;p&gt;The second approach is to derive ADMM in matrix form, identical to the original problem definition.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{\Theta, Z} &amp;amp;&amp;amp;\frac{1}{2}||Y-\Theta||^{2}_{F}+\lambda\sum_{i,j}(|\Theta_{i,j}-\Theta_{i+1,j}+|Z_{i+1,j}-Z_{i,j+1}|)\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;\Theta = Z
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The ADMM steps are as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
\Theta_{\cdot \\ , j}^{(k)} &amp;amp;= FL^{1d}_{ \frac{\lambda}{(1+\rho)} } \bigg( \frac{ Y+\rho( Z^{(k-1)}_{\cdot \\ , j}-W_{\cdot \\ ,j}^{(k-1)} ) } {1+\rho} \bigg),\qquad j=1,...,d\\\\
Z_{i, \cdot}^{(k)} &amp;amp;= FL^{1d}_{\frac{\lambda}{\rho}} \bigg(\Theta_{i, \cdot}^{(k)} + W_{i, \cdot}^{(k-1)} \bigg), \qquad j=1,...,d\\\\
W^{(k)} &amp;amp;= W^{(k-1)} + \Theta^{(k)} - Z^{(k)} \\\\
\end{align}\)
where \(FL_{\tau}^{1d}(a)\) is the 1D fused lasso defined as \(FL_{\tau}^{1d}(a) = \underset{x}{\operatorname{argmin}}\frac{1}{2}||a-x||^{2}_{2}+\tau\sum_{i=1}^{d-1}|x_{i}-x_{i+1}|\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;computational-complexity---matrix-form&quot;&gt;Computational Complexity - Matrix Form&lt;/h2&gt;

&lt;p&gt;The matrix form ADMM can also be performed with \(O(n)\) time complexity. Both \(\Theta\) and \(Z\) are in the form of 1D fused lasso, which has \(O(n)\) time complexity.&lt;/p&gt;

&lt;p&gt;[Fig 2] shows how the original penalty term is separated into 1D fused lasso problems.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/2dfussedlasso.png&quot; alt=&quot;[Fig 2]  Interpretation of the matrix form ADMM updates for 2d fused lasso[3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2]  Interpretation of the matrix form ADMM updates for 2d fused lasso[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;image-denoising-experiments&quot;&gt;Image denoising experiments&lt;/h2&gt;
&lt;h2 id=&quot;image-denoising-experiments-1&quot;&gt;Image Denoising Experiments&lt;/h2&gt;

&lt;p&gt;Now let’s revisit the image denoising problem we examined in Chapter 1.&lt;/p&gt;

&lt;p&gt;[Fig 3] shows the data and denoised images. [Fig 4] shows a comparison of the two ADMM methods. The “specialized” ADMM in matrix form, which defines constraints by decomposing in vertical/horizontal directions, shows much faster convergence performance than the “standard ADMM” derived in vector form.&lt;/p&gt;

&lt;p&gt;[Fig 5] shows the image quality according to ADMM iterations.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/ll1.png&quot; alt=&quot;[Fig 3]  Data, exact solution image(300x200 image : n = 60,000).  
left : original image before denoising, right : the exact solution of denoised image[3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 3]  Data, exact solution image(300x200 image : n = 60,000).
left : original image before denoising, right : the exact solution of denoised image[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/ll2.png&quot; alt=&quot;[Fig 4]  Convergence curves of two ADMM algorithms. black : standard(vector form), red : specialized(matrix form) [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 4]  Convergence curves of two ADMM algorithms. black : standard(vector form), red : specialized(matrix form) [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/admm_iteration_visualized.png&quot; alt=&quot;[Fig 5]  ADMM iterates visualized after k = 10, 30, 50, 100 iterations [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 5]  ADMM iterates visualized after k = 10, 30, 50, 100 iterations [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>21-05 Consensus ADMM</title>
   <link href="http://localhost:4000/contents/en/chapter21/21_05_Consensus_ADMM/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter21/21_05_Consensus_ADMM</id>
   <content type="html">&lt;h1 id=&quot;consensus-admm&quot;&gt;Consensus ADMM&lt;/h1&gt;

&lt;h2 id=&quot;basic-consensus-admm&quot;&gt;Basic Consensus ADMM&lt;/h2&gt;

&lt;p&gt;Consider the following problem:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\min_{x}\sum^{B}_{i=1} f_{i}(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;To solve this problem with ADMM, we need to introduce constraints. Here, we want to transform the equation into a form that is easy to operate in parallel. This approach, called consensus ADMM, reparametrizes the equation as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x_{1},...,x_{B},x} &amp;amp;&amp;amp;\sum^{B}_{i=1} f_{i}(x_{i})\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;x_{i}=x, i = 1,...B
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-algorithm&quot;&gt;ADMM Algorithm&lt;/h2&gt;

&lt;p&gt;This allows us to compute decomposable ADMM steps:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x^{(k)}_{i} &amp;amp;= \underset{x_{i}}{\operatorname{argmin}} f_{i}(x_{i})+\frac{\rho}{2}||x_{i}-x^{(k-1)}+w_{i}^{(k-1)}||_{2}^{2}, i=1,...B\\\\
x^{(k)} &amp;amp;=\frac{1}{B}\sum_{i=1}^{B}(x_{i}^{(k)}+w_{i}^{(k-1)})\\\\
w_{i}^{(k)} &amp;amp;=w_{i}^{(k-1)}+x_{i}^{(k)}-x^{(k)}, i=1,...,B
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;simplified-form&quot;&gt;Simplified Form&lt;/h2&gt;

&lt;p&gt;Additionally, we can define \(\overline{x}=\frac{1}{B}\sum_{i=1}^{B}x_{i}, \overline{w}=\frac{1}{B}\sum_{i=1}^{B}w_{i}\). With this, we can easily verify that \(\overline{w}^{(k)}=0\) for iterations \(k&amp;gt;1\), and the second equation of the ADMM update simplifies to \(x^{(k)}=\overline{x}^{(k)}\). Therefore, we can simplify the ADMM update equations as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x^{(k)}_{i} &amp;amp;= \underset{x_{i}}{\operatorname{argmin}} f_{i}(x_{i})+\frac{\rho}{2}||x_{i}-\overline{x}^{(k-1)}+w_{i}^{(k-1)}||_{2}^{2},  i=1,...B\\\\
w_{i}^{(k)} &amp;amp;=w_{i}^{(k-1)}+x_{i}^{(k)}-\overline{x}^{(k)},  i=1,...,B.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;intuition&quot;&gt;Intuition&lt;/h2&gt;

&lt;p&gt;The \(x_{i}\) updates for \(i = 1,...,B\) can be computed in parallel.&lt;/p&gt;

&lt;p&gt;From the simplified equations, we can gain intuition about consensus ADMM. Each \(x_{i}\) update tries to minimize \(f_{i}(x_{i})\) while simultaneously using \(l_{2}\) regularization to align each \(x_{i}\) with the average \(\overline{x}\). If \(x_{i}\) becomes larger than the average, \(w_{i}\) increases. Therefore, the regularization in the next step will reduce the enlarged \(x_{i}\).&lt;/p&gt;

&lt;h2 id=&quot;general-consensus-admm&quot;&gt;General consensus ADMM&lt;/h2&gt;
&lt;h2 id=&quot;general-consensus-admm-1&quot;&gt;General Consensus ADMM&lt;/h2&gt;

&lt;p&gt;Consensus ADMM can be generalized to a more general form. Let’s look at the form of problems with affine transformations of \(x\) and arbitrary function \(g\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{x}\sum_{i=1}^{B} f_{i}(a^{T}_{i}x+b_{i})+g(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For this equation as well, we reparameterize by adding constraints:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x_{1},..x_{B},x} &amp;amp;&amp;amp;\sum^{B}_{i=1}f_{i}(a_{i}^{T}x+b)+g(x)\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;x_{i} = x, i=1,...B
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;We can then derive decomposable ADMM updates:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x_{i}^{(k)} &amp;amp;= \underset{x_{i}}{\operatorname{argmin}}f_{i}(a_{i}^{T}x+b_{i})+\frac{\rho}{2}||x_{i}-x^{(k-1)}+w_{i}^{(k-1)}||^{2}_{2}+g(x)\\\\
x^{(k)}&amp;amp;=\underset{x}{\operatorname{argmin}} \frac{B\rho}{2}||x-\overline{x}^{(k)}-\overline{w}^{(k-1)}||^{2}_{2}+g(x)\\\\
w_{i}^{(k)}&amp;amp;=w_{i}^{(k-1)}+x_{i}^{(k)}-x^{(k)}, i=1,...B
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;key-differences&quot;&gt;Key Differences&lt;/h2&gt;

&lt;p&gt;The differences between generalized consensus ADMM and the consensus ADMM derived above can be summarized as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Because the ADMM step equations do not simplify, \(\overline{w}^{(k)}=0\) is no longer satisfied.&lt;/li&gt;
  &lt;li&gt;\(x_{i}, i=1,...,B\) can be updated in parallel.&lt;/li&gt;
  &lt;li&gt;Each \(x_{i}\) update can be thought of as minimizing the corresponding partial loss with \(l_2\) regularization.&lt;/li&gt;
  &lt;li&gt;The \(x\) update is a proximal operation for the arbitrary function \(g\) (generally a regularizer).&lt;/li&gt;
  &lt;li&gt;Different ADMM algorithms are derived depending on how the reparameterization is done.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more detailed information, see the &lt;a href=&quot;/contents/en/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;reference papers&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>21-04 Example - Sparse subspace estimation and sparse plus low rank decomposition</title>
   <link href="http://localhost:4000/contents/en/chapter21/21_04_Example_-_Sparse_subspace_estimation_and_sparse_plus_low_rank_decomposition/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter21/21_04_Example_:_Sparse_subspace_estimation_and_sparse_plus_low_rank_decomposition</id>
   <content type="html">&lt;h1 id=&quot;example-sparse-subspace-estimation-and-sparse-plus-low-rank-decomposition&quot;&gt;Example: Sparse Subspace Estimation and Sparse Plus Low Rank Decomposition&lt;/h1&gt;

&lt;h2 id=&quot;sparse-subspace-estimation&quot;&gt;Sparse Subspace Estimation&lt;/h2&gt;

&lt;p&gt;Given \(S=X^{T}X, X\in \mathbb{R}^{n\times p}\), consider the problem of finding a projection that minimizes the Frobenius norm distance between the original \(X\) and the projected \(X\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{P} &amp;amp;&amp;amp;||X-XP||^{2}_{F}\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;\text{rank(P)=k where P is a projection matrix}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This problem is non-convex because the set of projection matrices is not a convex set. However, it is known to be equivalent to the following convex problem [&lt;a href=&quot;/contents/en/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;VCLR13&lt;/a&gt;]. This is also called the subspace estimation problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{Y} &amp;amp;&amp;amp;tr(SY)\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;Y\in F_{k} = \left\{Y\in \mathbb{S}^{p} : 0 \preceq Y \preceq I, tr(Y) = k \right\}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;[VCLR13] discusses solving the sparse version (with added L1 norm) of the subspace estimation problem. For detailed derivation, please refer to the corresponding paper.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{Y} &amp;amp;&amp;amp;tr(SY)-\lambda ||Y||_{1}\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;Y\in F_{k} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(F_{k}\) is the Fantope of order k, as defined in the equation above.&lt;/p&gt;

&lt;p&gt;When \(\lambda = 0\), the above problem is equivalent to standard PCA.&lt;/p&gt;

&lt;p&gt;This problem has an SDP form and can be solved using interior point methods. However, this approach is complex to implement and becomes very slow as the problem size increases.&lt;/p&gt;

&lt;h2 id=&quot;admm-formulation&quot;&gt;ADMM Formulation&lt;/h2&gt;

&lt;p&gt;To solve this problem with ADMM, we reformulate it as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{Y,Z} &amp;amp;&amp;amp;-tr(SY)+I_{F_{k}}(Y) + \lambda||Z||_{1}\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;Y = Z.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-algorithm&quot;&gt;ADMM Algorithm&lt;/h2&gt;

&lt;p&gt;Summarizing the problem, the ADMM steps are as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
Y^{+} &amp;amp;=  \underset{Y}{\operatorname{argmin}} -tr(SY) + I_{F_{k}}(Y)+\frac{\rho}{2}||Y-Z+W||^{2}_{F}\\\\
&amp;amp;=\underset{Y\in F_{k}}{\operatorname{argmin}} \frac{1}{2}||Y-Z+W-\frac{S}{\rho}||^{2}_{F}\\\\
&amp;amp;=P_{F_{k}}(Z-W+\frac{S}{\rho})\\\\
Z^{+} &amp;amp; = \underset{Z}{\operatorname{argmin}}\lambda||Z||_{1}+\frac{\rho}{2}||Y^{+}-Z+W||^{2}_{F}\\\\
&amp;amp;=S_{\frac{\lambda}{\rho}}(Y^{+}+W)\\\\
W^{+} &amp;amp;=W+Y^{+}-Z^{+}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(P_{F_{k}}\) is the fantope projection operator. This is defined by clipping the eigendecomposition \(A= U\Sigma U^{T}, \Sigma = diag(\sigma_{1},...\sigma_{p})\) [&lt;a href=&quot;/contents/en/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;VCLR13&lt;/a&gt;]:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
P_{F_{k}}(A) = U\Sigma_{\theta}U^{T}, \: \Sigma_{\theta} = diag(\sigma_{1}(\theta),...\sigma_{p}(\theta))
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where each \(\sigma_{i}(\theta) = \min\left\{\max\left\{\sigma_{i}-\theta,0\right\},1\right\}\) and \(\sum^{p}_{i=1}\sigma_{i}(\theta)=k\).&lt;/p&gt;

&lt;h2 id=&quot;sparse-plus-low-rank-decomposition&quot;&gt;Sparse plus low rank decomposition&lt;/h2&gt;
&lt;p&gt;Given \(M\in \mathbb{R}^{n\times m}\), the sparse plus low rank decomposition problem is as follows [&lt;a href=&quot;/contents/en/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;CLMW09&lt;/a&gt;]:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{L,S} &amp;amp;&amp;amp;||L||_{tr}+\lambda||S||_{1}\\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;L+S=M
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;problem-description&quot;&gt;Problem Description&lt;/h2&gt;

&lt;p&gt;The goal of this problem is to decompose the observed matrix \(M\) into a low rank matrix \(L\) and a sparse matrix \(S\). The first term of the objective function is the trace penalty of \(L\), which minimizes the sum of singular values of \(L\). The second term uses the \(l_{1}\) norm on matrix \(S\) to induce sparsity in \(S\). \(\lambda\) is a tuning parameter that balances these two terms. Both the trace norm and \(l_{1}\) norm are non-smooth, and generally the trace norm is known to be difficult to optimize. Like the sparse subspace estimation problem, this problem has an SDP form and can be solved using interior point methods, but this is also complex and slow. For this problem, ADMM provides somewhat easier update steps.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
L^{+} &amp;amp;= S^{tr}_{\frac{1}{\rho}}(M-S+W)\\\\
S^{+} &amp;amp;= S^{l_{1}}_{\frac{\lambda}{\rho}}(M-L^{+}+W)\\\\
W^{+} &amp;amp;= W+M-L^{+}-S^{+}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(S^{tr}_{\frac{1}{\rho}}\) is matrix soft-thresholding and \(S^{l_{1}}_{\frac{\lambda}{\rho}}\) is elementwise soft-thresholding.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/candes.png&quot; alt=&quot;[Fig 1] Example of sparse plue low rank decomposition on surveliance camera[3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Example of sparse plue low rank decomposition on surveliance camera[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;application-example&quot;&gt;Application Example&lt;/h2&gt;

&lt;p&gt;[Fig 1] shows an example of applying sparse plus low rank decomposition to surveillance camera video analysis. From surveillance cameras that film a fixed area for a long time, we can easily separate the low rank part that shares most frames, and the sparse part extracts characteristic parts from specific frames. For example, in [Fig 1], the middle column represents the low rank part and the right column represents the sparse part. As can be confirmed, the low rank part contains background information that appears in almost all frames, and the sparse part contains only characteristic parts that appear only in specific frames.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>21-03 Example - Lasso regression and group lasso Regression</title>
   <link href="http://localhost:4000/contents/en/chapter21/21_03_Example_-_Lasso_regression_and_group_lasso_Regression/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter21/21_03_Example_:_Lasso_regression_and_group_lasso_Regression</id>
   <content type="html">&lt;h2 id=&quot;lasso-regression&quot;&gt;Lasso regression&lt;/h2&gt;
&lt;p&gt;Let’s solve the Lasso regression problem using ADMM.&lt;/p&gt;

&lt;p&gt;Given \(y\in \mathbb{R}^{n}, X\in \mathbb{R}^{n\times p}\), the Lasso problem is:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\min_{\beta}\frac{1}{2}||y-X\beta||^{2}_{2}+\lambda||\beta||_{1}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In previous chapters, we have solved the Lasso problem using various methods, including &lt;a href=&quot;/contents/en/chapter09/09_01_proximal_gradient_descent/&quot;&gt;proximal gradient descent (ISTA)&lt;/a&gt;, &lt;a href=&quot;/contents/en/chapter09/09_05_03_example_FISTA/&quot;&gt;accelerated proximal gradient descent (FISTA)&lt;/a&gt;, &lt;a href=&quot;/contents/en/chapter15/chapter16/15_barrier_method/&quot;&gt;barrier method&lt;/a&gt;, and &lt;a href=&quot;/contents/en/chapter17/17_primal_dual_interior_point_method/&quot;&gt;primal-dual interior-point method&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As with deriving the dual formulation, the performance of the ADMM algorithm depends on how we set up the auxiliary variables. Among many ways to set auxiliary variables, the following form is known to be one of the most effective:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{\beta, \alpha} &amp;amp;&amp;amp;||y-X\beta||^{2}_{2}+\lambda||\alpha||_{1}\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;\beta-\alpha= 0.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-updates&quot;&gt;ADMM Updates&lt;/h2&gt;

&lt;p&gt;The ADMM updates for this formulation are derived as follows. The \(\beta\) update involves a quadratic function, so we can find the minimum by differentiation. The \(\alpha\) update is similar to the problem covered in &lt;a href=&quot;/contents/en/chapter07/07_03_04_example_soft-thresholding/&quot;&gt;Chapter 7 (07-03-04)&lt;/a&gt;, which has a soft-thresholding solution.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\beta^{+} &amp;amp;= \underset{\beta}{\operatorname{argmin}}\frac{1}{2}||y-X\beta||^{2}_{2}+\frac{\rho}{2}||\beta-\alpha+w||^{2}_{2}\\\\
&amp;amp;= (X^{T}X+\rho I)^{-1}(X^{T}y+\rho (\alpha-w))\\\\
\alpha^{+} &amp;amp;= \underset{\alpha}{\operatorname{argmin}}\lambda||\alpha||_{1}+\frac{\rho}{2}||\beta^{+}-\alpha+w||^{2}_{2}\\\\
&amp;amp;= S_{\frac{\lambda}{\rho}}(\beta^{+}+w)\\\\
w^{+} &amp;amp;=w+\beta^{+}-\alpha^{+}
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;key-properties&quot;&gt;Key Properties&lt;/h2&gt;

&lt;p&gt;This result has the following characteristics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The matrix \(X^{T}X+\rho I\) is always invertible regardless of \(X\) since \(\rho&amp;gt;0\).&lt;/li&gt;
  &lt;li&gt;If we precompute the factorization (typically Cholesky factorization) in \(O(p^{3})\) flops, then the \(\beta\) update takes \(O(p^{2})\) flops.&lt;/li&gt;
  &lt;li&gt;The \(\alpha\) update applies the soft-thresholding operator \(S_{t}\), which is identical to the content in &lt;a href=&quot;/contents/en/chapter07/07_03_04_example_soft-thresholding/&quot;&gt;07-03-04&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The ADMM steps are “almost” equivalent to repeatedly soft-thresholding ridge regression coefficients.&lt;/li&gt;
  &lt;li&gt;Different values of \(\rho\) produce different results.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter21/lasso.png&quot; alt=&quot;[Fig 1] Comparison of various algorithms for lasso regression (50 instances with n = 100, p = 20) [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Comparison of various algorithms for lasso regression (50 instances with n = 100, p = 20) [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;performance-comparison&quot;&gt;Performance Comparison&lt;/h2&gt;

&lt;p&gt;[Fig 1] compares the convergence of various algorithms for the Lasso regression problem. All algorithms have the same computational complexity per iteration. As can be seen from the convergence speed in the graph, ADMM has similar convergence speed to proximal gradient descent (black). Accelerated proximal gradient descent (red) has “Nesterov ripples” but shows slightly faster convergence speed. We can also confirm that ADMM shows different convergence speeds according to the \(\rho\) value. Coordinate descent (green), which will be discussed later in &lt;a href=&quot;/contents/en/chapter23/23_Coordinate_Descent/&quot;&gt;Chapter 23&lt;/a&gt;, uses more information about the problem and therefore has faster convergence speed compared to other methods. The disadvantage of coordinate descent is that there are conditions required for its application.&lt;/p&gt;

&lt;p&gt;If the \(\rho\) value is set too large, the weight of minimizing the objective function \(f+g\) becomes small, and if the \(\rho\) value is set too small, feasibility decreases. Therefore, setting an appropriate \(\rho\) value is important. For detailed information, see [BPCPE] discussed in the &lt;a href=&quot;/contents/en/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;Chapter 21 reference papers&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;group-lasso-regression&quot;&gt;Group Lasso Regression&lt;/h2&gt;

&lt;p&gt;Similarly, let’s examine solving the Group Lasso regression problem with ADMM. The Group Lasso regression problem is defined as follows for \(y\in \mathbb{R}^{n}, X\in \mathbb{R}^{n \times p}\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{\beta}\frac{1}{2}||y-X\beta||^{2}_{2}+\lambda\sum^{G}_{g=1} c_{g}||\beta_{(g)}||_{2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;As with Lasso regression, we can reformulate the problem:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{\beta,\alpha} &amp;amp;&amp;amp;\frac{1}{2}||y-X\beta||^{2}_{2}+\lambda\sum^{G}_{g=1} c_{g}||\alpha_{(g)}||_{2}\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;\beta-\alpha=0.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The ADMM steps are as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\beta^{+} &amp;amp;= (X^{T}X+\rho I)^{-1}(X^{T}y+\rho (\alpha-w))\\\\
\alpha^{+} &amp;amp;= R_{c_{g}\frac{\lambda}{\rho}}(\beta^{+}_{(g)}+w_{(g)})\qquad \text{g = 1,...G}\\\\
w^{+} &amp;amp;=w+\beta^{+}-\alpha^{+}
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;properties-of-group-lasso-admm&quot;&gt;Properties of Group Lasso ADMM&lt;/h2&gt;

&lt;p&gt;This result has the following characteristics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The matrix \(X^{T}X+\rho I\) is always invertible regardless of \(X\) since \(\rho&amp;gt;0\).&lt;/li&gt;
  &lt;li&gt;If we precompute the factorization (typically Cholesky factorization) in \(O(p^{3})\) flops, then the \(\beta\) update takes \(O(p^{2})\) flops.&lt;/li&gt;
  &lt;li&gt;The \(\alpha\) update applies the group soft-thresholding operator \(R_{t}\), which is defined as follows:&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
R_{t}(x) = (1-\frac{x}{\lVert x \rVert_{2}})_{+}x
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>21-02 Connection to proximal operators</title>
   <link href="http://localhost:4000/contents/en/chapter21/21_02_Connection_to_proximal_operators/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter21/21_02_Connection_to_proximal_operators</id>
   <content type="html">&lt;h1 id=&quot;connection-to-proximal-operators&quot;&gt;Connection to Proximal Operators&lt;/h1&gt;

&lt;p&gt;Consider an optimization problem with a single variable that separates into two functions:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\min_{x} f(x)+g(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This can also be expressed by adding a constraint:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\min_{x, z} f(x)+g(z) \qquad \text{subject to  }x=z
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-steps-in-proximal-form&quot;&gt;ADMM Steps in Proximal Form&lt;/h2&gt;

&lt;p&gt;The ADMM steps for this problem are:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;x^{(k)} = {\operatorname{prox}}_{f,\frac{1}{\rho}}(z^{(k-1)}-w^{(k-1)})\\\\
&amp;amp;z^{(k)} = {\operatorname{prox}}_{g,\frac{1}{\rho}}(x^{(k)}+w^{(k-1)})\\\\
&amp;amp;w^{(k)}=w^{(k-1)}+x^{(k)}-z^{(k)}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where \({\operatorname{prox}}_{f,\frac{1}{\rho}}\) and \({\operatorname{prox}}_{g,\frac{1}{\rho}}\) are the proximal operators of \(f\) and \(g\) respectively, with parameter \(\frac{1}{\rho}\).&lt;/p&gt;

&lt;h2 id=&quot;proximal-operator-definition&quot;&gt;Proximal Operator Definition&lt;/h2&gt;

&lt;p&gt;Recall that for a convex function \(f\), the &lt;a href=&quot;/contents/en/chapter19/19_01_01_Reminder-_proximal_gradient_descent/&quot;&gt;proximal operator&lt;/a&gt; is defined as:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
{\operatorname{prox}}_{f, \lambda}(v) = \underset{x}{\operatorname{argmin}}\left(f(x)+\frac{1}{2\lambda}||x-v||_{2}^{2}\right). 
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;derivation-of-proximal-updates&quot;&gt;Derivation of Proximal Updates&lt;/h2&gt;

&lt;p&gt;The process of deriving ADMM updates in terms of proximal operators is as follows.&lt;/p&gt;

&lt;p&gt;Let \(x^{+}, z^{+}, w^{+}\) be the updated values of \(x, z, w\) after one step.&lt;/p&gt;

&lt;h3 id=&quot;update-for-x&quot;&gt;Update for x:&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
x^{+}&amp;amp; = \underset{x}{\operatorname{argmin}}f(x)+\frac{\rho}{2}||x-z+w||^{2}_{2}\\\\
&amp;amp; =\underset{x}{\operatorname{argmin}}\frac{1}{2\cdot\frac{1}{\rho}}||(z-w)-x||^{2}_{2}+f(x)\\\\
&amp;amp; ={\operatorname{prox}}_{f,\frac{1}{\rho}}(z-w)
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;update-for-z&quot;&gt;Update for z:&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
z^{+}&amp;amp; = \underset{z}{\operatorname{argmin}}g(z)+\frac{\rho}{2}||x^{+}-z+w||^{2}_{2}\\\\
&amp;amp; =\underset{z}{\operatorname{argmin}}\frac{1}{2\cdot\frac{1}{\rho}}||(x^{+}+w)-z||^{2}_{2}+g(z)\\\\
&amp;amp; ={\operatorname{prox}}_{g,\frac{1}{\rho}}(x^{+}+w)
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;key-insight&quot;&gt;Key Insight&lt;/h2&gt;

&lt;p&gt;The original ADMM constraint is \(Ax+Bz = c\), while here the constraint is \(x=z\). That is, when the linear transformation relationship between \(x\) and \(z\) is the identity, we can transform the original ADMM updates into proximal updates.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>21-01 Last time - Dual method, Augmented Lagrangian method, ADMM, ADMM in scaled form</title>
   <link href="http://localhost:4000/contents/en/chapter21/21_01_Last_time_Dual_method,_Augmented_Lagrangian_method,_ADMM,_ADMM_in_scaled_form/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter21/21_01_Last_time_Dual_method,_Augmented_Lagrangian_method,_ADMM,_ADMM_in_scaled_form</id>
   <content type="html">&lt;p&gt;before, 20장at, 우리는 Dual methods, ADMMabout, 살펴보았다. 여기선 ADMM의 응용을 살펴보기to, 앞서, Dual methodsand, Augmented Lagrangian method, ADMM, ADMM in scaled formabout, 정리하고자 한다.&lt;/p&gt;

&lt;h2 id=&quot;dual-method&quot;&gt;Dual method&lt;/h2&gt;
&lt;p&gt;아래의 problem를 let’s look at.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\\\
&amp;amp;\text{ subject to } &amp;amp;&amp;amp;Ax = b
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 $f$는 strictly convex하고 닫혀있다고 하자. 이 problem의 Lagrangian은 아래and, 같다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
L(x,u) = f(x)+u^{T}(Ax-b)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;위 problem의 dual problem는 아래and, 같다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{equation}
\max_u -f^{\ast}(-A^T u) - b^T u
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;여기at,의 u는 dual variable이다.&lt;/p&gt;

&lt;p&gt;이 식to, about, dual gradient ascent는 아래의 식을 iteration적with, computation한다.($k=1,2,3,…$)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^{(k)}&amp;amp;=\underset{x}{\operatorname{argmin}} L(x,u^{(k-1)}) \\\\
u^{(k)}&amp;amp;= u^{(k-1)} +t_{k}(Ax^{(k)}-b)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(t_{k}\)는 k번째 iteration의 step size이다.&lt;/p&gt;

&lt;p&gt;이 dual methodat,는, primal variable \(x\)는 첫번째 식처럼 before, 스텝at, 주어진 \(u^{(k-1)}\)at,의 Lagrangian을 minimization하는 \(x\)값with, 업데이트되고, dual variable \(u\)는 \(Ax-b\)이 gradient direction인 gradient ascent의 형태to, 업데이트가 된다.&lt;/p&gt;

&lt;p&gt;이 method의 장점은 \(f\)가 B개의 problemto, 분할이 가능할 when,(decomposable), \(x\) also, B개의 블록with, 분할하고\(( x =(x_{1}, ...,x_{B})\in \mathbb{R}^{n}, \text{ where }x_{i}\in \mathbb{R}^{n_{i}})\), matrix A also, B개의 sub-matrix 블록with, decompose가 가능solution서\((A = [A_{1}, ..., A_{B}] \text{ where }A_{i} \in \mathbb{R}^{m \times n_{i}})\), 쉽게 병렬화 or, 확장이 가능하여 computation이 용이하다. but, 단점은 convergence성를 보장하기 for, 까다to,운 condition,이 필요하다 ; primal의 feasible을 보장하기 for,, \(f\)가 strongly convex하다는 condition,이 필요하다.&lt;a href=&quot;/contents/en/chapter20/20_01_01_Convergence_Analysis/&quot;&gt;[20-01-01]&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;augmented-lagrangian-method&quot;&gt;Augmented Lagrangian method&lt;/h2&gt;
&lt;p&gt;Method of multipliers라고도 불리는 Augmented Lagrangian method는 primal problemto, 추가 항을 더하여 computation한다. 이렇게 하면 iteration을 iteration되면서 점difference KKT의 conditions을 만족하게 된다. Dual methodand, comparing, convergence성to, about, condition,(f가 strongly convex)을 완화시킨다. instead of, problem의 분solution(decompose)가 불가능solution지는 단점이 있다. Primal problem의 정의는 as follows:.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x)+\frac{\rho}{2}||Ax-b||_{2}^{2}&amp;amp;\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;Ax=b
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\rho&amp;gt;0\)이다. 이 problem의 Lagrangian은 아래and, 같다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
L_{\rho}(x,u)=f(x)+u^{T}(Ax-b)+\frac{\rho}{2}||Ax-b||_{2}^{2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Dual gradient ascent는 다음을 iteration한다. (\(k=1,2,3,...\))&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^{(k)}&amp;amp;=\underset{x}{\operatorname{argmin}} L_{\rho}(x,u^{(k-1)}) \\\\
u^{(k)}&amp;amp;= u^{(k-1)} +\rho(Ax^{(k)}-b)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이 method의 장점은 위at, 언급하였듯, dual methodto, 비하여 더 나은 convergence condition,을 가진다. 단점은 제product 항이 추가되는 탓to, 분solution가능한 성질(decomposability)을 잃게 된다.&lt;/p&gt;

&lt;h2 id=&quot;alternating-direction-method-of-multipliersadmm&quot;&gt;Alternating direction method of multipliers(ADMM)&lt;/h2&gt;
&lt;p&gt;ADMM은 dual methodand, augmented Lagrangian method의 장점을 섞은 method이다. problem가 아래의 형태to, 정의 되어있다고 하자.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{x} f(x)+g(z) \qquad \text{subject to  }Ax+Bz=c
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이 식to, \(\rho&amp;gt;0\)인 augmented Lagrangian을 정의할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;L_{\rho} (x,z,u) = f(x)+g(z)+u^{T}(Ax+Bz-c)+\frac{\rho}{2}||Ax+Bz-c||_{2}^{2}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이어서 아래를 iteration하여 variable를 업데이트한다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{for k = 1,2,3,...}\\\\
&amp;amp;x^{(k)}=\underset{x}{\operatorname{argmin}} L_{\rho}(x,z^{(k-1)},u^{(k-1)})\\\\
&amp;amp;z^{(k)}=\underset{z}{\operatorname{argmin}} L_{\rho}(x^{(k)},z,u^{(k-1)})\\\\
&amp;amp;u^{(k)}=u^{(k-1)}+\rho(Ax^{(k)}+Bz^{(k)}-c)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;ADMMat,는 primal variable인 \(x, z\)를 함께 업데이트하지 않고, 순difference적with, 각각 업데이트 한다. and, 순difference적with, 업데이트할 when,는 다른 variable는 가장 최근의 값을 이용한다. that is,, k번째 iterationat, \(z\)를 업데이트 할when,to,는 before, iteration의 값 \(x^{(k-1)}\)이 아닌 \(x^{(k)}\)를 이용하고, u를 업데이트 할when, also, 현재 iterationat, 구한 primal variable \(x^{(k)}, z^{(k)}\)를 바to, 이용한다.&lt;/p&gt;

&lt;h2 id=&quot;alternating-direction-method-of-multipliersadmm-1&quot;&gt;Alternating direction method of multipliers(ADMM)&lt;/h2&gt;
&lt;p&gt;ADMM은 제약식 내의 Aand, B가 full rank라는 가정 없이, \(f\)and, \(g\)to, about, 큰 제약 없이(under modeset assumption) 모든 \(\rho &amp;gt; 0\)about, 다음을 만족한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Residual convergence: \(k\)가 \(\infty\)to, 갈 when,, \(r^{(k)} = A x^{(k)} - B z^{(k)} - c \to 0\), that is, primal iteration이 feasibilityto, 접근한다.&lt;/li&gt;
  &lt;li&gt;Objective convergence: \(f(x^{(k)}) + g(x^{(k)}) \to f^{\star} + g^{\star}\), 여기서 \(f^{\star} + g^{\star}\)는 최적의 primal objective 값이다.&lt;/li&gt;
  &lt;li&gt;Dual convergence: \(u^{(k)} \to u^{\star}\), 여기서 \(u^{\star}\)는 dual solution 이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Convergence rateabout,서는 아직 generally, informing,지진 않았고, 연구가 이루어지고있다. Convergenceto, about, reference문헌은 &lt;a href=&quot;/contents/en/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/&quot;&gt;21장 소개파트&lt;/a&gt;to, 서술되어있다.&lt;/p&gt;

&lt;h2 id=&quot;admm-in-scaled-form&quot;&gt;ADMM in scaled form&lt;/h2&gt;
&lt;p&gt;We can express ADMM in scaled form by changing the dual variable \(u\) to the scaled variable \(w=u/\rho\). In summary, the ADMM steps can be represented as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;x^{(k)} = \underset{x}{\operatorname{argmin}} f(x) + \frac{\rho}{2} ||Ax + Bz^{(k-1)} - c + w^{(k-1)} ||_2^2 \\\\
&amp;amp;z^{(k)} = \arg\min_z g(x) + \frac{\rho}{2} || Ax^{(k)} + Bz - c + w^{(k-1)} ||_2^2  \\\\
&amp;amp;w^{(k)} = w^{(k-1)} + Ax^{(k)} + Bz^{(k)} - c 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(w^{(k)}\) can also be expressed as the sum of residuals up to the \(k\)-th iteration as shown below.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
w^{(k)} = w^{(0)} + \sum_{i=1}^k (Ax^{(i)} + Bz^{(i)} - c) 
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>21 Alternating Direction Method of Multipliers</title>
   <link href="http://localhost:4000/contents/en/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/"/>
   <updated>2021-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter21/21_00_Alternating_Direction_Method_of_Multipliers</id>
   <content type="html">&lt;p&gt;This chapter aims to examine ADMM, which was covered in &lt;a href=&quot;/contents/en/chapter20/20_00_Dual_Methods/&quot;&gt;Chapter 20&lt;/a&gt;, in more detail. The basic concepts are not significantly different in depth from what was covered in Chapter 20, and we will mainly look at application cases.&lt;/p&gt;

&lt;h3 id=&quot;reference-papers&quot;&gt;Reference Papers&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Boyd, Stephen, et al. [BPCPE11] “Distributed optimization and statistical learning via the alternating direction method of multipliers.” Foundations and Trends® in Machine learning 3.1 (2011): 1-122.&lt;/li&gt;
  &lt;li&gt;Hong, Mingyi, and Zhi-Quan Luo. [HL12] “On the linear convergence of the alternating direction method of multipliers.” Mathematical Programming 162.1-2 (2017): 165-199.&lt;/li&gt;
  &lt;li&gt;Deng, Wei, and Wotao Yin. [DY16] “On the global and linear convergence of the generalized alternating direction method of multipliers.” Journal of Scientific Computing 66.3 (2016): 889-916.&lt;/li&gt;
  &lt;li&gt;Iutzeler, Franck, et al. [IBCH14] “Linear convergence rate for distributed optimization with the alternating direction method of multipliers.” 53rd IEEE Conference on Decision and Control. IEEE, 2014.&lt;/li&gt;
  &lt;li&gt;Nishihara, Robert, et al. [NLRPJ15] “A general analysis of the convergence of ADMM.” arXiv preprint arXiv:1502.02009 (2015).&lt;/li&gt;
  &lt;li&gt;Parikh, Neal, and Stephen Boyd. [NB13] “Proximal algorithms.” Foundations and Trends® in Optimization 1.3 (2014): 127-239.&lt;/li&gt;
  &lt;li&gt;Vu, Vincent Q., et al. [VCLR13] “Fantope projection and selection: A near-optimal convex relaxation of sparse PCA.” Advances in neural information processing systems. 2013.&lt;/li&gt;
  &lt;li&gt;Candès, Emmanuel J., et al. [CLMW09] “Robust principal component analysis?.” Journal of the ACM (JACM) 58.3 (2011): 11.&lt;/li&gt;
  &lt;li&gt;Ramdas, Aaditya, and Ryan J. Tibshirani. [RT16] “Fast and flexible ADMM algorithms for trend filtering.” Journal of Computational and Graphical Statistics 25.3 (2016): 839-858.&lt;/li&gt;
  &lt;li&gt;Wytock, Matt, Suvrit Sra, and Jeremy Z. Kolter. [WSK14] “Fast Newton methods for the group fused lasso.” UAI. 2014.&lt;/li&gt;
  &lt;li&gt;Barbero, Alvaro, and Suvrit Sra. [BS14] “Modular proximal optimization for multidimensional total-variation regularization.” arXiv preprint arXiv:1411.0589 (2014).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ADMM convergence relation, : [BPCPE11], [HL12], [DY16], [IBCH14], [NLRPJ15]&lt;br /&gt;
Sparse subspace estimation : [VCLR13]&lt;br /&gt;
Sparse plus low rank decomposition : [CLMW09]&lt;br /&gt;
Consensus ADMM : [BPCPE11], [NB13]&lt;br /&gt;
Subprogram parameterization : [RT16], [WSK14], [BS14]&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>reference</title>
   <link href="http://localhost:4000/reference/26_reference/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/reference/26_reference</id>
   <content type="html">&lt;ol&gt;
  &lt;li&gt;Boyd, S. and Vandenberghe, L. (2004). &lt;em&gt;&lt;a href=&quot;https://web.stanford.edu/~boyd/cvxbook/&quot;&gt;Convex Optimization&lt;/a&gt;&lt;/em&gt;. Cambridge University Press.&lt;/li&gt;
  &lt;li&gt;Boyd, S. and Vandenberghe, L. (2014). &lt;em&gt;&lt;a href=&quot;https://web.stanford.edu/~boyd/cvxbook/bv_cvxslides.pdf&quot;&gt;Convex Optimization Lecture Slides&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Tibshirani, R. (2016). &lt;em&gt;&lt;a href=&quot;http://www.stat.cmu.edu/~ryantibs/convexopt/&quot;&gt;Convex Optimization: Fall 2016&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Wikipedia. &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Jensen%27s_inequality&quot;&gt;Jensen’s inequality&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Wikipedia. &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Positive-definite_matrix#Further_properties&quot;&gt;Positive-definite matrix - properties&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Wikipedia. &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_decomposition#Eigendecomposition&quot;&gt;Eigendecomposition&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Wikipedia. &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix#Real_symmetric_matrices&quot;&gt;Eigendecomposition of a matrix - Real symmetric matrices&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Wikipedia. &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Schur_complement&quot;&gt;Schur complement&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Wikipedia. &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Quasiconvex_function&quot;&gt;Quasiconvex function&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Boyd, S. and Dattorro, J. (2013). &lt;em&gt;&lt;a href=&quot;https://web.stanford.edu/class/ee392o/alt_proj.pdf&quot;&gt;Alternating Projections&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Wikipedia. &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Max-flow_min-cut_theorem&quot;&gt;Max-flow min-cut theorem&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Wikipedia. &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm&quot;&gt;Ford-Fulkerson algorithm&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Tibshirani, J. R. (2013). &lt;em&gt;&lt;a href=&quot;https://projecteuclid.org/download/pdfview_1/euclid.ejs/1369148600&quot;&gt;The lasso problem and uniqueness&lt;/a&gt;&lt;/em&gt;. Electronic Journal of Statistics
Vol. 7. pp. 1456–1490.&lt;/li&gt;
  &lt;li&gt;Nocedal, J. (2006). &lt;em&gt;Numerical Optimization 2nd ed&lt;/em&gt;. Springer.&lt;/li&gt;
  &lt;li&gt;Wikipedia. &lt;a href=&quot;https://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe_algorithm&quot;&gt;Frank–Wolfe algorithm&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Wikipedia. &lt;a href=&quot;https://en.wikipedia.org/wiki/Coordinate_descent&quot;&gt;Coordinate descent&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>25 Mixed Integer Programming (part II)</title>
   <link href="http://localhost:4000/contents/vi/chapter25/25_Mixed_integer_programming/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter25/25_Mixed_integer_programming</id>
   <content type="html">&lt;p&gt;This chapter examines the cutting plane algorithm, which can be considered the most core algorithm in Integer Programming (IP), and the branch and cut algorithm, which is its practical implementation.&lt;/p&gt;

&lt;p&gt;We will also examine examples of Integer Programming such as best subset selection and Least mean squares.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Belotti, Kirches, Leyer, Linderoth, Luedke, and Mahajan (2012), “Mixed-integer nonlinear optimization”&lt;/li&gt;
  &lt;li&gt;Bertsimas and Mazumder (2016), “Best subset selection via a modern optimization lens”&lt;/li&gt;
  &lt;li&gt;Bertsimas, King, and Mazumder (2014), “Least quantile regression via modern optimization”&lt;/li&gt;
  &lt;li&gt;Conforti, Cornuejols, and Zambelli (2014), “Integer programming”&lt;/li&gt;
  &lt;li&gt;Wolsey (1998), “Integer programming”&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>25-02 Two extended examples</title>
   <link href="http://localhost:4000/contents/vi/chapter25/25_02_Two_extended_examples/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter25/25_02_Two_extended_examples</id>
   <content type="html">&lt;p&gt;In this section, we will present two examples of Mixed Integer Programming.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Best subset selection&lt;/li&gt;
  &lt;li&gt;Least mean squares&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>25-02-02 Least mean squares</title>
   <link href="http://localhost:4000/contents/vi/chapter25/25_02_02_Least_mean_squares/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter25/25_02_02_Least_mean_squares</id>
   <content type="html">&lt;p&gt;So far, we have solved regression problems by minimizing the \(l_2\) norm or \(l_1\) norm of residuals. Is there a more robust method than these methods?&lt;/p&gt;

&lt;p&gt;When performing regression to minimize the median of residuals, we can achieve more robust regression. This is called &lt;strong&gt;Least Median of Squares&lt;/strong&gt;, and it is robust enough that the estimator does not get corrupted even if about 50% of the data is corrupted. However, this problem is also an NP-Hard problem!&lt;/p&gt;

&lt;p&gt;This section introduces how to solve the &lt;strong&gt;Least Quantile of Squares&lt;/strong&gt; problem, which generalizes the Least Median of Squares problem, using Integer programming.&lt;/p&gt;
&lt;h2 id=&quot;least-mean-squares&quot;&gt;Least mean squares&lt;/h2&gt;
&lt;p&gt;Let \(X = [x^{1} \quad \dotsc \quad x^{p}] \in \mathbb{R}^{n×p}\) and \(y \in \mathbb{R}^{n}\). And when \(\beta \in \mathbb{R}^{p}\), let \(r : = y - X\beta\).&lt;/p&gt;

&lt;h3 id=&quot;observe&quot;&gt;Observe&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Least squares (LS) : \(\beta_{LS} : = \underset{\beta}{\text{argmin}} \sum_{i} r^2_i\)&lt;/li&gt;
  &lt;li&gt;Least absolute deviation (LAD) : \(\beta_{LAD} : = \underset{\beta}{\text{argmin}} \sum_{i} \lvert r_{i} \rvert\)
    &lt;h3 id=&quot;least-median-of-squares-lms&quot;&gt;Least Median of Squares (LMS)&lt;/h3&gt;
    &lt;blockquote&gt;
\[\beta_{LMS} : = \underset{\beta}{\text{argmin}} (\text{median} \lvert r_{i} \rvert )\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;least-quantile-regression&quot;&gt;Least quantile regression&lt;/h2&gt;
&lt;p&gt;Least Median of Squares problem를 일반화한 Least Quantile of Squareproblem는 as follows: 정의할 수 있다. 여기서 \(r_{q}\)는 \(q\)번째 ordered absolute residual이다.&lt;/p&gt;
&lt;h3 id=&quot;least-quantile-of-squares-lqs&quot;&gt;Least Quantile of Squares (LQS)&lt;/h3&gt;
&lt;blockquote&gt;
\[\beta_{LQS} : = \underset{\beta}{\text{argmin}} (\lvert r_{(q)} \rvert ), \quad 1 \le q \le n, \quad \lvert r_{1} \rvert \le \lvert r_{2} \rvert \le \cdots \le \lvert r_{n} \rvert\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;key-step-in-the-formulation&quot;&gt;Key step in the formulation&lt;/h3&gt;
&lt;p&gt;이제 Least Quantile of Squareproblem를 Integer Programmingwith, 재정by,보자. 이when,, \(r\)의 각 entry \(i\)about, 다음and, 같은 binary variable을 사용한다.&lt;/p&gt;

&lt;blockquote&gt;
\[\lvert r_{i} \rvert \le \lvert r_{(q)} \rvert$ or $\lvert r_{i} \rvert \ge \lvert r_{(q)} \rvert\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;integer-programming-formulation&quot;&gt;Integer programming formulation&lt;/h3&gt;
&lt;p&gt;\(\bar{\mu_{i}}\)and, \(\mu_{i}\)은 thresholdto, 각각의 개수는 \(k\)개, \(n-k\)개이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
  \min_{\beta, \mu, \bar{\mu}, z, \gamma} &amp;amp; \quad {\gamma} \\
  \text{subject to} &amp;amp; \quad  \gamma \le \lvert r_{i} \rvert + \bar{\mu_{i}}, \quad i = 1, ..., n \\
  &amp;amp; \quad  \gamma \le \lvert r_{i} \rvert -  \mu_{i}, \quad i = 1, ..., n \\
  &amp;amp; \quad \bar{\mu_{i}} \le M \cdot z_{i}, \quad i = 1, ..., n \\
  &amp;amp; \quad \mu_{i} \le M \cdot (1-z_{i}), \quad i = 1, ..., n \\
  &amp;amp; \quad \sum^{p}_{i=1} z_{i} = q \\
  &amp;amp; \quad \mu_{i}, \bar{\mu_{i}} \ge 0, \quad i = 1, ..., n \\
  &amp;amp; \quad z_{i} \in \{0, 1\},  \quad i = 1, ..., n \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이 problemat, 첫번째and, 두번쨰 constraint을 보면 residual의 절대값 \(\lvert r_{i} \rvert\)이 포함되어 있어서 convex relaxationwith, 풀 수가 없다. therefore,, 첫번째and, 두번쨰 constraint을 convex functionwith, converting, 주어야 한다.&lt;/p&gt;

&lt;h2 id=&quot;first-order-algorithm&quot;&gt;First-order algorithm&lt;/h2&gt;
&lt;p&gt;\(\lvert r_{i} \rvert\)는 다음and, 같은 형태to, convex function \(H_{q}(\beta)\)to, 재정의할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;

\[\lvert r_{q} \rvert = \lvert y_{(q)} - x^{T}_{(q)} \beta \rvert = H_{q}(\beta) - H_{q+1}(\beta)\]
&lt;/blockquote&gt;

&lt;p&gt;이when, \(H_{q}(\beta)\)는 as follows: 정의된다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
H_{q}(\beta) = \sum^{n}_{i=q} \lvert y_{(i)} - x^{T}_{(i)} \beta \rvert  = &amp;amp;
\max_{w} \sum^{n}_{i=1} w_i \lvert y_{(i)} - x^{T}_{(i)} \beta \rvert \\
&amp;amp; \text{subject to} \sum^{n}_{i=1}  w_i  = n − q + 1 \\
&amp;amp;0 \le w_i \le 1, i = 1, ..., n \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(H_{q}(\beta)\)는 앞서 정의된 \(\lvert r_{i} \rvert\)을 작은것from, 큰 순with, 나열할 when,, \(q\)번째 이image의 모든 residual의 sum이다. therefore,, \(q\)번째 이image의 residual의 sumat, \(q+1\)번째 이image의 residual의 sum을 빼면 \(q\)번째의 residual 된다는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;Subgradient algorithmwith, \(H_{q}(\beta) - H_{q+1}(\beta)\)의 local minimum을 구할 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, see 논문 &lt;a href=&quot;https://arxiv.org/pdf/1310.8625.pdf&quot;&gt;LEAST QUANTILE REGRESSION VIA MODERN OPTIMIZATION&lt;/a&gt; see
    &lt;h2 id=&quot;computational-results&quot;&gt;Computational results&lt;/h2&gt;
    &lt;p&gt;위의 논문at,  Least Quantile of Squareproblem를 실험한 result,는 다음 그래프at, 볼 수 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mixed-integer-programming-gap&quot;&gt;Mixed integer programming gap&lt;/h3&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_06_LQS_results1.png&quot; alt=&quot;[Fig1] Mixed integer programming gap [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Mixed integer programming gap [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cold-vs-warm-starts&quot;&gt;Cold vs Warm Starts&lt;/h3&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_07_LQS_results2.png&quot; alt=&quot;[Fig2] Cold vs Warm Starts [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Cold vs Warm Starts [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>25-02-01 Best subset selection</title>
   <link href="http://localhost:4000/contents/vi/chapter25/25_02_01_Best_subset_selection/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter25/25_02_01_Best_subset_selection</id>
   <content type="html">&lt;p&gt;Best subset selection, one of the representative examples of Integer Programming, is a problem of selecting k entries from \(p\) entries.&lt;/p&gt;

&lt;h2 id=&quot;best-subset-selection&quot;&gt;Best subset selection&lt;/h2&gt;
&lt;p&gt;When \(X = [x^{1} \quad \dotsc \quad x^{p}] \in \mathbb{R}^{n×p}\) and \(y \in \mathbb{R}^{n}\), the best subset selection problem is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{\beta} &amp;amp; \quad \frac{1}{2} \parallel y - X\beta \parallel^{2} \\
\text{subject to } &amp;amp; \quad \parallel \beta \parallel_{0}  \  \leq  k \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(\parallel \beta \parallel_{0}\) is the number of nonzero entries in \(\beta\).&lt;/p&gt;

&lt;p&gt;Previously in earlier chapters, we defined this type of problem as a Lasso problem and made \(\beta\) sparse using the \(l_1\) norm. In this problem, it is defined as a problem that constrains the number of non-zero entries using the \(l_0\) norm, but since the constraint condition \(\parallel \beta \parallel_{0}  \  \leq  k\) is non-convex, the problem cannot be solved with the convex optimization techniques we have learned so far.&lt;/p&gt;

&lt;h3 id=&quot;integer-programming-formulation&quot;&gt;Integer programming formulation&lt;/h3&gt;
&lt;p&gt;Then let’s reformulate this problem with Integer programming.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{\beta, z} &amp;amp; \quad \frac{1}{2} \parallel y - X\beta \parallel^{2} \\
\text{subject to } &amp;amp; \quad \left\vert  \beta_{i} \right\vert  \leq M_{i} \cdot z_{i} \quad i = 1 \dotsc p \\
&amp;amp; \quad \sum_{i = 1}^{p} z_{i} \leq k \\
&amp;amp; \quad z_{ji} \in \lbrace 0, 1 \rbrace \quad i = 1 \dotsc p \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Binary variable \(z_i\)를 introducing,서 \(z_i\)의 sum이 \(k\)보다 작게 만듦with,써 위의 problemand, 동일solution지게 만들었다.  \(M_i\)는 사전to, 알고 있는 \(\left\vert  \beta_{i} \right\vert\)의 image한 값with, \(X\)and, \(y\)를 사전processing,서 computation할 수 있는 값이다.&lt;/p&gt;

&lt;p&gt;이제 problem를 Integer Programmingwith, 정의했으므to, 지금from, Integer Programming techniquewith, 풀 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;a-clever-way-to-get-good-feasible-solutions&quot;&gt;A clever way to get good feasible solutions&lt;/h2&gt;
&lt;p&gt;problem를 generalizing,서 algorithm을 explaining,보자. Objective function \(g : \mathbb{R}^{p} \to \mathbb{R}\)이 smooth convex이고 \(\nabla g\)가 L-Lipschitz이라고 하자.&lt;/p&gt;
&lt;blockquote&gt;

\[\min_{\beta} g(\beta) \quad \text{subject to} \quad \parallel \beta \parallel_{0} \le k\]
&lt;/blockquote&gt;

&lt;p&gt;Best subset selection의 case, \(g(\beta) = \frac{1}{2} \parallel X\beta - y \parallel^2_2\)이다.&lt;/p&gt;

&lt;h3 id=&quot;observation&quot;&gt;Observation&lt;/h3&gt;
&lt;p&gt;as follows: 정의된 \(H_k(u)\) function를 through, \(u \in \mathbb{R}^p\)at, 가장 큰 k개 entry를 구할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;

\[H_k(u) = \underset{\beta : \parallel \beta_{0} \parallel \le k}{\text{argmin}} \parallel \beta - u \parallel^2_2\]
&lt;/blockquote&gt;

&lt;p&gt;이when,, \(H_k(u)\) function는 hard thresholding을 한다. also,, \(u\)를 set \(\beta\)to, projection한 것with, 볼 수도 있다.&lt;/p&gt;

&lt;h3 id=&quot;discrete-first-order-algorithm&quot;&gt;Discrete first-order algorithm&lt;/h3&gt;
&lt;p&gt;이제 gradient descentand, function \(H_k(u)\)를 using,서 algorithm을 정by,보자.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(\beta^{(0)}\)with, 시작&lt;/li&gt;
  &lt;li&gt;for \(k = 0, 1, ...\) &lt;br /&gt;
\(\quad \beta^{(i+1)} = H_k \left(\beta^{(i)} - \frac{1}{L} \nabla g(\beta^{(i)})\right)\)&lt;br /&gt;
end for&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위의 process을 iteration하면 \(\beta^{(i)} \to \bar{\beta}\)to, convergence하게 된다. 이는 위의 minimization problemto, about, local solution이라고 할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;

\[\bar{\beta} =  H_k \left(\bar{\beta} - \frac{1}{L} \nabla g(\bar{\beta})\right)\]
&lt;/blockquote&gt;

&lt;p&gt;result,적with, 이 algorithm은 proximal gradient algorithmwith, 볼 수 있다. 왜냐하면 function \(H_k(u)\)가 proximal operator 역할을 하고 있기 because,이다.&lt;/p&gt;
&lt;h2 id=&quot;computational-results&quot;&gt;Computational results&lt;/h2&gt;
&lt;h3 id=&quot;mixed-integer-programming-gap&quot;&gt;Mixed integer programming gap&lt;/h3&gt;
&lt;p&gt;아래 그림at, Subset selection problem의 실험 result,를 let’s look at.&lt;/p&gt;

&lt;p&gt;왼쪽 그래프at, upper bound는 바to, optimal이 되었지만 lower bound는 천천히 올라오다가 upper boundand, 만나는 지점at,야 optimal임을 알게 된다. 왜냐하면 linear programat,는 solution이 optimal인지 체크할 method이 없으며 upper boundand, lower bound가 같아졌을 when, optimal임을 알 수 있게 된다.
(referenceto, upper boundand, lower bound의 difference를 mixed integer programming gap이라고 한다.)&lt;/p&gt;

&lt;p&gt;오른쪽 그림은 동일한 실험 result,를 mixed integer programming gap을 작아지는 모습with, showing,주고 있다. 주황색 그래프는 upper boundand, lower bound의 difference이인 mixed integer programming gap을 representing,며 점점 줄어들고 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_03_subset_results1.png&quot; alt=&quot;[Fig1] Dataset n=350, p = 64, k=6 [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$[Fig1] Dataset n=350, p = 64, k=6 [3]$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cold-and-warm-starts&quot;&gt;Cold and Warm Starts&lt;/h3&gt;
&lt;p&gt;다음 그림at, warm start가 cold start보다 전체적with, 성능이 매우 우수함을 showing,주고 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_04_subset_results2.png&quot; alt=&quot;[Fig2] Cold and Warm Starts [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Cold and Warm Starts [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;sparsity-detection&quot;&gt;Sparsity Detection&lt;/h3&gt;
&lt;p&gt;다음 그림at,는 MIP (Mixed Integer Programming)and, Lasso, Step regression, Sparsenet의 sparsity를 비교하고 있다. result,적with, MIP가 가장 sparse한 result,내고 있음을 알 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_05_subset_results3.png&quot; alt=&quot;[Fig3] Sparsity Detection (synthetic database) [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig3] Sparsity Detection (synthetic database) [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01 Cutting Planes</title>
   <link href="http://localhost:4000/contents/vi/chapter25/25_01_Cutting_planes/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter25/25_01_Cutting_planes</id>
   <content type="html">&lt;p&gt;The cutting plane method is an approach that changes an integer linear program to a convex problem and finds a solution. If this solution is not included in the original feasible set, it uses cuts to progressively guide the newly obtained solution to be included in the original feasible set by cutting out the region where the solution exists. Here, a cut is a line (or hyperplane) that cuts the feasible set, also called a cutting plane.&lt;/p&gt;

&lt;h2 id=&quot;concept-of-cutting-plane&quot;&gt;Concept of cutting plane&lt;/h2&gt;
&lt;p&gt;Conceptually, it can be thought of as a method that draws a line between the original feasible set and the feasible set to cut out regions that are not part of the original feasible set, as shown in the figure below.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_cutting_plane_concept.png&quot; alt=&quot;[Fig1] Cutting Plane&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Cutting Plane&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Red region: feasible set of the original integer linear program&lt;/li&gt;
  &lt;li&gt;Blue region: feasible set of the convex relaxation problem&lt;/li&gt;
  &lt;li&gt;Green line: cutting plane (the cutting plane exists between the blue and red regions)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The detailed algorithm will be introduced again in the main text.&lt;/p&gt;

&lt;h2 id=&quot;a-bit-of-history-on-cutting-planes&quot;&gt;A bit of history on cutting planes&lt;/h2&gt;
&lt;p&gt;It took a very long time for the cutting plane method to develop from theory to a practical method.&lt;/p&gt;

&lt;p&gt;In 1954, Dantzig, Fulkerson, and Johnson first proposed the cutting plane method to solve the TSP (traveling salesman problem), and in 1958, mathematician Gomory proposed a general cutting plane method that could solve arbitrary integer linear programs. However, for about 30 years after that, Gomory cuts remained buried in an impractical state for solving real problems.&lt;/p&gt;

&lt;p&gt;In 1990, Sebastian Ceria at CMU successfully implemented the cutting plane method using the branch and bound algorithm, which is called branch and cut. Since then, cutting planes have become a core component of commercial optimization solvers.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01-04 Branch and cut algorithm</title>
   <link href="http://localhost:4000/contents/vi/chapter25/25_01_04_Branch_and_cut_algorithm/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter25/25_01_04_Branch_and_cut_algorithm</id>
   <content type="html">&lt;p&gt;In 1990, Sebastian Ceria at CMU successfully implemented the cutting plane method using the branch and bound algorithm, which is called branch and cut. Since then, cutting planes have become a core component of commercial optimization solvers.&lt;/p&gt;

&lt;h2 id=&quot;branch-and-cut-algorithm&quot;&gt;Branch and cut algorithm&lt;/h2&gt;
&lt;p&gt;다음and, 같은 integer programming problem가 있다고 하자. 이when, \(f : \mathbb{R}^{n} \to \mathbb{R}\)이고  \(C \subseteq \mathbb{R}^{n}\)는 convex이며 \(J \subseteq {1, ..., n}\)이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {f(x)} \\
\text{subject to } &amp;amp; \quad  x \in C \\
                   &amp;amp; \quad  x_j \in \mathbb{Z}, \quad j \in J \\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;branch-and-cut-algorithm-1&quot;&gt;Branch and cut algorithm&lt;/h3&gt;
&lt;p&gt;algorithmat, Convex Problem은 CPto, Integer Program은 IPto, 표기한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;다음 convex relaxation problem를 푼다.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {f(x)} \\
\text{subject to } &amp;amp; \quad  x \in C \\
                   &amp;amp; \quad  x_j \in \mathbb{Z}, \quad j \in J \\
\end{align}\]
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;(CR) infeasible \(\Rightarrow\) (IP) infeasible &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;(CR)의 solution \(x^{\star}\)이 (IP) feasible \(\Rightarrow\) \(x^{\star}\)는 (IP)의 solution &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;(CR)의 solution \(x^{\star}\)이 (IP) infeasible하면 다음 두 가지 중to, 선택 &lt;br /&gt;
\(\quad\)4.1 cut을 추가하고 step 1to, 간다. &lt;br /&gt;
\(\quad\)4.2 branchsolution서 iteration적with, subproblem을 푼다. &lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Branch and cut algorithm은 branch and bound and, cutting plane method를 결sum한 algorithmwith,서, step 4at, branch-and-bound를 할지, cut을 할지 선택할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;integer-programming-technology&quot;&gt;Integer programming technology&lt;/h2&gt;
&lt;p&gt;Gurobi, CPLEX, FICOand, 같은 state-of-the-art solver들은 매우 효율적인 simplex, interior-point method 등의 algorithm 구현을 포함하고 있다. particularly,, mixed integer optimization의 case, 대부분의 solver들은 branch and cut algorithm을 사용하고 있으며 이들은 convex relaxationand, warm start의 이점을 많이 활용하고 있다.&lt;/p&gt;

&lt;p&gt;약 30년 전to, 비하면 Integer programming의 성능 향image은 매우 비약적이다. therefore,, 그during, 풀지 못했던  실생활의 많은 problem들이 최근to, Integer programming을 through, solution결되고 있으며 computing power가 향image됨according to, 더욱 적극적with, 활용될 전망이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Algorithmat,의 속도 향image 1990-2016 : over \(500,000\)&lt;/li&gt;
  &lt;li&gt;Hardwareat,의 속도 향image 1990-2016 : over \(500,000\)&lt;/li&gt;
  &lt;li&gt;Total speedup over \(250\) billion = \(2:5 \cdot 10^{11}\)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01-03 Gomory cuts (1958)</title>
   <link href="http://localhost:4000/contents/vi/chapter25/25_01_03_Gomory_cuts/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter25/25_01_03_Gomory_cuts</id>
   <content type="html">&lt;p&gt;Mathematician Gomory devised a method to easily find valid inequalities based on the following fact:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;if \(a \le b\) and \(a\) is an integer then \(a \le \lfloor b \rfloor\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That is, if a is an integer, then even if b is rounded down, the relationship that a is less than or equal to b is maintained.&lt;/p&gt;

&lt;h2 id=&quot;gomory-fractional-cut&quot;&gt;Gomory fractional cut&lt;/h2&gt;
&lt;p&gt;Let’s say that the feasible set \(S\) defined by the convex hull of the IP problem mentioned earlier is as follows:&lt;/p&gt;

\[S \subseteq \left\{ x \in \mathbb{Z}^{n}_{+} : \sum^{n}_{j=1} a_{j} x_{j} = a_{0} \right\} \quad \text{where} \quad  a_{0} \notin \mathbb{Z}\]

&lt;p&gt;In this case, the Gomory fractional cut is defined as follows:&lt;/p&gt;

\[\sum^{n}_{j=1} (a_{j} - \lfloor a_{j} \rfloor) x_{j} \ge a_{0} -  \lfloor a_{0} \rfloor\]

&lt;p&gt;There are many ideas that extend this concept. For example, there are Chvatal cuts, split cuts, lift-and-project cuts, etc.&lt;/p&gt;

&lt;p&gt;The derivation process of Gomory fractional cut is detailed on Wikipedia, so please refer to it.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, see &lt;a href=&quot;https://en.wikipedia.org/wiki/Cutting-plane_method&quot;&gt;Cutting-plane method&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01-02 Cutting plane algorithm</title>
   <link href="http://localhost:4000/contents/vi/chapter25/25_01_02_Cutting_plane_algorithm/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter25/25_01_02_Cutting_plane_algorithm</id>
   <content type="html">&lt;p&gt;In this section, we will examine the cutting plane algorithm that can solve integer linear programs.&lt;/p&gt;

&lt;h2 id=&quot;valid-inequality&quot;&gt;Valid Inequality&lt;/h2&gt;
&lt;p&gt;To define cutting planes, let’s first look at what valid inequalities are.&lt;/p&gt;

&lt;p&gt;An inequality \(\pi^{T}x \le \pi_{0}\) is said to be valid for set \(S\) if it satisfies the following condition. That is, if a set \(S\) is contained in the halfspace defined by the inequality \(\pi^{T}x \le \pi_{0}\), then this inequality can be considered valid for \(S\).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\pi^{T}x \le \pi_{0}\) for all \(x \in S\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;An inequality must be valid to become a cutting plane.&lt;/p&gt;
&lt;h2 id=&quot;cutting-plane-algorithm&quot;&gt;Cutting plane algorithm&lt;/h2&gt;
&lt;p&gt;이제 다음and, 같은 integer programming이 있을 when, cutting plane algorithm을 let’s examine.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {c^{T}x} \\
\text{subject to } &amp;amp; \quad  x \in C \\
                   &amp;amp; \quad  x_j \in \mathbb{Z}, \quad j \in J \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(S := \text{conv} \left \{ x \in C : x_j \in \mathbb{Z}, j \in J \right \}\)이다.&lt;/p&gt;

&lt;h3 id=&quot;cutting-plane-algorithm-1&quot;&gt;Cutting plane algorithm&lt;/h3&gt;
&lt;p&gt;다음 algorithmat, Convex Problem은 CPto, Integer Program은 IPto, 표기한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(C_{0} := C\)with, 두고 \(x^{(0)} := \text{argmin}_{x} \left\{c^{T}x : x \in C_{0} \right\}\)를 computation&lt;/li&gt;
  &lt;li&gt;for \(k = 0, 1, ...\) &lt;br /&gt;
\(\quad\)if \(x^{k}\)가 (IP) feasible이면 \(x^{k}\)는 optimal solution이므to, Stop함 &lt;br /&gt;
\(\quad\)else&lt;br /&gt;
\(\quad\quad\) \(S\)about, valid하면서 \(x^{k}\)를 잘라내는 부등식 (\(\pi\), \(\pi_{0}\))을 찾음&lt;br /&gt;
\(\quad\quad\) \(C_{k+1} := C_{k} \cap \{ x : \pi^{T}x \le \pi_{0} \}\)&lt;br /&gt;
\(\quad\quad\) \(x^{(k+1)} := \text{argmin}_{x} \left\{c^{T}x : x \in C_{k+1} \right\}\)&lt;br /&gt;
\(\quad\)end if&lt;br /&gt;
end for&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이and, 같은 valid inequality를 &lt;strong&gt;cutting plane&lt;/strong&gt; or, &lt;strong&gt;cut&lt;/strong&gt;이라고 한다.&lt;/p&gt;

&lt;p&gt;algorithm의 1step는 convex relaxation을 하여 CP problem를 푸는 step이다. 이떄 feasible set은 \(C\)이다.&lt;/p&gt;

&lt;p&gt;algorithm 2stepat,는 구한 solution가 IPat, feasible하다면 이를 solutionto, 본다. if, feasible하지 않다면 solution인 \(x^{k}\)and, set \(S\)를 나누는 valid inequality를 finding, \(C_{k}\)의 범위를 줄인다. and,, \(C_{k+1}\)to, 재정의된 CP problem를 풀고 algorithm 2step를 iteration하게 된다.&lt;/p&gt;

&lt;p&gt;아래 그림at, polygon은 set \(C\)를 representing,며 CP의 solution는 검정색 점with, 표시되어 있다. 이when,, valid inequality는 solution를 잘라내서 set \(C\)의 범위를 줄이게 된다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_02_valid_inequality.png&quot; alt=&quot;[Fig1] Valid Inequality&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Valid Inequality [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;이and, 같이 set \(C\)의 범위를 계속solution서 reducing,나가면 IP problem의 convex hull feasible set인 set \(S\)and, 만나게 되어 IPto, feasible한 solution를 구할 수 있게 된다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01-01 Convexification</title>
   <link href="http://localhost:4000/contents/vi/chapter25/25_01_01_Convexification/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter25/25_01_01_Convexification</id>
   <content type="html">&lt;p&gt;Transforming an integer program into an equivalent convex problem is called convexification. When convexification is performed, the feasible set becomes a polyhedron, making it easy to find valid cutting planes for the cutting plane algorithm.&lt;/p&gt;

&lt;h2 id=&quot;convexification&quot;&gt;Convexification&lt;/h2&gt;
&lt;p&gt;To convexify an integer program, the objective function must be linear. In this case, the constraints of the integer program consist of a convex set \(C\) and an integer set \({x_j}\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {c^{T}x} \\
\text{subject to } &amp;amp; \quad  x \in C \\
                   &amp;amp; \quad  x_j \in \mathbb{Z}, \quad j \in J \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In this case, the feasible set can be redefined as the convex hull \(S := \text{conv} \left \{ x \in C : x_j \in \mathbb{Z}, j \in J \right \}\). Using the feasible set defined by this convex hull \(S\), we can define a convex problem equivalent to the original problem as follows. This process is called convexification.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {c^{T}x} \\
\text{subject to } &amp;amp; \quad  x \in S \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In the figure below, the blue region is \(C\), the red points are \({x_j}\), and the convex hull \(S\) formed by these two sets is the red region.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_cutting_plane_concept.png&quot; alt=&quot;[Fig1] Cutting Plane&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Cutting Plane&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;출처: https://commons.wikimedia.org/wiki/File:Cutting_plane_algorithm2.png &lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The reason these two formulations are equivalent is because the objective function is linear.&lt;/p&gt;

&lt;h2 id=&quot;special-case-integer-linear-programs&quot;&gt;Special case: integer linear programs&lt;/h2&gt;
&lt;p&gt;Let’s apply the above convexification process to the following integer linear program.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {c^{T}x} \\
\text{subject to } &amp;amp; \quad  Ax \le b \\
                   &amp;amp; \quad  x_j \in \mathbb{Z}, \quad j \in J \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The convex hull \(S\) of the integer linear program is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: If \(A, b\) are rational numbers, then the following set is a polygon.
\(S := \text{conv} \left \{ x : Ax \le b,  x_j \in \mathbb{Z}, j \in J \right \}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So is an integer linear program a linear program? Of course it is. However, in this case, the polyhedron \(S\) can become a very complex polygon with an exponentially large number of inequalities. Therefore, generally, we need to solve the problem using different methods than those used to solve linear programs.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>24 Mixed Integer Programming (part I)</title>
   <link href="http://localhost:4000/contents/vi/chapter24/24_Mixed_integer_programming/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter24/24_Mixed_integer_programming</id>
   <content type="html">&lt;p&gt;This chapter introduces the definition, relationships, and examples of Mixed Integer Programming, and presents methods for finding optimal solutions by indirectly utilizing relaxation to find solutions for Integer programming.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>24-05 Branch and bound algorithm (B&B)</title>
   <link href="http://localhost:4000/contents/vi/chapter24/24_05_Branch_and_bound_algorithm/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter24/24_05_Branch_and_bound_algorithm</id>
   <content type="html">&lt;p&gt;Let’s find out the method of solving Integer programs through Branch and bound algorithm and Convex relaxation.&lt;/p&gt;

&lt;h2 id=&quot;definition-and-properties&quot;&gt;Definition and properties&lt;/h2&gt;
&lt;p&gt;Branch and bound algorithm is the most common method for solving integer programs. It is mainly a divide and conquer approach that breaks the original problem into several smaller problems (sub-problems) to approach the correct answer.&lt;/p&gt;

&lt;p&gt;When the constraint set \(X = X_{1} \cup X_{2} \cup \dotsc \cup X_{k}\) is a union of partitions consisting of each \(X_{i}\),&lt;/p&gt;
&lt;blockquote&gt;
\[\min_{x \in X} f(x) = \min_{i = 1, \dotsc , k} \lbrace \min_{x \in X_{i}} f(x) \rbrace .\]
&lt;/blockquote&gt;

&lt;p&gt;We can find the optimal solution by partitioning the region and finding the minimum.&lt;/p&gt;

&lt;p&gt;Any feasible solution of a sub-problem can be set as the upper bound \(u(X)\). To obtain the lower bound, we find the lower bound \(l(X_{i})\) of each sub-problem. Then, if \(l(X_{i}) \geq u(X)\), we exclude the sub-problem \(\min_{x \in X_{i}} f(x)\) corresponding to this part.&lt;/p&gt;

&lt;p&gt;The Integer Programming problem (IP) is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; x \in C \\\\
&amp;amp;&amp;amp;&amp;amp;x_j \in \mathbb{Z}, \quad j \in J \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f : \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\quad \text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And when the Convex Relaxation (CR) problem is as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;x \in C \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f : \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\quad \text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The problem is solved recursively.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If the constraint set is trivial, solve the (CR) problem. If the solution is less than the current upper bound, update the upper bound. Stop.
    &lt;ul&gt;
      &lt;li&gt;If (CR) is infeasible, then (IP) is also infeasible. Stop.&lt;/li&gt;
      &lt;li&gt;If the solution \(x^{\star}\) of (CR) is also feasible for (IP), then \(x^{\star}\) becomes the solution. Stop.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Find the lower bound of the problem.
    &lt;ul&gt;
      &lt;li&gt;If the solution \(x^{\star}\) of (CR) is infeasible for (IP), update the lower bound of (IP).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If the lower bound is greater than the current upper bound, Stop.&lt;/li&gt;
  &lt;li&gt;Split the constraint set and solve each sub-problem recursively.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;after-branching&quot;&gt;After branching&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;After branching, solve each subproblem.&lt;/li&gt;
  &lt;li&gt;If the lower bound of a subproblem is greater than the current upper bound, there is no need to consider the subproblems below it.&lt;/li&gt;
  &lt;li&gt;The most reliable method for computing the lower bound is through convex relaxation, but other methods (e.g., Lagrangian relaxation) are also used.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>24-04 Relaxations</title>
   <link href="http://localhost:4000/contents/vi/chapter24/24_04_Relaxations/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter24/24_04_Relaxations</id>
   <content type="html">&lt;p&gt;For relaxation, specific conditions must be satisfied, and Convex relaxation and Lagrangian relaxation methods can be utilized. Let’s examine the detailed content.&lt;/p&gt;

&lt;h2 id=&quot;conditions-for-relaxations&quot;&gt;Conditions for Relaxations&lt;/h2&gt;
&lt;p&gt;If a general optimization problem is defined as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_{x \in X} f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;The relaxation of this problem is defined as follows when represented as an arbitrary optimization problem:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x \in Y} \: g(x)\\\\
&amp;amp;\text{such that}\\\\
&amp;amp;\text{① } X \subset Y \quad \text{ and}\\\\ 
&amp;amp;\text{② } g(x) \leq f(x) \text{ for all } x \in X 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If the objective functions \(f(x)\) and \(g(x)\) are different, both conditions must be satisfied, and if they are the same, only condition ① needs to be satisfied.
By these two conditions, the optimal value of the relaxation becomes a lower bound of the optimal value of the original problem.&lt;/p&gt;

&lt;h2 id=&quot;convex-relaxations&quot;&gt;Convex relaxations&lt;/h2&gt;
&lt;p&gt;When the given problem is as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; x \in C \\\\
&amp;amp;&amp;amp;&amp;amp;x_j \in \mathbb{Z}, \quad j \in J \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f : \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\quad \text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;convex relaxation can be expressed as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp; f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; x \in C \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f: \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;lagrangian-relaxations&quot;&gt;Lagrangian relaxations&lt;/h2&gt;
&lt;p&gt;\(X\)가 convex and, integer constraints를 모두 포함할 when,, as follows: problem를 정의 할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;Ax \leq b \\\\
&amp;amp;&amp;amp;&amp;amp; x_{j} \in \mathbb{Z} \quad x \in X 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이 when,, constraints를 objectiveto, 더하여, 어떤 \(u \geq 0\)to, about, Lagrangian relaxation을 하면, as follows:.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
L(u) = &amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) + u^{\top}(Ax-b) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;x \in X
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Lagrangian form을 through,서 constraint set이 확장되었고, feasible \(x\)about, \(Ax \leq b\)을 만족하므to,, always, \(f(x) + u^{\top}(Ax - b) \leq f(x), u \geq 0\)이 성립한다. therefore, \(L(u)\)는 임의의 \(u \geq 0\)about,서 lower bound이고, 최선의 lower bound는 dual problem \(\max_{u \geq 0} L(u)\)을 solution결함with,써 obtaining,낼 수 있다. \(L(u)\)는 convex function의 point-wise minimization이기 because of, concave optimization problem이 된다는 것을 기억하자.&lt;/p&gt;

&lt;p&gt;앞서 언급되었던 Facility location problemto, Lagrangian relaxation을 applying, 보면, unconstrained \(v\)about, 다음 식을 푸는 problemto, 변형된다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
L(u) = &amp;amp;\min_{x} &amp;amp;&amp;amp; \sum_{i = 1}^{n} f_{j}y_{j} + \sum_{i = 1}^{m}\sum_{j = 1}^{n}(c_{ij} - v_{i})x_{ij} + \sum_{i = 1}^{m} v_{i} \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; x_{ij} \leq y_{j} \quad i = 1 \dotsc m, \quad j = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp; x_{ij}, y_{j} \in \lbrace 0, 1 \rbrace \quad  i = 1 \dotsc m, \quad j = 1 \dotsc n 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;각각의 \(v\)about, Lagrange relaxation \(L(v)\)는 쉽게 풀릴 수 있다 :&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(x_{ij}(v) =\begin{cases}1 &amp;amp; \text{if} \quad c_{ij} - v_{i} &amp;lt; 0 \quad \text{and}  \quad \sum_{l} (c_{lj} - v_{l})^{-} + f_{j} &amp;lt; 0 \\\\
0 &amp;amp; \text{otherwise.} \end{cases}\)
\(y_{j}(v) =\begin{cases}1 &amp;amp; \text{if } \quad \sum_{l} (c_{lj} - v_{l})^{-} + f_{j} &amp;lt; 0 \\\\
0 &amp;amp; \text{otherwise.} \end{cases}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이는 lower bound \(L(v)\) and, heuristic primal solution을 도출 할 수 있도록 한다. also, \(-L(v)\)의 부분미분(subdifferential)을 사용한다면 computation도 쉬워진다. subgradient method를 using, \(\max_{v} L(v)\)를 \(\min_{v} -L(v)\) to, transformation시켜서 problem를 풀어갈 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>24-03 Solving integer programs</title>
   <link href="http://localhost:4000/contents/vi/chapter24/24_03_Solving_integer_programs/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter24/24_03_Solving_integer_programs</id>
   <content type="html">&lt;p&gt;After transforming the mathematical formulation of Integer programming, techniques such as relaxation are needed to solve the problem. Let’s examine the constraints that appear in integer programs and what approaches are taken to address the problem.&lt;/p&gt;

&lt;h2 id=&quot;hardness-of-integer-programs&quot;&gt;Hardness of integer programs&lt;/h2&gt;
&lt;p&gt;Solving Integer program problems is much more difficult than solving convex optimization problems. General Integer programming is &lt;a href=&quot;https://en.wikipedia.org/wiki/NP-hardness&quot;&gt;NP-hard&lt;/a&gt;, requiring at least polynomial time without even knowing the possibility of solvability. In this case, by removing constraints on integer constraints and performing convex relaxation, we can obtain a lower bound that approaches the optimal value.&lt;br /&gt;&lt;br /&gt;
When solving problems using convex relaxation, the following limitations may occur:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Finding a feasible integer solution can become difficult.&lt;/li&gt;
  &lt;li&gt;The optimal solution obtained under relaxation conditions may be distant from the optimal solution obtained with integer programming.&lt;/li&gt;
  &lt;li&gt;The value after approximation (rounding) may differ from the optimal value.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;algorithmic-template-for-solving-integer-programs&quot;&gt;Algorithmic template for solving integer programs&lt;/h2&gt;
&lt;p&gt;When \(X\) is convex and includes integrality constraints, the integer program is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[z : = \min_{x \in X} f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Unlike convex optimization, there are no direct “optimality conditions” that prove a feasible point \(x* \in X\) is optimal. Instead, we can use a method that finds approximations of the optimal by finding lower bound \(\underline{z} \leq z\) and upper bound \(\bar{z} \geq z\) while approaching \(\underline{z} = \bar{z}\).&lt;/p&gt;

&lt;h3 id=&quot;algorithmic-template&quot;&gt;Algorithmic template&lt;/h3&gt;
&lt;p&gt;Observing the decreasing sequence of upper bounds,&lt;/p&gt;
&lt;blockquote&gt;
\[\bar{z_1} \geq \bar{z_2} \geq \dotsc \bar{z_s} \geq z\]
&lt;/blockquote&gt;

&lt;p&gt;Observing the increasing sequence of lower bounds,&lt;/p&gt;
&lt;blockquote&gt;
\[\underline{z_1} \leq \underline{z_2} \leq \dotsc \underline{z_t} \leq z\]
&lt;/blockquote&gt;

&lt;p&gt;For any \(\epsilon &amp;gt; 0\), the value of \(z\) is determined within the range where \(\bar{z_s} - \underline{z_t} \leq \epsilon\).&lt;/p&gt;

&lt;h3 id=&quot;primal-bounds&quot;&gt;Primal bounds&lt;/h3&gt;
&lt;p&gt;According to the previous \(z\) formula, for any feasible \(x \in X\), \(f(x) \geq z\) always holds, and in this case, \(f(x)\) is an upper bound. However, since we cannot always find a feasible \(x\), if the \(x\) value is included in the corresponding set, the problem can be solved easily, but this may not always be the case.&lt;/p&gt;

&lt;h3 id=&quot;dual-bounds&quot;&gt;Dual bounds&lt;/h3&gt;
&lt;p&gt;Usually also called lower bounds, their values are found through relaxation. Detailed explanations are added in the next section.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>24-02 Examples of integer programs</title>
   <link href="http://localhost:4000/contents/vi/chapter24/24_02_Example_of_integer_programs/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter24/24_02_Example_of_integer_programs</id>
   <content type="html">&lt;p&gt;In this section, let’s examine various examples corresponding to Integer programming and learn how they are utilized.&lt;/p&gt;

&lt;h2 id=&quot;knapsack-problem&quot;&gt;Knapsack problem&lt;/h2&gt;
&lt;p&gt;The Knapsack problem is a traditional combinatorial optimization problem where the volume that can be put into the knapsack is limited, constraining the total magnitude of items that can fit inside the knapsack. When this constraint exists, the problem aims to select items with maximum value. This problem can be expressed using binary variables \(x\), where \(x_{j}\) takes a value of 0 or 1 depending on whether the \(j\)-th item is selected or not.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{x} &amp;amp;&amp;amp; c^\intercal x \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; a^\intercal x \leq b \\\\
&amp;amp;&amp;amp;&amp;amp;x_{j} \in {0, 1}, j = 1, \dotsc , n
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(c_{j}, a_{j}\) represent the value and magnitude (volume) of the \(j\)-th item, respectively.&lt;/p&gt;

&lt;h2 id=&quot;assignment-problem&quot;&gt;Assignment problem&lt;/h2&gt;
&lt;p&gt;Let’s assume there are \(n\) people and \(n\) tasks. Each person can be assigned to exactly one task. Here, \(c_{ij}\) represents the cost required for person \(i\) to perform task \(j\). The Assignment problem aims to assign \(n\) people to \(n\) tasks with the minimum cost. To optimize these conditions, the mathematical formulation is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;\sum_{i = 1}^{n} \sum_{j = 1}^{n} c_{ij} x_{ij} \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;\sum_{i = 1}^{n} x_{ij} = 1, j = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp;\sum_{j = 1}^{n} x_{ij} = 1, i = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp;x_{ij} \in \lbrace 0, 1\rbrace \quad i = 1 \dotsc n, \quad j = 1 \dotsc n
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;facility-location-problem&quot;&gt;Facility location problem&lt;/h2&gt;
&lt;p&gt;The Facility location problem aims to minimize transportation costs from specific facilities to customers.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Let’s assume there are depots \(N = \lbrace 1, \dotsc, n \rbrace\) and customers \(M = \lbrace 1, \dotsc, m \rbrace\).&lt;br /&gt;
The fixed cost \(f_{j}\) is associated with using depot \(j\).
The transportation cost \(c_{ij}\) is the cost incurred when goods delivered to customer \(i\) are transported from depot \(j\).&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The decisions to be made here are which depots should be operational and which customers should receive deliveries from each depot, with the goal of minimizing both fixed costs and transportation costs by deriving and solving the mathematical formulation.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y} &amp;amp;&amp;amp; \sum_{i = 1}^{n} f_{j} y_{j} + \sum_{i = 1}^{m} \sum_{j = 1}^{n} c_{ij} x_{ij} \\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; \sum_{j = 1}^{n} x_{ij} = 1,  \quad i = 1 \dotsc m \\
&amp;amp;&amp;amp;&amp;amp; x_{ij} \leq y_{j},  \quad i = 1 \dotsc m,  \quad j = 1 \dotsc n \\
&amp;amp;&amp;amp;&amp;amp; x_{ij} \in \lbrace 0, 1\rbrace \quad i = 1 \dotsc m, \quad j = 1 \dotsc n \\
&amp;amp;&amp;amp;&amp;amp; y_{j} \in \lbrace 0, 1\rbrace \quad j = 1 \dotsc n \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The first constraint means that each customer can receive goods from one depot. The second constraint states that depot \(j\) must be operational for customer \(i\) to receive goods from there. Since both \(x_{ij}\) and \(y_{j}\) are binary, we can consider \(mn\) constraints. This can also be expressed in a “marginalized” form as the following constraint:&lt;/p&gt;

&lt;blockquote&gt;
\[\sum_{i = 1}^{n} x_{ij} \leq m y_{j}, \quad j = 1 \dotsc n\]
&lt;/blockquote&gt;

&lt;p&gt;Reflecting this, it can be replaced with the following mathematical formulation:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y} &amp;amp;&amp;amp;\sum_{i = 1}^{n} f_{j} y_{j} + \sum_{i = 1}^{m} \sum_{j = 1}^{n} c_{ij} x_{ij} \\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;\sum_{j = 1}^{n} x_{ij} = 1,  \quad i = 1 \dotsc n \\
&amp;amp;&amp;amp;&amp;amp; \sum_{i = 1}^{n} x_{ij} \leq m y_{j}, \quad j = 1 \dotsc n \\
&amp;amp;&amp;amp;&amp;amp; x_{ij} \in \lbrace 0, 1\rbrace \quad i = 1 \dotsc n, \quad j = 1 \dotsc n \\
&amp;amp;&amp;amp;&amp;amp; y_{j} \in \lbrace 0, 1\rbrace \quad j = 1 \dotsc n \\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;k-means-and-k-medoids-clustering&quot;&gt;K-means and K-medoids clustering&lt;/h2&gt;
&lt;p&gt;Clustering is the process of dividing data into similar groups. The K-means algorithm aims to find K clusters by finding \(K\) center values (centroids) that minimize the average distance between data points within clusters. The goal is to find a partition \(S_{1} \cup \dotsc \cup S_{K} = \lbrace 1, \dotsc, n \rbrace\) for the given data. In this case, the following formula is minimized:&lt;/p&gt;

\[\sum_{i = 1}^{K} \sum_{j \in S_{i}} \| x^{(j)} - \mu^{(i)} \|^{2}\]

&lt;p&gt;where \(\mu^{(i)} :  = \frac{1}{| S_{i} |} \sum_{j \in S_{i}} x^{(i)}\),
\(\mu^{(i)}\) represents the centroid of cluster \(i\).&lt;/p&gt;

&lt;p&gt;A method that is more robust to outliers than computing centroids by averaging (K-means) is K-medoids clustering, which sets the center value as the data point closest to the cluster center instead of computing the center values of K clusters using arithmetic mean.
That is, K-medoids clustering is a method that considers each data point (\(y^{(i)}\)) as a center point and designates the data point that yields the minimum value when computed as the centroid.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\sum_{i = 1}^{K} \sum_{j \in S_{i}} \| x^{(j)} - y^{(i)} \|^{2}\)
\(\text{where } y^{(i)} \in \lbrace x^{(j)} : j \in S_{i} \rbrace\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;
This problem can be transformed and represented as an integer program.
First, we define \(d_{ij} = \| x^{(i)} - x^{(j)} \|^2\) and define the following two binary variables:&lt;/p&gt;

\[\begin{align}
&amp;amp;w_{i} =\begin{cases}1 &amp;amp;&amp;amp; \text{if choose } x^{(i)} \text{ as a centroid} \\\\
0 &amp;amp;&amp;amp; \text{otherwise.} \end{cases}\\\\
&amp;amp;z_{ji} =\begin{cases}1 &amp;amp;&amp;amp; \text{if } x^{(j)} \text{ in the cluster with centroid } x^{(i)} \\\\
0 &amp;amp;&amp;amp; \text{otherwise.} \end{cases}
\end{align}\]

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The K-medoids problem can be defined as an optimization problem as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{w, z} &amp;amp;&amp;amp; \sum_{i = 1}^{n} \sum_{j = 1}^{n} d_{ij} z_{ji} \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; z_{ji} \leq w_{i} \\\\
&amp;amp;&amp;amp;&amp;amp; \sum_{i = 1}^{n} w_{i} = k \\\\
&amp;amp;&amp;amp;&amp;amp; w_{ij} \in 0, 1 \quad i = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp; z_{ji} \in 0, 1 \quad j, i = 1 \dotsc n
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The first constraint means that after the centroid is first determined, we will determine whether $x_{j}$ belongs to $x_{i}$ or not.&lt;/p&gt;

&lt;h2 id=&quot;best-subset-selection&quot;&gt;Best subset selection&lt;/h2&gt;
&lt;p&gt;When the conditions \(X = [x^{1} \quad \dotsc \quad x^{p}] \in \mathbb{R}^{n×p}, \quad y \in \mathbb{R}^{n}\) are given, the Best subset selection problem is as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{\beta} &amp;amp;&amp;amp;\frac{1}{2} \| y - X\beta \|^{2} \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;\| \beta \| \leq k\\\\
\end{align}\)
\(\begin{align}
\text{where}  \| \beta \|_{0}  :  = \text{ the number of nonzero entries of } \beta.
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since \(\| \beta \|_{0}\) is a non-convex constraint, the problem can be solved more easily by transforming it using Integer programming.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{\beta, z} &amp;amp;&amp;amp; \frac{1}{2} \| y - X\beta \|^{2} \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; | \beta_{i} | \leq Mz_{i} \quad i = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp;z_{ji} \in \lbrace 0, 1 \rbrace \quad i = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp;\sum_{i = 1}^{p} z_{i} \leq k
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;least-median-of-squares-regression&quot;&gt;Least median of squares regression&lt;/h2&gt;
&lt;p&gt;When the conditions \(X = [x^{1} \quad \dotsc \quad x^{p}] \in \mathbb{R}^{n×p}, \quad y \in \mathbb{R}^{n}\), and \(\beta \in \mathbb{R}^{p}\) are given, if we define \(r : = y - X\beta\), the Least median of squares regression problem is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\beta_{LMS} : = \arg\min_{\beta} (median | r_{i} | ).\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>24-01 Definition</title>
   <link href="http://localhost:4000/contents/vi/chapter24/24_01_Definition/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter24/24_01_Definition</id>
   <content type="html">&lt;p&gt;This section aims to explain the basic concepts for solving optimization problems through the mixed integer program approach.&lt;/p&gt;

&lt;h2 id=&quot;problem-definition&quot;&gt;Problem definition&lt;/h2&gt;
&lt;p&gt;When some variables in an optimization model have the constraint of being integers, this is called an integer program.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp; f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; x \in C \\\\
&amp;amp;&amp;amp;&amp;amp;x_{j} \in \mathbb{Z}, j \in J
\end{align}\)
\(\begin{align}
\text{where } f: \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \subseteq \mathbb{R}^{n} \quad and \quad J \subseteq {1, \dotsc, n}. 
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the above expression, if \(J\) satisfies the following, it is called a pure integer program.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(J =\) { \(1, \dotsc, n\) }&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let us assume that both \(f\) and \(C\) discussed in this section are convex.&lt;/p&gt;

&lt;h2 id=&quot;binary-variables&quot;&gt;Binary variables&lt;/h2&gt;
&lt;p&gt;Looking at some representative examples of integer programs, we can mention yes/no decision problems or logical values.
In this case, we define the problem using binary variables and solve the problem to find values of 0 or 1 for the conditions.&lt;/p&gt;

&lt;p&gt;The combinatorial optimization to be introduced next is directly associated with integer programming. This is because by utilizing binary variables, we can transform existing problems and solve them as new problems.&lt;/p&gt;

&lt;p&gt;Combinatorial optimization problems are defined using the triple \((N, \mathcal{F}, c)\) representation.&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;\(\quad N\) is a finite ground set&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;\(\quad \mathcal{F} \subseteq 2^{N}\) is the set of feasible solutions&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;\(\quad c \in \mathbb{R}^{N}\) is the cost function&lt;br /&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;The ultimate goal is to solve the following equation through the triple \((N, \mathcal{F}, c)\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\quad \min_{S \in \mathcal{F}} &amp;amp; \sum_{i \in S} c_{i} \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;많은 결sum optimization(combinatorial optimization) problem는 binary integer program들to, being used,질 수있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>23 Coordinate Descent</title>
   <link href="http://localhost:4000/contents/vi/chapter23/23_Coordinate_Descent/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter23/23_Coordinate_Descent</id>
   <content type="html">&lt;p&gt;Coordinate descent is an optimization algorithm that iteratively moves along each coordinate axis to find the minimum of the objective function. At each iteration, according to a coordinate selection rule, it determines a coordinate axis (coordinate) or coordinate block, then minimizes the function along the direction of that axis while keeping the unselected coordinate axes or coordinate blocks fixed (exactly or inexactly). Coordinate descent can be utilized not only with gradient-based methods but also with gradient-free methods. Additionally, depending on the case, line search can be used to determine appropriate step sizes for each axis [16].&lt;/p&gt;

&lt;p&gt;Coordinate descent is very simple and easy to implement, and shows very good performance when carefully implemented for appropriate problems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt; lasso regression, lasso GLMs (under proximal Newton), SVMs, group lasso, graphical lasso (applied to the dual), additive modeling, matrix completion, regression with nonconvex penalties&lt;/p&gt;

&lt;h2 id=&quot;references-and-further-readings&quot;&gt;References and Further readings&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Early coordinate descent in optimization:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;D. Bertsekas and J. Tsitsiklis (1989), “Parallel and distributed domputation: numerical methods”&lt;/li&gt;
  &lt;li&gt;Z. Luo and P. Tseng (1992), “On the convergence of the coordinate descent method for convex differentiable minimization”&lt;/li&gt;
  &lt;li&gt;J. Ortega and W. Rheinboldt (1970), “Iterative solution of nonlinear equations in several variables”&lt;/li&gt;
  &lt;li&gt;P. Tseng (2001), “Convergence of a block coordinate descent method for nondifferentiable minimization”
35 Early coordinate descent references in statistics and ML:&lt;/li&gt;
  &lt;li&gt;I. Daubechies and M. Defrise and C. De Mol (2004), “An iterative thresholding algorithm for linear inverse problems with a sparsity constraint”&lt;/li&gt;
  &lt;li&gt;J. Friedman and T. Hastie and H. Hoefling and R. Tibshirani (2007), “Pathwise coordinate optimization”&lt;/li&gt;
  &lt;li&gt;W. Fu (1998), “Penalized regressions: the bridge versus the lasso”&lt;/li&gt;
  &lt;li&gt;T. Wu and K. Lange (2008), “Coordinate descent algorithms for lasso penalized regression”&lt;/li&gt;
  &lt;li&gt;A. van der Kooij (2007), “Prediction accuracy and stability of regresssion with optimal scaling transformations”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Coordinate descent의 응용:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;O. Banerjee and L. Ghaoui and A. d’Aspremont (2007), “Model selection through sparse maximum likelihood estimation”&lt;/li&gt;
  &lt;li&gt;J. Friedman and T. Hastie and R. Tibshirani (2007), “Sparse inverse covariance estimation with the graphical lasso”&lt;/li&gt;
  &lt;li&gt;J. Friedman and T. Hastie and R. Tibshirani (2009), “Regularization paths for generalized linear models via coordinate descent”&lt;/li&gt;
  &lt;li&gt;C.J. Hsiesh and K.W. Chang and C.J. Lin and S. Keerthi and S. Sundararajan (2008), “A dual coordinate descent method for large-scale linear SVM”&lt;/li&gt;
  &lt;li&gt;R. Mazumder and J. Friedman and T. Hastie (2011), “SparseNet: coordinate descent with non-convex penalties”&lt;/li&gt;
  &lt;li&gt;J. Platt (1998), “Sequential minimal optimization: a fast algorithm for training support vector machines”
37 Recent theory for coordinate descent:&lt;/li&gt;
  &lt;li&gt;A. Beck and L. Tetruashvili (2013), “On the convergence of block coordinate descent type methods”&lt;/li&gt;
  &lt;li&gt;Y. Nesterov (2010), “Efficiency of coordinate descent methods on huge-scale optimization problems”&lt;/li&gt;
  &lt;li&gt;J. Nutini, M. Schmidt, I. Laradji, M. Friedlander, H. Koepke (2015), “Coordinate descent converges faster with the Gauss- Southwell rule than random selection”&lt;/li&gt;
  &lt;li&gt;A. Ramdas (2014), “Rows vs columns for linear systems of equations—randomized Kaczmarz or coordinate descent?”&lt;/li&gt;
  &lt;li&gt;P. Richtarik and M. Takac (2011), “Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function”&lt;/li&gt;
  &lt;li&gt;A. Saha and A. Tewari (2013), “On the nonasymptotic convergence of cyclic coordinate descent methods”&lt;/li&gt;
  &lt;li&gt;S. Wright (2015), “Coordinate descent algorithms”
38 Screening rules and graphical lasso references:&lt;/li&gt;
  &lt;li&gt;L. El Ghaoui and V. Viallon and T. Rabbani (2010), “Safe feature elimination in sparse supervised learning”&lt;/li&gt;
  &lt;li&gt;R. Tibshirani, J. Bien, J. Friedman, T. Hastie, N. Simon, J. Taylor, and R. J. Tibshirani (2011), “Strong rules for discarding predictors in lasso-type problems”&lt;/li&gt;
  &lt;li&gt;R. Mazumder and T. Hastie (2011), “The graphical lasso: new insights and alternatives”&lt;/li&gt;
  &lt;li&gt;R. Mazumder and T. Hastie (2011), “Exact covariance thresholding into connected components for large-scale graphical lasso”&lt;/li&gt;
  &lt;li&gt;J. Wang, P. Wonka, and J. Ye (2015), “Lasso screening rules via dual polytope projection”&lt;/li&gt;
  &lt;li&gt;D. Witten and J. Friedman and N. Simon (2011), “New insights and faster computations for the graphical lasso”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Convergence analysis:&lt;/strong&gt;&lt;br /&gt;
Coordinate descent의 convergence analysisto, about, 연구 흐름을 간략히 소개하겠다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Convergence of coordinatewise minimization for solving linear systems, the Gauss-Seidel method, is a classic topic. E.g., see Golub and van Loan (1996), or Ramdas (2014) for a modern twist that looks at randomized coordinate descent&lt;/li&gt;
  &lt;li&gt;Nesterov (2010) considers randomized coordinate descent for smooth functions and shows that it achieves a rate O(1/ε) under a Lipschitz gradient condition, and a rate O(log(1/ε)) under strong convexity&lt;/li&gt;
  &lt;li&gt;Richtarik and Takac (2011) extend and simplify these results, considering smooth plus separable functions, where now each coordinate descent update applies a prox operation&lt;/li&gt;
  &lt;li&gt;Saha and Tewari (2013) consider minimizing l1 regularized functions of the form g(β) + λ∥β∥1, for smooth g, and study both cyclic coordinate descent and cyclic coordinatewise min. Under (very strange) conditions on g, they show both methods dominate proximal gradient descent in iteration progress&lt;/li&gt;
  &lt;li&gt;Beck and Tetruashvili (2013) study cyclic coordinate descent for smooth functions in general. They show that it achieves a rate O(1/ε) under a Lipschitz gradient condition, and a rate O(log(1/ε)) under strong convexity. They also extend these results to a constrained setting with projections&lt;/li&gt;
  &lt;li&gt;Nutini et al. (2015) analyze greedy coordinate descent (called Gauss-Southwell rule), and show it achieves a faster rate than randomized coordinate descent for certain problems&lt;/li&gt;
  &lt;li&gt;Wright (2015) provides some unification and a great summary. Also covers parallel versions (even asynchronous ones)&lt;/li&gt;
  &lt;li&gt;General theory is still not complete; still unanswered questions (e.g., are descent and minimization strategies the same?)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>23-04 Example: Pathwise coordinate descent for lasso</title>
   <link href="http://localhost:4000/contents/vi/chapter23/23_04_Example_pathwise_coordinate/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter23/23_04_Example_pathwise_coordinate</id>
   <content type="html">&lt;p&gt;In this section, Pathwise coordinate descent for lassoto, about, 개요를 간단히 소개하도록 한다 [&lt;a href=&quot;https://arxiv.org/pdf/0708.1485.pdf&quot;&gt;Friedman et al. (2007)&lt;/a&gt;] [&lt;a href=&quot;https://www.jstatsoft.org/article/view/v033i01/v33i01.pdf&quot;&gt;Friedman et al. (2009)&lt;/a&gt;].&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lasso regression problem:&lt;/strong&gt;
\(\min_{\beta} \frac{1}{2} \| y - X\beta \|_2^2 + \lambda \|\beta\|_1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;/contents/vi/chapter07/07_03_03_example_lasso_optimality_condition/&quot;&gt;07-03-03 Example: Lasso Optimality Condition&lt;/a&gt;at, lasso regression problemto, about, optimality condition을 유도solution 보았다. 위 problemto, about, optimal solution는 다음의 condition,을 만족한다.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
X_1^T(y-X\beta) &amp;amp;= \lambda v_1\\
X_2^T(y-X\beta) &amp;amp;= \lambda v_2\\
\dots\\
X_p^T(y-X\beta) &amp;amp;= \lambda v_p
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;
\(X_i,i \in \{ 1,2,…,p \}\)는 주어진 matrix \(X\)의 \(i\)번째 열(column) 데이터를 의미한다.&lt;/p&gt;

&lt;p&gt;여기서 \(v=(v_1,v_2,\dots,v_p)\)는 \(\beta=(\beta_1,\beta_2,\dots,\beta_p )\)to, about, subgradient다.&lt;/p&gt;
&lt;blockquote&gt;

\[v_i, i \in \{1,2,\dots,p \} = 
\begin{cases}
\{ 1 \}  &amp;amp;\text{if $\beta_i &amp;gt; 0$} \\
\{-1 \}  &amp;amp;\text{if $\beta_i &amp;lt; 0$} \\
[-1,1]   &amp;amp;\text{if $\beta_i = 0$}
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;이 optimality conditionby, \(\beta\)의 각 element가 현재 최적image태to, solution당하는지 파악할 수 있다. Coordinate descent algorithm을 이용하면 아직 최적image태to, 도달하지 못한 element만을 업데이트하는 방식with, 좀 더 효율적with, lasso problem를 푸는 것이 가능solution진다. also, \(\lambda\)의 값이 클수록 lasso regression problemat, coordinate descent algorithm이 더 빨리 동작하는 경향성을 utilizing, \(\lambda\)를 점점 reducing,가는 방식(warm start)with, solutionto, 더욱 빠르게 접근한다.&lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;

&lt;h3 id=&quot;outer-loop-pathwise-strategy&quot;&gt;Outer loop (pathwise strategy):&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;\(\lambda_1 &amp;gt; \lambda_2 &amp;gt; \dots &amp;gt; \lambda_r\)의 순서를 따라 optimal solution를 computation한다.&lt;/li&gt;
  &lt;li&gt;Tuning parameter  \(\lambda_k\)at, computation된 result,를  \(\lambda_{k+1}\)to, about, coordinate descent algorithm을 초기화하는데 사용한다. (warm start)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;inner-loop-active-set-strategy&quot;&gt;Inner loop (active set strategy):&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;하나 or, 적은 수의 coordinate cycle을 시행한다. and, 0이 아닌 \(\beta\)의 element를 active set \(A\)to, 기록한다.&lt;/li&gt;
  &lt;li&gt;\(A\)to, 기록된 element들about,서만 convergence할 when,to, coordinate cycle을 시행한다.&lt;/li&gt;
  &lt;li&gt;\(\beta\)의 모든 element들about, optimality condition을 확인한다. condition,을 만족하지 않는 element가 있으면 \(A\)to, 추가하고 step 1with, 다시 돌아간다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;통image적with, pathwise strategy는 problemat, 주어진 \(\lambda\)to, about, solution를 바to, 구하는 것보다 훨씬 효율적with, 동작한다.&lt;/li&gt;
  &lt;li&gt;Active set strategy는 sparsityabout, 이점이 있다. 이 because of, coordinate descent는 ridge regression보다 lasso regressionat, 훨씬 더 빠르게 동작한다. (reference: &lt;a href=&quot;https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/&quot;&gt;ridge regressionand, lasso regression의 경향성 분석&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Pathwise coordinate descent for lasso는 lasso regression problemabout, 가장 빠르다고 informing,진 다른 algorithm들to, 비견될만큼 빠르게 동작한다.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>23-03 Example: lasso regression</title>
   <link href="http://localhost:4000/contents/vi/chapter23/23_03_Example_lasso_regression/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter23/23_03_Example_lasso_regression</id>
   <content type="html">&lt;p&gt;Lasso regression problem를 아래and, 같이 nonsmooth part가 분리되어있는 objective function의 형태to, 정by,보겠다.&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{\beta} \frac{1}{2} \| y - X\beta \|_2^2 + \lambda \|\beta\|_1\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;
\(\|\beta\|_1 = \sum_{i=1}^p | \beta_i |\)&lt;/p&gt;

&lt;p&gt;\(\beta_j, j \neq i\) 가 고정된 값일when,, 주어진 objective function를 minimization시키는 \(\beta_i\)를 let’s find.&lt;/p&gt;

\[\begin{align}
&amp;amp;0 = \nabla_i f(\beta) = X_i^T X_i \beta_i + X_i^T(X_{-i} \beta_{-i} - y) + \lambda s_i,\\\\
&amp;amp;\text{where } s_i \in \partial |\beta_i|
\Rightarrow 
\beta_i = S_{\lambda / \|X_i\|_2^2} \big( \frac{X_i^T(y-X_{-i} \beta_{-i})}{X_i^TX_i} \big)
\end{align}\]

&lt;p&gt;Solution은 thresholding level이 \(\lambda / \|X_i\|_2^2\)인 soft-thresholding functionand,도 같다. Coordinate descent를 through, \(\beta_i\) for \(i=1,2,\dots,p,1,2,\dots\)를 iteration하며 업데이트 한다.&lt;/p&gt;

&lt;h2 id=&quot;실험-convergence속도-비교---pg-vs-agd-vs-cd&quot;&gt;실험: convergence속도 비교 - PG vs AGD vs CD&lt;/h2&gt;

&lt;p&gt;아래 그래프는 \(n=100, p=20\)인 lasso regression problemabout, proximal gradient descent, accelerated gradient descent, coordinate descent의 convergence속도를 comparing, showing,준다. (가to,axis의 k는 한 step (PD, AGD) or, 한 cycle (CD)을 나타낸다.)&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter23/pd_vs_agd_vs_cd.png&quot; alt=&quot;[Fig1] PD vs AGD vs CD [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] PD vs AGD vs CD [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/contents/vi/chapter23/23_02_Example_linear_regression/&quot;&gt;Linear regression의 예시&lt;/a&gt;at,and, 마찬가지to, lasso regression problemat,도 coordinate descent는 월등한 convergence속도를 보인다. (First-order method보다 더 많은 정보를 활용한다.)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; 위 실험at,의 모든 methods는 각 iteration당 \(O(np)\) flops의 시간복잡도를 보인다.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>23-02 Example: linear regression</title>
   <link href="http://localhost:4000/contents/vi/chapter23/23_02_Example_linear_regression/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter23/23_02_Example_linear_regression</id>
   <content type="html">&lt;p&gt;Let’s define the linear regression problem as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\min_{\beta} \frac{1}{2} \| y - X\beta \|_2^2,\)
\(\text{given } y \in \mathbb{R}^n \text{ and } X \in \mathbb{R}^{n \times p} \text{ with columns } X_1, \dots, X_p.\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When \(\beta_j,\: j \neq i\) are fixed values, let’s find \(\beta_i\) that minimizes the given objective function.
(\(-i\) means the remaining terms excluding \(i\). - In the case of \(X\), the remaining columns excluding the \(i\)-th column.)&lt;/p&gt;

\[\begin{align}
0 &amp;amp;= \nabla_i f(\beta)\\\\
&amp;amp;= X_i^T (X\beta - y)\\\\
&amp;amp;= X_i^T (X_i \beta_i + X_{-i} \beta_{-i} - y)\\\\
\Rightarrow\\\\
&amp;amp;\beta_i = \frac{X_i^T (y - X_{-i} \beta_{-i})}{X_i^T X_i}
\end{align}\]

&lt;p&gt;Through coordinate descent, we iterate and update \(\beta_i\) for \(i=1,2,\dots,p,1,2,\dots\).&lt;/p&gt;

&lt;h2 id=&quot;experiment-convergence-speed-comparison---gd-vs-agd-vs-cd&quot;&gt;Experiment: Convergence speed comparison - GD vs AGD vs CD&lt;/h2&gt;

&lt;p&gt;The graph below shows the convergence speeds of coordinate descent, gradient descent, and accelerated gradient descent for a linear regression problem with \(n=100, p=20\). (The k on the horizontal axis represents one step (GD, AGD) or one cycle (CD).)&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter23/gd_vs_agd_vs_cd.png&quot; alt=&quot;[Fig1] GD vs AGD vs CD [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] GD vs AGD vs CD [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;According to the above results, coordinate descent shows significantly better convergence speed than AGD, which is optimal among first-order methods. Why can this phenomenon occur? To conclude, coordinate descent can achieve performance that far surpasses AGD because it utilizes more information than first-order methods. This is because coordinate descent uses the latest information updated in the previous step at each step within one cycle. (That is, CD is not a first-order method.)&lt;/p&gt;

&lt;h3 id=&quot;q-then-is-it-fair-to-compare-one-cycle-of-cd-with-one-step-of-gd-in-the-above-experiment&quot;&gt;Q. Then, is it fair to compare one cycle of CD with one step of GD in the above experiment?&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;A. Yes.&lt;/strong&gt; The CD update formula introduced earlier can be modified to have a time complexity of \(O(n)\) per step. Then, the time complexity of one cycle for CD becomes \(O(np)\), which has the same time complexity as one step of GD.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Gradient descent update:&lt;/strong&gt; \(\beta \leftarrow \beta + tX^T(y-X\beta)\), the time complexity of the \(X\beta\) operation becomes \(O(np)\) flops.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>23-01 Coordinate Descent</title>
   <link href="http://localhost:4000/contents/vi/chapter23/23_01_Coordinate_descent/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter23/23_01_Coordinate_descent</id>
   <content type="html">&lt;p&gt;In this chapter, we introduce a method called coordinate descent that is extremely simple, efficient, and highly scalable. First, let’s start with some simple questions and answers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q1. When function \(f: \mathbb{R}^n \rightarrow \mathbb{R}\) is convex and differentiable, if the point where \(f\) is minimized along each coordinate axis is \(x\), is this \(x\) a global minimizer?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A1: Yes. Since \(\nabla f(x) = 0\), \(x\) is a global minimizer of \(f\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The above question is equivalent to asking whether \(f(x + \delta e_i) \ge f(x)\) is satisfied for all \(\delta, i\) when \(e_i = (0, \dots, 1, \dots, 0) \in \mathbb{R}^n\) is the \(i\)-th standard basis vector. That is, since we cannot make \(f\) smaller by moving in any coordinate axis direction from \(x\), the partial derivatives in all axis directions become 0.&lt;/p&gt;

\[\nabla f(x) = \big( \frac{\partial f}{\partial x_1}(x), \dots, \frac{\partial f}{\partial x_n}(x) \big) = (0, \dots, 0) = 0\]

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter23/smooth_function.png&quot; alt=&quot;[Fig1] Smooth convex function f [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$[Fig1] \; Smooth \; convex \; function \; f \; [3]$$ &lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q2. Then, when \(f: \mathbb{R}^n \rightarrow \mathbb{R}\) is convex but ‘non-differentiable’ function, is the point \(x\) where \(f\) is minimized along each coordinate axis always a global minimizer?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A2: No. In this case, we cannot assert that \(x\) is a global minimizer of \(f\). (Counterexample: Fig2 below)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Looking at the contour lines on the right side of the counterexample below, we can see that although the marked point is not the global minimum, \(f\) cannot be made smaller by moving in any coordinate axis direction. (To make \(f\) smaller, one must be able to move inside the contour lines.) This is because at this position, all inner regions of the contour lines are contained within the two tangent lines parallel to the coordinate axes. On the other hand, when \(f\) is a differentiable convex function, only one tangent line exists at any point on the contour lines, so this phenomenon does not occur.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter23/non-smooth_function.png&quot; alt=&quot;[Fig2] Counterexample: Non-smooth convex function f [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$[Fig2] \; Counterexample: Non \, smooth \; convex \; function \; f \; [3]$$ &lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q3. When \(f\) can be expressed as the sum of a differentiable convex function \(g\) and a convex function \(h\), is the point \(x\) where \(f\) is minimized along each coordinate axis always a global minimizer? (That is, \(f(x) = g(x) + \sum_{i=1}^{n} h_i(x_i)\))&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A3. Yes. This is because it satisfies the following for any \(y\).&lt;/strong&gt;
\(\begin{align}
f(y) - f(x) &amp;amp;\ge \nabla g(x)^T (y-x) + \sum_{i=1}^{n} \big[ h_i(y_i) - h_i(x_i) \big] \\\\
&amp;amp;= \sum_{i=1}^{n} \big[ \underbrace{\nabla_i g(x) (y_i - x_i) + h_i(y_i) - h_i(x_i)}_{\ge 0} \big] \ge 0
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof:&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Let \(F_i(x_i) = g(x_i ; x_{-i}) + h_i(x_i)\). (\(g(x_i ; x_{-i})\) means viewing only the \(i\)-th element of \(x\) as a variable, and the rest as fixed values.)&lt;/p&gt;

\[\begin{align}
&amp;amp; \: 0 \in \partial F_i (x_i) \\\\
\Leftrightarrow &amp;amp; \: 0 \in \{ \nabla_i g(x) \} + \partial h_i(x_i)\\\\
\Leftrightarrow &amp;amp; \: - \nabla_i g(x) \in \partial h_i(x\_i)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;By the &lt;a href=&quot;/contents/vi/chapter07/07_01_subgradient/&quot;&gt;definition of subgradient&lt;/a&gt;,&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; h_i(y_i) \ge h_i(x_i) - \nabla_i g(x) (y_i - x_i)\\\\
\Leftrightarrow &amp;amp; \nabla_i g(x) (y_i - x_i) + h_i(y_i) - h_i(x_i) \ge 0.
\end{align}\]
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter23/separable_non-smooth.png&quot; alt=&quot;[Fig3] Convex function f with separable non-smooth parts [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$[Fig3] \; Convex \; function \; f \; with \; separable \; non \,smooth \; parts \; [3]$$ &lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The minimizer of \(f(x) = g(x) + \sum_{i=1}^{n} h_i(x_i)\) with \(g\) convex, differentiable and \(h_i\) convex can be found using &lt;strong&gt;coordinate descent&lt;/strong&gt;. Coordinate descent iterates the following cycle. (Assume that an appropriate initial value \(x^{(0)}\) is set.)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Coordinate Descent:&lt;/strong&gt; &lt;br /&gt;
\(\:\) For \(k = 1,2,3,\dots\),&lt;/p&gt;

\[\begin{align}
x_1^{(k)} &amp;amp;\in \text{arg}\min_{x_1} \: f(x_1, x_2^{(k-1)}, x_3^{(k-1)}, \dots, x_n^{(k-1)})\\\\
x_2^{(k)} &amp;amp;\in \text{arg}\min_{x_2} \: f(x_1^{(k)}, x_2, x_3^{(k-1)}, \dots, x_n^{(k-1)})\\\\
x_3^{(k)} &amp;amp;\in \text{arg}\min_{x_3} \: f(x_1^{(k)}, x_2^{(k)}, x_3, \dots, x_n^{(k-1)})\\\\
&amp;amp; \dots\\\\
x_n^{(k)} &amp;amp;\in \text{arg}\min_{x_n} \: f(x_1^{(k)}, x_2^{(k)}, x_3^{(k)}, \dots, x_n)
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;notes&quot;&gt;Notes:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The process of obtaining \(x_{i+1}^{(k)}, \dots, x_{n}^{(k)}\) uses the newly obtained \(x_i^{(k)}\) in the \(k\)-th cycle.&lt;/li&gt;
  &lt;li&gt;The order of coordinate axes in the cycle can be arbitrarily specified.&lt;/li&gt;
  &lt;li&gt;Two or more coordinate axes can be grouped together and processed as blocks.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The coordinate descent introduced above corresponds to exact coordinatewise minimization. Another approach is inexact coordinatewise minimization using gradients. (Assuming \(f\) is a differentiable convex function)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Coordinate Descent (inexact coordinatewise minimization):&lt;/strong&gt; &lt;br /&gt;
\(\:\) For \(k = 1,2,3,\dots\),&lt;/p&gt;

\[\begin{align}
x_1^{(k)} &amp;amp;= x_1^{(k-1)} - t_{k,1} \cdot \nabla_1 f(x_1^{(k-1)}, x_2^{(k-1)}, x_3^{(k-1)}, \dots, x_n^{(k-1)})\\\\
x_2^{(k)} &amp;amp;= x_2^{(k-1)} - t_{k,2} \cdot \nabla_2 f(x_1^{(k)}, x_2^{(k-1)}, x_3^{(k-1)}, \dots, x_n^{(k-1)})\\\\
x_3^{(k)} &amp;amp;= x_3^{(k-1)} - t_{k,3} \cdot \nabla_3 f(x_1^{(k)}, x_2^{(k)}, x_3^{(k-1)}, \dots, x_n^{(k-1)})\\\\
&amp;amp; \dots\\\\
x_n^{(k)} &amp;amp;= x_n^{(k-1)} - t_{k,n} \cdot \nabla_n f(x_1^{(k)}, x_2^{(k)}, x_3^{(k)}, \dots, x_n^{(k-1)})
\end{align}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>22 Conditional Gradient (Frank-Wolfe) Method</title>
   <link href="http://localhost:4000/contents/vi/chapter22/22_Conditional_Gradient_Method/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter22/22_Conditional_Gradient_Method</id>
   <content type="html">&lt;p&gt;This chapter will examine the Frank-Wolfe algorithm proposed by Marguerite Frank and Philip Wolfe in 1956.&lt;/p&gt;

&lt;p&gt;The Frank-Wolfe algorithm is an iterative first-order optimization algorithm for constrained convex optimization, also called the conditional gradient method, reduced gradient method, and convex combination algorithm.&lt;/p&gt;

&lt;p&gt;This method was originally proposed by Marguerite Frank and Philip Wolfe in 1956. The Frank-Wolfe algorithm considers a linear approximation of the objective function at each iteration and moves toward the minimizer of this linear function.&lt;/p&gt;

&lt;p&gt;[15] Wikipedia. &lt;a href=&quot;https://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe_algorithm&quot;&gt;Frank–Wolfe algorithm&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>22-04 Properties and variants</title>
   <link href="http://localhost:4000/contents/vi/chapter22/22_04_Properties_and_variants/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter22/22_04_Properties_and_variants</id>
   <content type="html">&lt;h2 id=&quot;some-variants&quot;&gt;Some variants&lt;/h2&gt;
&lt;p&gt;Let’s look at some variant conditional gradient methods:&lt;br /&gt;
• &lt;strong&gt;Line search&lt;/strong&gt;: Instead of fixing \(γk=2/(k+1),k=1,2,3,...\), we use exact line search for the step size at each \(k = 1, 2, 3, . . .\).&lt;/p&gt;
&lt;blockquote&gt;
\[γ_k = \arg\min_{γ∈[0,1]} f\Bigl( x^{(k−1)} + γ\bigl(s^{(k−1)} − x^{(k−1)} \bigr) \Bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;Backtracking can also be used.&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;Fully corrective&lt;/strong&gt;: Direct update according to the following equation.&lt;/p&gt;
&lt;blockquote&gt;
\[x^{(k)} = \arg\min_y f(y) \: \text{ subject to } y ∈ conv\{ x^{(0)}, s^{(0)}, . . . s^{(k−1)} \}\]
&lt;/blockquote&gt;

&lt;p&gt;This method can achieve much better progress, but the cost is high.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter22/away_steps.png&quot; alt=&quot;[Fig 3] Away step motivation [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 3] Away step motivation [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;another-variant-away-steps&quot;&gt;Another variant: away steps&lt;/h2&gt;
&lt;p&gt;For a faster solution, let’s look at the minimization problem in [Fig 3]. Here, the optimal solution is (0,0). The conditional descent method becomes difficult to move from the initial point (0,1). However, due to away step movement, conditional gradient descent not only moves to promising points but also moves away from unpromising points.&lt;/p&gt;

&lt;p&gt;Let’s assume a convex hull \(C = conv(A)\) for atoms set \(A\)&lt;/p&gt;

&lt;p&gt;We can explicitly represent \(x∈C\) as a convex combination of elements belonging to \(A\).&lt;/p&gt;
&lt;blockquote&gt;
\[x = \sum_{a∈A} λ_a(x)a\]
&lt;/blockquote&gt;

&lt;p&gt;Conditional gradient with away steps: &lt;br /&gt;
\(\text{1. choose } x^{(0)} = a^{(0)} ∈ A\) &lt;br /&gt;
\(\text{2. for } k = 1, 2, 3, . . .\) &lt;br /&gt;
\(\qquad s^{(k−1)} ∈ \arg\min_{a∈A} ∇f(x^{(k−1)})^Ta,\)
\(\qquad a^{(k−1)} ∈ \arg\max_{a∈A, λa(x(k−1))&amp;gt;0} ∇f(x^{(k−1)})^Ta\)
\(\qquad \text{choose } v = s^{(k−1)} − x^{(k−1)} or \quad v = x^{(k−1)} − a^{(k−1)}\)
\(\qquad x^{(k)} = x^{(k−1)} + γ_kv\) &lt;br /&gt;
\(\text{3. end for}\)&lt;/p&gt;

&lt;h2 id=&quot;linear-convergence&quot;&gt;Linear convergence&lt;/h2&gt;
&lt;p&gt;Let’s consider the following unconstrained problem.&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) \: \text{ subject to } x ∈ \mathbb{R}^n\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(f\) is µ-strongly convex and \(∇f\) is L-Lipschitz.&lt;/p&gt;

&lt;p&gt;By iterating gradient descent \(x^{(k+1)} = x^{(k)} − t_k∇f(x^{(k)})\) with \(t_k = 1/L\), the following is satisfied.&lt;/p&gt;
&lt;blockquote&gt;
\[f(x^{(k)}) − f^{\star} ≤ \Bigl( 1 −\frac{µ}{L} \Bigr)^k \bigl( f(x^{(0)}) − f^{\star} \bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;Now let’s also consider the following constrained problem.&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) \: \text{ subject to } x ∈ conv(A) ⊆ \mathbb{R}^n\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;theorem-lacoste-julien--jaggi-2013&quot;&gt;[Theorem (Lacoste-Julien &amp;amp; Jaggi 2013)]&lt;/h3&gt;
&lt;p&gt;Assume that \(f\) is µ-strongly convex, \(∇f\) is L-Lipschitz, and \(A ⊆ \mathbb{R}^n\) is finite.&lt;/p&gt;

&lt;p&gt;With appropriate \(γ_k\), the iteration steps generated by the conditional gradient algorithm always satisfy the following.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x^{(k)}) − f^{\star} ≤ (1 − r)^{k/2}(f(x^{(0)}) − f^{\star}) \text { for } r = \frac{µ}{L}·\frac{Φ(A)^2}{4\text{diam}(A)^2}\)
\(\text{where }Φ(A) = \min_{F ∈faces(conv(A))} dist(F, conv(A \ F))\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If the polytope is planar, \(Φ\) is small and the algorithm converges slowly.&lt;/p&gt;

&lt;h2 id=&quot;path-following&quot;&gt;Path following&lt;/h2&gt;
&lt;p&gt;Let’s look at the following given norm constrained problem&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) \: \text{ subject to } \| x \| ≤ t\]
&lt;/blockquote&gt;

&lt;p&gt;The Frank-Wolfe algorithm can be used for &lt;strong&gt;path following&lt;/strong&gt;. In other words, it means that it can generate a (approximate) solution path \(\hat{x}(t), t ≥ 0\).&lt;/p&gt;

&lt;p&gt;Starting with \(t_0 = 0\) and \(x^{\star}(0) = 0\), fix parameters \(\epsilon, m &amp;gt; 0\) and then iterate for \(k=1,2,3,...\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Compute \(t_k = t_{k−1} + \frac{(1 − 1/m)\epsilon}{\| ∇f(\hat{x}(t_k−1))\|\_{∗}}\) and set \(\hat{x}(t) = \hat{x}(t_{k−1})\) for all \(t ∈ (t_{k−1}, t_k)\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;At \(t = t_k\), execute Frank-Wolfe to compute \(\hat{x}(t_k)\) and terminate when the duality gap is \(≤ \frac{\epsilon}{m}\).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is a method that simplifies existing strategies. [Giesen et al. (2012)]&lt;/p&gt;

&lt;p&gt;Through this &lt;strong&gt;path following&lt;/strong&gt; strategy, we can guarantee the following for all visited $t$:&lt;/p&gt;
&lt;blockquote&gt;
\[f(\hat{x}(t)) − f(x^{\star}(t)) ≤ \epsilon\]
&lt;/blockquote&gt;

&lt;p&gt;That is, it generates a case of suboptimality gap that is uniformly bounded by \(\epsilon\) for all \(t\).&lt;/p&gt;

&lt;p&gt;As shown in the equation below, the Frank-Wolfe duality gap can be redefined as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[g_t(x) = \max_{\|s\|≤1} ∇f(x)^T(x − s) = ∇f(x)^Tx + t\|∇f(x)\|_{∗}\]
&lt;/blockquote&gt;

&lt;p&gt;This is a linear function with respect to $t$. Therefore, if \(g_t(x) ≤ \frac{\epsilon}{m}\), we can increase \(t\) to \(t^+ = t + (1 − 1/m)\epsilon/\|∇f(x)\|_{∗}\) using the following equation.&lt;/p&gt;

&lt;blockquote&gt;
\[g_t+ (x) = ∇f(x)^Tx + t\|∇f(x)\|_{∗} + \epsilon − \epsilon/m ≤ \epsilon\]
&lt;/blockquote&gt;

&lt;p&gt;That is, the duality gap is maintained at \(≤ \epsilon\) between \(t\) and \(t^+\) for the same \(x\).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>22-03 Convergence analysis</title>
   <link href="http://localhost:4000/contents/vi/chapter22/22_03_Convergence_analysis/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter22/22_03_Convergence_analysis</id>
   <content type="html">&lt;h2 id=&quot;convergence-analysis&quot;&gt;Convergence analysis&lt;/h2&gt;
&lt;p&gt;To find out the convergence characteristics of the Frank-Wolfe method, it is necessary to define the curvature constant of \(f\) for \(C\) as follows. [Jaggi (2011)]&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(M = \max_{x,s,y∈C, y = (1−γ)x+γs} \frac{2}{γ^2} \Bigl( f(y) − f(x) − ∇f(x)^T(y − x) \Bigr)\)
\(γ ∈ [0, 1]\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;M을 through,서 actually, function가 선형 approximation(linear approximation)from, 얼마나 먼 경향을 가지고 있는지를 측정할 수도 있다.
여기서 \(M = 0\)은 \(f\)가 선형임을 나타낸다. \(f (y) - f (x) - ∇f (x)^T(y - x)\)는 \(f\)by, 정의 된 Bregman divergence 라 부른다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theorem: 고정 스텝 사이즈 \(γk = 2 / (k + 1), k = 1,2,3, ...\)를 이용한 condition,부 그레디언드 method(conditional gradient method)은 다음을 만족한다.
 \(f(x^{(k)}) − f^{\star} ≤ \frac{2M}{k + 2}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;\(f(x^{(k)}) − f^{\star} ≤ \epsilon\)를 만족하기 for, 필요한 iteration 횟수는 \(O(1/\epsilon)\)이다.&lt;/p&gt;

&lt;p&gt;이제 이 이론은 귀납법with, proving,보고자 한다. however, 바to, 증명with, 넘어가기전 짚고 넘어가야 할 개념을 하나 소개하고자 한다.&lt;/p&gt;

&lt;h2 id=&quot;basic-inequality&quot;&gt;Basic inequality&lt;/h2&gt;
&lt;p&gt;Frank-Wolfe convergence 속도를 증명하는 데 사용되는 &lt;strong&gt;key inequality&lt;/strong&gt;는 as follows:.&lt;/p&gt;
&lt;blockquote&gt;
\[f(x^{(k)}) ≤  f(x^{(k−1)}) − γ_kg(x^{(k−1)}) + \frac{γ^2_k}{2}M\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(g(x) = \max_{s∈C} ∇f(x)^T(x − s)\)는 앞서 논의한 duality gap 을 의미하며, 귀납법according to, 이 비율은  inequality를 따르게 된다.&lt;/p&gt;

&lt;h3 id=&quot;proof&quot;&gt;[Proof]&lt;/h3&gt;
&lt;p&gt;Basic inequality를 증명하기 for, \(x^+ = x^{(k)}, x = x^{(k−1)}, s = s^{(k−1)}, γ = γ_k\) 를 지정한다. and, as follows: 정리한다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^+) &amp;amp;= f\bigl( x + γ(s − x) \bigr) \\\
&amp;amp;≤ f(x) + γ∇f(x)^T(s − x) + \frac{γ^2}{2}M \\\
&amp;amp;= f(x) − γg(x) + \frac{γ^2}{2}M
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;위 수식at, 두 번째 줄은 \(M\)의 정의를 사용했고, 세 번째 줄은 \(g\)의 정의를 사용하였다.&lt;/p&gt;

&lt;p&gt;이제, basic inequality를 using,, 우리는 convergence rate theorem을 증명하기 for, 귀납법을 사용한다.&lt;/p&gt;

&lt;p&gt;\(k=1\)의 case,, theorem이 만족함을 쉽게 확인할 수 있다.
and, 임의의 \(k &amp;gt; 1\)일 case,, \(f(x^{(k−1)}) − f^{\star} ≤ 2M/(k + 1)\)를 만족함을 가정한다.&lt;/p&gt;

&lt;p&gt;앞서 언급한 duality gap \(g(x)\)를 다시 떠올려 보자.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(g(x^{(k−1)}) ≤ f(x^{(k−1)}) − f^{\star}\)
\(γ_k = 2/(k + 1)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and, 이제 basic inequalityto, applying, 보자.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x^{(k)}) ≤ f(x^{(k−1)}) − 2(f(x^{(k−1)}) − f^{\star})/(k + 1) + 4M/2(k + 1)^2\)
\(f(x^{(k)}) − f^{\star} ≤ (1 − 2/(k + 1))(f(x^{(k−1)}) − f^{\star}) + 2M/(k + 1)^2\)
\(f(x^{(k)}) − f^{\star} ≤ (k − 1/k + 1) × 2M/(k + 1) + 2M/(k + 1)^2 ≤ 2M/(k + 2)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 증명 된 convergence 속도는 ∇f가 립시츠 (Lipschitz) 일 when, projected gradient descent의 informing,진 속helping, 일치한다.&lt;/p&gt;

&lt;p&gt;이제 이 가정 들을 comparing, 보자.
in fact, if, \(∇f\)가 constant \(L\)을 가지는 Lipschitz라면 \(diam^2(C) = max_{x,s∈C} ||x − s||^2\)일 when, \(M ≤ diam^2(C) · L\)이다.&lt;/p&gt;

&lt;p&gt;이를 확인하기 for, constant \(L\)을 가지는 \(∇f\) Lipschitz 아래and, 같다는 것을 image기할 필요가 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[f(y) − f(x) − ∇f(x)^T(y − x) ≤ \frac{L}{2} \| y − x \|^2_2\]
&lt;/blockquote&gt;

&lt;p&gt;모든 \(y = (1-γ) x + γs\)를 maximizing, \(\frac{2}{γ^2}\)를 product하면 as follows:.&lt;/p&gt;
&lt;blockquote&gt;
\[M ≤ \max_{x,s,y∈C, y=(1−γ)x+γs} \frac{2}{γ^2}·\frac{L}{2} \| y − x \|^2_2 = \max_{x,s∈C} L \| x − s \|^2_2\]
&lt;/blockquote&gt;

&lt;p&gt;M의 경계가 결정되었다. 기본적with, 경계가 있는 곡률이 proximal gradientabout, 가정한 곡률보다 크지 않다고 가정한다.&lt;/p&gt;

&lt;h2 id=&quot;affine-invariance&quot;&gt;Affine invariance&lt;/h2&gt;
&lt;p&gt;앞서 배운 개념들을 다시 생각solution 보자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Gradient Descent: \(x^+ = x − t∇f(x)\)&lt;/li&gt;
  &lt;li&gt;Pure Newton’s Method: \(x^+ = x − ∇^2f(x)^{−1}∇f(x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Gradient descent는 affine invariant하지 않다. that is,, coordinate들을 스케일링 함with, gradient descent의 성능은 향image 된다. 반면, Newton’s method는 affine invariant하다. that is,, 이 algorithm은 variable의 모든 affine transformationat, 동일하게 동작한다.&lt;/p&gt;

&lt;p&gt;and, Conditional gradient method는 gradient descentand, 비슷but, affine invariant 하다.&lt;/p&gt;

&lt;p&gt;Frank-Wolfe의 중요한 속성 : 업데이트는 &lt;strong&gt;affine invariant&lt;/strong&gt; 하다.
Nonsingular \(A : \mathbb{R}^n → \mathbb{R}^n\)가 주어지면, \(x = Ax&apos;, h(x&apos;) = f(Ax&apos;)\)를 정의할 수 있다.
그러면 \(h(x&apos;)\)at,의 Frank-Wolfe는 아래and, 같이 computation 가능하다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{array}{rcl}
s&apos; &amp;amp; = &amp;amp; \arg\min_{z∈A^{−1}C} ∇h(x&apos;)^Tz \\\
(x&apos;)^+ &amp;amp; = &amp;amp; (1 − γ)x&apos; + γs&apos;
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;\(A\)to, product하면 \(f (x)\)at, 수행되는 것and, 동일한 Frank-Wolfe 업데이트가 나타난다.
심지어 convergence analysis은 affine invariant이다.&lt;/p&gt;

&lt;p&gt;\(h\)의 곡률 constant \(M\)은 as follows:.&lt;/p&gt;
&lt;blockquote&gt;
\[M = \max_{x&apos;,s&apos;,y&apos;∈A^{−1}C, y&apos;=(1−γ)x&apos;+γs&apos;} \frac{2}{γ^2} \Bigl( h(y&apos;) − h(x&apos;) − ∇h(x&apos;)^T(y&apos; − x&apos;) \Bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;\(∇h(x&apos;)T(y&apos; − x&apos;) = ∇f(x)^T(y − x)\)이기 because of, \(f\)and, 일치한다.&lt;/p&gt;

&lt;p&gt;however,, affine invariance는 M의 경계at, 직관적이지 않다.&lt;/p&gt;

&lt;blockquote&gt;
\[M ≤ \max_{x,s∈C} L||x − s||^2_2\]
&lt;/blockquote&gt;

&lt;p&gt;주어진 C의 diameter이  affine invariance이 아니라면, 이것은 고민solution 볼 가치가 있다.&lt;/p&gt;

&lt;h2 id=&quot;inexact-updates&quot;&gt;Inexact updates&lt;/h2&gt;
&lt;p&gt;정확하지 않은 Frank-Wolfe 업데이트를 분석하였다.[Jaggi (2011)]&amp;lt;/br&amp;gt;
\(s^{(k−1)}\)를 선택한다.&lt;/p&gt;
&lt;blockquote&gt;
\[∇f(x^{(k−1)})^Ts^{(k−1)} ≤ \min_{s∈C} ∇f(x^{(k−1)})^Ts + \frac{Mγ_k}{2} · δ\]
&lt;/blockquote&gt;

&lt;p&gt;\(δ ≥ 0\)는 부정확한 파라미터이다. 이를 using,  기본적with, 다음and, 같은 비율을 얻게 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theorem: 고정 스텝 magnitude \(γk=2/(k+1),k=1,2,3, ...\) 및 부정확한 파라미터 δ≥0을 이용한 Conditional gradient method을 using,, 다음을 만족한다.
\(f(x^{(k)}) − f^{\star} ≤ \frac{2M}{k + 2} (1 + δ)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note: \(k\) step의 optimization 오difference는 \(\frac{Mγ_k}{2} · δ.\) 이다. 여기서 \(γ_k → 0\)이므to, 시간이 지날수록 오difference가 사라지는 것을 의도to, 한다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>22-02 Conditional gradient method</title>
   <link href="http://localhost:4000/contents/vi/chapter22/22_02_Conditional_gradient_method/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter22/22_02_Conditional_gradient_method</id>
   <content type="html">&lt;h2 id=&quot;projected-gradient-descent&quot;&gt;Projected Gradient Descent&lt;/h2&gt;
&lt;p&gt;Let’s consider a problem with the following constraints.&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x} f(x) \qquad \text{ subject to } x ∈ C\]
&lt;/blockquote&gt;

&lt;p&gt;We previously saw that if \(f\) is convex and smooth, and \(C\) is also convex, we can use the &lt;strong&gt;projected gradient descent&lt;/strong&gt; method.
When \(P_{C}\) is the projection operator for set \(C\), for the chosen initial value \(x^{(0)}\) and \(k = 1, 2, 3, . . .\), the following equation holds.&lt;/p&gt;

&lt;blockquote&gt;
\[x^{(k)} = P_{C } \bigl( x^{(k−1)} − t_k∇f(x^{(k−1)} \bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;Projected Gradient Descent can also be represented as a special case of proximal gradient descent, which is essentially motivated by the fact that the \(y\) value in the local quadratic expansion (2nd Taylor Expansion) becomes the next \(x^{(k)}\).&lt;/p&gt;

&lt;blockquote&gt;
\[x^{(k)} = P_{C} \Bigl( \arg\min_{y} ∇f(x^{(k−1)})^T(y − x^{(k−1)}) + \frac{1}{2t} \| y − x^{(k−1)} \|^2_ 2 \Bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;For more detailed information about Projected Gradient Descent, please reference &lt;a href=&quot;/contents/vi/chapter09/09_04_special_cases/&quot;&gt;9-4&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;conditional-gradient-frank-wolfe-method&quot;&gt;Conditional gradient (Frank-Wolfe) method&lt;/h2&gt;
&lt;p&gt;Instead of minimizing the quadratic approximation here, let’s try something simpler.
First, let’s examine the point where the value is minimized when we take the inner product of set \(C\) with \(\nabla f(x)\).&lt;/p&gt;

&lt;p&gt;Fundamentally, instead of projection, we can solve problems more conveniently and effectively by minimizing linear functions at points within set \(C\). Here, we proceed by applying a line search method using convex combinations between the current point and the minimum point.&lt;/p&gt;

&lt;p&gt;Let’s look at the following formalized method.&lt;/p&gt;

&lt;p&gt;Choose initial value \(x^{(0)} ∈ C\). \(k = 1, 2, 3, . . .\)&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{array}{rcl}
s^{(k−1)} &amp;amp; ∈ &amp;amp; \arg\min_{s ∈ C} ∇f(x^{(k−1)})^Ts \\\
x^{(k)} &amp;amp; = &amp;amp; (1 − γ_k)x^{(k−1)} + γ_ks^{(k−1)}
\end{array}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;reference&quot;&gt;[reference]&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(y) \approx f(x) + \nabla f(x)(y-x)\)
\(\arg\min_y = f(x) + \nabla f(x)(y-x)\)
\(\equiv \arg\min_y f(x)y\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서, before,and, 다르게 Projection process을 거치지 않고 업데이트를 할 떄, 제약 condition, set \(C\)to, 있는 점을 using, problem를 풀어나간다.&lt;/p&gt;

&lt;p&gt;기본적with, step size는 \(γ_k =  \frac{2}{(k + 1)}, k = 1, 2, 3, . . ..\)with, 설정된다.&lt;/p&gt;

&lt;p&gt;임의의 \(0 ≤ γ_k ≤ 1\)at, convexityby, \(x^{(k)} ∈ C\) 임을 보인다.&lt;/p&gt;

&lt;p&gt;also, 다음and, 같은 식with, 업데이트가 진행되기도 한다.&lt;/p&gt;
&lt;blockquote&gt;
\[x^{(k)} = x^{(k−1)} + γ_k\bigl( s^{(k−1)} − x^{(k−1)} \bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;that is,, algorithm 수행됨according to, 선형 minimizer directionwith, 점difference적with, 조금씩 덜 이동하게 된다.
대부분의 case,, co-ordinate descent의 스페셜 케이스인 Ball L1about,서 sub gradient 방식을 사용하는 것이 projection 방식을 사용하는 것 보다 problem를 solution결하기 더 쉽다.&lt;/p&gt;

&lt;h3 id=&quot;reference-1&quot;&gt;[reference]&lt;/h3&gt;
&lt;p&gt;흥미to,운 in fact,은, Frankand, Wolfe는 Tuckerand, 함께 일하던 post-doc 였다고 informing,져 있으며. 그들은 first, 첫번째to, 이 algorithm을 2 difference functionto, 제안했다고 한다. and, 그 algorithm은 1956년to, 출판되고, 후to, 논문with,도 발표되었다. and, 이 후to, 오랫during, 더 이image 이to, about, 후속 논문은 전혀 나오지 못했다. however, 지난 몇년 during, Jaggi의 통찰력to, 힘임어 세imageto, 소개되면서 다시 주목을 받게 되었다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter22/frank_wolfe.png&quot; alt=&quot;[Fig 1] Conditional Gradient (Frank-Wolfe) method (From Jaggi 2011)[3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Conditional Gradient (Frank-Wolfe) method (From Jaggi 2011)[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;norm-constraints&quot;&gt;Norm constraints&lt;/h2&gt;
&lt;p&gt;norm \(\| · \|\)about, \(C = \{x : \| x \| ≤ t \}\)일 when, 무슨일이 발생할까?&lt;/p&gt;

&lt;p&gt;다음을 let’s look at&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
s &amp;amp;∈ \arg\min_{\|s\|≤t} ∇f(x^{(k−1)})^Ts \\\
&amp;amp;= −t ·  \arg\max_{\|s\|≤1}  ∇f(x^{(k−1)})^Ts \\\
&amp;amp;= −t · ∂ \| ∇f(x^{(k−1)}) \|_{∗}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\| · \|_{∗}\)는 dual norm을 의마한다.&lt;/p&gt;

&lt;p&gt;다시 말solution, dual norm의 subgradient를 computation하는 method을 안다면, Frank-Wolfe step를 쉽게 수행 할 수 있다는 뜻이다.&lt;/p&gt;

&lt;p&gt;Frank-Wolfe의 핵심은 \(C = \{x : \| x \| ≤ t \}\)to, projection method을 사용하는 것보다 더 간단하거나 낮은 비용with, 구할 수 있으며, also, when,to,는 \(\| · \|\)의 prox operator보다도 간단하거나 더 낮은 비용을 요한다는 것이다.&lt;/p&gt;

&lt;h2 id=&quot;example-l_1-regularization&quot;&gt;Example: \(l_1\) regularization&lt;/h2&gt;
&lt;p&gt;다음은 &lt;strong&gt;\(l_1\)-regularized&lt;/strong&gt; 이다.&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) \qquad \text{ subject to } \| x \|_1 ≤ t\]
&lt;/blockquote&gt;

&lt;p&gt;앞선 공식대to, 전개하면, \(s^{(k−1)} ∈ −t∂ \|∇f(x^{(k−1)}) \|_∞\) 를 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;Frank-Wolfe method은 다음의 process을 through, 업데이트 된다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
i_{k−1} &amp;amp; ∈  &amp;amp; \arg\max_{i=1,...p} ∇_i f(x^{(k−1)}) \\\
x^{(k)}  &amp;amp; = &amp;amp; (1 − γ_k)x^{(k−1)} − γ_kt · sign ∇_{i_{k−1}} f(x^{(k−1)})· e_{i_{k−1}}
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;이것은 coordinate descent의 일종이다(coordinate descentabout,서는 나중to, 자세히 let’s look at).&lt;br /&gt;
Note : 두 가지 모두 \(O(n)\)의 복잡도가 필요but, \(l1\) ballto, projection 하는 것보다 훨씬 간단하다.&lt;/p&gt;

&lt;h2 id=&quot;example-l_p-regularization&quot;&gt;Example: \(l_p\) regularization&lt;/h2&gt;
&lt;p&gt;다음은 \(l_p\)-regularized problem다.&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x}  f(x) \qquad \text{ subject to } \| x \|_{p} ≤ t\]
&lt;/blockquote&gt;

&lt;p&gt;\(1 ≤ p ≤ ∞\)at, p가 q의 dual일 when,  \(s^{(k−1)} ∈ −t∂ \| ∇f(x^{(k−1)}) \|_{q}\) 이다. that is,, \(1/p + 1/q = 1\)이다.&lt;/p&gt;

&lt;p&gt;that is, as follows: 선택할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[s_i^{(k−1)} = −α · sign ∇f_i(x^{(k−1)}) · \left| ∇f_i(x^{(k−1)}) \right|^{p/q}, i = 1, . . . n\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(α\)는 \(\| s^{(k-1)} \|_{q} = t\)and, 같은 constant이고, Frank-Wolfe 업데이트도 동일하다.&lt;/p&gt;

&lt;p&gt;Note: 일반 \(p\)의 case, &lt;strong&gt;p Ballto, Projection&lt;/strong&gt;하는 것보다 훨씬 간단하다.&lt;br /&gt;
특별한 case,(\(p = 1, 2, ∞\))를 제외하고 이러한 projection은 직접 computation할 수 없다(optimizationto, 처리되어야 함).&lt;/p&gt;

&lt;h2 id=&quot;example-trace-norm-regularization&quot;&gt;Example: trace norm regularization&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;trace-regularized&lt;/strong&gt; problem를 let’s look at&lt;/p&gt;
&lt;blockquote&gt;
\[\min_{X} f(X) \qquad \text{ subject to } \| X \|_{tr} ≤ t\]
&lt;/blockquote&gt;

&lt;p&gt;\(S^{(k−1)} ∈ −t· ∂\| ∇f(X(k−1)) \|_{op}.\) 이다.&lt;/p&gt;

&lt;p&gt;as follows: \(S_i^{(k−1)}\)를 선택할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[S_i^{(k−1)} = −t · uv^T\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(u, v\)는 \(∇f(X^{(k−1)})\)의 왼쪽, 오른쪽 singular vector이고, Frank-Wolfe 업데이트는 평소and, 같다.&lt;/p&gt;

&lt;p&gt;Note: 이 method은 특이 값 분solution(SVD)가 가능하면, &lt;strong&gt;trace norm ballto, projection&lt;/strong&gt;하는 것보다 훨씬 간단하고 효율적with, solution를 구할 수 있는 method이다.&lt;/p&gt;

&lt;h2 id=&quot;constrained-and-lagrange-forms&quot;&gt;Constrained and Lagrange forms&lt;/h2&gt;
&lt;p&gt;제약 condition,이 있는 problem의 solution을 다시 한번 image기solution보자&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) \qquad \text{ subject to } \| x \| ≤ t\]
&lt;/blockquote&gt;

&lt;p&gt;다음의 Lagrange problem는 위 식and, equivalence이다.&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) + λ \| x \|\]
&lt;/blockquote&gt;

&lt;p&gt;튜닝 파라미터 \(t\)and, \(λ\)는 [0,∞]구간at, 변한다. also, \(\| · \|\)의 Frank-Wolfe 업데이트를 \(\| · \|\)의  proximal 오퍼레이터and, comparing,야 한다.&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;\(l_1\) norm&lt;/strong&gt;: Frank-Wolfe method은 gradient의 최댓값을 스캔하여 업데이트 한다.
proximal operator soft-threshold를 진행하면서 업데이트 한다. 두 step 모두 \(O(n)\) flops을 사용 한다.&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;\(l_p\) norm&lt;/strong&gt;: 프랭크-울프(Frank-Wolfe) 업데이트는 gradient의 각 항목마다 제product하고 모두 sum산하여 \(O(n)\) flopwith, 증가시킨다. proximal operator는 generally, 직접 computation할 수 없다.&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;Trace norm&lt;/strong&gt;: 프랭크-울프(Frank-Wolfe) 업데이트는 gradient의 image단 왼쪽 및 오른쪽 singular vector를 computation한다. proximal operatorat,는 soft-thresholds gradient step을 진행하며, 특이값 분solution(SVD)를 필요to, 한다.&lt;/p&gt;

&lt;p&gt;다른 많은 regularizer들이 효율적인 Frank-Wolfe update를 도출하였다.
예를 들면, special polyhedra or, cone constraints, sum-of-norms (group-based) regularization, atomic norms. 같은 것들이다.&lt;/p&gt;

&lt;p&gt;Constrained Lassoto, about, projected gradient techniqueand, conditional gradient technique을 활용했을 when, 성능을 비교하면 as follows:. (여기서 \(n=100, p = 500\))&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter22/comparing_projected_and_conditional_gradient.png&quot; alt=&quot;[Fig 2] Comparing projected and conditional gradient for constrained lasso
problem [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] Comparing projected and conditional gradient for constrained lasso
problem [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;프랭크-울프(Frank-Wolfe) method이 first-order method의 convergence율and, 비슷한 양image을 띠고 있는 것을 확인할 수 있을 것이다. however, actually,는 높은 정확도to, convergence하기 for,서는 속도가 더 느려질 수 있다. (reference: 여기서 fixed step size를 사용but,, line search를 using, convergence 속도를 향image시킬 수도 있다.)&lt;/p&gt;

&lt;h2 id=&quot;duality-gap&quot;&gt;Duality gap&lt;/h2&gt;
&lt;p&gt;프랭크-울프(Frank-Wolfe) iteration processat, 자연스럽게 duality gap 이 발생되며, 이는 actually, suboptimality gap을 의미한다.&lt;/p&gt;
&lt;blockquote&gt;
\[g(x^{(k-1)}) := \max_{s∈C} ∇f(x^{(k−1)})^T(x^{(k−1)} − s)\]
&lt;/blockquote&gt;

&lt;p&gt;이것은 \(f(x^{(k−1)}) − f^{\star}\)의 upper bound 이다.&lt;/p&gt;

&lt;h4 id=&quot;proof&quot;&gt;[Proof]&lt;/h4&gt;
&lt;p&gt;convexity의 first-order condition을 using, 증명할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[f(s) ≥ f(x^{(k−1)}) + ∇f(x^{(k−1)})^T(s − x^{(k−1)})\]
&lt;/blockquote&gt;

&lt;p&gt;모든 $s ∈ C$about, 양쪽을 minimization 한다.&lt;/p&gt;
&lt;blockquote&gt;
\[f^{\star} ≥ f(x^{(k−1)}) + min_{s∈C} ∇f(x^{(k−1)})^T(s − x^{(k−1)})\]
&lt;/blockquote&gt;

&lt;p&gt;최종적with,, 다시 정리하여 다음 식은 duality gap이 upper bound임을 showing, 준다.&lt;/p&gt;
&lt;blockquote&gt;
\[\max_{s∈C} ∇f(x^{(k−1)})^T(x^{(k−1)} − s) = ∇f(x^{(k−1)})^T(x^{(k−1)} − s^{(k−1)})\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;note&quot;&gt;[Note]&lt;/h4&gt;
&lt;p&gt;therefore, 이 quantity는 Frank-Wolfe 업데이트at, 직접 나온 것이다.
왜 우리는 이를 “duality gap”이라 부를까?&lt;/p&gt;

&lt;p&gt;original problem을 다시 써보면 아래and, 같이 쓸 수있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\min_{x} f(x) + I_C(x)\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(I_C\)는 \(C\)의 indicator function을 의미한다. dual problem는 아래and, 같다.&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u −f^{*} (u) − I^{*}_C(−u)\]
&lt;/blockquote&gt;

&lt;p&gt;\(I_C^{*}\)가 \(C\)의 support function을 의미한다. Indicator function의 conjugate는 support function 이 됨을 앞서 살펴보았다.&lt;/p&gt;

&lt;h4 id=&quot;recall&quot;&gt;[Recall]&lt;/h4&gt;
&lt;blockquote&gt;
\[I_C (X) =  
\begin{cases}
+&amp;amp; \infty &amp;amp;if &amp;amp;x &amp;amp;\notin; C \\\
 &amp;amp; 0      &amp;amp;if &amp;amp;x &amp;amp;\in; C
\end{cases}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[\begin{align}
I_C^{*} &amp;amp;= \max_{x} \{ &amp;lt;s, x\&amp;gt; - I_C(x)\} \\
        &amp;amp;= \max_{x \in C} &amp;lt;s, x&amp;gt; \\
        &amp;amp;= \text{Support function of } C \text{ at } S
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(x = x ^ {(k-1)}, u = ∇f (x ^ {(k-1)})\) 일 when,, \(x, u\)at, 발생하는 duality gap은 as follows:. (13-04 &lt;a href=&quot;/contents/vi/chapter13/13_04_Conjugate_function/&quot;&gt;Fenchel’s inequality&lt;/a&gt; from, 유도되기도 한다.)&lt;/p&gt;
&lt;blockquote&gt;
\[f(x) + f^{*}(u) + I^{*}_C(−u) ≥ x^Tu + I^{*}_C(−u)\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>22-01 Last time: ADMM</title>
   <link href="http://localhost:4000/contents/vi/chapter22/22_01_Last_time_ADMM/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter22/22_01_Last_time_ADMM</id>
   <content type="html">&lt;h2 id=&quot;last-time-admm&quot;&gt;Last time: ADMM&lt;/h2&gt;
&lt;p&gt;Let’s consider the following optimization problem&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x,z} &amp;amp;&amp;amp;f(x) + g(z)\\\\
&amp;amp;\text{ subject to } &amp;amp;&amp;amp;Ax + Bz = c 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Converting this to Augmented Lagrangian form gives us the following. (for some \(ρ &amp;gt; 0\))&lt;/p&gt;
&lt;blockquote&gt;
\[L_ρ(x, z, u) = f(x) + g(z) + u^T(Ax + Bz − c) + \frac{ρ}{2} \| Ax + Bz − c \|^2_2\]
&lt;/blockquote&gt;

&lt;p&gt;The above equation becomes Strongly Convex with the addition of \(\frac{ρ}{2} \| Ax + Bz − c \|^2_2\), and this can be transformed into a form useful for parallel processing as shown in the following equation.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For detailed proof, please refer to the content of the previous chapter.
ADMM: for \(k = 1, 2, 3, . . .\)
    &lt;blockquote&gt;
      &lt;p&gt;\(x^{(k)} = argmin_{x} L_ρ(x, z^{(k−1)}, u^{(k−1)})\)
\(z^{(k)} = argmin_{z} L_ρ(x^{(k)}  , z, u^{(k−1)})\)
\(u^{(k)} = u^{(k−1)} + ρ(Ax^{(k)} + Bz^{(k)} − c)\)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;admm-in-scaled-form&quot;&gt;ADMM in scaled form&lt;/h2&gt;
&lt;p&gt;Let’s change the dual variable \(u\) to the scaled variable \(w = u/ρ\). Here, the ADMM step can be computed as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x^{(k)} = argmin_{x} f(x) + \frac{ρ}{2} \| Ax + Bz^{(k−1)} − c + w^{(k−1)} \|^2_2\)
\(z^{(k)} = argmin_{z} g(z) + \frac{ρ}{2} \| Ax^{(k)} + Bz − c + w^{(k−1)} \|^2_2\) 
\(w^{(k)} = w^{(k−1)} + Ax^{(k)} + Bz^{(k)} − c\)&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>15 Barrier Method</title>
   <link href="http://localhost:4000/contents/vi/chapter15/chapter16/15_barrier_method/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/chapter16/15_barrier_method</id>
   <content type="html">&lt;p&gt;In this chapter, we will look at one of the 2nd-order methods, the &lt;strong&gt;Barrier Method&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Barrier Method&lt;/strong&gt; is a technique for solving &lt;strong&gt;inequality constraint and equality constrained smooth problems&lt;/strong&gt;, which are considered the most difficult among 2nd-order method problems.&lt;/p&gt;

&lt;p&gt;(For reference, using the gradient to solve an optimization problem is called a 1st-order method, and using the Hessian is called a 2nd-order method.)&lt;/p&gt;

&lt;h2 id=&quot;references-and-further-readings&quot;&gt;References and further readings&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;S. Boyd and L. Vandenberghe (2004), “Convex optimization”, Chapter 11&lt;/li&gt;
  &lt;li&gt;A. Nemirovski (2004), “Interior-point polynomial time methods in convex programming”, Chapter 4&lt;/li&gt;
  &lt;li&gt;J. Nocedal and S. Wright (2006), “Numerical optimization”, Chapters 14 and 19&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>15-08 Formal barrier method</title>
   <link href="http://localhost:4000/contents/vi/chapter15/chapter16/15_08_formal_barrier_method/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/chapter16/15_08_formal_barrier_method</id>
   <content type="html">&lt;p&gt;If a convex function \(\phi : D \to \mathbb{R}\) defined on an open convex set \(D \subset \mathbb{R}^n\) satisfies the following conditions, then the function is a &lt;strong&gt;self-concordant barrier&lt;/strong&gt; with parameter \(\nu\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\phi\) is self-concordant&lt;/li&gt;
  &lt;li&gt;For all \(x \in D\), the Newton decrement is bounded by the constant \(\nu\) as follows.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\lambda(x)^2 = \nabla \phi(x) (\nabla^2 \phi(x))^{-1} \nabla \phi(x) \le \nu\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s consider the following LP problem. (Here, \(\bar{D}\) is the closure of the domain \(D\).)&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x} \           &amp;amp;&amp;amp; c^Tx \\
&amp;amp;\text{subject to } \ &amp;amp;&amp;amp; x \in \bar{D}  \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This problem can be approximated as follows.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp; tc^Tx + \phi(x) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, let \(\phi_t(x) := tc^Tx + \phi(x)\) and let the corresponding Newton decrement be \(\lambda_t(x)\).&lt;/p&gt;

&lt;p&gt;Key observation: When \(t^+ &amp;gt; t\)&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
\lambda_t^+(x) \le &amp;amp; \frac{t^+}{t}\lambda_t^+(x) + \left ( \frac{t^+}{t} -1 \right ) \sqrt{\nu}  \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;theorem&quot;&gt;Theorem&lt;/h2&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \text{if} \quad \lambda_t(x) \le \frac{1}{9} \quad \text{and} \quad \frac{t^+}{t} \le 1 + \frac{1}{8 \sqrt{\nu}} \quad \text{then} \quad \lambda_t^+(x^+) \le \frac{1}{9}  \\
&amp;amp; \qquad \qquad \text{for} \quad x^+ = x - (\nabla^2 (\phi_{t^+}(x))^{-1} \nabla (\phi_{t^+}(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In conclusion, if we start with \(x^{(0)}, t^{(0)}\) such that \(\lambda_{t^{(0)}}(x^{(0)}) \lt \frac{1}{9}\) and choose \(\mu := 1 + \frac{1}{8 \sqrt{\nu}}\), then one Newton step per centering step is sufficient.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-07 Feasibility methods</title>
   <link href="http://localhost:4000/contents/vi/chapter15/chapter16/15_07_feasibility_methods/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/chapter16/15_07_feasibility_methods</id>
   <content type="html">&lt;p&gt;So far, we have implicitly assumed that the first centering step (\(t = t^{(0)}\)) starts from a strictly feasible point to compute \(x^{(0)} = x^*\).&lt;/p&gt;

&lt;p&gt;This means that \(x\) is a strictly feasible point satisfying the following conditions:&lt;/p&gt;
&lt;blockquote&gt;
\[h_i(x) \lt 0, \quad i = 1, \cdots, m, \quad Ax = b\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;maximum-infeasibility&quot;&gt;Maximum infeasibility&lt;/h2&gt;
&lt;p&gt;How do we find \(x\)? We can solve the following problem to find it.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x, s} \        &amp;amp;&amp;amp; s \\
&amp;amp;\text{subject to } \ &amp;amp;&amp;amp; h_i(x) \le s,&amp;amp; i = 1, \cdots, m \\
                      &amp;amp;&amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The goal is to make the solution \(s\) negative. This problem is called the &lt;strong&gt;feasibility method&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Finding a strictly feasible starting point is easy, so it can also be solved using the barrier method. That is, you can add slack variables to the inequality constraint \(h_i(x) \le s\) and convert it to an equality constraint to solve it.&lt;/p&gt;

&lt;p&gt;When solving this problem, high accuracy is not required; you just need to find a feasible \((x,s)\) with \(s &amp;lt; 0\).&lt;/p&gt;

&lt;h2 id=&quot;infeasibility-for-each-inequality-constraint&quot;&gt;Infeasibility for each inequality constraint&lt;/h2&gt;
&lt;p&gt;You can also define and solve the problem as follows. The previous method found the maximum infeasibility for all inequalities, while this problem finds the infeasible variable \(s_i, i = 1, \cdots, m\) for each inequality.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x, s} \        &amp;amp;&amp;amp; 1^Ts \\
&amp;amp;\text{subject to } \ &amp;amp;&amp;amp; h_i(x) \le s_i,&amp;amp; i = 1, \cdots, m \\
                      &amp;amp;&amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The advantage of this method is that by looking at the solution \(s\), you can tell if the problem is infeasible. That is, if any element of \(s\) is greater than or equal to 0, the corresponding constraint is not satisfied.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-06 Barrier method v.2</title>
   <link href="http://localhost:4000/contents/vi/chapter15/15_06_barrier_method_v2/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/15_06_barrier_method_v2</id>
   <content type="html">&lt;p&gt;이전 알고리즘에서는 central path에 있는 solution을 생성했는데, 실제 central path는 optimal로 가는 과정(“means to an end”)일 뿐이다. 따라서, 문제를 정확히 풀 필요는 없다.&lt;/p&gt;

&lt;p&gt;In the previous algorithm, we generated solutions along the central path, but in reality, the central path is just a means to reach the optimal solution. Therefore, it is not necessary to solve the problem exactly.&lt;/p&gt;

&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;
&lt;p&gt;For this reason, Barrier method v.2 solves the barrier problem approximately.&lt;/p&gt;

&lt;p&gt;단, 단계 2의  \(x^{(0)} \approx x^*(t)\)와 단계 3-2의 \(x^{(k+1)} \approx x^*(t)\) 부분이 approximation으로 바뀌었다.
The steps of the algorithm are the same as those in Barrier method v.1.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;\(t^{(0)} \gt 0\)이고 \(k := 0\)을 선택한다.
However, in step 2, \(x^{(0)} \approx x^*(t)\) and in step 3-2, \(x^{(k+1)} \approx x^*(t)\) are now approximations.&lt;/li&gt;
  &lt;li&gt;While \(m/t \gt \epsilon\) &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Choose \(t^{(0)} &amp;gt; 0\) and set \(k := 0\).&lt;/li&gt;
  &lt;li&gt;At \(t = t^{(0)}\), solve the barrier problem to obtain \(x^{(0)} \approx x^*(t)\).&lt;/li&gt;
  &lt;li&gt;While \(m/t &amp;gt; \epsilon\) &lt;br /&gt;
  3-1. Choose \(t^{(k+1)} &amp;gt; t^{(k)}\). &lt;br /&gt;
  3-2. Initialize Newton’s method with \(x^{(k)}\). (warm start)&lt;br /&gt;
     At \(t = t^{(k+1)}\), solve the barrier problem to obtain \(x^{(k+1)} \approx x^*(t)\).&lt;br /&gt;
  end while&lt;br /&gt;
Barrier method v.2에서는 다음 두 가지 사항이 매우 중요하다.&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;얼마나 근사를 잘 할 수 있는가? (How close should each approximation be?)
In Barrier method v.2, the following two issues are very important:&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;How close should each approximation be?&lt;/li&gt;
  &lt;li&gt;How many Newton steps are needed at each centering step?&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
In the following figure, you can see that when the barrier method is applied to a problem with $$m$$ constraints, linear convergence occurs even as $$m$$ becomes large. That is, it has a log scale with respect to $$m$$.
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter15/15_barrier_methodv2_04.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] m에 대해 newton iteration과 suboptimality gap 분석 [1]&lt;/figcaption&gt;
&amp;lt;/p&amp;gt;
&lt;/figure&gt;

&lt;p&gt;다르게 보면 (\(10^4\)인 초기 suboptimal gap (duality gap)을 줄이기 위해 필요한) newton step은 \(m\)에 대해 천천히 증가한다. 아래 그림을 보면 \(m\)이 크게 증하하더라도 각 centering step 별로 20~30 newton step 정도만 필요하다. 단, 한 newton step은 문제의 크기에 따라 크게 달라진다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter15/15_barrier_methodv2_05.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] m의 증가와 newton iteration 수 분석 [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>15-05 Convergence analysis</title>
   <link href="http://localhost:4000/contents/vi/chapter15/chapter16/15_05_convergence_analysis/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/chapter16/15_05_convergence_analysis</id>
   <content type="html">&lt;p&gt;Assuming the centering step in the barrier method is solved exactly, we can obtain the following convergence results.&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;
&lt;p&gt;After \(k\) centering steps, the &lt;strong&gt;barrier method&lt;/strong&gt; satisfies the following equation. (Here, \(k\) is the number of outer iterations.)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f^{*} \le  \frac{m}{\mu^k t^{(0)}}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;That is, to reach the desired accuracy level \(\epsilon\) with the barrier method, you need the following number of centering steps plus one for the first centering step.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\frac{log(m/(t^{(0)}\epsilon))}{\log \mu} + 1
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, we see that the convergence is linear, with \(O(\log 1/\epsilon )\).&lt;/p&gt;

&lt;p&gt;Newton’s method has quadratic convergence with \(O(\log \log 1/\epsilon )\), but in this case, the problem is very difficult, so linear convergence is not such a bad result.&lt;/p&gt;

&lt;p&gt;For the definitions of linear and quadratic convergence, refer to the Wiki.&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Rate_of_convergence&quot;&gt;Rate of convergence&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>15-04 Barrier method v.0 and v.1</title>
   <link href="http://localhost:4000/contents/vi/chapter15/chapter16/15_04_barrier_method_v0_and_v1/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/chapter16/15_04_barrier_method_v0_and_v1</id>
   <content type="html">&lt;h2 id=&quot;barrier-method-v0&quot;&gt;Barrier method v.0&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Barrier method v.0&lt;/strong&gt; chooses \(t = m/\epsilon\) for \(\epsilon &amp;gt; 0\) and solves the following barrier problem to obtain \(f(x^*(t)) - f(x^*) \le \epsilon\).&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
 &amp;amp;\min_{x} \ &amp;amp;&amp;amp; tf(x) + \phi(x) \\
 &amp;amp;\text{subject to } \ &amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(m\) is the number of constraints and \(t\) is a multiple of \(1/\epsilon\), so as \(\epsilon\) gets smaller, \(t\) becomes very large, and eventually the end of the central path is reached, making the problem equivalent to the original problem. Therefore, this can be very slow and difficult to solve.&lt;/p&gt;

&lt;p&gt;Thus, a better approach is to follow the central path to find the solution, which leads to the definition of &lt;strong&gt;barrier method v.1&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;barrier-method-v1&quot;&gt;Barrier method v.1&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Barrier method v.1&lt;/strong&gt; is a method that gradually increases the value of \(t\) and solves the following barrier problem multiple times.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
 &amp;amp;\min_{x} \ &amp;amp;&amp;amp; tf(x) + \phi(x) \\
 &amp;amp;\text{subject to } \ &amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;
&lt;p&gt;The algorithm can be described as follows.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Choose \(t^{(0)} &amp;gt; 0\) and set \(k := 0\).&lt;/li&gt;
  &lt;li&gt;At \(t = t^{(0)}\), solve the barrier problem to obtain \(x^{(0)} = x^*(t)\).&lt;/li&gt;
  &lt;li&gt;While \(m/t &amp;gt; \epsilon\) &lt;br /&gt;
  3-1. Choose \(t^{(k+1)} &amp;gt; t^{(k)}\). &lt;br /&gt;
  3-2. Initialize Newton’s method with \(x^{(k)}\). (warm start)&lt;br /&gt;
     At \(t = t^{(k+1)}\), solve the barrier problem to obtain \(x^{(k+1)} = x^*(t)\).&lt;br /&gt;
  end while&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;comments&quot;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Common update method&lt;/strong&gt;: \(t^{(k+1)} = \mu t^{(k)}\), (\(\mu &amp;gt; 1\))&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Warm start&lt;/strong&gt;: In step 3-2, the solution from the previous step is used as the initial value for the next step, which is called warm start.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Centering step&lt;/strong&gt;: Steps 2 and 3-2 in the algorithm, which solve the barrier problem, are called centering steps (or outer iterations).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;considerations&quot;&gt;Considerations&lt;/h3&gt;
&lt;p&gt;In choosing \(\mu\) and \(t^{(0)}\), the following trade-offs must be considered.&lt;/p&gt;
&lt;h5 id=&quot;choice-of-mu&quot;&gt;Choice of \(\mu\)&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;If \(\mu\) is too small, the number of outer iterations increases. (In this case, warm start helps.)&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;If \(\mu\) is too large, many iterations are required for Newton’s method to converge in every centering step.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;choice-of-initial-algorithm-value&quot;&gt;Choice of initial algorithm value&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;If \(t^{(0)}\) is too small, the number of outer iterations increases.&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;If \(t^{(0)}\) is too large, it becomes the same problem as v.0. Therefore, Newton’s method requires many iterations to find \(x^{(0)}\) in the first centering step.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fortunately, the performance of the actual barrier method is very robust to the choice of \(\mu\) and \(t^{(0)}\). Moreover, the appropriate range of these parameters varies depending on the problem size.&lt;/p&gt;

&lt;h2 id=&quot;example-of-small-lp&quot;&gt;Example of small LP&lt;/h2&gt;
&lt;p&gt;The following figure shows the performance when executing an LP problem with n=50 dimensions and m=100 inequality constraints using the barrier method. It can be confirmed that when \(\mu = 2\), the outer iterations increase, and when \(\mu=150\), the centering steps increase relatively compared to when \(\mu=50\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter15/15_barrier_method_03.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Example of small LP [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>15-03 Properties and interpretation</title>
   <link href="http://localhost:4000/contents/vi/chapter15/chapter16/15_03_properties_and_interpretation/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/chapter16/15_03_properties_and_interpretation</id>
   <content type="html">&lt;p&gt;In this section, we will derive the KKT conditions for the barrier problem and the original problem to see what differences exist. We will also calculate the suboptimality gap for the solutions to both problems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-03-02 Suboptimality gap</title>
   <link href="http://localhost:4000/contents/vi/chapter15/15_03_02_suboptimality_gap/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/15_03_02_suboptimality_gap</id>
   <content type="html">&lt;p&gt;앞 절에서 구한 barrier problem과 original problem의 solution인 \(f(x^*(t))\)와 \(f(x^*)\)의 suboptimality gap은 어떻게 될까?&lt;/p&gt;

&lt;p&gt;What is the suboptimality gap between \(f(x^*(t))\), the solution to the barrier problem, and \(f(x^*)\), the solution to the original problem, as derived in the previous section?
따라서, 다음의 식을 구할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
If convexity is guaranteed, the function is always greater than its tangent, so\)f(x^&lt;em&gt;) \ge f(x^&lt;/em&gt;(t)) + \nabla f(x^&lt;em&gt;(t))^T (x^&lt;/em&gt; - x^*(t))$$ holds. (The tangent is the first-order Taylor approximation)
Therefore, we can derive the following equation:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;비슷하게 \(h_i(x^*) \ge h_i(x^*(t)) + \nabla h_i(x^*(t))^T (x^* - x^*(t))\)가 성립하므로 다음의 식을 구할 수 있다.&lt;/p&gt;

&lt;p&gt;Similarly, since \(h_i(x^*) \ge h_i(x^*(t)) + \nabla h_i(x^*(t))^T (x^* - x^*(t))\) holds, we can derive the following equation:
h_i(x^&lt;em&gt;(t)) - h_i(x^&lt;/em&gt;) \le \nabla h_i(x^&lt;em&gt;(t))^T (x^&lt;/em&gt;(t) - x^*), \quad i = i, \cdots , m
\end{align}$$&lt;/p&gt;

&lt;h2 id=&quot;derivation-of-suboptimality-gap&quot;&gt;Derivation of suboptimality gap&lt;/h2&gt;
&lt;p&gt;이 두 식에서 suboptimality gap을 유도해 보도록 하겠다. 오른쪽 항은 위의 두 convexity 조건에 의해 도출된다.&lt;/p&gt;

&lt;p&gt;Let’s use these two equations to derive the suboptimality gap. The right-hand side is derived from the two convexity conditions above.
f(x^&lt;em&gt;(t)) - f(x^&lt;/em&gt;) + \sum_{i=1}^{m}  u_i(t) (h_i(x^&lt;em&gt;(t)) - h_i(x^&lt;/em&gt;) ) 
    &amp;amp; \le 	\left\langle \nabla  f(x^&lt;em&gt;(t))  + \sum_{i=1}^{m} u_i(t) \nabla h_i(x^&lt;/em&gt;(t)), \quad x^&lt;em&gt;(t) - x^&lt;/em&gt; \right\rangle \&lt;br /&gt;
    &amp;amp; = \left\langle -tA^Tv,  \quad x^&lt;em&gt;(t) - x^&lt;/em&gt; \right\rangle \&lt;br /&gt;
\end{align}$$&lt;/p&gt;

&lt;p&gt;이 식에서 오른쪽 항을 내적해 보면 \(Ax^*(t) = b\)이고 \(Ax^* = b\)이므로 전체가 0이 된다.
따라서, 첫번째 식의 세번째 항을 오른쪽으로 넘겨서 정리해 보면 다음과 같은 결과를 얻을 수 있다.
If we look at the right-hand side of this equation as an inner product, since \(Ax^*(t) = b\) and \(Ax^* = b\), the whole term becomes zero.
Therefore, moving the third term of the first equation to the right and simplifying, we get the following result:
f(x^&lt;em&gt;(t)) - f(x^&lt;/em&gt;) &amp;amp; \le - \sum_{i=1}^{m}  u_i(t) (h_i(x^&lt;em&gt;(t)) - h_i(x^&lt;/em&gt;) )  \&lt;br /&gt;
    &amp;amp; = \frac{m}{t} +  \sum_{i=1}^{m} u_i(t) h_i(x^*) \&lt;br /&gt;
    &amp;amp; \le \frac{m}{t} &lt;br /&gt;
\end{align}$$&lt;/p&gt;

&lt;p&gt;두번째 라인의 첫번째 항은 KKT condition에서 \(u_i(t) \cdot   h_i(x^*(t)) = - \frac{1}{t}\)를 만족하므로  \(\frac{m}{t}\)가 된다.  두번째 항도 KKT condition에서 \(\sum_{i=1}^{m} u_i(t)  h_i(x^*) \le 0\)이므로 제거할 수 있다.&lt;/p&gt;

&lt;p&gt;결과적으로 다음과 같은 suboptimality gap을 구할 수 있으며 이는 유용한 stopping criterion이 된다. 참고로, 이 결과는 다음 장에서 duality gap으로도 유도할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(x^*(t)) - f(x^*) \le \frac{m}{t}
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>15-03-01 Perturbed KKT conditions</title>
   <link href="http://localhost:4000/contents/vi/chapter15/chapter16/15_03_01_perturbed_kkt_conditions/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/chapter16/15_03_01_perturbed_kkt_conditions</id>
   <content type="html">&lt;p&gt;If we derive the KKT conditions from the barrier problem and the original formulation, we get the following.&lt;/p&gt;
&lt;h2 id=&quot;kkt-conditions-for-barrier-problem&quot;&gt;KKT conditions for barrier problem&lt;/h2&gt;
&lt;p&gt;The second term in the KKT conditions for the barrier problem is derived using the gradient of the log barrier function.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
t \nabla f(x^*(t)) - \sum_{i=1}^{m} \frac{1}{h_i(x^*(t))} \nabla h_i(x^*(t)) + A^Tw = 0  \\\ 
 Ax^*(t) = b, \quad h_i(x^*(t)) \lt 0, \quad i = 1, \cdots , m \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;kkt-conditions-for-the-original-problem&quot;&gt;KKT conditions for the original problem&lt;/h2&gt;
&lt;p&gt;In the KKT conditions for the original problem, complementary slackness gives \(h_i(x^*) \cdot u_i^* = 0\), but in practice, it is very difficult to know this boundary condition.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
\nabla f(x^*) + \sum_{i=1}^{m} u_i^* \nabla h_i(x^*) + A^Tv^* = 0 \\\ 
Ax^* = b, \quad h_i(x^*) \le 0, \quad u_i^* \ge 0,   \\\ 
h_i(x^*) \cdot u_i^* = 0,  \quad i = 1, \cdots , m \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;redefinition-of-kkt-conditions-for-barrier-problem&quot;&gt;Redefinition of KKT conditions for barrier problem&lt;/h2&gt;
&lt;p&gt;So, what is the relationship between these two KKT conditions?&lt;/p&gt;

&lt;p&gt;First, let \(u_i(t)\) and \(v\) be defined as follows:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
u_i(t) = - \frac{1}{t h_i(x^*(t))}, \quad v = \frac{1}{t}w
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s redefine the KKT conditions for the barrier problem.&lt;/p&gt;

&lt;p&gt;Looking at the redefined problem, we see that the KKT conditions are almost identical to those for the original problem. In this equation, \(u_i(t) \cdot   h_i(x^*(t)) = - \frac{1}{t}\) becomes 0 as \(t \to \infty\), which matches \(h_i(x^*) \cdot u_i^* = 0\) in the original formulation.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
&amp;amp; \nabla f(x^*(t)) + \sum_{i=1}^{m} u_i(t) \nabla h_i(x^*(t)) + tA^Tv = 0  \\\ 
&amp;amp; Ax^*(t) = b, \quad u_i(t) \cdot   h_i(x^*(t)) = - \frac{1}{t}, \quad h_i(x^*(t)) \lt 0, \quad u_i(t) \gt 0 , \quad i = 1, \cdots , m \\\
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>15-02 Central path</title>
   <link href="http://localhost:4000/contents/vi/chapter15/15_02_central_path/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/15_02_central_path</id>
   <content type="html">&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;If we denote the solution to the following barrier problem (\(t &amp;gt; 0\)) as \(x^*(t)\), then the &lt;strong&gt;central path&lt;/strong&gt; is the set $${x^*(t)&lt;/td&gt;
      &lt;td&gt;t &amp;gt; 0 }$$.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} \ &amp;amp;&amp;amp;  tf(x) + \phi(x) \\
&amp;amp;\text{subject to } \ &amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Given suitable conditions, the &lt;strong&gt;central path&lt;/strong&gt; set forms a smooth path in \(\mathbb{R}^n\), and as \(t \to \infty\), \(x^*(t) \to x^*\), where \(x^*\) is the solution to the original problem.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;central path&lt;/strong&gt; is a set of solutions obtained by gradually redefining the problem for new values of \(t\), moving from the interior toward the boundary when it is difficult to find the optimal solution at the boundary directly.&lt;/p&gt;

&lt;h2 id=&quot;example-central-path-for-an-lp&quot;&gt;Example: central path for an LP&lt;/h2&gt;
&lt;p&gt;Let’s find the central path for the following LP problem.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align*}
&amp;amp;\min_{x} \ &amp;amp;&amp;amp; c^Tx \\
&amp;amp;\text{subject to } \ &amp;amp;&amp;amp; a_i^Tx \le b_i^T, i = 1, \cdots , 6 \\
\end{align*}\]
&lt;/blockquote&gt;

&lt;p&gt;In the following figure, the dotted line represents the logarithmic barrier function \(\phi\). &lt;br /&gt;&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter15/15_central_path_02.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Central path [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;You can see that as \(t \to \infty\), the central path converges to the optimal \(x^*\). At this point, the hyperplane \(c^Tx = c^Tx(t)\) is the tangent to the level curve of \(\phi\) passing through \(c^Tx(t)\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-01 Barrier method and log barrier function</title>
   <link href="http://localhost:4000/contents/vi/chapter15/15_01_barrier_method_and_log_barrier_function/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/15_01_barrier_method_and_log_barrier_function</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In the previous chapter, we explored how to solve an &lt;strong&gt;equality constrained smooth problem&lt;/strong&gt; using Newton’s method. In this chapter, we will look at methods for solving &lt;strong&gt;inequality and equality constrained smooth problems&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The basic idea is to transform the problem into an equality constrained smooth problem and solve it using Newton’s method. This approach is called the &lt;strong&gt;interior method&lt;/strong&gt;, and in this chapter, we will focus on one type of interior method: the &lt;strong&gt;barrier method&lt;/strong&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-01-03 Log barrier calculus</title>
   <link href="http://localhost:4000/contents/vi/chapter15/15_01_03_log_barrier_calculus/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/15_01_03_log_barrier_calculus</id>
   <content type="html">&lt;p&gt;The gradient and Hessian of the log barrier function are as follows.&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\phi(x) = - \sum_{i=1}^{m} \log(-h_i(x))
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Gradient:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\nabla \phi(x) = - \sum_{i=1}^{m} \frac{1}{h_i(x)} \nabla h_i(x)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hessian:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\nabla^2 \phi(x) = \sum_{i=1}^{m} \frac{1}{h_i(x)^2} \nabla h_i(x) \nabla h_i(x)^T -  \sum_{i=1}^{m} \frac{1}{h_i(x)} \nabla^2 h_i(x)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;example-phix---sum_i1n-logx_i&quot;&gt;Example: \(\phi(x) = -\sum_{i=1}^{n} \log(x_i)\)&lt;/h2&gt;
&lt;p&gt;If we compute the gradient and Hessian for the barrier function \(\phi(x) = -\sum_{i=1}^{n} \log(-x_i)\), we get the following results.&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\phi(x) = -\sum_{i=1}^{n} \log(x_i)
\end{align}
Therefore, \(h_i(x) =  -x_i\) and \(x_i \ge 0\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Gradient:&lt;/p&gt;
&lt;blockquote&gt;

\[\nabla \phi(x) = - 
\begin{bmatrix}
1/x_1 \\\
\vdots \\\
1/x_n \\\
\end{bmatrix}
 = -X^{-1} \mathbb{1}, \qquad X = \text{diag}(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Hessian :&lt;/p&gt;
&lt;blockquote&gt;

\[\nabla^2 \phi(x) = 
\begin{bmatrix}
1/x_1^2 &amp;amp; \cdots &amp;amp; \\\
\vdots &amp;amp; \ddots &amp;amp; \vdots  \\\
&amp;amp; \cdots &amp;amp; 1/x_n^2 \\\
\end{bmatrix}
 = X^{-2}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>15-01-02 Log barrier function & barrier method</title>
   <link href="http://localhost:4000/contents/vi/chapter15/15_01_02_log_barrier_function_and_barrier_method/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/15_01_02_log_barrier_function_and_barrier_method</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Before introducing the barrier method, let’s first see how the indicator function can be approximated by a barrier function.&lt;/p&gt;

&lt;h2 id=&quot;approximation-of-indicator-function&quot;&gt;Approximation of indicator function&lt;/h2&gt;
&lt;p&gt;In the following figure, you can see the indicator function and the barrier function. The dotted line is the indicator function \(I_C\), and the solid lines are the barrier function \(\phi(x) = -1/t\log(-x)\) for \(t = 0.5, 1, 2\). The barrier function smoothly approximates the indicator function, and when \(t=2\), it provides the best approximation.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter15/15_barrier_function_01.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig 1] barrier function }\phi(x) = -1/t\log(-x) [1]$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;logarithmic-barrier-function&quot;&gt;Logarithmic barrier function&lt;/h2&gt;
&lt;p&gt;Suppose \(h_1, \cdots , h_m : \mathbb{R}^n \to \mathbb{R}\) are convex and twice differentiable. For the set \(\{x : h_i(x) \lt 0, i = 1, \cdots , m \}\), the following function is called the logarithmic barrier function.&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\phi(x) = - \sum_{i=1}^{m} \log(-h_i(x))
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, the set is assumed to be the interior of the feasible set \(C\) and is non-empty.&lt;/p&gt;

&lt;h2 id=&quot;barrier-method&quot;&gt;Barrier method&lt;/h2&gt;

&lt;p&gt;Using the barrier function, the original problem can be approximated as follows. Here, \(t\gt 0\).&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x}           &amp;amp;&amp;amp; f(x) + \frac{1}{t} \phi(x) &amp;amp; \qquad      &amp;amp; \min_{x} &amp;amp;&amp;amp; tf(x) + \phi(x) \\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; Ax = b                     &amp;amp; \iff \qquad &amp;amp; \text{subject to } &amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The method of solving the problem defined in this way using Newton’s method is called the &lt;strong&gt;barrier method&lt;/strong&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-01-01 Inequality constrained minimization problems</title>
   <link href="http://localhost:4000/contents/vi/chapter15/15_01_01_inequality_constrained_minimization_problems/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter15/15_01_01_inequality_constrained_minimization_problems</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Let’s consider the following convex optimization problem.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x}           &amp;amp;&amp;amp; f(x) \\ 
&amp;amp;\text{subject to } &amp;amp;&amp;amp; Ax = b \\
                    &amp;amp;&amp;amp;&amp;amp; h_{i}(x) \leq 0, i = 1, \dotsc, m
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In problems that include inequalities like this, it is difficult to distinguish between binding and non-binding constraints, especially at the boundary of the feasible region. Binding constraints refer to the constraints that affect the solution.&lt;/p&gt;

&lt;p&gt;Therefore, the &lt;strong&gt;interior method&lt;/strong&gt; is an approach that tries to solve the problem from the interior of the feasible region, not at the boundary.&lt;/p&gt;

&lt;h2 id=&quot;background-of-interior-method&quot;&gt;Background of interior method&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;interior method&lt;/strong&gt; for general problems was proposed in the 1960s by Anthony V. Fiacco and Garth P. McCormick. At the time, it was overshadowed by popular methods like sequential quadratic programming and the active set method, and only gained attention in the 1980s.&lt;/p&gt;

&lt;p&gt;The active set method is a theory for determining which constraints affect the optimization result. In the active set method, a constraint is considered active if it is zero, and such constraints are called the active set. However, to find the active set, you need to compute the boundary of the feasible region, and as the number of constraints increases, the computational cost increases.&lt;/p&gt;

&lt;p&gt;Recognizing these issues, the interior point method was developed to solve problems from the interior rather than the boundary. For example, in LP, if there are \(m\) constraints, calculating the boundary requires \(O(m^2)\) computations, but with the interior method, even for large \(m\), the solution can be found within 20–30 Newton steps. More details on performance will be discussed later.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Interior-point_method&quot;&gt;Interior point method&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Active_set_method&quot;&gt;Active set method&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reducing-equality-constrained-minimization-problem&quot;&gt;Reducing equality constrained minimization problem&lt;/h2&gt;
&lt;p&gt;The above problem can be rewritten as \(C := \{x : h_i(x) \le 0, i = 1, \cdots , m \}\). Inequality constraints can be included in the objective function as an indicator function.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} \ &amp;amp;&amp;amp; f(x) + I_C(x) \\
&amp;amp;\text{subject to }\  &amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In this way, the problem can be transformed into an equality constrained minimization problem. However, since the indicator function still includes the boundary, it still has the difficulty of boundary computation from the original problem, and since it is not differentiable, it is difficult to apply Newton’s method.&lt;/p&gt;

&lt;p&gt;What if we approximate the indicator function \(I_C\) with a &lt;strong&gt;barrier function&lt;/strong&gt;? In that case, the boundary would not be included and since it is differentiable, Newton’s method can be applied.&lt;/p&gt;

&lt;p&gt;The method of solving problems redefined with barrier functions in this way is called the barrier method, which is introduced in detail in the next section.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>25 Mixed Integer Programming (part II)</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_Mixed_integer_programming/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter25/25_Mixed_integer_programming</id>
   <content type="html">&lt;p&gt;This chapter examines the cutting plane algorithm, which can be considered the most core algorithm in Integer Programming (IP), and the branch and cut algorithm, which is its practical implementation.&lt;/p&gt;

&lt;p&gt;We will also examine examples of Integer Programming such as best subset selection and Least mean squares.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Belotti, Kirches, Leyer, Linderoth, Luedke, and Mahajan (2012), “Mixed-integer nonlinear optimization”&lt;/li&gt;
  &lt;li&gt;Bertsimas and Mazumder (2016), “Best subset selection via a modern optimization lens”&lt;/li&gt;
  &lt;li&gt;Bertsimas, King, and Mazumder (2014), “Least quantile regression via modern optimization”&lt;/li&gt;
  &lt;li&gt;Conforti, Cornuejols, and Zambelli (2014), “Integer programming”&lt;/li&gt;
  &lt;li&gt;Wolsey (1998), “Integer programming”&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>25-02 Two extended examples</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_02_Two_extended_examples/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter25/25_02_Two_extended_examples</id>
   <content type="html">&lt;p&gt;In this section, we will present two examples of Mixed Integer Programming.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Best subset selection&lt;/li&gt;
  &lt;li&gt;Least mean squares&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>25-02-02 Least mean squares</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_02_02_Least_mean_squares/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter25/25_02_02_Least_mean_squares</id>
   <content type="html">&lt;p&gt;So far, we have solved regression problems by minimizing the \(l_2\) norm or \(l_1\) norm of residuals. Is there a more robust method than these methods?&lt;/p&gt;

&lt;p&gt;When performing regression to minimize the median of residuals, we can achieve more robust regression. This is called &lt;strong&gt;Least Median of Squares&lt;/strong&gt;, and it is robust enough that the estimator does not get corrupted even if about 50% of the data is corrupted. However, this problem is also an NP-Hard problem!&lt;/p&gt;

&lt;p&gt;This section introduces how to solve the &lt;strong&gt;Least Quantile of Squares&lt;/strong&gt; problem, which generalizes the Least Median of Squares problem, using Integer programming.&lt;/p&gt;
&lt;h2 id=&quot;least-mean-squares&quot;&gt;Least mean squares&lt;/h2&gt;
&lt;p&gt;Let \(X = [x^{1} \quad \dotsc \quad x^{p}] \in \mathbb{R}^{n×p}\) and \(y \in \mathbb{R}^{n}\). And when \(\beta \in \mathbb{R}^{p}\), let \(r : = y - X\beta\).&lt;/p&gt;

&lt;h3 id=&quot;observe&quot;&gt;Observe&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Least squares (LS) : \(\beta_{LS} : = \underset{\beta}{\text{argmin}} \sum_{i} r^2_i\)&lt;/li&gt;
  &lt;li&gt;Least absolute deviation (LAD) : \(\beta_{LAD} : = \underset{\beta}{\text{argmin}} \sum_{i} \lvert r_{i} \rvert\)
    &lt;h3 id=&quot;least-median-of-squares-lms&quot;&gt;Least Median of Squares (LMS)&lt;/h3&gt;
    &lt;blockquote&gt;
\[\beta_{LMS} : = \underset{\beta}{\text{argmin}} (\text{median} \lvert r_{i} \rvert )\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;least-quantile-regression&quot;&gt;Least quantile regression&lt;/h2&gt;
&lt;p&gt;Least Median of Squares problem를 일반화한 Least Quantile of Squareproblem는 as follows: 정의할 수 있다. 여기서 \(r_{q}\)는 \(q\)번째 ordered absolute residual이다.&lt;/p&gt;
&lt;h3 id=&quot;least-quantile-of-squares-lqs&quot;&gt;Least Quantile of Squares (LQS)&lt;/h3&gt;
&lt;blockquote&gt;
\[\beta_{LQS} : = \underset{\beta}{\text{argmin}} (\lvert r_{(q)} \rvert ), \quad 1 \le q \le n, \quad \lvert r_{1} \rvert \le \lvert r_{2} \rvert \le \cdots \le \lvert r_{n} \rvert\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;key-step-in-the-formulation&quot;&gt;Key step in the formulation&lt;/h3&gt;
&lt;p&gt;이제 Least Quantile of Squareproblem를 Integer Programmingwith, 재정by,보자. 이when,, \(r\)의 각 entry \(i\)about, 다음and, 같은 binary variable을 사용한다.&lt;/p&gt;

&lt;blockquote&gt;
\[\lvert r_{i} \rvert \le \lvert r_{(q)} \rvert$ or $\lvert r_{i} \rvert \ge \lvert r_{(q)} \rvert\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;integer-programming-formulation&quot;&gt;Integer programming formulation&lt;/h3&gt;
&lt;p&gt;\(\bar{\mu_{i}}\)and, \(\mu_{i}\)은 thresholdto, 각각의 개수는 \(k\)개, \(n-k\)개이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
  \min_{\beta, \mu, \bar{\mu}, z, \gamma} &amp;amp; \quad {\gamma} \\
  \text{subject to} &amp;amp; \quad  \gamma \le \lvert r_{i} \rvert + \bar{\mu_{i}}, \quad i = 1, ..., n \\
  &amp;amp; \quad  \gamma \le \lvert r_{i} \rvert -  \mu_{i}, \quad i = 1, ..., n \\
  &amp;amp; \quad \bar{\mu_{i}} \le M \cdot z_{i}, \quad i = 1, ..., n \\
  &amp;amp; \quad \mu_{i} \le M \cdot (1-z_{i}), \quad i = 1, ..., n \\
  &amp;amp; \quad \sum^{p}_{i=1} z_{i} = q \\
  &amp;amp; \quad \mu_{i}, \bar{\mu_{i}} \ge 0, \quad i = 1, ..., n \\
  &amp;amp; \quad z_{i} \in \{0, 1\},  \quad i = 1, ..., n \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이 problemat, 첫번째and, 두번쨰 constraint을 보면 residual의 절대값 \(\lvert r_{i} \rvert\)이 포함되어 있어서 convex relaxationwith, 풀 수가 없다. therefore,, 첫번째and, 두번쨰 constraint을 convex functionwith, converting, 주어야 한다.&lt;/p&gt;

&lt;h2 id=&quot;first-order-algorithm&quot;&gt;First-order algorithm&lt;/h2&gt;
&lt;p&gt;\(\lvert r_{i} \rvert\)는 다음and, 같은 형태to, convex function \(H_{q}(\beta)\)to, 재정의할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;

\[\lvert r_{q} \rvert = \lvert y_{(q)} - x^{T}_{(q)} \beta \rvert = H_{q}(\beta) - H_{q+1}(\beta)\]
&lt;/blockquote&gt;

&lt;p&gt;이when, \(H_{q}(\beta)\)는 as follows: 정의된다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
H_{q}(\beta) = \sum^{n}_{i=q} \lvert y_{(i)} - x^{T}_{(i)} \beta \rvert  = &amp;amp;
\max_{w} \sum^{n}_{i=1} w_i \lvert y_{(i)} - x^{T}_{(i)} \beta \rvert \\
&amp;amp; \text{subject to} \sum^{n}_{i=1}  w_i  = n − q + 1 \\
&amp;amp;0 \le w_i \le 1, i = 1, ..., n \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(H_{q}(\beta)\)는 앞서 정의된 \(\lvert r_{i} \rvert\)을 작은것from, 큰 순with, 나열할 when,, \(q\)번째 이image의 모든 residual의 sum이다. therefore,, \(q\)번째 이image의 residual의 sumat, \(q+1\)번째 이image의 residual의 sum을 빼면 \(q\)번째의 residual 된다는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;Subgradient algorithmwith, \(H_{q}(\beta) - H_{q+1}(\beta)\)의 local minimum을 구할 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, see 논문 &lt;a href=&quot;https://arxiv.org/pdf/1310.8625.pdf&quot;&gt;LEAST QUANTILE REGRESSION VIA MODERN OPTIMIZATION&lt;/a&gt; see
    &lt;h2 id=&quot;computational-results&quot;&gt;Computational results&lt;/h2&gt;
    &lt;p&gt;위의 논문at,  Least Quantile of Squareproblem를 실험한 result,는 다음 그래프at, 볼 수 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mixed-integer-programming-gap&quot;&gt;Mixed integer programming gap&lt;/h3&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_06_LQS_results1.png&quot; alt=&quot;[Fig1] Mixed integer programming gap [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Mixed integer programming gap [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cold-vs-warm-starts&quot;&gt;Cold vs Warm Starts&lt;/h3&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_07_LQS_results2.png&quot; alt=&quot;[Fig2] Cold vs Warm Starts [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Cold vs Warm Starts [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>25-02-01 Best subset selection</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_02_01_Best_subset_selection/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter25/25_02_01_Best_subset_selection</id>
   <content type="html">&lt;p&gt;Best subset selection, one of the representative examples of Integer Programming, is a problem of selecting k entries from \(p\) entries.&lt;/p&gt;

&lt;h2 id=&quot;best-subset-selection&quot;&gt;Best subset selection&lt;/h2&gt;
&lt;p&gt;When \(X = [x^{1} \quad \dotsc \quad x^{p}] \in \mathbb{R}^{n×p}\) and \(y \in \mathbb{R}^{n}\), the best subset selection problem is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{\beta} &amp;amp; \quad \frac{1}{2} \parallel y - X\beta \parallel^{2} \\
\text{subject to } &amp;amp; \quad \parallel \beta \parallel_{0}  \  \leq  k \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(\parallel \beta \parallel_{0}\) is the number of nonzero entries in \(\beta\).&lt;/p&gt;

&lt;p&gt;Previously in earlier chapters, we defined this type of problem as a Lasso problem and made \(\beta\) sparse using the \(l_1\) norm. In this problem, it is defined as a problem that constrains the number of non-zero entries using the \(l_0\) norm, but since the constraint condition \(\parallel \beta \parallel_{0}  \  \leq  k\) is non-convex, the problem cannot be solved with the convex optimization techniques we have learned so far.&lt;/p&gt;

&lt;h3 id=&quot;integer-programming-formulation&quot;&gt;Integer programming formulation&lt;/h3&gt;
&lt;p&gt;Then let’s reformulate this problem with Integer programming.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{\beta, z} &amp;amp; \quad \frac{1}{2} \parallel y - X\beta \parallel^{2} \\
\text{subject to } &amp;amp; \quad \left\vert  \beta_{i} \right\vert  \leq M_{i} \cdot z_{i} \quad i = 1 \dotsc p \\
&amp;amp; \quad \sum_{i = 1}^{p} z_{i} \leq k \\
&amp;amp; \quad z_{ji} \in \lbrace 0, 1 \rbrace \quad i = 1 \dotsc p \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Binary variable \(z_i\)를 introducing,서 \(z_i\)의 sum이 \(k\)보다 작게 만듦with,써 위의 problemand, 동일solution지게 만들었다.  \(M_i\)는 사전to, 알고 있는 \(\left\vert  \beta_{i} \right\vert\)의 image한 값with, \(X\)and, \(y\)를 사전processing,서 computation할 수 있는 값이다.&lt;/p&gt;

&lt;p&gt;이제 problem를 Integer Programmingwith, 정의했으므to, 지금from, Integer Programming techniquewith, 풀 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;a-clever-way-to-get-good-feasible-solutions&quot;&gt;A clever way to get good feasible solutions&lt;/h2&gt;
&lt;p&gt;problem를 generalizing,서 algorithm을 explaining,보자. Objective function \(g : \mathbb{R}^{p} \to \mathbb{R}\)이 smooth convex이고 \(\nabla g\)가 L-Lipschitz이라고 하자.&lt;/p&gt;
&lt;blockquote&gt;

\[\min_{\beta} g(\beta) \quad \text{subject to} \quad \parallel \beta \parallel_{0} \le k\]
&lt;/blockquote&gt;

&lt;p&gt;Best subset selection의 case, \(g(\beta) = \frac{1}{2} \parallel X\beta - y \parallel^2_2\)이다.&lt;/p&gt;

&lt;h3 id=&quot;observation&quot;&gt;Observation&lt;/h3&gt;
&lt;p&gt;as follows: 정의된 \(H_k(u)\) function를 through, \(u \in \mathbb{R}^p\)at, 가장 큰 k개 entry를 구할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;

\[H_k(u) = \underset{\beta : \parallel \beta_{0} \parallel \le k}{\text{argmin}} \parallel \beta - u \parallel^2_2\]
&lt;/blockquote&gt;

&lt;p&gt;이when,, \(H_k(u)\) function는 hard thresholding을 한다. also,, \(u\)를 set \(\beta\)to, projection한 것with, 볼 수도 있다.&lt;/p&gt;

&lt;h3 id=&quot;discrete-first-order-algorithm&quot;&gt;Discrete first-order algorithm&lt;/h3&gt;
&lt;p&gt;이제 gradient descentand, function \(H_k(u)\)를 using,서 algorithm을 정by,보자.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(\beta^{(0)}\)with, 시작&lt;/li&gt;
  &lt;li&gt;for \(k = 0, 1, ...\) &lt;br /&gt;
\(\quad \beta^{(i+1)} = H_k \left(\beta^{(i)} - \frac{1}{L} \nabla g(\beta^{(i)})\right)\)&lt;br /&gt;
end for&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위의 process을 iteration하면 \(\beta^{(i)} \to \bar{\beta}\)to, convergence하게 된다. 이는 위의 minimization problemto, about, local solution이라고 할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;

\[\bar{\beta} =  H_k \left(\bar{\beta} - \frac{1}{L} \nabla g(\bar{\beta})\right)\]
&lt;/blockquote&gt;

&lt;p&gt;result,적with, 이 algorithm은 proximal gradient algorithmwith, 볼 수 있다. 왜냐하면 function \(H_k(u)\)가 proximal operator 역할을 하고 있기 because,이다.&lt;/p&gt;
&lt;h2 id=&quot;computational-results&quot;&gt;Computational results&lt;/h2&gt;
&lt;h3 id=&quot;mixed-integer-programming-gap&quot;&gt;Mixed integer programming gap&lt;/h3&gt;
&lt;p&gt;아래 그림at, Subset selection problem의 실험 result,를 let’s look at.&lt;/p&gt;

&lt;p&gt;왼쪽 그래프at, upper bound는 바to, optimal이 되었지만 lower bound는 천천히 올라오다가 upper boundand, 만나는 지점at,야 optimal임을 알게 된다. 왜냐하면 linear programat,는 solution이 optimal인지 체크할 method이 없으며 upper boundand, lower bound가 같아졌을 when, optimal임을 알 수 있게 된다.
(referenceto, upper boundand, lower bound의 difference를 mixed integer programming gap이라고 한다.)&lt;/p&gt;

&lt;p&gt;오른쪽 그림은 동일한 실험 result,를 mixed integer programming gap을 작아지는 모습with, showing,주고 있다. 주황색 그래프는 upper boundand, lower bound의 difference이인 mixed integer programming gap을 representing,며 점점 줄어들고 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_03_subset_results1.png&quot; alt=&quot;[Fig1] Dataset n=350, p = 64, k=6 [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$[Fig1] Dataset n=350, p = 64, k=6 [3]$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cold-and-warm-starts&quot;&gt;Cold and Warm Starts&lt;/h3&gt;
&lt;p&gt;다음 그림at, warm start가 cold start보다 전체적with, 성능이 매우 우수함을 showing,주고 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_04_subset_results2.png&quot; alt=&quot;[Fig2] Cold and Warm Starts [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Cold and Warm Starts [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;sparsity-detection&quot;&gt;Sparsity Detection&lt;/h3&gt;
&lt;p&gt;다음 그림at,는 MIP (Mixed Integer Programming)and, Lasso, Step regression, Sparsenet의 sparsity를 비교하고 있다. result,적with, MIP가 가장 sparse한 result,내고 있음을 알 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_05_subset_results3.png&quot; alt=&quot;[Fig3] Sparsity Detection (synthetic database) [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig3] Sparsity Detection (synthetic database) [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01 Cutting Planes</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_01_Cutting_planes/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter25/25_01_Cutting_planes</id>
   <content type="html">&lt;p&gt;The cutting plane method is an approach that changes an integer linear program to a convex problem and finds a solution. If this solution is not included in the original feasible set, it uses cuts to progressively guide the newly obtained solution to be included in the original feasible set by cutting out the region where the solution exists. Here, a cut is a line (or hyperplane) that cuts the feasible set, also called a cutting plane.&lt;/p&gt;

&lt;h2 id=&quot;concept-of-cutting-plane&quot;&gt;Concept of cutting plane&lt;/h2&gt;
&lt;p&gt;Conceptually, it can be thought of as a method that draws a line between the original feasible set and the feasible set to cut out regions that are not part of the original feasible set, as shown in the figure below.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_cutting_plane_concept.png&quot; alt=&quot;[Fig1] Cutting Plane&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Cutting Plane&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Red region: feasible set of the original integer linear program&lt;/li&gt;
  &lt;li&gt;Blue region: feasible set of the convex relaxation problem&lt;/li&gt;
  &lt;li&gt;Green line: cutting plane (the cutting plane exists between the blue and red regions)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The detailed algorithm will be introduced again in the main text.&lt;/p&gt;

&lt;h2 id=&quot;a-bit-of-history-on-cutting-planes&quot;&gt;A bit of history on cutting planes&lt;/h2&gt;
&lt;p&gt;It took a very long time for the cutting plane method to develop from theory to a practical method.&lt;/p&gt;

&lt;p&gt;In 1954, Dantzig, Fulkerson, and Johnson first proposed the cutting plane method to solve the TSP (traveling salesman problem), and in 1958, mathematician Gomory proposed a general cutting plane method that could solve arbitrary integer linear programs. However, for about 30 years after that, Gomory cuts remained buried in an impractical state for solving real problems.&lt;/p&gt;

&lt;p&gt;In 1990, Sebastian Ceria at CMU successfully implemented the cutting plane method using the branch and bound algorithm, which is called branch and cut. Since then, cutting planes have become a core component of commercial optimization solvers.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01-04 Branch and cut algorithm</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_01_04_Branch_and_cut_algorithm/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter25/25_01_04_Branch_and_cut_algorithm</id>
   <content type="html">&lt;p&gt;In 1990, Sebastian Ceria at CMU successfully implemented the cutting plane method using the branch and bound algorithm, which is called branch and cut. Since then, cutting planes have become a core component of commercial optimization solvers.&lt;/p&gt;

&lt;h2 id=&quot;branch-and-cut-algorithm&quot;&gt;Branch and cut algorithm&lt;/h2&gt;
&lt;p&gt;다음and, 같은 integer programming problem가 있다고 하자. 이when, \(f : \mathbb{R}^{n} \to \mathbb{R}\)이고  \(C \subseteq \mathbb{R}^{n}\)는 convex이며 \(J \subseteq {1, ..., n}\)이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {f(x)} \\
\text{subject to } &amp;amp; \quad  x \in C \\
                   &amp;amp; \quad  x_j \in \mathbb{Z}, \quad j \in J \\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;branch-and-cut-algorithm-1&quot;&gt;Branch and cut algorithm&lt;/h3&gt;
&lt;p&gt;algorithmat, Convex Problem은 CPto, Integer Program은 IPto, 표기한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;다음 convex relaxation problem를 푼다.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {f(x)} \\
\text{subject to } &amp;amp; \quad  x \in C \\
                   &amp;amp; \quad  x_j \in \mathbb{Z}, \quad j \in J \\
\end{align}\]
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;(CR) infeasible \(\Rightarrow\) (IP) infeasible &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;(CR)의 solution \(x^{\star}\)이 (IP) feasible \(\Rightarrow\) \(x^{\star}\)는 (IP)의 solution &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;(CR)의 solution \(x^{\star}\)이 (IP) infeasible하면 다음 두 가지 중to, 선택 &lt;br /&gt;
\(\quad\)4.1 cut을 추가하고 step 1to, 간다. &lt;br /&gt;
\(\quad\)4.2 branchsolution서 iteration적with, subproblem을 푼다. &lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Branch and cut algorithm은 branch and bound and, cutting plane method를 결sum한 algorithmwith,서, step 4at, branch-and-bound를 할지, cut을 할지 선택할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;integer-programming-technology&quot;&gt;Integer programming technology&lt;/h2&gt;
&lt;p&gt;Gurobi, CPLEX, FICOand, 같은 state-of-the-art solver들은 매우 효율적인 simplex, interior-point method 등의 algorithm 구현을 포함하고 있다. particularly,, mixed integer optimization의 case, 대부분의 solver들은 branch and cut algorithm을 사용하고 있으며 이들은 convex relaxationand, warm start의 이점을 많이 활용하고 있다.&lt;/p&gt;

&lt;p&gt;약 30년 전to, 비하면 Integer programming의 성능 향image은 매우 비약적이다. therefore,, 그during, 풀지 못했던  실생활의 많은 problem들이 최근to, Integer programming을 through, solution결되고 있으며 computing power가 향image됨according to, 더욱 적극적with, 활용될 전망이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Algorithmat,의 속도 향image 1990-2016 : over \(500,000\)&lt;/li&gt;
  &lt;li&gt;Hardwareat,의 속도 향image 1990-2016 : over \(500,000\)&lt;/li&gt;
  &lt;li&gt;Total speedup over \(250\) billion = \(2:5 \cdot 10^{11}\)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01-03 Gomory cuts (1958)</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_01_03_Gomory_cuts/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter25/25_01_03_Gomory_cuts</id>
   <content type="html">&lt;p&gt;Mathematician Gomory devised a method to easily find valid inequalities based on the following fact:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;if \(a \le b\) and \(a\) is an integer then \(a \le \lfloor b \rfloor\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That is, if a is an integer, then even if b is rounded down, the relationship that a is less than or equal to b is maintained.&lt;/p&gt;

&lt;h2 id=&quot;gomory-fractional-cut&quot;&gt;Gomory fractional cut&lt;/h2&gt;
&lt;p&gt;Let’s say that the feasible set \(S\) defined by the convex hull of the IP problem mentioned earlier is as follows:&lt;/p&gt;

\[S \subseteq \left\{ x \in \mathbb{Z}^{n}_{+} : \sum^{n}_{j=1} a_{j} x_{j} = a_{0} \right\} \quad \text{where} \quad  a_{0} \notin \mathbb{Z}\]

&lt;p&gt;In this case, the Gomory fractional cut is defined as follows:&lt;/p&gt;

\[\sum^{n}_{j=1} (a_{j} - \lfloor a_{j} \rfloor) x_{j} \ge a_{0} -  \lfloor a_{0} \rfloor\]

&lt;p&gt;There are many ideas that extend this concept. For example, there are Chvatal cuts, split cuts, lift-and-project cuts, etc.&lt;/p&gt;

&lt;p&gt;The derivation process of Gomory fractional cut is detailed on Wikipedia, so please refer to it.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, see &lt;a href=&quot;https://en.wikipedia.org/wiki/Cutting-plane_method&quot;&gt;Cutting-plane method&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01-02 Cutting plane algorithm</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_01_02_Cutting_plane_algorithm/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter25/25_01_02_Cutting_plane_algorithm</id>
   <content type="html">&lt;p&gt;In this section, we will examine the cutting plane algorithm that can solve integer linear programs.&lt;/p&gt;

&lt;h2 id=&quot;valid-inequality&quot;&gt;Valid Inequality&lt;/h2&gt;
&lt;p&gt;To define cutting planes, let’s first look at what valid inequalities are.&lt;/p&gt;

&lt;p&gt;An inequality \(\pi^{T}x \le \pi_{0}\) is said to be valid for set \(S\) if it satisfies the following condition. That is, if a set \(S\) is contained in the halfspace defined by the inequality \(\pi^{T}x \le \pi_{0}\), then this inequality can be considered valid for \(S\).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\pi^{T}x \le \pi_{0}\) for all \(x \in S\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;An inequality must be valid to become a cutting plane.&lt;/p&gt;
&lt;h2 id=&quot;cutting-plane-algorithm&quot;&gt;Cutting plane algorithm&lt;/h2&gt;
&lt;p&gt;이제 다음and, 같은 integer programming이 있을 when, cutting plane algorithm을 let’s examine.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {c^{T}x} \\
\text{subject to } &amp;amp; \quad  x \in C \\
                   &amp;amp; \quad  x_j \in \mathbb{Z}, \quad j \in J \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(S := \text{conv} \left \{ x \in C : x_j \in \mathbb{Z}, j \in J \right \}\)이다.&lt;/p&gt;

&lt;h3 id=&quot;cutting-plane-algorithm-1&quot;&gt;Cutting plane algorithm&lt;/h3&gt;
&lt;p&gt;다음 algorithmat, Convex Problem은 CPto, Integer Program은 IPto, 표기한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(C_{0} := C\)with, 두고 \(x^{(0)} := \text{argmin}_{x} \left\{c^{T}x : x \in C_{0} \right\}\)를 computation&lt;/li&gt;
  &lt;li&gt;for \(k = 0, 1, ...\) &lt;br /&gt;
\(\quad\)if \(x^{k}\)가 (IP) feasible이면 \(x^{k}\)는 optimal solution이므to, Stop함 &lt;br /&gt;
\(\quad\)else&lt;br /&gt;
\(\quad\quad\) \(S\)about, valid하면서 \(x^{k}\)를 잘라내는 부등식 (\(\pi\), \(\pi_{0}\))을 찾음&lt;br /&gt;
\(\quad\quad\) \(C_{k+1} := C_{k} \cap \{ x : \pi^{T}x \le \pi_{0} \}\)&lt;br /&gt;
\(\quad\quad\) \(x^{(k+1)} := \text{argmin}_{x} \left\{c^{T}x : x \in C_{k+1} \right\}\)&lt;br /&gt;
\(\quad\)end if&lt;br /&gt;
end for&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이and, 같은 valid inequality를 &lt;strong&gt;cutting plane&lt;/strong&gt; or, &lt;strong&gt;cut&lt;/strong&gt;이라고 한다.&lt;/p&gt;

&lt;p&gt;algorithm의 1step는 convex relaxation을 하여 CP problem를 푸는 step이다. 이떄 feasible set은 \(C\)이다.&lt;/p&gt;

&lt;p&gt;algorithm 2stepat,는 구한 solution가 IPat, feasible하다면 이를 solutionto, 본다. if, feasible하지 않다면 solution인 \(x^{k}\)and, set \(S\)를 나누는 valid inequality를 finding, \(C_{k}\)의 범위를 줄인다. and,, \(C_{k+1}\)to, 재정의된 CP problem를 풀고 algorithm 2step를 iteration하게 된다.&lt;/p&gt;

&lt;p&gt;아래 그림at, polygon은 set \(C\)를 representing,며 CP의 solution는 검정색 점with, 표시되어 있다. 이when,, valid inequality는 solution를 잘라내서 set \(C\)의 범위를 줄이게 된다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_02_valid_inequality.png&quot; alt=&quot;[Fig1] Valid Inequality&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Valid Inequality [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;이and, 같이 set \(C\)의 범위를 계속solution서 reducing,나가면 IP problem의 convex hull feasible set인 set \(S\)and, 만나게 되어 IPto, feasible한 solution를 구할 수 있게 된다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01-01 Convexification</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_01_01_Convexification/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter25/25_01_01_Convexification</id>
   <content type="html">&lt;p&gt;Transforming an integer program into an equivalent convex problem is called convexification. When convexification is performed, the feasible set becomes a polyhedron, making it easy to find valid cutting planes for the cutting plane algorithm.&lt;/p&gt;

&lt;h2 id=&quot;convexification&quot;&gt;Convexification&lt;/h2&gt;
&lt;p&gt;To convexify an integer program, the objective function must be linear. In this case, the constraints of the integer program consist of a convex set \(C\) and an integer set \({x_j}\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {c^{T}x} \\
\text{subject to } &amp;amp; \quad  x \in C \\
                   &amp;amp; \quad  x_j \in \mathbb{Z}, \quad j \in J \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In this case, the feasible set can be redefined as the convex hull \(S := \text{conv} \left \{ x \in C : x_j \in \mathbb{Z}, j \in J \right \}\). Using the feasible set defined by this convex hull \(S\), we can define a convex problem equivalent to the original problem as follows. This process is called convexification.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {c^{T}x} \\
\text{subject to } &amp;amp; \quad  x \in S \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In the figure below, the blue region is \(C\), the red points are \({x_j}\), and the convex hull \(S\) formed by these two sets is the red region.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter25/25_01_cutting_plane_concept.png&quot; alt=&quot;[Fig1] Cutting Plane&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Cutting Plane&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;출처: https://commons.wikimedia.org/wiki/File:Cutting_plane_algorithm2.png &lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The reason these two formulations are equivalent is because the objective function is linear.&lt;/p&gt;

&lt;h2 id=&quot;special-case-integer-linear-programs&quot;&gt;Special case: integer linear programs&lt;/h2&gt;
&lt;p&gt;Let’s apply the above convexification process to the following integer linear program.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
          \min_{x} &amp;amp; \quad {c^{T}x} \\
\text{subject to } &amp;amp; \quad  Ax \le b \\
                   &amp;amp; \quad  x_j \in \mathbb{Z}, \quad j \in J \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The convex hull \(S\) of the integer linear program is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: If \(A, b\) are rational numbers, then the following set is a polygon.
\(S := \text{conv} \left \{ x : Ax \le b,  x_j \in \mathbb{Z}, j \in J \right \}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So is an integer linear program a linear program? Of course it is. However, in this case, the polyhedron \(S\) can become a very complex polygon with an exponentially large number of inequalities. Therefore, generally, we need to solve the problem using different methods than those used to solve linear programs.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>24 Mixed Integer Programming (part I)</title>
   <link href="http://localhost:4000/contents/en/chapter24/24_Mixed_integer_programming/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter24/24_Mixed_integer_programming</id>
   <content type="html">&lt;p&gt;This chapter introduces the definition, relationships, and examples of Mixed Integer Programming, and presents methods for finding optimal solutions by indirectly utilizing relaxation to find solutions for Integer programming.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>24-05 Branch and bound algorithm (B&B)</title>
   <link href="http://localhost:4000/contents/en/chapter24/24_05_Branch_and_bound_algorithm/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter24/24_05_Branch_and_bound_algorithm</id>
   <content type="html">&lt;p&gt;Let’s find out the method of solving Integer programs through Branch and bound algorithm and Convex relaxation.&lt;/p&gt;

&lt;h2 id=&quot;definition-and-properties&quot;&gt;Definition and properties&lt;/h2&gt;
&lt;p&gt;Branch and bound algorithm is the most common method for solving integer programs. It is mainly a divide and conquer approach that breaks the original problem into several smaller problems (sub-problems) to approach the correct answer.&lt;/p&gt;

&lt;p&gt;When the constraint set \(X = X_{1} \cup X_{2} \cup \dotsc \cup X_{k}\) is a union of partitions consisting of each \(X_{i}\),&lt;/p&gt;
&lt;blockquote&gt;
\[\min_{x \in X} f(x) = \min_{i = 1, \dotsc , k} \lbrace \min_{x \in X_{i}} f(x) \rbrace .\]
&lt;/blockquote&gt;

&lt;p&gt;We can find the optimal solution by partitioning the region and finding the minimum.&lt;/p&gt;

&lt;p&gt;Any feasible solution of a sub-problem can be set as the upper bound \(u(X)\). To obtain the lower bound, we find the lower bound \(l(X_{i})\) of each sub-problem. Then, if \(l(X_{i}) \geq u(X)\), we exclude the sub-problem \(\min_{x \in X_{i}} f(x)\) corresponding to this part.&lt;/p&gt;

&lt;p&gt;The Integer Programming problem (IP) is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; x \in C \\\\
&amp;amp;&amp;amp;&amp;amp;x_j \in \mathbb{Z}, \quad j \in J \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f : \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\quad \text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And when the Convex Relaxation (CR) problem is as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;x \in C \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f : \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\quad \text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The problem is solved recursively.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If the constraint set is trivial, solve the (CR) problem. If the solution is less than the current upper bound, update the upper bound. Stop.
    &lt;ul&gt;
      &lt;li&gt;If (CR) is infeasible, then (IP) is also infeasible. Stop.&lt;/li&gt;
      &lt;li&gt;If the solution \(x^{\star}\) of (CR) is also feasible for (IP), then \(x^{\star}\) becomes the solution. Stop.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Find the lower bound of the problem.
    &lt;ul&gt;
      &lt;li&gt;If the solution \(x^{\star}\) of (CR) is infeasible for (IP), update the lower bound of (IP).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If the lower bound is greater than the current upper bound, Stop.&lt;/li&gt;
  &lt;li&gt;Split the constraint set and solve each sub-problem recursively.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;after-branching&quot;&gt;After branching&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;After branching, solve each subproblem.&lt;/li&gt;
  &lt;li&gt;If the lower bound of a subproblem is greater than the current upper bound, there is no need to consider the subproblems below it.&lt;/li&gt;
  &lt;li&gt;The most reliable method for computing the lower bound is through convex relaxation, but other methods (e.g., Lagrangian relaxation) are also used.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>24-04 Relaxations</title>
   <link href="http://localhost:4000/contents/en/chapter24/24_04_Relaxations/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter24/24_04_Relaxations</id>
   <content type="html">&lt;p&gt;For relaxation, specific conditions must be satisfied, and Convex relaxation and Lagrangian relaxation methods can be utilized. Let’s examine the detailed content.&lt;/p&gt;

&lt;h2 id=&quot;conditions-for-relaxations&quot;&gt;Conditions for Relaxations&lt;/h2&gt;
&lt;p&gt;If a general optimization problem is defined as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_{x \in X} f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;The relaxation of this problem is defined as follows when represented as an arbitrary optimization problem:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x \in Y} \: g(x)\\\\
&amp;amp;\text{such that}\\\\
&amp;amp;\text{① } X \subset Y \quad \text{ and}\\\\ 
&amp;amp;\text{② } g(x) \leq f(x) \text{ for all } x \in X 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If the objective functions \(f(x)\) and \(g(x)\) are different, both conditions must be satisfied, and if they are the same, only condition ① needs to be satisfied.
By these two conditions, the optimal value of the relaxation becomes a lower bound of the optimal value of the original problem.&lt;/p&gt;

&lt;h2 id=&quot;convex-relaxations&quot;&gt;Convex relaxations&lt;/h2&gt;
&lt;p&gt;When the given problem is as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; x \in C \\\\
&amp;amp;&amp;amp;&amp;amp;x_j \in \mathbb{Z}, \quad j \in J \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f : \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\quad \text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;convex relaxation can be expressed as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp; f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; x \in C \\\\
\end{align}\)
\(\begin{align}
\text{where f is convex } f: \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \in \mathbb{R}^n 
\text{and} \quad J \in \lbrace 1 \dotsc n \rbrace \\
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;lagrangian-relaxations&quot;&gt;Lagrangian relaxations&lt;/h2&gt;
&lt;p&gt;\(X\)가 convex and, integer constraints를 모두 포함할 when,, as follows: problem를 정의 할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;Ax \leq b \\\\
&amp;amp;&amp;amp;&amp;amp; x_{j} \in \mathbb{Z} \quad x \in X 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이 when,, constraints를 objectiveto, 더하여, 어떤 \(u \geq 0\)to, about, Lagrangian relaxation을 하면, as follows:.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
L(u) = &amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) + u^{\top}(Ax-b) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;x \in X
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Lagrangian form을 through,서 constraint set이 확장되었고, feasible \(x\)about, \(Ax \leq b\)을 만족하므to,, always, \(f(x) + u^{\top}(Ax - b) \leq f(x), u \geq 0\)이 성립한다. therefore, \(L(u)\)는 임의의 \(u \geq 0\)about,서 lower bound이고, 최선의 lower bound는 dual problem \(\max_{u \geq 0} L(u)\)을 solution결함with,써 obtaining,낼 수 있다. \(L(u)\)는 convex function의 point-wise minimization이기 because of, concave optimization problem이 된다는 것을 기억하자.&lt;/p&gt;

&lt;p&gt;앞서 언급되었던 Facility location problemto, Lagrangian relaxation을 applying, 보면, unconstrained \(v\)about, 다음 식을 푸는 problemto, 변형된다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
L(u) = &amp;amp;\min_{x} &amp;amp;&amp;amp; \sum_{i = 1}^{n} f_{j}y_{j} + \sum_{i = 1}^{m}\sum_{j = 1}^{n}(c_{ij} - v_{i})x_{ij} + \sum_{i = 1}^{m} v_{i} \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; x_{ij} \leq y_{j} \quad i = 1 \dotsc m, \quad j = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp; x_{ij}, y_{j} \in \lbrace 0, 1 \rbrace \quad  i = 1 \dotsc m, \quad j = 1 \dotsc n 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;각각의 \(v\)about, Lagrange relaxation \(L(v)\)는 쉽게 풀릴 수 있다 :&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(x_{ij}(v) =\begin{cases}1 &amp;amp; \text{if} \quad c_{ij} - v_{i} &amp;lt; 0 \quad \text{and}  \quad \sum_{l} (c_{lj} - v_{l})^{-} + f_{j} &amp;lt; 0 \\\\
0 &amp;amp; \text{otherwise.} \end{cases}\)
\(y_{j}(v) =\begin{cases}1 &amp;amp; \text{if } \quad \sum_{l} (c_{lj} - v_{l})^{-} + f_{j} &amp;lt; 0 \\\\
0 &amp;amp; \text{otherwise.} \end{cases}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이는 lower bound \(L(v)\) and, heuristic primal solution을 도출 할 수 있도록 한다. also, \(-L(v)\)의 부분미분(subdifferential)을 사용한다면 computation도 쉬워진다. subgradient method를 using, \(\max_{v} L(v)\)를 \(\min_{v} -L(v)\) to, transformation시켜서 problem를 풀어갈 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>24-03 Solving integer programs</title>
   <link href="http://localhost:4000/contents/en/chapter24/24_03_Solving_integer_programs/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter24/24_03_Solving_integer_programs</id>
   <content type="html">&lt;p&gt;After transforming the mathematical formulation of Integer programming, techniques such as relaxation are needed to solve the problem. Let’s examine the constraints that appear in integer programs and what approaches are taken to address the problem.&lt;/p&gt;

&lt;h2 id=&quot;hardness-of-integer-programs&quot;&gt;Hardness of integer programs&lt;/h2&gt;
&lt;p&gt;Solving Integer program problems is much more difficult than solving convex optimization problems. General Integer programming is &lt;a href=&quot;https://en.wikipedia.org/wiki/NP-hardness&quot;&gt;NP-hard&lt;/a&gt;, requiring at least polynomial time without even knowing the possibility of solvability. In this case, by removing constraints on integer constraints and performing convex relaxation, we can obtain a lower bound that approaches the optimal value.&lt;br /&gt;&lt;br /&gt;
When solving problems using convex relaxation, the following limitations may occur:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Finding a feasible integer solution can become difficult.&lt;/li&gt;
  &lt;li&gt;The optimal solution obtained under relaxation conditions may be distant from the optimal solution obtained with integer programming.&lt;/li&gt;
  &lt;li&gt;The value after approximation (rounding) may differ from the optimal value.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;algorithmic-template-for-solving-integer-programs&quot;&gt;Algorithmic template for solving integer programs&lt;/h2&gt;
&lt;p&gt;When \(X\) is convex and includes integrality constraints, the integer program is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[z : = \min_{x \in X} f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Unlike convex optimization, there are no direct “optimality conditions” that prove a feasible point \(x* \in X\) is optimal. Instead, we can use a method that finds approximations of the optimal by finding lower bound \(\underline{z} \leq z\) and upper bound \(\bar{z} \geq z\) while approaching \(\underline{z} = \bar{z}\).&lt;/p&gt;

&lt;h3 id=&quot;algorithmic-template&quot;&gt;Algorithmic template&lt;/h3&gt;
&lt;p&gt;Observing the decreasing sequence of upper bounds,&lt;/p&gt;
&lt;blockquote&gt;
\[\bar{z_1} \geq \bar{z_2} \geq \dotsc \bar{z_s} \geq z\]
&lt;/blockquote&gt;

&lt;p&gt;Observing the increasing sequence of lower bounds,&lt;/p&gt;
&lt;blockquote&gt;
\[\underline{z_1} \leq \underline{z_2} \leq \dotsc \underline{z_t} \leq z\]
&lt;/blockquote&gt;

&lt;p&gt;For any \(\epsilon &amp;gt; 0\), the value of \(z\) is determined within the range where \(\bar{z_s} - \underline{z_t} \leq \epsilon\).&lt;/p&gt;

&lt;h3 id=&quot;primal-bounds&quot;&gt;Primal bounds&lt;/h3&gt;
&lt;p&gt;According to the previous \(z\) formula, for any feasible \(x \in X\), \(f(x) \geq z\) always holds, and in this case, \(f(x)\) is an upper bound. However, since we cannot always find a feasible \(x\), if the \(x\) value is included in the corresponding set, the problem can be solved easily, but this may not always be the case.&lt;/p&gt;

&lt;h3 id=&quot;dual-bounds&quot;&gt;Dual bounds&lt;/h3&gt;
&lt;p&gt;Usually also called lower bounds, their values are found through relaxation. Detailed explanations are added in the next section.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>24-02 Examples of integer programs</title>
   <link href="http://localhost:4000/contents/en/chapter24/24_02_Example_of_integer_programs/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter24/24_02_Example_of_integer_programs</id>
   <content type="html">&lt;p&gt;In this section, let’s examine various examples corresponding to Integer programming and learn how they are utilized.&lt;/p&gt;

&lt;h2 id=&quot;knapsack-problem&quot;&gt;Knapsack problem&lt;/h2&gt;
&lt;p&gt;The Knapsack problem is a traditional combinatorial optimization problem where the volume that can be put into the knapsack is limited, constraining the total magnitude of items that can fit inside the knapsack. When this constraint exists, the problem aims to select items with maximum value. This problem can be expressed using binary variables \(x\), where \(x_{j}\) takes a value of 0 or 1 depending on whether the \(j\)-th item is selected or not.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{x} &amp;amp;&amp;amp; c^\intercal x \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; a^\intercal x \leq b \\\\
&amp;amp;&amp;amp;&amp;amp;x_{j} \in {0, 1}, j = 1, \dotsc , n
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(c_{j}, a_{j}\) represent the value and magnitude (volume) of the \(j\)-th item, respectively.&lt;/p&gt;

&lt;h2 id=&quot;assignment-problem&quot;&gt;Assignment problem&lt;/h2&gt;
&lt;p&gt;Let’s assume there are \(n\) people and \(n\) tasks. Each person can be assigned to exactly one task. Here, \(c_{ij}\) represents the cost required for person \(i\) to perform task \(j\). The Assignment problem aims to assign \(n\) people to \(n\) tasks with the minimum cost. To optimize these conditions, the mathematical formulation is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;\sum_{i = 1}^{n} \sum_{j = 1}^{n} c_{ij} x_{ij} \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;\sum_{i = 1}^{n} x_{ij} = 1, j = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp;\sum_{j = 1}^{n} x_{ij} = 1, i = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp;x_{ij} \in \lbrace 0, 1\rbrace \quad i = 1 \dotsc n, \quad j = 1 \dotsc n
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;facility-location-problem&quot;&gt;Facility location problem&lt;/h2&gt;
&lt;p&gt;The Facility location problem aims to minimize transportation costs from specific facilities to customers.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Let’s assume there are depots \(N = \lbrace 1, \dotsc, n \rbrace\) and customers \(M = \lbrace 1, \dotsc, m \rbrace\).&lt;br /&gt;
The fixed cost \(f_{j}\) is associated with using depot \(j\).
The transportation cost \(c_{ij}\) is the cost incurred when goods delivered to customer \(i\) are transported from depot \(j\).&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The decisions to be made here are which depots should be operational and which customers should receive deliveries from each depot, with the goal of minimizing both fixed costs and transportation costs by deriving and solving the mathematical formulation.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y} &amp;amp;&amp;amp; \sum_{i = 1}^{n} f_{j} y_{j} + \sum_{i = 1}^{m} \sum_{j = 1}^{n} c_{ij} x_{ij} \\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; \sum_{j = 1}^{n} x_{ij} = 1,  \quad i = 1 \dotsc m \\
&amp;amp;&amp;amp;&amp;amp; x_{ij} \leq y_{j},  \quad i = 1 \dotsc m,  \quad j = 1 \dotsc n \\
&amp;amp;&amp;amp;&amp;amp; x_{ij} \in \lbrace 0, 1\rbrace \quad i = 1 \dotsc m, \quad j = 1 \dotsc n \\
&amp;amp;&amp;amp;&amp;amp; y_{j} \in \lbrace 0, 1\rbrace \quad j = 1 \dotsc n \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The first constraint means that each customer can receive goods from one depot. The second constraint states that depot \(j\) must be operational for customer \(i\) to receive goods from there. Since both \(x_{ij}\) and \(y_{j}\) are binary, we can consider \(mn\) constraints. This can also be expressed in a “marginalized” form as the following constraint:&lt;/p&gt;

&lt;blockquote&gt;
\[\sum_{i = 1}^{n} x_{ij} \leq m y_{j}, \quad j = 1 \dotsc n\]
&lt;/blockquote&gt;

&lt;p&gt;Reflecting this, it can be replaced with the following mathematical formulation:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y} &amp;amp;&amp;amp;\sum_{i = 1}^{n} f_{j} y_{j} + \sum_{i = 1}^{m} \sum_{j = 1}^{n} c_{ij} x_{ij} \\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;\sum_{j = 1}^{n} x_{ij} = 1,  \quad i = 1 \dotsc n \\
&amp;amp;&amp;amp;&amp;amp; \sum_{i = 1}^{n} x_{ij} \leq m y_{j}, \quad j = 1 \dotsc n \\
&amp;amp;&amp;amp;&amp;amp; x_{ij} \in \lbrace 0, 1\rbrace \quad i = 1 \dotsc n, \quad j = 1 \dotsc n \\
&amp;amp;&amp;amp;&amp;amp; y_{j} \in \lbrace 0, 1\rbrace \quad j = 1 \dotsc n \\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;k-means-and-k-medoids-clustering&quot;&gt;K-means and K-medoids clustering&lt;/h2&gt;
&lt;p&gt;Clustering is the process of dividing data into similar groups. The K-means algorithm aims to find K clusters by finding \(K\) center values (centroids) that minimize the average distance between data points within clusters. The goal is to find a partition \(S_{1} \cup \dotsc \cup S_{K} = \lbrace 1, \dotsc, n \rbrace\) for the given data. In this case, the following formula is minimized:&lt;/p&gt;

\[\sum_{i = 1}^{K} \sum_{j \in S_{i}} \| x^{(j)} - \mu^{(i)} \|^{2}\]

&lt;p&gt;where \(\mu^{(i)} :  = \frac{1}{| S_{i} |} \sum_{j \in S_{i}} x^{(i)}\),
\(\mu^{(i)}\) represents the centroid of cluster \(i\).&lt;/p&gt;

&lt;p&gt;A method that is more robust to outliers than computing centroids by averaging (K-means) is K-medoids clustering, which sets the center value as the data point closest to the cluster center instead of computing the center values of K clusters using arithmetic mean.
That is, K-medoids clustering is a method that considers each data point (\(y^{(i)}\)) as a center point and designates the data point that yields the minimum value when computed as the centroid.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\sum_{i = 1}^{K} \sum_{j \in S_{i}} \| x^{(j)} - y^{(i)} \|^{2}\)
\(\text{where } y^{(i)} \in \lbrace x^{(j)} : j \in S_{i} \rbrace\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;
This problem can be transformed and represented as an integer program.
First, we define \(d_{ij} = \| x^{(i)} - x^{(j)} \|^2\) and define the following two binary variables:&lt;/p&gt;

\[\begin{align}
&amp;amp;w_{i} =\begin{cases}1 &amp;amp;&amp;amp; \text{if choose } x^{(i)} \text{ as a centroid} \\\\
0 &amp;amp;&amp;amp; \text{otherwise.} \end{cases}\\\\
&amp;amp;z_{ji} =\begin{cases}1 &amp;amp;&amp;amp; \text{if } x^{(j)} \text{ in the cluster with centroid } x^{(i)} \\\\
0 &amp;amp;&amp;amp; \text{otherwise.} \end{cases}
\end{align}\]

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The K-medoids problem can be defined as an optimization problem as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{w, z} &amp;amp;&amp;amp; \sum_{i = 1}^{n} \sum_{j = 1}^{n} d_{ij} z_{ji} \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; z_{ji} \leq w_{i} \\\\
&amp;amp;&amp;amp;&amp;amp; \sum_{i = 1}^{n} w_{i} = k \\\\
&amp;amp;&amp;amp;&amp;amp; w_{ij} \in 0, 1 \quad i = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp; z_{ji} \in 0, 1 \quad j, i = 1 \dotsc n
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The first constraint means that after the centroid is first determined, we will determine whether $x_{j}$ belongs to $x_{i}$ or not.&lt;/p&gt;

&lt;h2 id=&quot;best-subset-selection&quot;&gt;Best subset selection&lt;/h2&gt;
&lt;p&gt;When the conditions \(X = [x^{1} \quad \dotsc \quad x^{p}] \in \mathbb{R}^{n×p}, \quad y \in \mathbb{R}^{n}\) are given, the Best subset selection problem is as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{\beta} &amp;amp;&amp;amp;\frac{1}{2} \| y - X\beta \|^{2} \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;\| \beta \| \leq k\\\\
\end{align}\)
\(\begin{align}
\text{where}  \| \beta \|_{0}  :  = \text{ the number of nonzero entries of } \beta.
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since \(\| \beta \|_{0}\) is a non-convex constraint, the problem can be solved more easily by transforming it using Integer programming.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{\beta, z} &amp;amp;&amp;amp; \frac{1}{2} \| y - X\beta \|^{2} \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; | \beta_{i} | \leq Mz_{i} \quad i = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp;z_{ji} \in \lbrace 0, 1 \rbrace \quad i = 1 \dotsc n \\\\
&amp;amp;&amp;amp;&amp;amp;\sum_{i = 1}^{p} z_{i} \leq k
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;least-median-of-squares-regression&quot;&gt;Least median of squares regression&lt;/h2&gt;
&lt;p&gt;When the conditions \(X = [x^{1} \quad \dotsc \quad x^{p}] \in \mathbb{R}^{n×p}, \quad y \in \mathbb{R}^{n}\), and \(\beta \in \mathbb{R}^{p}\) are given, if we define \(r : = y - X\beta\), the Least median of squares regression problem is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\beta_{LMS} : = \arg\min_{\beta} (median | r_{i} | ).\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>24-01 Definition</title>
   <link href="http://localhost:4000/contents/en/chapter24/24_01_Definition/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter24/24_01_Definition</id>
   <content type="html">&lt;p&gt;This section aims to explain the basic concepts for solving optimization problems through the mixed integer program approach.&lt;/p&gt;

&lt;h2 id=&quot;problem-definition&quot;&gt;Problem definition&lt;/h2&gt;
&lt;p&gt;When some variables in an optimization model have the constraint of being integers, this is called an integer program.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp; f(x) \\\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; x \in C \\\\
&amp;amp;&amp;amp;&amp;amp;x_{j} \in \mathbb{Z}, j \in J
\end{align}\)
\(\begin{align}
\text{where } f: \mathbb{R}^{n} \rightarrow \mathbb{R}, \quad C \subseteq \mathbb{R}^{n} \quad and \quad J \subseteq {1, \dotsc, n}. 
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the above expression, if \(J\) satisfies the following, it is called a pure integer program.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(J =\) { \(1, \dotsc, n\) }&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let us assume that both \(f\) and \(C\) discussed in this section are convex.&lt;/p&gt;

&lt;h2 id=&quot;binary-variables&quot;&gt;Binary variables&lt;/h2&gt;
&lt;p&gt;Looking at some representative examples of integer programs, we can mention yes/no decision problems or logical values.
In this case, we define the problem using binary variables and solve the problem to find values of 0 or 1 for the conditions.&lt;/p&gt;

&lt;p&gt;The combinatorial optimization to be introduced next is directly associated with integer programming. This is because by utilizing binary variables, we can transform existing problems and solve them as new problems.&lt;/p&gt;

&lt;p&gt;Combinatorial optimization problems are defined using the triple \((N, \mathcal{F}, c)\) representation.&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;\(\quad N\) is a finite ground set&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;\(\quad \mathcal{F} \subseteq 2^{N}\) is the set of feasible solutions&lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;\(\quad c \in \mathbb{R}^{N}\) is the cost function&lt;br /&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;The ultimate goal is to solve the following equation through the triple \((N, \mathcal{F}, c)\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\quad \min_{S \in \mathcal{F}} &amp;amp; \sum_{i \in S} c_{i} \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;많은 결sum optimization(combinatorial optimization) problem는 binary integer program들to, being used,질 수있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>23 Coordinate Descent</title>
   <link href="http://localhost:4000/contents/en/chapter23/23_Coordinate_Descent/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter23/23_Coordinate_Descent</id>
   <content type="html">&lt;p&gt;Coordinate descent is an optimization algorithm that iteratively moves along each coordinate axis to find the minimum of the objective function. At each iteration, according to a coordinate selection rule, it determines a coordinate axis (coordinate) or coordinate block, then minimizes the function along the direction of that axis while keeping the unselected coordinate axes or coordinate blocks fixed (exactly or inexactly). Coordinate descent can be utilized not only with gradient-based methods but also with gradient-free methods. Additionally, depending on the case, line search can be used to determine appropriate step sizes for each axis [16].&lt;/p&gt;

&lt;p&gt;Coordinate descent is very simple and easy to implement, and shows very good performance when carefully implemented for appropriate problems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt; lasso regression, lasso GLMs (under proximal Newton), SVMs, group lasso, graphical lasso (applied to the dual), additive modeling, matrix completion, regression with nonconvex penalties&lt;/p&gt;

&lt;h2 id=&quot;references-and-further-readings&quot;&gt;References and Further readings&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Early coordinate descent in optimization:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;D. Bertsekas and J. Tsitsiklis (1989), “Parallel and distributed domputation: numerical methods”&lt;/li&gt;
  &lt;li&gt;Z. Luo and P. Tseng (1992), “On the convergence of the coordinate descent method for convex differentiable minimization”&lt;/li&gt;
  &lt;li&gt;J. Ortega and W. Rheinboldt (1970), “Iterative solution of nonlinear equations in several variables”&lt;/li&gt;
  &lt;li&gt;P. Tseng (2001), “Convergence of a block coordinate descent method for nondifferentiable minimization”
35 Early coordinate descent references in statistics and ML:&lt;/li&gt;
  &lt;li&gt;I. Daubechies and M. Defrise and C. De Mol (2004), “An iterative thresholding algorithm for linear inverse problems with a sparsity constraint”&lt;/li&gt;
  &lt;li&gt;J. Friedman and T. Hastie and H. Hoefling and R. Tibshirani (2007), “Pathwise coordinate optimization”&lt;/li&gt;
  &lt;li&gt;W. Fu (1998), “Penalized regressions: the bridge versus the lasso”&lt;/li&gt;
  &lt;li&gt;T. Wu and K. Lange (2008), “Coordinate descent algorithms for lasso penalized regression”&lt;/li&gt;
  &lt;li&gt;A. van der Kooij (2007), “Prediction accuracy and stability of regresssion with optimal scaling transformations”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Coordinate descent의 응용:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;O. Banerjee and L. Ghaoui and A. d’Aspremont (2007), “Model selection through sparse maximum likelihood estimation”&lt;/li&gt;
  &lt;li&gt;J. Friedman and T. Hastie and R. Tibshirani (2007), “Sparse inverse covariance estimation with the graphical lasso”&lt;/li&gt;
  &lt;li&gt;J. Friedman and T. Hastie and R. Tibshirani (2009), “Regularization paths for generalized linear models via coordinate descent”&lt;/li&gt;
  &lt;li&gt;C.J. Hsiesh and K.W. Chang and C.J. Lin and S. Keerthi and S. Sundararajan (2008), “A dual coordinate descent method for large-scale linear SVM”&lt;/li&gt;
  &lt;li&gt;R. Mazumder and J. Friedman and T. Hastie (2011), “SparseNet: coordinate descent with non-convex penalties”&lt;/li&gt;
  &lt;li&gt;J. Platt (1998), “Sequential minimal optimization: a fast algorithm for training support vector machines”
37 Recent theory for coordinate descent:&lt;/li&gt;
  &lt;li&gt;A. Beck and L. Tetruashvili (2013), “On the convergence of block coordinate descent type methods”&lt;/li&gt;
  &lt;li&gt;Y. Nesterov (2010), “Efficiency of coordinate descent methods on huge-scale optimization problems”&lt;/li&gt;
  &lt;li&gt;J. Nutini, M. Schmidt, I. Laradji, M. Friedlander, H. Koepke (2015), “Coordinate descent converges faster with the Gauss- Southwell rule than random selection”&lt;/li&gt;
  &lt;li&gt;A. Ramdas (2014), “Rows vs columns for linear systems of equations—randomized Kaczmarz or coordinate descent?”&lt;/li&gt;
  &lt;li&gt;P. Richtarik and M. Takac (2011), “Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function”&lt;/li&gt;
  &lt;li&gt;A. Saha and A. Tewari (2013), “On the nonasymptotic convergence of cyclic coordinate descent methods”&lt;/li&gt;
  &lt;li&gt;S. Wright (2015), “Coordinate descent algorithms”
38 Screening rules and graphical lasso references:&lt;/li&gt;
  &lt;li&gt;L. El Ghaoui and V. Viallon and T. Rabbani (2010), “Safe feature elimination in sparse supervised learning”&lt;/li&gt;
  &lt;li&gt;R. Tibshirani, J. Bien, J. Friedman, T. Hastie, N. Simon, J. Taylor, and R. J. Tibshirani (2011), “Strong rules for discarding predictors in lasso-type problems”&lt;/li&gt;
  &lt;li&gt;R. Mazumder and T. Hastie (2011), “The graphical lasso: new insights and alternatives”&lt;/li&gt;
  &lt;li&gt;R. Mazumder and T. Hastie (2011), “Exact covariance thresholding into connected components for large-scale graphical lasso”&lt;/li&gt;
  &lt;li&gt;J. Wang, P. Wonka, and J. Ye (2015), “Lasso screening rules via dual polytope projection”&lt;/li&gt;
  &lt;li&gt;D. Witten and J. Friedman and N. Simon (2011), “New insights and faster computations for the graphical lasso”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Convergence analysis:&lt;/strong&gt;&lt;br /&gt;
Coordinate descent의 convergence analysisto, about, 연구 흐름을 간략히 소개하겠다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Convergence of coordinatewise minimization for solving linear systems, the Gauss-Seidel method, is a classic topic. E.g., see Golub and van Loan (1996), or Ramdas (2014) for a modern twist that looks at randomized coordinate descent&lt;/li&gt;
  &lt;li&gt;Nesterov (2010) considers randomized coordinate descent for smooth functions and shows that it achieves a rate O(1/ε) under a Lipschitz gradient condition, and a rate O(log(1/ε)) under strong convexity&lt;/li&gt;
  &lt;li&gt;Richtarik and Takac (2011) extend and simplify these results, considering smooth plus separable functions, where now each coordinate descent update applies a prox operation&lt;/li&gt;
  &lt;li&gt;Saha and Tewari (2013) consider minimizing l1 regularized functions of the form g(β) + λ∥β∥1, for smooth g, and study both cyclic coordinate descent and cyclic coordinatewise min. Under (very strange) conditions on g, they show both methods dominate proximal gradient descent in iteration progress&lt;/li&gt;
  &lt;li&gt;Beck and Tetruashvili (2013) study cyclic coordinate descent for smooth functions in general. They show that it achieves a rate O(1/ε) under a Lipschitz gradient condition, and a rate O(log(1/ε)) under strong convexity. They also extend these results to a constrained setting with projections&lt;/li&gt;
  &lt;li&gt;Nutini et al. (2015) analyze greedy coordinate descent (called Gauss-Southwell rule), and show it achieves a faster rate than randomized coordinate descent for certain problems&lt;/li&gt;
  &lt;li&gt;Wright (2015) provides some unification and a great summary. Also covers parallel versions (even asynchronous ones)&lt;/li&gt;
  &lt;li&gt;General theory is still not complete; still unanswered questions (e.g., are descent and minimization strategies the same?)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>23-04 Example: Pathwise coordinate descent for lasso</title>
   <link href="http://localhost:4000/contents/en/chapter23/23_04_Example_pathwise_coordinate/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter23/23_04_Example_pathwise_coordinate</id>
   <content type="html">&lt;p&gt;In this section, Pathwise coordinate descent for lassoto, about, 개요를 간단히 소개하도록 한다 [&lt;a href=&quot;https://arxiv.org/pdf/0708.1485.pdf&quot;&gt;Friedman et al. (2007)&lt;/a&gt;] [&lt;a href=&quot;https://www.jstatsoft.org/article/view/v033i01/v33i01.pdf&quot;&gt;Friedman et al. (2009)&lt;/a&gt;].&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Lasso regression problem:&lt;/strong&gt;
\(\min_{\beta} \frac{1}{2} \| y - X\beta \|_2^2 + \lambda \|\beta\|_1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;/contents/en/chapter07/07_03_03_example_lasso_optimality_condition/&quot;&gt;07-03-03 Example: Lasso Optimality Condition&lt;/a&gt;at, lasso regression problemto, about, optimality condition을 유도solution 보았다. 위 problemto, about, optimal solution는 다음의 condition,을 만족한다.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
X_1^T(y-X\beta) &amp;amp;= \lambda v_1\\
X_2^T(y-X\beta) &amp;amp;= \lambda v_2\\
\dots\\
X_p^T(y-X\beta) &amp;amp;= \lambda v_p
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;
\(X_i,i \in \{ 1,2,…,p \}\)는 주어진 matrix \(X\)의 \(i\)번째 열(column) 데이터를 의미한다.&lt;/p&gt;

&lt;p&gt;여기서 \(v=(v_1,v_2,\dots,v_p)\)는 \(\beta=(\beta_1,\beta_2,\dots,\beta_p )\)to, about, subgradient다.&lt;/p&gt;
&lt;blockquote&gt;

\[v_i, i \in \{1,2,\dots,p \} = 
\begin{cases}
\{ 1 \}  &amp;amp;\text{if $\beta_i &amp;gt; 0$} \\
\{-1 \}  &amp;amp;\text{if $\beta_i &amp;lt; 0$} \\
[-1,1]   &amp;amp;\text{if $\beta_i = 0$}
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;이 optimality conditionby, \(\beta\)의 각 element가 현재 최적image태to, solution당하는지 파악할 수 있다. Coordinate descent algorithm을 이용하면 아직 최적image태to, 도달하지 못한 element만을 업데이트하는 방식with, 좀 더 효율적with, lasso problem를 푸는 것이 가능solution진다. also, \(\lambda\)의 값이 클수록 lasso regression problemat, coordinate descent algorithm이 더 빨리 동작하는 경향성을 utilizing, \(\lambda\)를 점점 reducing,가는 방식(warm start)with, solutionto, 더욱 빠르게 접근한다.&lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;

&lt;h3 id=&quot;outer-loop-pathwise-strategy&quot;&gt;Outer loop (pathwise strategy):&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;\(\lambda_1 &amp;gt; \lambda_2 &amp;gt; \dots &amp;gt; \lambda_r\)의 순서를 따라 optimal solution를 computation한다.&lt;/li&gt;
  &lt;li&gt;Tuning parameter  \(\lambda_k\)at, computation된 result,를  \(\lambda_{k+1}\)to, about, coordinate descent algorithm을 초기화하는데 사용한다. (warm start)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;inner-loop-active-set-strategy&quot;&gt;Inner loop (active set strategy):&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;하나 or, 적은 수의 coordinate cycle을 시행한다. and, 0이 아닌 \(\beta\)의 element를 active set \(A\)to, 기록한다.&lt;/li&gt;
  &lt;li&gt;\(A\)to, 기록된 element들about,서만 convergence할 when,to, coordinate cycle을 시행한다.&lt;/li&gt;
  &lt;li&gt;\(\beta\)의 모든 element들about, optimality condition을 확인한다. condition,을 만족하지 않는 element가 있으면 \(A\)to, 추가하고 step 1with, 다시 돌아간다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;통image적with, pathwise strategy는 problemat, 주어진 \(\lambda\)to, about, solution를 바to, 구하는 것보다 훨씬 효율적with, 동작한다.&lt;/li&gt;
  &lt;li&gt;Active set strategy는 sparsityabout, 이점이 있다. 이 because of, coordinate descent는 ridge regression보다 lasso regressionat, 훨씬 더 빠르게 동작한다. (reference: &lt;a href=&quot;https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/&quot;&gt;ridge regressionand, lasso regression의 경향성 분석&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Pathwise coordinate descent for lasso는 lasso regression problemabout, 가장 빠르다고 informing,진 다른 algorithm들to, 비견될만큼 빠르게 동작한다.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>23-03 Example: lasso regression</title>
   <link href="http://localhost:4000/contents/en/chapter23/23_03_Example_lasso_regression/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter23/23_03_Example_lasso_regression</id>
   <content type="html">&lt;p&gt;Lasso regression problem를 아래and, 같이 nonsmooth part가 분리되어있는 objective function의 형태to, 정by,보겠다.&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{\beta} \frac{1}{2} \| y - X\beta \|_2^2 + \lambda \|\beta\|_1\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt;
\(\|\beta\|_1 = \sum_{i=1}^p | \beta_i |\)&lt;/p&gt;

&lt;p&gt;\(\beta_j, j \neq i\) 가 고정된 값일when,, 주어진 objective function를 minimization시키는 \(\beta_i\)를 let’s find.&lt;/p&gt;

\[\begin{align}
&amp;amp;0 = \nabla_i f(\beta) = X_i^T X_i \beta_i + X_i^T(X_{-i} \beta_{-i} - y) + \lambda s_i,\\\\
&amp;amp;\text{where } s_i \in \partial |\beta_i|
\Rightarrow 
\beta_i = S_{\lambda / \|X_i\|_2^2} \big( \frac{X_i^T(y-X_{-i} \beta_{-i})}{X_i^TX_i} \big)
\end{align}\]

&lt;p&gt;Solution은 thresholding level이 \(\lambda / \|X_i\|_2^2\)인 soft-thresholding functionand,도 같다. Coordinate descent를 through, \(\beta_i\) for \(i=1,2,\dots,p,1,2,\dots\)를 iteration하며 업데이트 한다.&lt;/p&gt;

&lt;h2 id=&quot;실험-convergence속도-비교---pg-vs-agd-vs-cd&quot;&gt;실험: convergence속도 비교 - PG vs AGD vs CD&lt;/h2&gt;

&lt;p&gt;아래 그래프는 \(n=100, p=20\)인 lasso regression problemabout, proximal gradient descent, accelerated gradient descent, coordinate descent의 convergence속도를 comparing, showing,준다. (가to,axis의 k는 한 step (PD, AGD) or, 한 cycle (CD)을 나타낸다.)&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter23/pd_vs_agd_vs_cd.png&quot; alt=&quot;[Fig1] PD vs AGD vs CD [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] PD vs AGD vs CD [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/contents/en/chapter23/23_02_Example_linear_regression/&quot;&gt;Linear regression의 예시&lt;/a&gt;at,and, 마찬가지to, lasso regression problemat,도 coordinate descent는 월등한 convergence속도를 보인다. (First-order method보다 더 많은 정보를 활용한다.)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; 위 실험at,의 모든 methods는 각 iteration당 \(O(np)\) flops의 시간복잡도를 보인다.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>23-02 Example: linear regression</title>
   <link href="http://localhost:4000/contents/en/chapter23/23_02_Example_linear_regression/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter23/23_02_Example_linear_regression</id>
   <content type="html">&lt;p&gt;Let’s define the linear regression problem as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\min_{\beta} \frac{1}{2} \| y - X\beta \|_2^2,\)
\(\text{given } y \in \mathbb{R}^n \text{ and } X \in \mathbb{R}^{n \times p} \text{ with columns } X_1, \dots, X_p.\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When \(\beta_j,\: j \neq i\) are fixed values, let’s find \(\beta_i\) that minimizes the given objective function.
(\(-i\) means the remaining terms excluding \(i\). - In the case of \(X\), the remaining columns excluding the \(i\)-th column.)&lt;/p&gt;

\[\begin{align}
0 &amp;amp;= \nabla_i f(\beta)\\\\
&amp;amp;= X_i^T (X\beta - y)\\\\
&amp;amp;= X_i^T (X_i \beta_i + X_{-i} \beta_{-i} - y)\\\\
\Rightarrow\\\\
&amp;amp;\beta_i = \frac{X_i^T (y - X_{-i} \beta_{-i})}{X_i^T X_i}
\end{align}\]

&lt;p&gt;Through coordinate descent, we iterate and update \(\beta_i\) for \(i=1,2,\dots,p,1,2,\dots\).&lt;/p&gt;

&lt;h2 id=&quot;experiment-convergence-speed-comparison---gd-vs-agd-vs-cd&quot;&gt;Experiment: Convergence speed comparison - GD vs AGD vs CD&lt;/h2&gt;

&lt;p&gt;The graph below shows the convergence speeds of coordinate descent, gradient descent, and accelerated gradient descent for a linear regression problem with \(n=100, p=20\). (The k on the horizontal axis represents one step (GD, AGD) or one cycle (CD).)&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter23/gd_vs_agd_vs_cd.png&quot; alt=&quot;[Fig1] GD vs AGD vs CD [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] GD vs AGD vs CD [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;According to the above results, coordinate descent shows significantly better convergence speed than AGD, which is optimal among first-order methods. Why can this phenomenon occur? To conclude, coordinate descent can achieve performance that far surpasses AGD because it utilizes more information than first-order methods. This is because coordinate descent uses the latest information updated in the previous step at each step within one cycle. (That is, CD is not a first-order method.)&lt;/p&gt;

&lt;h3 id=&quot;q-then-is-it-fair-to-compare-one-cycle-of-cd-with-one-step-of-gd-in-the-above-experiment&quot;&gt;Q. Then, is it fair to compare one cycle of CD with one step of GD in the above experiment?&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;A. Yes.&lt;/strong&gt; The CD update formula introduced earlier can be modified to have a time complexity of \(O(n)\) per step. Then, the time complexity of one cycle for CD becomes \(O(np)\), which has the same time complexity as one step of GD.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Gradient descent update:&lt;/strong&gt; \(\beta \leftarrow \beta + tX^T(y-X\beta)\), the time complexity of the \(X\beta\) operation becomes \(O(np)\) flops.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>23-01 Coordinate Descent</title>
   <link href="http://localhost:4000/contents/en/chapter23/23_01_Coordinate_descent/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter23/23_01_Coordinate_descent</id>
   <content type="html">&lt;p&gt;In this chapter, we introduce a method called coordinate descent that is extremely simple, efficient, and highly scalable. First, let’s start with some simple questions and answers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q1. When function \(f: \mathbb{R}^n \rightarrow \mathbb{R}\) is convex and differentiable, if the point where \(f\) is minimized along each coordinate axis is \(x\), is this \(x\) a global minimizer?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A1: Yes. Since \(\nabla f(x) = 0\), \(x\) is a global minimizer of \(f\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The above question is equivalent to asking whether \(f(x + \delta e_i) \ge f(x)\) is satisfied for all \(\delta, i\) when \(e_i = (0, \dots, 1, \dots, 0) \in \mathbb{R}^n\) is the \(i\)-th standard basis vector. That is, since we cannot make \(f\) smaller by moving in any coordinate axis direction from \(x\), the partial derivatives in all axis directions become 0.&lt;/p&gt;

\[\nabla f(x) = \big( \frac{\partial f}{\partial x_1}(x), \dots, \frac{\partial f}{\partial x_n}(x) \big) = (0, \dots, 0) = 0\]

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter23/smooth_function.png&quot; alt=&quot;[Fig1] Smooth convex function f [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$[Fig1] \; Smooth \; convex \; function \; f \; [3]$$ &lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q2. Then, when \(f: \mathbb{R}^n \rightarrow \mathbb{R}\) is convex but ‘non-differentiable’ function, is the point \(x\) where \(f\) is minimized along each coordinate axis always a global minimizer?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A2: No. In this case, we cannot assert that \(x\) is a global minimizer of \(f\). (Counterexample: Fig2 below)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Looking at the contour lines on the right side of the counterexample below, we can see that although the marked point is not the global minimum, \(f\) cannot be made smaller by moving in any coordinate axis direction. (To make \(f\) smaller, one must be able to move inside the contour lines.) This is because at this position, all inner regions of the contour lines are contained within the two tangent lines parallel to the coordinate axes. On the other hand, when \(f\) is a differentiable convex function, only one tangent line exists at any point on the contour lines, so this phenomenon does not occur.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter23/non-smooth_function.png&quot; alt=&quot;[Fig2] Counterexample: Non-smooth convex function f [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$[Fig2] \; Counterexample: Non \, smooth \; convex \; function \; f \; [3]$$ &lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q3. When \(f\) can be expressed as the sum of a differentiable convex function \(g\) and a convex function \(h\), is the point \(x\) where \(f\) is minimized along each coordinate axis always a global minimizer? (That is, \(f(x) = g(x) + \sum_{i=1}^{n} h_i(x_i)\))&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A3. Yes. This is because it satisfies the following for any \(y\).&lt;/strong&gt;
\(\begin{align}
f(y) - f(x) &amp;amp;\ge \nabla g(x)^T (y-x) + \sum_{i=1}^{n} \big[ h_i(y_i) - h_i(x_i) \big] \\\\
&amp;amp;= \sum_{i=1}^{n} \big[ \underbrace{\nabla_i g(x) (y_i - x_i) + h_i(y_i) - h_i(x_i)}_{\ge 0} \big] \ge 0
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof:&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Let \(F_i(x_i) = g(x_i ; x_{-i}) + h_i(x_i)\). (\(g(x_i ; x_{-i})\) means viewing only the \(i\)-th element of \(x\) as a variable, and the rest as fixed values.)&lt;/p&gt;

\[\begin{align}
&amp;amp; \: 0 \in \partial F_i (x_i) \\\\
\Leftrightarrow &amp;amp; \: 0 \in \{ \nabla_i g(x) \} + \partial h_i(x_i)\\\\
\Leftrightarrow &amp;amp; \: - \nabla_i g(x) \in \partial h_i(x\_i)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;By the &lt;a href=&quot;/contents/en/chapter07/07_01_subgradient/&quot;&gt;definition of subgradient&lt;/a&gt;,&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; h_i(y_i) \ge h_i(x_i) - \nabla_i g(x) (y_i - x_i)\\\\
\Leftrightarrow &amp;amp; \nabla_i g(x) (y_i - x_i) + h_i(y_i) - h_i(x_i) \ge 0.
\end{align}\]
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter23/separable_non-smooth.png&quot; alt=&quot;[Fig3] Convex function f with separable non-smooth parts [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$[Fig3] \; Convex \; function \; f \; with \; separable \; non \,smooth \; parts \; [3]$$ &lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The minimizer of \(f(x) = g(x) + \sum_{i=1}^{n} h_i(x_i)\) with \(g\) convex, differentiable and \(h_i\) convex can be found using &lt;strong&gt;coordinate descent&lt;/strong&gt;. Coordinate descent iterates the following cycle. (Assume that an appropriate initial value \(x^{(0)}\) is set.)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Coordinate Descent:&lt;/strong&gt; &lt;br /&gt;
\(\:\) For \(k = 1,2,3,\dots\),&lt;/p&gt;

\[\begin{align}
x_1^{(k)} &amp;amp;\in \text{arg}\min_{x_1} \: f(x_1, x_2^{(k-1)}, x_3^{(k-1)}, \dots, x_n^{(k-1)})\\\\
x_2^{(k)} &amp;amp;\in \text{arg}\min_{x_2} \: f(x_1^{(k)}, x_2, x_3^{(k-1)}, \dots, x_n^{(k-1)})\\\\
x_3^{(k)} &amp;amp;\in \text{arg}\min_{x_3} \: f(x_1^{(k)}, x_2^{(k)}, x_3, \dots, x_n^{(k-1)})\\\\
&amp;amp; \dots\\\\
x_n^{(k)} &amp;amp;\in \text{arg}\min_{x_n} \: f(x_1^{(k)}, x_2^{(k)}, x_3^{(k)}, \dots, x_n)
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;notes&quot;&gt;Notes:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The process of obtaining \(x_{i+1}^{(k)}, \dots, x_{n}^{(k)}\) uses the newly obtained \(x_i^{(k)}\) in the \(k\)-th cycle.&lt;/li&gt;
  &lt;li&gt;The order of coordinate axes in the cycle can be arbitrarily specified.&lt;/li&gt;
  &lt;li&gt;Two or more coordinate axes can be grouped together and processed as blocks.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The coordinate descent introduced above corresponds to exact coordinatewise minimization. Another approach is inexact coordinatewise minimization using gradients. (Assuming \(f\) is a differentiable convex function)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Coordinate Descent (inexact coordinatewise minimization):&lt;/strong&gt; &lt;br /&gt;
\(\:\) For \(k = 1,2,3,\dots\),&lt;/p&gt;

\[\begin{align}
x_1^{(k)} &amp;amp;= x_1^{(k-1)} - t_{k,1} \cdot \nabla_1 f(x_1^{(k-1)}, x_2^{(k-1)}, x_3^{(k-1)}, \dots, x_n^{(k-1)})\\\\
x_2^{(k)} &amp;amp;= x_2^{(k-1)} - t_{k,2} \cdot \nabla_2 f(x_1^{(k)}, x_2^{(k-1)}, x_3^{(k-1)}, \dots, x_n^{(k-1)})\\\\
x_3^{(k)} &amp;amp;= x_3^{(k-1)} - t_{k,3} \cdot \nabla_3 f(x_1^{(k)}, x_2^{(k)}, x_3^{(k-1)}, \dots, x_n^{(k-1)})\\\\
&amp;amp; \dots\\\\
x_n^{(k)} &amp;amp;= x_n^{(k-1)} - t_{k,n} \cdot \nabla_n f(x_1^{(k)}, x_2^{(k)}, x_3^{(k)}, \dots, x_n^{(k-1)})
\end{align}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>22 Conditional Gradient (Frank-Wolfe) Method</title>
   <link href="http://localhost:4000/contents/en/chapter22/22_Conditional_Gradient_Method/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter22/22_Conditional_Gradient_Method</id>
   <content type="html">&lt;p&gt;This chapter will examine the Frank-Wolfe algorithm proposed by Marguerite Frank and Philip Wolfe in 1956.&lt;/p&gt;

&lt;p&gt;The Frank-Wolfe algorithm is an iterative first-order optimization algorithm for constrained convex optimization, also called the conditional gradient method, reduced gradient method, and convex combination algorithm.&lt;/p&gt;

&lt;p&gt;This method was originally proposed by Marguerite Frank and Philip Wolfe in 1956. The Frank-Wolfe algorithm considers a linear approximation of the objective function at each iteration and moves toward the minimizer of this linear function.&lt;/p&gt;

&lt;p&gt;[15] Wikipedia. &lt;a href=&quot;https://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe_algorithm&quot;&gt;Frank–Wolfe algorithm&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>22-04 Properties and variants</title>
   <link href="http://localhost:4000/contents/en/chapter22/22_04_Properties_and_variants/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter22/22_04_Properties_and_variants</id>
   <content type="html">&lt;h2 id=&quot;some-variants&quot;&gt;Some variants&lt;/h2&gt;
&lt;p&gt;Let’s look at some variant conditional gradient methods:&lt;br /&gt;
• &lt;strong&gt;Line search&lt;/strong&gt;: Instead of fixing \(γk=2/(k+1),k=1,2,3,...\), we use exact line search for the step size at each \(k = 1, 2, 3, . . .\).&lt;/p&gt;
&lt;blockquote&gt;
\[γ_k = \arg\min_{γ∈[0,1]} f\Bigl( x^{(k−1)} + γ\bigl(s^{(k−1)} − x^{(k−1)} \bigr) \Bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;Backtracking can also be used.&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;Fully corrective&lt;/strong&gt;: Direct update according to the following equation.&lt;/p&gt;
&lt;blockquote&gt;
\[x^{(k)} = \arg\min_y f(y) \: \text{ subject to } y ∈ conv\{ x^{(0)}, s^{(0)}, . . . s^{(k−1)} \}\]
&lt;/blockquote&gt;

&lt;p&gt;This method can achieve much better progress, but the cost is high.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter22/away_steps.png&quot; alt=&quot;[Fig 3] Away step motivation [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 3] Away step motivation [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;another-variant-away-steps&quot;&gt;Another variant: away steps&lt;/h2&gt;
&lt;p&gt;For a faster solution, let’s look at the minimization problem in [Fig 3]. Here, the optimal solution is (0,0). The conditional descent method becomes difficult to move from the initial point (0,1). However, due to away step movement, conditional gradient descent not only moves to promising points but also moves away from unpromising points.&lt;/p&gt;

&lt;p&gt;Let’s assume a convex hull \(C = conv(A)\) for atoms set \(A\)&lt;/p&gt;

&lt;p&gt;We can explicitly represent \(x∈C\) as a convex combination of elements belonging to \(A\).&lt;/p&gt;
&lt;blockquote&gt;
\[x = \sum_{a∈A} λ_a(x)a\]
&lt;/blockquote&gt;

&lt;p&gt;Conditional gradient with away steps: &lt;br /&gt;
\(\text{1. choose } x^{(0)} = a^{(0)} ∈ A\) &lt;br /&gt;
\(\text{2. for } k = 1, 2, 3, . . .\) &lt;br /&gt;
\(\qquad s^{(k−1)} ∈ \arg\min_{a∈A} ∇f(x^{(k−1)})^Ta,\)
\(\qquad a^{(k−1)} ∈ \arg\max_{a∈A, λa(x(k−1))&amp;gt;0} ∇f(x^{(k−1)})^Ta\)
\(\qquad \text{choose } v = s^{(k−1)} − x^{(k−1)} or \quad v = x^{(k−1)} − a^{(k−1)}\)
\(\qquad x^{(k)} = x^{(k−1)} + γ_kv\) &lt;br /&gt;
\(\text{3. end for}\)&lt;/p&gt;

&lt;h2 id=&quot;linear-convergence&quot;&gt;Linear convergence&lt;/h2&gt;
&lt;p&gt;Let’s consider the following unconstrained problem.&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) \: \text{ subject to } x ∈ \mathbb{R}^n\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(f\) is µ-strongly convex and \(∇f\) is L-Lipschitz.&lt;/p&gt;

&lt;p&gt;By iterating gradient descent \(x^{(k+1)} = x^{(k)} − t_k∇f(x^{(k)})\) with \(t_k = 1/L\), the following is satisfied.&lt;/p&gt;
&lt;blockquote&gt;
\[f(x^{(k)}) − f^{\star} ≤ \Bigl( 1 −\frac{µ}{L} \Bigr)^k \bigl( f(x^{(0)}) − f^{\star} \bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;Now let’s also consider the following constrained problem.&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) \: \text{ subject to } x ∈ conv(A) ⊆ \mathbb{R}^n\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;theorem-lacoste-julien--jaggi-2013&quot;&gt;[Theorem (Lacoste-Julien &amp;amp; Jaggi 2013)]&lt;/h3&gt;
&lt;p&gt;Assume that \(f\) is µ-strongly convex, \(∇f\) is L-Lipschitz, and \(A ⊆ \mathbb{R}^n\) is finite.&lt;/p&gt;

&lt;p&gt;With appropriate \(γ_k\), the iteration steps generated by the conditional gradient algorithm always satisfy the following.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x^{(k)}) − f^{\star} ≤ (1 − r)^{k/2}(f(x^{(0)}) − f^{\star}) \text { for } r = \frac{µ}{L}·\frac{Φ(A)^2}{4\text{diam}(A)^2}\)
\(\text{where }Φ(A) = \min_{F ∈faces(conv(A))} dist(F, conv(A \ F))\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If the polytope is planar, \(Φ\) is small and the algorithm converges slowly.&lt;/p&gt;

&lt;h2 id=&quot;path-following&quot;&gt;Path following&lt;/h2&gt;
&lt;p&gt;Let’s look at the following given norm constrained problem&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) \: \text{ subject to } \| x \| ≤ t\]
&lt;/blockquote&gt;

&lt;p&gt;The Frank-Wolfe algorithm can be used for &lt;strong&gt;path following&lt;/strong&gt;. In other words, it means that it can generate a (approximate) solution path \(\hat{x}(t), t ≥ 0\).&lt;/p&gt;

&lt;p&gt;Starting with \(t_0 = 0\) and \(x^{\star}(0) = 0\), fix parameters \(\epsilon, m &amp;gt; 0\) and then iterate for \(k=1,2,3,...\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Compute \(t_k = t_{k−1} + \frac{(1 − 1/m)\epsilon}{\| ∇f(\hat{x}(t_k−1))\|\_{∗}}\) and set \(\hat{x}(t) = \hat{x}(t_{k−1})\) for all \(t ∈ (t_{k−1}, t_k)\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;At \(t = t_k\), execute Frank-Wolfe to compute \(\hat{x}(t_k)\) and terminate when the duality gap is \(≤ \frac{\epsilon}{m}\).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is a method that simplifies existing strategies. [Giesen et al. (2012)]&lt;/p&gt;

&lt;p&gt;Through this &lt;strong&gt;path following&lt;/strong&gt; strategy, we can guarantee the following for all visited $t$:&lt;/p&gt;
&lt;blockquote&gt;
\[f(\hat{x}(t)) − f(x^{\star}(t)) ≤ \epsilon\]
&lt;/blockquote&gt;

&lt;p&gt;That is, it generates a case of suboptimality gap that is uniformly bounded by \(\epsilon\) for all \(t\).&lt;/p&gt;

&lt;p&gt;As shown in the equation below, the Frank-Wolfe duality gap can be redefined as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[g_t(x) = \max_{\|s\|≤1} ∇f(x)^T(x − s) = ∇f(x)^Tx + t\|∇f(x)\|_{∗}\]
&lt;/blockquote&gt;

&lt;p&gt;This is a linear function with respect to $t$. Therefore, if \(g_t(x) ≤ \frac{\epsilon}{m}\), we can increase \(t\) to \(t^+ = t + (1 − 1/m)\epsilon/\|∇f(x)\|_{∗}\) using the following equation.&lt;/p&gt;

&lt;blockquote&gt;
\[g_t+ (x) = ∇f(x)^Tx + t\|∇f(x)\|_{∗} + \epsilon − \epsilon/m ≤ \epsilon\]
&lt;/blockquote&gt;

&lt;p&gt;That is, the duality gap is maintained at \(≤ \epsilon\) between \(t\) and \(t^+\) for the same \(x\).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>22-03 Convergence analysis</title>
   <link href="http://localhost:4000/contents/en/chapter22/22_03_Convergence_analysis/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter22/22_03_Convergence_analysis</id>
   <content type="html">&lt;h2 id=&quot;convergence-analysis&quot;&gt;Convergence analysis&lt;/h2&gt;
&lt;p&gt;To find out the convergence characteristics of the Frank-Wolfe method, it is necessary to define the curvature constant of \(f\) for \(C\) as follows. [Jaggi (2011)]&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(M = \max_{x,s,y∈C, y = (1−γ)x+γs} \frac{2}{γ^2} \Bigl( f(y) − f(x) − ∇f(x)^T(y − x) \Bigr)\)
\(γ ∈ [0, 1]\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;M을 through,서 actually, function가 선형 approximation(linear approximation)from, 얼마나 먼 경향을 가지고 있는지를 측정할 수도 있다.
여기서 \(M = 0\)은 \(f\)가 선형임을 나타낸다. \(f (y) - f (x) - ∇f (x)^T(y - x)\)는 \(f\)by, 정의 된 Bregman divergence 라 부른다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theorem: 고정 스텝 사이즈 \(γk = 2 / (k + 1), k = 1,2,3, ...\)를 이용한 condition,부 그레디언드 method(conditional gradient method)은 다음을 만족한다.
 \(f(x^{(k)}) − f^{\star} ≤ \frac{2M}{k + 2}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;\(f(x^{(k)}) − f^{\star} ≤ \epsilon\)를 만족하기 for, 필요한 iteration 횟수는 \(O(1/\epsilon)\)이다.&lt;/p&gt;

&lt;p&gt;이제 이 이론은 귀납법with, proving,보고자 한다. however, 바to, 증명with, 넘어가기전 짚고 넘어가야 할 개념을 하나 소개하고자 한다.&lt;/p&gt;

&lt;h2 id=&quot;basic-inequality&quot;&gt;Basic inequality&lt;/h2&gt;
&lt;p&gt;Frank-Wolfe convergence 속도를 증명하는 데 사용되는 &lt;strong&gt;key inequality&lt;/strong&gt;는 as follows:.&lt;/p&gt;
&lt;blockquote&gt;
\[f(x^{(k)}) ≤  f(x^{(k−1)}) − γ_kg(x^{(k−1)}) + \frac{γ^2_k}{2}M\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(g(x) = \max_{s∈C} ∇f(x)^T(x − s)\)는 앞서 논의한 duality gap 을 의미하며, 귀납법according to, 이 비율은  inequality를 따르게 된다.&lt;/p&gt;

&lt;h3 id=&quot;proof&quot;&gt;[Proof]&lt;/h3&gt;
&lt;p&gt;Basic inequality를 증명하기 for, \(x^+ = x^{(k)}, x = x^{(k−1)}, s = s^{(k−1)}, γ = γ_k\) 를 지정한다. and, as follows: 정리한다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^+) &amp;amp;= f\bigl( x + γ(s − x) \bigr) \\\
&amp;amp;≤ f(x) + γ∇f(x)^T(s − x) + \frac{γ^2}{2}M \\\
&amp;amp;= f(x) − γg(x) + \frac{γ^2}{2}M
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;위 수식at, 두 번째 줄은 \(M\)의 정의를 사용했고, 세 번째 줄은 \(g\)의 정의를 사용하였다.&lt;/p&gt;

&lt;p&gt;이제, basic inequality를 using,, 우리는 convergence rate theorem을 증명하기 for, 귀납법을 사용한다.&lt;/p&gt;

&lt;p&gt;\(k=1\)의 case,, theorem이 만족함을 쉽게 확인할 수 있다.
and, 임의의 \(k &amp;gt; 1\)일 case,, \(f(x^{(k−1)}) − f^{\star} ≤ 2M/(k + 1)\)를 만족함을 가정한다.&lt;/p&gt;

&lt;p&gt;앞서 언급한 duality gap \(g(x)\)를 다시 떠올려 보자.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(g(x^{(k−1)}) ≤ f(x^{(k−1)}) − f^{\star}\)
\(γ_k = 2/(k + 1)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and, 이제 basic inequalityto, applying, 보자.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x^{(k)}) ≤ f(x^{(k−1)}) − 2(f(x^{(k−1)}) − f^{\star})/(k + 1) + 4M/2(k + 1)^2\)
\(f(x^{(k)}) − f^{\star} ≤ (1 − 2/(k + 1))(f(x^{(k−1)}) − f^{\star}) + 2M/(k + 1)^2\)
\(f(x^{(k)}) − f^{\star} ≤ (k − 1/k + 1) × 2M/(k + 1) + 2M/(k + 1)^2 ≤ 2M/(k + 2)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 증명 된 convergence 속도는 ∇f가 립시츠 (Lipschitz) 일 when, projected gradient descent의 informing,진 속helping, 일치한다.&lt;/p&gt;

&lt;p&gt;이제 이 가정 들을 comparing, 보자.
in fact, if, \(∇f\)가 constant \(L\)을 가지는 Lipschitz라면 \(diam^2(C) = max_{x,s∈C} ||x − s||^2\)일 when, \(M ≤ diam^2(C) · L\)이다.&lt;/p&gt;

&lt;p&gt;이를 확인하기 for, constant \(L\)을 가지는 \(∇f\) Lipschitz 아래and, 같다는 것을 image기할 필요가 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[f(y) − f(x) − ∇f(x)^T(y − x) ≤ \frac{L}{2} \| y − x \|^2_2\]
&lt;/blockquote&gt;

&lt;p&gt;모든 \(y = (1-γ) x + γs\)를 maximizing, \(\frac{2}{γ^2}\)를 product하면 as follows:.&lt;/p&gt;
&lt;blockquote&gt;
\[M ≤ \max_{x,s,y∈C, y=(1−γ)x+γs} \frac{2}{γ^2}·\frac{L}{2} \| y − x \|^2_2 = \max_{x,s∈C} L \| x − s \|^2_2\]
&lt;/blockquote&gt;

&lt;p&gt;M의 경계가 결정되었다. 기본적with, 경계가 있는 곡률이 proximal gradientabout, 가정한 곡률보다 크지 않다고 가정한다.&lt;/p&gt;

&lt;h2 id=&quot;affine-invariance&quot;&gt;Affine invariance&lt;/h2&gt;
&lt;p&gt;앞서 배운 개념들을 다시 생각solution 보자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Gradient Descent: \(x^+ = x − t∇f(x)\)&lt;/li&gt;
  &lt;li&gt;Pure Newton’s Method: \(x^+ = x − ∇^2f(x)^{−1}∇f(x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Gradient descent는 affine invariant하지 않다. that is,, coordinate들을 스케일링 함with, gradient descent의 성능은 향image 된다. 반면, Newton’s method는 affine invariant하다. that is,, 이 algorithm은 variable의 모든 affine transformationat, 동일하게 동작한다.&lt;/p&gt;

&lt;p&gt;and, Conditional gradient method는 gradient descentand, 비슷but, affine invariant 하다.&lt;/p&gt;

&lt;p&gt;Frank-Wolfe의 중요한 속성 : 업데이트는 &lt;strong&gt;affine invariant&lt;/strong&gt; 하다.
Nonsingular \(A : \mathbb{R}^n → \mathbb{R}^n\)가 주어지면, \(x = Ax&apos;, h(x&apos;) = f(Ax&apos;)\)를 정의할 수 있다.
그러면 \(h(x&apos;)\)at,의 Frank-Wolfe는 아래and, 같이 computation 가능하다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{array}{rcl}
s&apos; &amp;amp; = &amp;amp; \arg\min_{z∈A^{−1}C} ∇h(x&apos;)^Tz \\\
(x&apos;)^+ &amp;amp; = &amp;amp; (1 − γ)x&apos; + γs&apos;
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;\(A\)to, product하면 \(f (x)\)at, 수행되는 것and, 동일한 Frank-Wolfe 업데이트가 나타난다.
심지어 convergence analysis은 affine invariant이다.&lt;/p&gt;

&lt;p&gt;\(h\)의 곡률 constant \(M\)은 as follows:.&lt;/p&gt;
&lt;blockquote&gt;
\[M = \max_{x&apos;,s&apos;,y&apos;∈A^{−1}C, y&apos;=(1−γ)x&apos;+γs&apos;} \frac{2}{γ^2} \Bigl( h(y&apos;) − h(x&apos;) − ∇h(x&apos;)^T(y&apos; − x&apos;) \Bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;\(∇h(x&apos;)T(y&apos; − x&apos;) = ∇f(x)^T(y − x)\)이기 because of, \(f\)and, 일치한다.&lt;/p&gt;

&lt;p&gt;however,, affine invariance는 M의 경계at, 직관적이지 않다.&lt;/p&gt;

&lt;blockquote&gt;
\[M ≤ \max_{x,s∈C} L||x − s||^2_2\]
&lt;/blockquote&gt;

&lt;p&gt;주어진 C의 diameter이  affine invariance이 아니라면, 이것은 고민solution 볼 가치가 있다.&lt;/p&gt;

&lt;h2 id=&quot;inexact-updates&quot;&gt;Inexact updates&lt;/h2&gt;
&lt;p&gt;정확하지 않은 Frank-Wolfe 업데이트를 분석하였다.[Jaggi (2011)]&amp;lt;/br&amp;gt;
\(s^{(k−1)}\)를 선택한다.&lt;/p&gt;
&lt;blockquote&gt;
\[∇f(x^{(k−1)})^Ts^{(k−1)} ≤ \min_{s∈C} ∇f(x^{(k−1)})^Ts + \frac{Mγ_k}{2} · δ\]
&lt;/blockquote&gt;

&lt;p&gt;\(δ ≥ 0\)는 부정확한 파라미터이다. 이를 using,  기본적with, 다음and, 같은 비율을 얻게 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theorem: 고정 스텝 magnitude \(γk=2/(k+1),k=1,2,3, ...\) 및 부정확한 파라미터 δ≥0을 이용한 Conditional gradient method을 using,, 다음을 만족한다.
\(f(x^{(k)}) − f^{\star} ≤ \frac{2M}{k + 2} (1 + δ)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note: \(k\) step의 optimization 오difference는 \(\frac{Mγ_k}{2} · δ.\) 이다. 여기서 \(γ_k → 0\)이므to, 시간이 지날수록 오difference가 사라지는 것을 의도to, 한다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>22-02 Conditional gradient method</title>
   <link href="http://localhost:4000/contents/en/chapter22/22_02_Conditional_gradient_method/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter22/22_02_Conditional_gradient_method</id>
   <content type="html">&lt;h2 id=&quot;projected-gradient-descent&quot;&gt;Projected Gradient Descent&lt;/h2&gt;
&lt;p&gt;Let’s consider a problem with the following constraints.&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x} f(x) \qquad \text{ subject to } x ∈ C\]
&lt;/blockquote&gt;

&lt;p&gt;We previously saw that if \(f\) is convex and smooth, and \(C\) is also convex, we can use the &lt;strong&gt;projected gradient descent&lt;/strong&gt; method.
When \(P_{C}\) is the projection operator for set \(C\), for the chosen initial value \(x^{(0)}\) and \(k = 1, 2, 3, . . .\), the following equation holds.&lt;/p&gt;

&lt;blockquote&gt;
\[x^{(k)} = P_{C } \bigl( x^{(k−1)} − t_k∇f(x^{(k−1)} \bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;Projected Gradient Descent can also be represented as a special case of proximal gradient descent, which is essentially motivated by the fact that the \(y\) value in the local quadratic expansion (2nd Taylor Expansion) becomes the next \(x^{(k)}\).&lt;/p&gt;

&lt;blockquote&gt;
\[x^{(k)} = P_{C} \Bigl( \arg\min_{y} ∇f(x^{(k−1)})^T(y − x^{(k−1)}) + \frac{1}{2t} \| y − x^{(k−1)} \|^2_ 2 \Bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;For more detailed information about Projected Gradient Descent, please reference &lt;a href=&quot;/contents/en/chapter09/09_04_special_cases/&quot;&gt;9-4&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;conditional-gradient-frank-wolfe-method&quot;&gt;Conditional gradient (Frank-Wolfe) method&lt;/h2&gt;
&lt;p&gt;Instead of minimizing the quadratic approximation here, let’s try something simpler.
First, let’s examine the point where the value is minimized when we take the inner product of set \(C\) with \(\nabla f(x)\).&lt;/p&gt;

&lt;p&gt;Fundamentally, instead of projection, we can solve problems more conveniently and effectively by minimizing linear functions at points within set \(C\). Here, we proceed by applying a line search method using convex combinations between the current point and the minimum point.&lt;/p&gt;

&lt;p&gt;Let’s look at the following formalized method.&lt;/p&gt;

&lt;p&gt;Choose initial value \(x^{(0)} ∈ C\). \(k = 1, 2, 3, . . .\)&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{array}{rcl}
s^{(k−1)} &amp;amp; ∈ &amp;amp; \arg\min_{s ∈ C} ∇f(x^{(k−1)})^Ts \\\
x^{(k)} &amp;amp; = &amp;amp; (1 − γ_k)x^{(k−1)} + γ_ks^{(k−1)}
\end{array}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;reference&quot;&gt;[reference]&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(y) \approx f(x) + \nabla f(x)(y-x)\)
\(\arg\min_y = f(x) + \nabla f(x)(y-x)\)
\(\equiv \arg\min_y f(x)y\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서, before,and, 다르게 Projection process을 거치지 않고 업데이트를 할 떄, 제약 condition, set \(C\)to, 있는 점을 using, problem를 풀어나간다.&lt;/p&gt;

&lt;p&gt;기본적with, step size는 \(γ_k =  \frac{2}{(k + 1)}, k = 1, 2, 3, . . ..\)with, 설정된다.&lt;/p&gt;

&lt;p&gt;임의의 \(0 ≤ γ_k ≤ 1\)at, convexityby, \(x^{(k)} ∈ C\) 임을 보인다.&lt;/p&gt;

&lt;p&gt;also, 다음and, 같은 식with, 업데이트가 진행되기도 한다.&lt;/p&gt;
&lt;blockquote&gt;
\[x^{(k)} = x^{(k−1)} + γ_k\bigl( s^{(k−1)} − x^{(k−1)} \bigr)\]
&lt;/blockquote&gt;

&lt;p&gt;that is,, algorithm 수행됨according to, 선형 minimizer directionwith, 점difference적with, 조금씩 덜 이동하게 된다.
대부분의 case,, co-ordinate descent의 스페셜 케이스인 Ball L1about,서 sub gradient 방식을 사용하는 것이 projection 방식을 사용하는 것 보다 problem를 solution결하기 더 쉽다.&lt;/p&gt;

&lt;h3 id=&quot;reference-1&quot;&gt;[reference]&lt;/h3&gt;
&lt;p&gt;흥미to,운 in fact,은, Frankand, Wolfe는 Tuckerand, 함께 일하던 post-doc 였다고 informing,져 있으며. 그들은 first, 첫번째to, 이 algorithm을 2 difference functionto, 제안했다고 한다. and, 그 algorithm은 1956년to, 출판되고, 후to, 논문with,도 발표되었다. and, 이 후to, 오랫during, 더 이image 이to, about, 후속 논문은 전혀 나오지 못했다. however, 지난 몇년 during, Jaggi의 통찰력to, 힘임어 세imageto, 소개되면서 다시 주목을 받게 되었다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter22/frank_wolfe.png&quot; alt=&quot;[Fig 1] Conditional Gradient (Frank-Wolfe) method (From Jaggi 2011)[3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Conditional Gradient (Frank-Wolfe) method (From Jaggi 2011)[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;norm-constraints&quot;&gt;Norm constraints&lt;/h2&gt;
&lt;p&gt;norm \(\| · \|\)about, \(C = \{x : \| x \| ≤ t \}\)일 when, 무슨일이 발생할까?&lt;/p&gt;

&lt;p&gt;다음을 let’s look at&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
s &amp;amp;∈ \arg\min_{\|s\|≤t} ∇f(x^{(k−1)})^Ts \\\
&amp;amp;= −t ·  \arg\max_{\|s\|≤1}  ∇f(x^{(k−1)})^Ts \\\
&amp;amp;= −t · ∂ \| ∇f(x^{(k−1)}) \|_{∗}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\| · \|_{∗}\)는 dual norm을 의마한다.&lt;/p&gt;

&lt;p&gt;다시 말solution, dual norm의 subgradient를 computation하는 method을 안다면, Frank-Wolfe step를 쉽게 수행 할 수 있다는 뜻이다.&lt;/p&gt;

&lt;p&gt;Frank-Wolfe의 핵심은 \(C = \{x : \| x \| ≤ t \}\)to, projection method을 사용하는 것보다 더 간단하거나 낮은 비용with, 구할 수 있으며, also, when,to,는 \(\| · \|\)의 prox operator보다도 간단하거나 더 낮은 비용을 요한다는 것이다.&lt;/p&gt;

&lt;h2 id=&quot;example-l_1-regularization&quot;&gt;Example: \(l_1\) regularization&lt;/h2&gt;
&lt;p&gt;다음은 &lt;strong&gt;\(l_1\)-regularized&lt;/strong&gt; 이다.&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) \qquad \text{ subject to } \| x \|_1 ≤ t\]
&lt;/blockquote&gt;

&lt;p&gt;앞선 공식대to, 전개하면, \(s^{(k−1)} ∈ −t∂ \|∇f(x^{(k−1)}) \|_∞\) 를 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;Frank-Wolfe method은 다음의 process을 through, 업데이트 된다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{array}{rcl}
i_{k−1} &amp;amp; ∈  &amp;amp; \arg\max_{i=1,...p} ∇_i f(x^{(k−1)}) \\\
x^{(k)}  &amp;amp; = &amp;amp; (1 − γ_k)x^{(k−1)} − γ_kt · sign ∇_{i_{k−1}} f(x^{(k−1)})· e_{i_{k−1}}
\end{array}\]
&lt;/blockquote&gt;

&lt;p&gt;이것은 coordinate descent의 일종이다(coordinate descentabout,서는 나중to, 자세히 let’s look at).&lt;br /&gt;
Note : 두 가지 모두 \(O(n)\)의 복잡도가 필요but, \(l1\) ballto, projection 하는 것보다 훨씬 간단하다.&lt;/p&gt;

&lt;h2 id=&quot;example-l_p-regularization&quot;&gt;Example: \(l_p\) regularization&lt;/h2&gt;
&lt;p&gt;다음은 \(l_p\)-regularized problem다.&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x}  f(x) \qquad \text{ subject to } \| x \|_{p} ≤ t\]
&lt;/blockquote&gt;

&lt;p&gt;\(1 ≤ p ≤ ∞\)at, p가 q의 dual일 when,  \(s^{(k−1)} ∈ −t∂ \| ∇f(x^{(k−1)}) \|_{q}\) 이다. that is,, \(1/p + 1/q = 1\)이다.&lt;/p&gt;

&lt;p&gt;that is, as follows: 선택할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[s_i^{(k−1)} = −α · sign ∇f_i(x^{(k−1)}) · \left| ∇f_i(x^{(k−1)}) \right|^{p/q}, i = 1, . . . n\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(α\)는 \(\| s^{(k-1)} \|_{q} = t\)and, 같은 constant이고, Frank-Wolfe 업데이트도 동일하다.&lt;/p&gt;

&lt;p&gt;Note: 일반 \(p\)의 case, &lt;strong&gt;p Ballto, Projection&lt;/strong&gt;하는 것보다 훨씬 간단하다.&lt;br /&gt;
특별한 case,(\(p = 1, 2, ∞\))를 제외하고 이러한 projection은 직접 computation할 수 없다(optimizationto, 처리되어야 함).&lt;/p&gt;

&lt;h2 id=&quot;example-trace-norm-regularization&quot;&gt;Example: trace norm regularization&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;trace-regularized&lt;/strong&gt; problem를 let’s look at&lt;/p&gt;
&lt;blockquote&gt;
\[\min_{X} f(X) \qquad \text{ subject to } \| X \|_{tr} ≤ t\]
&lt;/blockquote&gt;

&lt;p&gt;\(S^{(k−1)} ∈ −t· ∂\| ∇f(X(k−1)) \|_{op}.\) 이다.&lt;/p&gt;

&lt;p&gt;as follows: \(S_i^{(k−1)}\)를 선택할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[S_i^{(k−1)} = −t · uv^T\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(u, v\)는 \(∇f(X^{(k−1)})\)의 왼쪽, 오른쪽 singular vector이고, Frank-Wolfe 업데이트는 평소and, 같다.&lt;/p&gt;

&lt;p&gt;Note: 이 method은 특이 값 분solution(SVD)가 가능하면, &lt;strong&gt;trace norm ballto, projection&lt;/strong&gt;하는 것보다 훨씬 간단하고 효율적with, solution를 구할 수 있는 method이다.&lt;/p&gt;

&lt;h2 id=&quot;constrained-and-lagrange-forms&quot;&gt;Constrained and Lagrange forms&lt;/h2&gt;
&lt;p&gt;제약 condition,이 있는 problem의 solution을 다시 한번 image기solution보자&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) \qquad \text{ subject to } \| x \| ≤ t\]
&lt;/blockquote&gt;

&lt;p&gt;다음의 Lagrange problem는 위 식and, equivalence이다.&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x f(x) + λ \| x \|\]
&lt;/blockquote&gt;

&lt;p&gt;튜닝 파라미터 \(t\)and, \(λ\)는 [0,∞]구간at, 변한다. also, \(\| · \|\)의 Frank-Wolfe 업데이트를 \(\| · \|\)의  proximal 오퍼레이터and, comparing,야 한다.&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;\(l_1\) norm&lt;/strong&gt;: Frank-Wolfe method은 gradient의 최댓값을 스캔하여 업데이트 한다.
proximal operator soft-threshold를 진행하면서 업데이트 한다. 두 step 모두 \(O(n)\) flops을 사용 한다.&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;\(l_p\) norm&lt;/strong&gt;: 프랭크-울프(Frank-Wolfe) 업데이트는 gradient의 각 항목마다 제product하고 모두 sum산하여 \(O(n)\) flopwith, 증가시킨다. proximal operator는 generally, 직접 computation할 수 없다.&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;Trace norm&lt;/strong&gt;: 프랭크-울프(Frank-Wolfe) 업데이트는 gradient의 image단 왼쪽 및 오른쪽 singular vector를 computation한다. proximal operatorat,는 soft-thresholds gradient step을 진행하며, 특이값 분solution(SVD)를 필요to, 한다.&lt;/p&gt;

&lt;p&gt;다른 많은 regularizer들이 효율적인 Frank-Wolfe update를 도출하였다.
예를 들면, special polyhedra or, cone constraints, sum-of-norms (group-based) regularization, atomic norms. 같은 것들이다.&lt;/p&gt;

&lt;p&gt;Constrained Lassoto, about, projected gradient techniqueand, conditional gradient technique을 활용했을 when, 성능을 비교하면 as follows:. (여기서 \(n=100, p = 500\))&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter22/comparing_projected_and_conditional_gradient.png&quot; alt=&quot;[Fig 2] Comparing projected and conditional gradient for constrained lasso
problem [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] Comparing projected and conditional gradient for constrained lasso
problem [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;프랭크-울프(Frank-Wolfe) method이 first-order method의 convergence율and, 비슷한 양image을 띠고 있는 것을 확인할 수 있을 것이다. however, actually,는 높은 정확도to, convergence하기 for,서는 속도가 더 느려질 수 있다. (reference: 여기서 fixed step size를 사용but,, line search를 using, convergence 속도를 향image시킬 수도 있다.)&lt;/p&gt;

&lt;h2 id=&quot;duality-gap&quot;&gt;Duality gap&lt;/h2&gt;
&lt;p&gt;프랭크-울프(Frank-Wolfe) iteration processat, 자연스럽게 duality gap 이 발생되며, 이는 actually, suboptimality gap을 의미한다.&lt;/p&gt;
&lt;blockquote&gt;
\[g(x^{(k-1)}) := \max_{s∈C} ∇f(x^{(k−1)})^T(x^{(k−1)} − s)\]
&lt;/blockquote&gt;

&lt;p&gt;이것은 \(f(x^{(k−1)}) − f^{\star}\)의 upper bound 이다.&lt;/p&gt;

&lt;h4 id=&quot;proof&quot;&gt;[Proof]&lt;/h4&gt;
&lt;p&gt;convexity의 first-order condition을 using, 증명할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[f(s) ≥ f(x^{(k−1)}) + ∇f(x^{(k−1)})^T(s − x^{(k−1)})\]
&lt;/blockquote&gt;

&lt;p&gt;모든 $s ∈ C$about, 양쪽을 minimization 한다.&lt;/p&gt;
&lt;blockquote&gt;
\[f^{\star} ≥ f(x^{(k−1)}) + min_{s∈C} ∇f(x^{(k−1)})^T(s − x^{(k−1)})\]
&lt;/blockquote&gt;

&lt;p&gt;최종적with,, 다시 정리하여 다음 식은 duality gap이 upper bound임을 showing, 준다.&lt;/p&gt;
&lt;blockquote&gt;
\[\max_{s∈C} ∇f(x^{(k−1)})^T(x^{(k−1)} − s) = ∇f(x^{(k−1)})^T(x^{(k−1)} − s^{(k−1)})\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;note&quot;&gt;[Note]&lt;/h4&gt;
&lt;p&gt;therefore, 이 quantity는 Frank-Wolfe 업데이트at, 직접 나온 것이다.
왜 우리는 이를 “duality gap”이라 부를까?&lt;/p&gt;

&lt;p&gt;original problem을 다시 써보면 아래and, 같이 쓸 수있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\min_{x} f(x) + I_C(x)\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(I_C\)는 \(C\)의 indicator function을 의미한다. dual problem는 아래and, 같다.&lt;/p&gt;
&lt;blockquote&gt;
\[\max_u −f^{*} (u) − I^{*}_C(−u)\]
&lt;/blockquote&gt;

&lt;p&gt;\(I_C^{*}\)가 \(C\)의 support function을 의미한다. Indicator function의 conjugate는 support function 이 됨을 앞서 살펴보았다.&lt;/p&gt;

&lt;h4 id=&quot;recall&quot;&gt;[Recall]&lt;/h4&gt;
&lt;blockquote&gt;
\[I_C (X) =  
\begin{cases}
+&amp;amp; \infty &amp;amp;if &amp;amp;x &amp;amp;\notin; C \\\
 &amp;amp; 0      &amp;amp;if &amp;amp;x &amp;amp;\in; C
\end{cases}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[\begin{align}
I_C^{*} &amp;amp;= \max_{x} \{ &amp;lt;s, x\&amp;gt; - I_C(x)\} \\
        &amp;amp;= \max_{x \in C} &amp;lt;s, x&amp;gt; \\
        &amp;amp;= \text{Support function of } C \text{ at } S
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(x = x ^ {(k-1)}, u = ∇f (x ^ {(k-1)})\) 일 when,, \(x, u\)at, 발생하는 duality gap은 as follows:. (13-04 &lt;a href=&quot;/contents/en/chapter13/13_04_Conjugate_function/&quot;&gt;Fenchel’s inequality&lt;/a&gt; from, 유도되기도 한다.)&lt;/p&gt;
&lt;blockquote&gt;
\[f(x) + f^{*}(u) + I^{*}_C(−u) ≥ x^Tu + I^{*}_C(−u)\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>22-01 Last time: ADMM</title>
   <link href="http://localhost:4000/contents/en/chapter22/22_01_Last_time_ADMM/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter22/22_01_Last_time_ADMM</id>
   <content type="html">&lt;h2 id=&quot;last-time-admm&quot;&gt;Last time: ADMM&lt;/h2&gt;
&lt;p&gt;Let’s consider the following optimization problem&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x,z} &amp;amp;&amp;amp;f(x) + g(z)\\\\
&amp;amp;\text{ subject to } &amp;amp;&amp;amp;Ax + Bz = c 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Converting this to Augmented Lagrangian form gives us the following. (for some \(ρ &amp;gt; 0\))&lt;/p&gt;
&lt;blockquote&gt;
\[L_ρ(x, z, u) = f(x) + g(z) + u^T(Ax + Bz − c) + \frac{ρ}{2} \| Ax + Bz − c \|^2_2\]
&lt;/blockquote&gt;

&lt;p&gt;The above equation becomes Strongly Convex with the addition of \(\frac{ρ}{2} \| Ax + Bz − c \|^2_2\), and this can be transformed into a form useful for parallel processing as shown in the following equation.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For detailed proof, please refer to the content of the previous chapter.
ADMM: for \(k = 1, 2, 3, . . .\)
    &lt;blockquote&gt;
      &lt;p&gt;\(x^{(k)} = argmin_{x} L_ρ(x, z^{(k−1)}, u^{(k−1)})\)
\(z^{(k)} = argmin_{z} L_ρ(x^{(k)}  , z, u^{(k−1)})\)
\(u^{(k)} = u^{(k−1)} + ρ(Ax^{(k)} + Bz^{(k)} − c)\)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;admm-in-scaled-form&quot;&gt;ADMM in scaled form&lt;/h2&gt;
&lt;p&gt;Let’s change the dual variable \(u\) to the scaled variable \(w = u/ρ\). Here, the ADMM step can be computed as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x^{(k)} = argmin_{x} f(x) + \frac{ρ}{2} \| Ax + Bz^{(k−1)} − c + w^{(k−1)} \|^2_2\)
\(z^{(k)} = argmin_{z} g(z) + \frac{ρ}{2} \| Ax^{(k)} + Bz − c + w^{(k−1)} \|^2_2\) 
\(w^{(k)} = w^{(k−1)} + Ax^{(k)} + Bz^{(k)} − c\)&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>15 Barrier Method</title>
   <link href="http://localhost:4000/contents/en/chapter15/chapter16/15_barrier_method/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/chapter16/15_barrier_method</id>
   <content type="html">&lt;p&gt;In this chapter, we will look at one of the 2nd-order methods, the &lt;strong&gt;Barrier Method&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Barrier Method&lt;/strong&gt; is a technique for solving &lt;strong&gt;inequality constraint and equality constrained smooth problems&lt;/strong&gt;, which are considered the most difficult among 2nd-order method problems.&lt;/p&gt;

&lt;p&gt;(For reference, using the gradient to solve an optimization problem is called a 1st-order method, and using the Hessian is called a 2nd-order method.)&lt;/p&gt;

&lt;h2 id=&quot;references-and-further-readings&quot;&gt;References and further readings&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;S. Boyd and L. Vandenberghe (2004), “Convex optimization”, Chapter 11&lt;/li&gt;
  &lt;li&gt;A. Nemirovski (2004), “Interior-point polynomial time methods in convex programming”, Chapter 4&lt;/li&gt;
  &lt;li&gt;J. Nocedal and S. Wright (2006), “Numerical optimization”, Chapters 14 and 19&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>15-08 Formal barrier method</title>
   <link href="http://localhost:4000/contents/en/chapter15/chapter16/15_08_formal_barrier_method/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/chapter16/15_08_formal_barrier_method</id>
   <content type="html">&lt;p&gt;If a convex function \(\phi : D \to \mathbb{R}\) defined on an open convex set \(D \subset \mathbb{R}^n\) satisfies the following conditions, then the function is a &lt;strong&gt;self-concordant barrier&lt;/strong&gt; with parameter \(\nu\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\phi\) is self-concordant&lt;/li&gt;
  &lt;li&gt;For all \(x \in D\), the Newton decrement is bounded by the constant \(\nu\) as follows.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\lambda(x)^2 = \nabla \phi(x) (\nabla^2 \phi(x))^{-1} \nabla \phi(x) \le \nu\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s consider the following LP problem. (Here, \(\bar{D}\) is the closure of the domain \(D\).)&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x} \           &amp;amp;&amp;amp; c^Tx \\
&amp;amp;\text{subject to } \ &amp;amp;&amp;amp; x \in \bar{D}  \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This problem can be approximated as follows.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp; tc^Tx + \phi(x) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, let \(\phi_t(x) := tc^Tx + \phi(x)\) and let the corresponding Newton decrement be \(\lambda_t(x)\).&lt;/p&gt;

&lt;p&gt;Key observation: When \(t^+ &amp;gt; t\)&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
\lambda_t^+(x) \le &amp;amp; \frac{t^+}{t}\lambda_t^+(x) + \left ( \frac{t^+}{t} -1 \right ) \sqrt{\nu}  \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;theorem&quot;&gt;Theorem&lt;/h2&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \text{if} \quad \lambda_t(x) \le \frac{1}{9} \quad \text{and} \quad \frac{t^+}{t} \le 1 + \frac{1}{8 \sqrt{\nu}} \quad \text{then} \quad \lambda_t^+(x^+) \le \frac{1}{9}  \\
&amp;amp; \qquad \qquad \text{for} \quad x^+ = x - (\nabla^2 (\phi_{t^+}(x))^{-1} \nabla (\phi_{t^+}(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In conclusion, if we start with \(x^{(0)}, t^{(0)}\) such that \(\lambda_{t^{(0)}}(x^{(0)}) \lt \frac{1}{9}\) and choose \(\mu := 1 + \frac{1}{8 \sqrt{\nu}}\), then one Newton step per centering step is sufficient.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-07 Feasibility methods</title>
   <link href="http://localhost:4000/contents/en/chapter15/chapter16/15_07_feasibility_methods/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/chapter16/15_07_feasibility_methods</id>
   <content type="html">&lt;p&gt;So far, we have implicitly assumed that the first centering step (\(t = t^{(0)}\)) starts from a strictly feasible point to compute \(x^{(0)} = x^*\).&lt;/p&gt;

&lt;p&gt;This means that \(x\) is a strictly feasible point satisfying the following conditions:&lt;/p&gt;
&lt;blockquote&gt;
\[h_i(x) \lt 0, \quad i = 1, \cdots, m, \quad Ax = b\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;maximum-infeasibility&quot;&gt;Maximum infeasibility&lt;/h2&gt;
&lt;p&gt;How do we find \(x\)? We can solve the following problem to find it.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x, s} \        &amp;amp;&amp;amp; s \\
&amp;amp;\text{subject to } \ &amp;amp;&amp;amp; h_i(x) \le s,&amp;amp; i = 1, \cdots, m \\
                      &amp;amp;&amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The goal is to make the solution \(s\) negative. This problem is called the &lt;strong&gt;feasibility method&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Finding a strictly feasible starting point is easy, so it can also be solved using the barrier method. That is, you can add slack variables to the inequality constraint \(h_i(x) \le s\) and convert it to an equality constraint to solve it.&lt;/p&gt;

&lt;p&gt;When solving this problem, high accuracy is not required; you just need to find a feasible \((x,s)\) with \(s &amp;lt; 0\).&lt;/p&gt;

&lt;h2 id=&quot;infeasibility-for-each-inequality-constraint&quot;&gt;Infeasibility for each inequality constraint&lt;/h2&gt;
&lt;p&gt;You can also define and solve the problem as follows. The previous method found the maximum infeasibility for all inequalities, while this problem finds the infeasible variable \(s_i, i = 1, \cdots, m\) for each inequality.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x, s} \        &amp;amp;&amp;amp; 1^Ts \\
&amp;amp;\text{subject to } \ &amp;amp;&amp;amp; h_i(x) \le s_i,&amp;amp; i = 1, \cdots, m \\
                      &amp;amp;&amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The advantage of this method is that by looking at the solution \(s\), you can tell if the problem is infeasible. That is, if any element of \(s\) is greater than or equal to 0, the corresponding constraint is not satisfied.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-06 Barrier method v.2</title>
   <link href="http://localhost:4000/contents/en/chapter15/15_06_barrier_method_v2/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/15_06_barrier_method_v2</id>
   <content type="html">&lt;p&gt;이전 알고리즘에서는 central path에 있는 solution을 생성했는데, 실제 central path는 optimal로 가는 과정(“means to an end”)일 뿐이다. 따라서, 문제를 정확히 풀 필요는 없다.&lt;/p&gt;

&lt;p&gt;In the previous algorithm, we generated solutions along the central path, but in reality, the central path is just a means to reach the optimal solution. Therefore, it is not necessary to solve the problem exactly.&lt;/p&gt;

&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;
&lt;p&gt;For this reason, Barrier method v.2 solves the barrier problem approximately.&lt;/p&gt;

&lt;p&gt;단, 단계 2의  \(x^{(0)} \approx x^*(t)\)와 단계 3-2의 \(x^{(k+1)} \approx x^*(t)\) 부분이 approximation으로 바뀌었다.
The steps of the algorithm are the same as those in Barrier method v.1.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;\(t^{(0)} \gt 0\)이고 \(k := 0\)을 선택한다.
However, in step 2, \(x^{(0)} \approx x^*(t)\) and in step 3-2, \(x^{(k+1)} \approx x^*(t)\) are now approximations.&lt;/li&gt;
  &lt;li&gt;While \(m/t \gt \epsilon\) &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Choose \(t^{(0)} &amp;gt; 0\) and set \(k := 0\).&lt;/li&gt;
  &lt;li&gt;At \(t = t^{(0)}\), solve the barrier problem to obtain \(x^{(0)} \approx x^*(t)\).&lt;/li&gt;
  &lt;li&gt;While \(m/t &amp;gt; \epsilon\) &lt;br /&gt;
  3-1. Choose \(t^{(k+1)} &amp;gt; t^{(k)}\). &lt;br /&gt;
  3-2. Initialize Newton’s method with \(x^{(k)}\). (warm start)&lt;br /&gt;
     At \(t = t^{(k+1)}\), solve the barrier problem to obtain \(x^{(k+1)} \approx x^*(t)\).&lt;br /&gt;
  end while&lt;br /&gt;
Barrier method v.2에서는 다음 두 가지 사항이 매우 중요하다.&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;얼마나 근사를 잘 할 수 있는가? (How close should each approximation be?)
In Barrier method v.2, the following two issues are very important:&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;How close should each approximation be?&lt;/li&gt;
  &lt;li&gt;How many Newton steps are needed at each centering step?&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
In the following figure, you can see that when the barrier method is applied to a problem with $$m$$ constraints, linear convergence occurs even as $$m$$ becomes large. That is, it has a log scale with respect to $$m$$.
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter15/15_barrier_methodv2_04.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] m에 대해 newton iteration과 suboptimality gap 분석 [1]&lt;/figcaption&gt;
&amp;lt;/p&amp;gt;
&lt;/figure&gt;

&lt;p&gt;다르게 보면 (\(10^4\)인 초기 suboptimal gap (duality gap)을 줄이기 위해 필요한) newton step은 \(m\)에 대해 천천히 증가한다. 아래 그림을 보면 \(m\)이 크게 증하하더라도 각 centering step 별로 20~30 newton step 정도만 필요하다. 단, 한 newton step은 문제의 크기에 따라 크게 달라진다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter15/15_barrier_methodv2_05.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] m의 증가와 newton iteration 수 분석 [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>15-05 Convergence analysis</title>
   <link href="http://localhost:4000/contents/en/chapter15/chapter16/15_05_convergence_analysis/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/chapter16/15_05_convergence_analysis</id>
   <content type="html">&lt;p&gt;Assuming the centering step in the barrier method is solved exactly, we can obtain the following convergence results.&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;
&lt;p&gt;After \(k\) centering steps, the &lt;strong&gt;barrier method&lt;/strong&gt; satisfies the following equation. (Here, \(k\) is the number of outer iterations.)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f^{*} \le  \frac{m}{\mu^k t^{(0)}}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;That is, to reach the desired accuracy level \(\epsilon\) with the barrier method, you need the following number of centering steps plus one for the first centering step.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\frac{log(m/(t^{(0)}\epsilon))}{\log \mu} + 1
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, we see that the convergence is linear, with \(O(\log 1/\epsilon )\).&lt;/p&gt;

&lt;p&gt;Newton’s method has quadratic convergence with \(O(\log \log 1/\epsilon )\), but in this case, the problem is very difficult, so linear convergence is not such a bad result.&lt;/p&gt;

&lt;p&gt;For the definitions of linear and quadratic convergence, refer to the Wiki.&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Rate_of_convergence&quot;&gt;Rate of convergence&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>15-04 Barrier method v.0 and v.1</title>
   <link href="http://localhost:4000/contents/en/chapter15/chapter16/15_04_barrier_method_v0_and_v1/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/chapter16/15_04_barrier_method_v0_and_v1</id>
   <content type="html">&lt;h2 id=&quot;barrier-method-v0&quot;&gt;Barrier method v.0&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Barrier method v.0&lt;/strong&gt; chooses \(t = m/\epsilon\) for \(\epsilon &amp;gt; 0\) and solves the following barrier problem to obtain \(f(x^*(t)) - f(x^*) \le \epsilon\).&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
 &amp;amp;\min_{x} \ &amp;amp;&amp;amp; tf(x) + \phi(x) \\
 &amp;amp;\text{subject to } \ &amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(m\) is the number of constraints and \(t\) is a multiple of \(1/\epsilon\), so as \(\epsilon\) gets smaller, \(t\) becomes very large, and eventually the end of the central path is reached, making the problem equivalent to the original problem. Therefore, this can be very slow and difficult to solve.&lt;/p&gt;

&lt;p&gt;Thus, a better approach is to follow the central path to find the solution, which leads to the definition of &lt;strong&gt;barrier method v.1&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;barrier-method-v1&quot;&gt;Barrier method v.1&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Barrier method v.1&lt;/strong&gt; is a method that gradually increases the value of \(t\) and solves the following barrier problem multiple times.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
 &amp;amp;\min_{x} \ &amp;amp;&amp;amp; tf(x) + \phi(x) \\
 &amp;amp;\text{subject to } \ &amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;
&lt;p&gt;The algorithm can be described as follows.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Choose \(t^{(0)} &amp;gt; 0\) and set \(k := 0\).&lt;/li&gt;
  &lt;li&gt;At \(t = t^{(0)}\), solve the barrier problem to obtain \(x^{(0)} = x^*(t)\).&lt;/li&gt;
  &lt;li&gt;While \(m/t &amp;gt; \epsilon\) &lt;br /&gt;
  3-1. Choose \(t^{(k+1)} &amp;gt; t^{(k)}\). &lt;br /&gt;
  3-2. Initialize Newton’s method with \(x^{(k)}\). (warm start)&lt;br /&gt;
     At \(t = t^{(k+1)}\), solve the barrier problem to obtain \(x^{(k+1)} = x^*(t)\).&lt;br /&gt;
  end while&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;comments&quot;&gt;Comments&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Common update method&lt;/strong&gt;: \(t^{(k+1)} = \mu t^{(k)}\), (\(\mu &amp;gt; 1\))&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Warm start&lt;/strong&gt;: In step 3-2, the solution from the previous step is used as the initial value for the next step, which is called warm start.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Centering step&lt;/strong&gt;: Steps 2 and 3-2 in the algorithm, which solve the barrier problem, are called centering steps (or outer iterations).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;considerations&quot;&gt;Considerations&lt;/h3&gt;
&lt;p&gt;In choosing \(\mu\) and \(t^{(0)}\), the following trade-offs must be considered.&lt;/p&gt;
&lt;h5 id=&quot;choice-of-mu&quot;&gt;Choice of \(\mu\)&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;If \(\mu\) is too small, the number of outer iterations increases. (In this case, warm start helps.)&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;If \(\mu\) is too large, many iterations are required for Newton’s method to converge in every centering step.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;choice-of-initial-algorithm-value&quot;&gt;Choice of initial algorithm value&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;If \(t^{(0)}\) is too small, the number of outer iterations increases.&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;If \(t^{(0)}\) is too large, it becomes the same problem as v.0. Therefore, Newton’s method requires many iterations to find \(x^{(0)}\) in the first centering step.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fortunately, the performance of the actual barrier method is very robust to the choice of \(\mu\) and \(t^{(0)}\). Moreover, the appropriate range of these parameters varies depending on the problem size.&lt;/p&gt;

&lt;h2 id=&quot;example-of-small-lp&quot;&gt;Example of small LP&lt;/h2&gt;
&lt;p&gt;The following figure shows the performance when executing an LP problem with n=50 dimensions and m=100 inequality constraints using the barrier method. It can be confirmed that when \(\mu = 2\), the outer iterations increase, and when \(\mu=150\), the centering steps increase relatively compared to when \(\mu=50\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter15/15_barrier_method_03.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Example of small LP [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>15-03 Properties and interpretation</title>
   <link href="http://localhost:4000/contents/en/chapter15/chapter16/15_03_properties_and_interpretation/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/chapter16/15_03_properties_and_interpretation</id>
   <content type="html">&lt;p&gt;In this section, we will derive the KKT conditions for the barrier problem and the original problem to see what differences exist. We will also calculate the suboptimality gap for the solutions to both problems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-03-02 Suboptimality gap</title>
   <link href="http://localhost:4000/contents/en/chapter15/15_03_02_suboptimality_gap/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/15_03_02_suboptimality_gap</id>
   <content type="html">&lt;p&gt;앞 절에서 구한 barrier problem과 original problem의 solution인 \(f(x^*(t))\)와 \(f(x^*)\)의 suboptimality gap은 어떻게 될까?&lt;/p&gt;

&lt;p&gt;What is the suboptimality gap between \(f(x^*(t))\), the solution to the barrier problem, and \(f(x^*)\), the solution to the original problem, as derived in the previous section?
따라서, 다음의 식을 구할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
If convexity is guaranteed, the function is always greater than its tangent, so\)f(x^&lt;em&gt;) \ge f(x^&lt;/em&gt;(t)) + \nabla f(x^&lt;em&gt;(t))^T (x^&lt;/em&gt; - x^*(t))$$ holds. (The tangent is the first-order Taylor approximation)
Therefore, we can derive the following equation:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;비슷하게 \(h_i(x^*) \ge h_i(x^*(t)) + \nabla h_i(x^*(t))^T (x^* - x^*(t))\)가 성립하므로 다음의 식을 구할 수 있다.&lt;/p&gt;

&lt;p&gt;Similarly, since \(h_i(x^*) \ge h_i(x^*(t)) + \nabla h_i(x^*(t))^T (x^* - x^*(t))\) holds, we can derive the following equation:
h_i(x^&lt;em&gt;(t)) - h_i(x^&lt;/em&gt;) \le \nabla h_i(x^&lt;em&gt;(t))^T (x^&lt;/em&gt;(t) - x^*), \quad i = i, \cdots , m
\end{align}$$&lt;/p&gt;

&lt;h2 id=&quot;derivation-of-suboptimality-gap&quot;&gt;Derivation of suboptimality gap&lt;/h2&gt;
&lt;p&gt;이 두 식에서 suboptimality gap을 유도해 보도록 하겠다. 오른쪽 항은 위의 두 convexity 조건에 의해 도출된다.&lt;/p&gt;

&lt;p&gt;Let’s use these two equations to derive the suboptimality gap. The right-hand side is derived from the two convexity conditions above.
f(x^&lt;em&gt;(t)) - f(x^&lt;/em&gt;) + \sum_{i=1}^{m}  u_i(t) (h_i(x^&lt;em&gt;(t)) - h_i(x^&lt;/em&gt;) ) 
    &amp;amp; \le 	\left\langle \nabla  f(x^&lt;em&gt;(t))  + \sum_{i=1}^{m} u_i(t) \nabla h_i(x^&lt;/em&gt;(t)), \quad x^&lt;em&gt;(t) - x^&lt;/em&gt; \right\rangle \&lt;br /&gt;
    &amp;amp; = \left\langle -tA^Tv,  \quad x^&lt;em&gt;(t) - x^&lt;/em&gt; \right\rangle \&lt;br /&gt;
\end{align}$$&lt;/p&gt;

&lt;p&gt;이 식에서 오른쪽 항을 내적해 보면 \(Ax^*(t) = b\)이고 \(Ax^* = b\)이므로 전체가 0이 된다.
따라서, 첫번째 식의 세번째 항을 오른쪽으로 넘겨서 정리해 보면 다음과 같은 결과를 얻을 수 있다.
If we look at the right-hand side of this equation as an inner product, since \(Ax^*(t) = b\) and \(Ax^* = b\), the whole term becomes zero.
Therefore, moving the third term of the first equation to the right and simplifying, we get the following result:
f(x^&lt;em&gt;(t)) - f(x^&lt;/em&gt;) &amp;amp; \le - \sum_{i=1}^{m}  u_i(t) (h_i(x^&lt;em&gt;(t)) - h_i(x^&lt;/em&gt;) )  \&lt;br /&gt;
    &amp;amp; = \frac{m}{t} +  \sum_{i=1}^{m} u_i(t) h_i(x^*) \&lt;br /&gt;
    &amp;amp; \le \frac{m}{t} &lt;br /&gt;
\end{align}$$&lt;/p&gt;

&lt;p&gt;두번째 라인의 첫번째 항은 KKT condition에서 \(u_i(t) \cdot   h_i(x^*(t)) = - \frac{1}{t}\)를 만족하므로  \(\frac{m}{t}\)가 된다.  두번째 항도 KKT condition에서 \(\sum_{i=1}^{m} u_i(t)  h_i(x^*) \le 0\)이므로 제거할 수 있다.&lt;/p&gt;

&lt;p&gt;결과적으로 다음과 같은 suboptimality gap을 구할 수 있으며 이는 유용한 stopping criterion이 된다. 참고로, 이 결과는 다음 장에서 duality gap으로도 유도할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(x^*(t)) - f(x^*) \le \frac{m}{t}
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>15-03-01 Perturbed KKT conditions</title>
   <link href="http://localhost:4000/contents/en/chapter15/chapter16/15_03_01_perturbed_kkt_conditions/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/chapter16/15_03_01_perturbed_kkt_conditions</id>
   <content type="html">&lt;p&gt;If we derive the KKT conditions from the barrier problem and the original formulation, we get the following.&lt;/p&gt;
&lt;h2 id=&quot;kkt-conditions-for-barrier-problem&quot;&gt;KKT conditions for barrier problem&lt;/h2&gt;
&lt;p&gt;The second term in the KKT conditions for the barrier problem is derived using the gradient of the log barrier function.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
t \nabla f(x^*(t)) - \sum_{i=1}^{m} \frac{1}{h_i(x^*(t))} \nabla h_i(x^*(t)) + A^Tw = 0  \\\ 
 Ax^*(t) = b, \quad h_i(x^*(t)) \lt 0, \quad i = 1, \cdots , m \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;kkt-conditions-for-the-original-problem&quot;&gt;KKT conditions for the original problem&lt;/h2&gt;
&lt;p&gt;In the KKT conditions for the original problem, complementary slackness gives \(h_i(x^*) \cdot u_i^* = 0\), but in practice, it is very difficult to know this boundary condition.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
\nabla f(x^*) + \sum_{i=1}^{m} u_i^* \nabla h_i(x^*) + A^Tv^* = 0 \\\ 
Ax^* = b, \quad h_i(x^*) \le 0, \quad u_i^* \ge 0,   \\\ 
h_i(x^*) \cdot u_i^* = 0,  \quad i = 1, \cdots , m \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;redefinition-of-kkt-conditions-for-barrier-problem&quot;&gt;Redefinition of KKT conditions for barrier problem&lt;/h2&gt;
&lt;p&gt;So, what is the relationship between these two KKT conditions?&lt;/p&gt;

&lt;p&gt;First, let \(u_i(t)\) and \(v\) be defined as follows:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
u_i(t) = - \frac{1}{t h_i(x^*(t))}, \quad v = \frac{1}{t}w
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s redefine the KKT conditions for the barrier problem.&lt;/p&gt;

&lt;p&gt;Looking at the redefined problem, we see that the KKT conditions are almost identical to those for the original problem. In this equation, \(u_i(t) \cdot   h_i(x^*(t)) = - \frac{1}{t}\) becomes 0 as \(t \to \infty\), which matches \(h_i(x^*) \cdot u_i^* = 0\) in the original formulation.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
&amp;amp; \nabla f(x^*(t)) + \sum_{i=1}^{m} u_i(t) \nabla h_i(x^*(t)) + tA^Tv = 0  \\\ 
&amp;amp; Ax^*(t) = b, \quad u_i(t) \cdot   h_i(x^*(t)) = - \frac{1}{t}, \quad h_i(x^*(t)) \lt 0, \quad u_i(t) \gt 0 , \quad i = 1, \cdots , m \\\
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>15-02 Central path</title>
   <link href="http://localhost:4000/contents/en/chapter15/15_02_central_path/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/15_02_central_path</id>
   <content type="html">&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;If we denote the solution to the following barrier problem (\(t &amp;gt; 0\)) as \(x^*(t)\), then the &lt;strong&gt;central path&lt;/strong&gt; is the set $${x^*(t)&lt;/td&gt;
      &lt;td&gt;t &amp;gt; 0 }$$.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} \ &amp;amp;&amp;amp;  tf(x) + \phi(x) \\
&amp;amp;\text{subject to } \ &amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Given suitable conditions, the &lt;strong&gt;central path&lt;/strong&gt; set forms a smooth path in \(\mathbb{R}^n\), and as \(t \to \infty\), \(x^*(t) \to x^*\), where \(x^*\) is the solution to the original problem.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;central path&lt;/strong&gt; is a set of solutions obtained by gradually redefining the problem for new values of \(t\), moving from the interior toward the boundary when it is difficult to find the optimal solution at the boundary directly.&lt;/p&gt;

&lt;h2 id=&quot;example-central-path-for-an-lp&quot;&gt;Example: central path for an LP&lt;/h2&gt;
&lt;p&gt;Let’s find the central path for the following LP problem.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align*}
&amp;amp;\min_{x} \ &amp;amp;&amp;amp; c^Tx \\
&amp;amp;\text{subject to } \ &amp;amp;&amp;amp; a_i^Tx \le b_i^T, i = 1, \cdots , 6 \\
\end{align*}\]
&lt;/blockquote&gt;

&lt;p&gt;In the following figure, the dotted line represents the logarithmic barrier function \(\phi\). &lt;br /&gt;&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter15/15_central_path_02.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Central path [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;You can see that as \(t \to \infty\), the central path converges to the optimal \(x^*\). At this point, the hyperplane \(c^Tx = c^Tx(t)\) is the tangent to the level curve of \(\phi\) passing through \(c^Tx(t)\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-01 Barrier method and log barrier function</title>
   <link href="http://localhost:4000/contents/en/chapter15/15_01_barrier_method_and_log_barrier_function/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/15_01_barrier_method_and_log_barrier_function</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In the previous chapter, we explored how to solve an &lt;strong&gt;equality constrained smooth problem&lt;/strong&gt; using Newton’s method. In this chapter, we will look at methods for solving &lt;strong&gt;inequality and equality constrained smooth problems&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The basic idea is to transform the problem into an equality constrained smooth problem and solve it using Newton’s method. This approach is called the &lt;strong&gt;interior method&lt;/strong&gt;, and in this chapter, we will focus on one type of interior method: the &lt;strong&gt;barrier method&lt;/strong&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-01-03 Log barrier calculus</title>
   <link href="http://localhost:4000/contents/en/chapter15/15_01_03_log_barrier_calculus/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/15_01_03_log_barrier_calculus</id>
   <content type="html">&lt;p&gt;The gradient and Hessian of the log barrier function are as follows.&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\phi(x) = - \sum_{i=1}^{m} \log(-h_i(x))
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Gradient:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\nabla \phi(x) = - \sum_{i=1}^{m} \frac{1}{h_i(x)} \nabla h_i(x)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hessian:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\nabla^2 \phi(x) = \sum_{i=1}^{m} \frac{1}{h_i(x)^2} \nabla h_i(x) \nabla h_i(x)^T -  \sum_{i=1}^{m} \frac{1}{h_i(x)} \nabla^2 h_i(x)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;example-phix---sum_i1n-logx_i&quot;&gt;Example: \(\phi(x) = -\sum_{i=1}^{n} \log(x_i)\)&lt;/h2&gt;
&lt;p&gt;If we compute the gradient and Hessian for the barrier function \(\phi(x) = -\sum_{i=1}^{n} \log(-x_i)\), we get the following results.&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\phi(x) = -\sum_{i=1}^{n} \log(x_i)
\end{align}
Therefore, \(h_i(x) =  -x_i\) and \(x_i \ge 0\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Gradient:&lt;/p&gt;
&lt;blockquote&gt;

\[\nabla \phi(x) = - 
\begin{bmatrix}
1/x_1 \\\
\vdots \\\
1/x_n \\\
\end{bmatrix}
 = -X^{-1} \mathbb{1}, \qquad X = \text{diag}(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Hessian :&lt;/p&gt;
&lt;blockquote&gt;

\[\nabla^2 \phi(x) = 
\begin{bmatrix}
1/x_1^2 &amp;amp; \cdots &amp;amp; \\\
\vdots &amp;amp; \ddots &amp;amp; \vdots  \\\
&amp;amp; \cdots &amp;amp; 1/x_n^2 \\\
\end{bmatrix}
 = X^{-2}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>15-01-02 Log barrier function & barrier method</title>
   <link href="http://localhost:4000/contents/en/chapter15/15_01_02_log_barrier_function_and_barrier_method/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/15_01_02_log_barrier_function_and_barrier_method</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Before introducing the barrier method, let’s first see how the indicator function can be approximated by a barrier function.&lt;/p&gt;

&lt;h2 id=&quot;approximation-of-indicator-function&quot;&gt;Approximation of indicator function&lt;/h2&gt;
&lt;p&gt;In the following figure, you can see the indicator function and the barrier function. The dotted line is the indicator function \(I_C\), and the solid lines are the barrier function \(\phi(x) = -1/t\log(-x)\) for \(t = 0.5, 1, 2\). The barrier function smoothly approximates the indicator function, and when \(t=2\), it provides the best approximation.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter15/15_barrier_function_01.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig 1] barrier function }\phi(x) = -1/t\log(-x) [1]$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;logarithmic-barrier-function&quot;&gt;Logarithmic barrier function&lt;/h2&gt;
&lt;p&gt;Suppose \(h_1, \cdots , h_m : \mathbb{R}^n \to \mathbb{R}\) are convex and twice differentiable. For the set \(\{x : h_i(x) \lt 0, i = 1, \cdots , m \}\), the following function is called the logarithmic barrier function.&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\phi(x) = - \sum_{i=1}^{m} \log(-h_i(x))
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, the set is assumed to be the interior of the feasible set \(C\) and is non-empty.&lt;/p&gt;

&lt;h2 id=&quot;barrier-method&quot;&gt;Barrier method&lt;/h2&gt;

&lt;p&gt;Using the barrier function, the original problem can be approximated as follows. Here, \(t\gt 0\).&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x}           &amp;amp;&amp;amp; f(x) + \frac{1}{t} \phi(x) &amp;amp; \qquad      &amp;amp; \min_{x} &amp;amp;&amp;amp; tf(x) + \phi(x) \\
&amp;amp;\text{subject to } &amp;amp;&amp;amp; Ax = b                     &amp;amp; \iff \qquad &amp;amp; \text{subject to } &amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The method of solving the problem defined in this way using Newton’s method is called the &lt;strong&gt;barrier method&lt;/strong&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>15-01-01 Inequality constrained minimization problems</title>
   <link href="http://localhost:4000/contents/en/chapter15/15_01_01_inequality_constrained_minimization_problems/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter15/15_01_01_inequality_constrained_minimization_problems</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Let’s consider the following convex optimization problem.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;\min_{x}           &amp;amp;&amp;amp; f(x) \\ 
&amp;amp;\text{subject to } &amp;amp;&amp;amp; Ax = b \\
                    &amp;amp;&amp;amp;&amp;amp; h_{i}(x) \leq 0, i = 1, \dotsc, m
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In problems that include inequalities like this, it is difficult to distinguish between binding and non-binding constraints, especially at the boundary of the feasible region. Binding constraints refer to the constraints that affect the solution.&lt;/p&gt;

&lt;p&gt;Therefore, the &lt;strong&gt;interior method&lt;/strong&gt; is an approach that tries to solve the problem from the interior of the feasible region, not at the boundary.&lt;/p&gt;

&lt;h2 id=&quot;background-of-interior-method&quot;&gt;Background of interior method&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;interior method&lt;/strong&gt; for general problems was proposed in the 1960s by Anthony V. Fiacco and Garth P. McCormick. At the time, it was overshadowed by popular methods like sequential quadratic programming and the active set method, and only gained attention in the 1980s.&lt;/p&gt;

&lt;p&gt;The active set method is a theory for determining which constraints affect the optimization result. In the active set method, a constraint is considered active if it is zero, and such constraints are called the active set. However, to find the active set, you need to compute the boundary of the feasible region, and as the number of constraints increases, the computational cost increases.&lt;/p&gt;

&lt;p&gt;Recognizing these issues, the interior point method was developed to solve problems from the interior rather than the boundary. For example, in LP, if there are \(m\) constraints, calculating the boundary requires \(O(m^2)\) computations, but with the interior method, even for large \(m\), the solution can be found within 20–30 Newton steps. More details on performance will be discussed later.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Interior-point_method&quot;&gt;Interior point method&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Active_set_method&quot;&gt;Active set method&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reducing-equality-constrained-minimization-problem&quot;&gt;Reducing equality constrained minimization problem&lt;/h2&gt;
&lt;p&gt;The above problem can be rewritten as \(C := \{x : h_i(x) \le 0, i = 1, \cdots , m \}\). Inequality constraints can be included in the objective function as an indicator function.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} \ &amp;amp;&amp;amp; f(x) + I_C(x) \\
&amp;amp;\text{subject to }\  &amp;amp;&amp;amp; Ax = b \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In this way, the problem can be transformed into an equality constrained minimization problem. However, since the indicator function still includes the boundary, it still has the difficulty of boundary computation from the original problem, and since it is not differentiable, it is difficult to apply Newton’s method.&lt;/p&gt;

&lt;p&gt;What if we approximate the indicator function \(I_C\) with a &lt;strong&gt;barrier function&lt;/strong&gt;? In that case, the boundary would not be included and since it is differentiable, Newton’s method can be applied.&lt;/p&gt;

&lt;p&gt;The method of solving problems redefined with barrier functions in this way is called the barrier method, which is introduced in detail in the next section.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-05 References</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_05_References/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_05_References</id>
   <content type="html">&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;S. Boyd, N. Parikh, E. Chu, B. Peleato and J. Eckstein (2010), “Distributed optimization and statistical learning via the alternating direction method of multipliers”&lt;/li&gt;
  &lt;li&gt;W. Deng and W. Yin (2012), “On the global and linear convergence of the generalized alternating direction method of multipliers”&lt;/li&gt;
  &lt;li&gt;M. Hong and Z. Luo (2012), “On  the linear convergence of the alternating direction  method of multipliers”&lt;/li&gt;
  &lt;li&gt;F. lutzeler, P. Bianchi, Ph. Ciblat, and W. Hachem (2014), “Linear convergence rate for distributed optimization with the alternating direction method of multipliers”&lt;/li&gt;
  &lt;li&gt;R. Nishihara, L. Lessard, B.  Recht, A. Packard, and M. Jordan (2015), “A general analysis of the convergence of ADMM”&lt;/li&gt;
  &lt;li&gt;L. Vandenberghe, Lecture Notes for EE 236C, UCLA, Spring 2011-2012&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>20-04-04 Example - Alternating Projection</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_04_04_Example-_Alternating_Projection/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_04_04_Example:_Alternating_Projection</id>
   <content type="html">&lt;h1 id=&quot;example-alternating-projection&quot;&gt;Example: Alternating Projection&lt;/h1&gt;

&lt;p&gt;Consider the problem of finding a point in the intersection of convex sets \(C, D \in \mathbb{R}^n\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_x I_C(x) + I_D(x)  &lt;br /&gt;
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;where \(I_C(x)\) and \(I_D(x)\) are indicator functions for sets \(C\) and \(D\) respectively.&lt;/p&gt;

&lt;p&gt;To reformulate this problem in ADMM form, we express it as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{equation}
\min_{x,z} I_C(x) + I_D(x) \quad \text{subject to} \quad x - z = 0   
\end{equation}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-algorithm-for-alternating-projection&quot;&gt;ADMM Algorithm for Alternating Projection&lt;/h2&gt;

&lt;p&gt;Each ADMM cycle involves two projections:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; = P_C \left( z^{(k-1)} - w^{(k-1)} \right) \\
z^{(k)} &amp;amp; = P_D \left( x^{(k)} + w^{(k-1)} \right) \\
w^{(k)} &amp;amp; = w^{(k-1)} + x^{(k)} - z^{(k)}
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(P_C\) and \(P_D\) denote the projection operators onto sets \(C\) and \(D\) respectively.&lt;/p&gt;

&lt;h2 id=&quot;derivation&quot;&gt;Derivation&lt;/h2&gt;

&lt;p&gt;The update for \(x^{(k)}\) is derived as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; = \arg\min_x I_C(x) + \frac{\rho}{2} \lVert x - z^{(k-1)} + w^{(k-1)} \rVert_2^2 \\
&amp;amp; = P_C \left( z^{(k-1)} - w^{(k-1)} \right)
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Similarly, the update for \(z^{(k)}\) is derived as:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
z^{(k)} &amp;amp; = \arg\min_z I_D(z) + \frac{\rho}{2} \lVert x^{(k)} - z + w^{(k-1)} \rVert_2^2 \\
&amp;amp; = P_D \left( x^{(k)} + w^{(k-1)} \right)
\end{alignat}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;comparison-with-classical-method&quot;&gt;Comparison with Classical Method&lt;/h2&gt;

&lt;p&gt;This method is similar to the classical alternating projection method but is often more efficient and robust in practice.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-04-03 ADMM in Scaled Form</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_04_03_ADMM_in_Scaled_Form/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_04_03_ADMM_in_Scaled_Form</id>
   <content type="html">&lt;h1 id=&quot;admm-in-scaled-form&quot;&gt;ADMM in Scaled Form&lt;/h1&gt;

&lt;p&gt;ADMM can be expressed in scaled form by substituting the dual variable \(u\) with \(w = u/\rho\). The ADMM steps can then be written as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; = \arg\min_x f(x) + \frac{\rho}{2} \lVert Ax + Bz^{(k-1)} - c + w^{(k-1)} \rVert_2^2  \\
z^{(k)} &amp;amp; = \arg\min_z g(x) + \frac{\rho}{2} \lVert Ax^{(k)} + Bz - c + w^{(k-1)} \rVert_2^2  \\
w^{(k)} &amp;amp; = w^{(k-1)} + Ax^{(k)} + Bz^{(k)} - c 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;equivalence-to-original-form&quot;&gt;Equivalence to Original Form&lt;/h2&gt;

&lt;p&gt;We can show that the above equations are equivalent to the original form through the following process:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x^{(k)} &amp;amp; = \arg\min_x f(x) + \frac{\rho}{2} \lVert Ax + Bz^{(k-1)} - c + w^{(k-1)} \rVert_2^2  \\
&amp;amp; = \arg\min_x f(x)  + \frac{\rho}{2} \lVert Ax + Bz^{(k-1)} - c \rVert_2^2  + \rho w^{(k-1)T} (Ax + Bz^{(k-1)} - c)  + \frac{\rho}{2}\lVert w^{(k-1)} \rVert_2^2 \\
&amp;amp; = \arg\min_x f(x)  + \frac{\rho}{2} \lVert Ax + Bz^{(k-1)} - c \rVert_2^2  + u^{(k-1)T} (Ax + Bz^{(k-1)} - c) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where we used \(u^{(k-1)} = \rho w^{(k-1)}\) and dropped the constant term.&lt;/p&gt;

&lt;h2 id=&quot;interpretation-of-scaled-variable&quot;&gt;Interpretation of Scaled Variable&lt;/h2&gt;

&lt;p&gt;Here, \(w^{(k)}\) can be viewed as the sum of residuals up to iteration \(k\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{equation}
w^{(k)} = w^{(0)} + \sum_{i=1}^k (Ax^{(i)} + Bz^{(i)} - c) 
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;This scaled form is often more convenient for implementation and analysis.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-04-02 Convergence Guarantee</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_04_02_Converegence_Guarantee/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_04_02_Converegence_Guarantee</id>
   <content type="html">&lt;h1 id=&quot;convergence-guarantee-for-admm&quot;&gt;Convergence Guarantee for ADMM&lt;/h1&gt;

&lt;p&gt;Under appropriate conditions on \(f\) and \(g\) (note that \(A\) and \(B\) do not need to be full rank), ADMM satisfies the following for all \(\rho &amp;gt; 0\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Residual convergence&lt;/strong&gt;: As \(k \to \infty\), \(r^{(k)} = Ax^{(k)} + Bz^{(k)} - c \to 0\), meaning the primal iterates approach feasibility.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Objective convergence&lt;/strong&gt;: \(f(x^{(k)}) + g(z^{(k)}) \to f^{\ast} + g^{\ast}\), where \(f^{\ast} + g^{\ast}\) is the optimal primal objective value.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dual convergence&lt;/strong&gt;: \(u^{(k)} \to u^{\ast}\), where \(u^{\ast}\) is the dual solution.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The exact convergence rate is not yet fully understood, and much research is currently ongoing in this area. Roughly speaking, ADMM performs similarly to or slightly better than first-order methods.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-04-01 ADMM</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_04_01_ADMM/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_04_01_ADMM</id>
   <content type="html">&lt;h1 id=&quot;alternating-direction-method-of-multipliers-admm&quot;&gt;Alternating Direction Method of Multipliers (ADMM)&lt;/h1&gt;

&lt;p&gt;The &lt;strong&gt;Alternating Direction Method of Multipliers (ADMM)&lt;/strong&gt; is a powerful optimization algorithm that combines the benefits of dual decomposition and the method of multipliers. It is particularly effective for solving convex optimization problems that can be decomposed into smaller, more manageable subproblems.&lt;/p&gt;

&lt;p&gt;Consider the following problem:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_{x,z} f(x) + g(z) \quad \text{subject to} \quad Ax + Bz = c
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As before, we can augment the objective function as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_{x,z} f(x) + g(z) + \frac{\rho}{2} \lVert Ax + Bz - c \rVert_2^2 \quad \text{subject to} \quad Ax + Bz = c
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;where \(\rho &amp;gt; 0\) is the penalty parameter.&lt;/p&gt;

&lt;h2 id=&quot;augmented-lagrangian&quot;&gt;Augmented Lagrangian&lt;/h2&gt;

&lt;p&gt;The augmented Lagrangian can be defined as:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
L_{\rho} (x,z,u) = f(x) + g(z) + u^T(Ax + Bz - c) + \frac{\rho}{2} \lVert Ax + Bz - c \rVert_2^2
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-algorithm&quot;&gt;ADMM Algorithm&lt;/h2&gt;

&lt;p&gt;ADMM performs the following iterative steps for \(k=1,2,3,\ldots\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; = \arg\min_x  L_{\rho} (x,z^{(k-1)},u^{(k-1)}) \\
z^{(k)} &amp;amp; = \arg\min_z  L_{\rho} (x^{(k)},z,u^{(k-1)}) \\
u^{(k)} &amp;amp; = u^{(k-1)} + \rho (Ax^{(k)} + Bz^{(k)} - c) 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Key Point:&lt;/strong&gt; It is crucial that \(x^{(k)}\) obtained from the first step is used in the second step to compute \(z^{(k)}\). This alternating update structure is essential for convergence.&lt;/p&gt;

&lt;h2 id=&quot;comparison-with-method-of-multipliers&quot;&gt;Comparison with Method of Multipliers&lt;/h2&gt;

&lt;p&gt;Note that in the general &lt;strong&gt;Method of Multipliers&lt;/strong&gt;, the first two steps are replaced by the following joint minimization:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
(x^{(k)}, z^{(k)}) = \arg\min_{x,z} L_{\rho} (x,z,u^{(k-1)})   &lt;br /&gt;
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The key advantage of ADMM is that it decomposes this joint minimization into two separate, simpler subproblems that can often be solved more efficiently or even in closed form.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-04 A peak at ADMM</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_04_00_A_peak_at_ADMM/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_04_00_A_peak_at_ADMM</id>
   <content type="html">&lt;h2 id=&quot;lipschitz-gradients-and-strong-convexity&quot;&gt;Lipschitz gradients and strong convexity&lt;/h2&gt;
&lt;p&gt;In this section, we examine an overview of the Alternating Direction Method of Multipliers (ADMM) technique. While the augmented Lagrangian method previously did not provide decomposability, ADMM is a method that provides decomposability along with convergence properties.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-03 Augmented Lagrangians</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_03_Augmented_Lagrangians/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_03_Augmented_Lagrangians</id>
   <content type="html">&lt;p&gt;Dual ascent의 단점은 convergence을 보장하기 for, 강한 condition,이 필요하다는 것이다. (convergence을 보장하려면 \(f\)가 strongly convexsolution야 했다.) 이런 단점은 &lt;strong&gt;Augmented Lagrangian method&lt;/strong&gt; (or, &lt;strong&gt;Method of multipliers&lt;/strong&gt;)by, 개선될 수 있다.&lt;/p&gt;

&lt;p&gt;Primal problem를 아래and, 같이 transformation한다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_x f(x) + \frac{\rho}{2} \lVert Ax - b \rVert _2^2 \quad \text{ subject to } \quad Ax = b
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\rho &amp;gt; 0\)이다. \(A\)가 full column rank를 갖는다면 목적식은 strongly convex하다. 이는 원래의 problemand, 정확히 동일한 problem가 된다. (Augmented term인 \(Ax - b\)는 0이 되기 because,이다.)&lt;/p&gt;

&lt;h2 id=&quot;augmented-lagrangian-method&quot;&gt;Augmented Lagrangian Method&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Dual gradient ascent&lt;/strong&gt; : \(k=1,2,3,\dots\)about, 다음을 iteration한다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; \in \arg\min_x f(x) + (u^{(k-1)})^T A x + \frac{\rho}{2} \lVert Ax - b \rVert_2^2  \\
u^{(k)} &amp;amp; = u^{(k-1)} + \rho (A x^{(k)} - b)
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;위 dual algorithmat, \(\rho\)는 step size 역할을 한다, that is, \(t_k=\rho\)이다. 이것은 next,서 그 reason,를 알 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;rho가-step-size일-when-optimality-증명&quot;&gt;\(\rho\)가 step size일 when, optimality 증명&lt;/h3&gt;

&lt;p&gt;\(x^{(k)}\)는 \(f(x) + (u^{(k-1)})^T Ax + \frac{\rho}{2} \lVert Ax - b\rVert _2^2\) 를 minimization하므to,, 
원래 primal problemto, about, stationary condition,according to,, \(x^{(k)}\)at, 목적식의 subgradient가 아래and, 같이 \(0\)을 포함solution야 한다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
0 &amp;amp; \in \partial f(x^{(k)}) + A^T (u^{(k-1)}) + \rho (A x^{(k)} -b))  \\
  &amp;amp; = \partial f(x^{(k)}) + A^T u^{(k)}
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;위식at,, \(u^{(k)} = u^{(k-1)} + \rho (A x^{(k)} - b)\)to, 동작하게 되면, 적당한 condition,하at, \(Ax^{(k)}-b\)가 \(0\)with, 가까워지면서 feasible한 solution를 제공하기 시작하고, 궁극적with, KKT condition,이 만족되고, \(x^{(k)}\)and, \(u^{(k)}\)가 optimalityto, 근접함을 보일 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Augmented Lagrangian method&lt;/strong&gt;의 장점은 훨씬 좋은 convergence성을 갖는다는 것이고, 단점은 problem를 분solution할 수 있는 decomposability를 잃는다는 것이다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-02-02 Dual Decomposition with Inequality Constraint</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_02_02_Dual_Decomposition_with_Inequality_Constraint/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_02_02_Dual_Decomposition_with_Inequality_Constraint</id>
   <content type="html">&lt;p&gt;다음의 problem를 생각solution 보자. 앞의 problemand, 다른점은 제약식이 부등식의 relationship,를 갖는 것이다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{equation}
\min_x \sum_{i=1}^B f_i(x_i) \quad \text{subject to} \quad \sum_{i=1}^B A_i x_i \leq b
\end{equation}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;dual-decomposition-projected-subgradient-method&quot;&gt;Dual decomposition (projected subgradient method)&lt;/h2&gt;
&lt;p&gt;위 problemat,는 dual variable가 always, \(0\)보다 같거나 커야 한다, that is, \(u \geq 0\). therefore,, 다음 스텝의 \(u\)값을 computation할 when,, \(0\)보다 큰 범위안with, projection을 시켜서 업데이트를 한다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
x_i^{(k)} &amp;amp; \in \arg \min_{x_i} f_i(x_i) + (u^{(k-1)})^T A_i x_i, \quad i=1,\dots,B  \\
u^{(k)}   &amp;amp; = u^{(k-1)} + t_k \left(\sum_{i=1}^B A_i x_i^{(k)} - b \right)_+
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서, \(u_{+}\)는 0보다 큰 \(u\)를 의미한다, that is,, \((u_+)_i = \max \left\{0,u_i \right\}, i=1,\dots,m\). 
위  process을 \(k=1,2,3,\dots\)about,서 iteration한다.&lt;/p&gt;

&lt;h3 id=&quot;price-coordination-interpretation&quot;&gt;Price coordination interpretation&lt;/h3&gt;
&lt;p&gt;generally, dual decomposition problem들은 price coordination 관점at, as follows: solution석될 수 있다. (Vandenberghe)&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;\(B\)개의 독립적인 유닛이 있고, 각 유닛은 자신의 결정 variable \(x_i\)를 결정한다.&lt;/li&gt;
    &lt;li&gt;각 constraint은 \(B\)개의 유닛이 공유하고 있는 자원to, about, 제약을 의미하며, dual variable \(u_j\)는 자원 \(j\)의 가격을 의미한다.&lt;/li&gt;
    &lt;li&gt;Dual variable는 아래and, 같이 업데이트되며
 \begin{equation}
 u_j^{+} = (u_j - t s_j)_{+}, \quad  j=1,\dots,m
 \end{equation}&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;\(\quad\) 여기서, \(s=b-\sum_{i=1}^B A_ix_i\)는 슬랙 variableto,써 &lt;br /&gt;
\(\qquad\) - \(s_j &amp;lt; 0\)이면, 자원 \(j\)가 over-utilized 되고 있다는 의미이고, therefore,, price \(u_j\)를 증가시킨다 &lt;br /&gt;
\(\qquad\) - \(s_j &amp;gt; 0\)이면, 자원 \(j\)가 under-utilized되고 있다는 의미이고,  therefore,, price \(u_j\)를 감소시킨다 &lt;br /&gt;
\(\qquad\) - price는 향image 음수가 되지 않도록 한다.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>20-02-01 Dual Decomposition with Equality Constraint</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_02_01_Dual_Decomposition_with_Equality_Constraint/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_02_01_Dual_Decomposition_with_Equality_Constraint</id>
   <content type="html">&lt;p&gt;다음의 problem를 보자.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_x \sum_{i=1}^B f_i(x_i) \quad \text{ subject to } \quad Ax = b
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;if,, variable \(x\)를 \(B\)개의 블록with, 분할하고, \(x = (x_1,\dots,x_B) \in \mathbb{R}^n, \text{ where } x_i \in \mathbb{R}^{n_i}\), matrix \(A\) 역시 \(B\)개의 sub-matrix 블록with, as follows: 분할하면, \(A = [A_1, \dots, A_B], \text{ where } A_i \in \mathbb{R}^{m \times n_i}\), 위 minimization problem는 as follows: \(B\)개의 분리된 problemto, 분solution될 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
&amp;amp; \quad x^+ \in \arg\min_x \sum_{i=1}^B f_i(x_i) + u^T Ax  \\
\Longleftrightarrow &amp;amp; \quad x_i^+ \in \arg\min_{x_i} f_i(x_i) + u^T A_ix_i, \quad i=1,\dots, B
\end{alignat}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;dual-decomposition-algorithm&quot;&gt;Dual decomposition algorithm:&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
x_i^{(k)} &amp;amp; \in \arg \min_{x_i} f_i(x_i) + (u^{(k-1)})^T A_i x_i, \quad i=1,\dots,B  \\
u^{(k)}   &amp;amp; = u^{(k-1)} + t_k \left(\sum_{i=1}^B A_i x_i^{(k)} - b \right)
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;위 두 step는 아래and, 같이 solution석할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;첫번째 수식은 broadcast stepto,서, \(B\)개의 프to,세서의 각각to,게 \(u\)를 보낸다. and,, 프to,세서 각각은 병렬to, 자신의 최적 \(x_i\)를 찾는다.&lt;/li&gt;
    &lt;li&gt;두번째 수식은 gather stepto,서, 각 프to,세서from, \(A_i x_i\)를 모은다. and, global dual variable \(u\)를 업데이트 한다.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;위 두 step는 \(k=1,2,3,\dots\)about, 계속 iteration한다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter20/decomposition.png&quot; alt=&quot;[Fig 1] Broadcast and Gather&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Broadcast and Gather&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>20-02 Dual Decomposition</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_02_00_Dual_Decomposition/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_02_00_Dual_Decomposition</id>
   <content type="html">&lt;p&gt;In this section, we examine techniques for decomposing problems using duality.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-01-01 Convergence Analysis</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_01_01_Convergence_Analysis/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_01_01_Convergence_Analysis</id>
   <content type="html">&lt;h2 id=&quot;lipschitz-gradients-and-strong-convexity&quot;&gt;Lipschitz gradients and strong convexity&lt;/h2&gt;
&lt;p&gt;Let’s assume \(f\) is a closed convex function. Then the following equivalence relationship holds.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\text{\(f\) is strongly convex with parameter \(d\) \(\Longleftrightarrow \nabla f^{\ast}\) Lipschitz with parameter \(1/d\).} 
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;
&lt;p&gt;if, \(g\)가 strongly convex하고 \(x\)at, minimize된다고 하면 다음 relationship,가 성립한다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
g(y) \geq g(x) + \frac{d}{2}\lVert y-x \rVert_2^2, \text{ for all } y
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;우선, \(g(x) = f(x) − u^T x\)를 minimization하는 \(x_u = \nabla f^{\ast}(u)\)and, \(g(x) = f(x) − v^T x\)를 minimization하는 \(x_v = \nabla f^{\ast}(v)\)가 있다고 하자.&lt;/p&gt;

&lt;p&gt;그러면, 위 식으from, 다음 두 부등식을 얻을 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
f(x_v) - u^Tx_v \geq f(x_u) - u^T x_u + \frac{d}{2} \lVert x_u - x_v \rVert_2^2 \\
f(x_u) - v^Tx_u \geq f(x_v) - v^T x_v + \frac{d}{2} \lVert x_u - x_v \rVert_2^2 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;위 두 식을 더하면 다음and, 같은 식을 얻을 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
f(x_v) - u^Tx_v + f(x_u) - v^Tx_u \geq f(x_u) - u^T x_u +  f(x_v) - v^T x_v + d \lVert x_u - x_v \rVert_2^2.&lt;br /&gt;
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 식을 재정렬 후 Cauchy-Schwartz를 적용하면 as follows: 정리된다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
d \lVert x_u - x_v \rVert_2^2 &amp;amp; \leq - u^Tx_v - v^Tx_u + u^T x_u + v^T x_v \\\\
&amp;amp; = (u-v)^T(x_u - x_v) \\\\
&amp;amp; \leq \lVert u-v \rVert_2 \lVert x_u - x_v \rVert_2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;therefore,, 다음and, 같은 relationship,를 확인할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
\[\lVert x_u - x_v \rVert_2 \leq \frac{1}{d} \lVert u-v \rVert_2\]
&lt;/blockquote&gt;

&lt;p&gt;이to,써 \(\nabla f^{\ast}\) Lipschitz with parameter \(1/d\)이 증명되었다.&lt;/p&gt;

&lt;h2 id=&quot;convergence-guarantees&quot;&gt;Convergence guarantees&lt;/h2&gt;
&lt;p&gt;위 result,and, gradient descent를 combining,, dual objective의 optimal solutionto,의 convergence성을 as follows: 설명할 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;if, \(f\)가 파라미터 \(d\)to, strongly convex 하면, step size \(t_k=d (k=1,2,3, \dots\))about,서, dual gradient ascent는 \(O(1/\epsilon)\)with, converge한다.&lt;/li&gt;
  &lt;li&gt;if, \(f\)가 파라미터 \(d\)to, strongly convex 하고, \(\nabla f\)는 파라미터 \(L\)to, Lipschitz하면, step size \(t_k=2/(1/d + 1/L)\) (\(k=1,2,3, \dots\))about,서, dual gradient ascent는 \(O(\log(1/\epsilon))\)with, converge한다. (linear convergence)&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>20-01 Dual (sub)gradient methods</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_01_00_Dual_(sub)gradient_methods/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_01_00_Dual_(sub)gradient_methods</id>
   <content type="html">&lt;p&gt;Even in cases where we cannot find a dual (conjugate) in closed-form, we can use subgradient or gradient methods based on the dual.&lt;/p&gt;

&lt;p&gt;For example, consider the following problem.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_x f(x) \text{ subject to } Ax = b
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The dual problem of the above problem is as follows. Here \(f^{\ast}\) is the conjugate of \(f\).&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\max_u -f^{\ast}(-A^T u) - b^T u
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this case, if we define \(g(u)\) as \(-f^{\ast}(-A^Tu)-b^Tu\), then the subgradient of \(g(u)\) is as follows.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\partial g(u) = A \partial f^{\ast}(-A^Tu) - b
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the above expression, \(\partial f^{\ast}(-A^Tu)\) can be expressed in terms of \(x\) as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\partial g(u) = Ax-b \quad \text{where} \quad x \in \arg\min_z f(z) + u^T A z
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;dual-subgradient-method&quot;&gt;Dual subgradient method&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Dual subgradient method&lt;/strong&gt;는 dual problem의 목적식을 maximization하기 for, 시작점 \(u^{(0)}\)at, 시작solution서 \(k=1,2,3,\dots\)about, 다음 step를 iteration한다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; \in \arg \min_x f(x) + ({u^{(k-1)}})^T A x  \\
u^{(k)} &amp;amp; = u^{(k-1)} + t_k (A x^{(k)} - b) 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 step size \(t_k(k=1,2,3,\dots\))는 표준적인 방식with, 선택된다.&lt;/p&gt;

&lt;h3 id=&quot;strictly-convex인-case&quot;&gt;Strictly Convex인 case,&lt;/h3&gt;
&lt;p&gt;if, \(f\)가 strictly convex라면 \(f^{\ast}\)는 미분가능solution진다.&lt;/p&gt;

&lt;p&gt;therefore,, algorithm은 \(k=1,2,3,\dots\)about, 다음 step를 iteration하는 &lt;strong&gt;dual gradient ascent&lt;/strong&gt;가 된다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; = \arg \min_x f(x) + ({u^{(k-1)}})^T A x  \\
u^{(k)} &amp;amp; = u^{(k-1)} + t_k (A x^{(k)}-b) 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;before, 방식and, 다른 점은 \(x^{(k)}\)가 유일하다는 것이다. (\(\text{argmin}\)and,의 relationship,가 \(=\) relationship,임을 confirming,보라.)&lt;/p&gt;

&lt;p&gt;여기서 step size \(t_k(k=1,2,3,\dots\))도 표준적인 방식with, 선택되며 \(\text{argmin}\)을 수행할 when, proximal gradient나 acceleration도 평소처럼 적용할 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20 Dual Methods</title>
   <link href="http://localhost:4000/contents/vi/chapter20/20_00_Dual_Methods/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter20/20_00_Dual_Methods</id>
   <content type="html">&lt;p&gt;In this chapter, we will examine methods for solving problems using duality, including dual subgradient method, dual decomposition method, augmented Lagrangian method, and briefly introduce the concept of Alternating Direction Method of Multipliers (ADMM).&lt;/p&gt;

&lt;p&gt;First, we will briefly review the previously learned content on Proximal Newton method and Conjugate function.&lt;/p&gt;

&lt;h2 id=&quot;review-proximal-newton-method&quot;&gt;Review: proximal Newton method&lt;/h2&gt;
&lt;p&gt;Consider the following problem.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_x g(x) + h(x)
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, functions \(g\) and \(h\) are convex functions, where \(g\) is twice differentiable and \(h\) is simple.&lt;/p&gt;

&lt;p&gt;The Proximal Newton method starts with initial \(x^{(0)} \in \mathbb{R}^n\) and finds the optimal vector direction that is good for both functions \(g\) and \(h\) as follows&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{alignat}{1}
v^{(k)} &amp;amp; = \arg \min_v g({x^{(k-1)}})^T v +  \frac{1}{2} v^T \nabla^2 g(x^{(k-1)}) v + h(x^{(k-1)} + v) 
\end{alignat}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Using the direction found above, we update the next \(x^{(k)}\) as follows.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
x^{(k)} = x^{(k-1)} + t_k v^{(k)}, k=1,2,3,\dots 
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, \(t_k\) is the step size determined by backtracking.&lt;/p&gt;

&lt;p&gt;We execute the above two processes iteratively.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;The above iteration is very expensive (computing \(v^{(k)}\) is generally very difficult)&lt;/li&gt;
    &lt;li&gt;However, under appropriate conditions, very few iterations are required to converge, and it has a convergence rate of local quadratic convergence&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;review-conjugate-function&quot;&gt;Review: conjugate function&lt;/h2&gt;
&lt;p&gt;For \(f: \mathbb{R}^n \to \mathbb{R}\), the conjugate function is defined as follows.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
f^*(y) = \max_x y^Tx - f(x)
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(1) The conjugate function can be written as follows, and this is a form that frequently appears in dual problems.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
-f^{\ast}(y) = \min_x f(x) - y^Tx
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(2) If \(f\) is closed and convex, then \(f^{**} = f\). Also,&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
x \in \partial f^{\ast}(y) \Longleftrightarrow y \in \partial f(x) \Longleftrightarrow x \in \arg\min_z f(z) - y^Tz
\end{equation}&lt;/p&gt;
  &lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;
  &lt;p&gt;first,, \(x \in \partial f^{\ast}(y) \Longleftrightarrow y \in \partial f(x)\)을 증명한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;1step--x-in-partial-fasty-longleftarrow-y-in-partial-fx&quot;&gt;1step : \(x \in \partial f^{\ast}(y) \Longleftarrow y \in \partial f(x)\)&lt;/h3&gt;
&lt;blockquote&gt;

  &lt;p&gt;\(y \in \partial f(x)\)를 let’s assume. 그러면, \(x\)는 \(y^Tz - f(z)\)를 최대to, 하게 하는 \(z\)들의 set \(M_y\) to, 속하게 된다, that is, \(x \in M_y\). &lt;br /&gt; however,, \(f^{\ast}(y)=   \max_z y^Tz - f(z)\) 이고, \(\partial f^{\ast}(y)=\text{cl} \left( \text{conv} \left( \bigcup_{z \in M_y} \left\{ z \right\} \right) \right)\). therefore,, \(x \in \partial f^{\ast}(y)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;2step--x-in-partial-fasty-longrightarrow-y-in-partial-fx&quot;&gt;2step : \(x \in \partial f^{\ast}(y) \Longrightarrow y \in \partial f(x)\)&lt;/h3&gt;
&lt;blockquote&gt;

  &lt;p&gt;위at, 보인것and, 같이, if,, \(x \in  \partial f^{\ast}(y)\) 이면, \(y \in \partial f^{\ast\ast}(x)\). 여기서, \(f^{\ast\ast}(x)=f\) 이므to, \(y \in \partial f(x)\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위 1, 2 step를 through,, \(x \in \partial f^{\ast}(y) \Longleftrightarrow y \in \partial f(x)\)이 증명되었다.&lt;/p&gt;
&lt;h3 id=&quot;3step--x-in-partial-fasty-longleftrightarrow-y-in-partial-fx-longleftrightarrow-x-in-argmin_z-fz---ytz&quot;&gt;3step : \(x \in \partial f^{\ast}(y) \Longleftrightarrow y \in \partial f(x) \Longleftrightarrow x \in \arg\min_z f(z) - y^Tz\)&lt;/h3&gt;
&lt;blockquote&gt;

  &lt;p&gt;한편, \(y \in \partial f(x) \Longleftrightarrow x \in \arg\min_z f(z) - y^Tz\)은 subgradient의 정의from, 자명한 in fact,이다.  &lt;br /&gt;
therefore,, 위 두 증명을 through,, \(x \in \partial f^{\ast}(y) \Longleftrightarrow y \in \partial f(x) \Longleftrightarrow x \in \arg\min_z f(z) - y^Tz\)임이 증명되었다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(3) if, \(f\)가 strictly convex이면,&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{equation}
\nabla f^{\ast}(y) = \arg\min_z f(z) - y^T z
\end{equation}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;proof-1&quot;&gt;Proof&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f\)가 strictly convex이면, \(f(z)-y^Tz\)는 최소값을 갖는 유일한 \(z\)가 존재하며, 
이것은 위 (2)to, about, 증명으from, \(\nabla f^{\ast}(y)\)이어야 한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;다시 말하면 \(f\)가 strictly convex이면  \(f^{\ast}\)의 subgradient는 1개이며 gradient가 된다. therefore,,  \(f^{\ast}\)는 differentiable한 function이다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-05 References</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_05_References/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_05_References</id>
   <content type="html">&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;S. Boyd, N. Parikh, E. Chu, B. Peleato and J. Eckstein (2010), “Distributed optimization and statistical learning via the alternating direction method of multipliers”&lt;/li&gt;
  &lt;li&gt;W. Deng and W. Yin (2012), “On the global and linear convergence of the generalized alternating direction method of multipliers”&lt;/li&gt;
  &lt;li&gt;M. Hong and Z. Luo (2012), “On  the linear convergence of the alternating direction  method of multipliers”&lt;/li&gt;
  &lt;li&gt;F. lutzeler, P. Bianchi, Ph. Ciblat, and W. Hachem (2014), “Linear convergence rate for distributed optimization with the alternating direction method of multipliers”&lt;/li&gt;
  &lt;li&gt;R. Nishihara, L. Lessard, B.  Recht, A. Packard, and M. Jordan (2015), “A general analysis of the convergence of ADMM”&lt;/li&gt;
  &lt;li&gt;L. Vandenberghe, Lecture Notes for EE 236C, UCLA, Spring 2011-2012&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>20-04-04 Example - Alternating Projection</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_04_04_Example-_Alternating_Projection/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_04_04_Example:_Alternating_Projection</id>
   <content type="html">&lt;h1 id=&quot;example-alternating-projection&quot;&gt;Example: Alternating Projection&lt;/h1&gt;

&lt;p&gt;Consider the problem of finding a point in the intersection of convex sets \(C, D \in \mathbb{R}^n\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_x I_C(x) + I_D(x)  &lt;br /&gt;
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;where \(I_C(x)\) and \(I_D(x)\) are indicator functions for sets \(C\) and \(D\) respectively.&lt;/p&gt;

&lt;p&gt;To reformulate this problem in ADMM form, we express it as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{equation}
\min_{x,z} I_C(x) + I_D(x) \quad \text{subject to} \quad x - z = 0   
\end{equation}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-algorithm-for-alternating-projection&quot;&gt;ADMM Algorithm for Alternating Projection&lt;/h2&gt;

&lt;p&gt;Each ADMM cycle involves two projections:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; = P_C \left( z^{(k-1)} - w^{(k-1)} \right) \\
z^{(k)} &amp;amp; = P_D \left( x^{(k)} + w^{(k-1)} \right) \\
w^{(k)} &amp;amp; = w^{(k-1)} + x^{(k)} - z^{(k)}
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(P_C\) and \(P_D\) denote the projection operators onto sets \(C\) and \(D\) respectively.&lt;/p&gt;

&lt;h2 id=&quot;derivation&quot;&gt;Derivation&lt;/h2&gt;

&lt;p&gt;The update for \(x^{(k)}\) is derived as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; = \arg\min_x I_C(x) + \frac{\rho}{2} \lVert x - z^{(k-1)} + w^{(k-1)} \rVert_2^2 \\
&amp;amp; = P_C \left( z^{(k-1)} - w^{(k-1)} \right)
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Similarly, the update for \(z^{(k)}\) is derived as:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
z^{(k)} &amp;amp; = \arg\min_z I_D(z) + \frac{\rho}{2} \lVert x^{(k)} - z + w^{(k-1)} \rVert_2^2 \\
&amp;amp; = P_D \left( x^{(k)} + w^{(k-1)} \right)
\end{alignat}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;comparison-with-classical-method&quot;&gt;Comparison with Classical Method&lt;/h2&gt;

&lt;p&gt;This method is similar to the classical alternating projection method but is often more efficient and robust in practice.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-04-03 ADMM in Scaled Form</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_04_03_ADMM_in_Scaled_Form/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_04_03_ADMM_in_Scaled_Form</id>
   <content type="html">&lt;h1 id=&quot;admm-in-scaled-form&quot;&gt;ADMM in Scaled Form&lt;/h1&gt;

&lt;p&gt;ADMM can be expressed in scaled form by substituting the dual variable \(u\) with \(w = u/\rho\). The ADMM steps can then be written as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; = \arg\min_x f(x) + \frac{\rho}{2} \lVert Ax + Bz^{(k-1)} - c + w^{(k-1)} \rVert_2^2  \\
z^{(k)} &amp;amp; = \arg\min_z g(x) + \frac{\rho}{2} \lVert Ax^{(k)} + Bz - c + w^{(k-1)} \rVert_2^2  \\
w^{(k)} &amp;amp; = w^{(k-1)} + Ax^{(k)} + Bz^{(k)} - c 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;equivalence-to-original-form&quot;&gt;Equivalence to Original Form&lt;/h2&gt;

&lt;p&gt;We can show that the above equations are equivalent to the original form through the following process:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x^{(k)} &amp;amp; = \arg\min_x f(x) + \frac{\rho}{2} \lVert Ax + Bz^{(k-1)} - c + w^{(k-1)} \rVert_2^2  \\
&amp;amp; = \arg\min_x f(x)  + \frac{\rho}{2} \lVert Ax + Bz^{(k-1)} - c \rVert_2^2  + \rho w^{(k-1)T} (Ax + Bz^{(k-1)} - c)  + \frac{\rho}{2}\lVert w^{(k-1)} \rVert_2^2 \\
&amp;amp; = \arg\min_x f(x)  + \frac{\rho}{2} \lVert Ax + Bz^{(k-1)} - c \rVert_2^2  + u^{(k-1)T} (Ax + Bz^{(k-1)} - c) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;where we used \(u^{(k-1)} = \rho w^{(k-1)}\) and dropped the constant term.&lt;/p&gt;

&lt;h2 id=&quot;interpretation-of-scaled-variable&quot;&gt;Interpretation of Scaled Variable&lt;/h2&gt;

&lt;p&gt;Here, \(w^{(k)}\) can be viewed as the sum of residuals up to iteration \(k\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{equation}
w^{(k)} = w^{(0)} + \sum_{i=1}^k (Ax^{(i)} + Bz^{(i)} - c) 
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;This scaled form is often more convenient for implementation and analysis.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-04-02 Convergence Guarantee</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_04_02_Converegence_Guarantee/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_04_02_Converegence_Guarantee</id>
   <content type="html">&lt;h1 id=&quot;convergence-guarantee-for-admm&quot;&gt;Convergence Guarantee for ADMM&lt;/h1&gt;

&lt;p&gt;Under appropriate conditions on \(f\) and \(g\) (note that \(A\) and \(B\) do not need to be full rank), ADMM satisfies the following for all \(\rho &amp;gt; 0\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Residual convergence&lt;/strong&gt;: As \(k \to \infty\), \(r^{(k)} = Ax^{(k)} + Bz^{(k)} - c \to 0\), meaning the primal iterates approach feasibility.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Objective convergence&lt;/strong&gt;: \(f(x^{(k)}) + g(z^{(k)}) \to f^{\ast} + g^{\ast}\), where \(f^{\ast} + g^{\ast}\) is the optimal primal objective value.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Dual convergence&lt;/strong&gt;: \(u^{(k)} \to u^{\ast}\), where \(u^{\ast}\) is the dual solution.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The exact convergence rate is not yet fully understood, and much research is currently ongoing in this area. Roughly speaking, ADMM performs similarly to or slightly better than first-order methods.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-04-01 ADMM</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_04_01_ADMM/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_04_01_ADMM</id>
   <content type="html">&lt;h1 id=&quot;alternating-direction-method-of-multipliers-admm&quot;&gt;Alternating Direction Method of Multipliers (ADMM)&lt;/h1&gt;

&lt;p&gt;The &lt;strong&gt;Alternating Direction Method of Multipliers (ADMM)&lt;/strong&gt; is a powerful optimization algorithm that combines the benefits of dual decomposition and the method of multipliers. It is particularly effective for solving convex optimization problems that can be decomposed into smaller, more manageable subproblems.&lt;/p&gt;

&lt;p&gt;Consider the following problem:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_{x,z} f(x) + g(z) \quad \text{subject to} \quad Ax + Bz = c
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As before, we can augment the objective function as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_{x,z} f(x) + g(z) + \frac{\rho}{2} \lVert Ax + Bz - c \rVert_2^2 \quad \text{subject to} \quad Ax + Bz = c
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;where \(\rho &amp;gt; 0\) is the penalty parameter.&lt;/p&gt;

&lt;h2 id=&quot;augmented-lagrangian&quot;&gt;Augmented Lagrangian&lt;/h2&gt;

&lt;p&gt;The augmented Lagrangian can be defined as:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
L_{\rho} (x,z,u) = f(x) + g(z) + u^T(Ax + Bz - c) + \frac{\rho}{2} \lVert Ax + Bz - c \rVert_2^2
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;admm-algorithm&quot;&gt;ADMM Algorithm&lt;/h2&gt;

&lt;p&gt;ADMM performs the following iterative steps for \(k=1,2,3,\ldots\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; = \arg\min_x  L_{\rho} (x,z^{(k-1)},u^{(k-1)}) \\
z^{(k)} &amp;amp; = \arg\min_z  L_{\rho} (x^{(k)},z,u^{(k-1)}) \\
u^{(k)} &amp;amp; = u^{(k-1)} + \rho (Ax^{(k)} + Bz^{(k)} - c) 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Key Point:&lt;/strong&gt; It is crucial that \(x^{(k)}\) obtained from the first step is used in the second step to compute \(z^{(k)}\). This alternating update structure is essential for convergence.&lt;/p&gt;

&lt;h2 id=&quot;comparison-with-method-of-multipliers&quot;&gt;Comparison with Method of Multipliers&lt;/h2&gt;

&lt;p&gt;Note that in the general &lt;strong&gt;Method of Multipliers&lt;/strong&gt;, the first two steps are replaced by the following joint minimization:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
(x^{(k)}, z^{(k)}) = \arg\min_{x,z} L_{\rho} (x,z,u^{(k-1)})   &lt;br /&gt;
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The key advantage of ADMM is that it decomposes this joint minimization into two separate, simpler subproblems that can often be solved more efficiently or even in closed form.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-04 A peak at ADMM</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_04_00_A_peak_at_ADMM/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_04_00_A_peak_at_ADMM</id>
   <content type="html">&lt;h2 id=&quot;lipschitz-gradients-and-strong-convexity&quot;&gt;Lipschitz gradients and strong convexity&lt;/h2&gt;
&lt;p&gt;In this section, we examine an overview of the Alternating Direction Method of Multipliers (ADMM) technique. While the augmented Lagrangian method previously did not provide decomposability, ADMM is a method that provides decomposability along with convergence properties.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-03 Augmented Lagrangians</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_03_Augmented_Lagrangians/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_03_Augmented_Lagrangians</id>
   <content type="html">&lt;p&gt;Dual ascent의 단점은 convergence을 보장하기 for, 강한 condition,이 필요하다는 것이다. (convergence을 보장하려면 \(f\)가 strongly convexsolution야 했다.) 이런 단점은 &lt;strong&gt;Augmented Lagrangian method&lt;/strong&gt; (or, &lt;strong&gt;Method of multipliers&lt;/strong&gt;)by, 개선될 수 있다.&lt;/p&gt;

&lt;p&gt;Primal problem를 아래and, 같이 transformation한다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_x f(x) + \frac{\rho}{2} \lVert Ax - b \rVert _2^2 \quad \text{ subject to } \quad Ax = b
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\rho &amp;gt; 0\)이다. \(A\)가 full column rank를 갖는다면 목적식은 strongly convex하다. 이는 원래의 problemand, 정확히 동일한 problem가 된다. (Augmented term인 \(Ax - b\)는 0이 되기 because,이다.)&lt;/p&gt;

&lt;h2 id=&quot;augmented-lagrangian-method&quot;&gt;Augmented Lagrangian Method&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Dual gradient ascent&lt;/strong&gt; : \(k=1,2,3,\dots\)about, 다음을 iteration한다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; \in \arg\min_x f(x) + (u^{(k-1)})^T A x + \frac{\rho}{2} \lVert Ax - b \rVert_2^2  \\
u^{(k)} &amp;amp; = u^{(k-1)} + \rho (A x^{(k)} - b)
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;위 dual algorithmat, \(\rho\)는 step size 역할을 한다, that is, \(t_k=\rho\)이다. 이것은 next,서 그 reason,를 알 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;rho가-step-size일-when-optimality-증명&quot;&gt;\(\rho\)가 step size일 when, optimality 증명&lt;/h3&gt;

&lt;p&gt;\(x^{(k)}\)는 \(f(x) + (u^{(k-1)})^T Ax + \frac{\rho}{2} \lVert Ax - b\rVert _2^2\) 를 minimization하므to,, 
원래 primal problemto, about, stationary condition,according to,, \(x^{(k)}\)at, 목적식의 subgradient가 아래and, 같이 \(0\)을 포함solution야 한다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
0 &amp;amp; \in \partial f(x^{(k)}) + A^T (u^{(k-1)}) + \rho (A x^{(k)} -b))  \\
  &amp;amp; = \partial f(x^{(k)}) + A^T u^{(k)}
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;위식at,, \(u^{(k)} = u^{(k-1)} + \rho (A x^{(k)} - b)\)to, 동작하게 되면, 적당한 condition,하at, \(Ax^{(k)}-b\)가 \(0\)with, 가까워지면서 feasible한 solution를 제공하기 시작하고, 궁극적with, KKT condition,이 만족되고, \(x^{(k)}\)and, \(u^{(k)}\)가 optimalityto, 근접함을 보일 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Augmented Lagrangian method&lt;/strong&gt;의 장점은 훨씬 좋은 convergence성을 갖는다는 것이고, 단점은 problem를 분solution할 수 있는 decomposability를 잃는다는 것이다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-02-02 Dual Decomposition with Inequality Constraint</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_02_02_Dual_Decomposition_with_Inequality_Constraint/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_02_02_Dual_Decomposition_with_Inequality_Constraint</id>
   <content type="html">&lt;p&gt;다음의 problem를 생각solution 보자. 앞의 problemand, 다른점은 제약식이 부등식의 relationship,를 갖는 것이다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{equation}
\min_x \sum_{i=1}^B f_i(x_i) \quad \text{subject to} \quad \sum_{i=1}^B A_i x_i \leq b
\end{equation}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;dual-decomposition-projected-subgradient-method&quot;&gt;Dual decomposition (projected subgradient method)&lt;/h2&gt;
&lt;p&gt;위 problemat,는 dual variable가 always, \(0\)보다 같거나 커야 한다, that is, \(u \geq 0\). therefore,, 다음 스텝의 \(u\)값을 computation할 when,, \(0\)보다 큰 범위안with, projection을 시켜서 업데이트를 한다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
x_i^{(k)} &amp;amp; \in \arg \min_{x_i} f_i(x_i) + (u^{(k-1)})^T A_i x_i, \quad i=1,\dots,B  \\
u^{(k)}   &amp;amp; = u^{(k-1)} + t_k \left(\sum_{i=1}^B A_i x_i^{(k)} - b \right)_+
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서, \(u_{+}\)는 0보다 큰 \(u\)를 의미한다, that is,, \((u_+)_i = \max \left\{0,u_i \right\}, i=1,\dots,m\). 
위  process을 \(k=1,2,3,\dots\)about,서 iteration한다.&lt;/p&gt;

&lt;h3 id=&quot;price-coordination-interpretation&quot;&gt;Price coordination interpretation&lt;/h3&gt;
&lt;p&gt;generally, dual decomposition problem들은 price coordination 관점at, as follows: solution석될 수 있다. (Vandenberghe)&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;\(B\)개의 독립적인 유닛이 있고, 각 유닛은 자신의 결정 variable \(x_i\)를 결정한다.&lt;/li&gt;
    &lt;li&gt;각 constraint은 \(B\)개의 유닛이 공유하고 있는 자원to, about, 제약을 의미하며, dual variable \(u_j\)는 자원 \(j\)의 가격을 의미한다.&lt;/li&gt;
    &lt;li&gt;Dual variable는 아래and, 같이 업데이트되며
 \begin{equation}
 u_j^{+} = (u_j - t s_j)_{+}, \quad  j=1,\dots,m
 \end{equation}&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;\(\quad\) 여기서, \(s=b-\sum_{i=1}^B A_ix_i\)는 슬랙 variableto,써 &lt;br /&gt;
\(\qquad\) - \(s_j &amp;lt; 0\)이면, 자원 \(j\)가 over-utilized 되고 있다는 의미이고, therefore,, price \(u_j\)를 증가시킨다 &lt;br /&gt;
\(\qquad\) - \(s_j &amp;gt; 0\)이면, 자원 \(j\)가 under-utilized되고 있다는 의미이고,  therefore,, price \(u_j\)를 감소시킨다 &lt;br /&gt;
\(\qquad\) - price는 향image 음수가 되지 않도록 한다.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>20-02-01 Dual Decomposition with Equality Constraint</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_02_01_Dual_Decomposition_with_Equality_Constraint/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_02_01_Dual_Decomposition_with_Equality_Constraint</id>
   <content type="html">&lt;p&gt;다음의 problem를 보자.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_x \sum_{i=1}^B f_i(x_i) \quad \text{ subject to } \quad Ax = b
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;if,, variable \(x\)를 \(B\)개의 블록with, 분할하고, \(x = (x_1,\dots,x_B) \in \mathbb{R}^n, \text{ where } x_i \in \mathbb{R}^{n_i}\), matrix \(A\) 역시 \(B\)개의 sub-matrix 블록with, as follows: 분할하면, \(A = [A_1, \dots, A_B], \text{ where } A_i \in \mathbb{R}^{m \times n_i}\), 위 minimization problem는 as follows: \(B\)개의 분리된 problemto, 분solution될 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
&amp;amp; \quad x^+ \in \arg\min_x \sum_{i=1}^B f_i(x_i) + u^T Ax  \\
\Longleftrightarrow &amp;amp; \quad x_i^+ \in \arg\min_{x_i} f_i(x_i) + u^T A_ix_i, \quad i=1,\dots, B
\end{alignat}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;dual-decomposition-algorithm&quot;&gt;Dual decomposition algorithm:&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
x_i^{(k)} &amp;amp; \in \arg \min_{x_i} f_i(x_i) + (u^{(k-1)})^T A_i x_i, \quad i=1,\dots,B  \\
u^{(k)}   &amp;amp; = u^{(k-1)} + t_k \left(\sum_{i=1}^B A_i x_i^{(k)} - b \right)
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;위 두 step는 아래and, 같이 solution석할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;첫번째 수식은 broadcast stepto,서, \(B\)개의 프to,세서의 각각to,게 \(u\)를 보낸다. and,, 프to,세서 각각은 병렬to, 자신의 최적 \(x_i\)를 찾는다.&lt;/li&gt;
    &lt;li&gt;두번째 수식은 gather stepto,서, 각 프to,세서from, \(A_i x_i\)를 모은다. and, global dual variable \(u\)를 업데이트 한다.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;위 두 step는 \(k=1,2,3,\dots\)about, 계속 iteration한다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter20/decomposition.png&quot; alt=&quot;[Fig 1] Broadcast and Gather&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Broadcast and Gather&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>20-02 Dual Decomposition</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_02_00_Dual_Decomposition/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_02_00_Dual_Decomposition</id>
   <content type="html">&lt;p&gt;In this section, we examine techniques for decomposing problems using duality.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20-01-01 Convergence Analysis</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_01_01_Convergence_Analysis/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_01_01_Convergence_Analysis</id>
   <content type="html">&lt;h2 id=&quot;lipschitz-gradients-and-strong-convexity&quot;&gt;Lipschitz gradients and strong convexity&lt;/h2&gt;
&lt;p&gt;Let’s assume \(f\) is a closed convex function. Then the following equivalence relationship holds.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\text{\(f\) is strongly convex with parameter \(d\) \(\Longleftrightarrow \nabla f^{\ast}\) Lipschitz with parameter \(1/d\).} 
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;
&lt;p&gt;if, \(g\)가 strongly convex하고 \(x\)at, minimize된다고 하면 다음 relationship,가 성립한다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
g(y) \geq g(x) + \frac{d}{2}\lVert y-x \rVert_2^2, \text{ for all } y
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;우선, \(g(x) = f(x) − u^T x\)를 minimization하는 \(x_u = \nabla f^{\ast}(u)\)and, \(g(x) = f(x) − v^T x\)를 minimization하는 \(x_v = \nabla f^{\ast}(v)\)가 있다고 하자.&lt;/p&gt;

&lt;p&gt;그러면, 위 식으from, 다음 두 부등식을 얻을 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
f(x_v) - u^Tx_v \geq f(x_u) - u^T x_u + \frac{d}{2} \lVert x_u - x_v \rVert_2^2 \\
f(x_u) - v^Tx_u \geq f(x_v) - v^T x_v + \frac{d}{2} \lVert x_u - x_v \rVert_2^2 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;위 두 식을 더하면 다음and, 같은 식을 얻을 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
f(x_v) - u^Tx_v + f(x_u) - v^Tx_u \geq f(x_u) - u^T x_u +  f(x_v) - v^T x_v + d \lVert x_u - x_v \rVert_2^2.&lt;br /&gt;
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 식을 재정렬 후 Cauchy-Schwartz를 적용하면 as follows: 정리된다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
d \lVert x_u - x_v \rVert_2^2 &amp;amp; \leq - u^Tx_v - v^Tx_u + u^T x_u + v^T x_v \\\\
&amp;amp; = (u-v)^T(x_u - x_v) \\\\
&amp;amp; \leq \lVert u-v \rVert_2 \lVert x_u - x_v \rVert_2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;therefore,, 다음and, 같은 relationship,를 확인할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
\[\lVert x_u - x_v \rVert_2 \leq \frac{1}{d} \lVert u-v \rVert_2\]
&lt;/blockquote&gt;

&lt;p&gt;이to,써 \(\nabla f^{\ast}\) Lipschitz with parameter \(1/d\)이 증명되었다.&lt;/p&gt;

&lt;h2 id=&quot;convergence-guarantees&quot;&gt;Convergence guarantees&lt;/h2&gt;
&lt;p&gt;위 result,and, gradient descent를 combining,, dual objective의 optimal solutionto,의 convergence성을 as follows: 설명할 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;if, \(f\)가 파라미터 \(d\)to, strongly convex 하면, step size \(t_k=d (k=1,2,3, \dots\))about,서, dual gradient ascent는 \(O(1/\epsilon)\)with, converge한다.&lt;/li&gt;
  &lt;li&gt;if, \(f\)가 파라미터 \(d\)to, strongly convex 하고, \(\nabla f\)는 파라미터 \(L\)to, Lipschitz하면, step size \(t_k=2/(1/d + 1/L)\) (\(k=1,2,3, \dots\))about,서, dual gradient ascent는 \(O(\log(1/\epsilon))\)with, converge한다. (linear convergence)&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>20-01 Dual (sub)gradient methods</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_01_00_Dual_(sub)gradient_methods/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_01_00_Dual_(sub)gradient_methods</id>
   <content type="html">&lt;p&gt;Even in cases where we cannot find a dual (conjugate) in closed-form, we can use subgradient or gradient methods based on the dual.&lt;/p&gt;

&lt;p&gt;For example, consider the following problem.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_x f(x) \text{ subject to } Ax = b
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The dual problem of the above problem is as follows. Here \(f^{\ast}\) is the conjugate of \(f\).&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\max_u -f^{\ast}(-A^T u) - b^T u
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this case, if we define \(g(u)\) as \(-f^{\ast}(-A^Tu)-b^Tu\), then the subgradient of \(g(u)\) is as follows.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\partial g(u) = A \partial f^{\ast}(-A^Tu) - b
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the above expression, \(\partial f^{\ast}(-A^Tu)\) can be expressed in terms of \(x\) as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\partial g(u) = Ax-b \quad \text{where} \quad x \in \arg\min_z f(z) + u^T A z
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;dual-subgradient-method&quot;&gt;Dual subgradient method&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Dual subgradient method&lt;/strong&gt;는 dual problem의 목적식을 maximization하기 for, 시작점 \(u^{(0)}\)at, 시작solution서 \(k=1,2,3,\dots\)about, 다음 step를 iteration한다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; \in \arg \min_x f(x) + ({u^{(k-1)}})^T A x  \\
u^{(k)} &amp;amp; = u^{(k-1)} + t_k (A x^{(k)} - b) 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 step size \(t_k(k=1,2,3,\dots\))는 표준적인 방식with, 선택된다.&lt;/p&gt;

&lt;h3 id=&quot;strictly-convex인-case&quot;&gt;Strictly Convex인 case,&lt;/h3&gt;
&lt;p&gt;if, \(f\)가 strictly convex라면 \(f^{\ast}\)는 미분가능solution진다.&lt;/p&gt;

&lt;p&gt;therefore,, algorithm은 \(k=1,2,3,\dots\)about, 다음 step를 iteration하는 &lt;strong&gt;dual gradient ascent&lt;/strong&gt;가 된다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{alignat}{1}
x^{(k)} &amp;amp; = \arg \min_x f(x) + ({u^{(k-1)}})^T A x  \\
u^{(k)} &amp;amp; = u^{(k-1)} + t_k (A x^{(k)}-b) 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;before, 방식and, 다른 점은 \(x^{(k)}\)가 유일하다는 것이다. (\(\text{argmin}\)and,의 relationship,가 \(=\) relationship,임을 confirming,보라.)&lt;/p&gt;

&lt;p&gt;여기서 step size \(t_k(k=1,2,3,\dots\))도 표준적인 방식with, 선택되며 \(\text{argmin}\)을 수행할 when, proximal gradient나 acceleration도 평소처럼 적용할 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>20 Dual Methods</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_00_Dual_Methods/"/>
   <updated>2021-03-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter20/20_00_Dual_Methods</id>
   <content type="html">&lt;p&gt;In this chapter, we will examine methods for solving problems using duality, including dual subgradient method, dual decomposition method, augmented Lagrangian method, and briefly introduce the concept of Alternating Direction Method of Multipliers (ADMM).&lt;/p&gt;

&lt;p&gt;First, we will briefly review the previously learned content on Proximal Newton method and Conjugate function.&lt;/p&gt;

&lt;h2 id=&quot;review-proximal-newton-method&quot;&gt;Review: proximal Newton method&lt;/h2&gt;
&lt;p&gt;Consider the following problem.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
\min_x g(x) + h(x)
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, functions \(g\) and \(h\) are convex functions, where \(g\) is twice differentiable and \(h\) is simple.&lt;/p&gt;

&lt;p&gt;The Proximal Newton method starts with initial \(x^{(0)} \in \mathbb{R}^n\) and finds the optimal vector direction that is good for both functions \(g\) and \(h\) as follows&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{alignat}{1}
v^{(k)} &amp;amp; = \arg \min_v g({x^{(k-1)}})^T v +  \frac{1}{2} v^T \nabla^2 g(x^{(k-1)}) v + h(x^{(k-1)} + v) 
\end{alignat}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Using the direction found above, we update the next \(x^{(k)}\) as follows.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
x^{(k)} = x^{(k-1)} + t_k v^{(k)}, k=1,2,3,\dots 
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, \(t_k\) is the step size determined by backtracking.&lt;/p&gt;

&lt;p&gt;We execute the above two processes iteratively.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;The above iteration is very expensive (computing \(v^{(k)}\) is generally very difficult)&lt;/li&gt;
    &lt;li&gt;However, under appropriate conditions, very few iterations are required to converge, and it has a convergence rate of local quadratic convergence&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;review-conjugate-function&quot;&gt;Review: conjugate function&lt;/h2&gt;
&lt;p&gt;For \(f: \mathbb{R}^n \to \mathbb{R}\), the conjugate function is defined as follows.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
f^*(y) = \max_x y^Tx - f(x)
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(1) The conjugate function can be written as follows, and this is a form that frequently appears in dual problems.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
-f^{\ast}(y) = \min_x f(x) - y^Tx
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(2) If \(f\) is closed and convex, then \(f^{**} = f\). Also,&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{equation}
x \in \partial f^{\ast}(y) \Longleftrightarrow y \in \partial f(x) \Longleftrightarrow x \in \arg\min_z f(z) - y^Tz
\end{equation}&lt;/p&gt;
  &lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;
  &lt;p&gt;first,, \(x \in \partial f^{\ast}(y) \Longleftrightarrow y \in \partial f(x)\)을 증명한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;1step--x-in-partial-fasty-longleftarrow-y-in-partial-fx&quot;&gt;1step : \(x \in \partial f^{\ast}(y) \Longleftarrow y \in \partial f(x)\)&lt;/h3&gt;
&lt;blockquote&gt;

  &lt;p&gt;\(y \in \partial f(x)\)를 let’s assume. 그러면, \(x\)는 \(y^Tz - f(z)\)를 최대to, 하게 하는 \(z\)들의 set \(M_y\) to, 속하게 된다, that is, \(x \in M_y\). &lt;br /&gt; however,, \(f^{\ast}(y)=   \max_z y^Tz - f(z)\) 이고, \(\partial f^{\ast}(y)=\text{cl} \left( \text{conv} \left( \bigcup_{z \in M_y} \left\{ z \right\} \right) \right)\). therefore,, \(x \in \partial f^{\ast}(y)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;2step--x-in-partial-fasty-longrightarrow-y-in-partial-fx&quot;&gt;2step : \(x \in \partial f^{\ast}(y) \Longrightarrow y \in \partial f(x)\)&lt;/h3&gt;
&lt;blockquote&gt;

  &lt;p&gt;위at, 보인것and, 같이, if,, \(x \in  \partial f^{\ast}(y)\) 이면, \(y \in \partial f^{\ast\ast}(x)\). 여기서, \(f^{\ast\ast}(x)=f\) 이므to, \(y \in \partial f(x)\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위 1, 2 step를 through,, \(x \in \partial f^{\ast}(y) \Longleftrightarrow y \in \partial f(x)\)이 증명되었다.&lt;/p&gt;
&lt;h3 id=&quot;3step--x-in-partial-fasty-longleftrightarrow-y-in-partial-fx-longleftrightarrow-x-in-argmin_z-fz---ytz&quot;&gt;3step : \(x \in \partial f^{\ast}(y) \Longleftrightarrow y \in \partial f(x) \Longleftrightarrow x \in \arg\min_z f(z) - y^Tz\)&lt;/h3&gt;
&lt;blockquote&gt;

  &lt;p&gt;한편, \(y \in \partial f(x) \Longleftrightarrow x \in \arg\min_z f(z) - y^Tz\)은 subgradient의 정의from, 자명한 in fact,이다.  &lt;br /&gt;
therefore,, 위 두 증명을 through,, \(x \in \partial f^{\ast}(y) \Longleftrightarrow y \in \partial f(x) \Longleftrightarrow x \in \arg\min_z f(z) - y^Tz\)임이 증명되었다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(3) if, \(f\)가 strictly convex이면,&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{equation}
\nabla f^{\ast}(y) = \arg\min_z f(z) - y^T z
\end{equation}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;proof-1&quot;&gt;Proof&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f\)가 strictly convex이면, \(f(z)-y^Tz\)는 최소값을 갖는 유일한 \(z\)가 존재하며, 
이것은 위 (2)to, about, 증명으from, \(\nabla f^{\ast}(y)\)이어야 한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;다시 말하면 \(f\)가 strictly convex이면  \(f^{\ast}\)의 subgradient는 1개이며 gradient가 된다. therefore,,  \(f^{\ast}\)는 differentiable한 function이다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14 Phương pháp Newton</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_newton_method/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_newton_method</id>
   <content type="html">&lt;p&gt;Trong chương này, chúng ta sẽ tìm hiểu về Phương pháp Newton.&lt;/p&gt;

&lt;p&gt;Phương pháp Newton là một cách tiếp cận để tìm giá trị nhỏ nhất của một hàm số có đạo hàm bậc hai bằng cách sử dụng khai triển Taylor bậc hai. Phương pháp này tìm giá trị tối ưu bằng cách xấp xỉ hàm số và cập nhật nghiệm một cách lặp đi lặp lại. Gần điểm tối ưu, nó đạt được sự hội tụ bậc hai và nhanh hơn nhiều so với phương pháp gradient descent.&lt;/p&gt;

&lt;h2 id=&quot;tài-liệu-tham-khảo-và-đọc-thêm&quot;&gt;Tài liệu tham khảo và đọc thêm&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;S. Boyd and L. Vandenberghe (2004), “Convex optimization”, Chapter 9 and 10&lt;/li&gt;
  &lt;li&gt;Y. Nesterov (1998), “Introductory lectures on convex optimization: a basic course”, Chapter 2&lt;/li&gt;
  &lt;li&gt;Y. Nesterov and A. Nemirovskii (1994), “Interior-point polynomial methods in convex programming”, Chapter 2&lt;/li&gt;
  &lt;li&gt;J. Nocedal and S. Wright (2006), “Numerical optimization”, Chapters 6 and 7&lt;/li&gt;
  &lt;li&gt;L. Vandenberghe, Lecture notes for EE 236C, UCLA, Spring 2011-2012&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>14-09 Các phương pháp Quasi-Newton</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_09_quasi_newton_methods/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_09_quasi_newton_methods</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
    });
&lt;/script&gt;

&lt;p&gt;Nếu việc tính toán Hessian quá đắt hoặc Hessian là suy biến, chúng ta sử dụng các phương pháp quasi-Newton để xấp xỉ ma trận Hessian, tức là, \(\nabla^{2}f(x)\) được thay thế bởi \(H&amp;gt;0\), và chúng ta sử dụng \(H\) cho cập nhật:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{+} = x - tH^{-1}\nabla f(x)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Một số đặc điểm của các phương pháp quasi-Newton như sau. Để biết thêm chi tiết, xem &lt;a href=&quot;/contents/vi/chapter18/18_00_Quasi_Newton_methods/&quot;&gt;Chương 18&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hessian xấp xỉ \(H\) được cập nhật ở mỗi bước. Mục tiêu là sử dụng tính toán tương đối rẻ cho \(H^{-1}\).&lt;/li&gt;
  &lt;li&gt;Tốc độ hội tụ là siêu tuyến tính, nhưng không nhanh bằng phương pháp Newton. Thông thường, \(n\) bước của quasi-Newton tương đương với một bước của Newton về tiến bộ.&lt;/li&gt;
  &lt;li&gt;Nhiều phương pháp quasi-Newton cập nhật \(H\) ở mỗi lần lặp sử dụng các kỹ thuật truyền.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>14-08 Các trường hợp đặc biệt</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_08_special_cases/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_08_special_cases</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
    });
&lt;/script&gt;

&lt;h2 id=&quot;các-bài-toán-thưa-có-cấu-trúc&quot;&gt;Các bài toán thưa, có cấu trúc&lt;/h2&gt;
&lt;p&gt;Nếu ma trận hệ tuyến tính trong bài toán là thưa và có cấu trúc, và Hessian có thể được tính toán hiệu quả, chúng ta có thể giải quyết bài toán hiệu quả hơn.&lt;/p&gt;

&lt;p&gt;For example, if \(\nabla^{2}f(x)\) is sparse and structured for all \(x\), such as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Band_matrix&quot;&gt;band matrix&lt;/a&gt;, Newton’s method can achieve \(O(n)\) performance in memory and computation. (A band matrix is a matrix where nonzero entries are only near the diagonal.)&lt;/p&gt;

&lt;p&gt;Let’s look at two typical examples of functions with structured Hessians:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;If \(g(\beta) = f(X\beta)\), then \(\nabla^{2}g(\beta)=X^{T}\nabla^{2}f(X\beta)X\). If \(X\) is a structured predictor matrix and \(\nabla^{2}f\) (the Hessian of \(f\)) is diagonal, then \(\nabla^{2}g\) is also structured.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If \(\nabla^{2}f\) is diagonal and \(g\) is non-smooth, consider minimizing \(f(\beta)+g(D\beta)\), where \(D\) is a structured penalty matrix. The Lagrange dual is \(-f^{*}(-D^{T}u)-g^{*}(-u)\). In general, \(-D\nabla^{2}f^{*}(-D^{T}u)D^{T}\) is also structured.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;phương-pháp-newton-với-ràng-buộc-đẳng-thức&quot;&gt;Phương pháp Newton với ràng buộc đẳng thức&lt;/h2&gt;
&lt;p&gt;Now let’s look at optimization problems with equality constraints. Generally, we can approach this problem in three ways:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} f(x) &amp;amp; \text{subject to }Ax=b.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;1) Reduced-space approach: Restrict the domain to the space satisfying the equality constraint. For the above problem, express \(x\) as \(x=Fy+x_{0}\), where \(F\) spans the null space of \(A\) and \(Ax_{0}=b\). Then solve for \(y\).&lt;/p&gt;

&lt;p&gt;2) Equality-constrained Newton’s method: Similar to unconstrained Newton’s method, but with two differences. First, the initial value must be feasible (\(x \in dom (f)\) and \(Ax = b\)). Second, the Newton step \(\Delta x_{nt}\) must satisfy \(A\Delta x_{nt}=0\). See below for details.&lt;/p&gt;

&lt;p&gt;3) Dual approach: The Fenchel dual is \(-f^{*}(-A^{T}v)-b^{T}v\), and strong duality holds. (&lt;a href=&quot;/contents/vi/chapter16/16_03_fenchel_duality/&quot;&gt;16-03&lt;/a&gt; covers this in detail.) Use the conjugate function to solve the dual problem. Here, \(f^{*}\) is the conjugate of \(f\).&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
g(v) &amp;amp;= -b^{T}v + \min_{x}(f(x)+v^{T}Ax)\\\\
&amp;amp;= -b^{T}v - \max_{x}\big( (-A^{T}v)^{T}x - f(x) \big)\\\\
&amp;amp;= -b^{T}v - f^{*}(-A^{T}v),
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This leads to the following dual problem:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\max -b^{T}v-f^{*}(-A^{T}v). 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Assuming the optimal value exists, this problem is strictly feasible and satisfies Slater’s condition. Therefore, as mentioned earlier, strong duality holds, and there exists a \(v^{*}\) such that \(g(v^{*})=p^{*}\).[1, p.525]&lt;/p&gt;

&lt;p&gt;Now, let’s examine the second method.
To derive a feasible Newton step \(\Delta x_{nt}\), we replace the objective function in the original problem with a quadratic approximation around \(x\). This can be expressed as:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\text{minimize}\quad &amp;amp;\hat{f}(x+v) = f(x) + \nabla f(x)^{T}v + \frac{1}{2}v^{T}\nabla^{2} f(x) v\\\\
\text{subject to}\quad &amp;amp;A(x+v) = b,
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This can also be expressed as:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^{+} = x + tv,\,\, \text{where}\\\\
v = \underset{A(x+z)=b}{\operatorname{argmin}}\big( f(x)+\nabla f(x)^{T}z+\frac{1}{2}z^{T}\nabla^{2} f(x)z \big)\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Since \(Ax^{+} = Ax+tAv = b\), the solution \(x\) remains within the constraint in the subsequent steps of the iteration.&lt;/p&gt;

&lt;p&gt;The KKT conditions for this problem can be expressed as follows, and by solving the linear system below, we can obtain the solution. Recall that \(v\) is the Newton step \(\Delta x_{nt}\).&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\begin{bmatrix}
\nabla^{2} f(x) &amp;amp; A^{T}\\\\
A &amp;amp; 0
\end{bmatrix}
\begin{bmatrix}
v\\\\
w
\end{bmatrix}
=-
\begin{bmatrix}
\nabla f(x)\\\\
Ax-b
\end{bmatrix}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(w\) is the optimal dual variable for the above quadratic problem.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-07 So sánh với phương pháp bậc nhất</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_07_comparison_to_first_order_method/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_07_comparison_to_first_order_method</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
    });
&lt;/script&gt;

&lt;p&gt;Trong chương này, chúng ta so sánh phương pháp Newton và gradient descent từ góc nhìn tổng quát. Giả sử chiều của miền là \(n\).&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Item&lt;/th&gt;
      &lt;th&gt;Newton’s method&lt;/th&gt;
      &lt;th&gt;Gradient descent&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Memory&lt;/td&gt;
      &lt;td&gt;\(O(n^{2})\) (storage for \(n \times n\) Hessian matrix)&lt;/td&gt;
      &lt;td&gt;\(O(n)\) (storage for \(n\)-dimensional gradient)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Computation&lt;/td&gt;
      &lt;td&gt;\(O(n^{3})\) flops (computation for \(n \times n\) linear system)&lt;/td&gt;
      &lt;td&gt;\(O(n)\) flops (computation for \(n\)-dimensional vector addition)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Backtracking&lt;/td&gt;
      &lt;td&gt;\(O(n)\)&lt;/td&gt;
      &lt;td&gt;\(O(n)\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Conditioning&lt;/td&gt;
      &lt;td&gt;Affine invariant, less affected by conditioning&lt;/td&gt;
      &lt;td&gt;Can be strongly affected by conditioning&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fragility&lt;/td&gt;
      &lt;td&gt;Sensitive to bugs or numerical errors&lt;/td&gt;
      &lt;td&gt;More robust than Newton’s method&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter14/gd(1).jpeg&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Logistic regression [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Figure 1 above is a logistic regression example discussed in &lt;a href=&quot;/contents/vi/chapter14/14_04_backtracking_line_search/&quot;&gt;14-04&lt;/a&gt;. If you plot the x-axis as actual computation time, you see the following. In convergence analysis, Newton’s method has two phases. In practice, after a certain time, you can observe fast convergence (quadratic convergence). In the initial damped phase of Newton’s method, the convergence rate is similar to gradient descent. However, since \(O(n^{3})\) computation is required, the actual computation time may be slower. After backtracking line search is no longer needed, you observe quadratic convergence and very fast progress.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-06 Tự hài hòa (Self concordance)</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_06_self_concordance/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_06_self_concordance</id>
   <content type="html">&lt;p&gt;Trong phân tích hội tụ trước đây của phương pháp Newton, có hai vấn đề chính. [1]&lt;/p&gt;

&lt;p&gt;Thứ nhất, trong các bài toán thực tế, rất khó tìm hằng số Lipschitz L, các cận dưới và trên của tính lồi mạnh m, M, v.v., được bao gồm trong các công thức. Vì điều này, trong khi chúng ta có thể quan sát sự hội tụ và tốc độ hội tụ, việc phân tích cần bao nhiêu bước Newton trong thực tế là gần như bất khả thi.&lt;/p&gt;

&lt;p&gt;Thứ hai, mặc dù bản thân phương pháp Newton là bất biến affine, nhưng phân tích hội tụ của phương pháp Newton không bất biến affine. Đối với các hàm tổng quát, giá trị của hằng số Lipschitz hoặc các cận tính lồi mạnh thay đổi tùy thuộc vào phép biến đổi tọa độ.&lt;/p&gt;

&lt;p&gt;Do đó, trong chương này, chúng ta giới thiệu các hàm tự hài hòa, giải quyết hai vấn đề trên.&lt;/p&gt;

&lt;p&gt;Các hàm tự hài hòa quan trọng và có ý nghĩa vì ba lý do chính:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Các hàm rào cản logarit được sử dụng trong các phương pháp điểm nội là các hàm tự hài hòa.&lt;/li&gt;
  &lt;li&gt;Trong phân tích phương pháp Newton cho các hàm tự hài hòa, các số hạng liên quan đến hằng số không xuất hiện.&lt;/li&gt;
  &lt;li&gt;Tính tự hài hòa là bất biến affine. Tức là, số lần lặp Newton cần thiết không phụ thuộc vào các phép biến đổi affine của hệ tọa độ.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>14-06-02 Phân tích hội tụ cho các hàm tự hài hòa</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_06_02_convergence_analysis_for_self_concordant_functions/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_06_02_convergence_analysis_for_self_concordant_functions</id>
   <content type="html">&lt;p&gt;Đối với các hàm tự hài hòa, kết quả phân tích hội tụ như sau:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Định lý (Nesterov và Nemirovskii): Phương pháp Newton với tìm kiếm đường backtracking yêu cầu số lần lặp sau để đạt được \(f(x^{(k)})-f^{\star}\leq \epsilon\):
\begin{align}
C(\alpha, \beta)\big( f(x^{(0)}-f^{\star} \big) + \log\log{(1/\epsilon)},
\end{align}
trong đó \(C(\alpha, \beta)\) là một hằng số phụ thuộc vào \(\alpha, \beta\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Chứng minh trên tương tự như phân tích hội tụ cho phương pháp Newton, nhưng sử dụng các tính chất của các hàm tự hài hòa để sắp xếp các bước. (Xem [1], tr.503)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-06-01 Định nghĩa các hàm tự hài hòa</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_06_01_definition_of_self_concordant_functions/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_06_01_definition_of_self_concordant_functions</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
    });
&lt;/script&gt;

&lt;h2 id=&quot;tự-hài-hòa-trên-r&quot;&gt;Tự hài hòa trên \(R\)&lt;/h2&gt;
&lt;p&gt;Một hàm lồi \(f : R \rightarrow R\) được định nghĩa là tự hài hòa khi nó thỏa mãn phương trình sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\|f^{&apos;&apos;&apos;}(x)\| \leq 2f^{&apos;&apos;}(x)^{3/2} \qquad \text{for all }x\in \text{dom }f.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Làm ví dụ đơn giản, các hàm tuyến tính (\(ax+b\)) và các hàm bậc hai (lồi) là tự hài hòa vì giá trị đạo hàm bậc ba của chúng là 0.&lt;/p&gt;

&lt;h2 id=&quot;tự-hài-hòa-trên-rn&quot;&gt;Tự hài hòa trên \(R^{n}\)&lt;/h2&gt;
&lt;p&gt;Một hàm \(f : R^{n}\rightarrow R\) được định nghĩa là tự hài hòa khi nó tự hài hòa cho bất kỳ đoạn thẳng nào trong miền, tức là, cho tất cả các đoạn thẳng được bao gồm trong miền. Ví dụ, đối với tất cả \(x\in dom\, f\) và tất cả \(v\), khi \(g(t) = f(x+tv)\) được định nghĩa, nếu \(g(t)\) là tự hài hòa, thì f được định nghĩa là một hàm tự hài hòa trong miền của \(\mathbb{R}^{n}\).&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ-về-hàm-tự-hài-hòa&quot;&gt;Ví dụ về hàm tự hài hòa&lt;/h2&gt;

&lt;p&gt;1) \(f : \mathbb{R}^{n}_{++}\rightarrow \mathbb{R}\), \(f(x) = -\sum^{n}_{i=1}log(x_{i})\).&lt;/p&gt;

&lt;p&gt;Có thể dễ dàng xác minh rằng \(f(t) = -\log{t}\). Hơn nữa, tổng của các hàm tự hài hòa cũng là tự hài hòa. Khi có các hàm tự hài hòa \(f_{1}, f_{2} : R\rightarrow R\), tổng của các hàm tự hài hòa cũng là tự hài hòa như được hiển thị dưới đây.[3]&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
|f_{1}^{&apos;&apos;&apos;}(x)+f_{2}^{&apos;&apos;&apos;}(x)|  \leq &amp;amp; |f^{&apos;&apos;&apos;}_{1}(x)|+|f^{&apos;&apos;&apos;}_{2}(x)|\\\\
\leq &amp;amp;2\big( f^{&apos;&apos;}_{1}(x)^{3/2}+f^{&apos;&apos;}_{2}(x)^{3/2}\big)\\\\
\leq &amp;amp;2\big( f^{&apos;&apos;}_{1}(x)+f^{&apos;&apos;}_{2}(x) \big)^{3/2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bước cuối sử dụng tính chất sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
(u^{3/2}+v^{3/2})^{2/3} \leq u+v, \qquad u, v \geq 0.
\end{align}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>14-05 Phân tích hội tụ</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_05_convergence_analysis/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_05_convergence_analysis</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
    });
&lt;/script&gt;

&lt;p&gt;Cho đến nay, chúng ta đã xem xét phương pháp Newton thuần túy, chỉ có tính chất hội tụ cục bộ, và phương pháp Newton có giảm chấn (phương pháp Newton với tìm kiếm đường backtracking), áp dụng tìm kiếm đường backtracking để đảm bảo hội tụ toàn cục khi lồi.&lt;/p&gt;

&lt;p&gt;Trong chương này, chúng ta phân tích tốc độ hội tụ của phương pháp Newton có giảm chấn. Đối với phương pháp Newton có giảm chấn, chúng ta xem xét các cận hội tụ được chia thành hai giai đoạn: giai đoạn mà backtracking được áp dụng (giai đoạn giảm chấn: tiến bộ chậm) và giai đoạn hội tụ cục bộ mà backtracking không còn cần thiết (giai đoạn thuần túy: hội tụ bậc hai).&lt;/p&gt;

&lt;h2 id=&quot;conditions-of-f-for-convergence-analysis&quot;&gt;Conditions of \(f\) for convergence analysis&lt;/h2&gt;
&lt;p&gt;Assume that \(f\) is convex, twice differentiable, has \(dom(f)=\mathbb{R}^{n}\), and satisfies the following three conditions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(\nabla f\) is Lipschitz continuous with parameter L.
    &lt;blockquote&gt;
\[\begin{align}
\|\nabla f(x) - \nabla f(y)\|_{2} \leq L\|x-y\|_{2} \quad \forall x,y.
\end{align}\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;\(f\) is strongly convex with parameter m. (Relationship between upper bound \(L\) and Lipschitz continuous: &lt;a href=&quot;https://xingyuzhou.org/blog/notes/strong-convexity&quot;&gt;source&lt;/a&gt;, &lt;a href=&quot;/contents/vi/chapter06/06_03_05_look_at_the_conditions_and_practicalities/&quot;&gt;this book: 06-03-05&lt;/a&gt;)
    &lt;blockquote&gt;
\[\begin{align}
mI\preceq\nabla^{2}f(x)\preceq LI.
\end{align}\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;\(\nabla^{2} f\) is Lipschitz continuous with parameter M.
    &lt;blockquote&gt;
\[\begin{align}
\|\nabla^{2}f(x)-\nabla^{2}f(y)\|_{2} \leq M\|x-y\|_{2} \quad \forall x,y.
\end{align}\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;convergence-analysis&quot;&gt;Convergence analysis&lt;/h2&gt;
&lt;p&gt;If the above three conditions are satisfied, for \(\eta, \gamma\) satisfying \(0&amp;lt;\eta \leq m^{2}/M\) and \(\gamma&amp;gt;0\), the convergence for each phase can be obtained as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Phase I : “Damped” phase, \(\|\nabla f(x^{(k)})\|_{2} \geq \eta\),&lt;/p&gt;

\[\begin{align}
f(x^{(k+1)})-f(x^{(k)}) \leq -\gamma
\end{align}\]

  &lt;p&gt;Phase 2 : “Pure” phase, \(\|\nabla f(x^{(k)})\|_{2}&amp;lt;\eta\), backtracking selects \(t = 1\)&lt;/p&gt;

\[\begin{align}
\frac{M}{2m^{2}}\|\nabla f(x^{(k+1)})\|_{2} \leq \bigg( \frac{M}{2m^{2}}\|\nabla f(x^{(k)})\|_{2} \bigg)^{2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Note that once the Pure phase is reached when \(\|\nabla f(x^{(k)})\|_{2}&amp;lt;\eta\) is satisfied at the \(k\)-th iteration for the first time, this condition is always satisfied for subsequent iterations.&lt;/p&gt;

&lt;h2 id=&quot;convergence-analysis--written-in-optimal-value-term&quot;&gt;Convergence analysis : written in optimal value term&lt;/h2&gt;
&lt;p&gt;Now we want to compare the convergence of each phase in terms of the difference from the optimal value.&lt;/p&gt;

&lt;p&gt;For Phase 1, if we perform k iterations starting from \(x^{(0)}\), we can organize the equation for each step and represent it as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\require{cancel}
&amp;amp; &amp;amp;\cancel{f(x^{(1)})}-f(x^{(0)}) \leq -\gamma \\\\
&amp;amp; &amp;amp;\cancel{f(x^{(2)})}-\cancel{f(x^{(1)})} \leq -\gamma \\\\
&amp;amp; &amp;amp;\vdots \\\\
&amp;amp;+ &amp;amp;f(x^{(k)})-\cancel{f(x^{(k-1)})} \leq -\gamma \\\\
&amp;amp;= &amp;amp;f(x^{(k)})-f(x^{(0)})\leq -k\gamma.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Subtracting \(f^{\star}\) from both sides, we can obtain the following result. Let \(k_{0}\) be the first \(k\) that satisfies \(\|\nabla f(x^{(k+1)})\|&amp;lt;\eta\).&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)})-f^{\star} \geq (f(x^{(0)})-f^{\star})-\gamma k \qquad \text{if }k \geq k_{0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For Phase 2, assume that iteration starts from \(k_{0}\) and proceeds for \(k-k_{0}\) steps. Also, using \(\|\nabla f(x^{(k)})\|_2&amp;lt;\eta \leq m^{2}/M\) from earlier and strong convexity, we can organize the equation as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;\frac{M}{2m^{2}}\|\nabla f^{(k_{0}+1)}\|_{2} \leq \big( \frac{M}{2m^{2}}\|\nabla f^{(k_{0})}\|_{2} \big) ^{2}.\\\\
&amp;amp;\Leftrightarrow &amp;amp;\frac{M}{2m^{2}}\|\nabla f^{(k_{0}+(k-k_{0}))}\|_{2} \leq \bigg( \big( \frac{M}{2m^{2}}\|\nabla f^{(k_{0}+1)}\|_{2} \big) ^{2} \bigg)^{k-k_{0}} \leq (\frac{1}{2})^{2^{(k-k_{0})}}.\\\\
&amp;amp;\Leftrightarrow &amp;amp;f(y)\geq f(x)+\nabla f(x)^{T}(y-x)+\frac{m}{2}\|y-x\|^{2}_{2}\geq f(x)-\frac{1}{2m}\|\nabla f(x)\|^{2}_{2}, \text{ for all }y,\\\\
&amp;amp;\Leftrightarrow &amp;amp;f(x^{(k)})-f^{\star} \leq \frac{1}{2m}\|\nabla f(x^{k})\|_{2}^{2}\leq \frac{2m^{3}}{M^{2}}(\frac{1}{2})^{2^{k-k_{0}+1}}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, we can organize the convergence according to steps with the \(k_{0}\)-th iteration as the branch point as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theorem: Newton’s method using backtracking line search has two-stage convergence bounds.
\(\begin{align}
&amp;amp;f(x^{(k)})-f^{\star} \leq \begin{cases} (f(x^{(0)})-f^{\star})-\gamma k \qquad &amp;amp;\text{if }k\leq k_{0}\\
\frac{2m^{3}}{M^{2}}(\frac{1}{2})^{2^{k-k_{0}+1}} \qquad &amp;amp;\text{if }k&amp;gt;k_{0}.
\end{cases}
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Here, \(\gamma = \frac{\alpha \beta^{2}\eta^{2}m}{L^{2}}\), \(\eta = \min\{1, 3(1-2\alpha)\}\frac{m^{2}}{M}\), and \(k_{0}\) is the step where \(\|\nabla f(x^{k_0+1}))\|_{2}&amp;lt;\eta\) starts to be satisfied.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof-1-damped-phase&quot;&gt;Proof 1. Damped phase&lt;/h2&gt;
&lt;p&gt;First, we derive the damped phase that satisfies \(\|\nabla f(x)\|_{2} \geq \eta\). We derive the convergence of the damped phase through the lower bound of the step size determined by the backtracking line search process. The Newton decrement relationship is frequently used in the proof process.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We start from the following equation where we set \(y=x+t\Delta x_{nt}\) in the Taylor approximation of \(f\) and apply the upper bound of the Lipschitz condition.&lt;/p&gt;

\[\begin{align}
f(x+t\Delta x_{nt}) \leq f(x)+t\nabla f(x)^{T}\Delta x_{nt} + \frac{L \|\Delta x_{nt} \|^{2}_{2} }{2}t^{2},
\end{align}\]

  &lt;p&gt;Newton decrement, 증분과 hessian matrix와의 관계와 Strong convexity의 관계를 이용하여 다음과 같이 전개할 수 있다.&lt;/p&gt;

\[\begin{align}
&amp;amp;\text{ Since, }\lambda(x)^{2}=\Delta x_{nt}^{T} \nabla^{2} f(x) \geq m\|\Delta x_{nt}\|^{2}_{2},\\\\
&amp;amp;f(x)+t\nabla f(x)^{T}\Delta x_{nt} + \frac{L \|\Delta x_{nt} \|^{2}_{2} }{2}t^{2} \leq f(x)-t\lambda(x)^{2} + \frac{L}{2m}t^{2}\lambda(x)^{2},
\end{align}\]

  &lt;p&gt;이 때, backtracking line search의 조건을 만족하기 위해서는 아래를 만족해야 한다.&lt;/p&gt;

\[\begin{align}
f(x+t\Delta x_{nt}) \leq f(x)-(1-\frac{L}{2m}t)t \lambda(x)^{2}, \qquad \text{ where, }0&amp;lt;1-\frac{L}{2m}t \leq \frac{1}{2}
\end{align}\]

  &lt;p&gt;위를 만족하는 t의 최소값을 \(\hat{t}\)라 할 때, \(\hat{t} = \frac{m}{L}\)이 되고, 이를 원 식에 대입하면 다음과 같다.&lt;/p&gt;

\[\begin{align}
f(x+\hat{t}\Delta x_{nt})\leq f(x)-\frac{m}{2L}\lambda(x)^{2} \leq f(x) -\alpha \hat{t} \lambda(x)^{2},
\end{align}\]

  &lt;p&gt;backtracking line search에서 \(0&amp;lt;\beta\leq 1\)이므로, \(t\geq \beta \frac{m}{L}\)를 만족하고, 이를 정리하여 최종 결과를 유도할 수 있다.&lt;/p&gt;

\[\begin{align}
f(x^{+})-f(x) &amp;amp;\leq -\alpha t \lambda(x)^{2}\\
&amp;amp;\leq -\alpha\beta \frac{m}{L}\lambda(x)^{2}\\
&amp;amp;\leq -\alpha\beta \frac{m}{L^{2}}\|\nabla f(x)\|^{2}_{2}\\
&amp;amp;\leq -\alpha\beta \eta^{2}\frac{m}{L^{2}},\\
&amp;amp;\gamma = \alpha\beta \eta^{2}\frac{m}{L^{2}}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof-2-pure-phase&quot;&gt;Proof 2. Pure phase&lt;/h2&gt;
&lt;p&gt;이제 \(\|\nabla f(x)\|_{2} &amp;lt; \eta\)일 때를 가정하고, Damped phase(quadratically convergent phase)를 살펴본다. 증명은 두가지 과정으로 나뉜다. backtracking line search의 t 업데이트가 필요하지 않음을 보이고, 수렴속도가 quadratic함을 보이게 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Backtracking line search로 부터 다음과 같은 식이 유도된다.&lt;/p&gt;

\[\begin{align}
\eta \leq 3(1-2\alpha)\frac{m^{2}}{M}.
\end{align}\]

  &lt;p&gt;또한, Lipschitz condition에 따라 \(t \geq 0\)에 대하여, 다음 조건을 만족한다.&lt;/p&gt;

\[\begin{align}
\|\nabla^{2}f(x+t\Delta x_{nt})-\nabla^{2}f(x)\|_{2} \leq tM \|\Delta x_{nt} \|_{2},\\
| \Delta x_{nt}^{T} \big( \nabla^{2}f(x+t\Delta x_{nt})-\nabla^{2}f(x) \big) \Delta x_{nt}| \leq tM \|\Delta x_{nt} \|_{2}^{3}.
\end{align}\]

  &lt;p&gt;\(\tilde{f} = f(x+t\Delta x_{nt}\))라 두면, \(\tilde{f}&apos;&apos;(t) = \Delta x_{nt}^{T} \nabla^{2}f(x+t\Delta x_{nt})\Delta x_{nt}\)이고, 이를 대입한다.&lt;/p&gt;

\[\begin{align}
\tilde{f}&apos;&apos;(t) \leq \tilde{f}&apos;&apos;(0)+tM\|\Delta x_{nt}\|^{3}_{2} \leq tM\|\Delta x_{nt} \|^{3}_{2}
\end{align}\]

  &lt;p&gt;\(\tilde{f}&apos;&apos;(0) = \lambda(x)^{2}\)이고, \(\lambda(x)^{2} \geq m\|\nabla x_{nt}\|_{2}^{2}\) 임을 이용하고, 부등식을 합친다. \(\tilde{f}&apos;(0) = -\lambda(x)^{2}\)이므로 다음과 같이 정리할 수 있다.&lt;/p&gt;

\[\begin{align}
\tilde{f}&apos;&apos;(t) &amp;amp;\leq \tilde{f}&apos;&apos;(0) + tM \| \Delta x_{nt} \| ^{3}_{2} \leq \lambda(x)^{2} + t\frac{M}{m^{3/2}}\lambda(x)^{3}, \\
\tilde{f}&apos;(t) &amp;amp;\leq \tilde{f}&apos;(0)+t\lambda(x)^{2} +t^{2}\frac{M}{2m^{3/2}}\lambda(x)^{3},\\
&amp;amp;= -\lambda(x)^{2}+t\lambda(x)^{2} + t^{2}\frac{L}{2m^{3/2}}\lambda(x)^{3}.
\end{align}\]

  &lt;p&gt;이제 양변을 적분한다.&lt;/p&gt;

\[\begin{align}
\tilde{f}(t) \leq \tilde{f}(0) - t\lambda(x)^{2} + t^{2} \frac{1}{2}\lambda(x)^{2} + t^{3}\frac{M}{6m^{3/2}}\lambda(x)^{3}.
\end{align}\]

  &lt;p&gt;t = 1로 두면, 아래와 같은 결과를 얻을 수 있다.&lt;/p&gt;

\[\begin{align}
f(x+\Delta x_{nt}) \leq f(x) -\frac{1}{2}\lambda(x)^{2} + \frac{M}{6m^{3/2}}\lambda(x)^{3}.
\end{align}\]

  &lt;p&gt;이제 \(\|\nabla f(x)\|_{2}\leq \eta \leq 3(1-2\alpha)\frac{m^{2}}{M}\)이라 가정하면, strong convexity 조건에 의해 \(\lambda(x) \leq 3(1-2\alpha)m^{3/2}/L\)이다. 이를 위에 부등식에 대입하면 아래와 같은 결과를 유도할 수 있다.&lt;/p&gt;

\[\begin{align}
f(x+\Delta x_{nt}) &amp;amp;\leq f(x) - \lambda(x)^{2}( \frac{1}{2}- \frac{M\lambda(x)}{6m^{3/2}} ) \\
&amp;amp;\leq f(x) -\alpha \lambda(x)^{2} \\
&amp;amp;= f(x) + \alpha \nabla f(x)^{T} \Delta x_{nt},
\end{align}\]

  &lt;p&gt;이 결과는 \(t=1\)일때 backtracking line search를 수행하더라도 항상 조건을 만족하기 때문에, \(t\)를 감소시키지 않음을 의미한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이제 우리는 수렴속도가 quadratic하게 줄어듬을 증명해본다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(x_{nt} = -(\nabla^{2}f(x))^{-1}\nabla f(x)\)임을 이용한 뒤, 적분의 성질 중 하나인 \(f(t, u) - f(t, v) = \int^{u}_{v}{\frac{\partial f}{\partial x}(t, x) dx}\)를 이용하여 정리하고, Hessian의 Lipschitz 조건을 적분식에 적용하고 정리한다. 마지막으로 strong convexity 조건을 적용하면 증명이 완료된다. 과정을 수식으로 나타내면 아래와 같다.&lt;/p&gt;

\[\begin{align}
\| \nabla f(x^{+}) \| _{2} &amp;amp;= \| \nabla f(x+\Delta x_{nt}) - \nabla f(x) - \nabla^{2}f(x)\Delta x_{nt} \|_{2}\\\\
&amp;amp;=\| \int^{1}_{0}{ \big( \nabla^{2}f(x+t\Delta x_{nt})-\nabla^{2} f(x) \big) \Delta x_{nt} dt } \|_{2}\\\\
&amp;amp; \leq \frac{M}{2}\|\Delta x_{nt} \|^{2}_{2}\\\\
&amp;amp; = \frac{M}{2}\|\nabla^{2}f(x)^{-1}\nabla f(x)\|^{2}_{2}\\\\
&amp;amp; \leq \frac{M}{2m^{2}}\|\nabla f(x)\|^{2}_{2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;결론을 다시 정리하면, \(\eta = \min \{1, 3(1-2\alpha)\}\frac{m^{2}}{M}\) 일 때, \(\|\nabla f(x^{(k)}) \|_{2}&amp;lt;\eta\)를 만족하는 조건에서는 Newton’s method는 backtracing line search에서의 업데이트가 더이상 필요하지 않고, quadratic하게 converge 한다.&lt;/p&gt;

&lt;h2 id=&quot;estimating-total-complexity&quot;&gt;Estimating total complexity&lt;/h2&gt;
&lt;p&gt;이제, 우리는 전체 과정에서의 complexity, 달리 말해 초기 값으로부터 최적값까지 도달하는데 걸리는 iteration 횟수에 대한 bound를 추정할 수 있다.
우선, 위의 damped Newton phase에서 \(f\)는 매 iteration마다 \(\gamma\)를 넘지 않는 선에서 값이 감소하므로, damped Newton step의 전체 step 수는 다음의 식의 결과값을 넘지 못한다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\frac{f(x^{(0)})-p^{\star}}{\gamma}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;pure Newton phase에서의 iteration 횟수의 bound 또한 계산할 수 있다. 위의 식을 \(f(x)-p^{\star}\leq \epsilon\), \(\epsilon_{0} = \frac{2m^{3}}{M^{2}}\)로 두고, iteration 횟수로 식을 정리하면 다음과 같은 값을 계산할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;\epsilon = \epsilon_{0} (\frac{1}{2})^{2^{k-k_{0}+1}}\\\\
&amp;amp;\Leftrightarrow &amp;amp;\frac{\epsilon_{0}}{\epsilon} = 2^{2^{k-k_{0}+1}}\\\\
&amp;amp;\Leftrightarrow &amp;amp;k-k_{0}+1 = log_{2}log_{2}(\frac{\epsilon_{0}}{\epsilon})
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;따라서 pure Newton phase에서 iteration 횟수는 \(\log \log(\frac{\epsilon_{0}}{\epsilon})\)로 bound 된다.&lt;/p&gt;

&lt;p&gt;이 두 결과를 더하면, Newton method를 통하여 원하는 정밀도의 해를 얻는데 필요한 iteration 횟수의 upper bound를 정의할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\frac{f(x^{(0)})-p^{\star}}{\gamma} + \log \log (\frac{\epsilon_{0}}{\epsilon}).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;문제를 해결할때 요구되는 정밀도 \(\epsilon\)의 변화에 비해 우변의 두번째 항은 매우 작은 변화를 보이므로, 실제 응용에서는 이를 상수로 두고 추정을 하게 된다. 일반적으로 6번의 iteration은 \(\epsilon \approx 5\cdot 10^{-20}\epsilon_{0}\)의 정밀도를 보인다고 알려져 있다.&lt;/p&gt;

&lt;p&gt;일반적으로 말해서, 목적함수 \(f\)를 최소화하는데 있어서 필요한 iteration 횟수는 다음과 같다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\frac{f(x^{(0)})-p^{\star}}{\gamma} + 6.
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>14-04 Tìm kiếm đường backtracking</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_04_backtracking_line_search/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_04_backtracking_line_search</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Cho đến nay, chúng ta đã xem xét phương pháp Newton thuần túy. Tuy nhiên, phương pháp này không đảm bảo hội tụ, vì vậy chúng ta sử dụng tìm kiếm đường backtracking để đảm bảo hội tụ trong phương pháp Newton có giảm chấn.&lt;/p&gt;

&lt;h2 id=&quot;phương-pháp-newton-có-giảm-chấn&quot;&gt;Phương pháp Newton có giảm chấn&lt;/h2&gt;
&lt;p&gt;Phương pháp Newton thuần túy áp dụng lặp đi lặp lại cập nhật sau (ở đây \(t=1\)):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{+} = x -t(\nabla^{2}f(x))^{-1}\nabla f(x).
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Phương pháp Newton có giảm chấn sử dụng tìm kiếm đường backtracking. Nếu giá trị hàm tại vị trí được cập nhật lớn hơn xấp xỉ bậc hai, chúng ta thu nhỏ kích thước bước \(t\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{với các tham số }0&amp;lt;\alpha \leq \frac{1}{2}, 0&amp;lt;\beta&amp;lt;1, \\
&amp;amp;\text{trong khi } f(x+tv)&amp;gt;f(x)+\alpha t \nabla f(x)^{T}v\\
&amp;amp;\text{thu nhỏ }t=\beta t
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(v=-(\nabla^{2}f(x))^{-1}\nabla f(x)\) and \(\nabla f(x)^{T}v = -\lambda^{2}(x)\).&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ-hồi-quy-logistic&quot;&gt;Ví dụ: hồi quy logistic&lt;/h2&gt;
&lt;p&gt;Làm ví dụ, đối với hồi quy logistic với n = 500, p = 100, chúng ta so sánh tốc độ hội tụ của gradient descent và phương pháp Newton với tìm kiếm đường backtracking.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter14/2.jpeg&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Hồi quy logistic [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Phương pháp Newton cho thấy tốc độ hội tụ nhanh hơn nhiều so với gradient descent. Từ chương tiếp theo, chúng ta sẽ xem xét tốc độ hội tụ này.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-03 Newton decrement</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_03_newton_decrement/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_03_newton_decrement</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Trong chương này, chúng ta định nghĩa Newton decrement và xem xét ý nghĩa của nó.&lt;/p&gt;

&lt;p&gt;Đối với bài toán tối ưu hóa dưới đây, Newton decrement tại \(x\) được định nghĩa là \(\lambda(x)\):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\min_{x} \quad f(x),\&lt;br /&gt;
\end{align}
\begin{align}
\lambda(x) = (\nabla f(x)^{T}(\nabla^{2}f(x))^{-1}\nabla f(x))^{1/2}.
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;đặc-điểm-của-newton-decrement&quot;&gt;Đặc điểm của Newton decrement&lt;/h2&gt;
&lt;p&gt;Thứ nhất, Newton decrement liên quan đến sự khác biệt giữa hàm \(f(x)\) và giá trị tối thiểu của xấp xỉ bậc hai của nó. Tính toán sự khác biệt này cho:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x)-&amp;amp;\min_{y} \big( f(x)+\nabla f(x)^{T}(y-x)+\frac{1}{2}(y-x)^{T}\nabla^{2}f(x)(y-x)\big),\\\\
f(x)-&amp;amp;\bigg( f(x) + \nabla^{T}f(x)\big( -(\nabla^{2} f(x) )^{-1} \nabla f(x)\big) + \frac{1}{2}\big( -(\nabla^{2}f(x))^{-1} \nabla f(x) \big)^{T} \nabla ^{2}f(x) \big( -(\nabla^{2}f(x))^{-1}\nabla f(x) \big) \bigg) \\\\ 
&amp;amp;= \frac{1}{2}\nabla f(x)^{T}(\nabla^{2} f(x) )^{-1}\nabla f(x) = \frac{1}{2}\lambda(x)^{2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Do đó, \(\frac{1}{2}\lambda^{2}(x)\) có thể được coi là một cận xấp xỉ cho khoảng cách tối ưu \(f(x)-f^{\star}\).&lt;/p&gt;

&lt;p&gt;Thứ hai, hướng Newton trong phương pháp Newton cho mỗi lần lặp là \(v = -(\nabla^{2}f(x))^{-1}\nabla f(x)\), và Newton decrement là độ dài của bước Newton trong chuẩn được định nghĩa bởi Hessian \(\nabla^{2}f(x)\).&lt;/p&gt;

&lt;p&gt;Ngoài ra, điều này có thể được xem là một loại khoảng cách Mahalanobis [&lt;a href=&quot;https://en.wikipedia.org/wiki/Mahalanobis_distance&quot;&gt;Wikipedia&lt;/a&gt;], trong đó bước mới \(y\) là quan sát, vị trí hiện tại \(x\) là giá trị trung bình, và Hessian của \(f(x)\) là hiệp phương sai. Khoảng cách Mahalanobis đo khoảng cách từ một điểm đến giá trị trung bình theo hướng của hiệp phương sai của phân phối.&lt;/p&gt;

&lt;p&gt;Nếu chúng ta xem xét định nghĩa khoảng cách Mahalanobis là khoảng cách giữa một điểm và giá trị trung bình của một phân phối chia cho độ lệch chuẩn theo hướng đó, Newton decrement biểu diễn khoảng cách của bước mới từ vị trí hiện tại, với Hessian đóng vai trò là hiệp phương sai của phân phối.&lt;/p&gt;

&lt;p&gt;Thứ ba, Newton decrement có thể được biểu diễn theo số gia và Hessian. Bắt đầu từ cập nhật bước trong phương pháp Newton, chúng ta có:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{+} &amp;amp;= x-\big(\nabla^{2} f(x) \big)^{-1} \nabla f(x) &amp;amp;\ 
\end{align}
\begin{align}
\Delta x_{nt} &amp;amp;= -\big(\nabla^{2} f(x) \big)^{-1} \nabla f(x) &amp;amp;&lt;br /&gt;
\end{align}
\begin{align}
\nabla f(x)^{T} \Delta x_{nt} &amp;amp;= -\lambda (x)^{2}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Sử dụng các mối quan hệ này, Newton decrement cũng có thể được biểu diễn là:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\lambda(x) = (\Delta x_{nt}^{T}\nabla^{2} f(x) \Delta x_{nt})^{1/2}.
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Cuối cùng, giống như bước Newton, Newton decrement cũng bất biến affine. Nói cách khác, đối với bất kỳ ma trận không suy biến nào, nếu hàm \(g(y) = f(Ay)\) được định nghĩa, thì tại \(x = Ay\), ta có \(\lambda_{g(y)} = \lambda_{f(x)}\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-02 Giải thích và Tính chất</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_02_interpretation_and_properties/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_02_interpretation_and_properties</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Trong chương này, trước khi xem xét các tính chất của phương pháp Newton, chúng ta tìm hiểu về việc áp dụng phương pháp Newton vào các bài toán tìm nghiệm của các hàm mục tiêu.&lt;/p&gt;

&lt;p&gt;Tiếp theo, chúng ta sẽ xem xét hai tính chất quan trọng của phương pháp Newton: Bất biến affine và Hội tụ cục bộ.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-02-03 Phân tích hội tụ cục bộ</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_02_03_local_convergence_analysis/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_02_03_local_convergence_analysis</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
});
&lt;/script&gt;

&lt;p&gt;Tính chất quan trọng thứ hai của phương pháp Newton là sự hội tụ được đảm bảo gần nghiệm khi các điều kiện nhất định được thỏa mãn. Điều này được gọi là hội tụ cục bộ. Vì phương pháp Newton thuần túy mà chúng ta đã thảo luận từ &lt;a href=&quot;/contents/vi/chapter14/14_01_newton_method/&quot;&gt;14-01&lt;/a&gt; không đảm bảo hội tụ, sau này chúng ta sẽ thiết kế phương pháp Newton có giảm chấn để đảm bảo hội tụ bằng cách điều chỉnh kích thước bước sử dụng cùng phương pháp tìm kiếm đường backtracking được đề cập trong &lt;a href=&quot;/contents/vi/chapter06/06_00_gradient_descent/&quot;&gt;Chương 6&lt;/a&gt;, và phân tích sự hội tụ của nó.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Định lý: Cho \(F : \mathbb{R}^{n}\, \rightarrow  \, \mathbb{R}^{n}\) liên tục khả vi, và cho \(x^{\star} \in \mathbb{R}^{n}\) là một nghiệm của hàm \(F\), tức là \(F(x^{\star})=0\).
Nếu \(F^{&apos;}(x^{\star})\) không suy biến, thì các điều kiện (a) và (b) sau được thỏa mãn: &lt;br /&gt;
(a) Nếu tồn tại một \(\delta\) dương (&amp;gt;0) sao cho \(\| x^{(0)}-x^{\star} \|&amp;lt;\delta\) và phương pháp Newton được định nghĩa, thì phương trình sau (hội tụ siêu tuyến tính) được thỏa mãn:
\begin{align}
\lim_{ k \rightarrow \infty } \frac{ || x^{ (k+1) }-x^{ \star } || } { || x^{ (k) }-x^{ \star } || } =0.
\end{align} &lt;br /&gt;
(b) Nếu \(F^{&apos;}\) liên tục Lipschitz gần \(x^{\star}\), thì tồn tại một K dương (&amp;gt;0) sao cho phương trình sau (hội tụ bậc hai) được thỏa mãn:
\begin{align}
||x^{ (k+1) } - x^{ \star }|| \leq K || x^{ (k) }-x^{ \star }||^{2}.
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;chứng-minh-a&quot;&gt;Chứng minh (a)&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Chúng ta sắp xếp \(F(x^{\star})\) đến bậc 1 sử dụng khai triển Taylor. Vì các số hạng bậc 2 và cao hơn được giới hạn bởi một bội số hằng của chuẩn của số hạng bậc 1, chúng ta có thể biểu diễn nó bằng ký hiệu little-o như sau:
\begin{align}
0=F(x^{\star}) = F(x^{k}) +\nabla F(x^{k})(x^{\star}-x^{k})+o(||x^{k}-x^{\star}||).&lt;br /&gt;
\end{align}
Nhân cả hai vế với \(\nabla F(x^{k})^{-1}\) và sắp xếp. Vì little-o được xử lý như một số hạng hằng số, nó có thể được bỏ qua.
\begin{align}
x^{k}-x^{\star}-\nabla F(x^{k})^{-1} F(x^{k}) = o(||x^{k}-x^{\star}||).
\end{align}
Sử dụng phương pháp Newton \(x^{k+1}=x^{k}-\nabla F(x^{k})^{-1}F(x^{k})\), chúng ta có thể thu được kết quả sau:
\begin{align}
x^{k+1}-x^{\star}=o(||x^{k}-x^{\star}||),
\end{align}
Do đó, khi \(x^{k} \neq x^{\star}\), chúng ta có thể chứng minh (a) bằng định nghĩa giới hạn của little-o [&lt;a href=&quot;https://en.wikipedia.org/wiki/Big_O_notation&quot;&gt;wikipedia&lt;/a&gt;].&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\lim_{k\rightarrow \infty} \frac{||x^{k+1}-x^{\star}||}{||x^{k}-x^{\star}||} = \lim_{k\rightarrow \infty}\frac{o(||x^{k}-x^{\star}||)}{||x^{k}-x^{\star}||}.
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;chứng-minh-b&quot;&gt;Chứng minh (b)&lt;/h2&gt;
&lt;p&gt;Quá trình này giống hệt với việc chứng minh rằng tốc độ hội tụ trong giai đoạn Damped của [&lt;a href=&quot;/contents/vi/chapter14/14_05_convergence_analysis/&quot;&gt;14-05&lt;/a&gt;] là bậc hai. Do đó, nó được bỏ qua.&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ--trường-hợp-phân-kỳ&quot;&gt;Ví dụ : trường hợp phân kỳ&lt;/h2&gt;
&lt;p&gt;Chúng ta xem xét ngắn gọn một ví dụ mà sự hội tụ không được đảm bảo với phương pháp Newton thuần túy.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter14/1_.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] phương pháp Newton thuần túy áp dụng cho tìm nghiệm : trường hợp phân kỳ &lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;https://slideplayer.com/slide/4998677/&quot;&gt;image-link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Như được hiển thị trong hình, tùy thuộc vào điểm khởi tạo \(x_0\), nghiệm có thể phân kỳ.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-02-02 Tính bất biến affine của phương pháp Newton</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_02_02_affine_invariance_of_newton_method/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_02_02_affine_invariance_of_newton_method</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Một trong những tính chất quan trọng của phương pháp Newton là nó bất biến affine. Điều này có nghĩa là hướng của việc cập nhật không phụ thuộc vào các phép biến đổi affine của hệ tọa độ. Ví dụ, gradient descent biến thiên theo các phép biến đổi affine, do đó tốc độ hội tụ khác nhau tùy thuộc vào không gian tọa độ.&lt;/p&gt;

&lt;p&gt;Trang này dẫn xuất tính chất bất biến affine.&lt;/p&gt;

&lt;h2 id=&quot;tính-bất-biến-affine--chứng-minh&quot;&gt;Tính bất biến affine : chứng minh&lt;/h2&gt;
&lt;p&gt;Cho \(f:\mathbb{R}^{n}\rightarrow \mathbb{R}\) khả vi hai lần, và cho \(A\in \mathbb{R}^{n\times n}\) không suy biến. Cũng định nghĩa \(g(y)\) là \(f(Ay)\). \(g(y):=f(Ay)\). Điều này có nghĩa là một hàm \(g\) nào đó nhận \(y\) làm đầu vào có cùng đầu ra như hàm \(f\) nhận \(Ay\) (biến đổi affine bởi \(A\) đối với \(y\)) làm đầu vào. Để giảm thiểu sự nhầm lẫn về ký hiệu và đối số gradient, chúng ta định nghĩa \(x:=Ay\).&lt;/p&gt;

&lt;p&gt;Sử dụng quy tắc chuỗi để lấy đạo hàm cả hai vế một lần và hai lần, chúng ta nhận được các kết quả sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\nabla g(y) &amp;amp;= A^{T} \nabla f(x)\\\\
\nabla^{2} g(y) &amp;amp;= A^{T}\nabla^{2}f(x)A,
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bước Newton của \(g\) đối với \(y\) như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
y^{+}  = y-(\nabla^{2}g(y))^{-1}\nabla g(y).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, thay vì hàm \(g\), nếu chúng ta biến đổi và sắp xếp nó theo hàm \(f\) đối với \(x\), chúng ta có thể dẫn xuất bước Newton cho \(x\) và \(f\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
y^{+} &amp;amp;= y-(A^{T}\nabla^{2}f(x)A)^{-1}A^{T} \nabla f(x)\\\\
\Leftrightarrow y^{+} &amp;amp;= y-A^{-1}(\nabla^{2}f(x))^{-1}(A^{T})^{-1}A^{T} \nabla f(x)\\\\
\Leftrightarrow Ay^{+} &amp;amp;= Ay-(\nabla^{2}f(x))^{-1}\nabla f(x)\\\\
\Leftrightarrow x^{+} &amp;amp;= x - \nabla^{2}f(x)^{-1}\nabla f(x).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này có nghĩa là bước Newton là bất biến affine, tức là, các cập nhật trong các hệ tọa độ được biến đổi bởi các phép biến đổi affine được biểu diễn bởi các ma trận không suy biến là giống hệt nhau.&lt;/p&gt;

&lt;p&gt;Sử dụng cùng phương pháp để kiểm tra tính bất biến affine của gradient descent bằng cách dẫn xuất cập nhật bước, chúng ta có thể thu được kết quả sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
y^{+} &amp;amp;= y-t_{k}\cdot \nabla g(y)\\\\
\Leftrightarrow y^{+} &amp;amp;= y-t_{k}\cdot \nabla f(x)A^{T}\\\\
\Leftrightarrow x^{+} &amp;amp;= x - t_{k}\cdot A\nabla f(x)A^{T}. 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Trong trường hợp của gradient descent, vì ma trận Hessian được xấp xỉ là \(\frac{1}{t}I\) cho các cập nhật, chúng ta có thể thấy rằng hướng của cập nhật thay đổi đối với các tọa độ được biến đổi affine.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-02-01 Tìm nghiệm</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_02_01_root_finding/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_02_01_root_finding</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Trong chương này, chúng ta áp dụng phương pháp Newton vào bài toán tìm nghiệm. Phương pháp Newton được sử dụng trong các bài toán tối ưu hóa có một số khác biệt, được giải thích ở đây. [&lt;a href=&quot;https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization&quot;&gt;Newton’s method in optimization&lt;/a&gt;][&lt;a href=&quot;https://en.wikipedia.org/wiki/Newton%27s_method&quot;&gt;Newton’s method in root finding&lt;/a&gt;]&lt;/p&gt;

&lt;h2 id=&quot;phương-pháp-newton-cho-tìm-nghiệm&quot;&gt;Phương pháp Newton cho tìm nghiệm&lt;/h2&gt;
&lt;p&gt;Giả sử chúng ta có một hàm vector \(F:\mathbb{R}^{n}\rightarrow \mathbb{R}^{n}\). Bài toán tìm nghiệm là tìm \(x\) sao cho \(F(x) = 0\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
F(x) = 0.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán này được giải quyết bằng cách chọn một giá trị khởi tạo \(x^{(0)}\) và áp dụng phương pháp Newton một cách lặp đi lặp lại:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{chọn giá trị khởi tạo }x^{(0)}\in \mathbb{R}^{n},\\\\
&amp;amp;x^{(k)}=x^{(k-1)}-\nabla F(x^{(k-1)})^{-1}F(x^{(k-1)}), \qquad k=1,2,3,...\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(\nabla F(x^{(k-1)})\) là ma trận Jacobian của \(F\) tại \(x^{(k-1)}\). Bước Newton \(x^{+}=x-\nabla F(x)^{-1}F(x)\) có thể được dẫn xuất bằng cách sử dụng xấp xỉ tuyến tính của \(F\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
F(y)\approx F(x) + F^{&apos;}(x)(y-x) = 0\\\\
y = x^{+}=x-F^{&apos;}(x)^{-1}F(x).
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;phương-pháp-newton-cho-bài-toán-tối-ưu-hóa&quot;&gt;Phương pháp Newton cho bài toán tối ưu hóa&lt;/h2&gt;
&lt;p&gt;Giả sử chúng ta áp dụng phương pháp Newton vào một bài toán tối ưu hóa được công thức hóa như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{x} F(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này tương đương với việc áp dụng phương pháp Newton vào bài toán tìm nghiệm cho gradient \(\nabla{F(x)}=0\) của hàm mục tiêu \(F(x)\).&lt;/p&gt;

&lt;p&gt;Tóm lại, không giống như bài toán tìm nghiệm của đạo hàm của một hàm cho trước (\(\nabla F=0\)) bằng phương pháp Newton trong các bài toán tối ưu hóa, bài toán tìm nghiệm yêu cầu tìm nghiệm của chính giá trị hàm (\(F=0\)) bằng phương pháp Newton. Điều này dẫn đến sự khác biệt một bậc trong số hạng đạo hàm trong công thức cập nhật cho \(x\) trong phương pháp Newton cho mỗi bài toán.&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ-tìm-nghiệm&quot;&gt;Ví dụ tìm nghiệm&lt;/h2&gt;
&lt;p&gt;Xem xét một hàm \(F:\mathbb{R}\rightarrow\mathbb{R}\) được định nghĩa như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
F(x)=x^{2}-2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bắt đầu với một giá trị khởi tạo \(x^{(0)}=1\), chúng ta áp dụng phương pháp Newton thuần túy, thu được các kết quả sau:&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter14/table1.jpeg&quot; alt=&quot;&quot; width=&quot;90%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Phương pháp Newton được áp dụng trên ví dụ[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Khi số lần lặp \(k\) tăng lên, chúng ta có thể thấy rằng giá trị của \(x\) tiến gần đến nghiệm \(\sqrt 2\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-01 Phương pháp Newton</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_01_newton_method/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_01_newton_method</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Các phương pháp gradient descent mà chúng ta đã thảo luận được gọi là &lt;strong&gt;phương pháp bậc nhất&lt;/strong&gt; vì các nghiệm dựa trên đạo hàm bậc nhất của hàm số. Phương pháp Newton là một &lt;strong&gt;phương pháp bậc hai&lt;/strong&gt;, có nghĩa là nghiệm yêu cầu tính toán đạo hàm bậc hai.&lt;/p&gt;

&lt;p&gt;Hãy xem xét một bài toán tối ưu hóa cho hàm số \(f\) không có ràng buộc, khả vi hai lần, lồi, và có dom(\(f\)) = \(\mathbb{R}^{n}\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{x} f(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Trong &lt;a href=&quot;/contents/vi/chapter06/06_00_gradient_descent/&quot;&gt;Gradient descent&lt;/a&gt;, chúng ta đã thực hiện quy trình sau đây cho hàm số \(f\):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Thực hiện xấp xỉ Taylor bậc hai&lt;/li&gt;
  &lt;li&gt;Giả sử ma trận Hessian tương ứng với số hạng đạo hàm bậc hai là \(I/t\), tức là ma trận đơn vị chia cho t (kích thước bước)&lt;/li&gt;
  &lt;li&gt;Thực hiện xấp xỉ bậc hai để tiến hành bước cập nhật&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Quy trình chi tiết được giải thích trong bước cập nhật gradient descent ở trang tiếp theo. Công thức bước cập nhật tại mỗi lần lặp như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{chọn giá trị khởi tạo } x^{(0)} \in \mathbb{R}^{n},\\\\
&amp;amp;x^{(k)} = x^{(k-1)} - t_{k} \cdot \nabla f(x^{(k-1)}), \qquad k = 1,2,3,...
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Phương pháp Newton (phương pháp Newton thuần túy) thực sự tính toán số hạng đạo hàm bậc hai mà được giả sử là \(\frac{1}{t}I\) trong gradient descent, thực hiện xấp xỉ bậc hai, và tiến hành bước cập nhật. Quy trình này cũng được giải thích trong bước cập nhật phương pháp Newton ở trang tiếp theo. Công thức bước cập nhật tại mỗi lần lặp như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{chọn giá trị khởi tạo } x^{(0)} \in \mathbb{R}^{n},\\\\
&amp;amp;x^{(k)} = x^{(k-1)} - \Big(\nabla^{2}f(x^{(k-1)})\Big)^{-1} \nabla f(x^{(k-1)}), \qquad k = 1,2,3,...
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>14-01-01 Giải thích phương pháp Newton</title>
   <link href="http://localhost:4000/contents/vi/chapter14/14_01_01_newton_method_interpretation/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/14_01_01_newton_method_interpretation</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
});
&lt;/script&gt;

&lt;p&gt;Trang này xem xét cách bước cập nhật đã thảo luận trước đó được dẫn xuất từ xấp xỉ bậc hai của hàm số gốc \(f\). Chúng ta cũng so sánh nó với bước cập nhật gradient descent được đề cập trong &lt;a href=&quot;/contents/vi/chapter06/06_00_gradient_descent/&quot;&gt;Chương 6&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;bước-cập-nhật-phương-pháp-newton&quot;&gt;Bước cập nhật phương pháp Newton&lt;/h2&gt;
&lt;p&gt;Xấp xỉ Taylor bậc hai (xấp xỉ bậc hai) của hàm số \(f\) như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y)	\approx f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2}(y-x)^{T}\nabla^{2}f(x)(y-x),\\\\
f_{approx}(y)	= f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2}(y-x)^{T}\nabla^{2}f(x)(y-x).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(y\) là giá trị \(x\) của bước tiếp theo, tức là \(x^{+}\). Chúng ta cũng định nghĩa xấp xỉ bậc hai là \(f_{approx}\).&lt;/p&gt;

&lt;p&gt;Chúng ta muốn tìm đầu vào \(y\) để tối thiểu hóa \(f_{approx}\) này, tức là xấp xỉ bậc hai. Vì \(f_{approx}\) là lồi, đầu vào \(y\) làm cho gradient của phương trình trên bằng không sẽ tối thiểu hóa \(f_{approx}\). Kết quả này trở thành công thức cập nhật bước trong phương pháp Newton. Hãy nhớ rằng việc lấy đạo hàm trong phương trình dưới đây là theo y.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\nabla f_{approx}(y)	&amp;amp;= \nabla f(x) +\frac{1}{2} \Big((\nabla^{2} f(x))^{T}(y-x)+(y-x)^{T}\nabla^{2}f(x)\Big)\\\\
&amp;amp;=\nabla f(x) +\nabla^{2} f(x)(y-x)\\\\
&amp;amp; = 0,\\\\
\Leftrightarrow y &amp;amp;= x-(\nabla^{2}f(x))^{-1}\nabla f(x).
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;bước-cập-nhật-gradient-descent&quot;&gt;Bước cập nhật gradient descent&lt;/h2&gt;
&lt;p&gt;Trong gradient descent, chúng ta sử dụng các số hạng xấp xỉ Taylor bậc hai của hàm số \(f\), nhưng đối với số hạng bậc hai, chúng ta giả sử nó là ma trận đơn vị chia cho \(t\), thay vì kết quả đạo hàm bậc hai thực tế.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y)	\approx f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2t}\|{y-x}\|_{2}^{2},\\\\
f_{approx}(y)	= f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2t}\|{y-x}\|_{2}^{2}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Tương tự như phương pháp Newton, chúng ta có thể xác định giá trị \(y\) mà tại đó gradient của xấp xỉ trên bằng không, tức là \(x^{+}\).&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\nabla f(y) &amp;amp;= \nabla f(x) + \frac{1}{t}(y-x), \\\\
&amp;amp;= 0,\\\\
y &amp;amp;= x-t\nabla f(x).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Kết quả này giống hệt với bước cập nhật của gradient descent.&lt;/p&gt;

&lt;p&gt;Để biết thông tin chi tiết về gradient descent, hãy tham khảo &lt;a href=&quot;/contents/vi/chapter06/06_00_gradient_descent/&quot;&gt;chương gradient descent&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ&quot;&gt;Ví dụ&lt;/h2&gt;
&lt;p&gt;Làm ví dụ, đối với hàm số \(f = (10x_{1}^{2}+x_{2}^{2})/2+5log(1+e^{-x_{1}-x_{2}})\), chúng ta giả sử thực hiện các bước có độ dài gần bằng nhau. Tức là, chúng ta đặt kích thước bước trong gradient descent để khớp với độ lớn cập nhật của phương pháp Newton tại mỗi lần lặp, và so sánh hướng hội tụ của gradient descent (màu đen) và phương pháp Newton (màu xanh) theo các bước của chúng.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter14/gd.jpeg&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] So sánh giữa gradient descent (màu đen) và phương pháp Newton (màu xanh)[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Như có thể thấy trong Hình 1, gradient descent giả sử số hạng đạo hàm bậc hai là một hằng số nhân với ma trận đơn vị khi tính toán gradient, do đó nó hội tụ vuông góc với hướng tiếp tuyến của các đường đồng mức, và cho thấy tốc độ hội tụ chậm hơn so với phương pháp Newton. Các chương còn lại sẽ đề cập đến các tính chất, đặc điểm, sự hội tụ, ví dụ, v.v. của phương pháp Newton.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14 Newton's Method</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_newton_method/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_newton_method</id>
   <content type="html">&lt;p&gt;In this chapter, we look at Newton’s Method.&lt;/p&gt;

&lt;p&gt;Newton’s method is an approach for finding the minimum of a function with a twice differentiable function using the second-order Taylor expansion. It finds the minimum by approximating the function and iteratively updating the solution. Near the optimum, it achieves quadratic convergence and is much faster than gradient descent.&lt;/p&gt;

&lt;h2 id=&quot;references-and-further-readings&quot;&gt;References and further readings&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;S. Boyd and L. Vandenberghe (2004), “Convex optimization”, Chapter 9 and 10&lt;/li&gt;
  &lt;li&gt;Y. Nesterov (1998), “Introductory lectures on convex optimization: a basic course”, Chapter 2&lt;/li&gt;
  &lt;li&gt;Y. Nesterov and A. Nemirovskii (1994), “Interior-point polynomial methods in convex programming”, Chapter 2&lt;/li&gt;
  &lt;li&gt;J. Nocedal and S. Wright (2006), “Numerical optimization”, Chapters 6 and 7&lt;/li&gt;
  &lt;li&gt;L. Vandenberghe, Lecture notes for EE 236C, UCLA, Spring 2011-2012&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>14-09 Quasi-Newton methods</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_09_quasi_newton_methods/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_09_quasi_newton_methods</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
    });
&lt;/script&gt;

&lt;p&gt;If the computation of the Hessian is too expensive or the Hessian is singular, we use quasi-Newton methods to approximate the Hessian matrix, i.e., \(\nabla^{2}f(x)\) is replaced by \(H&amp;gt;0\), and we use \(H\) for the update:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{+} = x - tH^{-1}\nabla f(x)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Some features of quasi-Newton methods are as follows. For more details, see &lt;a href=&quot;/contents/en/chapter18/18_00_Quasi_Newton_methods/&quot;&gt;Chapter 18&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The approximate Hessian \(H\) is updated at each step. The goal is to use a relatively cheap computation for \(H^{-1}\).&lt;/li&gt;
  &lt;li&gt;The convergence rate is superlinear, but not as fast as Newton’s method. Typically, \(n\) steps of quasi-Newton are equivalent to one step of Newton in terms of progress.&lt;/li&gt;
  &lt;li&gt;Many quasi-Newton methods update \(H\) at each iteration using propagation techniques.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>14-08 Special cases</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_08_special_cases/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_08_special_cases</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
    });
&lt;/script&gt;

&lt;h2 id=&quot;sparse-structured-problems&quot;&gt;Sparse, structured problems&lt;/h2&gt;
&lt;p&gt;If the linear system matrix in the problem is sparse and structured, and the Hessian can be efficiently computed, we can solve the problem more efficiently.&lt;/p&gt;

&lt;p&gt;For example, if \(\nabla^{2}f(x)\) is sparse and structured for all \(x\), such as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Band_matrix&quot;&gt;band matrix&lt;/a&gt;, Newton’s method can achieve \(O(n)\) performance in memory and computation. (A band matrix is a matrix where nonzero entries are only near the diagonal.)&lt;/p&gt;

&lt;p&gt;Let’s look at two typical examples of functions with structured Hessians:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;If \(g(\beta) = f(X\beta)\), then \(\nabla^{2}g(\beta)=X^{T}\nabla^{2}f(X\beta)X\). If \(X\) is a structured predictor matrix and \(\nabla^{2}f\) (the Hessian of \(f\)) is diagonal, then \(\nabla^{2}g\) is also structured.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If \(\nabla^{2}f\) is diagonal and \(g\) is non-smooth, consider minimizing \(f(\beta)+g(D\beta)\), where \(D\) is a structured penalty matrix. The Lagrange dual is \(-f^{*}(-D^{T}u)-g^{*}(-u)\). In general, \(-D\nabla^{2}f^{*}(-D^{T}u)D^{T}\) is also structured.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;equality-constrained-newtons-method&quot;&gt;Equality-constrained Newton’s method&lt;/h2&gt;
&lt;p&gt;Now let’s look at optimization problems with equality constraints. Generally, we can approach this problem in three ways:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} f(x) &amp;amp; \text{subject to }Ax=b.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;1) Reduced-space approach: Restrict the domain to the space satisfying the equality constraint. For the above problem, express \(x\) as \(x=Fy+x_{0}\), where \(F\) spans the null space of \(A\) and \(Ax_{0}=b\). Then solve for \(y\).&lt;/p&gt;

&lt;p&gt;2) Equality-constrained Newton’s method: Similar to unconstrained Newton’s method, but with two differences. First, the initial value must be feasible (\(x \in dom (f)\) and \(Ax = b\)). Second, the Newton step \(\Delta x_{nt}\) must satisfy \(A\Delta x_{nt}=0\). See below for details.&lt;/p&gt;

&lt;p&gt;3) Dual approach: The Fenchel dual is \(-f^{*}(-A^{T}v)-b^{T}v\), and strong duality holds. (&lt;a href=&quot;/contents/en/chapter16/16_03_fenchel_duality/&quot;&gt;16-03&lt;/a&gt; covers this in detail.) Use the conjugate function to solve the dual problem. Here, \(f^{*}\) is the conjugate of \(f\).&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
g(v) &amp;amp;= -b^{T}v + \min_{x}(f(x)+v^{T}Ax)\\\\
&amp;amp;= -b^{T}v - \max_{x}\big( (-A^{T}v)^{T}x - f(x) \big)\\\\
&amp;amp;= -b^{T}v - f^{*}(-A^{T}v),
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This leads to the following dual problem:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\max -b^{T}v-f^{*}(-A^{T}v). 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Assuming the optimal value exists, this problem is strictly feasible and satisfies Slater’s condition. Therefore, as mentioned earlier, strong duality holds, and there exists a \(v^{*}\) such that \(g(v^{*})=p^{*}\).[1, p.525]&lt;/p&gt;

&lt;p&gt;Now, let’s examine the second method.
To derive a feasible Newton step \(\Delta x_{nt}\), we replace the objective function in the original problem with a quadratic approximation around \(x\). This can be expressed as:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\text{minimize}\quad &amp;amp;\hat{f}(x+v) = f(x) + \nabla f(x)^{T}v + \frac{1}{2}v^{T}\nabla^{2} f(x) v\\\\
\text{subject to}\quad &amp;amp;A(x+v) = b,
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This can also be expressed as:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^{+} = x + tv,\,\, \text{where}\\\\
v = \underset{A(x+z)=b}{\operatorname{argmin}}\big( f(x)+\nabla f(x)^{T}z+\frac{1}{2}z^{T}\nabla^{2} f(x)z \big)\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Since \(Ax^{+} = Ax+tAv = b\), the solution \(x\) remains within the constraint in the subsequent steps of the iteration.&lt;/p&gt;

&lt;p&gt;The KKT conditions for this problem can be expressed as follows, and by solving the linear system below, we can obtain the solution. Recall that \(v\) is the Newton step \(\Delta x_{nt}\).&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\begin{bmatrix}
\nabla^{2} f(x) &amp;amp; A^{T}\\\\
A &amp;amp; 0
\end{bmatrix}
\begin{bmatrix}
v\\\\
w
\end{bmatrix}
=-
\begin{bmatrix}
\nabla f(x)\\\\
Ax-b
\end{bmatrix}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(w\) is the optimal dual variable for the above quadratic problem.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-07 Comparison to first-order method</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_07_comparison_to_first_order_method/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_07_comparison_to_first_order_method</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
    });
&lt;/script&gt;

&lt;p&gt;In this chapter, we compare Newton’s method and gradient descent from a general perspective. Let the dimension of the domain be \(n\).&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Item&lt;/th&gt;
      &lt;th&gt;Newton’s method&lt;/th&gt;
      &lt;th&gt;Gradient descent&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Memory&lt;/td&gt;
      &lt;td&gt;\(O(n^{2})\) (storage for \(n \times n\) Hessian matrix)&lt;/td&gt;
      &lt;td&gt;\(O(n)\) (storage for \(n\)-dimensional gradient)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Computation&lt;/td&gt;
      &lt;td&gt;\(O(n^{3})\) flops (computation for \(n \times n\) linear system)&lt;/td&gt;
      &lt;td&gt;\(O(n)\) flops (computation for \(n\)-dimensional vector addition)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Backtracking&lt;/td&gt;
      &lt;td&gt;\(O(n)\)&lt;/td&gt;
      &lt;td&gt;\(O(n)\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Conditioning&lt;/td&gt;
      &lt;td&gt;Affine invariant, less affected by conditioning&lt;/td&gt;
      &lt;td&gt;Can be strongly affected by conditioning&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fragility&lt;/td&gt;
      &lt;td&gt;Sensitive to bugs or numerical errors&lt;/td&gt;
      &lt;td&gt;More robust than Newton’s method&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter14/gd(1).jpeg&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Logistic regression [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Figure 1 above is a logistic regression example discussed in &lt;a href=&quot;/contents/en/chapter14/14_04_backtracking_line_search/&quot;&gt;14-04&lt;/a&gt;. If you plot the x-axis as actual computation time, you see the following. In convergence analysis, Newton’s method has two phases. In practice, after a certain time, you can observe fast convergence (quadratic convergence). In the initial damped phase of Newton’s method, the convergence rate is similar to gradient descent. However, since \(O(n^{3})\) computation is required, the actual computation time may be slower. After backtracking line search is no longer needed, you observe quadratic convergence and very fast progress.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-06 Self concordance</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_06_self_concordance/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_06_self_concordance</id>
   <content type="html">&lt;p&gt;In the previous convergence analysis of Newton’s method, there are two major issues. [1]&lt;/p&gt;

&lt;p&gt;First, in practical problems, it is difficult to find the Lipschitz constant L, the lower and upper bounds of strong convexity m, M, etc., which are included in the formulas. Because of this, while we can observe convergence and convergence rate, it is almost impossible to analyze how many Newton steps are needed in practice.&lt;/p&gt;

&lt;p&gt;Second, although Newton’s method itself is affine invariant, the convergence analysis of Newton’s method is not affine invariant. For general functions, the values of the Lipschitz constant or strong convexity bounds change depending on the coordinate transformation.&lt;/p&gt;

&lt;p&gt;Therefore, in this chapter, we introduce self-concordant functions, which address the above two issues.&lt;/p&gt;

&lt;p&gt;Self-concordant functions are important and meaningful for three main reasons:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The log barrier functions used in interior-point methods are self-concordant functions.&lt;/li&gt;
  &lt;li&gt;In the analysis of Newton’s method for self-concordant functions, terms involving constants do not appear.&lt;/li&gt;
  &lt;li&gt;Self-concordance is affine-invariant. That is, the number of Newton iterations required is independent of affine transformations of the coordinate system.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>14-06-02 Convergence analysis for self-concordant functions</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_06_02_convergence_analysis_for_self_concordant_functions/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_06_02_convergence_analysis_for_self_concordant_functions</id>
   <content type="html">&lt;p&gt;For self-concordant functions, the result of convergence analysis is as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theorem (Nesterov and Nemirovskii): Newton’s method with backtracking line search requires the following number of iterations to achieve \(f(x^{(k)})-f^{\star}\leq \epsilon\):
\begin{align}
C(\alpha, \beta)\big( f(x^{(0)}-f^{\star} \big) + \log\log{(1/\epsilon)},
\end{align}
where \(C(\alpha, \beta)\) is a constant depending on \(\alpha, \beta\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The proof above is similar to the convergence analysis for Newton’s method, but uses the properties of self-concordant functions to organize the steps. (See [1], p.503)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-06-01 Definition of self-concordant functions</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_06_01_definition_of_self_concordant_functions/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_06_01_definition_of_self_concordant_functions</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
    });
&lt;/script&gt;

&lt;h2 id=&quot;self-concordant-on-r&quot;&gt;Self-concordant on \(R\)&lt;/h2&gt;
&lt;p&gt;A convex function \(f : R \rightarrow R\) is defined as self-concordant when it satisfies the following equation:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\|f^{&apos;&apos;&apos;}(x)\| \leq 2f^{&apos;&apos;}(x)^{3/2} \qquad \text{for all }x\in \text{dom }f.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;As simple examples, linear functions (\(ax+b\)) and (convex) quadratic functions are self-concordant because their third derivative values are 0.&lt;/p&gt;

&lt;h2 id=&quot;self-concordant-on-rn&quot;&gt;Self-concordant on \(R^{n}\)&lt;/h2&gt;
&lt;p&gt;A function \(f : R^{n}\rightarrow R\) is defined as self-concordant when it is self-concordant for any line segment within the domain, that is, for all line segments included in the domain. For example, for all \(x\in dom\, f\) and all \(v\), when \(g(t) = f(x+tv)\) is defined, if \(g(t)\) is self-concordant, then f is defined as a self-concordant function in the domain of \(\mathbb{R}^{n}\).&lt;/p&gt;

&lt;h2 id=&quot;example-of-self-concordance-function&quot;&gt;Example of self-concordance function&lt;/h2&gt;

&lt;p&gt;1) \(f : \mathbb{R}^{n}_{++}\rightarrow \mathbb{R}\), \(f(x) = -\sum^{n}_{i=1}log(x_{i})\).&lt;/p&gt;

&lt;p&gt;It can be easily verified that \(f(t) = -\log{t}\). Furthermore, the sum of self-concordant functions is also self-concordant. When there are self-concordant functions \(f_{1}, f_{2} : R\rightarrow R\), the sum of self-concordant functions is also self-concordant as shown below.[3]&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
|f_{1}^{&apos;&apos;&apos;}(x)+f_{2}^{&apos;&apos;&apos;}(x)|  \leq &amp;amp; |f^{&apos;&apos;&apos;}_{1}(x)|+|f^{&apos;&apos;&apos;}_{2}(x)|\\\\
\leq &amp;amp;2\big( f^{&apos;&apos;}_{1}(x)^{3/2}+f^{&apos;&apos;}_{2}(x)^{3/2}\big)\\\\
\leq &amp;amp;2\big( f^{&apos;&apos;}_{1}(x)+f^{&apos;&apos;}_{2}(x) \big)^{3/2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The last step uses the following property:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
(u^{3/2}+v^{3/2})^{2/3} \leq u+v, \qquad u, v \geq 0.
\end{align}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>14-05 Convergence analysis</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_05_convergence_analysis/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_05_convergence_analysis</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
    });
&lt;/script&gt;

&lt;p&gt;So far, we have examined pure Newton’s method, which only has local convergence properties, and damped Newton’s method (Newton’s method with backtracking line search), which applies backtracking line search to ensure global convergence when convex.&lt;/p&gt;

&lt;p&gt;In this chapter, we analyze the convergence rate of damped Newton’s method. For damped Newton’s method, we examine convergence bounds divided into two phases: the phase where backtracking is applied (damped phase: slow progress) and the locally convergent phase where backtracking is no longer needed (pure phase: quadratic convergence).&lt;/p&gt;

&lt;h2 id=&quot;conditions-of-f-for-convergence-analysis&quot;&gt;Conditions of \(f\) for convergence analysis&lt;/h2&gt;
&lt;p&gt;Assume that \(f\) is convex, twice differentiable, has \(dom(f)=\mathbb{R}^{n}\), and satisfies the following three conditions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(\nabla f\) is Lipschitz continuous with parameter L.
    &lt;blockquote&gt;
\[\begin{align}
\|\nabla f(x) - \nabla f(y)\|_{2} \leq L\|x-y\|_{2} \quad \forall x,y.
\end{align}\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;\(f\) is strongly convex with parameter m. (Relationship between upper bound \(L\) and Lipschitz continuous: &lt;a href=&quot;https://xingyuzhou.org/blog/notes/strong-convexity&quot;&gt;source&lt;/a&gt;, &lt;a href=&quot;/contents/en/chapter06/06_03_05_look_at_the_conditions_and_practicalities/&quot;&gt;this book: 06-03-05&lt;/a&gt;)
    &lt;blockquote&gt;
\[\begin{align}
mI\preceq\nabla^{2}f(x)\preceq LI.
\end{align}\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;\(\nabla^{2} f\) is Lipschitz continuous with parameter M.
    &lt;blockquote&gt;
\[\begin{align}
\|\nabla^{2}f(x)-\nabla^{2}f(y)\|_{2} \leq M\|x-y\|_{2} \quad \forall x,y.
\end{align}\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;convergence-analysis&quot;&gt;Convergence analysis&lt;/h2&gt;
&lt;p&gt;If the above three conditions are satisfied, for \(\eta, \gamma\) satisfying \(0&amp;lt;\eta \leq m^{2}/M\) and \(\gamma&amp;gt;0\), the convergence for each phase can be obtained as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Phase I : “Damped” phase, \(\|\nabla f(x^{(k)})\|_{2} \geq \eta\),&lt;/p&gt;

\[\begin{align}
f(x^{(k+1)})-f(x^{(k)}) \leq -\gamma
\end{align}\]

  &lt;p&gt;Phase 2 : “Pure” phase, \(\|\nabla f(x^{(k)})\|_{2}&amp;lt;\eta\), backtracking selects \(t = 1\)&lt;/p&gt;

\[\begin{align}
\frac{M}{2m^{2}}\|\nabla f(x^{(k+1)})\|_{2} \leq \bigg( \frac{M}{2m^{2}}\|\nabla f(x^{(k)})\|_{2} \bigg)^{2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Note that once the Pure phase is reached when \(\|\nabla f(x^{(k)})\|_{2}&amp;lt;\eta\) is satisfied at the \(k\)-th iteration for the first time, this condition is always satisfied for subsequent iterations.&lt;/p&gt;

&lt;h2 id=&quot;convergence-analysis--written-in-optimal-value-term&quot;&gt;Convergence analysis : written in optimal value term&lt;/h2&gt;
&lt;p&gt;Now we want to compare the convergence of each phase in terms of the difference from the optimal value.&lt;/p&gt;

&lt;p&gt;For Phase 1, if we perform k iterations starting from \(x^{(0)}\), we can organize the equation for each step and represent it as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\require{cancel}
&amp;amp; &amp;amp;\cancel{f(x^{(1)})}-f(x^{(0)}) \leq -\gamma \\\\
&amp;amp; &amp;amp;\cancel{f(x^{(2)})}-\cancel{f(x^{(1)})} \leq -\gamma \\\\
&amp;amp; &amp;amp;\vdots \\\\
&amp;amp;+ &amp;amp;f(x^{(k)})-\cancel{f(x^{(k-1)})} \leq -\gamma \\\\
&amp;amp;= &amp;amp;f(x^{(k)})-f(x^{(0)})\leq -k\gamma.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Subtracting \(f^{\star}\) from both sides, we can obtain the following result. Let \(k_{0}\) be the first \(k\) that satisfies \(\|\nabla f(x^{(k+1)})\|&amp;lt;\eta\).&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)})-f^{\star} \geq (f(x^{(0)})-f^{\star})-\gamma k \qquad \text{if }k \geq k_{0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For Phase 2, assume that iteration starts from \(k_{0}\) and proceeds for \(k-k_{0}\) steps. Also, using \(\|\nabla f(x^{(k)})\|_2&amp;lt;\eta \leq m^{2}/M\) from earlier and strong convexity, we can organize the equation as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;\frac{M}{2m^{2}}\|\nabla f^{(k_{0}+1)}\|_{2} \leq \big( \frac{M}{2m^{2}}\|\nabla f^{(k_{0})}\|_{2} \big) ^{2}.\\\\
&amp;amp;\Leftrightarrow &amp;amp;\frac{M}{2m^{2}}\|\nabla f^{(k_{0}+(k-k_{0}))}\|_{2} \leq \bigg( \big( \frac{M}{2m^{2}}\|\nabla f^{(k_{0}+1)}\|_{2} \big) ^{2} \bigg)^{k-k_{0}} \leq (\frac{1}{2})^{2^{(k-k_{0})}}.\\\\
&amp;amp;\Leftrightarrow &amp;amp;f(y)\geq f(x)+\nabla f(x)^{T}(y-x)+\frac{m}{2}\|y-x\|^{2}_{2}\geq f(x)-\frac{1}{2m}\|\nabla f(x)\|^{2}_{2}, \text{ for all }y,\\\\
&amp;amp;\Leftrightarrow &amp;amp;f(x^{(k)})-f^{\star} \leq \frac{1}{2m}\|\nabla f(x^{k})\|_{2}^{2}\leq \frac{2m^{3}}{M^{2}}(\frac{1}{2})^{2^{k-k_{0}+1}}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, we can organize the convergence according to steps with the \(k_{0}\)-th iteration as the branch point as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theorem: Newton’s method using backtracking line search has two-stage convergence bounds.
\(\begin{align}
&amp;amp;f(x^{(k)})-f^{\star} \leq \begin{cases} (f(x^{(0)})-f^{\star})-\gamma k \qquad &amp;amp;\text{if }k\leq k_{0}\\
\frac{2m^{3}}{M^{2}}(\frac{1}{2})^{2^{k-k_{0}+1}} \qquad &amp;amp;\text{if }k&amp;gt;k_{0}.
\end{cases}
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Here, \(\gamma = \frac{\alpha \beta^{2}\eta^{2}m}{L^{2}}\), \(\eta = \min\{1, 3(1-2\alpha)\}\frac{m^{2}}{M}\), and \(k_{0}\) is the step where \(\|\nabla f(x^{k_0+1}))\|_{2}&amp;lt;\eta\) starts to be satisfied.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof-1-damped-phase&quot;&gt;Proof 1. Damped phase&lt;/h2&gt;
&lt;p&gt;First, we derive the damped phase that satisfies \(\|\nabla f(x)\|_{2} \geq \eta\). We derive the convergence of the damped phase through the lower bound of the step size determined by the backtracking line search process. The Newton decrement relationship is frequently used in the proof process.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We start from the following equation where we set \(y=x+t\Delta x_{nt}\) in the Taylor approximation of \(f\) and apply the upper bound of the Lipschitz condition.&lt;/p&gt;

\[\begin{align}
f(x+t\Delta x_{nt}) \leq f(x)+t\nabla f(x)^{T}\Delta x_{nt} + \frac{L \|\Delta x_{nt} \|^{2}_{2} }{2}t^{2},
\end{align}\]

  &lt;p&gt;Newton decrement, 증분과 hessian matrix와의 관계와 Strong convexity의 관계를 이용하여 다음과 같이 전개할 수 있다.&lt;/p&gt;

\[\begin{align}
&amp;amp;\text{ Since, }\lambda(x)^{2}=\Delta x_{nt}^{T} \nabla^{2} f(x) \geq m\|\Delta x_{nt}\|^{2}_{2},\\\\
&amp;amp;f(x)+t\nabla f(x)^{T}\Delta x_{nt} + \frac{L \|\Delta x_{nt} \|^{2}_{2} }{2}t^{2} \leq f(x)-t\lambda(x)^{2} + \frac{L}{2m}t^{2}\lambda(x)^{2},
\end{align}\]

  &lt;p&gt;이 때, backtracking line search의 조건을 만족하기 위해서는 아래를 만족해야 한다.&lt;/p&gt;

\[\begin{align}
f(x+t\Delta x_{nt}) \leq f(x)-(1-\frac{L}{2m}t)t \lambda(x)^{2}, \qquad \text{ where, }0&amp;lt;1-\frac{L}{2m}t \leq \frac{1}{2}
\end{align}\]

  &lt;p&gt;위를 만족하는 t의 최소값을 \(\hat{t}\)라 할 때, \(\hat{t} = \frac{m}{L}\)이 되고, 이를 원 식에 대입하면 다음과 같다.&lt;/p&gt;

\[\begin{align}
f(x+\hat{t}\Delta x_{nt})\leq f(x)-\frac{m}{2L}\lambda(x)^{2} \leq f(x) -\alpha \hat{t} \lambda(x)^{2},
\end{align}\]

  &lt;p&gt;backtracking line search에서 \(0&amp;lt;\beta\leq 1\)이므로, \(t\geq \beta \frac{m}{L}\)를 만족하고, 이를 정리하여 최종 결과를 유도할 수 있다.&lt;/p&gt;

\[\begin{align}
f(x^{+})-f(x) &amp;amp;\leq -\alpha t \lambda(x)^{2}\\
&amp;amp;\leq -\alpha\beta \frac{m}{L}\lambda(x)^{2}\\
&amp;amp;\leq -\alpha\beta \frac{m}{L^{2}}\|\nabla f(x)\|^{2}_{2}\\
&amp;amp;\leq -\alpha\beta \eta^{2}\frac{m}{L^{2}},\\
&amp;amp;\gamma = \alpha\beta \eta^{2}\frac{m}{L^{2}}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof-2-pure-phase&quot;&gt;Proof 2. Pure phase&lt;/h2&gt;
&lt;p&gt;이제 \(\|\nabla f(x)\|_{2} &amp;lt; \eta\)일 때를 가정하고, Damped phase(quadratically convergent phase)를 살펴본다. 증명은 두가지 과정으로 나뉜다. backtracking line search의 t 업데이트가 필요하지 않음을 보이고, 수렴속도가 quadratic함을 보이게 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Backtracking line search로 부터 다음과 같은 식이 유도된다.&lt;/p&gt;

\[\begin{align}
\eta \leq 3(1-2\alpha)\frac{m^{2}}{M}.
\end{align}\]

  &lt;p&gt;또한, Lipschitz condition에 따라 \(t \geq 0\)에 대하여, 다음 조건을 만족한다.&lt;/p&gt;

\[\begin{align}
\|\nabla^{2}f(x+t\Delta x_{nt})-\nabla^{2}f(x)\|_{2} \leq tM \|\Delta x_{nt} \|_{2},\\
| \Delta x_{nt}^{T} \big( \nabla^{2}f(x+t\Delta x_{nt})-\nabla^{2}f(x) \big) \Delta x_{nt}| \leq tM \|\Delta x_{nt} \|_{2}^{3}.
\end{align}\]

  &lt;p&gt;\(\tilde{f} = f(x+t\Delta x_{nt}\))라 두면, \(\tilde{f}&apos;&apos;(t) = \Delta x_{nt}^{T} \nabla^{2}f(x+t\Delta x_{nt})\Delta x_{nt}\)이고, 이를 대입한다.&lt;/p&gt;

\[\begin{align}
\tilde{f}&apos;&apos;(t) \leq \tilde{f}&apos;&apos;(0)+tM\|\Delta x_{nt}\|^{3}_{2} \leq tM\|\Delta x_{nt} \|^{3}_{2}
\end{align}\]

  &lt;p&gt;\(\tilde{f}&apos;&apos;(0) = \lambda(x)^{2}\)이고, \(\lambda(x)^{2} \geq m\|\nabla x_{nt}\|_{2}^{2}\) 임을 이용하고, 부등식을 합친다. \(\tilde{f}&apos;(0) = -\lambda(x)^{2}\)이므로 다음과 같이 정리할 수 있다.&lt;/p&gt;

\[\begin{align}
\tilde{f}&apos;&apos;(t) &amp;amp;\leq \tilde{f}&apos;&apos;(0) + tM \| \Delta x_{nt} \| ^{3}_{2} \leq \lambda(x)^{2} + t\frac{M}{m^{3/2}}\lambda(x)^{3}, \\
\tilde{f}&apos;(t) &amp;amp;\leq \tilde{f}&apos;(0)+t\lambda(x)^{2} +t^{2}\frac{M}{2m^{3/2}}\lambda(x)^{3},\\
&amp;amp;= -\lambda(x)^{2}+t\lambda(x)^{2} + t^{2}\frac{L}{2m^{3/2}}\lambda(x)^{3}.
\end{align}\]

  &lt;p&gt;이제 양변을 적분한다.&lt;/p&gt;

\[\begin{align}
\tilde{f}(t) \leq \tilde{f}(0) - t\lambda(x)^{2} + t^{2} \frac{1}{2}\lambda(x)^{2} + t^{3}\frac{M}{6m^{3/2}}\lambda(x)^{3}.
\end{align}\]

  &lt;p&gt;t = 1로 두면, 아래와 같은 결과를 얻을 수 있다.&lt;/p&gt;

\[\begin{align}
f(x+\Delta x_{nt}) \leq f(x) -\frac{1}{2}\lambda(x)^{2} + \frac{M}{6m^{3/2}}\lambda(x)^{3}.
\end{align}\]

  &lt;p&gt;이제 \(\|\nabla f(x)\|_{2}\leq \eta \leq 3(1-2\alpha)\frac{m^{2}}{M}\)이라 가정하면, strong convexity 조건에 의해 \(\lambda(x) \leq 3(1-2\alpha)m^{3/2}/L\)이다. 이를 위에 부등식에 대입하면 아래와 같은 결과를 유도할 수 있다.&lt;/p&gt;

\[\begin{align}
f(x+\Delta x_{nt}) &amp;amp;\leq f(x) - \lambda(x)^{2}( \frac{1}{2}- \frac{M\lambda(x)}{6m^{3/2}} ) \\
&amp;amp;\leq f(x) -\alpha \lambda(x)^{2} \\
&amp;amp;= f(x) + \alpha \nabla f(x)^{T} \Delta x_{nt},
\end{align}\]

  &lt;p&gt;이 결과는 \(t=1\)일때 backtracking line search를 수행하더라도 항상 조건을 만족하기 때문에, \(t\)를 감소시키지 않음을 의미한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이제 우리는 수렴속도가 quadratic하게 줄어듬을 증명해본다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(x_{nt} = -(\nabla^{2}f(x))^{-1}\nabla f(x)\)임을 이용한 뒤, 적분의 성질 중 하나인 \(f(t, u) - f(t, v) = \int^{u}_{v}{\frac{\partial f}{\partial x}(t, x) dx}\)를 이용하여 정리하고, Hessian의 Lipschitz 조건을 적분식에 적용하고 정리한다. 마지막으로 strong convexity 조건을 적용하면 증명이 완료된다. 과정을 수식으로 나타내면 아래와 같다.&lt;/p&gt;

\[\begin{align}
\| \nabla f(x^{+}) \| _{2} &amp;amp;= \| \nabla f(x+\Delta x_{nt}) - \nabla f(x) - \nabla^{2}f(x)\Delta x_{nt} \|_{2}\\\\
&amp;amp;=\| \int^{1}_{0}{ \big( \nabla^{2}f(x+t\Delta x_{nt})-\nabla^{2} f(x) \big) \Delta x_{nt} dt } \|_{2}\\\\
&amp;amp; \leq \frac{M}{2}\|\Delta x_{nt} \|^{2}_{2}\\\\
&amp;amp; = \frac{M}{2}\|\nabla^{2}f(x)^{-1}\nabla f(x)\|^{2}_{2}\\\\
&amp;amp; \leq \frac{M}{2m^{2}}\|\nabla f(x)\|^{2}_{2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;결론을 다시 정리하면, \(\eta = \min \{1, 3(1-2\alpha)\}\frac{m^{2}}{M}\) 일 때, \(\|\nabla f(x^{(k)}) \|_{2}&amp;lt;\eta\)를 만족하는 조건에서는 Newton’s method는 backtracing line search에서의 업데이트가 더이상 필요하지 않고, quadratic하게 converge 한다.&lt;/p&gt;

&lt;h2 id=&quot;estimating-total-complexity&quot;&gt;Estimating total complexity&lt;/h2&gt;
&lt;p&gt;이제, 우리는 전체 과정에서의 complexity, 달리 말해 초기 값으로부터 최적값까지 도달하는데 걸리는 iteration 횟수에 대한 bound를 추정할 수 있다.
우선, 위의 damped Newton phase에서 \(f\)는 매 iteration마다 \(\gamma\)를 넘지 않는 선에서 값이 감소하므로, damped Newton step의 전체 step 수는 다음의 식의 결과값을 넘지 못한다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\frac{f(x^{(0)})-p^{\star}}{\gamma}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;pure Newton phase에서의 iteration 횟수의 bound 또한 계산할 수 있다. 위의 식을 \(f(x)-p^{\star}\leq \epsilon\), \(\epsilon_{0} = \frac{2m^{3}}{M^{2}}\)로 두고, iteration 횟수로 식을 정리하면 다음과 같은 값을 계산할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;\epsilon = \epsilon_{0} (\frac{1}{2})^{2^{k-k_{0}+1}}\\\\
&amp;amp;\Leftrightarrow &amp;amp;\frac{\epsilon_{0}}{\epsilon} = 2^{2^{k-k_{0}+1}}\\\\
&amp;amp;\Leftrightarrow &amp;amp;k-k_{0}+1 = log_{2}log_{2}(\frac{\epsilon_{0}}{\epsilon})
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;따라서 pure Newton phase에서 iteration 횟수는 \(\log \log(\frac{\epsilon_{0}}{\epsilon})\)로 bound 된다.&lt;/p&gt;

&lt;p&gt;이 두 결과를 더하면, Newton method를 통하여 원하는 정밀도의 해를 얻는데 필요한 iteration 횟수의 upper bound를 정의할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\frac{f(x^{(0)})-p^{\star}}{\gamma} + \log \log (\frac{\epsilon_{0}}{\epsilon}).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;문제를 해결할때 요구되는 정밀도 \(\epsilon\)의 변화에 비해 우변의 두번째 항은 매우 작은 변화를 보이므로, 실제 응용에서는 이를 상수로 두고 추정을 하게 된다. 일반적으로 6번의 iteration은 \(\epsilon \approx 5\cdot 10^{-20}\epsilon_{0}\)의 정밀도를 보인다고 알려져 있다.&lt;/p&gt;

&lt;p&gt;일반적으로 말해서, 목적함수 \(f\)를 최소화하는데 있어서 필요한 iteration 횟수는 다음과 같다.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\frac{f(x^{(0)})-p^{\star}}{\gamma} + 6.
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>14-04 Backtracking line search</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_04_backtracking_line_search/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_04_backtracking_line_search</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;So far, we have examined pure Newton’s method. However, this method does not guarantee convergence, so we use backtracking line search to ensure convergence in the damped Newton’s method.&lt;/p&gt;

&lt;h2 id=&quot;damped-newtons-method&quot;&gt;Damped Newton’s method&lt;/h2&gt;
&lt;p&gt;The pure Newton’s method iteratively applies the following update (here \(t=1\)):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{+} = x -t(\nabla^{2}f(x))^{-1}\nabla f(x).
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Damped Newton’s method uses backtracking line search. If the function value at the updated position is greater than the quadratic approximation, we shrink the step size \(t\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{with parameters }0&amp;lt;\alpha \leq \frac{1}{2}, 0&amp;lt;\beta&amp;lt;1, \\
&amp;amp;\text{while } f(x+tv)&amp;gt;f(x)+\alpha t \nabla f(x)^{T}v\\
&amp;amp;\text{shrink }t=\beta t
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(v=-(\nabla^{2}f(x))^{-1}\nabla f(x)\) and \(\nabla f(x)^{T}v = -\lambda^{2}(x)\).&lt;/p&gt;

&lt;h2 id=&quot;example-logistic-regression&quot;&gt;Example: logistic regression&lt;/h2&gt;
&lt;p&gt;As an example, for logistic regression with n = 500, p = 100, we compare the convergence rate of gradient descent and Newton’s method with backtracking line search.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter14/2.jpeg&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Logistic regression [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Newton’s method shows a much faster convergence rate than gradient descent. From the next chapter, we will examine this convergence rate.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-03 Newton decrement</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_03_newton_decrement/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_03_newton_decrement</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In this chapter, we define the Newton decrement and examine its meaning.&lt;/p&gt;

&lt;p&gt;For the optimization problem below, the Newton decrement at \(x\) is defined as \(\lambda(x)\):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\min_{x} \quad f(x),\&lt;br /&gt;
\end{align}
\begin{align}
\lambda(x) = (\nabla f(x)^{T}(\nabla^{2}f(x))^{-1}\nabla f(x))^{1/2}.
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;characteristics-of-newton-decrement&quot;&gt;Characteristics of Newton decrement&lt;/h2&gt;
&lt;p&gt;First, the Newton decrement is related to the difference between the function \(f(x)\) and the minimum of its quadratic approximation. Calculating this difference gives:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x)-&amp;amp;\min_{y} \big( f(x)+\nabla f(x)^{T}(y-x)+\frac{1}{2}(y-x)^{T}\nabla^{2}f(x)(y-x)\big),\\\\
f(x)-&amp;amp;\bigg( f(x) + \nabla^{T}f(x)\big( -(\nabla^{2} f(x) )^{-1} \nabla f(x)\big) + \frac{1}{2}\big( -(\nabla^{2}f(x))^{-1} \nabla f(x) \big)^{T} \nabla ^{2}f(x) \big( -(\nabla^{2}f(x))^{-1}\nabla f(x) \big) \bigg) \\\\ 
&amp;amp;= \frac{1}{2}\nabla f(x)^{T}(\nabla^{2} f(x) )^{-1}\nabla f(x) = \frac{1}{2}\lambda(x)^{2}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Thus, \(\frac{1}{2}\lambda^{2}(x)\) can be considered an approximate bound for the suboptimality gap \(f(x)-f^{\star}\).&lt;/p&gt;

&lt;p&gt;Second, the Newton direction in Newton’s method for each iteration is \(v = -(\nabla^{2}f(x))^{-1}\nabla f(x)\), and the Newton decrement is the length of the Newton step in the norm defined by the Hessian \(\nabla^{2}f(x)\).&lt;/p&gt;

&lt;p&gt;Alternatively, this can be viewed as a type of Mahalanobis distance [&lt;a href=&quot;https://en.wikipedia.org/wiki/Mahalanobis_distance&quot;&gt;Wikipedia&lt;/a&gt;], where the new step \(y\) is the observation, the current position \(x\) is the mean, and the Hessian of \(f(x)\) is the covariance. The Mahalanobis distance measures the distance from a point to the mean in the direction of the covariance of the distribution.&lt;/p&gt;

&lt;p&gt;If we consider the definition of Mahalanobis distance as the distance between a point and the mean of a distribution divided by the standard deviation in that direction, the Newton decrement represents the distance of the new step from the current position, with the Hessian serving as the covariance of the distribution.&lt;/p&gt;

&lt;p&gt;Third, the Newton decrement can be expressed in terms of the increment and the Hessian. Starting from the step update in Newton’s method, we have:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{+} &amp;amp;= x-\big(\nabla^{2} f(x) \big)^{-1} \nabla f(x) &amp;amp;\ 
\end{align}
\begin{align}
\Delta x_{nt} &amp;amp;= -\big(\nabla^{2} f(x) \big)^{-1} \nabla f(x) &amp;amp;&lt;br /&gt;
\end{align}
\begin{align}
\nabla f(x)^{T} \Delta x_{nt} &amp;amp;= -\lambda (x)^{2}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Utilizing these relations, the Newton decrement can also be expressed as:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\lambda(x) = (\Delta x_{nt}^{T}\nabla^{2} f(x) \Delta x_{nt})^{1/2}.
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, like the Newton step, the Newton decrement is also affine invariant. In other words, for any nonsingular matrix, if the function \(g(y) = f(Ay)\) is defined, then at \(x = Ay\), it holds that \(\lambda_{g(y)} = \lambda_{f(x)}\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-02 Interpretation & Properties</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_02_interpretation_and_properties/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_02_interpretation_and_properties</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In this chapter, before examining the properties of Newton’s method, we learn about applying Newton’s method to root finding problems of objective functions.&lt;/p&gt;

&lt;p&gt;Subsequently, we will examine two important properties of Newton’s method: Affine invariance and Local convergence.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-02-03 Local convergence analyisis</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_02_03_local_convergence_analysis/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_02_03_local_convergence_analysis</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
});
&lt;/script&gt;

&lt;p&gt;The second important property of Newton’s method is that convergence is guaranteed near the solution when certain conditions are satisfied. This is called local convergence. Since the pure Newton’s method we have discussed from &lt;a href=&quot;/contents/en/chapter14/14_01_newton_method/&quot;&gt;14-01&lt;/a&gt; does not guarantee convergence, we later devise the damped Newton’s method that ensures convergence by adjusting the step size using the same backtracking line search covered in &lt;a href=&quot;/contents/en/chapter06/06_00_gradient_descent/&quot;&gt;Chapter 6&lt;/a&gt;, and analyze its convergence.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Theorem: Let \(F : \mathbb{R}^{n}\, \rightarrow  \, \mathbb{R}^{n}\) be continuously differentiable, and let \(x^{\star} \in \mathbb{R}^{n}\) be a root of function \(F\), i.e., \(F(x^{\star})=0\).
If \(F^{&apos;}(x^{\star})\) is non-singular, then the following (a) and (b) are satisfied: &lt;br /&gt;
(a) If there exists a positive \(\delta\) (&amp;gt;0) such that \(\| x^{(0)}-x^{\star} \|&amp;lt;\delta\) and Newton’s method is defined, then the following equation (converges superlinearly) is satisfied:
\begin{align}
\lim_{ k \rightarrow \infty } \frac{ || x^{ (k+1) }-x^{ \star } || } { || x^{ (k) }-x^{ \star } || } =0.
\end{align} &lt;br /&gt;
(b) If \(F^{&apos;}\) is Lipschitz continuous near \(x^{\star}\), then there exists a positive K (&amp;gt;0) such that the following equation (quadratic convergence) is satisfied:
\begin{align}
||x^{ (k+1) } - x^{ \star }|| \leq K || x^{ (k) }-x^{ \star }||^{2}.
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof-of-a&quot;&gt;Proof of (a)&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;We organize \(F(x^{\star})\) up to 1st order using Taylor expansion. Since 2nd order and higher terms are bounded by a constant multiple of the norm of the 1st order term, we can represent it using little-o notation as follows:
\begin{align}
0=F(x^{\star}) = F(x^{k}) +\nabla F(x^{k})(x^{\star}-x^{k})+o(||x^{k}-x^{\star}||).&lt;br /&gt;
\end{align}
Multiply both sides by \(\nabla F(x^{k})^{-1}\) and organize. Since little-o is treated as a constant term, it can be ignored.
\begin{align}
x^{k}-x^{\star}-\nabla F(x^{k})^{-1} F(x^{k}) = o(||x^{k}-x^{\star}||).
\end{align}
Using Newton’s method \(x^{k+1}=x^{k}-\nabla F(x^{k})^{-1}F(x^{k})\), we can obtain the following result:
\begin{align}
x^{k+1}-x^{\star}=o(||x^{k}-x^{\star}||),
\end{align}
Therefore, when \(x^{k} \neq x^{\star}\), we can prove (a) using the limit-definition of little-o [&lt;a href=&quot;https://en.wikipedia.org/wiki/Big_O_notation&quot;&gt;wikipedia&lt;/a&gt;].&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\lim_{k\rightarrow \infty} \frac{||x^{k+1}-x^{\star}||}{||x^{k}-x^{\star}||} = \lim_{k\rightarrow \infty}\frac{o(||x^{k}-x^{\star}||)}{||x^{k}-x^{\star}||}.
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof-of-b&quot;&gt;Proof of (b)&lt;/h2&gt;
&lt;p&gt;The process is identical to proving that the convergence rate in the Damped phase of [&lt;a href=&quot;/contents/en/chapter14/14_05_convergence_analysis/&quot;&gt;14-05&lt;/a&gt;] is quadratic. Therefore, it is omitted.&lt;/p&gt;

&lt;h2 id=&quot;example--divergence-case&quot;&gt;Example : divergence case&lt;/h2&gt;
&lt;p&gt;We briefly examine an example where convergence is not guaranteed with pure Newton’s method.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter14/1_.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] pure Newton&apos;s method applied on root finding : divergence case &lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;https://slideplayer.com/slide/4998677/&quot;&gt;image-link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As shown in the figure, depending on the initial point \(x_0\), the solution can diverge.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-02-02 Affine invariance of Newton's method</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_02_02_affine_invariance_of_newton_method/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_02_02_affine_invariance_of_newton_method</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;One of the important properties of Newton’s method is that it is affine invariant. This means that the direction of the update is independent of affine transformations of the coordinate system. For example, gradient descent is variant to affine transformations, so the convergence speed differs depending on the coordinate space.&lt;/p&gt;

&lt;p&gt;This page derives the affine invariance property.&lt;/p&gt;

&lt;h2 id=&quot;affine-invariance--proof&quot;&gt;Affine invariance : proof&lt;/h2&gt;
&lt;p&gt;Let \(f:\mathbb{R}^{n}\rightarrow \mathbb{R}\) be twice differentiable, and let \(A\in \mathbb{R}^{n\times n}\) be nonsingular. Also, define \(g(y)\) as \(f(Ay)\). \(g(y):=f(Ay)\). This means that some function \(g\) that takes \(y\) as input has the same output as function \(f\) that takes \(Ay\) (affine transformed by \(A\) with respect to \(y\)) as input. To reduce confusion about notation and gradient arguments, we define \(x:=Ay\).&lt;/p&gt;

&lt;p&gt;Using the chain rule to differentiate both sides once and twice, we get the following results:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\nabla g(y) &amp;amp;= A^{T} \nabla f(x)\\\\
\nabla^{2} g(y) &amp;amp;= A^{T}\nabla^{2}f(x)A,
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The Newton step of \(g\) with respect to \(y\) is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
y^{+}  = y-(\nabla^{2}g(y))^{-1}\nabla g(y).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, instead of function \(g\), if we transform and organize it in terms of function \(f\) with respect to \(x\), we can derive the Newton step for \(x\) and \(f\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
y^{+} &amp;amp;= y-(A^{T}\nabla^{2}f(x)A)^{-1}A^{T} \nabla f(x)\\\\
\Leftrightarrow y^{+} &amp;amp;= y-A^{-1}(\nabla^{2}f(x))^{-1}(A^{T})^{-1}A^{T} \nabla f(x)\\\\
\Leftrightarrow Ay^{+} &amp;amp;= Ay-(\nabla^{2}f(x))^{-1}\nabla f(x)\\\\
\Leftrightarrow x^{+} &amp;amp;= x - \nabla^{2}f(x)^{-1}\nabla f(x).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This means that the Newton step is affine invariant, i.e., the updates in coordinate systems transformed by affine transformations represented by non-singular matrices are identical to each other.&lt;/p&gt;

&lt;p&gt;Using the same method to check the affine invariance of gradient descent by deriving the step update, we can obtain the following result:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
y^{+} &amp;amp;= y-t_{k}\cdot \nabla g(y)\\\\
\Leftrightarrow y^{+} &amp;amp;= y-t_{k}\cdot \nabla f(x)A^{T}\\\\
\Leftrightarrow x^{+} &amp;amp;= x - t_{k}\cdot A\nabla f(x)A^{T}. 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In the case of gradient descent, since the Hessian matrix is approximated as \(\frac{1}{t}I\) for updates, we can see that the direction of the update changes for affine transformed coordinates.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-02-01 Root finding</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_02_01_root_finding/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_02_01_root_finding</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In this chapter, we apply Newton’s method to the root finding problem. The Newton’s method used in optimization problems has some differences, which are explained here. [&lt;a href=&quot;https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization&quot;&gt;Newton’s method in optimization&lt;/a&gt;][&lt;a href=&quot;https://en.wikipedia.org/wiki/Newton%27s_method&quot;&gt;Newton’s method in root finding&lt;/a&gt;]&lt;/p&gt;

&lt;h2 id=&quot;newtons-method-for-root-finding&quot;&gt;Newton’s method for root finding&lt;/h2&gt;
&lt;p&gt;Suppose we have a vector function \(F:\mathbb{R}^{n}\rightarrow \mathbb{R}^{n}\). The root finding problem is to find \(x\) such that \(F(x) = 0\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
F(x) = 0.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This problem is solved by choosing an initial value \(x^{(0)}\) and applying Newton’s method iteratively:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{choose initial }x^{(0)}\in \mathbb{R}^{n},\\\\
&amp;amp;x^{(k)}=x^{(k-1)}-\nabla F(x^{(k-1)})^{-1}F(x^{(k-1)}), \qquad k=1,2,3,...\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(\nabla F(x^{(k-1)})\) is the Jacobian matrix of \(F\) at \(x^{(k-1)}\). The Newton step \(x^{+}=x-\nabla F(x)^{-1}F(x)\) can be derived using the linear approximation of \(F\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
F(y)\approx F(x) + F^{&apos;}(x)(y-x) = 0\\\\
y = x^{+}=x-F^{&apos;}(x)^{-1}F(x).
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;newtons-method-for-optimization-problem&quot;&gt;Newton’s method for optimization problem&lt;/h2&gt;
&lt;p&gt;Suppose we apply Newton’s method to an optimization problem formulated as:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{x} F(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This is equivalent to applying Newton’s method to the root finding problem for the gradient \(\nabla{F(x)}=0\) of the objective function \(F(x)\).&lt;/p&gt;

&lt;p&gt;In summary, unlike the problem of finding the root of a given function’s derivative (\(\nabla F=0\)) using Newton’s method in optimization problems, the root finding problem requires finding the root of the function value itself (\(F=0\)) using Newton’s method. This results in a difference of one order in the derivative term in the update formula for \(x\) in Newton’s method for each problem.&lt;/p&gt;

&lt;h2 id=&quot;root-finding-example&quot;&gt;Root finding example&lt;/h2&gt;
&lt;p&gt;Consider a function \(F:\mathbb{R}\rightarrow\mathbb{R}\) defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
F(x)=x^{2}-2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Starting with an initial guess of \(x^{(0)}=1\), we apply pure Newton’s method, yielding the following results:&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter14/table1.jpeg&quot; alt=&quot;&quot; width=&quot;90%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Newton&apos;s method applied on example[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;As the iteration count \(k\) increases, we can see that the value of \(x\) approaches the root \(\sqrt 2\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>14-01 Newton's method</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_01_newton_method/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_01_newton_method</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;The gradient descent methods we have discussed are called &lt;strong&gt;first-order methods&lt;/strong&gt; because the solutions are based on the first derivative of the function. Newton’s method is a &lt;strong&gt;second-order method&lt;/strong&gt;, meaning the solution requires computing the second derivative.&lt;/p&gt;

&lt;p&gt;Let us consider an optimization problem for a function \(f\) that is unconstrained, twice differentiable, convex, and has dom(\(f\)) = \(\mathbb{R}^{n}\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min_{x} f(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In &lt;a href=&quot;/contents/en/chapter06/06_00_gradient_descent/&quot;&gt;Gradient descent&lt;/a&gt;, we performed the following process for this function \(f\):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Perform second-order Taylor approximation&lt;/li&gt;
  &lt;li&gt;Assume the Hessian matrix corresponding to the second derivative term as \(I/t\), i.e., the identity matrix divided by t (step size)&lt;/li&gt;
  &lt;li&gt;Perform quadratic approximation to proceed with the update step&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The detailed process is explained in the gradient descent update step on the next page. The update step formula at each iteration is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{choose initial } x^{(0)} \in \mathbb{R}^{n},\\\\
&amp;amp;x^{(k)} = x^{(k-1)} - t_{k} \cdot \nabla f(x^{(k-1)}), \qquad k = 1,2,3,...
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Newton’s method (pure Newton’s method) actually computes the second derivative term that was assumed as \(\frac{1}{t}I\) in gradient descent, performs quadratic approximation, and proceeds with the update step. This process is also explained in the Newton’s method update step on the next page. The update step formula at each iteration is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{choose initial } x^{(0)} \in \mathbb{R}^{n},\\\\
&amp;amp;x^{(k)} = x^{(k-1)} - \Big(\nabla^{2}f(x^{(k-1)})\Big)^{-1} \nabla f(x^{(k-1)}), \qquad k = 1,2,3,...
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>14-01-01 Newton's method interpretation</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_01_01_newton_method_interpretation/"/>
   <updated>2021-03-26T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter14/14_01_01_newton_method_interpretation</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
});
&lt;/script&gt;

&lt;p&gt;This page examines how the update step discussed earlier is derived from the quadratic approximation of the original function \(f\). We also compare it with the gradient descent update step covered in &lt;a href=&quot;/contents/en/chapter06/06_00_gradient_descent/&quot;&gt;Chapter 6&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;newtons-method-update-step&quot;&gt;Newton’s method update step&lt;/h2&gt;
&lt;p&gt;The second-order Taylor approximation (quadratic approximation) of function \(f\) is as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y)	\approx f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2}(y-x)^{T}\nabla^{2}f(x)(y-x),\\\\
f_{approx}(y)	= f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2}(y-x)^{T}\nabla^{2}f(x)(y-x).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(y\) is the next step’s \(x\) value, which is \(x^{+}\). We also define the quadratic approximation as \(f_{approx}\).&lt;/p&gt;

&lt;p&gt;We want to find the input \(y\) that minimizes this \(f_{approx}\), i.e., the quadratic approximation. Since \(f_{approx}\) is convex, the input \(y\) that makes the gradient of the above equation equal to zero will minimize \(f_{approx}\). This result becomes the step update formula in Newton’s method. Remember that the differentiation in the equation below is with respect to y.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\nabla f_{approx}(y)	&amp;amp;= \nabla f(x) +\frac{1}{2} \Big((\nabla^{2} f(x))^{T}(y-x)+(y-x)^{T}\nabla^{2}f(x)\Big)\\\\
&amp;amp;=\nabla f(x) +\nabla^{2} f(x)(y-x)\\\\
&amp;amp; = 0,\\\\
\Leftrightarrow y &amp;amp;= x-(\nabla^{2}f(x))^{-1}\nabla f(x).
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;gradient-descent-update-step&quot;&gt;Gradient descent update step&lt;/h2&gt;
&lt;p&gt;In gradient descent, we use the second-order Taylor approximation terms of function \(f\), but for the second-order term, we assume it as the identity matrix divided by \(t\), rather than the actual second derivative result.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y)	\approx f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2t}\|{y-x}\|_{2}^{2},\\\\
f_{approx}(y)	= f(x) + \nabla f(x)^{T}(y-x) +\frac{1}{2t}\|{y-x}\|_{2}^{2}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Similar to Newton’s method, we can determine the \(y\) value where the gradient of the above approximation is zero, i.e., \(x^{+}\).&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\nabla f(y) &amp;amp;= \nabla f(x) + \frac{1}{t}(y-x), \\\\
&amp;amp;= 0,\\\\
y &amp;amp;= x-t\nabla f(x).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This result is identical to the step update of gradient descent.&lt;/p&gt;

&lt;p&gt;For detailed information about gradient descent, refer to the &lt;a href=&quot;/contents/en/chapter06/06_00_gradient_descent/&quot;&gt;gradient descent chapter&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;
&lt;p&gt;As an example, for the function \(f = (10x_{1}^{2}+x_{2}^{2})/2+5log(1+e^{-x_{1}-x_{2}})\), we assume taking steps of approximately equal length. That is, we set the step size in gradient descent to match the update magnitude of Newton’s method at each iteration, and compare the convergence directions of gradient descent (black) and Newton’s method (blue) according to their steps.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter14/gd.jpeg&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Comparison between gradient descent(black) and Newton&apos;s method(blue)[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;As can be seen in Fig 1, gradient descent assumes the second derivative term as a constant multiplied by the identity matrix when calculating the gradient, so it converges perpendicularly to the tangent direction of the contour lines, and shows slower convergence speed compared to Newton’s method. The remaining chapters will cover the properties, characteristics, convergence, examples, etc. of Newton’s method.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03 Điều kiện tối ưu gradient dưới</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_03_subgradient_optimality_condition/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_03_subgradient_optimality_condition</id>
   <content type="html">&lt;p&gt;Trong phần này, chúng ta xem xét các điều kiện tối ưu sử dụng gradient dưới, và cung cấp một số ví dụ để minh họa ứng dụng và tính hữu ích của chúng.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03-05 Ví dụ: Khoảng cách đến tập lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_03_05_example_distance_to_convex_set/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_03_05_example_distance_to_convex_set</id>
   <content type="html">&lt;p&gt;Hàm khoảng cách đến một tập lồi đóng \(C\) được định nghĩa như sau:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{alignat}{1}
dist(x,C) &amp;amp; = \min_{y \in C} | y-x |_2 &lt;br /&gt;
      &amp;amp; = | x-P_C(x) |_2 &lt;br /&gt;
      &amp;amp; \geq 0 
\end{alignat}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(P_C(x)\) là phép chiếu của điểm \(x\) lên tập \(C\), tức là điểm gần nhất trong \(C\) với \(x\). Gradient dưới của hàm khoảng cách là:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\partial dist(x,C) = {\frac{x-P_C(x)}{ | x-P_C(x) |_2}}
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;chứng-minh&quot;&gt;Chứng minh&lt;/h3&gt;

&lt;p&gt;Nếu \(u=P_C(x)\), thì theo điều kiện tối ưu bậc một,&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
(x-u)^T(y-u) \leq 0 \ \text{ với mọi } y \in C
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Do đó,&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
C \subseteq H = {y:(x-u)^T(y-u) \leq 0 }
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(i) Với \(y \in H\),&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
(x-u)^T(y-u) \leq 0
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Mặt khác, vì \(dist(y,C)\geq 0\),&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
dist(y,C) \geq \frac{(x-u)^T(y-u)}{ | x-u |_2} \text{ với mọi } y \in H
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(ii) Với \(y \notin H\),&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
(x-u)^T(y-u) = | x-u |_2 | y-u |_2 \cos\theta,
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;trong đó \(\theta\) là góc giữa \(x-u\) và \(y-u\). Khi đó,&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;$$
\eqalign{
dist(y,C) &amp;amp;\geq dist(y,H) \&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;amp;= | y-u |_2 \cos \theta &lt;br /&gt;
&amp;amp;= \frac{(x-u)^T(y-u)}{ | x-u |_2} \text{ với mọi }y \notin H
}
$$&lt;/p&gt;

&lt;p&gt;Do đó, từ (i) và (ii), với mọi \(y\),&lt;/p&gt;
&lt;blockquote&gt;

\[\eqalign{
dist(y,C) &amp;amp;\geq \frac{(x-u)^T(y-u)}{ \| x-u \|_2} \\
&amp;amp;= \frac{(x-u)^T(y-x+x-u)}{ \| x-u \|_2}\\
&amp;amp; = \| x-u \|_2 + \left(\frac{x-u}{ \| x-u \|_2}\right)^T(y-x)
}\]
&lt;/blockquote&gt;

&lt;p&gt;Kết luận, \(dist(x,C)\) có gradient dưới sau tại \(x\):&lt;/p&gt;
&lt;blockquote&gt;

\[g=\frac{x-u}{ \| x-u \|_2}=\frac{x-P_C(x)}{ \| x-P_C(x) \|_2}\]
&lt;/blockquote&gt;

&lt;p&gt;Hơn nữa, vi phân dưới \(\partial dist(x,C)\) chỉ chứa một phần tử, nên \(dist(x,C)\) khả vi và đạo hàm của nó trùng với gradient dưới.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03-04 Ví dụ: Ngưỡng mềm (Soft-Thresholding)</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_03_04_example_soft-thresholding/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_03_04_example_soft-thresholding</id>
   <content type="html">&lt;p&gt;Với bài toán lasso đơn giản hơn với \(X=I\):&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\min_{\beta} \frac{1}{2} | y-\beta |_2^2 + \lambda | \beta |_1
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Từ ví dụ trước, điều kiện tối ưu gradient dưới là:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{cases}
y_i-\beta_i = \lambda \cdot \text{sign}(\beta_i) &amp;amp;\text{nếu } \beta_i \neq 0 \\
 |y_i-\beta_i| \leq \lambda &amp;amp;\text{nếu } \beta_i = 0
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Từ điều kiện này, có thể tìm được nghiệm \(\beta = S_{\lambda}(y)\), trong đó&lt;/p&gt;
&lt;blockquote&gt;

\[[S_{\lambda}(y)]_{i} = 
\begin{cases}
y_i - \lambda &amp;amp;\text{nếu }y_i &amp;gt; \lambda \\
0             &amp;amp;\text{nếu }-\lambda \leq y_i \leq \lambda, \quad \quad i \in \{1,2,\dots,n \} \\
y_i + \lambda &amp;amp;\text{nếu } y_i &amp;lt; -\lambda
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(S_{\lambda}\) được gọi là toán tử ngưỡng mềm.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_03_subgrad-6.png&quot; alt=&quot;connection_to_convexity_geometry&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Hình 1] Ngưỡng mềm, y (trục x), } \beta \text{ (trục y), } \lambda=1/2 \text{ [3]}$$ &lt;/figcaption&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03-03 Ví dụ: Điều kiện tối ưu Lasso</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_03_03_example_lasso_optimality_condition/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_03_03_example_lasso_optimality_condition</id>
   <content type="html">&lt;p&gt;Với bài toán lasso được cho dưới đây,&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\min_{\beta} \frac{1}{2}  | y-X\beta |_2^2 + \lambda | \beta |_1
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;trong đó \(y \in \mathbb{R}^n\), \(X \in \mathbb{R}^{n \times p}\), \(\lambda \geq 0\).&lt;/p&gt;

&lt;p&gt;Điều kiện tối ưu gradient dưới cho bài toán này có thể được biểu diễn như sau:&lt;/p&gt;
&lt;blockquote&gt;

\[\eqalign{
0 \in \partial\left(\frac{1}{2} \| y-X\beta \|_2^2 + \lambda \| \beta \|_1\right)
&amp;amp;\quad \Longleftrightarrow \quad 0 \in - X^T (y-X\beta) + \lambda \partial  \| \beta \|_1 \\
&amp;amp;\quad \Longleftrightarrow \quad X^T (y-X\beta)  = \lambda v \\
&amp;amp; \quad \text{với } v \in \partial  \| \beta \|_1 \text{ nào đó}
}\\\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, đối với một điểm \(\beta=(\beta_1,\beta_2,\dots,\beta_p )\), gradient dưới \(v=(v_1,v_2,\dots,v_p)\) được cho bởi:&lt;/p&gt;

\[v_i = 
\begin{cases}
 1   &amp;amp;\text{nếu } \beta_i &amp;gt; 0 \\
-1   &amp;amp;\text{nếu } \beta_i &amp;lt; 0 \\
[-1,1]   &amp;amp;\text{nếu } \beta_i = 0
\end{cases}
, i \in \{1,2,\dots,p \}\]

&lt;p&gt;Bất kỳ \(\beta\) nào thỏa mãn điều kiện sau là tối ưu:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
X^T(y-X\beta) = \lambda v 
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Tức là, đối với \(\beta\) tối ưu, các điều kiện sau được thỏa mãn:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{cases}
X_i^T(y-X\beta) = \lambda \cdot \text{sign}(\beta_i) &amp;amp;\text{nếu } \beta_i \neq 0 \\
 |X_i^T(y-X\beta)|  \leq \lambda &amp;amp;\text{nếu } \beta_i = 0 
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(X_i, i \in \{1,2,\dots, p \}\) ký hiệu cột thứ \(i\) của ma trận \(X\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03-02 Suy dẫn điều kiện tối ưu bậc một</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_03_02_derivation_of_first-order_optimality_condition/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_03_02_derivation_of_first-order_optimality_condition</id>
   <content type="html">&lt;p&gt;Nếu \(f\) lồi và khả vi, điều kiện tối ưu gradient dưới trùng với điều kiện tối ưu bậc một, như được chỉ ra dưới đây.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Điều kiện tối ưu bậc một:&lt;/strong&gt;
\(x^* \text{ là tối ưu} \quad \Longleftrightarrow \quad \nabla f(x^*)^T(y - x^*) \geq 0, \text{ với mọi } y \in C\)&lt;/p&gt;

&lt;h3 id=&quot;chứng-minh&quot;&gt;Chứng minh&lt;/h3&gt;
&lt;blockquote&gt;

\[\begin{alignat}{2}
f(x^{*}) = \min_{x\in C} f(x)  \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp; \quad f(x^{*}) = \min_x f(x) + I_C(x) \\
                      \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp;\quad 0 \in \partial(f(x^{*}) + I_C(x^{*})) \\
                      \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp;\quad 0 \in \{\nabla f(x^{*}) \} + \mathcal{N}_C(x^{*}) \\
                      \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp;\quad - \nabla f(x^{*}) \in \mathcal{N}_C(x^{*}) \\
                      \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp;\quad - \nabla f(x^{*})^Tx^{*} \geq -\nabla f(x^{*})^Ty, \text{ với mọi }  y \in C \\
                      \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp;\quad \nabla f(x^{*})^T(y-x^{*}) \geq 0, \text{ với mọi } y \in C 
\end{alignat}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03-01 Điều kiện tối ưu gradient dưới</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_03_01_subgradient_optimality_condition/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_03_01_subgradient_optimality_condition</id>
   <content type="html">&lt;h3 id=&quot;bổ-đề&quot;&gt;Bổ đề&lt;/h3&gt;

&lt;p&gt;Đối với bất kỳ hàm \(f\) nào, điều kiện \(x^*\) là một điểm cực tiểu của \(f\) và điều kiện \(0\) là một gradient dưới tại \(x^*\) là tương đương:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{equation}
f(x^*) = \min_x f(x) \Longleftrightarrow 0 \in \partial f(x^*)
\end{equation}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;chứng-minh&quot;&gt;Chứng minh&lt;/h3&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;f(x^*) = \min_x f(x)\\
\Longleftrightarrow &amp;amp;f(y) \geq f(x^*) \text{ với mọi } y\\
\Longleftrightarrow &amp;amp;f(y) \geq f(x^*) + 0^T(y-x^*)\\
\Longleftrightarrow &amp;amp;0 \in \partial f(x^*)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Lưu ý rằng tính lồi của \(f\) không được sử dụng trong chứng minh này, nên điều kiện tối ưu này áp dụng ngay cả cho các hàm không lồi.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>07-02 Vi phân dưới (Sub-differentials)</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_02_subdifferentials/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_02_subdifferentials</id>
   <content type="html">&lt;p&gt;Vi phân dưới \(\partial f(x)\) của một hàm lồi \(f\) tại điểm \(x\) là tập hợp tất cả các gradient dưới tại \(x\):&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\partial f(x) = {g \in \mathbb{R}^n | \text{g là gradient dưới của f tại x} }
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Vi phân dưới có các tính chất sau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\partial f(x)\) luôn là một tập lồi đóng, bất kể \(f\) có lồi hay không.&lt;/li&gt;
  &lt;li&gt;Nếu \(f\) lồi, \(\partial f(x)\) luôn chứa ít nhất một phần tử; nếu \(f\) không lồi, nó có thể rỗng.&lt;/li&gt;
  &lt;li&gt;Nếu \(f\) khả vi và lồi tại \(x\), thì \(\partial f(x) = \{\nabla f(x)\}\).&lt;/li&gt;
  &lt;li&gt;Nếu \(\partial f(x) = \{g\}\), thì \(f\) khả vi tại \(x\) và \(\nabla f(x) = g\).&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>07-02-02 Phép tính gradient dưới</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_02_02_subgradient_calculus/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_02_02_subgradient_calculus</id>
   <content type="html">&lt;p&gt;Các quy tắc cơ bản sau đây áp dụng cho vi phân dưới của các hàm lồi:&lt;/p&gt;

&lt;h3 id=&quot;tỷ-lệ&quot;&gt;Tỷ lệ&lt;/h3&gt;

&lt;blockquote&gt;

\[\eqalign{
	\text{nếu } &amp;amp; a&amp;gt;0, \\
	\text{thì } &amp;amp;\partial (af) = a\cdot \partial f
}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;phép-cộng&quot;&gt;Phép cộng&lt;/h3&gt;

&lt;blockquote&gt;

\[\partial(f_1 + f_2) = \partial f_1 + \partial f_2\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, tổng của hai tập hợp \(A+B= \{a+b:a\in A, b \in B\}\) được định nghĩa là tập hợp tất cả các tổng có thể.&lt;/p&gt;

&lt;h3 id=&quot;hợp-thành-affine&quot;&gt;Hợp thành affine&lt;/h3&gt;

&lt;blockquote&gt;

\[\eqalign{
	\text{nếu } &amp;amp; g(x)=f(Ax+b), \\
	\text{thì } &amp;amp; \partial g(x) = A^T \partial f(Ax+b)
}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;maximum-điểm-hữu-hạn&quot;&gt;Maximum điểm hữu hạn&lt;/h3&gt;

&lt;blockquote&gt;

\[\eqalign{
	\text{nếu } &amp;amp; f(x)=\max_{i=1,\dots,m} f_i(x), \\
	\text{thì } &amp;amp; \partial f(x) = \text{conv}\left(\bigcup_{i:f_i(x)=f(x)} \partial f_i(x)\right)
}\]
&lt;/blockquote&gt;

&lt;p&gt;Tức là, \(\partial f(x)\) được định nghĩa là bao lồi của hợp các vi phân dưới của các hàm đạt giá trị \(f(x)\) tại \(x\).&lt;/p&gt;

&lt;h3 id=&quot;maximum-điểm-tổng-quát&quot;&gt;Maximum điểm tổng quát&lt;/h3&gt;

&lt;blockquote&gt;
\[\eqalign{
	\text{nếu } &amp;amp; f(x) = \max_{s \in S} f_s(x),\\ 
	\text{thì } &amp;amp; \partial f(x) \supseteq cl \left \{ \text{conv} \left(\bigcup_{s:f_s(x)=f(x)} \partial f_s(x)\right) \right\}
}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(S\) có thể là một tập vô hạn, nên hợp của vô số tập hợp có thể không đóng. Do đó, chúng ta lấy bao đóng để đảm bảo vi phân dưới là một tập đóng.&lt;/p&gt;

&lt;p&gt;Mặt khác, nếu tập hợp \(S\) compact (đóng và bị chặn), và các hàm \(f_s\) liên tục theo \(s\), thì quan hệ đẳng thức được thiết lập.&lt;/p&gt;

&lt;p&gt;Ví dụ, đối với hàm p-norm \(f(x)\) sau đây:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
f(x) =  \vert  \vert x \vert  \vert _p = \max_{ \vert  \vert z \vert  \vert _q \leq 1} z^Tx, \qquad 1/p + 1/q =1
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nếu đặt \(f_z(x)=z^Tx\), thì \(z^*\) sao cho \(f(x)=f_{z^*}(x)\) thuộc \(\arg\max_{ \vert  \vert z \vert  \vert _q \leq 1} z^Tx\).&lt;/p&gt;

&lt;p&gt;Mặt khác, vì \(\partial f_{z^*}(x)=z^*\), nên \(\bigcup \partial f_{z^*}(x)\) là hợp của tất cả \(z^*\), do đó \(\partial f(x) = \arg\max_{ \vert  \vert z \vert  \vert _q \leq 1} z^Tx\).&lt;/p&gt;

&lt;p&gt;Ở đây, \(S={z: \vert  \vert z \vert  \vert _q \leq 1}\) là tập compact, và \(f_z(x)=z^Tx\) là tuyến tính, nên&lt;/p&gt;

&lt;p&gt;theo quy tắc maximum điểm tổng quát, việc lấy bao lồi rồi bao đóng của \(\bigcup \partial f_{z^*}(x)\) không thêm phần tử nào mới.&lt;/p&gt;

&lt;p&gt;Do đó, gradient dưới của hàm \(f(x)\) như sau:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\partial f(x) = \arg\max_{ \vert  \vert z \vert  \vert _q \leq 1} z^T x
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>07-02-01 Liên hệ với hình học tập lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_02_01_connection_to_a_convexity_geometry/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_02_01_connection_to_a_convexity_geometry</id>
   <content type="html">&lt;p&gt;Đối với một tập lồi \(C \subseteq \mathbb{R}^n\), xét hàm chỉ thị \(I_C: \mathbb{R}^n \to \mathbb{R}\) được định nghĩa như sau:&lt;/p&gt;

&lt;blockquote&gt;

\[I_C(x) = I\{x \in C \} =
\begin{cases}
0               &amp;amp;\text{nếu } x \in C \\
\infty         &amp;amp;\text{nếu } x \notin C 
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Vi phân dưới của hàm này có ý nghĩa hình học sau:&lt;/p&gt;

&lt;h3 id=&quot;bổ-đề&quot;&gt;Bổ đề&lt;/h3&gt;
&lt;p&gt;Với \(x \in C\), vi phân dưới \(\partial I_C(x)\) trùng với nón pháp tuyến \(\mathcal{N}_C(x)\) của tập \(C\) tại \(x\):&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\mathcal{N}_C(x) = {g \in \mathbb{R}^n | g^Tx \geq g^Ty \text{  với mọi  } y \in C }
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;chứng-minh&quot;&gt;Chứng minh&lt;/h3&gt;

&lt;p&gt;Theo định nghĩa, gradient dưới phải thỏa mãn:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
I_C(y) \geq I_C(x) + g^T(y-x) \text{ với mọi } y
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(x \in C\) và \(I_C(x)=0\), nên:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
I_C(y) \geq g^T(y-x) \text{ với mọi } y
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thứ nhất, với mọi \(y \in C\), ta có:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
I_C(y) = 0 \geq g^T(y-x)
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Do đó, gradient dưới \(g\) phải thỏa mãn \(g^Tx \geq g^Ty\).&lt;/p&gt;

&lt;p&gt;Thứ hai, với mọi \(y \notin C\), \(I_C(y) = \infty\), nên bất đẳng thức đúng với mọi giá trị của \(g\):&lt;/p&gt;
&lt;blockquote&gt;

\[I_C(y)=\infty \geq g^T(y-x)\]
&lt;/blockquote&gt;

&lt;p&gt;điều này luôn đúng.&lt;/p&gt;

&lt;p&gt;Đối với hai điều kiện trên, gradient dưới phải thỏa mãn cả hai, do đó gradient dưới của hàm trên là&lt;/p&gt;
&lt;blockquote&gt;

\[\{g \in \mathbb{R}^n | g^Tx \geq g^Ty\}\]
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_02_subgrad-5.png&quot; alt=&quot;connection_to_convexity_geometry&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Nón pháp tuyến [1]&lt;/figcaption&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>07-01 Gradient dưới (Subgradient)</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_01_subgradient/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_01_subgradient</id>
   <content type="html">&lt;h1 id=&quot;gradient-dưới-subgradient&quot;&gt;Gradient dưới (Subgradient)&lt;/h1&gt;

&lt;p&gt;Đối với một hàm lồi \(f:\mathbb{R}^n \to \mathbb{R}\), gradient dưới tại \(x\) là bất kỳ vector \(g \in \mathbb{R}^n\) nào thỏa mãn:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{equation}\label{subgradient}
f(y) \geq f(x) + g^T(y-x), \text{ với mọi } y
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Gradient dưới được định nghĩa ở trên:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tổng quát hóa gradient cho các hàm lồi trong trường hợp hàm không khả vi.&lt;/li&gt;
  &lt;li&gt;Đối với các hàm lồi, gradient dưới luôn tồn tại. Nếu \(f\) khả vi tại \(x\), thì \(\nabla f(x)\) là gradient dưới duy nhất.&lt;/li&gt;
  &lt;li&gt;Đối với các hàm không lồi, gradient dưới có thể được định nghĩa tương tự, nhưng nó có thể không luôn tồn tại tùy thuộc vào hàm.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dưới đây là các ví dụ về gradient dưới cho một số hàm.&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-1&quot;&gt;Ví dụ 1&lt;/h3&gt;

&lt;center&gt;
$$f:\mathbb{R} \to \mathbb{R}, f(x) =  \vert x \vert $$
&lt;/center&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_01_subgrad-1.png&quot; alt=&quot;Subgradient1&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Hình 1] Gradient dưới của } f(x)= \vert x \vert \text{ [3]}$$&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Với \(x \neq 0\), \(\vert y \vert \geq \vert x \vert + g^T(y-x)\) phải được thỏa mãn. Tức là,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;\(\vert y \vert - g^Ty \geq \vert x \vert - g^Tx\). Nếu \(\vert x \vert - g^Tx = 0\), tức là \(g=\text{sign}(x)\), thì điều kiện này được thỏa mãn với mọi \(y\). Do đó, \(g=\text{sign}(x)\) (&lt;a href=&quot;https://en.wikipedia.org/wiki/Sign_function&quot;&gt;Wikipedia: Hàm dấu&lt;/a&gt;).&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Với \(x=0\), \(\vert y \vert \geq g^Ty\) phải được thỏa mãn. Do đó, \(g \in [-1,1]\).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ví-dụ-2&quot;&gt;Ví dụ 2&lt;/h3&gt;

&lt;center&gt;
$$f:\mathbb{R}^n \to \mathbb{R}, f(x) =  \| x \|_1$$ 
&lt;/center&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_01_subgrad-3.png&quot; alt=&quot;Subgradient2&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Hình 2] Gradient dưới của }f(x)= \| x \|_1\text{ [3]}$$&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Tại một điểm \(x=(x_1,x_2,\dots,x_n)\),&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Với \(x_i \neq 0, i \in \{1,2,\dots,n\}\), vì hàm khả vi tại \(x_i\), ta có \(g_i=\text{sign}(x_i)\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Với \(x_i=0, i \in \{1,2,\dots,n\}\), ta có \(g_i \in [-1,1]\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ví-dụ-3&quot;&gt;Ví dụ 3&lt;/h3&gt;

&lt;center&gt;
$$f:\mathbb{R}^n \to \mathbb{R}, f(x) =  \vert x \vert _2$$
&lt;/center&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_01_subgrad-2.png&quot; alt=&quot;Subgradient3&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Hình 3] Gradient dưới của }f(x)= \vert x \vert _2\text{ [3]}$$&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Với \(x \neq 0\), vì hàm khả vi, ta có \(g=\nabla \sqrt{x^Tx} = \frac{1}{2}(x^Tx)^{-\frac{1}{2}} (2x) = \frac{x}{\vert x \vert _2}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Với \(x=0\), ta có \(\vert y \vert _2 \geq g^Ty \Longrightarrow  \vert y \vert _2 \geq  \vert g \vert _2 \vert y \vert _2 \cos \theta\). Do đó, \(g \in \{z: \vert z \vert _2 \leq 1 \}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ví-dụ-4&quot;&gt;Ví dụ 4&lt;/h3&gt;

&lt;p&gt;\(f(x) = \max f_1(x),f_2(x)\), trong đó \(f_1,f_2:\mathbb{R}^n \to \mathbb{R}\) đều là các hàm lồi và khả vi.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_01_subgrad-4.png&quot; alt=&quot;Subgradient4&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Hình 4] Gradient dưới của }f(x)=\max f_1(x),f_2(x) \text{ [3]}$$&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Với \(f_1(x) &amp;gt; f_2(x)\), ta có \(g = \nabla f_1(x)\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Với \(f_1(x) &amp;lt; f_2(x)\), ta có \(g = \nabla f_2(x)\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Với \(f_1(x) = f_2(x)\), ta có \(g \in \{\theta_1 \nabla f_1(x) + \theta_2 \nabla f_2(x): \theta_1 + \theta_2 = 1, \theta_1 \geq 0, \theta_2 \geq 0 \}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>07 Gradient dưới (Subgradient)</title>
   <link href="http://localhost:4000/contents/vi/chapter07/07_00_subgradient/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/07_00_subgradient</id>
   <content type="html">&lt;p&gt;Trong chương này, chúng ta giới thiệu khái niệm về gradient dưới (subgradient) và điều kiện tối ưu gradient dưới, vốn là sự tổng quát hóa của gradient và điều kiện tối ưu bậc một đã thảo luận trước đây. Chúng ta cũng sẽ khám phá một số ứng dụng và ví dụ liên quan đến các khái niệm này.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03 Subgradient Optimality Condition</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_03_subgradient_optimality_condition/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_03_subgradient_optimality_condition</id>
   <content type="html">&lt;p&gt;In this section, we examine optimality conditions using subgradients, and provide several examples to illustrate their application and usefulness.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03-05 Example: Distance to a Convex Set</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_03_05_example_distance_to_convex_set/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_03_05_example_distance_to_convex_set</id>
   <content type="html">&lt;p&gt;The distance function to a closed convex set \(C\) is defined as:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{alignat}{1}
dist(x,C) &amp;amp; = \min_{y \in C} | y-x |_2 &lt;br /&gt;
      &amp;amp; = | x-P_C(x) |_2 &lt;br /&gt;
      &amp;amp; \geq 0 
\end{alignat}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, \(P_C(x)\) is the projection of the point \(x\) onto the set \(C\), i.e., the closest point in \(C\) to \(x\). The subgradient of the distance function is:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\partial dist(x,C) = {\frac{x-P_C(x)}{ | x-P_C(x) |_2}}
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;If \(u=P_C(x)\), then by the first-order optimality condition,&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
(x-u)^T(y-u) \leq 0 \ \text{ for all } y \in C
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thus,&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
C \subseteq H = {y:(x-u)^T(y-u) \leq 0 }
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(i) For \(y \in H\),&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
(x-u)^T(y-u) \leq 0
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On the other hand, since \(dist(y,C)\geq 0\),&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
dist(y,C) \geq \frac{(x-u)^T(y-u)}{ | x-u |_2} \text{ for all } y \in H
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(ii) For \(y \notin H\),&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
(x-u)^T(y-u) = | x-u |_2 | y-u |_2 \cos\theta,
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;where \(\theta\) is the angle between \(x-u\) and \(y-u\). Then,&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;$$
\eqalign{
dist(y,C) &amp;amp;\geq dist(y,H) \&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;amp;= | y-u |_2 \cos \theta &lt;br /&gt;
&amp;amp;= \frac{(x-u)^T(y-u)}{ | x-u |_2} \text{ for all }y \notin H
}
$$&lt;/p&gt;

&lt;p&gt;Therefore, from (i) and (ii), for all \(y\),&lt;/p&gt;
&lt;blockquote&gt;

\[\eqalign{
dist(y,C) &amp;amp;\geq \frac{(x-u)^T(y-u)}{ \| x-u \|_2} \\
&amp;amp;= \frac{(x-u)^T(y-x+x-u)}{ \| x-u \|_2}\\
&amp;amp; = \| x-u \|_2 + \left(\frac{x-u}{ \| x-u \|_2}\right)^T(y-x)
}\]
&lt;/blockquote&gt;

&lt;p&gt;In conclusion, \(dist(x,C)\) has the following subgradient at \(x\):&lt;/p&gt;
&lt;blockquote&gt;

\[g=\frac{x-u}{ \| x-u \|_2}=\frac{x-P_C(x)}{ \| x-P_C(x) \|_2}\]
&lt;/blockquote&gt;

&lt;p&gt;Moreover, the subdifferential \(\partial dist(x,C)\) contains only one element, so \(dist(x,C)\) is differentiable and its derivative coincides with the subgradient.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03-04 Example: Soft-Thresholding</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_03_04_example_soft-thresholding/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_03_04_example_soft-thresholding</id>
   <content type="html">&lt;p&gt;For the simpler lasso problem with \(X=I\):&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\min_{\beta} \frac{1}{2} | y-\beta |_2^2 + \lambda | \beta |_1
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;From the previous example, the subgradient optimality condition is:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{cases}
y_i-\beta_i = \lambda \cdot \text{sign}(\beta_i) &amp;amp;\text{if } \beta_i \neq 0 \\
 |y_i-\beta_i| \leq \lambda &amp;amp;\text{if } \beta_i = 0
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;From this condition, the solution \(\beta = S_{\lambda}(y)\) can be found, where&lt;/p&gt;
&lt;blockquote&gt;

\[[S_{\lambda}(y)]_{i} = 
\begin{cases}
y_i - \lambda &amp;amp;\text{if }y_i &amp;gt; \lambda \\
0             &amp;amp;\text{if }-\lambda \leq y_i \leq \lambda, \quad \quad i \in \{1,2,\dots,n \} \\
y_i + \lambda &amp;amp;\text{if } y_i &amp;lt; -\lambda
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(S_{\lambda}\) is called the soft-thresholding operator.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_03_subgrad-6.png&quot; alt=&quot;connection_to_convexity_geometry&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig 1] Soft-thresholding, y (x-axis), } \beta \text{ (y-axis), } \lambda=1/2 \text{ [3]}$$ &lt;/figcaption&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03-03 Example: Lasso Optimality Condition</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_03_03_example_lasso_optimality_condition/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_03_03_example_lasso_optimality_condition</id>
   <content type="html">&lt;p&gt;For the lasso problem given below,&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\min_{\beta} \frac{1}{2}  | y-X\beta |_2^2 + \lambda | \beta |_1
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;where \(y \in \mathbb{R}^n\), \(X \in \mathbb{R}^{n \times p}\), \(\lambda \geq 0\).&lt;/p&gt;

&lt;p&gt;The subgradient optimality condition for this problem can be expressed as:&lt;/p&gt;
&lt;blockquote&gt;

\[\eqalign{
0 \in \partial\left(\frac{1}{2} \| y-X\beta \|_2^2 + \lambda \| \beta \|_1\right)
&amp;amp;\quad \Longleftrightarrow \quad 0 \in - X^T (y-X\beta) + \lambda \partial  \| \beta \|_1 \\
&amp;amp;\quad \Longleftrightarrow \quad X^T (y-X\beta)  = \lambda v \\
&amp;amp; \quad \text{for some } v \in \partial  \| \beta \|_1
}\\\]
&lt;/blockquote&gt;

&lt;p&gt;Here, for a point \(\beta=(\beta_1,\beta_2,\dots,\beta_p )\), the subgradient \(v=(v_1,v_2,\dots,v_p)\) is given by:&lt;/p&gt;

\[v_i = 
\begin{cases}
 1   &amp;amp;\text{if } \beta_i &amp;gt; 0 \\
-1   &amp;amp;\text{if } \beta_i &amp;lt; 0 \\
[-1,1]   &amp;amp;\text{if } \beta_i = 0
\end{cases}
, i \in \{1,2,\dots,p \}\]

&lt;p&gt;Any \(\beta\) satisfying the following is optimal:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
X^T(y-X\beta) = \lambda v 
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That is, for the optimal \(\beta\), the following conditions hold:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{cases}
X_i^T(y-X\beta) = \lambda \cdot \text{sign}(\beta_i) &amp;amp;\text{if } \beta_i \neq 0 \\
 |X_i^T(y-X\beta)|  \leq \lambda &amp;amp;\text{if } \beta_i = 0 
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(X_i, i \in \{1,2,\dots, p \}\) denotes the \(i\)th column of the matrix \(X\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03-02 Derivation of First-Order Optimality Condition</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_03_02_derivation_of_first-order_optimality_condition/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_03_02_derivation_of_first-order_optimality_condition</id>
   <content type="html">&lt;h3 id=&quot;first-order-optimality-condition&quot;&gt;&lt;strong&gt;First-order optimality condition:&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;If \(f\) is convex and differentiable, the subgradient optimality condition coincides with the first-order optimality condition, as shown below.&lt;/p&gt;

\[x^* \text{ is optimal} \quad \Longleftrightarrow \quad \nabla f(x^*)^T(y - x^*) \geq 0, \text{ for all } y \in C\]

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;
&lt;blockquote&gt;

\[\begin{alignat}{2}
f(x^{*}) = \min_{x\in C} f(x)  \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp; \quad f(x^{*}) = \min_x f(x) + I_C(x) \\
                      \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp;\quad 0 \in \partial(f(x^{*}) + I_C(x^{*})) \\
                      \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp;\quad 0 \in \{\nabla f(x^{*}) \} + \mathcal{N}_C(x^{*}) \\
                      \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp;\quad - \nabla f(x^{*}) \in \mathcal{N}_C(x^{*}) \\
                      \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp;\quad - \nabla f(x^{*})^Tx^{*} \geq -\nabla f(x^{*})^Ty, \text{ for all }  y \in C \\
                      \quad &amp;amp; \Longleftrightarrow &amp;amp; &amp;amp;\quad \nabla f(x^{*})^T(y-x^{*}) \geq 0, \text{ for all } y \in C 
\end{alignat}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>07-03-01 Subgradient Optimality Condition</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_03_01_subgradient_optimality_condition/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_03_01_subgradient_optimality_condition</id>
   <content type="html">&lt;h3 id=&quot;lemma&quot;&gt;Lemma&lt;/h3&gt;

&lt;p&gt;For any function \(f\), the condition that \(x^*\) is a minimizer of \(f\) and that \(0\) is a subgradient at \(x^*\) are equivalent:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{equation}
f(x^*) = \min_x f(x) \Longleftrightarrow 0 \in \partial f(x^*)
\end{equation}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp;f(x^*) = \min_x f(x)\\
\Longleftrightarrow &amp;amp;f(y) \geq f(x^*) \text{ for all } y\\
\Longleftrightarrow &amp;amp;f(y) \geq f(x^*) + 0^T(y-x^*)\\
\Longleftrightarrow &amp;amp;0 \in \partial f(x^*)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Note that convexity of \(f\) is not used in this proof, so this optimality condition applies even to non-convex functions.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>07-02 Sub-differentials</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_02_subdifferentials/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_02_subdifferentials</id>
   <content type="html">&lt;p&gt;The subdifferential \(\partial f(x)\) of a convex function \(f\) at a point \(x\) is the set of all subgradients at \(x\):&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\partial f(x) = {g \in \mathbb{R}^n | \text{g is a subgradient of f at x} }
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The subdifferential has the following properties:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\partial f(x)\) is always a closed convex set, whether \(f\) is convex or not.&lt;/li&gt;
  &lt;li&gt;If \(f\) is convex, \(\partial f(x)\) always contains at least one element; if \(f\) is not convex, it may be empty.&lt;/li&gt;
  &lt;li&gt;If \(f\) is differentiable and convex at \(x\), then \(\partial f(x) = \{\nabla f(x)\}\).&lt;/li&gt;
  &lt;li&gt;If \(\partial f(x) = \{g\}\), then \(f\) is differentiable at \(x\) and \(\nabla f(x) = g\).&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>07-02-02 Subgradient Calculus</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_02_02_subgradient_calculus/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_02_02_subgradient_calculus</id>
   <content type="html">&lt;p&gt;The following basic rules hold for the subdifferential of convex functions:&lt;/p&gt;

&lt;h3 id=&quot;scaling&quot;&gt;Scaling&lt;/h3&gt;

&lt;blockquote&gt;

\[\eqalign{
	ext{if } &amp;amp; a&amp;gt;0, \\
	ext{then } &amp;amp;\partial (af) = a\cdot \partial f
}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;addition&quot;&gt;Addition&lt;/h3&gt;

&lt;blockquote&gt;

\[\partial(f_1 + f_2) = \partial f_1 + \partial f_2\]
&lt;/blockquote&gt;

&lt;p&gt;Here, the sum of two sets \(A+B= \{a+b:a\in A, b \in B\}\) is defined as the set of all possible sums.&lt;/p&gt;

&lt;h3 id=&quot;affine-composition&quot;&gt;Affine composition&lt;/h3&gt;

&lt;blockquote&gt;

\[\eqalign{
	ext{if } &amp;amp; g(x)=f(Ax+b), \\
	ext{then } &amp;amp; \partial g(x) = A^T \partial f(Ax+b)
}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;finite-pointwise-maximum&quot;&gt;Finite pointwise maximum&lt;/h3&gt;

&lt;blockquote&gt;

\[\eqalign{
	ext{if } &amp;amp; f(x)=\max_{i=1,\dots,m} f_i(x), \\
	ext{then } &amp;amp; \partial f(x) = \text{conv}\left(\bigcup_{i:f_i(x)=f(x)} \partial f_i(x)\right)
}\]
&lt;/blockquote&gt;

&lt;p&gt;That is, \(\partial f(x)\) is defined as the convex hull of the union of the subdifferentials of the functions attaining the value \(f(x)\) at \(x\).&lt;/p&gt;

&lt;h3 id=&quot;general-pointwise-maximum&quot;&gt;General pointwise maximum&lt;/h3&gt;

&lt;blockquote&gt;
\[\eqalign{
	ext{if } &amp;amp; f(x) = \max_{s \in S} f_s(x),\\ 
	ext{then } &amp;amp; \partial f(x) \supseteq cl \left \{ \text{conv} \left(\bigcup_{s:f_s(x)=f(x)} \partial f_s(x)\right) \right\}
}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(S\) may be an infinite set, so the union of infinitely many sets may not be closed. Therefore, we take the closure to ensure the subdifferential is a closed set.&lt;/p&gt;

&lt;p&gt;On the other hand, if the set \(S\) is compact (closed and bounded) and the functions \(f_s\) are continuous with respect to \(s\), then the equality holds.&lt;/p&gt;

&lt;p&gt;For example, consider the following p-norm function \(f(x)\):&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
f(x) =  \vert  \vert x \vert  \vert _p = \max_{ \vert  \vert z \vert  \vert _q \leq 1} z^Tx, \qquad 1/p + 1/q =1
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we let \(f_z(x)=z^Tx\), then \(z^*\) such that \(f(x)=f_{z^*}(x)\) belongs to \(\arg\max_{ \vert  \vert z \vert  \vert _q \leq 1} z^Tx\).&lt;/p&gt;

&lt;p&gt;Since \(\partial f_{z^*}(x)=z^*\), the union \(\bigcup \partial f_{z^*}(x)\) is the union of all \(z^*\), which gives us \(\partial f(x) = \arg\max_{ \vert  \vert z \vert  \vert _q \leq 1} z^Tx\).&lt;/p&gt;

&lt;p&gt;Here, \(S=\{z: \vert  \vert z \vert  \vert _q \leq 1\}\) is a compact set, and \(f_z(x)=z^Tx\) is linear.&lt;/p&gt;

&lt;p&gt;By the general pointwise maximum rule, taking the convex hull and then the closure of \(\bigcup \partial f_{z^*}(x)\) does not add any additional elements to the set.&lt;/p&gt;

&lt;p&gt;Therefore, the subgradient of the function \(f(x)\) is as follows:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\partial f(x) = \arg\max_{ \vert  \vert z \vert  \vert _q \leq 1} z^T x
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>07-02-01 Connection to a Convexity Geometry</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_02_01_connection_to_a_convexity_geometry/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_02_01_connection_to_a_convexity_geometry</id>
   <content type="html">&lt;p&gt;For a convex set \(C \subseteq \mathbb{R}^n\), consider the indicator function \(I_C: \mathbb{R}^n \to \mathbb{R}\) defined as:&lt;/p&gt;

&lt;blockquote&gt;

\[I_C(x) = I\{x \in C \} =
\begin{cases}
0               &amp;amp;\text{if } x \in C \\
\infty         &amp;amp;\text{if } x \notin C 
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;The subdifferential of this function has the following geometric meaning:&lt;/p&gt;

&lt;h3 id=&quot;lemma&quot;&gt;Lemma&lt;/h3&gt;
&lt;p&gt;For \(x \in C\), the subdifferential \(\partial I_C(x)\) coincides with the normal cone \(\mathcal{N}_C(x)\) to the set \(C\) at \(x\):&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
\mathcal{N}_C(x) = {g \in \mathbb{R}^n | g^Tx \geq g^Ty \text{  for all  } y \in C }
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;By definition, the subgradient must satisfy:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
I_C(y) \geq I_C(x) + g^T(y-x) \text{ for all } y
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, \(x \in C\) and \(I_C(x)=0\), so:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
I_C(y) \geq g^T(y-x) \text{ for all } y
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;First, for all \(y \in C\), we have:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
I_C(y) = 0 \geq g^T(y-x)
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thus, the subgradient \(g\) must satisfy \(g^Tx \geq g^Ty\).&lt;/p&gt;

&lt;p&gt;Second, for all \(y \notin C\), \(I_C(y) = \infty\), so the inequality holds for any value of \(g\):&lt;/p&gt;
&lt;blockquote&gt;

\[I_C(y)=\infty \geq g^T(y-x)\]
&lt;/blockquote&gt;

&lt;p&gt;which is always true.&lt;/p&gt;

&lt;p&gt;Since the subgradient must satisfy both conditions above, the subgradient for this function becomes:&lt;/p&gt;
&lt;blockquote&gt;

\[\{g \in \mathbb{R}^n | g^Tx \geq g^Ty\}\]
&lt;/blockquote&gt;

&lt;p&gt;This completes the proof.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_02_subgrad-5.png&quot; alt=&quot;connection_to_convexity_geometry&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Normal cone [1]&lt;/figcaption&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>07-01 Subgradient</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_01_subgradient/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_01_subgradient</id>
   <content type="html">&lt;h1 id=&quot;subgradient&quot;&gt;Subgradient&lt;/h1&gt;

&lt;p&gt;For a convex function \(f:\mathbb{R}^n \to \mathbb{R}\), a subgradient at \(x\) is any vector \(g \in \mathbb{R}^n\) that satisfies:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{equation}\label{subgradient}
f(y) \geq f(x) + g^T(y-x), \text{ for all } y
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;The subgradient defined above:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Generalizes the gradient for convex functions to cases where the function is not differentiable.&lt;/li&gt;
  &lt;li&gt;For convex functions, a subgradient always exists. If \(f\) is differentiable at \(x\), then \(\nabla f(x)\) is the unique subgradient.&lt;/li&gt;
  &lt;li&gt;For non-convex functions, a subgradient may be defined similarly, but it may not always exist depending on the function.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below are examples of subgradients for some functions.&lt;/p&gt;

&lt;h3 id=&quot;example-1&quot;&gt;Example 1&lt;/h3&gt;

&lt;center&gt;
$$f:\mathbb{R} \to \mathbb{R}, f(x) =  \vert x \vert $$
&lt;/center&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_01_subgrad-1.png&quot; alt=&quot;Subgradient1&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig 1] Subgradient of } f(x)= \vert x \vert \text{ [3]}$$&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;For \(x \neq 0\), \(\vert y \vert \geq \vert x \vert + g^T(y-x)\) must hold. That is,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;\(\vert y \vert - g^Ty \geq \vert x \vert - g^Tx\). If \(\vert x \vert - g^Tx = 0\), i.e., \(g=\text{sign}(x)\), then the condition holds for all \(y\). Thus, \(g=\text{sign}(x)\) (&lt;a href=&quot;https://en.wikipedia.org/wiki/Sign_function&quot;&gt;Wikipedia: Sign function&lt;/a&gt;).&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For \(x=0\), \(\vert y \vert \geq g^Ty\) must hold. Therefore, \(g \in [-1,1]\).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-2&quot;&gt;Example 2&lt;/h3&gt;

&lt;center&gt;
$$f:\mathbb{R}^n \to \mathbb{R}, f(x) =  \| x \|_1$$ 
&lt;/center&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_01_subgrad-3.png&quot; alt=&quot;Subgradient2&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig 2] Subgradient of }f(x)= \| x \|_1\text{ [3]}$$&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;At a point \(x=(x_1,x_2,\dots,x_n)\),&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;For \(x_i \neq 0, i \in \{1,2,\dots,n\}\), since it is differentiable at \(x_i\), we have \(g_i=\text{sign}(x_i)\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For \(x_i=0, i \in \{1,2,\dots,n\}\), we have \(g_i \in [-1,1]\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example3&quot;&gt;Example3&lt;/h3&gt;

&lt;center&gt;
$$f:\mathbb{R}^n \to \mathbb{R}, f(x) =  \vert x \vert _2$$
&lt;/center&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_01_subgrad-2.png&quot; alt=&quot;Subgradient3&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig 3] Subgradient of }f(x)= \vert x \vert _2\text{ [3]}$$&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;For \(x \neq 0\), since it is differentiable, we have \(g=\nabla \sqrt{x^Tx} = \frac{1}{2}(x^Tx)^{-\frac{1}{2}} (2x) = \frac{x}{\vert x \vert _2}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For \(x=0\), we have \(\vert y \vert _2 \geq g^Ty \Longrightarrow  \vert y \vert _2 \geq  \vert g \vert _2 \vert y \vert _2 \cos \theta\). Therefore, \(g \in \{z: \vert z \vert _2 \leq 1 \}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example4&quot;&gt;Example4&lt;/h3&gt;

&lt;p&gt;\(f(x) = \max f_1(x),f_2(x)\), where \(f_1,f_2:\mathbb{R}^n \to \mathbb{R}\) are both convex and differentiable functions.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter07/07_01_subgrad-4.png&quot; alt=&quot;Subgradient4&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig 4] Subgradient of }f(x)=\max f_1(x),f_2(x) \text{ [3]}$$&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;For \(f_1(x) &amp;gt; f_2(x)\), we have \(g = \nabla f_1(x)\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For \(f_1(x) &amp;lt; f_2(x)\), we have \(g = \nabla f_2(x)\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For \(f_1(x) = f_2(x)\), we have \(g \in \{\theta_1 \nabla f_1(x) + \theta_2 \nabla f_2(x): \theta_1 + \theta_2 = 1, \theta_1 \geq 0, \theta_2 \geq 0 \}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>07 Subgradient</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_00_subgradient/"/>
   <updated>2021-03-25T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter07/07_00_subgradient</id>
   <content type="html">&lt;p&gt;In this chapter, we introduce the concept of subgradient and subgradient optimality conditions, which generalize the gradient and first-order optimality conditions discussed previously. We also explore several applications and examples related to these concepts.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19-07 Projected Newton method</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_07_Projected_Newton_method/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_07_Projected_Newton_method</id>
   <content type="html">&lt;h2 id=&quot;whats-wrong-with-projected-newton&quot;&gt;What’s wrong with projected Newton?&lt;/h2&gt;
&lt;p&gt;When \(h\) is the indicator function \(h = I_c(x)\) of convex set \(C\), the problem can be defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x} \ g(x) \quad  \text{subject to}  \quad  x \in C\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, if \(h(x) = I_c(x)\), then proximal gradient descent becomes &lt;strong&gt;projected gradient descent&lt;/strong&gt;. That is, projected gradient descent is a special case of proximal gradient descent.&lt;/p&gt;

&lt;p&gt;What about the case of proximal Newton when \(h(x) = I_c(x)\)? In this case, the update equation is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
z^{+} &amp;amp; =\underset{z \in C}{\text{argmin}} \ \frac{1}{2} \parallel x - H^{-1} \nabla g(x) - z \parallel_H^2  \\\\
&amp;amp;= \underset{z \in C}{\text{argmin}} \ \nabla g(x)^T (z - x) + \frac{1}{2} (z - x)^T H (z - x)  \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If \(H = I\), then this becomes the result of projecting \(x - \nabla g(x)\) onto set \(C\), but for general \(H \neq I\), it is not a projection. (If \(H = I\), it would be the \(l_2\)-norm, so if it were the \(l_2\)-norm instead of the H-norm, it would be a projection.) 
Therefore, the projected Newton method is not a special case of the proximal Newton method.&lt;/p&gt;

&lt;h2 id=&quot;projected-newton-for-box-constraints&quot;&gt;Projected Newton for box constraints&lt;/h2&gt;
&lt;p&gt;For the special case of problems with box constraints, projected Newton can be applied. (Bertsekas, 1982; Kim et al., 2010; Schmidt et al., 2011).&lt;/p&gt;

&lt;p&gt;Let the problem be as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x} \ g(x) \quad  \text{subject to}  \quad  l \le x \le u\]
&lt;/blockquote&gt;

&lt;p&gt;Starting with the initial point \(x^{(0)}\) of the Projected Newton method and a small constant \(\epsilon \gt 0\), we iterate the following steps (\(k = 1, 2, 3, ...\)).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step1: Binding set을 정의한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
B_{k-1} &amp;amp; = \{ i : x_i^{(k-1)} \le l_i + \epsilon \quad \text{and} \quad  \nabla_i g(x^{(k-1)}) \gt 0 \} \quad  \cup \quad 
\{ i : x_i^{(k-1)} \ge u_i - \epsilon  \quad \text{and} \quad  \nabla_i g(x^{(k-1)}) \lt 0 \} 
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;optimization stepat, 이 variable들을 box constraint의 경계to, 밀어낸다. 이들을 점점 더 많이 밀어낼수록 목적 function는 줄어든다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step2: Free set \(F_{k-1} = \left\{1,....,n \right\} \backslash B_{k-1}\)을 정의한다.&lt;/li&gt;
  &lt;li&gt;step3: Free variable을 therefore, Hessian의 주요 submatrix의 inverse를 정의한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[S^{(k-1)} = [(\nabla^2 g(x^{(k-1)}))_{F_{k-1}}]^{-1}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;step4: Fee variable을 따라 Newton step을 실행하고 projection을 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\begin{align}
x_{(k)} = P_{[l, u]} \left( x^{(k-1)} - t_k \begin{bmatrix} S^{(k-1)} &amp;amp; 0 \\
0 &amp;amp; I \end{bmatrix} 
\begin{bmatrix} \nabla F_{k-1} g(x^{(k-1)}) \\ \nabla B_{k-1} g(x^{(k-1)}) \end{bmatrix}
\right)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(P_{[l,u]}\)는 \([l, u] = [l_1, u_1] \times \cdots [l_n, u_n]\)to,의 projection이다.&lt;/p&gt;

&lt;p&gt;matrix식을 보면 free variableabout,서는 Newton step을 실행but, binding variable의 case, 변하지 않는 것을 알 수 있다. also,, projection은 box 범위 밖to, 있는 점들about,서 각 coordinateabout, 적절한 \(l_i\) or, \(u_i\)를 지정solution주는 간단한 작업이다.&lt;/p&gt;

&lt;p&gt;이 method은 problem가 매우 크고 (ex, difference원이 큰 case,) 대부분의 variable이 boundary 근처to, 있어서 free set이 매우 작을 when, optimization를 하는 method이다.&lt;/p&gt;

&lt;p&gt;어떤 종류의 problem가 box constraint를 갖는가? as follows: 이런 종류의 problem는 매우 많은 것with, informing,져 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nonnegative least squares&lt;/li&gt;
  &lt;li&gt;Support vector machine dual&lt;/li&gt;
  &lt;li&gt;Graphical lasso dual&lt;/li&gt;
  &lt;li&gt;Fused lasso (total variation denoising) dual&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;convergence-properties&quot;&gt;Convergence properties&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Bertsekas (1982)는 적절한 가정하to, projected Newtonwith, 유한번 iteration을 하면 적절한 binding constraints를 찾을 수 있다는 것을 보였다. 그러면, free variableabout, Newton’s methodand, 같아진다.&lt;/li&gt;
  &lt;li&gt;Bertsekas (1982)는 also,  superlinear convergence를 증명하였다.&lt;/li&gt;
  &lt;li&gt;Kim et al. (2010), Schmidt et al. (2011)은 BFGS-style update를 사용한 projected quasi-Newton method를 제안했다.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>19-06 Proximal quasi-Newton methods</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_06_Proximal_quasi_Newton_methods/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_06_Proximal_quasi_Newton_methods</id>
   <content type="html">&lt;p&gt;problem가 커질수록 Hessian의 computation 비용이 매우 높아진다. &lt;strong&gt;Proximal quasi-Newton method&lt;/strong&gt;는 각 stepat, Hessian \(H^{(k-1)} = \nabla^2 g(x^{(k-1)})\)를 computation하지 않는 방식with, superlinear or, linear convergence의 convergence 속도를 제공한다.&lt;/p&gt;

&lt;h2 id=&quot;proximal-quasi-newton-method&quot;&gt;Proximal quasi-Newton method&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Lee (2014)는 Hessian을  BFGS-styleto, update하는 방식을 제안했다. 이 method은 매우 잘 실행되며 local superlinear convergence의 convergence 속도를 갖는다.&lt;/li&gt;
  &lt;li&gt;Tseng and Yun (2009)은  Hessian을 blockwiseto, approximation하는 방식을 제안했다. 이 method은 \(f = g + h\)at, \(h\)가 일부 optimization variableto, 의존하는 부분with, 나뉠 수 있을 when,만 작동한다. Hessian을 blockwiseto, computation하면 computation이 매우 빨라진다. 이 method은 linear convergence의 convergence 속도를 갖는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quasi-Newton은 Hessian computation이 힘들when, 뿐 아니라 Hessian이 singular이거나 near singular인 ill-conditionat,도 유용하다.&lt;/p&gt;

&lt;h3 id=&quot;reference-논문&quot;&gt;reference 논문&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;J. Lee and Y. Sun and M. Saunders (2014), “Proximal Newton-type methods for minimizing composite functions”&lt;/li&gt;
  &lt;li&gt;P. Tseng and S. Yun (2009), “A coordinate gradient descent method for nonsmooth separable minimization”&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>19-05 Notable examples</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_05_Notable_examples/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_05_Notable_examples</id>
   <content type="html">&lt;h2 id=&quot;glmnet-and-quic&quot;&gt;Glmnet and QUIC&lt;/h2&gt;
&lt;p&gt;Proximal newton method의 매우 유명한 패키지가 두 가지가 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;glmnet&lt;/strong&gt; (Friedman et al., 2009): \(l_1\) penalized generalized linear modelsto, about, prox Newton를 구현한 패키지. Coordinate descent를 using,서 inner problem을 푼다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;QUIC&lt;/strong&gt;  (Hsiesh et al., 2011): graphical lasso problemto, about, prox Newton을 구현한 패키지. Factorization trick을 사용하고 coordinate descent를 using,서 inner problem을 푼다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;두 구현 패키지는 각자의 용도to, 맞춰서 매우 광범위하게 사용되고 있으며 state-of-the-art라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;Proximal Newton method는  proximal gradient보다 \(g\)의 gradient을 덜 자주 computation한다. therefore,, computation 비용이 커질수록 proximal newton이 유리하다. also,, inner solver를 신중하게 선택할수록 좋은 성능을 얻을 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;example-lasso-logistic-regression&quot;&gt;Example: lasso logistic regression&lt;/h2&gt;
&lt;p&gt;Lee et al. (2012)논문at, 제시된 예제를 let’s look at.&lt;/p&gt;

&lt;p&gt;\(l_1\) regularized logistic regressionto,대solution 다음 세가지 methodabout,서 성능을 평가하였다.
1.FISTA : accelerated prox grad 2. spaRSA : spectral projected gradient method 3. PN  : proximal Newton&lt;/p&gt;

&lt;h3 id=&quot;dense-hessian-x-n5000-p6000-예시&quot;&gt;Dense hessian X (n=5000, p=6000) 예시&lt;/h3&gt;
&lt;p&gt;데이터 수 n = 5000, feature 개수 p = 6000인 dense feature matrix \(X\)를 갖는 problemabout, 다음and, 같은 성능을 보였다. Hessian이 dense하기 because of, 매우 challenging한 problem라고 할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter19/09.05_Lasso_Example1.png&quot; alt=&quot;[Fig 1] Dense hessian X (n=5000, p=6000) [2]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Dense hessian X (n=5000, p=6000) [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;오른쪽은 function 호출 기준with,, 왼쪽은 시간 기준with, 평가한 것with,서, function 호출 기준with, 봤을 when,가 PN의 성능이 매우 우세함을 알 수 있다.&lt;/p&gt;

&lt;p&gt;여기서 비용은 \(g\)and, \(\nabla g\)를 computation하는 시간이 대부분이며 particularly, \(\exp\)and, \(\log\)function를 computation하는 시간이 많이 들었다.&lt;/p&gt;

&lt;h3 id=&quot;sparse-hessian-x-n542000-p47000-예시&quot;&gt;Sparse hessian X (n=542,000, p=47,000) 예시&lt;/h3&gt;

&lt;p&gt;다음의 case,는 \(X\)가 sparse하기 because of, \(g\)and, \(\nabla g\)를 computation하는 시간이 덜 들었다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter19/09.05_Lasso_Example-sparse.png&quot; alt=&quot;[Fig 2] Sparse hessian X (n=542,000, p=47,000) [2]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] Sparse hessian X (n=542,000, p=47,000) [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;inexact-prox-evaluations&quot;&gt;Inexact prox evaluations&lt;/h2&gt;
&lt;p&gt;Proximal Newton methodat, proximal operation을 computation할 when,  prox operator가 closed form이 아니기 because of, 정확히 computation하지 못한다. 그럼to,도 불구하고, 매우 높은 정확도를 갖는다면 매우 좋은 성질이 될 수 있다.&lt;/p&gt;

&lt;p&gt;Lee (2014)at,는 global convergenceand,  local superlinear convergence를 보장하는 inner problem의 stopping rule을 제안했다.&lt;/p&gt;

&lt;h3 id=&quot;three-stopping-rules&quot;&gt;Three stopping rules&lt;/h3&gt;
&lt;p&gt;Graphical lasso estimation problemto, inner optimizations을 위한 세 가지 stopping rules을 비교하였다. 이when,, 데이터 개수는 n = 72이고 feature 개수는 p = 1255이다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter19/09.05_Inexact_prox.png&quot; alt=&quot;[Fig 3] Three stopping rules [2]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 3] Three stopping rules [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;세 가지 stopping rule은 adaptive, maxiter = 10, exact이다. Maxiter는 inner iteration을 최대 10번to,만 하는 방식이고 exact는 정확한 solution를 구할 when,to, iteration하는 방식이다.&lt;/p&gt;

&lt;p&gt;Proximal newton method가 quadratic convergence를 만족하므to, exact는  quadratic convergence를 만족한다고 볼 수 있다. Maxiter=10의 case, 최대 10번의 inner iterationwith,는 quadratic convergence를 만족하지 못but, adaptive의 case, quadratic convergence를 만족하며 세 가지 방식 중 가장 빠르다.&lt;/p&gt;

&lt;h3 id=&quot;stopping-rule-of-usual-newton-method&quot;&gt;Stopping rule of usual newton method&lt;/h3&gt;
&lt;p&gt;일반적인 newton’s methodat,는 inner problem은 \(x^{(k-1)}\)의 \(g\)to, about, quadratic approximation인 \(\tilde{g}_{k-1}\)를 minimization한다. and,, \(\eta_k, k=1,2,3,...\)를 choosing,서 다음 condition,을 만족할 when, 중지한다. (이를 forcing sequence라고 한다.)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\parallel \nabla \tilde{g}_{k-1}(x^{(k)}) \parallel_2 &amp;amp; \le \eta_k \parallel  \nabla g(x^{(k-1)})  \parallel_2 \&lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 condition,은 다음 positionat,의 gradient가 현재 positionat,의 gradient보다 \(\eta_k\)배 만큼 작다는 것을 의미한다. 이when,, Quadratic approximation은 \(\tilde{g}_{k-1}(z) = \nabla g(x)^T (z-x) + \frac{1}{2t} \parallel  z - x \parallel_2^2\)이다.&lt;/p&gt;

&lt;h3 id=&quot;stopping-rule-of-proximal-gradient-method&quot;&gt;Stopping rule of proximal gradient method&lt;/h3&gt;
&lt;p&gt;Lee et al. (2012)at,는 proximal gradientat,는 gradient instead, generalized gradient를 사용하는 방식을 제안하였다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\parallel G_{\tilde{f}_{k-1}/M}(x^{(k)}) \parallel_2 &amp;amp; \le \eta_k \parallel  G_{f/M}(x^{(k-1)})  \parallel_2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\tilde{f}_{k-1} = \tilde{g}_{k-1} + h\)이고 \(mI \preceq \nabla^2 g \preceq MI\)이다.&lt;/p&gt;

&lt;p&gt;and,, as follows: \(\eta_k\)를 설정하여 inexact proximal newton이 local superlinear rate를 갖는다는 것을 증명하였다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\eta_k \le \min \left\{ \frac{m}{2},  \frac{\parallel  G_{\tilde{f}_{k-2}/M}(x^{(k-1)}) - G_{f/M}(x^{(k-1)})  \parallel_2}{\parallel  G_{f/M}(x^{(k-2)})  \parallel_2} \right\}
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>19-04 Convergence analysis</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_04_Convergence_analysis/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_04_Convergence_analysis</id>
   <content type="html">&lt;p&gt;To analyze the convergence of the Proximal Newton method, we will follow the proof from Lee (2014) [1].&lt;/p&gt;

&lt;p&gt;[1] J. Lee and Y. Sun and M. Saunders (2014), Proximal Newton-type methods for minimizing&lt;/p&gt;

&lt;p&gt;To prove convergence, we make the following assumptions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(f = g + h\), \(g\) and \(h\) are convex and \(g\) is twice differentiable (smooth)&lt;/li&gt;
  &lt;li&gt;\(mI \preceq \nabla^2 g(x) \preceq LI\).&lt;/li&gt;
  &lt;li&gt;\(\nabla^2 g(x)\) is Lipschitz with constant \(M\)&lt;/li&gt;
  &lt;li&gt;\(\text{prox}_H(\cdot)\) can be computed exactly&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The above three assumptions imply that the function is strictly convex, and assuming that \(\text{prox}_H(\cdot)\) can be computed exactly is because this is not easy to achieve in practice.&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Proximal Newton method&lt;/strong&gt; converges globally using backtracking line search.
\begin{align}
\parallel x^{(k)} - x^{\star} \parallel_2 \le \frac{M}{2m} \parallel x^{(k-1)} - x^{\star} \parallel_2^2
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is called &lt;strong&gt;local quadratic convergence&lt;/strong&gt;. After \(k \ge k_0\), to satisfy \(f(x^{(k)}) - f^{\star} \le \epsilon\), \(O(\log \log (1/\epsilon))\) iterations are needed. However, each iteration uses a scaled prox.&lt;/p&gt;

&lt;h2 id=&quot;proof-sketch&quot;&gt;Proof sketch&lt;/h2&gt;
&lt;p&gt;To show &lt;strong&gt;global convergence&lt;/strong&gt;, we can show that at any step, the backtracking exit condition for step size \(t\) is satisfied as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
t \le \min \left\{ 1, \frac{2m}{L} (1-\alpha) \right\} \&lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;With this equation, we can show that when the global minimum is reached, the update direction converges to 0.&lt;/p&gt;

&lt;p&gt;To show &lt;strong&gt;local quadratic convergence&lt;/strong&gt;, after sufficiently many iterations, the pure Newton step \(t=1\) satisfies the backtracking exit conditions, and the following equation holds.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\parallel x^{+} - x^{\star} \parallel_2 &amp;amp; \le \frac{1}{\sqrt(m)} \parallel x^{+} - x^{\star} \parallel_H \\\\
&amp;amp; =  \frac{1}{\sqrt(m)} \parallel \text{prox}_H(x - H^{-1} \nabla g(x) )  - \text{prox}_H(x^{\star} - H^{-1} \nabla g(x^{\star}) )  \parallel_H \\\\
&amp;amp; \le \frac{M}{2m} \parallel x - x^{\star} \parallel_2^2 \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Summarizing this, we get the following:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\parallel x^{+} - x^{\star} \parallel_2 \ \le \ \frac{1}{\sqrt(m)} \parallel x^{+} - x^{\star} \parallel_H \  \le \ \frac{M}{2m} \parallel x - x^{\star} \parallel_2^2
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The first inequality holds due to the lowest eigenvalue bound, and the equality holds by the fact that \(\text{prox}_H(\cdot)\) becomes the identity at the definition of \(x^+\) and global minimum \(x^{\star}\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The second inequality holds due to the nonexpansiveness of the proximal operator, the Lipschitz assumption, and the largest eigenvalue bound.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>19-03 When would we use proximal Newton?</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_03_When_would_we_use_proximal_Newton/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_03_When_would_we_use_proximal_Newton</id>
   <content type="html">&lt;p&gt;When should we use the proximal newton method?&lt;/p&gt;

&lt;p&gt;To understand the usefulness of the proximal newton method, let’s compare the proximal newton method and proximal gradient descent on the following problem.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt; : \(\min_x g(x) + h(x)\)&lt;/p&gt;

&lt;h2 id=&quot;proximal-gradient-descent-vs-proximal-newton&quot;&gt;Proximal gradient descent vs. proximal newton&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Proximal Newton&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;\(\frac{1}{2} \parallel b - x \parallel_2^2 + h(x)\) minimization&lt;/td&gt;
      &lt;td&gt;\(b^T x + x^T A x + h(x)\) minimization&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Prox operator가 대부분 closed formwith, 정의됨&lt;/td&gt;
      &lt;td&gt;Prox operator가 대부분 closed formwith, 정의되지 않음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;iteration이 저렴&lt;/td&gt;
      &lt;td&gt;iteration이 아주 비쌈 (newton method보다 비쌈)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Gradient descent convergence 속도 &lt;br /&gt; \(O(1/\epsilon)\)&lt;/td&gt;
      &lt;td&gt;Newton’s method convergence 속도 &lt;br /&gt; \(O(\log \log 1/\epsilon)\)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;두 method은 비슷solution 보이지만 실제 매우 다른 일을 한다.&lt;/p&gt;

&lt;p&gt;therefore,, proximal newton method는 아주 적은 iteration을 기대할 수 있는 scaled prox operator(quadratic + \(h\))to, about, 빠른 inner optimizer를 가질 when, 사용할 수 있다. \(h\)가 separable function일 when, inner optimizerto, 가장 많이 사용되는 method이 coordinate descent이다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19-02 Backtracking line search</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_02_Backtracking_line_search/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_02_Backtracking_line_search</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Proximal newton method&lt;/strong&gt; may not converge in cases with pure step size \(t_k=1, k=1,2,3, \cdots\) like newton’s method. Therefore, we need to optimize the step size through backtracking line search.&lt;/p&gt;

&lt;h2 id=&quot;backtracking-line-search-algorithm&quot;&gt;Backtracking line search algorithm&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize parameters. (\(0 \lt \alpha \le 1/2, 0 \lt \beta \lt 1\))&lt;/li&gt;
  &lt;li&gt;At each iteration, compute the Proximal newton direction as \(v = \text{prox}_{H} ( x - H^{-1} \nabla g (x) ) - x\).&lt;/li&gt;
  &lt;li&gt;Initialize \(t=1\).&lt;/li&gt;
  &lt;li&gt;If the condition \(f(x + tv) \gt f(x) + \alpha t \nabla g(x)^T v + \alpha (h(x + tv) - h(x))\) is satisfied, reduce \(t=\beta t\). Iterate step 4 while this condition is satisfied. (\(f = g + h\))&lt;/li&gt;
  &lt;li&gt;Execute the Proximal newton update \(x^+ = x + tv\).&lt;/li&gt;
  &lt;li&gt;If the termination condition is not satisfied, go to step 2.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Intuitively, we find a step size \(t\) such that we move along direction \(v\) to a position where the linear approximation of function \(f\) at \(x\) is reduced by a factor of \(\alpha\). Since the \(h\) part of \(f\) is not differentiable, we use the discrete derivative \(h(x + tv) - h(x)\).&lt;/p&gt;

&lt;h2 id=&quot;efficiency-of-algorithm&quot;&gt;Efficiency of algorithm&lt;/h2&gt;
&lt;p&gt;There are many methods for performing backtracking line search, and here we have introduced one of them.&lt;/p&gt;

&lt;p&gt;In this method, when computing \(v\), the prox operator is computed only once. In the case of proximal gradient descent, the prox operator had to be computed iteratively in the inner loop, which is a distinctly different characteristic. Therefore, this method can perform backtracking line search very efficiently when the computation of the prox operator is complex.&lt;/p&gt;

&lt;h3 id=&quot;reference-method-별--backtracking-line-search&quot;&gt;[reference] Method 별  backtracking line search&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Gradient descent &lt;a href=&quot;/contents/vi/chapter06/06_02_02_backtracking_line_search/&quot;&gt;06-02-02 Backtracking line search&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Proximal gradient descent &lt;a href=&quot;/contents/vi/chapter09/09_02_convergence_analysis/&quot;&gt;09-02 Convergence analysis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Newton’s method &lt;a href=&quot;/contents/vi/chapter14/14_04_backtracking_line_search/&quot;&gt;14-04 Backtracking line search&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>19-01-03 Scaled proximal map</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_01_03_Scaled_proximal_map/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_01_03_Scaled_proximal_map</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Proximal newton method&lt;/strong&gt;를 &lt;strong&gt;proximal gradient descent&lt;/strong&gt;and, 같은 형식with, 다시 작성solution 볼 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;scaled-proximal-map&quot;&gt;Scaled proximal map&lt;/h2&gt;
&lt;p&gt;if, \(H \succ 0\)라고 하면 &lt;strong&gt;scaled proximal map&lt;/strong&gt;은 as follows: 정의된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\text{prox}_{t}(x) = \underset{z}{\text{argmin}}  \frac{1}{2} \parallel x - z \parallel_H^2 + h(z)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\parallel x\parallel_H^2 = x^THx\)with, \(H\text{-norm}\)이다.  \(H = \frac{1}{t} I\)일 when, 일반적인 &lt;strong&gt;unscaled proximal map&lt;/strong&gt;이 된다.&lt;/p&gt;

&lt;p&gt;generally, &lt;strong&gt;scaled proximal map&lt;/strong&gt;는 usually,의 prox보다 좋은 성질을 갖고 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;uniqueness&lt;/strong&gt; : solution가 하나만 존재하는 성질 (\(H \succ 0\)이므to, strictly convex optimization problem이기 because of, 만족된다.)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;non-expansiveness&lt;/strong&gt; :  팽창하지 않는 성질 (scaled proximal map이 non-expansive 성질을 갖는 projection operator의 일반화이기 because of, 만족된다.)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reference-projection-operator의-non-expansiveness&quot;&gt;[reference] Projection operator의 non-expansiveness&lt;/h3&gt;
&lt;p&gt;두 점 \(x\), \(y\)and, convex set \(C\)to, about, projection operator \(P_c\)about, non-expansiveness란 \(\parallel P_c(x) - P_c(y) \parallel_2 \le \parallel x - y \parallel_2\)를 만족한다는 것을 의미한다. that is,,  \(P_c\)는 Lipschitz-1을 만족하며 \(C\)가 convex일 case,to,만 만족한다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter19/09.01_03_projection_operator.png&quot; alt=&quot;[Fig 1] Projection onto a convex set C [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Projection onto a convex set C [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;proximal-newton-update&quot;&gt;Proximal newton update&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Scaled proximal map&lt;/strong&gt;을 using,서 Proximal newton update를 다시 expressing,보면 as follows:.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
z^{+} &amp;amp; = \underset{z}{\text{argmin}} \nabla g(x)^T (z - x)^T v + \frac{1}{2} (z - x)^T H (z - x) + h(z) \\\\
&amp;amp; =\underset{z}{\text{argmin}} \ \frac{1}{2} \parallel x - H^{-1} \nabla g(x) - z \parallel_H^2 + h(z)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;다르게 표현하면 as follows:.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
z^{(k)} &amp;amp; = \text{prox}_{H^{(k-1)}} ( x^{(k-1)} - (H^{(k-1)})^{-1} \nabla g (x^{(k-1)}) ) \\\\
x^{(k)} &amp;amp; =x^{(k-1)} + t_k (z^{(k)} - x^{(k-1)} )
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;직관적with, \(g\)about,서 newton step을 수행하고, \(H^{(k-1)}\)about, scaled prox operator를 applying,서 그 directionwith, 이동한다는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;이from, 다음and, 같은 사항을 알 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(h(z) = 0\)일when, proximal operator는 identity function가 되여 일반적인 Newton update가 된다.&lt;/li&gt;
  &lt;li&gt;\(H^{(k+1)}\)를 \(\frac{1}{r_k} I\)to, 대체하고 \(t_k = 1\)to, 두면 step size \(r_k\)about, proximal gradient update를 구할 수 있다.&lt;/li&gt;
  &lt;li&gt;Prox의 어려움은 \(h\)뿐만 아니라 \(g\)의 hessian의 구조according to, 달라진다. for example, \(H\)가 diagonal이거나 banded이면 dense한 \(H\)일 case,to, 비solution problem가 매우 쉬워진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;therefore,,  proximal Newton method는 proximal gradient descentand, Newton’s method를 둘 다 일반화한 것임을 알 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19-01-02 Proximal Newton method</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_01_02_Proximal_Newton_method/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_01_02_Proximal_Newton_method</id>
   <content type="html">&lt;p&gt;In the previous section, we explained that the &lt;strong&gt;proximal newton method&lt;/strong&gt; is a method that wants to use the local hessian \(\nabla^2 g(x)\) instead of the spherical curvature \(\frac{1}{t} I\) in the &lt;strong&gt;proximal gradient descent&lt;/strong&gt; formula. The proximal newton method is an old idea that is being studied in statistics under the term local score.&lt;/p&gt;

&lt;p&gt;Now let’s look at how the &lt;strong&gt;proximal newton method&lt;/strong&gt; can be formulated.&lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;
&lt;p&gt;The Proximal gradient descent algorithm consists of the process of finding the direction \(v\) of the next step and then optimizing the step size \(t_k\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Step 1: Starting from the starting point \(x^{(0)}\), iterate the following process. (\(k=1,2,3,...\))&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Step 2: Find the direction \(v\) of the next step.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
v^{(k)} &amp;amp; = \underset{v}{\text{argmin}} \ \nabla g(x^{(k-1)})^T v + \frac{1}{2} v^T H^{(k-1)} v + h(x^{(k-1)} + v)
\end{align}
여기서 \(H^{(k-1)} = \nabla^2 g(x^{(k-1)})\)은 \(x^{(k-1)}\)at,의 Hessian이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;3step : \(v^{(k)}\) directionwith, step을 이동하기 for, step size를 optimization한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{(k)} &amp;amp; =x^{(k-1)} + t_k v^{(k)}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;\(t_k\)는 step sizeto, \(t_k=1\)이면 pure proximal Newton method이다.&lt;/p&gt;

&lt;p&gt;Backtracking line search를 through, step size를 optimization하는 process이 있다는 점은 proximal gradient descent methodand, 다른 점이다.&lt;/p&gt;

&lt;h3 id=&quot;next-position-view&quot;&gt;Next position view&lt;/h3&gt;
&lt;p&gt;위의 식을 direction \(v\)이 아닌 다음 position인 \(z\)의 관점at, 표현하면 as follows:.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
z^{(k)} &amp;amp; = \underset{z}{\text{argmin}} \ \nabla g(x^{(k-1)})^T (z - x^{(k-1)})^T + \frac{1}{2} (z - x^{(k-1)})^T H^{(k-1)} (z - x^{(k-1)}) + h(z) \\\\
x^{(k)} &amp;amp; =x^{(k-1)} + t_k (z^{(k)} - x^{(k-1)} )
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;직관적with, 첫번째 stepat, 목적 function를 minimization 하는 surrogate point인 \(z\)를 구한다. 그런 다음, \(x^{(k-1)}\)at, \(z\)의 directionwith, 이동but, always, \(z\)to, 이동하게 되는 것은 아니다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19-01-01 Reminder - proximal gradient descent</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_01_01_Reminder-_proximal_gradient_descent/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_01_01_Reminder:_proximal_gradient_descent</id>
   <content type="html">&lt;p&gt;Before examining the &lt;strong&gt;Proximal newton method&lt;/strong&gt; that we will learn in this chapter, let’s first review &lt;strong&gt;Proximal gradient descent&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For detailed information, see &lt;a href=&quot;/contents/vi/chapter09/09_proximal_gradient_descent_and_acceleration/&quot;&gt;09 Proximal Gradient Descent and Acceleration&lt;/a&gt; see.&lt;/p&gt;

&lt;h2 id=&quot;proximal-gradient-descent&quot;&gt;Proximal gradient descent&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt; works on the following problem.&lt;/p&gt;

&lt;blockquote&gt;
\[f(x) = g(x) + h(x)\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;\(g\) is convex and differentiable. (&lt;strong&gt;dom&lt;/strong&gt;\((g) = \mathbb{R}^n\))&lt;/li&gt;
  &lt;li&gt;\(h\) is convex and non-differentiable and “simple”.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;
&lt;p&gt;Proximal gradient descent는 시작점 \(x^{(0)}\)at, 시작solution서 다음 process을 iteration한다.&lt;/p&gt;

&lt;blockquote&gt;
\[x^{(k)} = \text{prox}_{t_k}(x^{(k-1)} - t_k \nabla g(x^{(k-1)}) ),k=1,2,3,...\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\text{prox}_{t}(\cdot)\)는 \(h\)and, association,된 proximal operator 이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\text{prox}_{t}(x) = \underset{z}{\text{argmin}}  \frac{1}{2t} \parallel x - z \parallel_2^2 + h(z)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Update 식은 generalized gradient \(G_{t}\)를 using,서 표준화된 형태to, 표현할 수도 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{(k)} = x^{(k-1)} - t_k \cdot G_{t_k}(x^{(k-1)}), \space \space \text{where} \space G_{t}(x) = \frac{x-\text{prox}_{t} (x - t \nabla g(x))}{t} \&lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;performance&quot;&gt;Performance&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt;의 성능은 \(h\)according to, 달라질 수 있다. if,, \(h\)가 복잡한 function이고 particularly, closed form이 아니라면 minimize할 when, computation을 많이 solution야 하므to, 성능이 매우 떨어질 수 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;also,, \(g\)function의 convergence rateand, 같은 convergence 속도를 갖는다. 단, iteration할 when,마다 prox operator를 실행하기 because of, prox computation이 효율적인 case,to,만 유용하다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt;at,는 미분 가능한 function \(g\)를 Taylor 2difference식with, approximation하고 여기to, 미분이 되지 않는 function인 \(h\)를 더하여 목적 functionto, 정의한 후 이를 iteration적with, minimization한다. therefore,, as follows: 2difference 식with, 정리solution 볼 수 있다.&lt;/p&gt;

&lt;p&gt;식to, 전개되는 자세한 process은 &lt;a href=&quot;/contents/vi/chapter09/09_01_proximal_gradient_descent/&quot;&gt;09-01 Proximal gradient descent&lt;/a&gt; reference.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x^+ &amp;amp; = \underset{z}{\text{argmin}}  \, \frac{1}{2t} \parallel x - t \nabla g(x) - z \parallel_2 ^2 + h(z) \\\\
&amp;amp; = \underset{z}{\text{argmin}} \ \nabla g(x)^T (z - x) + \frac{1}{2t} \parallel z - x \parallel_2 ^2 + h(z) \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;두번째 식의 1항and, 2항은 \(g\)의 Taylor 2difference approximation식with, from, 유도할 수 있는데, first, constant항 \(g(x)\)은 제거하고 (gradient descentat,and, 마찬가지to,) Hessian \(\nabla^2 g(x)\)을 \(\frac{1}{t} I\)(spherical curvature)to, 대체solution서 구할 수 있다.&lt;/p&gt;

&lt;p&gt;다음 그림at,는 proximal gradient descent의 update stepat, \(g\)를 2difference approximation식with, minimization 하는 process을 showing,주고 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter19/09.01_01_proximal_gradient_descent.png&quot; alt=&quot;[Fig 1] Proximal gradient descent updates [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Proximal gradient descent updates [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Gradient descentand, newton’s method의 difference이점는 2difference approximation를 할 when, function의 local hessian인 \(\nabla^2 g(x)\)를 사용하는지 여부이다. 그렇다면, 위의 식at, \(\frac{1}{t} I\) instead, \(\nabla^2 g(x)\)를 사용하면 어떻게 될까?&lt;/p&gt;

&lt;p&gt;이것이 바to, 다음 절at, 설명하게 될 &lt;strong&gt;proximal newton method&lt;/strong&gt;가 나오게 된 background,이다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19-01 Proximal Newton method</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_01_00_Proximal_Newton_method/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_01_00_Proximal_Newton_method</id>
   <content type="html">&lt;p&gt;In this section, we will review the &lt;strong&gt;proximal gradient method&lt;/strong&gt; and examine how the &lt;strong&gt;proximal newton method&lt;/strong&gt; emerged from it.&lt;/p&gt;

&lt;p&gt;We will also examine the definition of the &lt;strong&gt;proximal newton method&lt;/strong&gt; and the scaled proximal map that has good properties such as uniqueness and non-expansiveness compared to the general proximal map.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19 Proximal Newton Method</title>
   <link href="http://localhost:4000/contents/vi/chapter19/19_00_Proximal_Newton_Method/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/19_00_Proximal_Newton_Method</id>
   <content type="html">&lt;p&gt;In this chapter, we will examine &lt;strong&gt;Proximal Newton Method&lt;/strong&gt;, &lt;strong&gt;Proximal quasi-Newton method&lt;/strong&gt;, and &lt;strong&gt;Projected Newton method&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;reference-papers&quot;&gt;Reference Papers&lt;/h3&gt;

&lt;p&gt;Proximal Newton method:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;J. Friedman and T. Hastie and R. Tibshirani (2009), “Regularization paths for generalized linear models via coordinate descent”&lt;/li&gt;
  &lt;li&gt;C.J. Hsiesh and M.A. Sustik and I. Dhillon and P. Ravikumar (2011), “Sparse inverse covariance matrix estimation using quadratic approximation”&lt;/li&gt;
  &lt;li&gt;M. Patriksson (1998), “Cost approximation: a unified framework of descent algorithms for nonlinear programs”&lt;/li&gt;
  &lt;li&gt;J. Lee and Y. Sun and M. Saunders (2014), “Proximal Newton-type methods for minimizing composite functions”&lt;/li&gt;
  &lt;li&gt;P. Tseng and S. Yun (2009), “A coordinate gradient descent method for nonsmooth separable minimization”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Projected Newton method:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A. Barbero and S. Sra (2011), “Fast Newton-type methods for total variation regularization”&lt;/li&gt;
  &lt;li&gt;D. Bertsekas (1982), “Projected Newton methods for optimization problems with simple constraints”&lt;/li&gt;
  &lt;li&gt;D. Kim and S. Sra. and I. Dhillon (2010), “Tackling box-constrained optimization via a new projected
quasi-Newton approach”&lt;/li&gt;
  &lt;li&gt;M. Schmidt and D. Kim and S. Sra (2011), “Projected Newton-type methods in machine learning”&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>11-5 Khoảng cách đối ngẫu</title>
   <link href="http://localhost:4000/contents/vi/chapter11/11_05_Duality_gap/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter11/11_05_Duality_gap</id>
   <content type="html">&lt;p&gt;Nếu bài toán gốc có giá trị \(f(x)\) tại \(x\), và bài toán đối ngẫu có giá trị \(g(u,v)\) tại \(u,v\), thì hiệu số \(f(x) - g(u,v)\) được gọi là khoảng cách đối ngẫu.&lt;/p&gt;

&lt;p&gt;Trong khi đó, các giá trị khả thi này luôn thỏa mãn mối quan hệ sau&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
f(x) - f^* \leq f(x) - g(u,v), 
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Nếu khoảng cách đối ngẫu bằng \(0\), thì \(x\) là một nghiệm tối ưu của bài toán gốc và \(u,v\) là tối ưu cho bài toán đối ngẫu.&lt;/p&gt;

&lt;p&gt;Ngoài ra, nếu khoảng cách đối ngẫu thỏa mãn \(f(x)-g(u,v) \leq \epsilon\), điều này ngụ ý \(f(x) -f^* \leq \epsilon\), vì vậy các thuật toán giải bài toán một cách lặp có thể sử dụng khoảng cách đối ngẫu làm tiêu chí dừng.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>11-4 Tính đối ngẫu mạnh</title>
   <link href="http://localhost:4000/contents/vi/chapter11/11_04_Strong_duality/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter11/11_04_Strong_duality</id>
   <content type="html">&lt;p&gt;Khi một bài toán thỏa mãn \(f^* = g^*\), điều này được gọi là &lt;strong&gt;tính đối ngẫu mạnh&lt;/strong&gt;. &lt;strong&gt;Điều kiện Slater&lt;/strong&gt; là một điều kiện đủ cho tính đối ngẫu mạnh.&lt;/p&gt;

&lt;h2 id=&quot;điều-kiện-slater&quot;&gt;Điều kiện Slater:&lt;/h2&gt;
&lt;p&gt;Nếu bài toán gốc là lồi và tồn tại ít nhất một \(x \in \mathbb{R}^n\) khả thi nghiêm ngặt, thì tính đối ngẫu mạnh xảy ra.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
h_1(x)&amp;lt;0,\dots,h_m(x)&amp;lt;0, \text{ and } l_1(x) = 0,\dots,l_r(x) = 0,
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Lưu ý quan trọng: Bất đẳng thức nghiêm ngặt không cần được thỏa mãn khi hàm là affine.&lt;/p&gt;
&lt;h2 id=&quot;ví-dụ-bài-toán-đối-ngẫu-support-vector-machine&quot;&gt;Ví dụ: Bài toán đối ngẫu Support Vector Machine&lt;/h2&gt;
&lt;p&gt;Cho \(y \in \{-1,1\}^n\), \(X \in \mathbb{R}^{n \times p}\) (các cột của \(X\) là \(x_1, ..., x_n\)), bài toán SVM(Support Vector Machine) được định nghĩa như sau:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{alignat}{1}
\min_{\beta, \beta_0, \xi} &amp;amp; \quad \frac{1}{2}\parallel\beta\parallel_2^2 + C \sum_{i=1}^n \xi_i   \\\\
                                  s.t. &amp;amp; \quad \xi_i \geq 0, i=1,\dots,n   \\\\
                                       &amp;amp; \quad y_i(x_i^T \beta + \beta_o) \geq 1 - \xi_i, i=1,\dots,n
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Sử dụng các biến đối ngẫu \(v, w \geq 0\), hãy định nghĩa hàm Lagrangian:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
L(\beta,\beta_0,\xi,v,w) = \frac{1}{2} \parallel\beta\parallel_2^2 + C\sum_{i=1}^n \xi_i - \sum_{i=1}^n v_i \xi_i +  \sum_{i=1}^n w_i (1-\xi_i - y_i(x_i^T\beta + \beta_o))
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Tối thiểu hóa theo \(\beta, \beta_0, \xi\), ta có thể tìm được hàm đối ngẫu Lagrangian như sau:&lt;/p&gt;
&lt;blockquote&gt;

\[g(v,w) = 
\begin{cases}
-\frac{1}{2} w^T\tilde{X}\tilde{X}^T w +  1^Tw, &amp;amp;\text{if $w=C1-v, w^Ty=0$} \\\\
-\infty, &amp;amp;\text{otherwise}
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây \(\tilde{X}=\text{diag}(y) X\). Do đó, bài toán đối ngẫu SVM (sau khi loại bỏ biến slack \(v\)) trở thành:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\max_{w}  &amp;amp; \quad -\frac{1}{2} w^T\tilde{X}\tilde{X}^T w +  1^Tw \\\\
     s.t. &amp;amp;  \quad 0 \leq w \leq C1, w^Ty = 0
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Vì bài toán gốc thỏa mãn điều kiện Slater, tính đối ngẫu mạnh xảy ra. (Đó là, hàm mục tiêu là lồi và các ràng buộc bất đẳng thức là affine theo \(\beta, \beta_0, \xi\).)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>11-3 Bài toán đối ngẫu Lagrange</title>
   <link href="http://localhost:4000/contents/vi/chapter11/11_03_Lagrange_dual_problem/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter11/11_03_Lagrange_dual_problem</id>
   <content type="html">&lt;p&gt;Xem xét bài toán tối ưu sau đây:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\min_x &amp;amp; \quad f(x)  \\
s.t.   &amp;amp; \quad h_i(x) \leq 0, i=1,\dots,m  \\
       &amp;amp; \quad l_j(x) = 0, j=1,\dots,r
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Hàm đối ngẫu \(g(u,v)\) thỏa mãn \(f^* \geq g(u,v)\) với mọi \(u\geq 0\) và \(v\). Do đó, chúng ta có thể thu được cận dưới tốt nhất bằng cách tối đa hóa \(g(u,v)\) trên tất cả \(u\) và \(v\) khả thi. Điều này được gọi là bài toán đối ngẫu Lagrange.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\max_{u,v} &amp;amp; \quad g(u,v)   \\
           s.t. &amp;amp; \quad u \geq 0
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, nếu ta ký hiệu giá trị tối ưu đối ngẫu là \(g^*\), thì \(f^* \geq g^*\). Điều này được gọi là tính đối ngẫu yếu. Tính chất này luôn đúng ngay cả khi bài toán gốc không lồi. Hơn nữa, bài toán đối ngẫu luôn là một bài toán tối ưu lồi, ngay cả khi bài toán gốc không lồi.&lt;/p&gt;

&lt;p&gt;Theo định nghĩa, \(g\) là hàm lõm theo \((u,v)\), và \(u \geq 0\) là một ràng buộc lồi. Do đó, bài toán đối ngẫu tương ứng với một bài toán tối đa hóa hàm lõm.&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{alignat}{1}
 g(u,v) &amp;amp; = \min_x { f(x) + \sum_{i=1}^m u_i h_i(x) + \sum_{j=1}^r v_j l_j(x) }  \ 
        &amp;amp; = - \underbrace{\max_x { -f(x) - \sum_{i=1}^m u_i h_i(x) - \sum_{j=1}^r v_j l_j(x) }}_{\text{pointwise maximum of convex functions in $(u,v)$}}
\end{alignat}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;ví-dụ-tối-thiểu-hóa-hàm-bậc-bốn-không-lồi&quot;&gt;Ví dụ: Tối thiểu hóa hàm bậc bốn không lồi&lt;/h2&gt;
&lt;p&gt;Hãy tối thiểu hóa hàm \(f(x)=x^4 - 50 x^2 + 100 x\) với điều kiện \(x \geq -4.5\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter11/dual-gen_13.png&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 4] Ví dụ về tối thiểu hóa hàm bậc bốn không lồi&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Trong trường hợp này, hàm đối ngẫu \(g\) như sau:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
 g(u) = \min_{i=1,2,3} \{F_i^4(u) - 50 F_i^2(u) + 100 F_i(u) \}
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;where, for \(i=1,2,3\),&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
F_i(u) = &amp;amp; \frac{- a_i}{12\cdot 2^{1/3}} \left( 432(100-u)-(432^2(100-u)^2 - 4\cdot 1200^3)^{1/2} \right )^{1/3} \\ 
           &amp;amp; - 100 \cdot 2^{1/3} \frac{1}{\left( 432(100-u)-(432^2(100-u)^2 - 4\cdot 1200^3)^{1/2} \right )^{1/3}}
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;và \(a_1=1, a_2 = (-1+i\sqrt{3})/2, a_3 = (-1-i \sqrt{3})/2\).
Mặc dù khó xác định liệu \(g\) có lõm hay không chỉ bằng cách nhìn vào hàm số, nhưng chúng ta có thể biết rằng \(g\) là hàm lõm dưới tính chất lồi của tính đối ngẫu.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>11-2 Hàm đối ngẫu Lagrange</title>
   <link href="http://localhost:4000/contents/vi/chapter11/11_02_Lagrange_dual_function/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter11/11_02_Lagrange_dual_function</id>
   <content type="html">&lt;p&gt;Gọi \(C\) là tập khả thi của bài toán gốc và \(f^*\) là giá trị tối ưu của bài toán gốc. Tối thiểu hóa \(L(x,u,v)\) trên tất cả \(x\) cho ta cận dưới sau đây.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
f^* \geq \min_{x \in C} L(x,u,v) \geq \min_x L(x,u,v) := g(u,v)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(g(u,v)\) được gọi là hàm đối ngẫu Lagrange và cung cấp một cận dưới cho \(f^*\) với bất kỳ \(u\geq 0\), \(v\) khả thi đối ngẫu nào.&lt;/p&gt;

&lt;p&gt;Ví dụ, trong hình dưới đây&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter11/dual-gen_7.png&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 2] Ví dụ về hàm đối ngẫu Lagrangian[1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Đường nằm ngang đứt nét biểu thị hàm \(f^*\).&lt;/li&gt;
  &lt;li&gt;Biến đối ngẫu là \(\lambda\).&lt;/li&gt;
  &lt;li&gt;Đường liền nét biểu thị \(g(\lambda)\).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ví-dụ-chương-trình-bậc-hai&quot;&gt;Ví dụ: Chương trình bậc hai&lt;/h2&gt;
&lt;h3 id=&quot;1-xác-định-dương-q-succ-0&quot;&gt;1) Xác định dương (\(Q \succ 0\))&lt;/h3&gt;

&lt;p&gt;Xem xét bài toán bậc hai sau đây (ở đây \(Q \succ 0\))&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\min_x  &amp;amp; \quad \frac{1}{2}x^T Q x + c^T x \\\\
       s.t. &amp;amp; \quad Ax = b, \\\\
            &amp;amp; \quad x \geq 0
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Khi đó,&lt;/p&gt;

&lt;h4 id=&quot;hàm-lagrangian&quot;&gt;Hàm Lagrangian:&lt;/h4&gt;
&lt;blockquote&gt;

\[\begin{equation}
L(x,u,v) = \frac{1}{2}x^T Q x + c^T x - u^Tx + v^T (Ax-b)
\end{equation}\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;hàm-đối-ngẫu-lagrangian&quot;&gt;Hàm đối ngẫu Lagrangian:&lt;/h4&gt;

&lt;p&gt;Từ biểu thức trên, để tối thiểu hóa hàm Lagrangian, ta lấy đạo hàm theo \(x\) và tìm \(x^*\) sao cho đạo hàm bằng không.
\begin{equation}
Qx - (c-u+A^T v) = 0,
\end{equation}
Tức là,
\begin{equation}
Qx = (c-u+A^T v)
\end{equation}
Lúc này, vì \(Q\) là positive definite nên tồn tại ma trận nghịch đảo, do đó khi tìm \(x^*\), ta có \(x^* = Q^{-1}(c - u + A^Tv)\). Vậy nên, khi thay \(x^*\) vào hàm Lagrangian, ta được kết quả dưới đây.&lt;/p&gt;

\[\begin{alignat}{1}
&amp;amp; (c - u + A^T v)^T (Q^{-1})^T Q Q^{-1}(c - u + A^T v) - (c - u + A^T v)^T Q^{-1} (c - u + A^T v) - b^T v \\\
= &amp;amp; (c - u + A^T v)^T Q^{-1}(c - u + A^T v) - (c - u + A^T v)^T Q^{-1} (c - u + A^T v) - b^T v \\\
= &amp;amp; -\frac{1}{2} (c-u+A^Tv)^T Q^{-1} (c-u+A^T v) - b^T v
\end{alignat}\]

&lt;p&gt;Do đó,&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
g(u,v) = \min_x L(x,u,v) = -\frac{1}{2} (c-u+A^Tv)^T Q^{-1} (c-u+A^T v) - b^T v
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Với mọi \(u \geq 0\) và \(v\), điều này tương ứng với một cận dưới của giá trị tối ưu gốc \(f^*\).&lt;/p&gt;

&lt;h3 id=&quot;2-nửa-xác-định-dương-q-succeq-0&quot;&gt;2) Nửa xác định dương (\(Q \succeq 0\))&lt;/h3&gt;
&lt;p&gt;Cùng bài toán như trên, nhưng lần này nếu \(Q \succeq 0\),&lt;/p&gt;

&lt;h4 id=&quot;hàm-lagrangian-1&quot;&gt;Hàm Lagrangian:&lt;/h4&gt;
&lt;blockquote&gt;

\[\begin{equation}
L(x,u,v) = \frac{1}{2}x^T Q x + c^T x - u^Tx + v^T (Ax-b)
\end{equation}\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;hàm-đối-ngẫu-lagrangian-1&quot;&gt;Hàm đối ngẫu Lagrangian:&lt;/h4&gt;
&lt;p&gt;Giống như khi \(Q\) là positive definite, ta cần tìm \(x^*\) thỏa mãn phương trình dưới đây.&lt;/p&gt;

&lt;p&gt;\(\begin{equation}
Qx = (c-u+A^T v)
\end{equation}\)
Lúc này, vì \(Q\) là positive semi-definite nên có thể không tồn tại ma trận nghịch đảo. Do đó, ta cần xem xét hai trường hợp sau:&lt;/p&gt;

&lt;p&gt;(1) \(c-u+A^T v \in col(Q)\). Trong trường hợp này, tồn tại \(x^*\) thỏa mãn \(Qx = (c-u+A^T v)\), có thể tìm được bằng cách sử dụng nghịch đảo tổng quát \(Q^+\) (nghịch đảo giả Moore-Penrose, \(Q^+ = (Q^TQ)^{-1}Q^T\)).
(2) \(c-u+A^T v \notin col(Q)\). Trong trường hợp này, không tồn tại \(x^*\) thỏa mãn \(Qx = (c-u+A^T v)\), nghĩa là không có \(x^*\) nào tối thiểu hóa \(L(x,u,v)\), và giá trị tối thiểu của \(L(x,u,v)\) là \(-\infty\).&lt;/p&gt;

&lt;p&gt;Từ hai trường hợp này, hàm đối ngẫu Lagrangian có thể được tóm tắt như sau:&lt;/p&gt;
&lt;blockquote&gt;

\[g(u,v) =
\begin{cases}
-\frac{1}{2} (c-u+A^T v)^T Q^{+} (c - u + A^T v) - b^T v  &amp;amp; \text{if $c-u+A^T v \perp \text{null}(Q)$} \\\\
-\infty  &amp;amp; \text{otherwise}
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Với mọi \(u\geq 0\), \(v\) thỏa mãn \(c-u+A^Tv \perp \text{null}(Q)\), \(g(u,v)\) là một cận dưới không tầm thường của \(f^*\).&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ-chương-trình-bậc-hai-trong-2d&quot;&gt;Ví dụ: Chương trình bậc hai trong 2D&lt;/h2&gt;

&lt;p&gt;Ví dụ, trong hình sau đây, \(f(x_1,x_2)\) là một hàm bậc hai trên các biến lớn hơn 0 (\(x\ge0\)), và hàm đối ngẫu \(g(u_1,u_2)\) là một hàm bậc hai trên các biến lớn hơn 0 (\(u\ge0\)).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter11/dual-gen_10.png&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 3] Ví dụ về chương trình bậc hai trong 2D&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Điểm màu xanh là giá trị tối ưu đối ngẫu, và điểm màu đỏ là giá trị tối ưu gốc.&lt;/li&gt;
  &lt;li&gt;Với mọi \(u&amp;gt;0\), hàm đối ngẫu \(g(u)\) cung cấp một cận dưới cho \(f^*\).&lt;/li&gt;
  &lt;li&gt;Giá trị tối đa của hàm đối ngẫu \(g(u)\) trùng khớp chính xác với giá trị \(f^*\).&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>11-1 Hàm Lagrangian</title>
   <link href="http://localhost:4000/contents/vi/chapter11/11_01_Lagrangian/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter11/11_01_Lagrangian</id>
   <content type="html">&lt;p&gt;Bây giờ chúng ta sẽ xem xét dạng Lagrangian cho bài toán tối ưu sau đây. Ở đây, bài toán tối ưu không nhất thiết phải là lồi.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{alignat}{1}
\min_x &amp;amp; \quad f(x)  \\\
s.t.   &amp;amp; \quad h_i(x) \leq 0, i = 1,\dots,m \\\
       &amp;amp; \quad l_j(x) = 0, j=1,\dots,r
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Hàm Lagrangian được định nghĩa như sau:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
L(x,u,v) = f(x) + \sum_{i=1}^m u_i h_i(x) + \sum_{j=1}^r v_j l_j(x)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(u \in \mathbb{R}^m\), \(v \in \mathbb{R}^r\), \(u \geq 0\) (ngầm định rằng \(L(x,u,v) = - \infty\) khi \(u &amp;lt;0\)).&lt;/p&gt;

&lt;p&gt;Vì trong các ràng buộc ta có \(h_i(x) \leq 0\) và \(l_j(x)=0\),&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
L(x,u,v) =  f(x) + \sum_{i=1}^{m} u_i \underbrace{h_i(x)}_{\leq 0} + \sum_{j=1}^r v_j \underbrace{l_j(x)}_{=0} \leq f(x)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Nói cách khác, hàm Lagrangian có tính chất quan trọng sau:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;Với mọi \(u \geq 0\), \(v\), ta có \(f(x) \geq L(x,u,v) \text{ tại mỗi } x \text{ khả thi}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ví dụ, trong hình dưới đây:&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter11/dual-gen_6.png&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Ví dụ về hàm Lagrangian[1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Đường liền nét biểu thị hàm \(f\).&lt;/li&gt;
  &lt;li&gt;Đường đứt nét biểu thị hàm \(h\). Ở đây, tập khả thi xấp xỉ là \([-0.46,0.46]\).&lt;/li&gt;
  &lt;li&gt;Mỗi đường chấm biểu thị hàm \(L(x,u,v)\) với \(u \geq 0\), \(v\).&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>11 Tính đối ngẫu trong chương trình tổng quát</title>
   <link href="http://localhost:4000/contents/vi/chapter11/11_00_Duality_in_General_Programs/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter11/11_00_Duality_in_General_Programs</id>
   <content type="html">&lt;h3 id=&quot;ôn-tập-tính-đối-ngẫu-trong-quy-hoạch-tuyến-tính&quot;&gt;Ôn tập: Tính đối ngẫu trong quy hoạch tuyến tính&lt;/h3&gt;

&lt;p&gt;Cho \(c \in \mathbb{R}^n\), \(A \in \mathbb{R}^{m \times n}\), \(b \in \mathbb{R}^m\), \(G \in \mathbb{R}^{r \times n}\), \(h \in \mathbb{R}^r\),&lt;/p&gt;

&lt;h4 id=&quot;bài-toán-gốc-primal-lp&quot;&gt;Bài toán gốc (Primal LP):&lt;/h4&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\min_{x} &amp;amp; \quad c^T x   \\\\ 
  s.t.   &amp;amp; \quad Ax = b  \\\\
         &amp;amp; \quad Gx \leq h 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;bài-toán-đối-ngẫu-dual-lp&quot;&gt;Bài toán đối ngẫu (Dual LP):&lt;/h4&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\max_{u,v} &amp;amp; \quad -b^T u - h^T v   \\\\
         s.t. &amp;amp; \quad - A^T u - G^T v = c  \\\\
             &amp;amp; \quad v \geq 0 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;giải-thích-1&quot;&gt;Giải thích 1:&lt;/h3&gt;

&lt;p&gt;Với mọi \(u\) và \(v \geq 0\), và với bất kỳ \(x\) khả thi của bài toán gốc nào, ta có:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
u^T (Ax-b) + v^T(Gx-h) \leq 0
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Tức là,&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
(-A^Tu - G^Tv)^T x \geq -b^Tu - h^T v
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Từ mối quan hệ này, nếu \(c=-A^Tu - G^Tv\), ta thu được một cận dưới cho giá trị tối ưu của bài toán gốc.&lt;/p&gt;

&lt;h3 id=&quot;giải-thích-2&quot;&gt;Giải thích 2:&lt;/h3&gt;

&lt;p&gt;Với mọi \(u\) và \(v \geq 0\), và với bất kỳ \(x\) khả thi của bài toán gốc nào,&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
c^T x \geq c^T x + u^T (Ax-b) + v^T (Gx -h) := L(x,u,v)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Do đó, nếu \(C\) là tập khả thi của bài toán gốc và \(f^*\) là giá trị tối ưu của bài toán gốc, thì&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
f^* \geq \min_{x \in C} L(x,u,v) \geq \min_x L(x,u,v) := g(u,v)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Nói cách khác, \(g(u,v)\) là một cận dưới của \(f^*\).&lt;/p&gt;

&lt;blockquote&gt;

\[g(u,v) =
\begin{cases}
-b^T u - h^T v &amp;amp; \text{nếu $c=-A^Tu - G^T v$} \\\\
-\infty            &amp;amp; \text{trường hợp khác} 
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Giải thích thứ hai cho ra cùng một bài toán đối ngẫu như giải thích thứ nhất, nhưng nó hoàn toàn tổng quát và áp dụng được cho các bài toán tối ưu bất kỳ (bao gồm cả những bài toán không lồi).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19-07 Projected Newton method</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_07_Projected_Newton_method/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_07_Projected_Newton_method</id>
   <content type="html">&lt;h2 id=&quot;whats-wrong-with-projected-newton&quot;&gt;What’s wrong with projected Newton?&lt;/h2&gt;
&lt;p&gt;When \(h\) is the indicator function \(h = I_c(x)\) of convex set \(C\), the problem can be defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x} \ g(x) \quad  \text{subject to}  \quad  x \in C\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, if \(h(x) = I_c(x)\), then proximal gradient descent becomes &lt;strong&gt;projected gradient descent&lt;/strong&gt;. That is, projected gradient descent is a special case of proximal gradient descent.&lt;/p&gt;

&lt;p&gt;What about the case of proximal Newton when \(h(x) = I_c(x)\)? In this case, the update equation is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
z^{+} &amp;amp; =\underset{z \in C}{\text{argmin}} \ \frac{1}{2} \parallel x - H^{-1} \nabla g(x) - z \parallel_H^2  \\\\
&amp;amp;= \underset{z \in C}{\text{argmin}} \ \nabla g(x)^T (z - x) + \frac{1}{2} (z - x)^T H (z - x)  \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If \(H = I\), then this becomes the result of projecting \(x - \nabla g(x)\) onto set \(C\), but for general \(H \neq I\), it is not a projection. (If \(H = I\), it would be the \(l_2\)-norm, so if it were the \(l_2\)-norm instead of the H-norm, it would be a projection.) 
Therefore, the projected Newton method is not a special case of the proximal Newton method.&lt;/p&gt;

&lt;h2 id=&quot;projected-newton-for-box-constraints&quot;&gt;Projected Newton for box constraints&lt;/h2&gt;
&lt;p&gt;For the special case of problems with box constraints, projected Newton can be applied. (Bertsekas, 1982; Kim et al., 2010; Schmidt et al., 2011).&lt;/p&gt;

&lt;p&gt;Let the problem be as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x} \ g(x) \quad  \text{subject to}  \quad  l \le x \le u\]
&lt;/blockquote&gt;

&lt;p&gt;Starting with the initial point \(x^{(0)}\) of the Projected Newton method and a small constant \(\epsilon \gt 0\), we iterate the following steps (\(k = 1, 2, 3, ...\)).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step1: Binding set을 정의한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
B_{k-1} &amp;amp; = \{ i : x_i^{(k-1)} \le l_i + \epsilon \quad \text{and} \quad  \nabla_i g(x^{(k-1)}) \gt 0 \} \quad  \cup \quad 
\{ i : x_i^{(k-1)} \ge u_i - \epsilon  \quad \text{and} \quad  \nabla_i g(x^{(k-1)}) \lt 0 \} 
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;optimization stepat, 이 variable들을 box constraint의 경계to, 밀어낸다. 이들을 점점 더 많이 밀어낼수록 목적 function는 줄어든다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step2: Free set \(F_{k-1} = \left\{1,....,n \right\} \backslash B_{k-1}\)을 정의한다.&lt;/li&gt;
  &lt;li&gt;step3: Free variable을 therefore, Hessian의 주요 submatrix의 inverse를 정의한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[S^{(k-1)} = [(\nabla^2 g(x^{(k-1)}))_{F_{k-1}}]^{-1}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;step4: Fee variable을 따라 Newton step을 실행하고 projection을 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\begin{align}
x_{(k)} = P_{[l, u]} \left( x^{(k-1)} - t_k \begin{bmatrix} S^{(k-1)} &amp;amp; 0 \\
0 &amp;amp; I \end{bmatrix} 
\begin{bmatrix} \nabla F_{k-1} g(x^{(k-1)}) \\ \nabla B_{k-1} g(x^{(k-1)}) \end{bmatrix}
\right)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(P_{[l,u]}\)는 \([l, u] = [l_1, u_1] \times \cdots [l_n, u_n]\)to,의 projection이다.&lt;/p&gt;

&lt;p&gt;matrix식을 보면 free variableabout,서는 Newton step을 실행but, binding variable의 case, 변하지 않는 것을 알 수 있다. also,, projection은 box 범위 밖to, 있는 점들about,서 각 coordinateabout, 적절한 \(l_i\) or, \(u_i\)를 지정solution주는 간단한 작업이다.&lt;/p&gt;

&lt;p&gt;이 method은 problem가 매우 크고 (ex, difference원이 큰 case,) 대부분의 variable이 boundary 근처to, 있어서 free set이 매우 작을 when, optimization를 하는 method이다.&lt;/p&gt;

&lt;p&gt;어떤 종류의 problem가 box constraint를 갖는가? as follows: 이런 종류의 problem는 매우 많은 것with, informing,져 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nonnegative least squares&lt;/li&gt;
  &lt;li&gt;Support vector machine dual&lt;/li&gt;
  &lt;li&gt;Graphical lasso dual&lt;/li&gt;
  &lt;li&gt;Fused lasso (total variation denoising) dual&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;convergence-properties&quot;&gt;Convergence properties&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Bertsekas (1982)는 적절한 가정하to, projected Newtonwith, 유한번 iteration을 하면 적절한 binding constraints를 찾을 수 있다는 것을 보였다. 그러면, free variableabout, Newton’s methodand, 같아진다.&lt;/li&gt;
  &lt;li&gt;Bertsekas (1982)는 also,  superlinear convergence를 증명하였다.&lt;/li&gt;
  &lt;li&gt;Kim et al. (2010), Schmidt et al. (2011)은 BFGS-style update를 사용한 projected quasi-Newton method를 제안했다.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>19-06 Proximal quasi-Newton methods</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_06_Proximal_quasi_Newton_methods/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_06_Proximal_quasi_Newton_methods</id>
   <content type="html">&lt;p&gt;problem가 커질수록 Hessian의 computation 비용이 매우 높아진다. &lt;strong&gt;Proximal quasi-Newton method&lt;/strong&gt;는 각 stepat, Hessian \(H^{(k-1)} = \nabla^2 g(x^{(k-1)})\)를 computation하지 않는 방식with, superlinear or, linear convergence의 convergence 속도를 제공한다.&lt;/p&gt;

&lt;h2 id=&quot;proximal-quasi-newton-method&quot;&gt;Proximal quasi-Newton method&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Lee (2014)는 Hessian을  BFGS-styleto, update하는 방식을 제안했다. 이 method은 매우 잘 실행되며 local superlinear convergence의 convergence 속도를 갖는다.&lt;/li&gt;
  &lt;li&gt;Tseng and Yun (2009)은  Hessian을 blockwiseto, approximation하는 방식을 제안했다. 이 method은 \(f = g + h\)at, \(h\)가 일부 optimization variableto, 의존하는 부분with, 나뉠 수 있을 when,만 작동한다. Hessian을 blockwiseto, computation하면 computation이 매우 빨라진다. 이 method은 linear convergence의 convergence 속도를 갖는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quasi-Newton은 Hessian computation이 힘들when, 뿐 아니라 Hessian이 singular이거나 near singular인 ill-conditionat,도 유용하다.&lt;/p&gt;

&lt;h3 id=&quot;reference-논문&quot;&gt;reference 논문&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;J. Lee and Y. Sun and M. Saunders (2014), “Proximal Newton-type methods for minimizing composite functions”&lt;/li&gt;
  &lt;li&gt;P. Tseng and S. Yun (2009), “A coordinate gradient descent method for nonsmooth separable minimization”&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>19-05 Notable examples</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_05_Notable_examples/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_05_Notable_examples</id>
   <content type="html">&lt;h2 id=&quot;glmnet-and-quic&quot;&gt;Glmnet and QUIC&lt;/h2&gt;
&lt;p&gt;Proximal newton method의 매우 유명한 패키지가 두 가지가 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;glmnet&lt;/strong&gt; (Friedman et al., 2009): \(l_1\) penalized generalized linear modelsto, about, prox Newton를 구현한 패키지. Coordinate descent를 using,서 inner problem을 푼다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;QUIC&lt;/strong&gt;  (Hsiesh et al., 2011): graphical lasso problemto, about, prox Newton을 구현한 패키지. Factorization trick을 사용하고 coordinate descent를 using,서 inner problem을 푼다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;두 구현 패키지는 각자의 용도to, 맞춰서 매우 광범위하게 사용되고 있으며 state-of-the-art라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;Proximal Newton method는  proximal gradient보다 \(g\)의 gradient을 덜 자주 computation한다. therefore,, computation 비용이 커질수록 proximal newton이 유리하다. also,, inner solver를 신중하게 선택할수록 좋은 성능을 얻을 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;example-lasso-logistic-regression&quot;&gt;Example: lasso logistic regression&lt;/h2&gt;
&lt;p&gt;Lee et al. (2012)논문at, 제시된 예제를 let’s look at.&lt;/p&gt;

&lt;p&gt;\(l_1\) regularized logistic regressionto,대solution 다음 세가지 methodabout,서 성능을 평가하였다.
1.FISTA : accelerated prox grad 2. spaRSA : spectral projected gradient method 3. PN  : proximal Newton&lt;/p&gt;

&lt;h3 id=&quot;dense-hessian-x-n5000-p6000-예시&quot;&gt;Dense hessian X (n=5000, p=6000) 예시&lt;/h3&gt;
&lt;p&gt;데이터 수 n = 5000, feature 개수 p = 6000인 dense feature matrix \(X\)를 갖는 problemabout, 다음and, 같은 성능을 보였다. Hessian이 dense하기 because of, 매우 challenging한 problem라고 할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter19/09.05_Lasso_Example1.png&quot; alt=&quot;[Fig 1] Dense hessian X (n=5000, p=6000) [2]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Dense hessian X (n=5000, p=6000) [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;오른쪽은 function 호출 기준with,, 왼쪽은 시간 기준with, 평가한 것with,서, function 호출 기준with, 봤을 when,가 PN의 성능이 매우 우세함을 알 수 있다.&lt;/p&gt;

&lt;p&gt;여기서 비용은 \(g\)and, \(\nabla g\)를 computation하는 시간이 대부분이며 particularly, \(\exp\)and, \(\log\)function를 computation하는 시간이 많이 들었다.&lt;/p&gt;

&lt;h3 id=&quot;sparse-hessian-x-n542000-p47000-예시&quot;&gt;Sparse hessian X (n=542,000, p=47,000) 예시&lt;/h3&gt;

&lt;p&gt;다음의 case,는 \(X\)가 sparse하기 because of, \(g\)and, \(\nabla g\)를 computation하는 시간이 덜 들었다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter19/09.05_Lasso_Example-sparse.png&quot; alt=&quot;[Fig 2] Sparse hessian X (n=542,000, p=47,000) [2]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] Sparse hessian X (n=542,000, p=47,000) [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;inexact-prox-evaluations&quot;&gt;Inexact prox evaluations&lt;/h2&gt;
&lt;p&gt;Proximal Newton methodat, proximal operation을 computation할 when,  prox operator가 closed form이 아니기 because of, 정확히 computation하지 못한다. 그럼to,도 불구하고, 매우 높은 정확도를 갖는다면 매우 좋은 성질이 될 수 있다.&lt;/p&gt;

&lt;p&gt;Lee (2014)at,는 global convergenceand,  local superlinear convergence를 보장하는 inner problem의 stopping rule을 제안했다.&lt;/p&gt;

&lt;h3 id=&quot;three-stopping-rules&quot;&gt;Three stopping rules&lt;/h3&gt;
&lt;p&gt;Graphical lasso estimation problemto, inner optimizations을 위한 세 가지 stopping rules을 비교하였다. 이when,, 데이터 개수는 n = 72이고 feature 개수는 p = 1255이다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter19/09.05_Inexact_prox.png&quot; alt=&quot;[Fig 3] Three stopping rules [2]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 3] Three stopping rules [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;세 가지 stopping rule은 adaptive, maxiter = 10, exact이다. Maxiter는 inner iteration을 최대 10번to,만 하는 방식이고 exact는 정확한 solution를 구할 when,to, iteration하는 방식이다.&lt;/p&gt;

&lt;p&gt;Proximal newton method가 quadratic convergence를 만족하므to, exact는  quadratic convergence를 만족한다고 볼 수 있다. Maxiter=10의 case, 최대 10번의 inner iterationwith,는 quadratic convergence를 만족하지 못but, adaptive의 case, quadratic convergence를 만족하며 세 가지 방식 중 가장 빠르다.&lt;/p&gt;

&lt;h3 id=&quot;stopping-rule-of-usual-newton-method&quot;&gt;Stopping rule of usual newton method&lt;/h3&gt;
&lt;p&gt;일반적인 newton’s methodat,는 inner problem은 \(x^{(k-1)}\)의 \(g\)to, about, quadratic approximation인 \(\tilde{g}_{k-1}\)를 minimization한다. and,, \(\eta_k, k=1,2,3,...\)를 choosing,서 다음 condition,을 만족할 when, 중지한다. (이를 forcing sequence라고 한다.)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\parallel \nabla \tilde{g}_{k-1}(x^{(k)}) \parallel_2 &amp;amp; \le \eta_k \parallel  \nabla g(x^{(k-1)})  \parallel_2 \&lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 condition,은 다음 positionat,의 gradient가 현재 positionat,의 gradient보다 \(\eta_k\)배 만큼 작다는 것을 의미한다. 이when,, Quadratic approximation은 \(\tilde{g}_{k-1}(z) = \nabla g(x)^T (z-x) + \frac{1}{2t} \parallel  z - x \parallel_2^2\)이다.&lt;/p&gt;

&lt;h3 id=&quot;stopping-rule-of-proximal-gradient-method&quot;&gt;Stopping rule of proximal gradient method&lt;/h3&gt;
&lt;p&gt;Lee et al. (2012)at,는 proximal gradientat,는 gradient instead, generalized gradient를 사용하는 방식을 제안하였다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\parallel G_{\tilde{f}_{k-1}/M}(x^{(k)}) \parallel_2 &amp;amp; \le \eta_k \parallel  G_{f/M}(x^{(k-1)})  \parallel_2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\tilde{f}_{k-1} = \tilde{g}_{k-1} + h\)이고 \(mI \preceq \nabla^2 g \preceq MI\)이다.&lt;/p&gt;

&lt;p&gt;and,, as follows: \(\eta_k\)를 설정하여 inexact proximal newton이 local superlinear rate를 갖는다는 것을 증명하였다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\eta_k \le \min \left\{ \frac{m}{2},  \frac{\parallel  G_{\tilde{f}_{k-2}/M}(x^{(k-1)}) - G_{f/M}(x^{(k-1)})  \parallel_2}{\parallel  G_{f/M}(x^{(k-2)})  \parallel_2} \right\}
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>19-04 Convergence analysis</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_04_Convergence_analysis/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_04_Convergence_analysis</id>
   <content type="html">&lt;p&gt;To analyze the convergence of the Proximal Newton method, we will follow the proof from Lee (2014) [1].&lt;/p&gt;

&lt;p&gt;[1] J. Lee and Y. Sun and M. Saunders (2014), Proximal Newton-type methods for minimizing&lt;/p&gt;

&lt;p&gt;To prove convergence, we make the following assumptions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(f = g + h\), \(g\) and \(h\) are convex and \(g\) is twice differentiable (smooth)&lt;/li&gt;
  &lt;li&gt;\(mI \preceq \nabla^2 g(x) \preceq LI\).&lt;/li&gt;
  &lt;li&gt;\(\nabla^2 g(x)\) is Lipschitz with constant \(M\)&lt;/li&gt;
  &lt;li&gt;\(\text{prox}_H(\cdot)\) can be computed exactly&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The above three assumptions imply that the function is strictly convex, and assuming that \(\text{prox}_H(\cdot)\) can be computed exactly is because this is not easy to achieve in practice.&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Proximal Newton method&lt;/strong&gt; converges globally using backtracking line search.
\begin{align}
\parallel x^{(k)} - x^{\star} \parallel_2 \le \frac{M}{2m} \parallel x^{(k-1)} - x^{\star} \parallel_2^2
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is called &lt;strong&gt;local quadratic convergence&lt;/strong&gt;. After \(k \ge k_0\), to satisfy \(f(x^{(k)}) - f^{\star} \le \epsilon\), \(O(\log \log (1/\epsilon))\) iterations are needed. However, each iteration uses a scaled prox.&lt;/p&gt;

&lt;h2 id=&quot;proof-sketch&quot;&gt;Proof sketch&lt;/h2&gt;
&lt;p&gt;To show &lt;strong&gt;global convergence&lt;/strong&gt;, we can show that at any step, the backtracking exit condition for step size \(t\) is satisfied as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
t \le \min \left\{ 1, \frac{2m}{L} (1-\alpha) \right\} \&lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;With this equation, we can show that when the global minimum is reached, the update direction converges to 0.&lt;/p&gt;

&lt;p&gt;To show &lt;strong&gt;local quadratic convergence&lt;/strong&gt;, after sufficiently many iterations, the pure Newton step \(t=1\) satisfies the backtracking exit conditions, and the following equation holds.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\parallel x^{+} - x^{\star} \parallel_2 &amp;amp; \le \frac{1}{\sqrt(m)} \parallel x^{+} - x^{\star} \parallel_H \\\\
&amp;amp; =  \frac{1}{\sqrt(m)} \parallel \text{prox}_H(x - H^{-1} \nabla g(x) )  - \text{prox}_H(x^{\star} - H^{-1} \nabla g(x^{\star}) )  \parallel_H \\\\
&amp;amp; \le \frac{M}{2m} \parallel x - x^{\star} \parallel_2^2 \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Summarizing this, we get the following:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\parallel x^{+} - x^{\star} \parallel_2 \ \le \ \frac{1}{\sqrt(m)} \parallel x^{+} - x^{\star} \parallel_H \  \le \ \frac{M}{2m} \parallel x - x^{\star} \parallel_2^2
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The first inequality holds due to the lowest eigenvalue bound, and the equality holds by the fact that \(\text{prox}_H(\cdot)\) becomes the identity at the definition of \(x^+\) and global minimum \(x^{\star}\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The second inequality holds due to the nonexpansiveness of the proximal operator, the Lipschitz assumption, and the largest eigenvalue bound.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>19-03 When would we use proximal Newton?</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_03_When_would_we_use_proximal_Newton/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_03_When_would_we_use_proximal_Newton</id>
   <content type="html">&lt;p&gt;When should we use the proximal newton method?&lt;/p&gt;

&lt;p&gt;To understand the usefulness of the proximal newton method, let’s compare the proximal newton method and proximal gradient descent on the following problem.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt; : \(\min_x g(x) + h(x)\)&lt;/p&gt;

&lt;h2 id=&quot;proximal-gradient-descent-vs-proximal-newton&quot;&gt;Proximal gradient descent vs. proximal newton&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Proximal Newton&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;\(\frac{1}{2} \parallel b - x \parallel_2^2 + h(x)\) minimization&lt;/td&gt;
      &lt;td&gt;\(b^T x + x^T A x + h(x)\) minimization&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Prox operator가 대부분 closed formwith, 정의됨&lt;/td&gt;
      &lt;td&gt;Prox operator가 대부분 closed formwith, 정의되지 않음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;iteration이 저렴&lt;/td&gt;
      &lt;td&gt;iteration이 아주 비쌈 (newton method보다 비쌈)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Gradient descent convergence 속도 &lt;br /&gt; \(O(1/\epsilon)\)&lt;/td&gt;
      &lt;td&gt;Newton’s method convergence 속도 &lt;br /&gt; \(O(\log \log 1/\epsilon)\)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;두 method은 비슷solution 보이지만 실제 매우 다른 일을 한다.&lt;/p&gt;

&lt;p&gt;therefore,, proximal newton method는 아주 적은 iteration을 기대할 수 있는 scaled prox operator(quadratic + \(h\))to, about, 빠른 inner optimizer를 가질 when, 사용할 수 있다. \(h\)가 separable function일 when, inner optimizerto, 가장 많이 사용되는 method이 coordinate descent이다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19-02 Backtracking line search</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_02_Backtracking_line_search/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_02_Backtracking_line_search</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Proximal newton method&lt;/strong&gt; may not converge in cases with pure step size \(t_k=1, k=1,2,3, \cdots\) like newton’s method. Therefore, we need to optimize the step size through backtracking line search.&lt;/p&gt;

&lt;h2 id=&quot;backtracking-line-search-algorithm&quot;&gt;Backtracking line search algorithm&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize parameters. (\(0 \lt \alpha \le 1/2, 0 \lt \beta \lt 1\))&lt;/li&gt;
  &lt;li&gt;At each iteration, compute the Proximal newton direction as \(v = \text{prox}_{H} ( x - H^{-1} \nabla g (x) ) - x\).&lt;/li&gt;
  &lt;li&gt;Initialize \(t=1\).&lt;/li&gt;
  &lt;li&gt;If the condition \(f(x + tv) \gt f(x) + \alpha t \nabla g(x)^T v + \alpha (h(x + tv) - h(x))\) is satisfied, reduce \(t=\beta t\). Iterate step 4 while this condition is satisfied. (\(f = g + h\))&lt;/li&gt;
  &lt;li&gt;Execute the Proximal newton update \(x^+ = x + tv\).&lt;/li&gt;
  &lt;li&gt;If the termination condition is not satisfied, go to step 2.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Intuitively, we find a step size \(t\) such that we move along direction \(v\) to a position where the linear approximation of function \(f\) at \(x\) is reduced by a factor of \(\alpha\). Since the \(h\) part of \(f\) is not differentiable, we use the discrete derivative \(h(x + tv) - h(x)\).&lt;/p&gt;

&lt;h2 id=&quot;efficiency-of-algorithm&quot;&gt;Efficiency of algorithm&lt;/h2&gt;
&lt;p&gt;There are many methods for performing backtracking line search, and here we have introduced one of them.&lt;/p&gt;

&lt;p&gt;In this method, when computing \(v\), the prox operator is computed only once. In the case of proximal gradient descent, the prox operator had to be computed iteratively in the inner loop, which is a distinctly different characteristic. Therefore, this method can perform backtracking line search very efficiently when the computation of the prox operator is complex.&lt;/p&gt;

&lt;h3 id=&quot;reference-method-별--backtracking-line-search&quot;&gt;[reference] Method 별  backtracking line search&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Gradient descent &lt;a href=&quot;/contents/en/chapter06/06_02_02_backtracking_line_search/&quot;&gt;06-02-02 Backtracking line search&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Proximal gradient descent &lt;a href=&quot;/contents/en/chapter09/09_02_convergence_analysis/&quot;&gt;09-02 Convergence analysis&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Newton’s method &lt;a href=&quot;/contents/en/chapter14/14_04_backtracking_line_search/&quot;&gt;14-04 Backtracking line search&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>19-01-03 Scaled proximal map</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_01_03_Scaled_proximal_map/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_01_03_Scaled_proximal_map</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Proximal newton method&lt;/strong&gt;를 &lt;strong&gt;proximal gradient descent&lt;/strong&gt;and, 같은 형식with, 다시 작성solution 볼 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;scaled-proximal-map&quot;&gt;Scaled proximal map&lt;/h2&gt;
&lt;p&gt;if, \(H \succ 0\)라고 하면 &lt;strong&gt;scaled proximal map&lt;/strong&gt;은 as follows: 정의된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\text{prox}_{t}(x) = \underset{z}{\text{argmin}}  \frac{1}{2} \parallel x - z \parallel_H^2 + h(z)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\parallel x\parallel_H^2 = x^THx\)with, \(H\text{-norm}\)이다.  \(H = \frac{1}{t} I\)일 when, 일반적인 &lt;strong&gt;unscaled proximal map&lt;/strong&gt;이 된다.&lt;/p&gt;

&lt;p&gt;generally, &lt;strong&gt;scaled proximal map&lt;/strong&gt;는 usually,의 prox보다 좋은 성질을 갖고 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;uniqueness&lt;/strong&gt; : solution가 하나만 존재하는 성질 (\(H \succ 0\)이므to, strictly convex optimization problem이기 because of, 만족된다.)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;non-expansiveness&lt;/strong&gt; :  팽창하지 않는 성질 (scaled proximal map이 non-expansive 성질을 갖는 projection operator의 일반화이기 because of, 만족된다.)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reference-projection-operator의-non-expansiveness&quot;&gt;[reference] Projection operator의 non-expansiveness&lt;/h3&gt;
&lt;p&gt;두 점 \(x\), \(y\)and, convex set \(C\)to, about, projection operator \(P_c\)about, non-expansiveness란 \(\parallel P_c(x) - P_c(y) \parallel_2 \le \parallel x - y \parallel_2\)를 만족한다는 것을 의미한다. that is,,  \(P_c\)는 Lipschitz-1을 만족하며 \(C\)가 convex일 case,to,만 만족한다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter19/09.01_03_projection_operator.png&quot; alt=&quot;[Fig 1] Projection onto a convex set C [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Projection onto a convex set C [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;proximal-newton-update&quot;&gt;Proximal newton update&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Scaled proximal map&lt;/strong&gt;을 using,서 Proximal newton update를 다시 expressing,보면 as follows:.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
z^{+} &amp;amp; = \underset{z}{\text{argmin}} \nabla g(x)^T (z - x)^T v + \frac{1}{2} (z - x)^T H (z - x) + h(z) \\\\
&amp;amp; =\underset{z}{\text{argmin}} \ \frac{1}{2} \parallel x - H^{-1} \nabla g(x) - z \parallel_H^2 + h(z)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;다르게 표현하면 as follows:.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
z^{(k)} &amp;amp; = \text{prox}_{H^{(k-1)}} ( x^{(k-1)} - (H^{(k-1)})^{-1} \nabla g (x^{(k-1)}) ) \\\\
x^{(k)} &amp;amp; =x^{(k-1)} + t_k (z^{(k)} - x^{(k-1)} )
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;직관적with, \(g\)about,서 newton step을 수행하고, \(H^{(k-1)}\)about, scaled prox operator를 applying,서 그 directionwith, 이동한다는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;이from, 다음and, 같은 사항을 알 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(h(z) = 0\)일when, proximal operator는 identity function가 되여 일반적인 Newton update가 된다.&lt;/li&gt;
  &lt;li&gt;\(H^{(k+1)}\)를 \(\frac{1}{r_k} I\)to, 대체하고 \(t_k = 1\)to, 두면 step size \(r_k\)about, proximal gradient update를 구할 수 있다.&lt;/li&gt;
  &lt;li&gt;Prox의 어려움은 \(h\)뿐만 아니라 \(g\)의 hessian의 구조according to, 달라진다. for example, \(H\)가 diagonal이거나 banded이면 dense한 \(H\)일 case,to, 비solution problem가 매우 쉬워진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;therefore,,  proximal Newton method는 proximal gradient descentand, Newton’s method를 둘 다 일반화한 것임을 알 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19-01-02 Proximal Newton method</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_01_02_Proximal_Newton_method/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_01_02_Proximal_Newton_method</id>
   <content type="html">&lt;p&gt;In the previous section, we explained that the &lt;strong&gt;proximal newton method&lt;/strong&gt; is a method that wants to use the local hessian \(\nabla^2 g(x)\) instead of the spherical curvature \(\frac{1}{t} I\) in the &lt;strong&gt;proximal gradient descent&lt;/strong&gt; formula. The proximal newton method is an old idea that is being studied in statistics under the term local score.&lt;/p&gt;

&lt;p&gt;Now let’s look at how the &lt;strong&gt;proximal newton method&lt;/strong&gt; can be formulated.&lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;
&lt;p&gt;The Proximal gradient descent algorithm consists of the process of finding the direction \(v\) of the next step and then optimizing the step size \(t_k\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Step 1: Starting from the starting point \(x^{(0)}\), iterate the following process. (\(k=1,2,3,...\))&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Step 2: Find the direction \(v\) of the next step.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
v^{(k)} &amp;amp; = \underset{v}{\text{argmin}} \ \nabla g(x^{(k-1)})^T v + \frac{1}{2} v^T H^{(k-1)} v + h(x^{(k-1)} + v)
\end{align}
여기서 \(H^{(k-1)} = \nabla^2 g(x^{(k-1)})\)은 \(x^{(k-1)}\)at,의 Hessian이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;3step : \(v^{(k)}\) directionwith, step을 이동하기 for, step size를 optimization한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{(k)} &amp;amp; =x^{(k-1)} + t_k v^{(k)}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;\(t_k\)는 step sizeto, \(t_k=1\)이면 pure proximal Newton method이다.&lt;/p&gt;

&lt;p&gt;Backtracking line search를 through, step size를 optimization하는 process이 있다는 점은 proximal gradient descent methodand, 다른 점이다.&lt;/p&gt;

&lt;h3 id=&quot;next-position-view&quot;&gt;Next position view&lt;/h3&gt;
&lt;p&gt;위의 식을 direction \(v\)이 아닌 다음 position인 \(z\)의 관점at, 표현하면 as follows:.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
z^{(k)} &amp;amp; = \underset{z}{\text{argmin}} \ \nabla g(x^{(k-1)})^T (z - x^{(k-1)})^T + \frac{1}{2} (z - x^{(k-1)})^T H^{(k-1)} (z - x^{(k-1)}) + h(z) \\\\
x^{(k)} &amp;amp; =x^{(k-1)} + t_k (z^{(k)} - x^{(k-1)} )
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;직관적with, 첫번째 stepat, 목적 function를 minimization 하는 surrogate point인 \(z\)를 구한다. 그런 다음, \(x^{(k-1)}\)at, \(z\)의 directionwith, 이동but, always, \(z\)to, 이동하게 되는 것은 아니다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19-01-01 Reminder - proximal gradient descent</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_01_01_Reminder-_proximal_gradient_descent/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_01_01_Reminder:_proximal_gradient_descent</id>
   <content type="html">&lt;p&gt;Before examining the &lt;strong&gt;Proximal newton method&lt;/strong&gt; that we will learn in this chapter, let’s first review &lt;strong&gt;Proximal gradient descent&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For detailed information, see &lt;a href=&quot;/contents/en/chapter09/09_proximal_gradient_descent_and_acceleration/&quot;&gt;09 Proximal Gradient Descent and Acceleration&lt;/a&gt; see.&lt;/p&gt;

&lt;h2 id=&quot;proximal-gradient-descent&quot;&gt;Proximal gradient descent&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt; works on the following problem.&lt;/p&gt;

&lt;blockquote&gt;
\[f(x) = g(x) + h(x)\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;\(g\) is convex and differentiable. (&lt;strong&gt;dom&lt;/strong&gt;\((g) = \mathbb{R}^n\))&lt;/li&gt;
  &lt;li&gt;\(h\) is convex and non-differentiable and “simple”.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h3&gt;
&lt;p&gt;Proximal gradient descent는 시작점 \(x^{(0)}\)at, 시작solution서 다음 process을 iteration한다.&lt;/p&gt;

&lt;blockquote&gt;
\[x^{(k)} = \text{prox}_{t_k}(x^{(k-1)} - t_k \nabla g(x^{(k-1)}) ),k=1,2,3,...\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 \(\text{prox}_{t}(\cdot)\)는 \(h\)and, association,된 proximal operator 이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\text{prox}_{t}(x) = \underset{z}{\text{argmin}}  \frac{1}{2t} \parallel x - z \parallel_2^2 + h(z)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Update 식은 generalized gradient \(G_{t}\)를 using,서 표준화된 형태to, 표현할 수도 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{(k)} = x^{(k-1)} - t_k \cdot G_{t_k}(x^{(k-1)}), \space \space \text{where} \space G_{t}(x) = \frac{x-\text{prox}_{t} (x - t \nabla g(x))}{t} \&lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;performance&quot;&gt;Performance&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt;의 성능은 \(h\)according to, 달라질 수 있다. if,, \(h\)가 복잡한 function이고 particularly, closed form이 아니라면 minimize할 when, computation을 많이 solution야 하므to, 성능이 매우 떨어질 수 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;also,, \(g\)function의 convergence rateand, 같은 convergence 속도를 갖는다. 단, iteration할 when,마다 prox operator를 실행하기 because of, prox computation이 효율적인 case,to,만 유용하다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt;at,는 미분 가능한 function \(g\)를 Taylor 2difference식with, approximation하고 여기to, 미분이 되지 않는 function인 \(h\)를 더하여 목적 functionto, 정의한 후 이를 iteration적with, minimization한다. therefore,, as follows: 2difference 식with, 정리solution 볼 수 있다.&lt;/p&gt;

&lt;p&gt;식to, 전개되는 자세한 process은 &lt;a href=&quot;/contents/en/chapter09/09_01_proximal_gradient_descent/&quot;&gt;09-01 Proximal gradient descent&lt;/a&gt; reference.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x^+ &amp;amp; = \underset{z}{\text{argmin}}  \, \frac{1}{2t} \parallel x - t \nabla g(x) - z \parallel_2 ^2 + h(z) \\\\
&amp;amp; = \underset{z}{\text{argmin}} \ \nabla g(x)^T (z - x) + \frac{1}{2t} \parallel z - x \parallel_2 ^2 + h(z) \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;두번째 식의 1항and, 2항은 \(g\)의 Taylor 2difference approximation식with, from, 유도할 수 있는데, first, constant항 \(g(x)\)은 제거하고 (gradient descentat,and, 마찬가지to,) Hessian \(\nabla^2 g(x)\)을 \(\frac{1}{t} I\)(spherical curvature)to, 대체solution서 구할 수 있다.&lt;/p&gt;

&lt;p&gt;다음 그림at,는 proximal gradient descent의 update stepat, \(g\)를 2difference approximation식with, minimization 하는 process을 showing,주고 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter19/09.01_01_proximal_gradient_descent.png&quot; alt=&quot;[Fig 1] Proximal gradient descent updates [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Proximal gradient descent updates [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Gradient descentand, newton’s method의 difference이점는 2difference approximation를 할 when, function의 local hessian인 \(\nabla^2 g(x)\)를 사용하는지 여부이다. 그렇다면, 위의 식at, \(\frac{1}{t} I\) instead, \(\nabla^2 g(x)\)를 사용하면 어떻게 될까?&lt;/p&gt;

&lt;p&gt;이것이 바to, 다음 절at, 설명하게 될 &lt;strong&gt;proximal newton method&lt;/strong&gt;가 나오게 된 background,이다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19-01 Proximal Newton method</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_01_00_Proximal_Newton_method/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_01_00_Proximal_Newton_method</id>
   <content type="html">&lt;p&gt;In this section, we will review the &lt;strong&gt;proximal gradient method&lt;/strong&gt; and examine how the &lt;strong&gt;proximal newton method&lt;/strong&gt; emerged from it.&lt;/p&gt;

&lt;p&gt;We will also examine the definition of the &lt;strong&gt;proximal newton method&lt;/strong&gt; and the scaled proximal map that has good properties such as uniqueness and non-expansiveness compared to the general proximal map.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>19 Proximal Newton Method</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_00_Proximal_Newton_Method/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter19/19_00_Proximal_Newton_Method</id>
   <content type="html">&lt;p&gt;In this chapter, we will examine &lt;strong&gt;Proximal Newton Method&lt;/strong&gt;, &lt;strong&gt;Proximal quasi-Newton method&lt;/strong&gt;, and &lt;strong&gt;Projected Newton method&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;reference-papers&quot;&gt;Reference Papers&lt;/h3&gt;

&lt;p&gt;Proximal Newton method:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;J. Friedman and T. Hastie and R. Tibshirani (2009), “Regularization paths for generalized linear models via coordinate descent”&lt;/li&gt;
  &lt;li&gt;C.J. Hsiesh and M.A. Sustik and I. Dhillon and P. Ravikumar (2011), “Sparse inverse covariance matrix estimation using quadratic approximation”&lt;/li&gt;
  &lt;li&gt;M. Patriksson (1998), “Cost approximation: a unified framework of descent algorithms for nonlinear programs”&lt;/li&gt;
  &lt;li&gt;J. Lee and Y. Sun and M. Saunders (2014), “Proximal Newton-type methods for minimizing composite functions”&lt;/li&gt;
  &lt;li&gt;P. Tseng and S. Yun (2009), “A coordinate gradient descent method for nonsmooth separable minimization”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Projected Newton method:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A. Barbero and S. Sra (2011), “Fast Newton-type methods for total variation regularization”&lt;/li&gt;
  &lt;li&gt;D. Bertsekas (1982), “Projected Newton methods for optimization problems with simple constraints”&lt;/li&gt;
  &lt;li&gt;D. Kim and S. Sra. and I. Dhillon (2010), “Tackling box-constrained optimization via a new projected
quasi-Newton approach”&lt;/li&gt;
  &lt;li&gt;M. Schmidt and D. Kim and S. Sra (2011), “Projected Newton-type methods in machine learning”&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>11-5 Duality gap</title>
   <link href="http://localhost:4000/contents/en/chapter11/11_05_Duality_gap/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter11/11_05_Duality_gap</id>
   <content type="html">&lt;p&gt;If the primal problem has value \(f(x)\) at \(x\), and the dual problem has value \(g(u,v)\) at \(u,v\), then the difference \(f(x) - g(u,v)\) is called the duality gap.&lt;/p&gt;

&lt;p&gt;Meanwhile, these feasible values always satisfy the following relation&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
f(x) - f^* \leq f(x) - g(u,v), 
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;If the duality gap is \(0\), then \(x\) is an optimal solution of the primal problem and \(u,v\) are optimal for the dual problem.&lt;/p&gt;

&lt;p&gt;Also, if the duality gap satisfies \(f(x)-g(u,v) \leq \epsilon\), it implies \(f(x) -f^* \leq \epsilon\), so algorithms that solve problems iteratively can use the duality gap as a stopping criterion.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>11-4 Strong duality</title>
   <link href="http://localhost:4000/contents/en/chapter11/11_04_Strong_duality/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter11/11_04_Strong_duality</id>
   <content type="html">&lt;p&gt;When a problem satisfies \(f^* = g^*\), this is called &lt;strong&gt;strong duality&lt;/strong&gt;. The &lt;strong&gt;Slater condition&lt;/strong&gt; is a sufficient condition for strong duality.&lt;/p&gt;

&lt;h2 id=&quot;slater-condition&quot;&gt;Slater condition:&lt;/h2&gt;
&lt;p&gt;If the primal problem is convex and there exists at least one strictly feasible \(x \in \mathbb{R}^n\), then strong duality holds.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
h_1(x)&amp;lt;0,\dots,h_m(x)&amp;lt;0, \text{ and } l_1(x) = 0,\dots,l_r(x) = 0,
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Important refinement: Strict inequality need not be satisfied when the function is affine.&lt;/p&gt;
&lt;h2 id=&quot;example-support-vector-machine-dual&quot;&gt;Example: Support Vector Machine Dual&lt;/h2&gt;
&lt;p&gt;\(y \in \{-1,1\}^n\), \(X \in \mathbb{R}^{n \times p}\) (\(X\)의 열은 \(x_1, ..., x_n\))라고 할 때, SVM(Support Vector Machine) 문제는 다음과 같이 정의된다.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{alignat}{1}
\min_{\beta, \beta_0, \xi} &amp;amp; \quad \frac{1}{2}\parallel\beta\parallel_2^2 + C \sum_{i=1}^n \xi_i   \\\\
                                  s.t. &amp;amp; \quad \xi_i \geq 0, i=1,\dots,n   \\\\
                                       &amp;amp; \quad y_i(x_i^T \beta + \beta_o) \geq 1 - \xi_i, i=1,\dots,n
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Dual 변수, \(v, w \geq 0\)를 사용하여 Lagrangian을 정의해보자.&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{equation}
L(\beta,\beta_0,\xi,v,w) = \frac{1}{2} \parallel\beta\parallel_2^2 + C\sum_{i=1}^n \xi_i - \sum_{i=1}^n v_i \xi_i +  \sum_{i=1}^n w_i (1-\xi_i - y_i(x_i^T\beta + \beta_o))
\end{equation}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;\(\beta, \beta_0, \xi\)에 대해 최소화해서 다음과 같은 Lagrangian dual function을 구할 수 있다.&lt;/p&gt;
&lt;blockquote&gt;

\[g(v,w) = 
\begin{cases}
-\frac{1}{2} w^T\tilde{X}\tilde{X}^T w +  1^Tw, &amp;amp;\text{if $w=C1-v, w^Ty=0$} \\\\
-\infty, &amp;amp;\text{otherwise}
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Here \(\tilde{X}=\text{diag}(y) X\). Therefore, the SVM dual problem (after eliminating the slack variable \(v\)) becomes the following.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\max_{w}  &amp;amp; \quad -\frac{1}{2} w^T\tilde{X}\tilde{X}^T w +  1^Tw \\\\
     s.t. &amp;amp;  \quad 0 \leq w \leq C1, w^Ty = 0
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Since the primal problem satisfies the Slater condition, strong duality holds. (That is, the objective is convex and the inequality constraints are affine in \(\beta, \beta_0, \xi\).)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>11-3 Lagrange dual problem</title>
   <link href="http://localhost:4000/contents/en/chapter11/11_03_Lagrange_dual_problem/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter11/11_03_Lagrange_dual_problem</id>
   <content type="html">&lt;p&gt;Consider the following optimization problem:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\min_x &amp;amp; \quad f(x)  \\
s.t.   &amp;amp; \quad h_i(x) \leq 0, i=1,\dots,m  \\
       &amp;amp; \quad l_j(x) = 0, j=1,\dots,r
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;The dual function \(g(u,v)\) satisfies \(f^* \geq g(u,v)\) for all \(u\geq 0\) and \(v\). Therefore, we can obtain the best lower bound by maximizing \(g(u,v)\) over all feasible \(u\) and \(v\). This is called the Lagrange dual problem.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\max_{u,v} &amp;amp; \quad g(u,v)   \\
           s.t. &amp;amp; \quad u \geq 0
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, if we denote the dual optimal value as \(g^*\), then \(f^* \geq g^*\). This is called weak duality. This property always holds even when the primal problem is not convex. Moreover, the dual problem is always a convex optimization problem, even when the primal problem is not convex.&lt;/p&gt;

&lt;p&gt;By definition, \(g\) is concave with respect to \((u,v)\), and \(u \geq 0\) is a convex constraint. Therefore, the dual problem corresponds to a concave maximization problem.&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{alignat}{1}
 g(u,v) &amp;amp; = \min_x { f(x) + \sum_{i=1}^m u_i h_i(x) + \sum_{j=1}^r v_j l_j(x) }  \ 
        &amp;amp; = - \underbrace{\max_x { -f(x) - \sum_{i=1}^m u_i h_i(x) - \sum_{j=1}^r v_j l_j(x) }}_{\text{pointwise maximum of convex functions in $(u,v)$}}
\end{alignat}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;example-nonconvex-quartic-minimization&quot;&gt;Example: nonconvex quartic minimization&lt;/h2&gt;
&lt;p&gt;Let us minimize the function \(f(x)=x^4 - 50 x^2 + 100 x\) subject to \(x \geq -4.5\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter11/dual-gen_13.png&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 4] Example of nonconvex quadratic minimization&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;In this case, the dual function \(g\) is as follows:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
 g(u) = \min_{i=1,2,3} \{F_i^4(u) - 50 F_i^2(u) + 100 F_i(u) \}
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;where, for \(i=1,2,3\),&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
F_i(u) = &amp;amp; \frac{- a_i}{12\cdot 2^{1/3}} \left( 432(100-u)-(432^2(100-u)^2 - 4\cdot 1200^3)^{1/2} \right )^{1/3} \\ 
           &amp;amp; - 100 \cdot 2^{1/3} \frac{1}{\left( 432(100-u)-(432^2(100-u)^2 - 4\cdot 1200^3)^{1/2} \right )^{1/3}}
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;and \(a_1=1, a_2 = (-1+i\sqrt{3})/2, a_3 = (-1-i \sqrt{3})/2\).
While it is difficult to determine whether \(g\) is concave just by looking at the function, we can know that \(g\) is concave under the convexity property of duality.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>11-2 Lagrange dual function</title>
   <link href="http://localhost:4000/contents/en/chapter11/11_02_Lagrange_dual_function/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter11/11_02_Lagrange_dual_function</id>
   <content type="html">&lt;p&gt;Let \(C\) be the primal feasible set and \(f^*\) the primal optimal value. Minimizing \(L(x,u,v)\) over all \(x\) yields the following lower bound.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
f^* \geq \min_{x \in C} L(x,u,v) \geq \min_x L(x,u,v) := g(u,v)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(g(u,v)\) is called the Lagrange dual function and provides a lower bound on \(f^*\) for any dual feasible \(u\geq 0\), \(v\).&lt;/p&gt;

&lt;p&gt;For example, in the figure below&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter11/dual-gen_7.png&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] Example of Lagrangian dual function[1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;The dashed horizontal line indicates the function \(f^*\).&lt;/li&gt;
  &lt;li&gt;The dual variable is \(\lambda\).&lt;/li&gt;
  &lt;li&gt;The solid line indicates \(g(\lambda)\).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;example-quadratic-program&quot;&gt;Example: Quadratic Program&lt;/h2&gt;
&lt;h3 id=&quot;1-positive-definite-q-succ-0&quot;&gt;1) Positive Definite (\(Q \succ 0\))&lt;/h3&gt;

&lt;p&gt;Consider the following quadratic problem (here \(Q \succ 0\))&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\min_x  &amp;amp; \quad \frac{1}{2}x^T Q x + c^T x \\\\
       s.t. &amp;amp; \quad Ax = b, \\\\
            &amp;amp; \quad x \geq 0
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Then,&lt;/p&gt;

&lt;h4 id=&quot;lagrangian&quot;&gt;Lagrangian:&lt;/h4&gt;
&lt;blockquote&gt;

\[\begin{equation}
L(x,u,v) = \frac{1}{2}x^T Q x + c^T x - u^Tx + v^T (Ax-b)
\end{equation}\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;lagrangian-dual-function&quot;&gt;Lagrangian dual function:&lt;/h4&gt;

&lt;p&gt;From the expression above, to minimize the Lagrangian function, differentiate with respect to \(x\) and find \(x^*\) such that the derivative is zero.
\begin{equation}
Qx - (c-u+A^T v) = 0,
\end{equation}
즉,
\begin{equation}
Qx = (c-u+A^T v)
\end{equation}
이 때, \(Q\)는 positive definite하므로 역행렬이 존재하므로, \(x^*\)를 찾으면, \(x^* = Q^{-1}(c - u + A^Tv)\) 임을 알 수 있다. 따라서, \(x^*\)를 Lagrangian 함수에 대입을 하면, 아래를 얻을 수 있다.&lt;/p&gt;

\[\begin{alignat}{1}
&amp;amp; (c - u + A^T v)^T (Q^{-1})^T Q Q^{-1}(c - u + A^T v) - (c - u + A^T v)^T Q^{-1} (c - u + A^T v) - b^T v \\\
= &amp;amp; (c - u + A^T v)^T Q^{-1}(c - u + A^T v) - (c - u + A^T v)^T Q^{-1} (c - u + A^T v) - b^T v \\\
= &amp;amp; -\frac{1}{2} (c-u+A^Tv)^T Q^{-1} (c-u+A^T v) - b^T v
\end{alignat}\]

&lt;p&gt;따라서,&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
g(u,v) = \min_x L(x,u,v) = -\frac{1}{2} (c-u+A^Tv)^T Q^{-1} (c-u+A^T v) - b^T v
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;For all \(u \geq 0\) and \(v\), this corresponds to a lower bound on the primal optimum \(f^*\).&lt;/p&gt;

&lt;h3 id=&quot;2-positive-semidefinite-q-succeq-0&quot;&gt;2) Positive Semidefinite (\(Q \succeq 0\))&lt;/h3&gt;
&lt;p&gt;위와 같은문제이나, 이번에는 \(Q \succeq 0\) 이면,&lt;/p&gt;

&lt;h4 id=&quot;lagrangian-1&quot;&gt;Lagrangian:&lt;/h4&gt;
&lt;blockquote&gt;

\[\begin{equation}
L(x,u,v) = \frac{1}{2}x^T Q x + c^T x - u^Tx + v^T (Ax-b)
\end{equation}\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;lagrangian-dual-function-1&quot;&gt;Lagrangian dual function:&lt;/h4&gt;
&lt;p&gt;\(Q\)가 positive definite 할 때 처럼, 아래 식을 만족하는 \(x^*\)를 찾아야 한다.&lt;/p&gt;

&lt;p&gt;\(\begin{equation}
Qx = (c-u+A^T v)
\end{equation}\)
이 때, \(Q\)는 positive semi-definite이므로 역행렬이 존재하지 않을 수 있다. 따라서, 다음의 두가지 경우를 고려해야 한다.&lt;/p&gt;

&lt;p&gt;(1) \(c-u+A^T v \in col(Q)\). In this case, there exists \(x^*\) satisfying \(Qx = (c-u+A^T v)\), which can be found using the generalized inverse \(Q^+\) (the Moore-Penrose pseudo-inverse, \(Q^+ = (Q^TQ)^{-1}Q^T\)).
(2) \(c-u+A^T v \notin col(Q)\). In this case, there is no \(x^*\) satisfying \(Qx = (c-u+A^T v)\), meaning there is no \(x^*\) that minimizes \(L(x,u,v)\), and the minimum of \(L(x,u,v)\) is \(-\infty\).&lt;/p&gt;

&lt;p&gt;From these two cases, the Lagrangian dual function can be summarized as follows.&lt;/p&gt;
&lt;blockquote&gt;

\[g(u,v) =
\begin{cases}
-\frac{1}{2} (c-u+A^T v)^T Q^{+} (c - u + A^T v) - b^T v  &amp;amp; \text{if $c-u+A^T v \perp \text{null}(Q)$} \\\\
-\infty  &amp;amp; \text{otherwise}
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;For all \(u\geq 0\), \(v\) with \(c-u+A^Tv \perp \text{null}(Q)\), \(g(u,v)\) is a nontrivial lower bound on \(f^*\).&lt;/p&gt;

&lt;h2 id=&quot;example-quadratic-program-in-2d&quot;&gt;Example: Quadratic Program in 2D&lt;/h2&gt;

&lt;p&gt;For example, in the following figure, \(f(x_1,x_2)\) is a quadratic function over variables greater than 0 (\(x\ge0\)), and the dual function \(g(u_1,u_2)\) is a quadratic function over variables greater than 0 (\(u\ge0\)).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter11/dual-gen_10.png&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 3] Example of quadratic program in 2D&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;The blue point is the optimal dual value, and the red point is the optimal primal value.&lt;/li&gt;
  &lt;li&gt;For all \(u&amp;gt;0\), the dual function \(g(u)\) provides a lower bound on \(f^*\).&lt;/li&gt;
  &lt;li&gt;The maximum of the dual function \(g(u)\) matches exactly the value \(f^*\).&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>11-1 Lagrangian</title>
   <link href="http://localhost:4000/contents/en/chapter11/11_01_Lagrangian/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter11/11_01_Lagrangian</id>
   <content type="html">&lt;p&gt;We now look at the Lagrangian form for the following optimization problem. Here, the optimization problem need not be convex.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{alignat}{1}
\min_x &amp;amp; \quad f(x)  \\\
s.t.   &amp;amp; \quad h_i(x) \leq 0, i = 1,\dots,m \\\
       &amp;amp; \quad l_j(x) = 0, j=1,\dots,r
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;The Lagrangian is defined as follows.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
L(x,u,v) = f(x) + \sum_{i=1}^m u_i h_i(x) + \sum_{j=1}^r v_j l_j(x)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(u \in \mathbb{R}^m\), \(v \in \mathbb{R}^r\), \(u \geq 0\) (implicitly, \(L(x,u,v) = - \infty\) for \(u &amp;lt;0\)).&lt;/p&gt;

&lt;p&gt;Since in the constraints we have \(h_i(x) \leq 0\) and \(l_j(x)=0\),&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
L(x,u,v) =  f(x) + \sum_{i=1}^{m} u_i \underbrace{h_i(x)}_{\leq 0} + \sum_{j=1}^r v_j \underbrace{l_j(x)}_{=0} \leq f(x)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;In other words, the Lagrangian has the following important property.&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;For all \(u \geq 0\), \(v\), we have \(f(x) \geq L(x,u,v) \text{ at each feasible } x\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For example, in the figure below,&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter11/dual-gen_6.png&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Example of Lagrangian[1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;The solid line indicates the function \(f\).&lt;/li&gt;
  &lt;li&gt;The dashed line indicates the function \(h\). Here, the feasible set is roughly \([-0.46,0.46]\).&lt;/li&gt;
  &lt;li&gt;Each dotted line indicates the function \(L(x,u,v)\) for \(u \geq 0\), \(v\).&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>11 Duality in General Programs</title>
   <link href="http://localhost:4000/contents/en/chapter11/11_00_Duality_in_General_Programs/"/>
   <updated>2021-03-24T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter11/11_00_Duality_in_General_Programs</id>
   <content type="html">&lt;h3 id=&quot;review-duality-in-linear-program&quot;&gt;Review: duality in linear program&lt;/h3&gt;

&lt;p&gt;Given \(c \in \mathbb{R}^n\), \(A \in \mathbb{R}^{m \times n}\), \(b \in \mathbb{R}^m\), \(G \in \mathbb{R}^{r \times n}\), \(h \in \mathbb{R}^r\),&lt;/p&gt;

&lt;h4 id=&quot;primal-lp&quot;&gt;Primal LP:&lt;/h4&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\min_{x} &amp;amp; \quad c^T x   \\\\ 
  s.t.   &amp;amp; \quad Ax = b  \\\\
         &amp;amp; \quad Gx \leq h 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;dual-lp&quot;&gt;Dual LP:&lt;/h4&gt;
&lt;blockquote&gt;

\[\begin{alignat}{1}
\max_{u,b} &amp;amp; \quad -b^T u - h^T v   \\\\
         s.t. &amp;amp; \quad - A^T u - G^T v = c  \\\\
             &amp;amp; \quad v \geq 0 
\end{alignat}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;explanation-1&quot;&gt;Explanation 1:&lt;/h3&gt;

&lt;p&gt;For all \(u\) and \(v \geq 0\), and for any primal feasible \(x\), the following holds.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
u^T (Ax-b) + v^T(Gx-h) \leq 0
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;즉,&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
(-A^Tu - G^Tv)^T x \geq -b^Tu - h^T v
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;By this relationship, if \(c=-A^Tu - G^Tv\), we obtain a lower bound on the primal optimum.&lt;/p&gt;

&lt;h3 id=&quot;explanation-2&quot;&gt;Explanation 2:&lt;/h3&gt;

&lt;p&gt;For all \(u\) and \(v \geq 0\), and for any primal feasible \(x\),&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
c^T x \geq c^T x + u^T (Ax-b) + v^T (Gx -h) := L(x,u,v)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Thus, if \(C\) is the primal feasible set and \(f^*\) is the primal optimum, then&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
f^* \geq \min_{x \in C} L(x,u,v) \geq \min_x L(x,u,v) := g(u,v)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;In other words, \(g(u,v)\) is a lower bound on \(f^*\).&lt;/p&gt;

&lt;blockquote&gt;

\[g(u,v) =
\begin{cases}
-b^T u - h^T v &amp;amp; \text{if $c=-A^Tu - G^T v$} \\\\
-\infty            &amp;amp; \text{otherwise} 
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;The second explanation yields the same dual as the first, but it is completely general and applies to arbitrary optimization problems (including nonconvex ones).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>18-07 Limited Memory BFGS (LBFGS)</title>
   <link href="http://localhost:4000/contents/vi/chapter18/18_07_Limited_Memory_BFGS_(LBFGS)/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter18/18_07_Limited_Memory_BFGS_(LBFGS)</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;LBFGS is an example of Limited-memory quasi-Newton methods, and is useful when the cost of computing or storing the Hessian matrix is not reasonable. This method estimates (approximates) the Hessian matrix by maintaining only a few \(n\)-dimensional vectors instead of storing a dense \(n \times n\) Hessian matrix.&lt;/p&gt;

&lt;p&gt;The LBFGS algorithm is based on BFGS, as its name suggests. The main idea is to use curvature information from the most recent iterations to estimate the Hessian. On the other hand, curvature information from older iterations is not used to save storage space, as it may be somewhat distant from the behavior shown by the Hessian of the current iteration.&lt;/p&gt;

&lt;p&gt;As a side note, limited-memory versions of other quasi-Newton algorithms (e.g., SR1) can also be derived using the same technique [14].&lt;/p&gt;

&lt;h2 id=&quot;lbfgs&quot;&gt;LBFGS&lt;/h2&gt;

&lt;p&gt;LBFGS를 본격적with, 설명하기to, 앞서 BFGS methodabout, 다시 let’s look at. 각 stepat, BFGS는 as follows: \(x\)를 업데이트 한다.&lt;/p&gt;
&lt;blockquote&gt;
\[x^+ = x - t H \nabla f, \\\\
\text{where } t \text{ is the step length and } H \text{ is updated at every iteration by means of the formula, }\\\\
\text{     }\\\\
H^+ =  \big( I - \frac{sy^T}{y^Ts} \big) H \big( I - \frac{ys^T}{y^Ts} \big) + \frac{ss^T}{y^Ts}.\\\\\]
&lt;/blockquote&gt;

&lt;p&gt;\(H\)to, about, 업데이트 식을 이용하면 \(H^+q, q \in \mathbb{R}^n\)를 임의의 scalar \(\alpha, \beta \in \mathbb{R}\)and, 임의의 vector \(p, s \in \mathbb{R}^n\)를 using, 표현할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
H^+q &amp;amp;=  \big( I - \frac{sy^T}{y^Ts} \big) H \big( I - \frac{ys^T}{y^Ts} \big)q + \frac{ss^Tq}{y^Ts}\\\\
&amp;amp;= \big( I - \frac{sy^T}{y^Ts} \big) \underbrace{H \\big( q - \frac{s^T q}{y^Ts} y \big)}_{p} + \underbrace{\frac{s^Tq}{y^Ts}}_{\alpha} s\\\\
&amp;amp;= \big( I - \frac{sy^T}{y^Ts} \big) p + \alpha s\\\\
&amp;amp;= p - \underbrace{\frac{y^Tp}{y^Ts}}_{\beta}s + \alpha s \\\\
&amp;amp;= p + (\alpha - \beta) s,\\\\
&amp;amp; \text{where } \alpha = \frac{s^Tq}{y^Ts}, q^+ = q - \alpha y, p = Hq, \beta = \frac{y^Tp}{y^Ts}.
\end{align}\\\\\]
&lt;/blockquote&gt;

&lt;p&gt;\(H\)가 k번의 BFGS update를 through, 얻이진다고 할when,, \(Hq= -H\nabla f(x)\)는 length k의 iteration문 2개to, computation할 수 있다 (아래 algorithm reference). 단, 메모리의 효율적인 사용을 for, 가장 최근 $m$개 iterationsat,의 curvature information만을 이용한다. (\(k \ge m\))&lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter18/algorithm_quasi-newton.png&quot; alt=&quot;[Fig1] The algorithm of LBFGS [3]&quot; width=&quot;90%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] The algorithm of LBFGS [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;usually, inverse Hessian approximation \(H_k\)는 dense하며, variable의 개수가 많은 case, 저장 및 operation 비용이 매우 높아지게 된다. 반면 LBFGS는 \(H_k \nabla f_k\)을 연속한 vectorsumand, vectorproductwith, obtaining,냄with,써 \(H_k\)의 computation 및 유지를 위한 비용problem를 완화시킬 수 있다. 뿐만 아니라 이 computationto, 사용되는 initial Hessian approximation \(H^{0,k}\)는 usually, (실전at, 매우 effect,적with, 작동한다고 검증된) identity matrixto, 어떤 constant를 product한 형태(\(H^{0,k} = \gamma_k I\))를 띄기 because of, 유지 및 computationto, 그다지 큰 비용이 발생하지 않는다 ([14]의 7.2).&lt;/p&gt;
&lt;blockquote&gt;
\[H^{0,k} = \gamma_k I, \\\\
\text{where } \: \gamma_k = \frac{s^T_{k-1}y_{k-1}}{y^T_{k-1}y_{k-1}}.\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; \(H^{0,k}\)는 매 iteration마다 다르게 선택될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>18-06 Superlinear convergence</title>
   <link href="http://localhost:4000/contents/vi/chapter18/18_06_Superlinear_convergence/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter18/18_06_Superlinear_convergence</id>
   <content type="html">&lt;h3 id=&quot;assumption1&quot;&gt;Assumption1:&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;The Hessian matrix \(G\) is Lipschitz continuous at \(x^∗\), that is, 
\(\| G(x) − G(x^∗)  \le L \| x − x^∗ \|,\)
for all \(x\) near \(x^∗\), where \(L\) is a positive constant.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;assumption2-wolfe-conditions&quot;&gt;Assumption2: Wolfe conditions&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Assume \(t\) is chosen (via backtracking) so that
\(f(x + tp) \le f(x) + \alpha_1 t \nabla f(x)^T p\)
and
\(\nabla f(x + tp)^T p \ge \alpha_2 \nabla f(x)^T p\)
for \(0 &amp;lt; \alpha_1 &amp;lt; \alpha_2 &amp;lt; 1.\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;The first condition of Wolfe conditions ensures that too large a \(t\) is not selected.&lt;/li&gt;
  &lt;li&gt;The second condition of Wolfe conditions ensures that too small a \(t\) is not selected.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DFP and BFGS show superlinear convergence under the above two assumptions. (reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Rate_of_convergence&quot;&gt;Rate of convergence in Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;blockquote&gt;
\[\lim_{k \rightarrow \infty} \frac{ \| x^{k+1} - x^\ast \| }{ \| x^k - x^\ast \| } = 0.\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;theorem-dennis-moré&quot;&gt;Theorem (Dennis-Moré)&lt;/h2&gt;

&lt;p&gt;다음은 Quasi-Newton method의 search direction이 Newton direction을 충분히 잘 approximation하고 있을when,, solutionwith, convergence하는 processat, step length가 Wolfe conditions를 만족함을 보인다. Superlinear convergence를 보이기 for, search direction이 만족solution야하는 condition,이라고도 할 수 있다 [14].&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f\)가 두 번 미분 가능하고 \(x^k \rightarrow x^\ast\) s.t. \(\nabla f(x^\ast) = 0\)이며 \(\nabla^2 f(x^\ast)\)가 positive definite이라고 let’s assume.&lt;/p&gt;

\[\lim_{k \rightarrow \infty} \frac{\| \nabla f(x^k) + \nabla^2 f(x^k) p^k \| }{\| p^k \|} = 0.\]

  &lt;p&gt;if, search direction \(p^k\)가 위 condition,을 만족하면, 다음 두 가지 항목을 만족하는 \(k_0\)가 존재한다.&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;\(k \ge k_0\)about, step length \(t_k=1\)은 Wolfe conditions를 만족한다.&lt;/li&gt;
    &lt;li&gt;if, \(k \ge k_0\)about, \(t_k = 1\)이면 \(x^k \rightarrow x^\ast\)는 superlinear convergence를 보인다.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>18-05 The Broyden Class</title>
   <link href="http://localhost:4000/contents/vi/chapter18/18_05_The_Broyden_Class/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter18/18_05_The_Broyden_Class</id>
   <content type="html">&lt;p&gt;The Broyden class generalizes BFGS, DFP, and SR1 with the following formula.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; \(B^+_{\text{BFGS}}\)and, \(B^+_{\text{DFP}}\)는 각각 BFGSand, DFPby, 유도되는 \(B^+\)다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[B^+ = (1 - \phi)B^+_{\text{BFGS}} + \phi B^+_{\text{DFP}}, \text{ for } \phi \in \mathbb{R}.\]
&lt;/blockquote&gt;

&lt;p&gt;\(v\)를 \(\frac{y}{y^Ts} - \frac{Bs}{s^TBs}\)to, 정의하면 위 공식은 아래and, 같이 정리된다.&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = B - \frac{Bss^TB}{s^TBs} + \frac{yy^T}{y^Ts} + \phi(s^TBs)vv^T.\]
&lt;/blockquote&gt;

&lt;p&gt;Observe:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\phi =0\)일when,, 위 update는 BFGSand, 동일solution진다.&lt;/li&gt;
  &lt;li&gt;\(\phi =1\)일when,, 위 update는 DFPand, 동일solution진다.&lt;/li&gt;
  &lt;li&gt;\(\phi = \frac{y^Ts}{y^Ts - s^TBs}\)일when,, 위 update는 SR1and, 동일solution진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;*reference&lt;/strong&gt;: \(\phi\)의 범위를 \([0,1]\)to, 제한한 특수한 case,를 restricted Broyden class라 부른다 [14].&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>18-04 Broyden-Fletcher-Goldfarb-Shanno (BFGS) update</title>
   <link href="http://localhost:4000/contents/vi/chapter18/18_04_Broyden_Fletcher_Goldfarb_Shanno_(BFGS)_update/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter18/18_04_Broyden_Fletcher_Goldfarb_Shanno_(BFGS)_update</id>
   <content type="html">&lt;p&gt;The idea of BFGS is the same as DFP. The only difference is that the roles of B and H are reversed.&lt;/p&gt;

&lt;p&gt;BFGS is derived by solving the following problem.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Solve
\(\begin{align}
&amp;amp; \min_{H^+} \: \: &amp;amp;&amp;amp; {\|W^{1/2} (H^+ - H) W^{1/2} \|_F} \\\\
&amp;amp; \text{subject to } &amp;amp;&amp;amp; {H^+ = (H^+)^T} \\\\
&amp;amp;&amp;amp;&amp;amp; {H^+s = y}  \\\\
&amp;amp; \text{where } &amp;amp;&amp;amp; W \in \mathbb{R}^{n \; \times \;n} \text{ is nonsingular and such that } Ws_k = y_k.
\end{align}\\\\\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The derived updating formulas for \(H\) and \(B\) are as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = B - \frac{Bss^TB}{s^TBs} + \frac{yy^T}{y^Ts}\]
&lt;/blockquote&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
H^+ &amp;amp;= H + \frac{(s-Hy)s^T}{y^Ts} + \frac{s(s-Hy)^T}{y^Ts} - \frac{(s-Hy)^Ty}{(y^Ts)^2} ss^T\\\\
&amp;amp;= \big( I - \frac{sy^T}{y^Ts} \big) H \big( I - \frac{ys^T}{y^Ts} \big) + \frac{ss^T}{y^Ts} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;BFGS also, DFP처럼 positive definiteness를 유지한다. (if, \(B\)가 positive definite이고 \(s^Ty &amp;gt; 0\)이면 \(B^+\)는 positive definite이다.)&lt;/p&gt;

&lt;p&gt;BFGS의 특장점은 self-correcting property를 지니고 있다는 것이다. if, matrix \(H\)가 부정확하게 추정되어 iteration의 속도가 느려지게 되면 Hessian approximation이 단 몇 step 만to, 이를 바to,잡는 경향성을 보인다. 반면 DFP는 잘못된 Hessian approximation의 추정about, effect,적with, 바to,잡지 못하므to, 실전at,는 usually, BFGS의 성능이 더 좋은 편이다 [14].&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>18-03 Davidon-Fletcher-Powell (DFP) Update</title>
   <link href="http://localhost:4000/contents/vi/chapter18/18_03_Davidon_Fletcher_Powell_(DFP)_Update/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter18/18_03_Davidon_Fletcher_Powell_(DFP)_Update</id>
   <content type="html">&lt;p&gt;The DFP update is a method that updates \(H (=B^{-1})\) with a rank-2 symmetric matrix.&lt;/p&gt;

&lt;blockquote&gt;
\[H^+ = H + auu^T + bvv^T.\]
&lt;/blockquote&gt;

&lt;p&gt;If \(H^+\) computed through the DFP update satisfies the secant equation, then \(s-Hy\) can be expressed as a linear combination of \(u\) and \(v\). (reference: by the secant equation, \(B^+ s =y \Leftrightarrow H^+ y = s\))&lt;/p&gt;

&lt;blockquote&gt;
\[H^+y = Hy + auu^Ty + bvv^Ty = Hy + (au^Ty)u + (bv^Ty)v = s\]

\[\Rightarrow s - Hy = (au^Ty)u + (bv^Ty)v\]
&lt;/blockquote&gt;

&lt;p&gt;Setting \(u=s, v=Hy\) and solving for \(a\) and \(b\), we derive the updating formula for \(H\).&lt;/p&gt;
&lt;blockquote&gt;
\[H^+ = H - \frac{Hyy^TH}{y^THy} + \frac{ss^T}{y^Ts}\]
&lt;/blockquote&gt;

&lt;p&gt;Similar to the SR1 update, we can derive the updating formula for \(B\) using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula&quot;&gt;Sherman–Morrison formula&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
B^+ &amp;amp;= B + \frac{(y-Bs)y^T}{y^Ts} + \frac{y(y-Bs)^T}{y^Ts} - \frac{(y-Bs)^Ts}{(y^Ts)^2} yy^T\\\\
&amp;amp;= \big( I - \frac{ys^T}{y^Ts} \big) B \big( I - \frac{sy^T}{y^Ts} \big) + \frac{yy^T}{y^Ts} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If \(B\) is positive definite, then \(\big( I - \frac{ys^T}{y^Ts} \big) B \big( I - \frac{sy^T}{y^Ts} \big)\) becomes positive semidefinite. In this case, if \(\frac{yy^T}{y^Ts}\) is positive definite, then \(B^+ = \big( I - \frac{ys^T}{y^Ts} \big) B \big( I - \frac{sy^T}{y^Ts} \big) + \frac{yy^T}{y^Ts}\) is guaranteed to be positive definite. This solves the problem of maintaining positive definiteness that was raised with SR1.&lt;/p&gt;

&lt;h2 id=&quot;dfp-update---alternate-derivation&quot;&gt;DFP Update - Alternate Derivation&lt;/h2&gt;

&lt;p&gt;Recall: if the curvature condition (\(y^Ts &amp;gt; 0, y,s \in \mathbb{R}^n\)) is satisfied, then there exists a symmetric positive definite matrix that satisfies the secant equation.&lt;/p&gt;

&lt;p&gt;The DFP update can also be derived by solving the problem of minimizing the weighted Frobenius norm between matrix \(B^+\) and \(B\) where \(B^+\) 1. satisfies symmetry and 2. satisfies the secant equation. (Each different matrix norm corresponds to each different Quasi-Newton method. Among them, the norm that makes it easy to solve this problem while also making it work as a scale-invariant optimization method is the weighted Frobenius norm.)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Solve
\(\begin{align}
&amp;amp; \min_{B^+} \: \: &amp;amp;&amp;amp; {\|W^{1/2} (B^+ - B) W^{1/2} \|_F} \\\\
&amp;amp; \text{subject to } &amp;amp;&amp;amp; {B^+ = (B^+)^T} \\\\
   &amp;amp;&amp;amp;&amp;amp; {B^+s = y}  \\\\
&amp;amp; \text{where } &amp;amp;&amp;amp; W \in \mathbb{R}^{n \; \times \;n} \text{ is nonsingular and such that } Wy_k = s_k.
\end{align}\\\\\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;*reference&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Frobenius norm: The Frobenius norm of matrix \(A\) is defined as follows.
\(\| A \|_{F}  \doteq ( \sum_{i,j} A_{i,j}^2 )^{1/2}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Weighted Frobenius norm: The weighted Frobenius norm of matrix \(A\) with weight matrix \(W(W \succ 0)\) is defined as follows. 
\(\|A\|_W \doteq \| W^{1/2} A W^{1/2} \|_F\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>18-02 Symmetric Rank-One Update (SR1)</title>
   <link href="http://localhost:4000/contents/vi/chapter18/18_02_Symmetric_Rank_One_Update_(SR1)/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter18/18_02_Symmetric_Rank_One_Update_(SR1)</id>
   <content type="html">&lt;p&gt;The SR1 update is a method that updates \(B\) with a rank-1 symmetric matrix so that \(B^+\) maintains symmetry and continues to satisfy the secant equation. If a rank-1 symmetric matrix is decomposed as a product of \(a \in \left\{-1, 1\right\}\) and \(u \in \mathbb{R^n}\), the update form would be as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = B + auu^T.\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;key-observation&quot;&gt;Key Observation&lt;/h2&gt;
&lt;p&gt;\(a\) and \(u\) must be chosen so that \(B^+\) satisfies the secant equation. Thus, let’s substitute the update form introduced above into the secant equation \(y = B^+s\).&lt;/p&gt;

&lt;blockquote&gt;
\[y = B^+s \Rightarrow y = Bs + (au^Ts)u. \quad \text{--- (1)}\]
&lt;/blockquote&gt;

&lt;p&gt;Since \((au^Ts)\) is a scalar, \(u\) can also be expressed as a product of \(y-Bs\) and an arbitrary scalar \(\delta\) \(\big( u = \delta(y - Bs) \big)\). Let’s substitute \(u\) in (1) with \(\delta(y - Bs)\).&lt;/p&gt;

&lt;blockquote&gt;
\[y-Bs = a\delta^2 \big[ s^T(y - Bs) \big] (y -Bs),\]
&lt;/blockquote&gt;

&lt;p&gt;The parameters \(\delta\) and \(a\) that satisfy the above equation are as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[a = \text{sign} \big[ s^T (y - Bs) \big], \quad \delta = \pm | s^T(y-Bs) |^{-1/2}. \quad \text{--- (2)}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-only-sr1-updating-formula&quot;&gt;The Only SR1 Updating Formula&lt;/h2&gt;
&lt;p&gt;Using the information obtained from the key observation, we can derive the unique form of SR1 update ([14] section 6.2). &lt;br /&gt;
\(\big( u = \delta (y - Bs)\) and substituting (2) into \(B^+ = B + auu^T\). \(\big)\)&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = B + \frac{(y-Bs)(y-Bs)^T}{(y-Bs)^Ts}.\]

&lt;/blockquote&gt;

&lt;h2 id=&quot;the-update-formula-for-the-inverse-hessian-approximation&quot;&gt;The Update Formula for the Inverse Hessian Approximation&lt;/h2&gt;

&lt;p&gt;To find \(x^+\), we need to compute \(B^{-1}\).&lt;/p&gt;

&lt;blockquote&gt;
\[x^+ = x + tp = x - tB^{-1}\nabla f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;If we can update \(B^{-1}\) instead of \(B\), wouldn’t we be able to reduce the cost of computing \(B^{-1}\) every time?&lt;/p&gt;

&lt;p&gt;Using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula&quot;&gt;Sherman–Morrison formula&lt;/a&gt;, we can see through the derivation process that \(B^{-1}\) can also be updated in the same form. (\(H = B^{-1}\))&lt;/p&gt;

&lt;blockquote&gt;
\[H^+ = H + \frac{(s-Hy)(s-Hy)^T}{(s-Hy)^Ty}.\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;shortcomings-of-sr1&quot;&gt;Shortcomings of SR1&lt;/h2&gt;

&lt;p&gt;SR1 has the advantage of being very simple, but it has two critical shortcomings.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The update can fail when \((y-Bs)^Ts\) approaches 0.&lt;/li&gt;
  &lt;li&gt;It cannot maintain the positive definiteness of \(B\) and \(H\).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The following sections introduce methods that complement the shortcomings of SR1.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>18-01 Secant Equation and Curvature Condition</title>
   <link href="http://localhost:4000/contents/vi/chapter18/18_01_Secant_Equation_and_Curvature_Condition/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter18/18_01_Secant_Equation_and_Curvature_Condition</id>
   <content type="html">&lt;h2 id=&quot;secant-equation&quot;&gt;Secant Equation&lt;/h2&gt;
&lt;p&gt;As mentioned earlier, \(B\) is a matrix that approximates \(\nabla^2 f(x)\). For matrix \(B\) to have similar properties to the Hessian \(\nabla^2 f(x)\), it must satisfy a condition called the secant equation. When \(x^{k+1} = x^k + s^k\) and \(f\) is twice differentiable, the first-order Taylor expansion of \(\nabla f(x^k + s^k)\) shows that the true Hessian has the following property.&lt;/p&gt;

&lt;blockquote&gt;
\[\nabla f(x^k + s^k)  \approx \nabla f(x^k) + \nabla^2 f(x^k) s^k\]
&lt;/blockquote&gt;

&lt;p&gt;Here, we call the approximation matrix of \(\nabla^2 f(x^k)\) as \(B^{k+1}\). This matrix satisfies the following equation.&lt;/p&gt;

&lt;blockquote&gt;
\[\nabla f(x^k + s^k)  = \nabla f(x^k) + B^{k+1} s^k\]
&lt;/blockquote&gt;

&lt;p&gt;If \(x^{k+1} = x^k + s^k, y^k = \nabla f(x^{k + 1})  - \nabla f(x^k)\), then the above equation can be rearranged as follows, and this is called the secant equation.&lt;/p&gt;

&lt;blockquote&gt;
\[B^{k+1} s^k = y^k\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-intuition-of-secant-equation&quot;&gt;The Intuition of Secant Equation&lt;/h2&gt;

&lt;p&gt;\(x\)axis은 \(x^k\)를, \(y\)axis은 \(\nabla f(x^k)\)를 나타낸다고 할when, \(B^{k+1}\)은 \((x^k, \nabla f(x^k))\)and, \((x^{k+1}, \nabla f(x^{k+1}))\)를 통and,하는 직선의 기울기and, 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter18/intuition_of_secant_eq.png&quot; alt=&quot;[Fig1] The intuition of secant equation&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] The intuition of secant equation&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;conditions-to-determine-b&quot;&gt;Conditions to Determine \(B^+\)&lt;/h2&gt;
&lt;p&gt;matrix \(B\)를 basis,with, computation된 \(B^+\)는 다음의 3가지 condition,을 만족solution야한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(B^+\) is symmetric: Because it is an approximation of the Hessian.&lt;/li&gt;
  &lt;li&gt;\(B^+\) close to \(B\): A condition to determine a unique \(B^+\). Since \(B\) already contains useful information, we choose the matrix closest to \(B\) among those \(B^+\) that satisfy the secant equation.&lt;/li&gt;
  &lt;li&gt;\(B\) is positive definite \(\Rightarrow B^+\) is positive definite: To guarantee global optimum, we maintain the convexity of the problem. (reference: &lt;a href=&quot;https://web.stanford.edu/group/sisl/k12/optimization/MO-unit4-pdfs/4.10applicationsofhessians.pdf&quot;&gt;Analyzing the hessian&lt;/a&gt;)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;curvature-condition&quot;&gt;Curvature Condition&lt;/h2&gt;
&lt;p&gt;The fact that \(B^+\) is positive definite and \(B^+ s = y\) implies the following fact.&lt;/p&gt;
&lt;blockquote&gt;
\[s^T y = s^T B^+ s &amp;gt; 0.\]
&lt;/blockquote&gt;

&lt;p&gt;(reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Positive-definite_matrix&quot;&gt;positive definite in WikiPedia&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Here, \(s^T y &amp;gt; 0\) is called the curvature condition. If the curvature condition is satisfied, the secant equation \(B^+ s = y\) always has a solution (\(B^+\)).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>18-00 Quasi-Newton methods</title>
   <link href="http://localhost:4000/contents/vi/chapter18/18_00_Quasi_Newton_methods/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter18/18_00_Quasi_Newton_methods</id>
   <content type="html">&lt;p&gt;In the mid-1950s, physicist W.C. Davidon, who was working at Argonne National Laboratory, was solving optimization problems with large computational requirements using coordinate descent methods. Unfortunately, due to the instability of computers at the time, system crashes frequently occurred before computations could be completed, and frustrated by this, Davidon decided to find methods that could improve computational speed. This led to the birth of the first Quasi-Newton algorithm. This became a catalyst for dramatic progress in nonlinear optimization, and subsequently, various follow-up studies on this method emerged over the next 20 years.&lt;/p&gt;

&lt;p&gt;Ironically, &lt;a href=&quot;http://www.math.mcgill.ca/dstephens/680/Papers/Davidon91.pdf&quot;&gt;Davidon’s research&lt;/a&gt; was not published at the time and remained as a technical report for more than 30 years. It was finally published in the &lt;a href=&quot;https://epubs.siam.org/toc/sjope8/1/1&quot;&gt;first issue of SIAM Journal on Optimization&lt;/a&gt; in 1991.&lt;/p&gt;

&lt;p&gt;Quasi-Newton methods require only the gradient of the objective function at each iteration. This has much less computational burden than Newton methods that require second derivatives, and moreover shows superlinear convergence, making it a sufficiently attractive method [14].&lt;/p&gt;

&lt;h2 id=&quot;motivation-for-quasi-newton-methods&quot;&gt;Motivation for Quasi-Newton methods&lt;/h2&gt;

&lt;p&gt;Consider the following unconstrained, smooth optimization problem:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x \: f(x), \\\\
\text{where } f \text{ is twice differentiable, and } dom \; f = \mathbb{R}^n.\]
&lt;/blockquote&gt;

&lt;p&gt;The update methods for x in Gradient descent method and Newton’s method for the above problem are as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Gradient descent method:&lt;/strong&gt;
\(x^+ = x - t \nabla f(x)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Newton’s method:&lt;/strong&gt;
\(x^+ = x - t \nabla^2 f(x)^{-1} \nabla f(x)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Newton’s method has the advantage of showing quadratic convergence rate (\(O(\log \log 1/ \epsilon)\)), but there are problems with significantly high computational costs in the following two processes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Computing the Hessian \(\nabla^2 f(x)\): Computing and storing the Hessian matrix requires \(O(n^2)\) memory. This is not suitable performance for handling high-dimensional functions. (reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Hessian_matrix#Use_in_optimization&quot;&gt;Hessian matrix&lt;/a&gt; in Wikipedia)&lt;/li&gt;
  &lt;li&gt;Solving the equation \(\nabla^2 f(x) p = -\nabla f(x)\): To solve this equation, we must compute the inverse matrix of the Hessian \(\nabla^2 f(x)\). (reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations#Matrix_algebra&quot;&gt;Computational complexity of Matrix algebra&lt;/a&gt; in Wikipedia)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quasi-Newton methods use an approximation \(B\) instead of \(\nabla^2 f(x)\).&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Quasi-Newton method:&lt;/strong&gt;
\(x^+ = x + tp \\\\
\text{where } Bp = -\nabla f(x).\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, B should be easy to compute, and it should also be easy to solve the equation \(Bp = g\).&lt;/p&gt;

&lt;h2 id=&quot;quasi-newton-algorithm&quot;&gt;Quasi-Newton Algorithm&lt;/h2&gt;
&lt;p&gt;The Quasi-Newton algorithm is as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pick initial \(x^0\) and \(B^0\)&lt;/li&gt;
  &lt;li&gt;For \(k = 0, 1, \dots\)
    &lt;ul&gt;
      &lt;li&gt;Solve \(B^k p^k = - \nabla f(x^k)\)&lt;/li&gt;
      &lt;li&gt;Pick \(t_k\) and let \(x^{k+1} = x^{k} + t_k p^k\)&lt;/li&gt;
      &lt;li&gt;Update \(B^k\) to \(B^{k+1}\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;End for&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A major characteristic of this method is updating \(B\) so that we can gradually approach the optimal point. That is, the method of obtaining the next step \(B^+\) from \(B\) will be the main topic of discussion in this chapter. (&lt;strong&gt;Note:&lt;/strong&gt; For convenience, we will use the two notations \(B^{k+1}, B^k\) and \(B^+, B\) interchangeably.)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>18-07 Limited Memory BFGS (LBFGS)</title>
   <link href="http://localhost:4000/contents/en/chapter18/18_07_Limited_Memory_BFGS_(LBFGS)/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter18/18_07_Limited_Memory_BFGS_(LBFGS)</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;LBFGS is an example of Limited-memory quasi-Newton methods, and is useful when the cost of computing or storing the Hessian matrix is not reasonable. This method estimates (approximates) the Hessian matrix by maintaining only a few \(n\)-dimensional vectors instead of storing a dense \(n \times n\) Hessian matrix.&lt;/p&gt;

&lt;p&gt;The LBFGS algorithm is based on BFGS, as its name suggests. The main idea is to use curvature information from the most recent iterations to estimate the Hessian. On the other hand, curvature information from older iterations is not used to save storage space, as it may be somewhat distant from the behavior shown by the Hessian of the current iteration.&lt;/p&gt;

&lt;p&gt;As a side note, limited-memory versions of other quasi-Newton algorithms (e.g., SR1) can also be derived using the same technique [14].&lt;/p&gt;

&lt;h2 id=&quot;lbfgs&quot;&gt;LBFGS&lt;/h2&gt;

&lt;p&gt;LBFGS를 본격적with, 설명하기to, 앞서 BFGS methodabout, 다시 let’s look at. 각 stepat, BFGS는 as follows: \(x\)를 업데이트 한다.&lt;/p&gt;
&lt;blockquote&gt;
\[x^+ = x - t H \nabla f, \\\\
\text{where } t \text{ is the step length and } H \text{ is updated at every iteration by means of the formula, }\\\\
\text{     }\\\\
H^+ =  \big( I - \frac{sy^T}{y^Ts} \big) H \big( I - \frac{ys^T}{y^Ts} \big) + \frac{ss^T}{y^Ts}.\\\\\]
&lt;/blockquote&gt;

&lt;p&gt;\(H\)to, about, 업데이트 식을 이용하면 \(H^+q, q \in \mathbb{R}^n\)를 임의의 scalar \(\alpha, \beta \in \mathbb{R}\)and, 임의의 vector \(p, s \in \mathbb{R}^n\)를 using, 표현할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
H^+q &amp;amp;=  \big( I - \frac{sy^T}{y^Ts} \big) H \big( I - \frac{ys^T}{y^Ts} \big)q + \frac{ss^Tq}{y^Ts}\\\\
&amp;amp;= \big( I - \frac{sy^T}{y^Ts} \big) \underbrace{H \\big( q - \frac{s^T q}{y^Ts} y \big)}_{p} + \underbrace{\frac{s^Tq}{y^Ts}}_{\alpha} s\\\\
&amp;amp;= \big( I - \frac{sy^T}{y^Ts} \big) p + \alpha s\\\\
&amp;amp;= p - \underbrace{\frac{y^Tp}{y^Ts}}_{\beta}s + \alpha s \\\\
&amp;amp;= p + (\alpha - \beta) s,\\\\
&amp;amp; \text{where } \alpha = \frac{s^Tq}{y^Ts}, q^+ = q - \alpha y, p = Hq, \beta = \frac{y^Tp}{y^Ts}.
\end{align}\\\\\]
&lt;/blockquote&gt;

&lt;p&gt;\(H\)가 k번의 BFGS update를 through, 얻이진다고 할when,, \(Hq= -H\nabla f(x)\)는 length k의 iteration문 2개to, computation할 수 있다 (아래 algorithm reference). 단, 메모리의 효율적인 사용을 for, 가장 최근 $m$개 iterationsat,의 curvature information만을 이용한다. (\(k \ge m\))&lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter18/algorithm_quasi-newton.png&quot; alt=&quot;[Fig1] The algorithm of LBFGS [3]&quot; width=&quot;90%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] The algorithm of LBFGS [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;usually, inverse Hessian approximation \(H_k\)는 dense하며, variable의 개수가 많은 case, 저장 및 operation 비용이 매우 높아지게 된다. 반면 LBFGS는 \(H_k \nabla f_k\)을 연속한 vectorsumand, vectorproductwith, obtaining,냄with,써 \(H_k\)의 computation 및 유지를 위한 비용problem를 완화시킬 수 있다. 뿐만 아니라 이 computationto, 사용되는 initial Hessian approximation \(H^{0,k}\)는 usually, (실전at, 매우 effect,적with, 작동한다고 검증된) identity matrixto, 어떤 constant를 product한 형태(\(H^{0,k} = \gamma_k I\))를 띄기 because of, 유지 및 computationto, 그다지 큰 비용이 발생하지 않는다 ([14]의 7.2).&lt;/p&gt;
&lt;blockquote&gt;
\[H^{0,k} = \gamma_k I, \\\\
\text{where } \: \gamma_k = \frac{s^T_{k-1}y_{k-1}}{y^T_{k-1}y_{k-1}}.\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; \(H^{0,k}\)는 매 iteration마다 다르게 선택될 수 있다.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>18-06 Superlinear convergence</title>
   <link href="http://localhost:4000/contents/en/chapter18/18_06_Superlinear_convergence/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter18/18_06_Superlinear_convergence</id>
   <content type="html">&lt;h3 id=&quot;assumption1&quot;&gt;Assumption1:&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;The Hessian matrix \(G\) is Lipschitz continuous at \(x^∗\), that is, 
\(\| G(x) − G(x^∗)  \le L \| x − x^∗ \|,\)
for all \(x\) near \(x^∗\), where \(L\) is a positive constant.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;assumption2-wolfe-conditions&quot;&gt;Assumption2: Wolfe conditions&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Assume \(t\) is chosen (via backtracking) so that
\(f(x + tp) \le f(x) + \alpha_1 t \nabla f(x)^T p\)
and
\(\nabla f(x + tp)^T p \ge \alpha_2 \nabla f(x)^T p\)
for \(0 &amp;lt; \alpha_1 &amp;lt; \alpha_2 &amp;lt; 1.\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;The first condition of Wolfe conditions ensures that too large a \(t\) is not selected.&lt;/li&gt;
  &lt;li&gt;The second condition of Wolfe conditions ensures that too small a \(t\) is not selected.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DFP and BFGS show superlinear convergence under the above two assumptions. (reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Rate_of_convergence&quot;&gt;Rate of convergence in Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;blockquote&gt;
\[\lim_{k \rightarrow \infty} \frac{ \| x^{k+1} - x^\ast \| }{ \| x^k - x^\ast \| } = 0.\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;theorem-dennis-moré&quot;&gt;Theorem (Dennis-Moré)&lt;/h2&gt;

&lt;p&gt;다음은 Quasi-Newton method의 search direction이 Newton direction을 충분히 잘 approximation하고 있을when,, solutionwith, convergence하는 processat, step length가 Wolfe conditions를 만족함을 보인다. Superlinear convergence를 보이기 for, search direction이 만족solution야하는 condition,이라고도 할 수 있다 [14].&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f\)가 두 번 미분 가능하고 \(x^k \rightarrow x^\ast\) s.t. \(\nabla f(x^\ast) = 0\)이며 \(\nabla^2 f(x^\ast)\)가 positive definite이라고 let’s assume.&lt;/p&gt;

\[\lim_{k \rightarrow \infty} \frac{\| \nabla f(x^k) + \nabla^2 f(x^k) p^k \| }{\| p^k \|} = 0.\]

  &lt;p&gt;if, search direction \(p^k\)가 위 condition,을 만족하면, 다음 두 가지 항목을 만족하는 \(k_0\)가 존재한다.&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;\(k \ge k_0\)about, step length \(t_k=1\)은 Wolfe conditions를 만족한다.&lt;/li&gt;
    &lt;li&gt;if, \(k \ge k_0\)about, \(t_k = 1\)이면 \(x^k \rightarrow x^\ast\)는 superlinear convergence를 보인다.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>18-05 The Broyden Class</title>
   <link href="http://localhost:4000/contents/en/chapter18/18_05_The_Broyden_Class/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter18/18_05_The_Broyden_Class</id>
   <content type="html">&lt;p&gt;The Broyden class generalizes BFGS, DFP, and SR1 with the following formula.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; \(B^+_{\text{BFGS}}\)and, \(B^+_{\text{DFP}}\)는 각각 BFGSand, DFPby, 유도되는 \(B^+\)다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[B^+ = (1 - \phi)B^+_{\text{BFGS}} + \phi B^+_{\text{DFP}}, \text{ for } \phi \in \mathbb{R}.\]
&lt;/blockquote&gt;

&lt;p&gt;\(v\)를 \(\frac{y}{y^Ts} - \frac{Bs}{s^TBs}\)to, 정의하면 위 공식은 아래and, 같이 정리된다.&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = B - \frac{Bss^TB}{s^TBs} + \frac{yy^T}{y^Ts} + \phi(s^TBs)vv^T.\]
&lt;/blockquote&gt;

&lt;p&gt;Observe:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\phi =0\)일when,, 위 update는 BFGSand, 동일solution진다.&lt;/li&gt;
  &lt;li&gt;\(\phi =1\)일when,, 위 update는 DFPand, 동일solution진다.&lt;/li&gt;
  &lt;li&gt;\(\phi = \frac{y^Ts}{y^Ts - s^TBs}\)일when,, 위 update는 SR1and, 동일solution진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;*reference&lt;/strong&gt;: \(\phi\)의 범위를 \([0,1]\)to, 제한한 특수한 case,를 restricted Broyden class라 부른다 [14].&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>18-04 Broyden-Fletcher-Goldfarb-Shanno (BFGS) update</title>
   <link href="http://localhost:4000/contents/en/chapter18/18_04_Broyden_Fletcher_Goldfarb_Shanno_(BFGS)_update/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter18/18_04_Broyden_Fletcher_Goldfarb_Shanno_(BFGS)_update</id>
   <content type="html">&lt;p&gt;The idea of BFGS is the same as DFP. The only difference is that the roles of B and H are reversed.&lt;/p&gt;

&lt;p&gt;BFGS is derived by solving the following problem.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Solve
\(\begin{align}
&amp;amp; \min_{H^+} \: \: &amp;amp;&amp;amp; {\|W^{1/2} (H^+ - H) W^{1/2} \|_F} \\\\
&amp;amp; \text{subject to } &amp;amp;&amp;amp; {H^+ = (H^+)^T} \\\\
&amp;amp;&amp;amp;&amp;amp; {H^+s = y}  \\\\
&amp;amp; \text{where } &amp;amp;&amp;amp; W \in \mathbb{R}^{n \; \times \;n} \text{ is nonsingular and such that } Ws_k = y_k.
\end{align}\\\\\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The derived updating formulas for \(H\) and \(B\) are as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = B - \frac{Bss^TB}{s^TBs} + \frac{yy^T}{y^Ts}\]
&lt;/blockquote&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
H^+ &amp;amp;= H + \frac{(s-Hy)s^T}{y^Ts} + \frac{s(s-Hy)^T}{y^Ts} - \frac{(s-Hy)^Ty}{(y^Ts)^2} ss^T\\\\
&amp;amp;= \big( I - \frac{sy^T}{y^Ts} \big) H \big( I - \frac{ys^T}{y^Ts} \big) + \frac{ss^T}{y^Ts} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;BFGS also, DFP처럼 positive definiteness를 유지한다. (if, \(B\)가 positive definite이고 \(s^Ty &amp;gt; 0\)이면 \(B^+\)는 positive definite이다.)&lt;/p&gt;

&lt;p&gt;BFGS의 특장점은 self-correcting property를 지니고 있다는 것이다. if, matrix \(H\)가 부정확하게 추정되어 iteration의 속도가 느려지게 되면 Hessian approximation이 단 몇 step 만to, 이를 바to,잡는 경향성을 보인다. 반면 DFP는 잘못된 Hessian approximation의 추정about, effect,적with, 바to,잡지 못하므to, 실전at,는 usually, BFGS의 성능이 더 좋은 편이다 [14].&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>18-03 Davidon-Fletcher-Powell (DFP) Update</title>
   <link href="http://localhost:4000/contents/en/chapter18/18_03_Davidon_Fletcher_Powell_(DFP)_Update/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter18/18_03_Davidon_Fletcher_Powell_(DFP)_Update</id>
   <content type="html">&lt;p&gt;The DFP update is a method that updates \(H (=B^{-1})\) with a rank-2 symmetric matrix.&lt;/p&gt;

&lt;blockquote&gt;
\[H^+ = H + auu^T + bvv^T.\]
&lt;/blockquote&gt;

&lt;p&gt;If \(H^+\) computed through the DFP update satisfies the secant equation, then \(s-Hy\) can be expressed as a linear combination of \(u\) and \(v\). (reference: by the secant equation, \(B^+ s =y \Leftrightarrow H^+ y = s\))&lt;/p&gt;

&lt;blockquote&gt;
\[H^+y = Hy + auu^Ty + bvv^Ty = Hy + (au^Ty)u + (bv^Ty)v = s\]

\[\Rightarrow s - Hy = (au^Ty)u + (bv^Ty)v\]
&lt;/blockquote&gt;

&lt;p&gt;Setting \(u=s, v=Hy\) and solving for \(a\) and \(b\), we derive the updating formula for \(H\).&lt;/p&gt;
&lt;blockquote&gt;
\[H^+ = H - \frac{Hyy^TH}{y^THy} + \frac{ss^T}{y^Ts}\]
&lt;/blockquote&gt;

&lt;p&gt;Similar to the SR1 update, we can derive the updating formula for \(B\) using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula&quot;&gt;Sherman–Morrison formula&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
B^+ &amp;amp;= B + \frac{(y-Bs)y^T}{y^Ts} + \frac{y(y-Bs)^T}{y^Ts} - \frac{(y-Bs)^Ts}{(y^Ts)^2} yy^T\\\\
&amp;amp;= \big( I - \frac{ys^T}{y^Ts} \big) B \big( I - \frac{sy^T}{y^Ts} \big) + \frac{yy^T}{y^Ts} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If \(B\) is positive definite, then \(\big( I - \frac{ys^T}{y^Ts} \big) B \big( I - \frac{sy^T}{y^Ts} \big)\) becomes positive semidefinite. In this case, if \(\frac{yy^T}{y^Ts}\) is positive definite, then \(B^+ = \big( I - \frac{ys^T}{y^Ts} \big) B \big( I - \frac{sy^T}{y^Ts} \big) + \frac{yy^T}{y^Ts}\) is guaranteed to be positive definite. This solves the problem of maintaining positive definiteness that was raised with SR1.&lt;/p&gt;

&lt;h2 id=&quot;dfp-update---alternate-derivation&quot;&gt;DFP Update - Alternate Derivation&lt;/h2&gt;

&lt;p&gt;Recall: if the curvature condition (\(y^Ts &amp;gt; 0, y,s \in \mathbb{R}^n\)) is satisfied, then there exists a symmetric positive definite matrix that satisfies the secant equation.&lt;/p&gt;

&lt;p&gt;The DFP update can also be derived by solving the problem of minimizing the weighted Frobenius norm between matrix \(B^+\) and \(B\) where \(B^+\) 1. satisfies symmetry and 2. satisfies the secant equation. (Each different matrix norm corresponds to each different Quasi-Newton method. Among them, the norm that makes it easy to solve this problem while also making it work as a scale-invariant optimization method is the weighted Frobenius norm.)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Solve
\(\begin{align}
&amp;amp; \min_{B^+} \: \: &amp;amp;&amp;amp; {\|W^{1/2} (B^+ - B) W^{1/2} \|_F} \\\\
&amp;amp; \text{subject to } &amp;amp;&amp;amp; {B^+ = (B^+)^T} \\\\
   &amp;amp;&amp;amp;&amp;amp; {B^+s = y}  \\\\
&amp;amp; \text{where } &amp;amp;&amp;amp; W \in \mathbb{R}^{n \; \times \;n} \text{ is nonsingular and such that } Wy_k = s_k.
\end{align}\\\\\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;*reference&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Frobenius norm: The Frobenius norm of matrix \(A\) is defined as follows.
\(\| A \|_{F}  \doteq ( \sum_{i,j} A_{i,j}^2 )^{1/2}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Weighted Frobenius norm: The weighted Frobenius norm of matrix \(A\) with weight matrix \(W(W \succ 0)\) is defined as follows. 
\(\|A\|_W \doteq \| W^{1/2} A W^{1/2} \|_F\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>18-02 Symmetric Rank-One Update (SR1)</title>
   <link href="http://localhost:4000/contents/en/chapter18/18_02_Symmetric_Rank_One_Update_(SR1)/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter18/18_02_Symmetric_Rank_One_Update_(SR1)</id>
   <content type="html">&lt;p&gt;The SR1 update is a method that updates \(B\) with a rank-1 symmetric matrix so that \(B^+\) maintains symmetry and continues to satisfy the secant equation. If a rank-1 symmetric matrix is decomposed as a product of \(a \in \left\{-1, 1\right\}\) and \(u \in \mathbb{R^n}\), the update form would be as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = B + auu^T.\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;key-observation&quot;&gt;Key Observation&lt;/h2&gt;
&lt;p&gt;\(a\) and \(u\) must be chosen so that \(B^+\) satisfies the secant equation. Thus, let’s substitute the update form introduced above into the secant equation \(y = B^+s\).&lt;/p&gt;

&lt;blockquote&gt;
\[y = B^+s \Rightarrow y = Bs + (au^Ts)u. \quad \text{--- (1)}\]
&lt;/blockquote&gt;

&lt;p&gt;Since \((au^Ts)\) is a scalar, \(u\) can also be expressed as a product of \(y-Bs\) and an arbitrary scalar \(\delta\) \(\big( u = \delta(y - Bs) \big)\). Let’s substitute \(u\) in (1) with \(\delta(y - Bs)\).&lt;/p&gt;

&lt;blockquote&gt;
\[y-Bs = a\delta^2 \big[ s^T(y - Bs) \big] (y -Bs),\]
&lt;/blockquote&gt;

&lt;p&gt;The parameters \(\delta\) and \(a\) that satisfy the above equation are as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[a = \text{sign} \big[ s^T (y - Bs) \big], \quad \delta = \pm | s^T(y-Bs) |^{-1/2}. \quad \text{--- (2)}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-only-sr1-updating-formula&quot;&gt;The Only SR1 Updating Formula&lt;/h2&gt;
&lt;p&gt;Using the information obtained from the key observation, we can derive the unique form of SR1 update ([14] section 6.2). &lt;br /&gt;
\(\big( u = \delta (y - Bs)\) and substituting (2) into \(B^+ = B + auu^T\). \(\big)\)&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = B + \frac{(y-Bs)(y-Bs)^T}{(y-Bs)^Ts}.\]

&lt;/blockquote&gt;

&lt;h2 id=&quot;the-update-formula-for-the-inverse-hessian-approximation&quot;&gt;The Update Formula for the Inverse Hessian Approximation&lt;/h2&gt;

&lt;p&gt;To find \(x^+\), we need to compute \(B^{-1}\).&lt;/p&gt;

&lt;blockquote&gt;
\[x^+ = x + tp = x - tB^{-1}\nabla f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;If we can update \(B^{-1}\) instead of \(B\), wouldn’t we be able to reduce the cost of computing \(B^{-1}\) every time?&lt;/p&gt;

&lt;p&gt;Using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula&quot;&gt;Sherman–Morrison formula&lt;/a&gt;, we can see through the derivation process that \(B^{-1}\) can also be updated in the same form. (\(H = B^{-1}\))&lt;/p&gt;

&lt;blockquote&gt;
\[H^+ = H + \frac{(s-Hy)(s-Hy)^T}{(s-Hy)^Ty}.\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;shortcomings-of-sr1&quot;&gt;Shortcomings of SR1&lt;/h2&gt;

&lt;p&gt;SR1 has the advantage of being very simple, but it has two critical shortcomings.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The update can fail when \((y-Bs)^Ts\) approaches 0.&lt;/li&gt;
  &lt;li&gt;It cannot maintain the positive definiteness of \(B\) and \(H\).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The following sections introduce methods that complement the shortcomings of SR1.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>18-01 Secant Equation and Curvature Condition</title>
   <link href="http://localhost:4000/contents/en/chapter18/18_01_Secant_Equation_and_Curvature_Condition/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter18/18_01_Secant_Equation_and_Curvature_Condition</id>
   <content type="html">&lt;h2 id=&quot;secant-equation&quot;&gt;Secant Equation&lt;/h2&gt;
&lt;p&gt;As mentioned earlier, \(B\) is a matrix that approximates \(\nabla^2 f(x)\). For matrix \(B\) to have similar properties to the Hessian \(\nabla^2 f(x)\), it must satisfy a condition called the secant equation. When \(x^{k+1} = x^k + s^k\) and \(f\) is twice differentiable, the first-order Taylor expansion of \(\nabla f(x^k + s^k)\) shows that the true Hessian has the following property.&lt;/p&gt;

&lt;blockquote&gt;
\[\nabla f(x^k + s^k)  \approx \nabla f(x^k) + \nabla^2 f(x^k) s^k\]
&lt;/blockquote&gt;

&lt;p&gt;Here, we call the approximation matrix of \(\nabla^2 f(x^k)\) as \(B^{k+1}\). This matrix satisfies the following equation.&lt;/p&gt;

&lt;blockquote&gt;
\[\nabla f(x^k + s^k)  = \nabla f(x^k) + B^{k+1} s^k\]
&lt;/blockquote&gt;

&lt;p&gt;If \(x^{k+1} = x^k + s^k, y^k = \nabla f(x^{k + 1})  - \nabla f(x^k)\), then the above equation can be rearranged as follows, and this is called the secant equation.&lt;/p&gt;

&lt;blockquote&gt;
\[B^{k+1} s^k = y^k\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-intuition-of-secant-equation&quot;&gt;The Intuition of Secant Equation&lt;/h2&gt;

&lt;p&gt;\(x\)axis은 \(x^k\)를, \(y\)axis은 \(\nabla f(x^k)\)를 나타낸다고 할when, \(B^{k+1}\)은 \((x^k, \nabla f(x^k))\)and, \((x^{k+1}, \nabla f(x^{k+1}))\)를 통and,하는 직선의 기울기and, 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter18/intuition_of_secant_eq.png&quot; alt=&quot;[Fig1] The intuition of secant equation&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] The intuition of secant equation&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;conditions-to-determine-b&quot;&gt;Conditions to Determine \(B^+\)&lt;/h2&gt;
&lt;p&gt;matrix \(B\)를 basis,with, computation된 \(B^+\)는 다음의 3가지 condition,을 만족solution야한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(B^+\) is symmetric: Because it is an approximation of the Hessian.&lt;/li&gt;
  &lt;li&gt;\(B^+\) close to \(B\): A condition to determine a unique \(B^+\). Since \(B\) already contains useful information, we choose the matrix closest to \(B\) among those \(B^+\) that satisfy the secant equation.&lt;/li&gt;
  &lt;li&gt;\(B\) is positive definite \(\Rightarrow B^+\) is positive definite: To guarantee global optimum, we maintain the convexity of the problem. (reference: &lt;a href=&quot;https://web.stanford.edu/group/sisl/k12/optimization/MO-unit4-pdfs/4.10applicationsofhessians.pdf&quot;&gt;Analyzing the hessian&lt;/a&gt;)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;curvature-condition&quot;&gt;Curvature Condition&lt;/h2&gt;
&lt;p&gt;The fact that \(B^+\) is positive definite and \(B^+ s = y\) implies the following fact.&lt;/p&gt;
&lt;blockquote&gt;
\[s^T y = s^T B^+ s &amp;gt; 0.\]
&lt;/blockquote&gt;

&lt;p&gt;(reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Positive-definite_matrix&quot;&gt;positive definite in WikiPedia&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Here, \(s^T y &amp;gt; 0\) is called the curvature condition. If the curvature condition is satisfied, the secant equation \(B^+ s = y\) always has a solution (\(B^+\)).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>18-00 Quasi-Newton methods</title>
   <link href="http://localhost:4000/contents/en/chapter18/18_00_Quasi_Newton_methods/"/>
   <updated>2021-03-23T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter18/18_00_Quasi_Newton_methods</id>
   <content type="html">&lt;p&gt;In the mid-1950s, physicist W.C. Davidon, who was working at Argonne National Laboratory, was solving optimization problems with large computational requirements using coordinate descent methods. Unfortunately, due to the instability of computers at the time, system crashes frequently occurred before computations could be completed, and frustrated by this, Davidon decided to find methods that could improve computational speed. This led to the birth of the first Quasi-Newton algorithm. This became a catalyst for dramatic progress in nonlinear optimization, and subsequently, various follow-up studies on this method emerged over the next 20 years.&lt;/p&gt;

&lt;p&gt;Ironically, &lt;a href=&quot;http://www.math.mcgill.ca/dstephens/680/Papers/Davidon91.pdf&quot;&gt;Davidon’s research&lt;/a&gt; was not published at the time and remained as a technical report for more than 30 years. It was finally published in the &lt;a href=&quot;https://epubs.siam.org/toc/sjope8/1/1&quot;&gt;first issue of SIAM Journal on Optimization&lt;/a&gt; in 1991.&lt;/p&gt;

&lt;p&gt;Quasi-Newton methods require only the gradient of the objective function at each iteration. This has much less computational burden than Newton methods that require second derivatives, and moreover shows superlinear convergence, making it a sufficiently attractive method [14].&lt;/p&gt;

&lt;h2 id=&quot;motivation-for-quasi-newton-methods&quot;&gt;Motivation for Quasi-Newton methods&lt;/h2&gt;

&lt;p&gt;Consider the following unconstrained, smooth optimization problem:&lt;/p&gt;
&lt;blockquote&gt;
\[\min_x \: f(x), \\\\
\text{where } f \text{ is twice differentiable, and } dom \; f = \mathbb{R}^n.\]
&lt;/blockquote&gt;

&lt;p&gt;The update methods for x in Gradient descent method and Newton’s method for the above problem are as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Gradient descent method:&lt;/strong&gt;
\(x^+ = x - t \nabla f(x)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Newton’s method:&lt;/strong&gt;
\(x^+ = x - t \nabla^2 f(x)^{-1} \nabla f(x)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Newton’s method has the advantage of showing quadratic convergence rate (\(O(\log \log 1/ \epsilon)\)), but there are problems with significantly high computational costs in the following two processes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Computing the Hessian \(\nabla^2 f(x)\): Computing and storing the Hessian matrix requires \(O(n^2)\) memory. This is not suitable performance for handling high-dimensional functions. (reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Hessian_matrix#Use_in_optimization&quot;&gt;Hessian matrix&lt;/a&gt; in Wikipedia)&lt;/li&gt;
  &lt;li&gt;Solving the equation \(\nabla^2 f(x) p = -\nabla f(x)\): To solve this equation, we must compute the inverse matrix of the Hessian \(\nabla^2 f(x)\). (reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations#Matrix_algebra&quot;&gt;Computational complexity of Matrix algebra&lt;/a&gt; in Wikipedia)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quasi-Newton methods use an approximation \(B\) instead of \(\nabla^2 f(x)\).&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Quasi-Newton method:&lt;/strong&gt;
\(x^+ = x + tp \\\\
\text{where } Bp = -\nabla f(x).\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, B should be easy to compute, and it should also be easy to solve the equation \(Bp = g\).&lt;/p&gt;

&lt;h2 id=&quot;quasi-newton-algorithm&quot;&gt;Quasi-Newton Algorithm&lt;/h2&gt;
&lt;p&gt;The Quasi-Newton algorithm is as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pick initial \(x^0\) and \(B^0\)&lt;/li&gt;
  &lt;li&gt;For \(k = 0, 1, \dots\)
    &lt;ul&gt;
      &lt;li&gt;Solve \(B^k p^k = - \nabla f(x^k)\)&lt;/li&gt;
      &lt;li&gt;Pick \(t_k\) and let \(x^{k+1} = x^{k} + t_k p^k\)&lt;/li&gt;
      &lt;li&gt;Update \(B^k\) to \(B^{k+1}\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;End for&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A major characteristic of this method is updating \(B\) so that we can gradually approach the optimal point. That is, the method of obtaining the next step \(B^+\) from \(B\) will be the main topic of discussion in this chapter. (&lt;strong&gt;Note:&lt;/strong&gt; For convenience, we will use the two notations \(B^{k+1}, B^k\) and \(B^+, B\) interchangeably.)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>10 Duality in Linear Programs</title>
   <link href="http://localhost:4000/contents/vi/chapter10/10_Duality_in_Linear_Programs/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter10/10_Duality_in_Linear_Programs</id>
   <content type="html">&lt;p&gt;Starting from this chapter, we will examine duality, which plays a significant role in optimization theory.
From an optimization perspective, duality can be simply described as the concept that a single optimization problem can be viewed from two perspectives: the primal problem and the dual problem.&lt;/p&gt;

&lt;p&gt;In this chapter, we specifically explore duality in linear programs.
Rather than directly applying it to general convex problems, we will derive the dual problem from the primal problem by applying it to linear programs, and organize how the relationship between these two problems is established and what properties they have under specific conditions.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>10-05 Matrix Games</title>
   <link href="http://localhost:4000/contents/vi/chapter10/10_05_Matrix_Games/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter10/10_05_Matrix_Games</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In this chapter, we examine mixed strategies for matrix games, which is an example of primal LP and dual LP in game theory. The setup assumes two players, J and R, and a payout matrix \(P\).&lt;/p&gt;

&lt;h2 id=&quot;game-setup&quot;&gt;Game Setup&lt;/h2&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter10/matrix_game.png&quot; alt=&quot;Line Segment&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Game Setup[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;The payout matrix is the amount of reward J must give to R when J chooses strategy \(i\) (row) and R chooses strategy \(j\) (column) (\(P_{ij}\)). However, if this value is positive, J gives R a reward equal to the size of the corresponding matrix, and if negative, R gives J a reward equal to the size of the corresponding matrix.&lt;/p&gt;

&lt;p&gt;This setting is also called a zero-sum setting, where if the reward R will receive or must pay is \(r_{R}\) and J’s reward is \(r_{J}\), then in each game the result of the rewards is \(r_{R} = - r_{J}\), and the total sum of the two rewards is always 0.&lt;/p&gt;

&lt;p&gt;Also, we assume that both players use mixed strategies. Mixed strategies is the assumption that each player’s choice follows a specific probability distribution (or is sampled from a specific probability distribution).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x : P(\text{J chooses i}) = x_{i}, \qquad i=1,...m\\\\
y : P(\text{R chooses j}) = y_{j}, \qquad j=1,...n.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If they know each other’s mixed strategy, i.e., probability distribution, each player can calculate the payout they expect to get, i.e., the expected payout.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\sum_{i=1}^{m}\sum_{j=1}^{n}x_{i}y_{j}P_{ij} = x^{T}Py.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Considering that the sign of the payout matrix is defined as the amount J gives to R, J will try to minimize this expected payout because J wants to give as little as possible to R, and R will try to maximize this expected payout because R wants to receive as much as possible from J.&lt;/p&gt;

&lt;p&gt;이제 두 player의 입장에서 각자가 상대의 mixed strategy를 고려하여, 이 expected payout을 최대화(R의 입장) 혹은 최소화(J의 입장)하려는 관점을 살펴보고, 서로가 서로를 optimal하게 행동하는 전제하에, 두 입장에서 유도되는 optimal strategy를 구하고, 결과적으론 Von Neumman’s minimax theorem에 의해 두 결과가 같다는 것을 확인할 것이다.&lt;/p&gt;

&lt;h2 id=&quot;minimizing-expected-payout--js-perspective&quot;&gt;Minimizing Expected Payout : J’s Perspective&lt;/h2&gt;
&lt;p&gt;먼저 R이 J의 strategy \(x\)를 알고 있다고 가정하자. R은 expected payout \(x^{T}Py\)를 maximize하고자 할 것이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\max\{x^{T}Py : y\geq0, 1^{T}y = 1\} = \max_{i=1,...n}(P^{T}x)_{i}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이때 R은 식의 내용처럼 \((P^{T}x)_{i}\) 중 가장 큰 값을 갖는 i(row index)를 찾게되고, 이 i에 대응되는 \(y_{i}\)를 1로 가지고 나머지의 row index에 대해선 0을 가지는 strategy가 R에게 있어서 expected payout을 maximize하는 strategy일 것이다.&lt;/p&gt;

&lt;p&gt;R이 위처럼 최적으로 행동할 것을 알고 있을 때, J의 최적의 strategy는 밑의 식을 만족하는 distribution \(x\)일 것이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \min_{x}
&amp;amp; &amp;amp;\max_{i=1,...n} (P^{T}x)_{i}\\\\
&amp;amp; \text{subject to}
&amp;amp; &amp;amp; x\geq 0, 1^{T}x =1.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Convex function의 maximization 또한 convex function이 된다.  이를 첫 번째 관점의 문제 정의라고 칭할 것이다. 또한 이 최적화 문제의 해를 optimal expected payout \(f^{*}_{1}\)이라고 정하자. 또 하나 유념할 점은 게임참가자, 즉 player들이 모두 최적으로 행동한다는 가정이 기본적인 형태의 게임이론 formulation에서 가정이 된다.&lt;/p&gt;

&lt;h2 id=&quot;maximizing-expected-payout--rs-perspective&quot;&gt;Maximizing Expected Payout : R’s Perspective&lt;/h2&gt;
&lt;p&gt;두 번째 관점으로 J가 R의 strategy \(y\)를 알고 있다고 가정하자. J는 expected payout을 minimize하고자 할 것이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min \{x^{T}Py : x\geq0, 1^{T}x = 1\} = \min_{j=1,...n}(Py)_{j}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;같은 논리로, J가 위처럼 최적으로 행동할 것을 알고 있을 때 R의 최적의 strategy는 밑의 식을 만족하는 distribution \(y\)이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \max_{y}  
&amp;amp; &amp;amp; \min_{j=1,...m} (Py)_{j}\\\\
&amp;amp;\text{subject to}
&amp;amp; &amp;amp;y\geq 0, 1^{T}y =1.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;위와 마찬가지로 이를 두 번째 관점의 문제 정의라고 칭하고, 이 최적화 문제의 해를 \(f^{*}_{2}\) 라고 하자. player R이 이 expected payout을 maximize하고자 하기 때문에, 첫 번째, 즉, R이 J의 strategy를 미리 알고 있다는 가정 하에 결정되는 expected payout \(f^{*}_{1}\)이 두 번째 가정보다 더 크거나 같은 값을 가질 것이라 쉽게 예상할 수 있다. (\(f^{*}_{1}\geq f^{*}_{2}\))&lt;/p&gt;

&lt;h2 id=&quot;von-neumanns-minimax-theorem&quot;&gt;Von Neumann’s minimax theorem&lt;/h2&gt;
&lt;p&gt;하지만,  Von Neumann’s minimax theorem에 따르면 \(f^{*}_{1} = f^{*}_{2}\)가 된다. 실제 minimax theorem은 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{Let } X\subset \mathbb{R}^{N} \text{ and }Y\subset \mathbb{R}^{m} \text{ be compact convex sets. }\\\\
&amp;amp;\text{If } f:X\times Y\rightarrow \mathbb{R} \text{ is a continuous function that is convex-concave, i.e.}\\\\
&amp;amp;\qquad f(\cdot, y): X\rightarrow\mathbb{R} \text{ is convex for fixed }y, \text{ and}\\\\
&amp;amp;\qquad f(x, \cdot): Y\rightarrow\mathbb{R} \text{ is concave for fixed }x.\\\\
&amp;amp;\text{Then we have that} \\\\ 
&amp;amp;\min_{x\in X} \max_{y\in Y} f(x,y) = \max_{y\in Y} \min_{x\in X} f(x,y).\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;해당 내용의 증명은 생략한다.&lt;/p&gt;

&lt;h2 id=&quot;proof-of-each-perspective-having-primal-and-dual-relationship&quot;&gt;Proof of each perspective having Primal and Dual relationship&lt;/h2&gt;
&lt;p&gt;이제 위 두 가지 관점의 경우에 대한 expected payout이 LP 문제로써 서로 primal, dual 관계이고, Von Neumman’s minimax theorem에 의하여 두 결과가 같다는 점을 이용하여, strong duality를 만족함을 보이고자 한다.&lt;/p&gt;

&lt;p&gt;먼저 첫 번째 관점의 문제를 다음과 같이 reformulate 할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \min_{x} \max_{i=1,...m} 
&amp;amp; &amp;amp;(P^{T}x)_{i}\\\\
&amp;amp;\text{subject to } 
&amp;amp; &amp;amp;x\geq 0, 1^{T}x = 1\\\\
\end{align}\]

\[\begin{align}
\Leftrightarrow{} \\\\
&amp;amp; \min_{x,t}
&amp;amp; &amp;amp; t \\\\
&amp;amp;\text{subject to } 
&amp;amp; &amp;amp;x\geq0, 1^{T}x = 1, P^{T}x \preceq t. \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(t\)를 \(P^{T}x\)의 항들 중 가장 큰 값과 같게 만들어주는 문제로 reformulate 하였다.&lt;/p&gt;

&lt;p&gt;이제 여기에 앞서 배운 duality의 두 번째 방법인 Lagrangian을 구하고,  Lagrange dual function \(g\)를 구하면,&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;L(x, t, u, v, y) &amp;amp;&amp;amp;= t-u^{T}x+v(1-1^{T}x)+y^{T}(P^{T}x-t1)\\\\
&amp;amp;g(u, v, y) &amp;amp;&amp;amp;= \min_{x,t} \quad L(x, t, u, v, y)\\\\
&amp;amp;&amp;amp;&amp;amp;= \begin{cases} v \qquad &amp;amp;\text{if } 1-1^{T}y = 0, Py-u-v1=0\\\\
-\infty \qquad &amp;amp;\text{otherwise.} \end{cases}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(u\)는 slack variable이므로, 이를 제거하고 식을 정리하면 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{y,v} \qquad \quad &amp;amp;&amp;amp; v\\\\
&amp;amp;\text{subject to }\quad &amp;amp;&amp;amp; y\geq0, 1^{T}y = 1\\\\
&amp;amp;&amp;amp;&amp;amp; Py\geq v.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이는 두 번째 관점의 문제의 primal LP이다. 따라서 두 관점은 dual 관계에 있고 두 문제의 optimal value는 같으므로, strong duality가 성립한다.&lt;/p&gt;

&lt;p&gt;일반적으로 LP문제에서는, 향 후의 내용에서 다루지만, primal과 dual 중 하나만 feasible하다면 strong duality가 성립한다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>10-04 Another Perspective on LP duality</title>
   <link href="http://localhost:4000/contents/vi/chapter10/10_04_Another_Perspective_on_LP_duality/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter10/10_04_Another_Perspective_on_LP_duality</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In the case of duality discussed earlier, for LP, we multiplied the constraints of the primal problem by dual variables, obtained their linear combination, and then organized it to separate out the primal’s objective function to obtain a bound. The separated remaining terms (something in the formula below) served as the bound for the primal problem. That is, they became the objective function of the dual problem, and the conditions created during the formula development process became the constraints of the dual problem.
Writing this partial process (the part of the above content that separates out the primal objective function to obtain a bound) as a formula, it looks like this:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x)\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;Ax = b\\\\
&amp;amp; &amp;amp;&amp;amp;Gx \leq h\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;\text{for any }u,\, v\geq 0,\\\\
&amp;amp; &amp;amp;u^{T}(Ax-b) = 0\\\\
&amp;amp;{+} &amp;amp;v^{T}(Gx-h)\leq 0\\\\
&amp;amp;{=} &amp;amp;u^{T}(Ax-b) + v^{T}(Gx-h)\leq 0\\\\
&amp;amp;{\approx} &amp;amp;f(x)+\text{something}. \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;However, for optimization problems that are not linear programs, most cannot express the objective function as a linear combination of constraints.&lt;/p&gt;

&lt;p&gt;In this chapter, we examine the perspective of duality that is applicable to more universally common problems (all convex, most non-convex). We will find the duality of LP using this method called Lagrangian, and examine more detailed discussions in Chapter 11.&lt;/p&gt;

&lt;p&gt;Looking at the equations up to the linear combination form for the primal LP problem described above, we can understand the following relationship:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
c^{T}x\geq c^{T}x+\overbrace{u^{T} \underbrace{(Ax-b)} _ {=0}+\underbrace{v^{T}} _ {\geq 0} \underbrace{(Gx-h)} _ {\leq 0}} ^ {\leq 0} := L(x,u,v).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The right side of the inequality has a value less than or equal to the left side according to the conditions. Also, we define this expression as a function \(L(x, u, v)\) for x, u, v.
Here, if we call the set satisfying the constraints of the primal LP (primal feasible set) C, we can understand the following relationship:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
C =  \{ x: Ax=b, Gx\leq h \},
\end{align}\)
\(\begin{align}
f^{*}=\min_{x\in C} f(x) \geq \min_{x\in C}L(x,u,v)\geq \min_{x}L(x,u,v):=g(u,v).\\\\
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In other words, \(g(u,v)\) becomes a lower bound of \(f^{*}\) for any u or \(v\) satisfying \(v\geq0\).
Let’s examine the lower bound value determined by \(g(u,v)\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
g(u,v) = min_{x} c^{T}x+u^{T}(Ax-b) + v^{T}(Gx-h) \\\\
= \min_{x} (c+A^{T}u+G^{T}v)^{T}x - b^{T}u-h^{T}v \\\\
\begin{cases}= -b^{T}u-h^{T}v \qquad &amp;amp;\text{if }\ c = -A^{T}u-G^{T}v \\\\
-\infty \qquad &amp;amp;\text{otherwise}.
\end{cases}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;As can be seen from the equation, when \(c = -A^{T}u-G^{T}v\) is not satisfied, it has a value of \(-\infty\) due to the \(x\) term.
Since we want to find the lower bound closest to \(f^{*}\), we want to find the value that maximizes \(g(u, v)\). This is \(-b^{T}u-h^{T}v\), the value when \(c = -A^{T}u-G^{T}v\) is satisfied, and this matches the Dual LP we obtained with the first method.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f^{*} \geq g(u,v), \qquad \text{provided } v \geq 0\\\\
\text{find the biggest lowerbound  } g(u,v)\\\\
\max_{u,v} g(u,v)\\\\
\text{s.t. }v \geq 0. 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This method is also applicable to other types of optimization problems that are not in LP form.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>10-03 Luồng cực đại và cắt cực tiểu</title>
   <link href="http://localhost:4000/contents/vi/chapter10/10_03_Max_flow_and_min_cut/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter10/10_03_Max_flow_and_min_cut</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Như một ví dụ về tính đối ngẫu trong chương trình tuyến tính, chúng ta muốn xem xét bài toán luồng cực đại cắt cực tiểu.&lt;/p&gt;

&lt;h2 id=&quot;đồ-thị-có-hướng-điều-kiện-của-luồng&quot;&gt;Đồ thị có hướng, Điều kiện của luồng&lt;/h2&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter10/max_flow.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Đồ thị có hướng[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Có một đồ thị có hướng \(G = (V, E)\) như được hiển thị ở trên, và đặt cạnh nối đỉnh i và đỉnh j, \((i,j)\in E\), tức là luồng từ i đến j, là \(f_{ij}\). Mỗi cạnh có một công suất, tức là luồng tối đa có thể chảy qua nó. Đặt đây là \(c_{ij}\).&lt;/p&gt;

&lt;p&gt;Như một ví dụ đơn giản, điều này có thể được hiểu như một biểu diễn đồ thị của một luồng nào đó từ một nguồn(s) chảy ra đến một đích(t). Đây là một dạng đồ thị có thể được áp dụng cho nhiều bài toán khác nhau như quy hoạch thoát nước đô thị/truyền tải điện, vận chuyển vật liệu, v.v.&lt;/p&gt;

&lt;p&gt;Ở đây, luồng thỏa mãn ba điều kiện.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(f_{ij}\) luôn là một số dương lớn hơn hoặc bằng 0: \(f_{ij} \geq 0,\, (i,j)\in E\)&lt;/li&gt;
  &lt;li&gt;\(f_{ij}\) phải nhỏ hơn luồng tối đa được xác định cho cạnh, tức là công suất (giới hạn công suất) \(c_{ij}\): \(f_{ij}&amp;lt;c_{ij}, \, (i,j)\in E\)&lt;/li&gt;
  &lt;li&gt;Đối với đỉnh k không bao gồm nguồn (điểm mà luồng ra, s) hoặc đích (điểm mà luồng vào, t), tổng lượng luồng vào k bằng tổng lượng luồng ra khỏi k: \(\sum_{(i,k)\in E}f_{ik} = \sum_{(k,j)\in E}f_{kj}, \, k\in V\backslash{s,t}\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;mối-quan-hệ-giữa-bài-toán-luồng-cực-đại-và-cắt-cực-tiểu1&quot;&gt;Mối quan hệ giữa bài toán Luồng cực đại và Cắt cực tiểu(1)&lt;/h2&gt;

&lt;p&gt;Đối với đồ thị và luồng được định nghĩa ở trên, chúng ta sẽ xem xét hai bài toán nổi tiếng, bài toán luồng cực đại và bài toán cắt cực tiểu, và mối quan hệ giữa chúng.&lt;/p&gt;

&lt;p&gt;Để kết luận trước, bài toán luồng cực đại là một bài toán LP, và bài toán cắt cực tiểu là một chương trình nguyên, trong đó đối ngẫu của bài toán luồng cực đại có cùng dạng bài toán như việc nới lỏng LP của bài toán cắt cực tiểu.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{Giá trị luồng cực đại} &amp;amp;\leq \text{LP đối ngẫu của luồng cực đại}\\
&amp;amp;= \text{Giá trị tối ưu cho cắt cực tiểu nới lỏng LP}\\
&amp;amp;\leq \text{Công suất của cắt cực tiểu}\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Trong trang này, chúng ta sẽ chỉ ra mối quan hệ bất đẳng thức bằng quá trình ngược của đối ngẫu và nới lỏng (thêm ràng buộc vào bài toán LP để chuyển đổi nó thành chương trình nguyên). Mặc dù không được đề cập ở đây, trên thực tế, cả ba kết quả đều bằng nhau.&lt;/p&gt;

&lt;p&gt;Điều này được gọi là định lý luồng cực đại cắt cực tiểu, nói rằng luồng tối đa trong một mạng bằng công suất tối thiểu của một cắt.&lt;/p&gt;

&lt;p&gt;Tổng quát hơn, dưới một số điều kiện nhất định, các giá trị tối ưu của các bài toán nguyên thủy và đối ngẫu bằng nhau, điều này được gọi là tính đối ngẫu mạnh.&lt;/p&gt;

&lt;p&gt;Trong các bài toán LP, ngoại trừ trường hợp mà cả bài toán nguyên thủy và đối ngẫu đều không khả thi, tính đối ngẫu mạnh được giữ. Điều này sẽ được thảo luận trong Chương 11.&lt;/p&gt;

&lt;p&gt;Đầu tiên, hãy xem xét hai bài toán, suy ra đối ngẫu từ bài toán luồng cực đại, và chỉ ra rằng bằng cách thêm các điều kiện cụ thể vào bài toán đối ngẫu (ngược lại của nới lỏng), nó biến đổi thành bài toán cắt cực tiểu.&lt;/p&gt;

&lt;h2 id=&quot;bài-toán-luồng-cực-đại&quot;&gt;Bài toán luồng cực đại&lt;/h2&gt;

&lt;p&gt;Bài toán luồng cực đại là tìm luồng tối đa từ s đến t trong một đồ thị thỏa mãn các điều kiện trên.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{f\in {\mathbb{R}^{|E|}}} &amp;amp;&amp;amp;{\sum_{(s,j)\in E} f_{sj}}\\
&amp;amp;\text{với điều kiện} &amp;amp;&amp;amp;{f_{ij}\geq 0,\,f_{ij}\leq c_{i,j}\,\, \text{với mọi }(i, j)\in E}\\
&amp;amp;&amp;amp;&amp;amp;{\sum_{(i, k)\in E}f_{ik}=\sum_{(k,j)\in E}f_{kj}}\,\, \text{với mọi }k\in V \backslash \{s,t\}.\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;bài-toán-cắt-cực-tiểu&quot;&gt;Bài toán cắt cực tiểu&lt;/h2&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter10/min_cut.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 2] Ví dụ Cắt Đồ thị[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Bài toán cắt cực tiểu chia tất cả các đỉnh của đồ thị thành hai tập hợp: vùng có bóng và vùng không có bóng, như được hiển thị trong hình. Một tập hợp chứa nguồn, và tập hợp khác chứa đích, trong khi các đỉnh còn lại được gán tùy ý vào một trong hai tập hợp (ở đây, tập hợp chứa nguồn được gọi là A, và tập hợp chứa đích được gọi là B). Tổng các công suất của các cạnh đi từ tập hợp A đến tập hợp B được định nghĩa là cắt.&lt;/p&gt;

&lt;p&gt;Nói cách khác, một cắt là một phân hoạch các đỉnh của đồ thị sao cho nguồn và đích ở các phân hoạch khác nhau. Bài toán cắt cực tiểu là tìm giá trị tối thiểu của cắt này cho một đồ thị cho trước. Trong định nghĩa tổng quát của bài toán cắt cực tiểu, vì nó được định nghĩa trên một đồ thị có hướng, nó luôn thỏa mãn nguồn \(x_{s}=1\), đích \(x_{t}=0\). Phần này được bỏ qua trong định nghĩa bài toán dưới đây.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{b\in {\mathbb{R}^{|E|}},\, x \in {\mathbb{R}^{|V|}} } &amp;amp;&amp;amp;{\sum_{(i,j)\in E} b_{ij}c_{ij}}\\
&amp;amp;\text{với điều kiện} &amp;amp;&amp;amp;{b_{ij} \geq x_{i}-x_{j}}\\
&amp;amp;&amp;amp;&amp;amp;{b_{ij},\,x_{i},\,x_{j}\,\in \{ 0,1 \} }\\
&amp;amp;&amp;amp;&amp;amp;\text{với mọi }i, j.\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Trực quan, bài toán luồng cực đại là tìm luồng tối đa từ nguồn, và bài toán cắt cực tiểu là tìm tổng công suất tối thiểu có thể được gửi từ tập nguồn đến tập đích, vì vậy rõ ràng rằng hai bài toán này có liên quan chặt chẽ.&lt;/p&gt;

&lt;h2 id=&quot;đối-ngẫu-của-bài-toán-luồng-cực-đại&quot;&gt;Đối ngẫu của bài toán Luồng cực đại&lt;/h2&gt;
&lt;p&gt;Hãy suy ra đối ngẫu cho bài toán tối ưu luồng cực đại.&lt;/p&gt;

&lt;p&gt;Đầu tiên, định nghĩa các biến đối ngẫu cho các ràng buộc theo thứ tự là \(a_{ij}, b_{ij}, x_{k}\). Trong đối ngẫu của bài toán max, cận trên sẽ được tối thiểu hóa, vì vậy dạng được tổ chức phải ở dạng mục tiêu nguyên thủy \(\leq\) một cái gì đó. Do đó, tổ chức phương trình để tìm cận trên của \(f_{ij}\) cho các ràng buộc.
Điều này có thể được tổ chức như sau.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\sum_{(i,j)\in E} {\Big(-a_{ij}f_{ij}+b_{ij}(f_{ij}-c_{ij})\Big)} + \sum_{k \in V\backslash \{s,t\}} x_{k}\Big( \sum_{(i,k)\in E} f_{ik} - \sum_{(k,j)\in E } f_{kj} \Big)\leq 0\\
\text{với bất kỳ }a_{ij}, b_{ij} \geq 0, (i, j)\in E, \text{ và } x_{k}, k\in V \backslash \{s,t\}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Tổ chức các số hạng \(f\) liên quan đến hàm mục tiêu LP nguyên thủy ở bên trái, và phần còn lại ở bên phải.&lt;/p&gt;

&lt;p&gt;Tiếp theo, vì chúng ta muốn cận trên của LP nguyên thủy, tìm phương trình sao cho các số hạng được nhân với \(f\) ở bên trái khớp với hàm mục tiêu LP nguyên thủy.&lt;/p&gt;

&lt;p&gt;Điều kiện thỏa mãn phương trình này trở thành ràng buộc trong LP đối ngẫu.&lt;/p&gt;

&lt;p&gt;Tức là, tổ chức phương trình sao cho số hạng \(f_{ij}\) chỉ là 1 trong \(\sum_{(s,j)\in E}f_{sj}\) và 0 ở nơi khác.&lt;/p&gt;

&lt;p&gt;This process is detailed as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\sum_{(i,j)\in E}{\Big((b_{ij}-a_{ij})f_{ij}\Big)}+\sum_{k\in V\backslash \{s,t\}}{x_{k}\Big(\sum_{(i,k)\in E}{f_{ik}}-\sum_{(k,j)\in E}{f_{kj}}\Big)} \leq \sum_{(i,j)\in E}b_{ij}c_{ij}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, our goal is to make the result of the left side when \(i=s\) be \(\sum_{(s,j)\in E}f_{sj}\) and 0 for other cases.&lt;/p&gt;

&lt;p&gt;The k in the x term of the second sigma does not include the source and sink, and can be divided into three cases: when \(i=s, j\neq t\), when \(i\neq s, j=t\), and when \(i\neq s,j\neq t\).&lt;/p&gt;

&lt;h3 id=&quot;case-1-i--s-j-neq-t&quot;&gt;Case 1. \(i = s, j \neq t.\)&lt;/h3&gt;

&lt;p&gt;For the term multiplied by \(x_{k}\), it is eliminated by the third condition of flow except for the case of \(k=j\).
Therefore, the sigma for the x term of the second term can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;=\sum_{(s,j)\in E}{\Big((b_{sj}-a_{sj})f_{sj}\Big)}+x_{j}\sum_{(s,j)\in E}{f_{sj}}+\sum_{k\in V\backslash \\{s,t,j\\}}{x_{k}\Big(\underbrace{\sum_{(s,k)\in E}{f_{sk}}-\sum_{(k,j)\in E}{f_{kj}}}_{=0}\Big)} \\\\
&amp;amp;=\sum_{(s,j)\in E}{\Big(b_{sj}-a_{sj}+x_{j}\Big)f_{sj}}, \ j \in V \backslash \{s,t\},\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;case-2-i-neq-s-j--t&quot;&gt;Case 2. \(i \neq s, j = t.\)&lt;/h3&gt;
&lt;p&gt;For the term multiplied by \(x_{k}\), it is eliminated by the third condition of flow except for the case of \(k=i\).
Therefore, the sigma for the x term of the second term can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;=\sum_{(i,t)\in E}{\Big((b_{it}-a_{it})f_{it}\Big)}-x_{i}\sum_{(i,t)\in E}{f_{it}}+\sum_{k\in V\backslash \{s,t,i\}}{x_{k}\Big(\underbrace{\sum_{(i,k)\in E}{f_{ik}}-\sum_{(k,t)\in E}{f_{kt}}}_{=0}\Big)} \\\\
&amp;amp;=\sum_{(i,t)\in E}{\Big(b_{it}-a_{it}-x_{i}\Big)f_{it}}, \ i \in V\backslash \{s,t\},\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;case-3-i-neq-s-j-neq-t&quot;&gt;Case 3. \(i \neq s, j \neq t.\)&lt;/h3&gt;
&lt;p&gt;For the term multiplied by \(x_{k}\), it is eliminated by the third condition of flow except for the cases of \(k=i\) and \(k=j\).
Therefore, the sigma for the x term of the second term can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;=\sum_{(i,j)\in E}{\Big((b_{ij}-a_{ij})f_{ij}\Big)}+x_{j}\sum_{(i,j)\in E}{f_{ij}}-x_{i}\sum_{(i,j)\in E}{f_{ij}}+\sum_{k\in V\backslash \{s,t,i,j\}}{x_{k}\Big(\underbrace{\sum_{(i,k)\in E}{f_{ik}}-\sum_{(k,j)\in E}{f_{kj}}}_{=0}\Big)} \\\\
&amp;amp;=\sum_{(i,j)\in E}{\Big(b_{ij}-a_{ij}+x_{j}-x_{i}\Big)f_{ij}}, \ i, j \in V \backslash \{s,t\}. \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The objective function of the primal LP matches with the case 1 of the above, where the term is 1 in \(b_{sj}-a_{sj}+x_{j}\), and for the other cases, it makes the multiplied term 0, completing the form of left side being the objective function and the right side being the upper bound.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;b_{sj}-a_{sj}+x_{j} = 1\\\\
&amp;amp;b_{it}-a_{it}-x_{i} = 0\\\\
&amp;amp;b_{ij}-a_{ij}+x_{j}-x_{i} = 0\\\\
&amp;amp;\text{Result in,} \\\\
&amp;amp;\sum_{(s,j)\in E}{f_{sj}} \leq \sum_{(i,j)\in E}{b_{ij}c_{ij}}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, the dual problem is to find the minimum value of the upper bound (objective function of dual LP) for the dual variables \(a, b, x\), and this minimum value becomes the best upper bound. A dummy variable \(a\) is eliminated while maintaining the conditions. Additionally, by adding the condition that flow occurs from source to sink in the directed graph, the equation becomes:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{b\in {\mathbb{R}^{|E|}},\, x\in{\mathbb{R}^{|V|}}}  &amp;amp;&amp;amp;{\sum_{(i,j)\in E} b_{ij}c_{ij}} \\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;{b_{ij}+x_{j}-x_{i}\geq 0 \,\, \text{for all } (i,j)\in E}\\\\
&amp;amp;&amp;amp;&amp;amp;{b\geq 0, x_{s}=1,x_{t}=0}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;dual-lp-to-integer-program&quot;&gt;Dual LP to Integer program&lt;/h2&gt;
&lt;p&gt;Now, we want to show that this dual LP is the same as the LP relaxation of the min cut problem.
Therefore, we will go through the process of converting it to an integer program by adding conditions to the above dual LP problem.
The variable \(x\) is not defined for vertices other than s and t.
Therefore, to narrow the scope of the problem, let’s add a condition that the remaining vertices except s and t belong to either group s or t.
In other words, let’s assume that all vertices belong to either group 0 or 1. This is equivalent to determining the vertex partition for the min cut.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x_{i} \in \{0,1 \} \ \ \text{ for all }i\in V.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s define the group that belongs to 1 as set A, and the group that belongs to 0 as set B. Also, let’s define that the source (s) belongs to A, and the sink (t) belongs to B.&lt;/p&gt;

&lt;p&gt;With the above definitions, \(b_{ij}\) acts as an on/off switch, being 1 for edges going from set A to set B, and 0 otherwise.&lt;/p&gt;

&lt;p&gt;This can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\text{Let } A= \{ i:x_{i}=1 \} ,\, B= \{ i:x_{i}=0 \} \\\\
&amp;amp;\text{note that  } s \in A, \,t \in B, \text{ and  }b_{ij}\geq x_{i}-x_{j} \,\,\,\, \text{for }\,(i,j) \in E, \,\, b\geq 0,\\\\
\end{align}\)
\(\begin{align}
\text{Simply say, } \qquad \begin{cases} b_{ij}=1 \qquad \text{if } i\in A, j\in B\\\\
0 \qquad\qquad \text{otherwise}.\end{cases}
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The above result is the same as the formulation of the min cut problem.&lt;/p&gt;

&lt;h2 id=&quot;relationship-between-max-flow-and-min-cut-problem2&quot;&gt;Relationship between Max flow and Min cut problem(2)&lt;/h2&gt;
&lt;p&gt;That is, the dual problem of the max flow problem is the result of removing the condition that the vertices except s and t in the min cut problem are included in 0 or 1 (relaxation). The optimal value of max flow \(\leq\) dual LP (upper bound), and this relaxation expands the domain scope of the optimization variable, so the optimal value LP relaxed min cut \(\leq\) capacity of min cut. Summarizing these three results, we get the following result.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{Value of max flow} &amp;amp;\leq \text{Dual LP of max flow}\\\\
&amp;amp;= \text{Optimal value for LP relaxed min cut}\\\\
&amp;amp;\leq \text{Capacity of min cut}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For the equality of these three results, refer to the max-flow min-cut theorem[11], and for a representative algorithm for solving the max flow min cut problem, refer to the Ford-Fulkerson algorithm[12].&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>10-02 Tính đối ngẫu trong LP tổng quát</title>
   <link href="http://localhost:4000/contents/vi/chapter10/10_02_Duality_in_general_LPs/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter10/10_02_Duality_in_general_LPs</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Trong &lt;a href=&quot;/contents/vi/chapter10/10_01_Lower_Bounds_in_Linear_Programs/&quot;&gt;10-01&lt;/a&gt;, chúng ta đã xem xét nguyên thủy và đối ngẫu của các bài toán LP với các biến một chiều. Trong 10-02, chúng ta muốn xem xét đối ngẫu cho LP ở dạng tổng quát.&lt;/p&gt;

&lt;p&gt;Dạng tổng quát của LP như sau:&lt;/p&gt;

&lt;p&gt;Cho \(c\in\mathbb{R}^{n},\, A\in\mathbb{R}^{m\times n},\, b\in\mathbb{R}^{m},\, G\in\mathbb{R}^{r\times n},\, h\in\mathbb{R}^{r}\),&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;c^{T}x\\\\
&amp;amp;\text{với điều kiện} &amp;amp;&amp;amp;Ax = b\\\\
&amp;amp; &amp;amp;&amp;amp;Gx \leq h.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Tương tự như ví dụ trong 10-01, chúng ta định nghĩa các biến đối ngẫu \(u, v\) có số lượng bằng số lượng ràng buộc,
và có thể định nghĩa hàm mục tiêu của bài toán đối ngẫu và các ràng buộc như tổng của các tích của ràng buộc và mỗi biến đối ngẫu.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;u^{T}(Ax-b) = 0\\\\
&amp;amp;{+} &amp;amp;v^{T}(Gx-h)\leq 0\\\\
&amp;amp;{=} &amp;amp;u^{T}(Ax-b) + v^{T}(Gx-h)\leq 0.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Nhớ rằng biến đối ngẫu \(u\) cho đẳng thức không có ràng buộc, trong khi \(v\) là biến đối ngẫu cho bất đẳng thức và do đó có ràng buộc bổ sung là phải dương.
Bằng cách sắp xếp phương trình cuối để biểu diễn hàm mục tiêu của LP nguyên thủy, chúng ta có được LP đối ngẫu.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
u^{T}(Ax-b) + v^{T}(Gx-h)\leq 0 \\\\
\underbrace{(-A^{T}u-G^{T}v)^{T}}_{=c^{T}}x\geq-b^{T}u-h^{T}v \\\\
\text{Cận dưới là} -b^{T}u-h^{T}v \\\\ 
\text{với } x \text{ khả thi nguyên thủy, và bất kỳ u, v thỏa mãn,} \\\\
c = -A^{T}u-G^{T}v \\\\
v\geq 0. \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Tức là, khi \(c = -A^{T}u-G^{T}v\), giá trị tối ưu của nguyên thủy có cận dưới là \(-b^{T}u-h^{T}v\).&lt;/p&gt;

&lt;p&gt;Do đó, LP đối ngẫu có thể được định nghĩa như sau.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{u,v} &amp;amp;&amp;amp;-b^{T}u-h^{T}v \\\\
&amp;amp;\text{với điều kiện} &amp;amp;&amp;amp;c = -A^{T}u-G^{T}v \\\\
&amp;amp; &amp;amp;&amp;amp;v\geq 0.
\end{align}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>10-01 Cận dưới trong Chương trình Tuyến tính</title>
   <link href="http://localhost:4000/contents/vi/chapter10/10_01_Lower_Bounds_in_Linear_Programs/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter10/10_01_Lower_Bounds_in_Linear_Programs</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;h2 id=&quot;ví-dụ-1-dạng-mà-ràng-buộc-chứa-hàm-mục-tiêu&quot;&gt;Ví dụ 1: Dạng mà ràng buộc chứa hàm mục tiêu&lt;/h2&gt;

&lt;p&gt;Giả sử chúng ta muốn tìm giá trị cận dưới B của giá trị tối ưu cho một bài toán lồi cho trước.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
B \leq \min_{x} f(x).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Hãy xét cụ thể cận dưới của các chương trình tuyến tính. Chúng ta sẽ xem xét các trường hợp từ đơn giản đến dạng tổng quát theo thứ tự.
Đầu tiên, lấy dạng đơn giản nhất của bài toán LP làm ví dụ&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y}  
&amp;amp; &amp;amp;{x+y} \\\\
&amp;amp;\text{với điều kiện} 
&amp;amp; &amp;amp;{x + y \geq 2}\\\\
&amp;amp; &amp;amp; &amp;amp;{x, y \geq 0.}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán trên đã bao gồm cận dưới của hàm mục tiêu trong ràng buộc, vì vậy chúng ta có thể dễ dàng thấy rằng \(B=2\).&lt;/p&gt;

&lt;p&gt;Hơn nữa, hãy xem xét trường hợp mà ràng buộc không bao gồm cận dưới.&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ-2-dạng-mà-hàm-mục-tiêu-có-thể-được-biểu-diễn-như-tổ-hợp-tuyến-tính-của-các-ràng-buộc-1&quot;&gt;Ví dụ 2: Dạng mà hàm mục tiêu có thể được biểu diễn như tổ hợp tuyến tính của các ràng buộc (1)&lt;/h2&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y}  
&amp;amp; &amp;amp; {x+3y} \\\\
&amp;amp;\text{với điều kiện} 
&amp;amp; &amp;amp;{x + y \geq 2}\\\\
&amp;amp; &amp;amp; &amp;amp;{x, y \geq 0.}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Nếu \(x,\, y\) là khả thi, thì việc nhân ba ràng buộc với các giá trị vô hướng và cộng hoặc trừ chúng vẫn thỏa mãn cả ba ràng buộc. Do đó, đối với bài toán LP như vậy, quá trình nhân các ràng buộc với các giá trị vô hướng và cộng hoặc trừ chúng, tức là biểu diễn hàm mục tiêu như tổ hợp tuyến tính của các ràng buộc, là có thể, và kết quả là chúng ta có thể tìm \(B\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;{x + y \geq 2}\\\\
&amp;amp;{+} &amp;amp;{0x \geq 0}\\\\
&amp;amp;{+} &amp;amp;{2y \geq 0}\\\\
&amp;amp;{=} &amp;amp;{x + 3y \geq 2}\\\\

&amp;amp; &amp;amp;{\text{Cận dưới}\ B = 2.}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Tổng quát hóa hơn nữa bằng cách áp dụng các biến tùy ý để biểu diễn hàm mục tiêu, chúng ta có được như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y}  
&amp;amp; &amp;amp;{px+qy} \\\\
&amp;amp;\text{với điều kiện} 
&amp;amp; &amp;amp;{x + y \geq 2}\\\\
&amp;amp; &amp;amp; &amp;amp;{x, y \geq 0.}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Tương tự như ví dụ thứ hai, bằng cách nhân các ràng buộc với các giá trị vô hướng a, b, c tương ứng, hàm mục tiêu có thể được biểu diễn như tổ hợp tuyến tính của ba ràng buộc này.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;{a(x+y) \geq 2a} \\\\
&amp;amp;{+} &amp;amp;{bx \geq 0} \\\\
&amp;amp;{+} &amp;amp;{cy \geq 0} \\\\
&amp;amp;{=} &amp;amp;{(a+b)x+(a+c)y \geq 2a} \\\\
&amp;amp;&amp;amp;\text{Cận dưới}\ B=2a, \\
&amp;amp;&amp;amp;\text{với bất kỳ a,b,c thỏa mãn điều kiện dưới đây}\\\\
&amp;amp; &amp;amp;{a + b = p}\\\\
&amp;amp; &amp;amp;{a + c = q}\\\\
&amp;amp; &amp;amp;{a,b,c \geq 0.}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Để cận dưới thỏa mãn là 2a như trên, vì dấu bất đẳng thức sẽ bị đảo ngược trong quá trình nhân với các giá trị vô hướng và điều này sẽ không thỏa mãn, các điều kiện \(a, b, c\) phải dương và tổng các giá trị vô hướng phải bằng hàm mục tiêu, tức là các điều kiện \(a+b = p\) và \(a+c = q\) phải được thỏa mãn.&lt;/p&gt;

&lt;p&gt;Một bài toán tối ưu mới có thể được định nghĩa bằng cách tối đa hóa kết quả cận dưới thu được như trên. Trong trường hợp này, các điều kiện thỏa mãn cận dưới trở thành các ràng buộc trong bài toán này.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{a, b, c}  
&amp;amp; &amp;amp;{2a} \\\\
&amp;amp;\text{với điều kiện} 
&amp;amp; &amp;amp;{a + b = p}\\\\
&amp;amp; &amp;amp; &amp;amp;{a + c = q}\\\\
&amp;amp; &amp;amp; &amp;amp;{a, b, c \geq 0}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán LP ban đầu ở trên được gọi là LP nguyên thủy, và dạng định nghĩa lại bài toán tối ưu bằng cách tối đa hóa cận dưới trong LP nguyên thủy được gọi là LP đối ngẫu. Lưu ý rằng số lượng biến tối ưu trong bài toán đối ngẫu bằng số lượng ràng buộc trong bài toán nguyên thủy.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{LP Nguyên thủy}\qquad
&amp;amp;\qquad \min_{x, y}  &amp;amp;{px+qy} \\\\
&amp;amp;\qquad \text{với điều kiện} &amp;amp;{x + y \geq 2}\\\\
&amp;amp;\qquad &amp;amp;{x, y \geq 0}\\\\
\\\\
\\\\
\text{LP Đối ngẫu}\qquad
&amp;amp;\qquad \max_{a, b, c}  &amp;amp;{2a} \\\\
&amp;amp;\qquad \text{với điều kiện} &amp;amp;{a + b = p}\\\\
&amp;amp;\qquad &amp;amp;{a + c = q}\\\\
&amp;amp;\qquad &amp;amp;{a, b, c \geq 0}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;ví-dụ-3-dạng-mà-hàm-mục-tiêu-có-thể-được-biểu-diễn-như-tổ-hợp-tuyến-tính-của-các-ràng-buộc-2&quot;&gt;Ví dụ 3: Dạng mà hàm mục tiêu có thể được biểu diễn như tổ hợp tuyến tính của các ràng buộc (2)&lt;/h2&gt;

&lt;p&gt;Như một ví dụ cuối cùng, hãy xem xét một dạng mà các dấu bất đẳng thức trong ràng buộc bị đảo ngược và bao gồm các ràng buộc đẳng thức.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y}  &amp;amp;{px+qy} \\\\
&amp;amp;\text{với điều kiện} &amp;amp;{x \geq 0}\\\\
&amp;amp; &amp;amp;{y \leq 1}\\\\
&amp;amp; &amp;amp;{3x + y = 2}\\\\
\\\\
&amp;amp; &amp;amp;{ax \geq 0}\\\\
&amp;amp;{+} &amp;amp;{-by \geq -b}\\\\
&amp;amp;{+} &amp;amp;{3cx + cy = 2c}\\\\
&amp;amp;{=} &amp;amp;{(a+3c)x+(-b+c)y \geq 2c-b}
\\\\
\\\\
&amp;amp;&amp;amp; \text{Cận dưới}  \ B=2c-b, \\
&amp;amp;&amp;amp; \text{với bất kỳ a,b,c thỏa mãn điều kiện dưới đây}\\\\
&amp;amp; &amp;amp;{a + 3c = p}\\\\
&amp;amp; &amp;amp;{-b + c = q}\\\\
&amp;amp; &amp;amp;{a,b \geq 0}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, c là giá trị vô hướng được nhân với cả hai vế của đẳng thức, vì vậy bất kỳ giá trị nào cũng có thể được nhân mà không có hạn chế.&lt;/p&gt;

&lt;p&gt;Do đó, LP đối ngẫu có thể được định nghĩa như sau.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\qquad \max_{a, b, c}  &amp;amp;{2c-b} \\\\
&amp;amp;\qquad \text{với điều kiện} &amp;amp;{a + 3c = p}\\\\
&amp;amp;\qquad &amp;amp;{-b + c = q}\\\\
&amp;amp;\qquad &amp;amp;{a, b \geq 0}\\\\
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>10 Duality in Linear Programs</title>
   <link href="http://localhost:4000/contents/en/chapter10/10_Duality_in_Linear_Programs/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter10/10_Duality_in_Linear_Programs</id>
   <content type="html">&lt;p&gt;Starting from this chapter, we will examine duality, which plays a significant role in optimization theory.
From an optimization perspective, duality can be simply described as the concept that a single optimization problem can be viewed from two perspectives: the primal problem and the dual problem.&lt;/p&gt;

&lt;p&gt;In this chapter, we specifically explore duality in linear programs.
Rather than directly applying it to general convex problems, we will derive the dual problem from the primal problem by applying it to linear programs, and organize how the relationship between these two problems is established and what properties they have under specific conditions.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>10-05 Matrix Games</title>
   <link href="http://localhost:4000/contents/en/chapter10/10_05_Matrix_Games/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter10/10_05_Matrix_Games</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In this chapter, we examine mixed strategies for matrix games, which is an example of primal LP and dual LP in game theory. The setup assumes two players, J and R, and a payout matrix \(P\).&lt;/p&gt;

&lt;h2 id=&quot;game-setup&quot;&gt;Game Setup&lt;/h2&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter10/matrix_game.png&quot; alt=&quot;Line Segment&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Game Setup[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;The payout matrix is the amount of reward J must give to R when J chooses strategy \(i\) (row) and R chooses strategy \(j\) (column) (\(P_{ij}\)). However, if this value is positive, J gives R a reward equal to the size of the corresponding matrix, and if negative, R gives J a reward equal to the size of the corresponding matrix.&lt;/p&gt;

&lt;p&gt;This setting is also called a zero-sum setting, where if the reward R will receive or must pay is \(r_{R}\) and J’s reward is \(r_{J}\), then in each game the result of the rewards is \(r_{R} = - r_{J}\), and the total sum of the two rewards is always 0.&lt;/p&gt;

&lt;p&gt;Also, we assume that both players use mixed strategies. Mixed strategies is the assumption that each player’s choice follows a specific probability distribution (or is sampled from a specific probability distribution).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x : P(\text{J chooses i}) = x_{i}, \qquad i=1,...m\\\\
y : P(\text{R chooses j}) = y_{j}, \qquad j=1,...n.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If they know each other’s mixed strategy, i.e., probability distribution, each player can calculate the payout they expect to get, i.e., the expected payout.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\sum_{i=1}^{m}\sum_{j=1}^{n}x_{i}y_{j}P_{ij} = x^{T}Py.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Considering that the sign of the payout matrix is defined as the amount J gives to R, J will try to minimize this expected payout because J wants to give as little as possible to R, and R will try to maximize this expected payout because R wants to receive as much as possible from J.&lt;/p&gt;

&lt;p&gt;이제 두 player의 입장에서 각자가 상대의 mixed strategy를 고려하여, 이 expected payout을 최대화(R의 입장) 혹은 최소화(J의 입장)하려는 관점을 살펴보고, 서로가 서로를 optimal하게 행동하는 전제하에, 두 입장에서 유도되는 optimal strategy를 구하고, 결과적으론 Von Neumman’s minimax theorem에 의해 두 결과가 같다는 것을 확인할 것이다.&lt;/p&gt;

&lt;h2 id=&quot;minimizing-expected-payout--js-perspective&quot;&gt;Minimizing Expected Payout : J’s Perspective&lt;/h2&gt;
&lt;p&gt;먼저 R이 J의 strategy \(x\)를 알고 있다고 가정하자. R은 expected payout \(x^{T}Py\)를 maximize하고자 할 것이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\max\{x^{T}Py : y\geq0, 1^{T}y = 1\} = \max_{i=1,...n}(P^{T}x)_{i}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이때 R은 식의 내용처럼 \((P^{T}x)_{i}\) 중 가장 큰 값을 갖는 i(row index)를 찾게되고, 이 i에 대응되는 \(y_{i}\)를 1로 가지고 나머지의 row index에 대해선 0을 가지는 strategy가 R에게 있어서 expected payout을 maximize하는 strategy일 것이다.&lt;/p&gt;

&lt;p&gt;R이 위처럼 최적으로 행동할 것을 알고 있을 때, J의 최적의 strategy는 밑의 식을 만족하는 distribution \(x\)일 것이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \min_{x}
&amp;amp; &amp;amp;\max_{i=1,...n} (P^{T}x)_{i}\\\\
&amp;amp; \text{subject to}
&amp;amp; &amp;amp; x\geq 0, 1^{T}x =1.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Convex function의 maximization 또한 convex function이 된다.  이를 첫 번째 관점의 문제 정의라고 칭할 것이다. 또한 이 최적화 문제의 해를 optimal expected payout \(f^{*}_{1}\)이라고 정하자. 또 하나 유념할 점은 게임참가자, 즉 player들이 모두 최적으로 행동한다는 가정이 기본적인 형태의 게임이론 formulation에서 가정이 된다.&lt;/p&gt;

&lt;h2 id=&quot;maximizing-expected-payout--rs-perspective&quot;&gt;Maximizing Expected Payout : R’s Perspective&lt;/h2&gt;
&lt;p&gt;두 번째 관점으로 J가 R의 strategy \(y\)를 알고 있다고 가정하자. J는 expected payout을 minimize하고자 할 것이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\min \{x^{T}Py : x\geq0, 1^{T}x = 1\} = \min_{j=1,...n}(Py)_{j}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;같은 논리로, J가 위처럼 최적으로 행동할 것을 알고 있을 때 R의 최적의 strategy는 밑의 식을 만족하는 distribution \(y\)이다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \max_{y}  
&amp;amp; &amp;amp; \min_{j=1,...m} (Py)_{j}\\\\
&amp;amp;\text{subject to}
&amp;amp; &amp;amp;y\geq 0, 1^{T}y =1.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;위와 마찬가지로 이를 두 번째 관점의 문제 정의라고 칭하고, 이 최적화 문제의 해를 \(f^{*}_{2}\) 라고 하자. player R이 이 expected payout을 maximize하고자 하기 때문에, 첫 번째, 즉, R이 J의 strategy를 미리 알고 있다는 가정 하에 결정되는 expected payout \(f^{*}_{1}\)이 두 번째 가정보다 더 크거나 같은 값을 가질 것이라 쉽게 예상할 수 있다. (\(f^{*}_{1}\geq f^{*}_{2}\))&lt;/p&gt;

&lt;h2 id=&quot;von-neumanns-minimax-theorem&quot;&gt;Von Neumann’s minimax theorem&lt;/h2&gt;
&lt;p&gt;하지만,  Von Neumann’s minimax theorem에 따르면 \(f^{*}_{1} = f^{*}_{2}\)가 된다. 실제 minimax theorem은 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\text{Let } X\subset \mathbb{R}^{N} \text{ and }Y\subset \mathbb{R}^{m} \text{ be compact convex sets. }\\\\
&amp;amp;\text{If } f:X\times Y\rightarrow \mathbb{R} \text{ is a continuous function that is convex-concave, i.e.}\\\\
&amp;amp;\qquad f(\cdot, y): X\rightarrow\mathbb{R} \text{ is convex for fixed }y, \text{ and}\\\\
&amp;amp;\qquad f(x, \cdot): Y\rightarrow\mathbb{R} \text{ is concave for fixed }x.\\\\
&amp;amp;\text{Then we have that} \\\\ 
&amp;amp;\min_{x\in X} \max_{y\in Y} f(x,y) = \max_{y\in Y} \min_{x\in X} f(x,y).\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;해당 내용의 증명은 생략한다.&lt;/p&gt;

&lt;h2 id=&quot;proof-of-each-perspective-having-primal-and-dual-relationship&quot;&gt;Proof of each perspective having Primal and Dual relationship&lt;/h2&gt;
&lt;p&gt;이제 위 두 가지 관점의 경우에 대한 expected payout이 LP 문제로써 서로 primal, dual 관계이고, Von Neumman’s minimax theorem에 의하여 두 결과가 같다는 점을 이용하여, strong duality를 만족함을 보이고자 한다.&lt;/p&gt;

&lt;p&gt;먼저 첫 번째 관점의 문제를 다음과 같이 reformulate 할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; \min_{x} \max_{i=1,...m} 
&amp;amp; &amp;amp;(P^{T}x)_{i}\\\\
&amp;amp;\text{subject to } 
&amp;amp; &amp;amp;x\geq 0, 1^{T}x = 1\\\\
\end{align}\]

\[\begin{align}
\Leftrightarrow{} \\\\
&amp;amp; \min_{x,t}
&amp;amp; &amp;amp; t \\\\
&amp;amp;\text{subject to } 
&amp;amp; &amp;amp;x\geq0, 1^{T}x = 1, P^{T}x \preceq t. \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(t\)를 \(P^{T}x\)의 항들 중 가장 큰 값과 같게 만들어주는 문제로 reformulate 하였다.&lt;/p&gt;

&lt;p&gt;이제 여기에 앞서 배운 duality의 두 번째 방법인 Lagrangian을 구하고,  Lagrange dual function \(g\)를 구하면,&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;L(x, t, u, v, y) &amp;amp;&amp;amp;= t-u^{T}x+v(1-1^{T}x)+y^{T}(P^{T}x-t1)\\\\
&amp;amp;g(u, v, y) &amp;amp;&amp;amp;= \min_{x,t} \quad L(x, t, u, v, y)\\\\
&amp;amp;&amp;amp;&amp;amp;= \begin{cases} v \qquad &amp;amp;\text{if } 1-1^{T}y = 0, Py-u-v1=0\\\\
-\infty \qquad &amp;amp;\text{otherwise.} \end{cases}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(u\)는 slack variable이므로, 이를 제거하고 식을 정리하면 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{y,v} \qquad \quad &amp;amp;&amp;amp; v\\\\
&amp;amp;\text{subject to }\quad &amp;amp;&amp;amp; y\geq0, 1^{T}y = 1\\\\
&amp;amp;&amp;amp;&amp;amp; Py\geq v.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이는 두 번째 관점의 문제의 primal LP이다. 따라서 두 관점은 dual 관계에 있고 두 문제의 optimal value는 같으므로, strong duality가 성립한다.&lt;/p&gt;

&lt;p&gt;일반적으로 LP문제에서는, 향 후의 내용에서 다루지만, primal과 dual 중 하나만 feasible하다면 strong duality가 성립한다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>10-04 Another Perspective on LP duality</title>
   <link href="http://localhost:4000/contents/en/chapter10/10_04_Another_Perspective_on_LP_duality/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter10/10_04_Another_Perspective_on_LP_duality</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In the case of duality discussed earlier, for LP, we multiplied the constraints of the primal problem by dual variables, obtained their linear combination, and then organized it to separate out the primal’s objective function to obtain a bound. The separated remaining terms (something in the formula below) served as the bound for the primal problem. That is, they became the objective function of the dual problem, and the conditions created during the formula development process became the constraints of the dual problem.
Writing this partial process (the part of the above content that separates out the primal objective function to obtain a bound) as a formula, it looks like this:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x)\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;Ax = b\\\\
&amp;amp; &amp;amp;&amp;amp;Gx \leq h\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;\text{for any }u,\, v\geq 0,\\\\
&amp;amp; &amp;amp;u^{T}(Ax-b) = 0\\\\
&amp;amp;{+} &amp;amp;v^{T}(Gx-h)\leq 0\\\\
&amp;amp;{=} &amp;amp;u^{T}(Ax-b) + v^{T}(Gx-h)\leq 0\\\\
&amp;amp;{\approx} &amp;amp;f(x)+\text{something}. \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;However, for optimization problems that are not linear programs, most cannot express the objective function as a linear combination of constraints.&lt;/p&gt;

&lt;p&gt;In this chapter, we examine the perspective of duality that is applicable to more universally common problems (all convex, most non-convex). We will find the duality of LP using this method called Lagrangian, and examine more detailed discussions in Chapter 11.&lt;/p&gt;

&lt;p&gt;Looking at the equations up to the linear combination form for the primal LP problem described above, we can understand the following relationship:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
c^{T}x\geq c^{T}x+\overbrace{u^{T} \underbrace{(Ax-b)} _ {=0}+\underbrace{v^{T}} _ {\geq 0} \underbrace{(Gx-h)} _ {\leq 0}} ^ {\leq 0} := L(x,u,v).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The right side of the inequality has a value less than or equal to the left side according to the conditions. Also, we define this expression as a function \(L(x, u, v)\) for x, u, v.
Here, if we call the set satisfying the constraints of the primal LP (primal feasible set) C, we can understand the following relationship:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
C =  \{ x: Ax=b, Gx\leq h \},
\end{align}\)
\(\begin{align}
f^{*}=\min_{x\in C} f(x) \geq \min_{x\in C}L(x,u,v)\geq \min_{x}L(x,u,v):=g(u,v).\\\\
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In other words, \(g(u,v)\) becomes a lower bound of \(f^{*}\) for any u or \(v\) satisfying \(v\geq0\).
Let’s examine the lower bound value determined by \(g(u,v)\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
g(u,v) = min_{x} c^{T}x+u^{T}(Ax-b) + v^{T}(Gx-h) \\\\
= \min_{x} (c+A^{T}u+G^{T}v)^{T}x - b^{T}u-h^{T}v \\\\
\begin{cases}= -b^{T}u-h^{T}v \qquad &amp;amp;\text{if }\ c = -A^{T}u-G^{T}v \\\\
-\infty \qquad &amp;amp;\text{otherwise}.
\end{cases}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;As can be seen from the equation, when \(c = -A^{T}u-G^{T}v\) is not satisfied, it has a value of \(-\infty\) due to the \(x\) term.
Since we want to find the lower bound closest to \(f^{*}\), we want to find the value that maximizes \(g(u, v)\). This is \(-b^{T}u-h^{T}v\), the value when \(c = -A^{T}u-G^{T}v\) is satisfied, and this matches the Dual LP we obtained with the first method.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f^{*} \geq g(u,v), \qquad \text{provided } v \geq 0\\\\
\text{find the biggest lowerbound  } g(u,v)\\\\
\max_{u,v} g(u,v)\\\\
\text{s.t. }v \geq 0. 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This method is also applicable to other types of optimization problems that are not in LP form.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>10-03 Max flow and min cut</title>
   <link href="http://localhost:4000/contents/en/chapter10/10_03_Max_flow_and_min_cut/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter10/10_03_Max_flow_and_min_cut</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;As an example of duality in linear programs, we want to examine the max flow min cut problem.&lt;/p&gt;

&lt;h2 id=&quot;directed-graph-condition-of-flow&quot;&gt;Directed Graph, Condition of flow&lt;/h2&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter10/max_flow.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Directed Graph[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;There is a directed graph \(G = (V, E)\) as shown above, and let the edge connecting vertex i and vertex j, \((i,j)\in E\), i.e., the flow from i to j, be \(f_{ij}\). Each edge has a capacity, i.e., the maximum flow that can flow through it. Let this be \(c_{ij}\).&lt;/p&gt;

&lt;p&gt;As a simple example, this can be understood as a graph representation of some flow from a source(s) flowing out to a sink(t). It is a graph form that can be applied to various problems such as urban drainage/power transmission planning, material transportation, etc.&lt;/p&gt;

&lt;p&gt;Here, the flow satisfies three conditions.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(f_{ij}\) is always a positive number greater than or equal to 0: \(f_{ij} \geq 0,\, (i,j)\in E\)&lt;/li&gt;
  &lt;li&gt;\(f_{ij}\) must be less than the maximum flow determined for the edge, i.e., the capacity (limit capacity) \(c_{ij}\): \(f_{ij}&amp;lt;c_{ij}, \, (i,j)\in E\)&lt;/li&gt;
  &lt;li&gt;For vertex k excluding the source (the point where flow comes out, s) or sink (the point where flow goes out, t), the total amount of flow entering k equals the total amount of flow leaving k: \(\sum_{(i,k)\in E}f_{ik} = \sum_{(k,j)\in E}f_{kj}, \, k\in V\backslash{s,t}\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;relationship-between-max-flow-and-min-cut-problem1&quot;&gt;Relationship between Max flow and Min cut problem(1)&lt;/h2&gt;

&lt;p&gt;For the graph and flow defined above, we will examine two well-known problems, the max flow problem and the min cut problem, and the relationship between them.&lt;/p&gt;

&lt;p&gt;To conclude first, the max flow problem is an LP problem, and the min cut problem is an integer program, where the dual of the max flow problem has the same problem form as the LP relaxation of the min cut problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{Value of max flow} &amp;amp;\leq \text{dual LP of max flow}\\
&amp;amp;= \text{Optimal value for LP relaxed min cut}\\
&amp;amp;\leq \text{Capacity of min cut}\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;In this page, we will show the inequality relationship by the reverse process of dual and relaxation (adding constraints to the LP problem to convert it to an integer program). Although not covered here, in reality, all three results are equal.&lt;/p&gt;

&lt;p&gt;This is called the max flow min cut theorem, which states that the maximum flow in a network is equal to the minimum capacity of a cut.&lt;/p&gt;

&lt;p&gt;More generally, under certain conditions, the optimal values of the primal and dual problems are equal, which is called strong duality.&lt;/p&gt;

&lt;p&gt;In LP problems, except for the case where both the primal and dual problems are infeasible, strong duality holds. This will be discussed in Chapter 11.&lt;/p&gt;

&lt;p&gt;First, let’s look at the two problems, derive the dual from the max flow problem, and show that by adding specific conditions to the dual problem (reverse of relaxation), it transforms into the min cut problem.&lt;/p&gt;

&lt;h2 id=&quot;max-flow-problem&quot;&gt;Max flow problem&lt;/h2&gt;

&lt;p&gt;The max flow problem is to find the maximum flow from s to t in a graph that satisfies the above conditions.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{f\in {\mathbb{R}^{|E|}}} &amp;amp;&amp;amp;{\sum_{(s,j)\in E} f_{sj}}\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;{f_{ij}\geq 0,\,f_{ij}\leq c_{i,j}\,\, \text{for all }(i, j)\in E}\\
&amp;amp;&amp;amp;&amp;amp;{\sum_{(i, k)\in E}f_{ik}=\sum_{(k,j)\in E}f_{kj}}\,\, \text{for all }k\in V \backslash \{s,t\}.\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;min-cut-problem&quot;&gt;Min cut problem&lt;/h2&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter10/min_cut.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] Graph Cut Example[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;The min cut problem divides all vertices of the graph into two sets: the shaded region and the unshaded region, as shown in the figure. One set contains the source, and the other contains the sink, while the remaining vertices are arbitrarily assigned to either set (here, the set containing the source is called A, and the set containing the sink is called B). The sum of the capacities of the edges going from set A to set B is defined as the cut.&lt;/p&gt;

&lt;p&gt;In other words, a cut is a partition of the graph’s vertices such that the source and sink are in different partitions. The min cut problem is to find the minimum value of this cut for a given graph. In the general definition of the min cut problem, since it is defined on a directed graph, it always satisfies source \(x_{s}=1\), sink \(x_{t}=0\). This part is omitted in the problem definition below.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{b\in {\mathbb{R}^{|E|}},\, x \in {\mathbb{R}^{|V|}} } &amp;amp;&amp;amp;{\sum_{(i,j)\in E} b_{ij}c_{ij}}\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;{b_{ij} \geq x_{i}-x_{j}}\\
&amp;amp;&amp;amp;&amp;amp;{b_{ij},\,x_{i},\,x_{j}\,\in \{ 0,1 \} }\\
&amp;amp;&amp;amp;&amp;amp;\text{for all }i, j.\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Intuitively, the max flow problem is to find the maximum flow from the source, and the min cut problem is to find the minimum total capacity that can be sent from the source set to the sink set, so it is clear that these two problems are closely related.&lt;/p&gt;

&lt;h2 id=&quot;dual-of-max-flow-problem&quot;&gt;Dual of Max flow problem&lt;/h2&gt;
&lt;p&gt;Let’s derive the dual for the max flow optimization problem.&lt;/p&gt;

&lt;p&gt;First, define the dual variables for the constraints in order as \(a_{ij}, b_{ij}, x_{k}\). In the dual of the max problem, the upper bound will be minimized, so the organized form should be in the form of primal objective \(\leq\) something. Therefore, organize the equation to find the upper bound of \(f_{ij}\) for the constraints.
This can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\sum_{(i,j)\in E} {\Big(-a_{ij}f_{ij}+b_{ij}(f_{ij}-c_{ij})\Big)} + \sum_{k \in V\backslash \{s,t\}} x_{k}\Big( \sum_{(i,k)\in E} f_{ik} - \sum_{(k,j)\in E } f_{kj} \Big)\leq 0\\
\text{for any }a_{ij}, b_{ij} \geq 0, (i, j)\in E, \text{ and } x_{k}, k\in V \backslash \{s,t\}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Organize the \(f\) terms related to the primal LP objective function on the left, and the rest on the right.&lt;/p&gt;

&lt;p&gt;Next, since we want the upper bound of the primal LP, find the equation such that the terms multiplied by \(f\) on the left match the primal LP objective function.&lt;/p&gt;

&lt;p&gt;The condition that satisfies this equation becomes the constraint in the dual LP.&lt;/p&gt;

&lt;p&gt;That is, organize the equation so that the \(f_{ij}\) term is 1 only in \(\sum_{(s,j)\in E}f_{sj}\) and 0 elsewhere.&lt;/p&gt;

&lt;p&gt;This process is detailed as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\sum_{(i,j)\in E}{\Big((b_{ij}-a_{ij})f_{ij}\Big)}+\sum_{k\in V\backslash \{s,t\}}{x_{k}\Big(\sum_{(i,k)\in E}{f_{ik}}-\sum_{(k,j)\in E}{f_{kj}}\Big)} \leq \sum_{(i,j)\in E}b_{ij}c_{ij}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, our goal is to make the result of the left side when \(i=s\) be \(\sum_{(s,j)\in E}f_{sj}\) and 0 for other cases.&lt;/p&gt;

&lt;p&gt;The k in the x term of the second sigma does not include the source and sink, and can be divided into three cases: when \(i=s, j\neq t\), when \(i\neq s, j=t\), and when \(i\neq s,j\neq t\).&lt;/p&gt;

&lt;h3 id=&quot;case-1-i--s-j-neq-t&quot;&gt;Case 1. \(i = s, j \neq t.\)&lt;/h3&gt;

&lt;p&gt;For the term multiplied by \(x_{k}\), it is eliminated by the third condition of flow except for the case of \(k=j\).
Therefore, the sigma for the x term of the second term can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;=\sum_{(s,j)\in E}{\Big((b_{sj}-a_{sj})f_{sj}\Big)}+x_{j}\sum_{(s,j)\in E}{f_{sj}}+\sum_{k\in V\backslash \\{s,t,j\\}}{x_{k}\Big(\underbrace{\sum_{(s,k)\in E}{f_{sk}}-\sum_{(k,j)\in E}{f_{kj}}}_{=0}\Big)} \\\\
&amp;amp;=\sum_{(s,j)\in E}{\Big(b_{sj}-a_{sj}+x_{j}\Big)f_{sj}}, \ j \in V \backslash \{s,t\},\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;case-2-i-neq-s-j--t&quot;&gt;Case 2. \(i \neq s, j = t.\)&lt;/h3&gt;
&lt;p&gt;For the term multiplied by \(x_{k}\), it is eliminated by the third condition of flow except for the case of \(k=i\).
Therefore, the sigma for the x term of the second term can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;=\sum_{(i,t)\in E}{\Big((b_{it}-a_{it})f_{it}\Big)}-x_{i}\sum_{(i,t)\in E}{f_{it}}+\sum_{k\in V\backslash \{s,t,i\}}{x_{k}\Big(\underbrace{\sum_{(i,k)\in E}{f_{ik}}-\sum_{(k,t)\in E}{f_{kt}}}_{=0}\Big)} \\\\
&amp;amp;=\sum_{(i,t)\in E}{\Big(b_{it}-a_{it}-x_{i}\Big)f_{it}}, \ i \in V\backslash \{s,t\},\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;case-3-i-neq-s-j-neq-t&quot;&gt;Case 3. \(i \neq s, j \neq t.\)&lt;/h3&gt;
&lt;p&gt;For the term multiplied by \(x_{k}\), it is eliminated by the third condition of flow except for the cases of \(k=i\) and \(k=j\).
Therefore, the sigma for the x term of the second term can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;=\sum_{(i,j)\in E}{\Big((b_{ij}-a_{ij})f_{ij}\Big)}+x_{j}\sum_{(i,j)\in E}{f_{ij}}-x_{i}\sum_{(i,j)\in E}{f_{ij}}+\sum_{k\in V\backslash \{s,t,i,j\}}{x_{k}\Big(\underbrace{\sum_{(i,k)\in E}{f_{ik}}-\sum_{(k,j)\in E}{f_{kj}}}_{=0}\Big)} \\\\
&amp;amp;=\sum_{(i,j)\in E}{\Big(b_{ij}-a_{ij}+x_{j}-x_{i}\Big)f_{ij}}, \ i, j \in V \backslash \{s,t\}. \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The objective function of the primal LP matches with the case 1 of the above, where the term is 1 in \(b_{sj}-a_{sj}+x_{j}\), and for the other cases, it makes the multiplied term 0, completing the form of left side being the objective function and the right side being the upper bound.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;b_{sj}-a_{sj}+x_{j} = 1\\\\
&amp;amp;b_{it}-a_{it}-x_{i} = 0\\\\
&amp;amp;b_{ij}-a_{ij}+x_{j}-x_{i} = 0\\\\
&amp;amp;\text{Result in,} \\\\
&amp;amp;\sum_{(s,j)\in E}{f_{sj}} \leq \sum_{(i,j)\in E}{b_{ij}c_{ij}}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, the dual problem is to find the minimum value of the upper bound (objective function of dual LP) for the dual variables \(a, b, x\), and this minimum value becomes the best upper bound. A dummy variable \(a\) is eliminated while maintaining the conditions. Additionally, by adding the condition that flow occurs from source to sink in the directed graph, the equation becomes:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{b\in {\mathbb{R}^{|E|}},\, x\in{\mathbb{R}^{|V|}}}  &amp;amp;&amp;amp;{\sum_{(i,j)\in E} b_{ij}c_{ij}} \\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;{b_{ij}+x_{j}-x_{i}\geq 0 \,\, \text{for all } (i,j)\in E}\\\\
&amp;amp;&amp;amp;&amp;amp;{b\geq 0, x_{s}=1,x_{t}=0}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;dual-lp-to-integer-program&quot;&gt;Dual LP to Integer program&lt;/h2&gt;
&lt;p&gt;Now, we want to show that this dual LP is the same as the LP relaxation of the min cut problem.
Therefore, we will go through the process of converting it to an integer program by adding conditions to the above dual LP problem.
The variable \(x\) is not defined for vertices other than s and t.
Therefore, to narrow the scope of the problem, let’s add a condition that the remaining vertices except s and t belong to either group s or t.
In other words, let’s assume that all vertices belong to either group 0 or 1. This is equivalent to determining the vertex partition for the min cut.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x_{i} \in \{0,1 \} \ \ \text{ for all }i\in V.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s define the group that belongs to 1 as set A, and the group that belongs to 0 as set B. Also, let’s define that the source (s) belongs to A, and the sink (t) belongs to B.&lt;/p&gt;

&lt;p&gt;With the above definitions, \(b_{ij}\) acts as an on/off switch, being 1 for edges going from set A to set B, and 0 otherwise.&lt;/p&gt;

&lt;p&gt;This can be organized as follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\begin{align}
&amp;amp;\text{Let } A= \{ i:x_{i}=1 \} ,\, B= \{ i:x_{i}=0 \} \\\\
&amp;amp;\text{note that  } s \in A, \,t \in B, \text{ and  }b_{ij}\geq x_{i}-x_{j} \,\,\,\, \text{for }\,(i,j) \in E, \,\, b\geq 0,\\\\
\end{align}\)
\(\begin{align}
\text{Simply say, } \qquad \begin{cases} b_{ij}=1 \qquad \text{if } i\in A, j\in B\\\\
0 \qquad\qquad \text{otherwise}.\end{cases}
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The above result is the same as the formulation of the min cut problem.&lt;/p&gt;

&lt;h2 id=&quot;relationship-between-max-flow-and-min-cut-problem2&quot;&gt;Relationship between Max flow and Min cut problem(2)&lt;/h2&gt;
&lt;p&gt;That is, the dual problem of the max flow problem is the result of removing the condition that the vertices except s and t in the min cut problem are included in 0 or 1 (relaxation). The optimal value of max flow \(\leq\) dual LP (upper bound), and this relaxation expands the domain scope of the optimization variable, so the optimal value LP relaxed min cut \(\leq\) capacity of min cut. Summarizing these three results, we get the following result.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{Value of max flow} &amp;amp;\leq \text{Dual LP of max flow}\\\\
&amp;amp;= \text{Optimal value for LP relaxed min cut}\\\\
&amp;amp;\leq \text{Capacity of min cut}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For the equality of these three results, refer to the max-flow min-cut theorem[11], and for a representative algorithm for solving the max flow min cut problem, refer to the Ford-Fulkerson algorithm[12].&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>10-02 Duality in general LPs</title>
   <link href="http://localhost:4000/contents/en/chapter10/10_02_Duality_in_general_LPs/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter10/10_02_Duality_in_general_LPs</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;In &lt;a href=&quot;/contents/en/chapter10/10_01_Lower_Bounds_in_Linear_Programs/&quot;&gt;10-01&lt;/a&gt;, we examined the primal and dual of LP problems with single-dimensional variables. In 10-02, we want to examine the dual for LPs in general form.&lt;/p&gt;

&lt;p&gt;The general form of LP is as follows:&lt;/p&gt;

&lt;p&gt;Given \(c\in\mathbb{R}^{n},\, A\in\mathbb{R}^{m\times n},\, b\in\mathbb{R}^{m},\, G\in\mathbb{R}^{r\times n},\, h\in\mathbb{R}^{r}\),&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;c^{T}x\\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;Ax = b\\\\
&amp;amp; &amp;amp;&amp;amp;Gx \leq h.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Similar to the example in 10-01, we define dual variables \(u, v\) equal in number to the number of constraints,
and can define the objective function of the dual problem and constraints as the sum of products of constraints and each dual variable.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;u^{T}(Ax-b) = 0\\\\
&amp;amp;{+} &amp;amp;v^{T}(Gx-h)\leq 0\\\\
&amp;amp;{=} &amp;amp;u^{T}(Ax-b) + v^{T}(Gx-h)\leq 0.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Remember that the dual variable \(u\) for equality has no constraints, while \(v\) is a dual variable for inequality and thus has the additional constraint of being positive.
By organizing the last equation to represent the objective function of the primal LP, we get the dual LP.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
u^{T}(Ax-b) + v^{T}(Gx-h)\leq 0 \\\\
\underbrace{(-A^{T}u-G^{T}v)^{T}}_{=c^{T}}x\geq-b^{T}u-h^{T}v \\\\
\text{Lower bound is} -b^{T}u-h^{T}v \\\\ 
\text{for } x \text{ primal feasible, and any u, v satisfies,} \\\\
c = -A^{T}u-G^{T}v \\\\
v\geq 0. \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;That is, when \(c = -A^{T}u-G^{T}v\), the optimal value of the primal has a lower bound of \(-b^{T}u-h^{T}v\).&lt;/p&gt;

&lt;p&gt;Consequently, the dual LP can be defined as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{u,v} &amp;amp;&amp;amp;-b^{T}u-h^{T}v \\\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;c = -A^{T}u-G^{T}v \\\\
&amp;amp; &amp;amp;&amp;amp;v\geq 0.
\end{align}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>10-01 Lower Bounds in Linear Programs</title>
   <link href="http://localhost:4000/contents/en/chapter10/10_01_Lower_Bounds_in_Linear_Programs/"/>
   <updated>2021-03-22T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter10/10_01_Lower_Bounds_in_Linear_Programs</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;h2 id=&quot;example-1-form-where-the-constraint-contains-the-objective-function&quot;&gt;Example 1: Form where the constraint contains the objective function&lt;/h2&gt;

&lt;p&gt;Suppose we want to find the lower bound value B of the optimal value for a given convex problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
B \leq \min_{x} f(x).
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s specifically consider the lower bound of linear programs. We will examine cases ranging from simple cases to generalized forms in order.
First, taking the simplest form of LP problem as an example&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y}  
&amp;amp; &amp;amp;{x+y} \\\\
&amp;amp;\text{subject to} 
&amp;amp; &amp;amp;{x + y \geq 2}\\\\
&amp;amp; &amp;amp; &amp;amp;{x, y \geq 0.}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The above problem already includes the lower bound of the objective function in the constraint, so we can easily see that \(B=2\).&lt;/p&gt;

&lt;p&gt;Furthermore, let’s examine the case where the constraint does not include a lower bound.&lt;/p&gt;

&lt;h2 id=&quot;example-2-form-where-the-objective-function-can-be-expressed-as-a-linear-combination-of-constraints-1&quot;&gt;Example 2: Form where the objective function can be expressed as a linear combination of constraints (1)&lt;/h2&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y}  
&amp;amp; &amp;amp; {x+3y} \\\\
&amp;amp;\text{subject to} 
&amp;amp; &amp;amp;{x + y \geq 2}\\\\
&amp;amp; &amp;amp; &amp;amp;{x, y \geq 0.}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If \(x,\, y\) are feasible, then multiplying the three constraints by scalar values and adding or subtracting them still satisfies all three constraints. Therefore, for such an LP problem, the process of multiplying constraints by scalar values and adding or subtracting them, i.e., expressing the objective function as a linear combination of constraints, is possible, and as a result, we can find \(B\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;{x + y \geq 2}\\\\
&amp;amp;{+} &amp;amp;{0x \geq 0}\\\\
&amp;amp;{+} &amp;amp;{2y \geq 0}\\\\
&amp;amp;{=} &amp;amp;{x + 3y \geq 2}\\\\

&amp;amp; &amp;amp;{\text{Lower bound}\ B = 2.}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Generalizing further by applying arbitrary variables to represent the objective function, we get the following:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y}  
&amp;amp; &amp;amp;{px+qy} \\\\
&amp;amp;\text{subject to} 
&amp;amp; &amp;amp;{x + y \geq 2}\\\\
&amp;amp; &amp;amp; &amp;amp;{x, y \geq 0.}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Similar to the second example, by multiplying the constraints by scalar values a, b, c respectively, the objective function can be expressed as a linear combination of these three.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; &amp;amp;{a(x+y) \geq 2a} \\\\
&amp;amp;{+} &amp;amp;{bx \geq 0} \\\\
&amp;amp;{+} &amp;amp;{cy \geq 0} \\\\
&amp;amp;{=} &amp;amp;{(a+b)x+(a+c)y \geq 2a} \\\\
&amp;amp;&amp;amp;\text{Lower bound}\ B=2a, \\
&amp;amp;&amp;amp;\text{for any satisfying a,b,c below}\\\\
&amp;amp; &amp;amp;{a + b = p}\\\\
&amp;amp; &amp;amp;{a + c = q}\\\\
&amp;amp; &amp;amp;{a,b,c \geq 0.}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For the lower bound to satisfy being 2a as above, since the inequality sign would be reversed in the process of multiplying by scalar values and this would not hold, the conditions \(a, b, c\) must be positive and the sum of scalar values must equal the objective function, i.e., the conditions \(a+b = p\) and \(a+c = q\) must be satisfied.&lt;/p&gt;

&lt;p&gt;A new optimization problem can be defined by maximizing the lower bound result obtained as above. In this case, the conditions that satisfy the lower bound become the constraints in this problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\max_{a, b, c}  
&amp;amp; &amp;amp;{2a} \\\\
&amp;amp;\text{subject to} 
&amp;amp; &amp;amp;{a + b = p}\\\\
&amp;amp; &amp;amp; &amp;amp;{a + c = q}\\\\
&amp;amp; &amp;amp; &amp;amp;{a, b, c \geq 0}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The original LP problem above is called the primal LP, and the form that redefines the optimization problem by maximizing the lower bound in the primal LP is called the dual LP. Note that the number of optimization variables in the dual problem equals the number of constraints in the primal problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{Primal LP}\qquad
&amp;amp;\qquad \min_{x, y}  &amp;amp;{px+qy} \\\\
&amp;amp;\qquad \text{subject to} &amp;amp;{x + y \geq 2}\\\\
&amp;amp;\qquad &amp;amp;{x, y \geq 0}\\\\
\\\\
\\\\
\text{Dual LP}\qquad
&amp;amp;\qquad \max_{a, b, c}  &amp;amp;{2a} \\\\
&amp;amp;\qquad \text{subject to} &amp;amp;{a + b = p}\\\\
&amp;amp;\qquad &amp;amp;{a + c = q}\\\\
&amp;amp;\qquad &amp;amp;{a, b, c \geq 0}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;example-3-form-where-the-objective-function-can-be-expressed-as-a-linear-combination-of-constraints-2&quot;&gt;Example 3: Form where the objective function can be expressed as a linear combination of constraints (2)&lt;/h2&gt;

&lt;p&gt;As a final example, let’s examine a form where the inequality signs in the constraints are reversed and equality constraints are included.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x, y}  &amp;amp;{px+qy} \\\\
&amp;amp;\text{subject to} &amp;amp;{x \geq 0}\\\\
&amp;amp; &amp;amp;{y \leq 1}\\\\
&amp;amp; &amp;amp;{3x + y = 2}\\\\
\\\\
&amp;amp; &amp;amp;{ax \geq 0}\\\\
&amp;amp;{+} &amp;amp;{-by \geq -b}\\\\
&amp;amp;{+} &amp;amp;{3cx + cy = 2c}\\\\
&amp;amp;{=} &amp;amp;{(a+3c)x+(-b+c)y \geq 2c-b}
\\\\
\\\\
&amp;amp;&amp;amp; \text{Lower bound}  \ B=2c-b, \\
&amp;amp;&amp;amp; \text{for any satisfying a,b,c below}\\\\
&amp;amp; &amp;amp;{a + 3c = p}\\\\
&amp;amp; &amp;amp;{-b + c = q}\\\\
&amp;amp; &amp;amp;{a,b \geq 0}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, c is a scalar value multiplied to both sides of the equality, so any value can be multiplied without restriction.&lt;/p&gt;

&lt;p&gt;Consequently, the dual LP can be defined as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\qquad \max_{a, b, c}  &amp;amp;{2c-b} \\\\
&amp;amp;\qquad \text{subject to} &amp;amp;{a + 3c = p}\\\\
&amp;amp;\qquad &amp;amp;{-b + c = q}\\\\
&amp;amp;\qquad &amp;amp;{a, b \geq 0}\\\\
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>06-07 Regularization và Loss Functions</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_07_regularization_and_loss_functions/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_07_regularization_and_loss_functions</id>
   <content type="html">&lt;script src=&quot;../../../public/js/script.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://d3js.org/d3.v7.min.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;giới-thiệu-vấn-đề-overfitting-trong-machine-learning&quot;&gt;Giới thiệu: Vấn đề Overfitting trong Machine Learning&lt;/h2&gt;

&lt;p&gt;Trong machine learning, một trong những thử thách lớn nhất là &lt;strong&gt;overfitting&lt;/strong&gt; - hiện tượng mô hình học quá chi tiết từ dữ liệu huấn luyện, dẫn đến hiệu suất kém trên dữ liệu mới. &lt;strong&gt;Regularization&lt;/strong&gt; là kỹ thuật quan trọng để giải quyết vấn đề này.&lt;/p&gt;

&lt;h3 id=&quot;tại-sao-cần-regularization&quot;&gt;Tại sao cần Regularization?&lt;/h3&gt;

&lt;p&gt;Hãy xem xét bài toán hồi quy tuyến tính cơ bản:
\(\min_{\mathbf{w}} \frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Vấn đề&lt;/strong&gt;: Khi số lượng đặc trưng lớn hoặc dữ liệu ít, mô hình có thể tìm được nghiệm với training error = 0 nhưng generalization kém.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Giải pháp&lt;/strong&gt;: Thêm &lt;strong&gt;regularization term&lt;/strong&gt; để “phạt” các trọng số lớn:
\(\min_{\mathbf{w}} \frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2 + \lambda R(\mathbf{w})\)&lt;/p&gt;

&lt;p&gt;trong đó:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\lambda &amp;gt; 0\) là &lt;strong&gt;regularization parameter&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;\(R(\mathbf{w})\) là &lt;strong&gt;regularization function&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ridge-regression-l2-regularization&quot;&gt;Ridge Regression (L2 Regularization)&lt;/h2&gt;

&lt;h3 id=&quot;định-nghĩa-toán-học&quot;&gt;Định nghĩa Toán học&lt;/h3&gt;

&lt;p&gt;Ridge regression sử dụng L2 norm làm regularization term:&lt;/p&gt;

\[\min_{\mathbf{w}} \frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2 + \frac{\lambda}{2} \|\mathbf{w}\|_2^2\]

&lt;p&gt;&lt;strong&gt;Giải thích các thành phần:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Loss term&lt;/strong&gt;: \(\frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2\) - đo lường độ lệch giữa dự đoán và thực tế&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization term&lt;/strong&gt;: \(\frac{\lambda}{2} \|\mathbf{w}\|_2^2 = \frac{\lambda}{2} \sum_{j=1}^p w_j^2\) - phạt các trọng số lớn&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization strength&lt;/strong&gt;: \(\lambda\) kiểm soát mức độ regularization&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nghiệm-giải-tích&quot;&gt;Nghiệm Giải tích&lt;/h3&gt;

&lt;p&gt;Ridge regression có nghiệm dạng đóng:
\(\mathbf{w}^* = (\mathbf{X}^T\mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{X}^T \mathbf{y}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ưu điểm của nghiệm này:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ma trận \((\mathbf{X}^T\mathbf{X} + \lambda \mathbf{I})\) luôn khả nghịch khi \(\lambda &amp;gt; 0\)&lt;/li&gt;
  &lt;li&gt;Giải quyết vấn đề multicollinearity&lt;/li&gt;
  &lt;li&gt;Tính toán hiệu quả&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hiệu-ứng-của-ridge-regularization&quot;&gt;Hiệu ứng của Ridge Regularization&lt;/h3&gt;

&lt;div id=&quot;ridge-effect-demo&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;&quot;&gt;
        &lt;h4&gt;Điều khiển Ridge Regularization&lt;/h4&gt;
        &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px;&quot;&gt;
            &lt;div&gt;
                &lt;label for=&quot;ridge-lambda&quot;&gt;Lambda (λ): &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;ridge-lambda&quot; min=&quot;0&quot; max=&quot;10&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;
                &lt;span id=&quot;ridge-lambda-value&quot;&gt;1.0&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;ridge-noise&quot;&gt;Noise Level: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;ridge-noise&quot; min=&quot;0&quot; max=&quot;0.5&quot; step=&quot;0.05&quot; value=&quot;0.1&quot; /&gt;
                &lt;span id=&quot;ridge-noise-value&quot;&gt;0.1&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;ridge-features&quot;&gt;Number of Features: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;ridge-features&quot; min=&quot;5&quot; max=&quot;20&quot; step=&quot;1&quot; value=&quot;10&quot; /&gt;
                &lt;span id=&quot;ridge-features-value&quot;&gt;10&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
            &lt;button id=&quot;ridge-regenerate&quot; style=&quot;background-color: #4CAF50; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Tạo dữ liệu mới&lt;/button&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Coefficients Path&lt;/h4&gt;
            &lt;svg id=&quot;ridge-coefficients&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;ridge-coeff-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;L2 Norm của coefficients: 0&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Training vs Validation Error&lt;/h4&gt;
            &lt;svg id=&quot;ridge-error&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;ridge-error-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;Optimal λ: 0&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;practical-example-minimizing-a-quadratic-function&quot;&gt;Practical Example: Minimizing a Quadratic Function&lt;/h2&gt;

&lt;p&gt;Để hiểu sâu hơn về regularization, hãy xem xét một ví dụ cụ thể với quadratic function. Đây là nền tảng toán học cho nhiều thuật toán machine learning.&lt;/p&gt;

&lt;h3 id=&quot;bài-toán-portfolio-optimization-với-regularization&quot;&gt;Bài toán: Portfolio Optimization với Regularization&lt;/h3&gt;

&lt;p&gt;Giả sử chúng ta có bài toán tối ưu hóa danh mục đầu tư:&lt;/p&gt;

\[\min_{\mathbf{w}} \frac{1}{2} \mathbf{w}^T \mathbf{Q} \mathbf{w} - \mathbf{\mu}^T \mathbf{w} + \frac{\lambda}{2} \|\mathbf{w}\|_2^2\]

&lt;p&gt;trong đó:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{w} \in \mathbb{R}^n\): trọng số đầu tư cho \(n\) tài sản&lt;/li&gt;
  &lt;li&gt;\(\mathbf{Q} \in \mathbb{R}^{n \times n}\): ma trận hiệp phương sai (risk matrix)&lt;/li&gt;
  &lt;li&gt;\(\mathbf{\mu} \in \mathbb{R}^n\): vector lợi nhuận kỳ vọng&lt;/li&gt;
  &lt;li&gt;\(\lambda &amp;gt; 0\): tham số regularization (risk aversion)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;phân-tích-toán-học-chi-tiết&quot;&gt;Phân tích Toán học Chi tiết&lt;/h3&gt;

&lt;h4 id=&quot;1-gradient-của-objective-function&quot;&gt;1. Gradient của Objective Function&lt;/h4&gt;

\[\nabla f(\mathbf{w}) = \mathbf{Q}\mathbf{w} - \mathbf{\mu} + \lambda \mathbf{w} = (\mathbf{Q} + \lambda \mathbf{I})\mathbf{w} - \mathbf{\mu}\]

&lt;h4 id=&quot;2-hessian-matrix&quot;&gt;2. Hessian Matrix&lt;/h4&gt;

\[\nabla^2 f(\mathbf{w}) = \mathbf{Q} + \lambda \mathbf{I}\]

&lt;p&gt;&lt;strong&gt;Quan sát quan trọng&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Khi \(\lambda &amp;gt; 0\), Hessian luôn positive definite (nếu \(\mathbf{Q}\) positive semidefinite)&lt;/li&gt;
  &lt;li&gt;Điều này đảm bảo hàm mục tiêu là strongly convex&lt;/li&gt;
  &lt;li&gt;Nghiệm tối ưu duy nhất tồn tại&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3-nghiệm-tối-ưu&quot;&gt;3. Nghiệm Tối ưu&lt;/h4&gt;

&lt;p&gt;Đặt gradient bằng 0:
\((\mathbf{Q} + \lambda \mathbf{I})\mathbf{w}^* = \mathbf{\mu}\)&lt;/p&gt;

\[\mathbf{w}^* = (\mathbf{Q} + \lambda \mathbf{I})^{-1} \mathbf{\mu}\]

&lt;h3 id=&quot;interactive-quadratic-function-explorer&quot;&gt;Interactive Quadratic Function Explorer&lt;/h3&gt;

&lt;div id=&quot;quadratic-function-demo&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;&quot;&gt;
        &lt;h4&gt;Quadratic Function Parameters&lt;/h4&gt;
        &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px;&quot;&gt;
            &lt;div&gt;
                &lt;label for=&quot;quad-lambda&quot;&gt;Regularization λ: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;quad-lambda&quot; min=&quot;0&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;
                &lt;span id=&quot;quad-lambda-value&quot;&gt;1.0&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;quad-condition&quot;&gt;Condition Number: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;quad-condition&quot; min=&quot;1&quot; max=&quot;50&quot; step=&quot;1&quot; value=&quot;10&quot; /&gt;
                &lt;span id=&quot;quad-condition-value&quot;&gt;10&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;quad-dimension&quot;&gt;Dimension: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;quad-dimension&quot; min=&quot;2&quot; max=&quot;5&quot; step=&quot;1&quot; value=&quot;2&quot; /&gt;
                &lt;span id=&quot;quad-dimension-value&quot;&gt;2&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
            &lt;button id=&quot;quad-optimize&quot; style=&quot;background-color: #4CAF50; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Run Optimization&lt;/button&gt;
            &lt;button id=&quot;quad-reset&quot; style=&quot;background-color: #f44336; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Reset&lt;/button&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;2D Contour Plot&lt;/h4&gt;
            &lt;svg id=&quot;quadratic-contour&quot; width=&quot;400&quot; height=&quot;400&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;quad-contour-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;Click to set starting point&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Convergence Analysis&lt;/h4&gt;
            &lt;svg id=&quot;quadratic-convergence&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;quad-convergence-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;Convergence rate: -&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;margin-top: 20px;&quot;&gt;
        &lt;h4&gt;Eigenvalue Analysis&lt;/h4&gt;
        &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
            &lt;div style=&quot;text-align: center;&quot;&gt;
                &lt;h5&gt;Original Matrix Q&lt;/h5&gt;
                &lt;svg id=&quot;eigenvalue-original&quot; width=&quot;300&quot; height=&quot;200&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;/div&gt;
            &lt;div style=&quot;text-align: center;&quot;&gt;
                &lt;h5&gt;Regularized Matrix Q + λI&lt;/h5&gt;
                &lt;svg id=&quot;eigenvalue-regularized&quot; width=&quot;300&quot; height=&quot;200&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;margin-top: 10px; padding: 10px; background-color: #e3f2fd; border-radius: 4px;&quot;&gt;
            &lt;p id=&quot;eigenvalue-analysis&quot; style=&quot;margin: 0; font-size: 14px;&quot;&gt;
                &lt;strong&gt;Analysis:&lt;/strong&gt; Regularization improves condition number from ∞ to finite value
            &lt;/p&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;gradient-descent-cho-quadratic-functions&quot;&gt;Gradient Descent cho Quadratic Functions&lt;/h3&gt;

&lt;p&gt;Đối với quadratic function, gradient descent có dạng đặc biệt:&lt;/p&gt;

\[\mathbf{w}^{(k+1)} = \mathbf{w}^{(k)} - \alpha [(\mathbf{Q} + \lambda \mathbf{I})\mathbf{w}^{(k)} - \mathbf{\mu}]\]

&lt;h4 id=&quot;phân-tích-convergence-rate&quot;&gt;Phân tích Convergence Rate&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Eigenvalue decomposition&lt;/strong&gt;: \(\mathbf{Q} + \lambda \mathbf{I} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^T\)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Convergence rate&lt;/strong&gt;: $$\rho = \max_i \left&lt;/td&gt;
      &lt;td&gt;1 - \alpha \lambda_i\right&lt;/td&gt;
      &lt;td&gt;$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;trong đó \(\lambda_i\) là eigenvalues của \(\mathbf{Q} + \lambda \mathbf{I}\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Optimal step size&lt;/strong&gt;: \(\alpha^* = \frac{2}{\lambda_{\min} + \lambda_{\max}}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Convergence factor&lt;/strong&gt;: \(\rho^* = \frac{\kappa - 1}{\kappa + 1}\)&lt;/p&gt;

&lt;p&gt;trong đó \(\kappa = \frac{\lambda_{\max}}{\lambda_{\min}}\) là condition number.&lt;/p&gt;

&lt;h3 id=&quot;hiệu-ứng-của-regularization-lên-convergence&quot;&gt;Hiệu ứng của Regularization lên Convergence&lt;/h3&gt;

&lt;div id=&quot;regularization-convergence-demo&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #fff3e0;&quot;&gt;
        &lt;h4&gt;Convergence Rate Analysis&lt;/h4&gt;
        &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px;&quot;&gt;
            &lt;div&gt;
                &lt;label for=&quot;conv-lambda&quot;&gt;Lambda: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;conv-lambda&quot; min=&quot;0.01&quot; max=&quot;3&quot; step=&quot;0.01&quot; value=&quot;0.1&quot; /&gt;
                &lt;span id=&quot;conv-lambda-value&quot;&gt;0.1&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;conv-step-size&quot;&gt;Step Size: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;conv-step-size&quot; min=&quot;0.01&quot; max=&quot;0.5&quot; step=&quot;0.01&quot; value=&quot;0.1&quot; /&gt;
                &lt;span id=&quot;conv-step-size-value&quot;&gt;0.1&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;button id=&quot;conv-optimal-step&quot; style=&quot;background-color: #FF9800; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Optimal Step Size&lt;/button&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Convergence Comparison&lt;/h4&gt;
            &lt;svg id=&quot;convergence-comparison&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;div style=&quot;display: flex; gap: 15px; justify-content: center; font-size: 12px;&quot;&gt;
                    &lt;span style=&quot;color: #1f77b4;&quot;&gt;■ No Regularization&lt;/span&gt;
                    &lt;span style=&quot;color: #ff7f0e;&quot;&gt;■ With Regularization&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Condition Number vs λ&lt;/h4&gt;
            &lt;svg id=&quot;condition-number-plot&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;condition-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;Current κ: ∞&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;case-study-ill-conditioned-problems&quot;&gt;Case Study: Ill-conditioned Problems&lt;/h3&gt;

&lt;h4 id=&quot;vấn-đề-multicollinearity-trong-linear-regression&quot;&gt;Vấn đề: Multicollinearity trong Linear Regression&lt;/h4&gt;

&lt;p&gt;Xem xét ma trận thiết kế \(\mathbf{X}\) với các cột gần như phụ thuộc tuyến tính:&lt;/p&gt;

\[\mathbf{X} = \begin{bmatrix}
1 &amp;amp; 1 &amp;amp; 1.001 \\
1 &amp;amp; 2 &amp;amp; 2.001 \\
1 &amp;amp; 3 &amp;amp; 3.001 \\
\vdots &amp;amp; \vdots &amp;amp; \vdots
\end{bmatrix}\]

&lt;p&gt;&lt;strong&gt;Normal equations&lt;/strong&gt;: \(\mathbf{X}^T\mathbf{X} \mathbf{w} = \mathbf{X}^T \mathbf{y}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Vấn đề&lt;/strong&gt;: \(\mathbf{X}^T\mathbf{X}\) có condition number rất lớn → numerical instability&lt;/p&gt;

&lt;h4 id=&quot;giải-pháp-ridge-regularization&quot;&gt;Giải pháp: Ridge Regularization&lt;/h4&gt;

\[(\mathbf{X}^T\mathbf{X} + \lambda \mathbf{I}) \mathbf{w} = \mathbf{X}^T \mathbf{y}\]

&lt;p&gt;&lt;strong&gt;Hiệu quả&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Condition number giảm từ \(10^{12}\) xuống \(10^2\)&lt;/li&gt;
  &lt;li&gt;Numerical stability được cải thiện đáng kể&lt;/li&gt;
  &lt;li&gt;Trade-off: bias tăng nhưng variance giảm&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mathematical-insights&quot;&gt;Mathematical Insights&lt;/h3&gt;

&lt;h4 id=&quot;1-bias-variance-decomposition&quot;&gt;1. Bias-Variance Decomposition&lt;/h4&gt;

&lt;p&gt;Đối với Ridge regression:&lt;/p&gt;

\[\text{MSE} = \text{Bias}^2 + \text{Variance} + \text{Noise}\]

&lt;p&gt;&lt;strong&gt;Bias&lt;/strong&gt;: \(\mathbb{E}[\hat{\mathbf{w}}] - \mathbf{w}^* = -\lambda (\mathbf{X}^T\mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{w}^*\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}[\hat{\mathbf{w}}] = \sigma^2 (\mathbf{X}^T\mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{X}^T\mathbf{X} (\mathbf{X}^T\mathbf{X} + \lambda \mathbf{I})^{-1}\)&lt;/p&gt;

&lt;h4 id=&quot;2-effective-degrees-of-freedom&quot;&gt;2. Effective Degrees of Freedom&lt;/h4&gt;

\[\text{df}(\lambda) = \text{tr}[\mathbf{X}(\mathbf{X}^T\mathbf{X} + \lambda \mathbf{I})^{-1}\mathbf{X}^T] = \sum_{i=1}^p \frac{\sigma_i^2}{\sigma_i^2 + \lambda}\]

&lt;p&gt;trong đó \(\sigma_i^2\) là singular values của \(\mathbf{X}\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: Regularization effectively reduces model complexity.&lt;/p&gt;

&lt;h3 id=&quot;computational-considerations&quot;&gt;Computational Considerations&lt;/h3&gt;

&lt;h4 id=&quot;1-direct-solution-vs-iterative-methods&quot;&gt;1. Direct Solution vs Iterative Methods&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Direct (Cholesky decomposition)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Complexity: \(O(p^3)\)&lt;/li&gt;
  &lt;li&gt;Suitable for \(p &amp;lt; 10^4\)&lt;/li&gt;
  &lt;li&gt;Numerically stable with regularization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Iterative (Gradient descent)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Complexity per iteration: \(O(np)\)&lt;/li&gt;
  &lt;li&gt;Suitable for large \(p\)&lt;/li&gt;
  &lt;li&gt;Convergence depends on condition number&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-preconditioning&quot;&gt;2. Preconditioning&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Jacobi preconditioning&lt;/strong&gt;: \(\mathbf{P} = \text{diag}(\mathbf{Q} + \lambda \mathbf{I})\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Preconditioned system&lt;/strong&gt;: \(\mathbf{P}^{-1}(\mathbf{Q} + \lambda \mathbf{I})\mathbf{w} = \mathbf{P}^{-1}\mathbf{\mu}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Benefit&lt;/strong&gt;: Improved condition number → faster convergence&lt;/p&gt;

&lt;h2 id=&quot;lasso-regression-l1-regularization&quot;&gt;Lasso Regression (L1 Regularization)&lt;/h2&gt;

&lt;h3 id=&quot;định-nghĩa-toán-học-1&quot;&gt;Định nghĩa Toán học&lt;/h3&gt;

&lt;p&gt;Lasso (Least Absolute Shrinkage and Selection Operator) sử dụng L1 norm:&lt;/p&gt;

\[\min_{\mathbf{w}} \frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2 + \lambda \|\mathbf{w}\|_1\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;trong đó $$|\mathbf{w}|&lt;em&gt;1 = \sum&lt;/em&gt;{j=1}^p&lt;/td&gt;
      &lt;td&gt;w_j&lt;/td&gt;
      &lt;td&gt;$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;đặc-điểm-quan-trọng-của-lasso&quot;&gt;Đặc điểm Quan trọng của Lasso&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1. Sparse Solutions (Nghiệm thưa):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lasso có thể đặt một số coefficients về &lt;strong&gt;chính xác bằng 0&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Tự động thực hiện &lt;strong&gt;feature selection&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Tạo ra mô hình đơn giản, dễ diễn giải&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2. Không có nghiệm dạng đóng:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Cần sử dụng thuật toán tối ưu hóa (coordinate descent, proximal gradient)&lt;/li&gt;
  &lt;li&gt;Phức tạp tính toán hơn Ridge&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;so-sánh-ridge-vs-lasso&quot;&gt;So sánh Ridge vs Lasso&lt;/h3&gt;

&lt;div id=&quot;ridge-lasso-comparison&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f0f8ff;&quot;&gt;
        &lt;h4&gt;So sánh Ridge và Lasso Regularization&lt;/h4&gt;
        &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr; gap: 20px;&quot;&gt;
            &lt;div&gt;
                &lt;label for=&quot;comparison-lambda&quot;&gt;Lambda (λ): &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;comparison-lambda&quot; min=&quot;0&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;
                &lt;span id=&quot;comparison-lambda-value&quot;&gt;1.0&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;comparison-correlation&quot;&gt;Feature Correlation: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;comparison-correlation&quot; min=&quot;0&quot; max=&quot;0.9&quot; step=&quot;0.1&quot; value=&quot;0.5&quot; /&gt;
                &lt;span id=&quot;comparison-correlation-value&quot;&gt;0.5&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
            &lt;button id=&quot;comparison-update&quot; style=&quot;background-color: #2196F3; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Cập nhật So sánh&lt;/button&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Ridge Coefficients&lt;/h4&gt;
            &lt;svg id=&quot;ridge-comparison&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 5px; padding: 5px; background-color: #e8f5e8; border-radius: 4px;&quot;&gt;
                &lt;p style=&quot;margin: 0; font-size: 12px;&quot;&gt;Shrinkage: Đều, không về 0&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Lasso Coefficients&lt;/h4&gt;
            &lt;svg id=&quot;lasso-comparison&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 5px; padding: 5px; background-color: #fff3e0; border-radius: 4px;&quot;&gt;
                &lt;p style=&quot;margin: 0; font-size: 12px;&quot;&gt;Sparsity: Một số về chính xác 0&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Regularization Geometry&lt;/h4&gt;
            &lt;svg id=&quot;regularization-geometry&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 5px; padding: 5px; background-color: #f3e5f5; border-radius: 4px;&quot;&gt;
                &lt;p style=&quot;margin: 0; font-size: 12px;&quot;&gt;L1: Diamond, L2: Circle&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;hình-học-của-regularization&quot;&gt;Hình học của Regularization&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Hiểu trực quan tại sao Lasso tạo sparse solutions:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;L1 constraint&lt;/strong&gt;: \(\|\mathbf{w}\|_1 \leq t\) tạo ra &lt;strong&gt;diamond shape&lt;/strong&gt; trong 2D&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;L2 constraint&lt;/strong&gt;: \(\|\mathbf{w}\|_2 \leq t\) tạo ra &lt;strong&gt;circular shape&lt;/strong&gt; trong 2D&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Intersection với loss contours&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;L1: Có khả năng cao giao với contour tại các góc (sparse solutions)&lt;/li&gt;
      &lt;li&gt;L2: Thường giao tại các điểm smooth (non-sparse solutions)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;elastic-net-kết-hợp-ridge-và-lasso&quot;&gt;Elastic Net: Kết hợp Ridge và Lasso&lt;/h2&gt;

&lt;p&gt;Elastic Net kết hợp cả L1 và L2 regularization:&lt;/p&gt;

\[\min_{\mathbf{w}} \frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2 + \lambda \left[ \alpha \|\mathbf{w}\|_1 + \frac{1-\alpha}{2} \|\mathbf{w}\|_2^2 \right]\]

&lt;p&gt;&lt;strong&gt;Tham số:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\alpha \in [0,1]\): mixing parameter&lt;/li&gt;
  &lt;li&gt;\(\alpha = 1\): Pure Lasso&lt;/li&gt;
  &lt;li&gt;\(\alpha = 0\): Pure Ridge&lt;/li&gt;
  &lt;li&gt;\(0 &amp;lt; \alpha &amp;lt; 1\): Combination&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ưu điểm:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Kết hợp sparsity của Lasso với stability của Ridge&lt;/li&gt;
  &lt;li&gt;Xử lý tốt grouped variables&lt;/li&gt;
  &lt;li&gt;Hoạt động tốt khi \(p &amp;gt; n\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;loss-functions-trong-machine-learning&quot;&gt;Loss Functions trong Machine Learning&lt;/h2&gt;

&lt;h3 id=&quot;1-regression-loss-functions&quot;&gt;1. Regression Loss Functions&lt;/h3&gt;

&lt;h4 id=&quot;mean-squared-error-mse&quot;&gt;Mean Squared Error (MSE)&lt;/h4&gt;
&lt;p&gt;\(L_{MSE}(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n (y_i - \mathbf{w}^T \mathbf{x}_i)^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Đặc điểm:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Smooth, differentiable everywhere&lt;/li&gt;
  &lt;li&gt;Sensitive to outliers&lt;/li&gt;
  &lt;li&gt;Convex optimization problem&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;mean-absolute-error-mae&quot;&gt;Mean Absolute Error (MAE)&lt;/h4&gt;
&lt;p&gt;\(L_{MAE}(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n |y_i - \mathbf{w}^T \mathbf{x}_i|\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Đặc điểm:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Robust to outliers&lt;/li&gt;
  &lt;li&gt;Non-differentiable at zero&lt;/li&gt;
  &lt;li&gt;Convex but requires subgradient methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;huber-loss&quot;&gt;Huber Loss&lt;/h4&gt;
&lt;p&gt;\(L_{Huber}(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n \begin{cases}
\frac{1}{2}(y_i - \mathbf{w}^T \mathbf{x}_i)^2 &amp;amp; \text{if } |y_i - \mathbf{w}^T \mathbf{x}_i| \leq \delta \\
\delta |y_i - \mathbf{w}^T \mathbf{x}_i| - \frac{1}{2}\delta^2 &amp;amp; \text{otherwise}
\end{cases}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Đặc điểm:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Combines MSE (small errors) and MAE (large errors)&lt;/li&gt;
  &lt;li&gt;Smooth and robust&lt;/li&gt;
  &lt;li&gt;Parameter \(\delta\) controls transition point&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-classification-loss-functions&quot;&gt;2. Classification Loss Functions&lt;/h3&gt;

&lt;h4 id=&quot;logistic-loss-cross-entropy&quot;&gt;Logistic Loss (Cross-entropy)&lt;/h4&gt;
&lt;p&gt;\(L_{logistic}(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n \log(1 + \exp(-y_i \mathbf{w}^T \mathbf{x}_i))\)&lt;/p&gt;

&lt;h4 id=&quot;hinge-loss-svm&quot;&gt;Hinge Loss (SVM)&lt;/h4&gt;
&lt;p&gt;\(L_{hinge}(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n \max(0, 1 - y_i \mathbf{w}^T \mathbf{x}_i)\)&lt;/p&gt;

&lt;h3 id=&quot;interactive-loss-functions-comparison&quot;&gt;Interactive Loss Functions Comparison&lt;/h3&gt;

&lt;div id=&quot;loss-functions-demo&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;&quot;&gt;
        &lt;h4&gt;So sánh các Loss Functions&lt;/h4&gt;
        &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px;&quot;&gt;
            &lt;div&gt;
                &lt;label for=&quot;loss-delta&quot;&gt;Huber Delta (δ): &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;loss-delta&quot; min=&quot;0.5&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;
                &lt;span id=&quot;loss-delta-value&quot;&gt;1.0&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;loss-range&quot;&gt;Error Range: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;loss-range&quot; min=&quot;2&quot; max=&quot;8&quot; step=&quot;0.5&quot; value=&quot;4&quot; /&gt;
                &lt;span id=&quot;loss-range-value&quot;&gt;4.0&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label&gt;
                    &lt;input type=&quot;checkbox&quot; id=&quot;show-derivatives&quot; /&gt; Show Derivatives
                &lt;/label&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Regression Loss Functions&lt;/h4&gt;
            &lt;svg id=&quot;regression-losses&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;div style=&quot;display: flex; gap: 15px; justify-content: center; font-size: 12px;&quot;&gt;
                    &lt;span style=&quot;color: #1f77b4;&quot;&gt;■ MSE&lt;/span&gt;
                    &lt;span style=&quot;color: #ff7f0e;&quot;&gt;■ MAE&lt;/span&gt;
                    &lt;span style=&quot;color: #2ca02c;&quot;&gt;■ Huber&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Classification Loss Functions&lt;/h4&gt;
            &lt;svg id=&quot;classification-losses&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;div style=&quot;display: flex; gap: 15px; justify-content: center; font-size: 12px;&quot;&gt;
                    &lt;span style=&quot;color: #d62728;&quot;&gt;■ Logistic&lt;/span&gt;
                    &lt;span style=&quot;color: #9467bd;&quot;&gt;■ Hinge&lt;/span&gt;
                    &lt;span style=&quot;color: #8c564b;&quot;&gt;■ 0-1 Loss&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;regularization-path-và-model-selection&quot;&gt;Regularization Path và Model Selection&lt;/h2&gt;

&lt;h3 id=&quot;cross-validation-cho-regularization&quot;&gt;Cross-Validation cho Regularization&lt;/h3&gt;

&lt;p&gt;Việc chọn \(\lambda\) tối ưu thường được thực hiện thông qua cross-validation:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Chia dữ liệu&lt;/strong&gt;: Training, validation, test sets&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Grid search&lt;/strong&gt;: Thử nhiều giá trị \(\lambda\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Evaluate&lt;/strong&gt;: Tính validation error cho mỗi \(\lambda\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Select&lt;/strong&gt;: Chọn \(\lambda\) có validation error thấp nhất&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;regularization-path-visualization&quot;&gt;Regularization Path Visualization&lt;/h3&gt;

&lt;div id=&quot;regularization-path-demo&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f0f8ff;&quot;&gt;
        &lt;h4&gt;Regularization Path Analysis&lt;/h4&gt;
        &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px;&quot;&gt;
            &lt;div&gt;
                &lt;label for=&quot;path-method&quot;&gt;Method: &lt;/label&gt;
                &lt;select id=&quot;path-method&quot;&gt;
                    &lt;option value=&quot;ridge&quot;&gt;Ridge&lt;/option&gt;
                    &lt;option value=&quot;lasso&quot;&gt;Lasso&lt;/option&gt;
                    &lt;option value=&quot;elastic&quot;&gt;Elastic Net&lt;/option&gt;
                &lt;/select&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;path-alpha&quot;&gt;Elastic Net α: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;path-alpha&quot; min=&quot;0&quot; max=&quot;1&quot; step=&quot;0.1&quot; value=&quot;0.5&quot; /&gt;
                &lt;span id=&quot;path-alpha-value&quot;&gt;0.5&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;button id=&quot;path-animate&quot; style=&quot;background-color: #FF9800; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Animate Path&lt;/button&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Coefficient Path&lt;/h4&gt;
            &lt;svg id=&quot;coefficient-path&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;path-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;Current λ: 0, Active features: 0&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Cross-Validation Curve&lt;/h4&gt;
            &lt;svg id=&quot;cv-curve&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;cv-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;Optimal λ: 0, CV Score: 0&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;practical-guidelines-và-best-practices&quot;&gt;Practical Guidelines và Best Practices&lt;/h2&gt;

&lt;h3 id=&quot;1-khi-nào-sử-dụng-ridge-vs-lasso&quot;&gt;1. Khi nào sử dụng Ridge vs Lasso?&lt;/h3&gt;

&lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;border: 1px solid #4CAF50; padding: 15px; border-radius: 5px; background-color: #f1f8e9;&quot;&gt;
        &lt;h4 style=&quot;color: #4CAF50;&quot;&gt;Sử dụng Ridge khi:&lt;/h4&gt;
        &lt;ul&gt;
            &lt;li&gt;Tất cả features đều có ý nghĩa&lt;/li&gt;
            &lt;li&gt;Multicollinearity cao&lt;/li&gt;
            &lt;li&gt;Cần stability trong predictions&lt;/li&gt;
            &lt;li&gt;Dataset nhỏ, nhiều features&lt;/li&gt;
            &lt;li&gt;Không cần feature selection tự động&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div style=&quot;border: 1px solid #FF9800; padding: 15px; border-radius: 5px; background-color: #fff8e1;&quot;&gt;
        &lt;h4 style=&quot;color: #FF9800;&quot;&gt;Sử dụng Lasso khi:&lt;/h4&gt;
        &lt;ul&gt;
            &lt;li&gt;Cần feature selection tự động&lt;/li&gt;
            &lt;li&gt;Nhiều features không liên quan&lt;/li&gt;
            &lt;li&gt;Muốn mô hình đơn giản, dễ diễn giải&lt;/li&gt;
            &lt;li&gt;Sparse solutions được ưa chuộng&lt;/li&gt;
            &lt;li&gt;High-dimensional data&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2-hyperparameter-tuning-strategy&quot;&gt;2. Hyperparameter Tuning Strategy&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Pseudo-code cho regularization tuning
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;tune_regularization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lambda_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;logspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Log-spaced values
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;best_lambda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;inf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda_val&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit_regularized_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;val_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_score&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;best_lambda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda_val&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-feature-scaling&quot;&gt;3. Feature Scaling&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Quan trọng&lt;/strong&gt;: Regularization nhạy cảm với scale của features!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ridge/Lasso&lt;/strong&gt;: Yêu cầu feature scaling (standardization)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lý do&lt;/strong&gt;: Regularization penalty phụ thuộc vào magnitude của coefficients&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Giải pháp&lt;/strong&gt;: Standardize features trước khi áp dụng regularization&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;kết-luận-và-takeaways&quot;&gt;Kết luận và Takeaways&lt;/h2&gt;

&lt;h3 id=&quot;những-điểm-chính&quot;&gt;Những điểm chính:&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt; là công cụ mạnh mẽ để chống overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ridge (L2)&lt;/strong&gt; tạo smooth shrinkage, tốt cho stability&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lasso (L1)&lt;/strong&gt; tạo sparse solutions, tốt cho feature selection&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Elastic Net&lt;/strong&gt; kết hợp ưu điểm của cả hai&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Loss function choice&lt;/strong&gt; ảnh hưởng lớn đến model behavior&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cross-validation&lt;/strong&gt; là key cho hyperparameter tuning&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;practical-workflow&quot;&gt;Practical Workflow:&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Data preprocessing&lt;/strong&gt;: Scale features appropriately&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Method selection&lt;/strong&gt;: Choose based on problem characteristics&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hyperparameter tuning&lt;/strong&gt;: Use cross-validation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Model evaluation&lt;/strong&gt;: Test on held-out data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: Analyze coefficient patterns&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Nhớ rằng&lt;/strong&gt;: Regularization không phải là magic bullet - hiểu rõ data và problem domain vẫn là quan trọng nhất!&lt;/p&gt;

&lt;script&gt;
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    // Quadratic Function Demo
    initializeQuadraticFunctionDemo();
    
    // Regularization Convergence Demo
    initializeRegularizationConvergenceDemo();
    
    // Ridge Effect Demo
    initializeRidgeEffectDemo();
    
    // Ridge vs Lasso Comparison
    initializeRidgeLassoComparison();
    
    // Loss Functions Demo
    initializeLossFunctionsDemo();
    
    // Regularization Path Demo
    initializeRegularizationPathDemo();
    
    function initializeRidgeEffectDemo() {
        const lambdaSlider = document.getElementById(&apos;ridge-lambda&apos;);
        const noiseSlider = document.getElementById(&apos;ridge-noise&apos;);
        const featuresSlider = document.getElementById(&apos;ridge-features&apos;);
        const regenerateBtn = document.getElementById(&apos;ridge-regenerate&apos;);
        
        let currentData = generateRidgeData();
        
        function generateRidgeData() {
            const n = 50; // samples
            const p = parseInt(featuresSlider.value); // features
            const noise = parseFloat(noiseSlider.value);
            
            // Generate true coefficients (sparse)
            const trueCoeffs = Array(p).fill(0).map((_, i) =&gt; 
                i &lt; 3 ? (Math.random() - 0.5) * 4 : 0
            );
            
            // Generate X matrix
            const X = Array(n).fill().map(() =&gt; 
                Array(p).fill().map(() =&gt; Math.random() * 2 - 1)
            );
            
            // Generate y with noise
            const y = X.map(row =&gt; 
                row.reduce((sum, x, i) =&gt; sum + x * trueCoeffs[i], 0) + 
                (Math.random() - 0.5) * noise * 2
            );
            
            return { X, y, trueCoeffs, n, p };
        }
        
        function updateRidgeDemo() {
            const lambda = parseFloat(lambdaSlider.value);
            document.getElementById(&apos;ridge-lambda-value&apos;).textContent = lambda.toFixed(1);
            
            // Compute Ridge coefficients for different lambda values
            const lambdaRange = Array(50).fill().map((_, i) =&gt; i * 0.2);
            const coeffPaths = computeRidgeCoefficients(currentData, lambdaRange);
            
            // Update visualizations
            updateRidgeCoefficientsPlot(coeffPaths, lambdaRange, lambda);
            updateRidgeErrorPlot(currentData, lambdaRange);
        }
        
        function computeRidgeCoefficients(data, lambdaRange) {
            const { X, y, p } = data;
            const paths = Array(p).fill().map(() =&gt; []);
            
            lambdaRange.forEach(lambda =&gt; {
                const coeffs = solveRidge(X, y, lambda);
                coeffs.forEach((coeff, i) =&gt; paths[i].push(coeff));
            });
            
            return paths;
        }
        
        function solveRidge(X, y, lambda) {
            // Simplified Ridge solution: w = (X&apos;X + λI)^(-1) X&apos;y
            const p = X[0].length;
            const n = X.length;
            
            // Compute X&apos;X
            const XtX = Array(p).fill().map(() =&gt; Array(p).fill(0));
            for (let i = 0; i &lt; p; i++) {
                for (let j = 0; j &lt; p; j++) {
                    for (let k = 0; k &lt; n; k++) {
                        XtX[i][j] += X[k][i] * X[k][j];
                    }
                }
            }
            
            // Add λI
            for (let i = 0; i &lt; p; i++) {
                XtX[i][i] += lambda;
            }
            
            // Compute X&apos;y
            const Xty = Array(p).fill(0);
            for (let i = 0; i &lt; p; i++) {
                for (let k = 0; k &lt; n; k++) {
                    Xty[i] += X[k][i] * y[k];
                }
            }
            
            // Solve linear system (simplified - using pseudo-inverse)
            return solveLinearSystem(XtX, Xty);
        }
        
        function solveLinearSystem(A, b) {
            // Simplified solution using Gaussian elimination
            const n = A.length;
            const coeffs = Array(n).fill(0);
            
            // For demo purposes, use a simplified approach
            for (let i = 0; i &lt; n; i++) {
                coeffs[i] = b[i] / (A[i][i] + 1e-10);
            }
            
            return coeffs;
        }
        
        function updateRidgeCoefficientsPlot(coeffPaths, lambdaRange, currentLambda) {
            const svg = d3.select(&apos;#ridge-coefficients&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain(d3.extent(lambdaRange))
                .range([0, width]);
            
            const allCoeffs = coeffPaths.flat();
            const yScale = d3.scaleLinear()
                .domain(d3.extent(allCoeffs))
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Lambda (λ)&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Coefficient Value&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(lambdaRange[i]))
                .y(d =&gt; yScale(d));
            
            // Draw coefficient paths
            const colors = d3.schemeCategory10;
            coeffPaths.forEach((path, i) =&gt; {
                g.append(&apos;path&apos;)
                    .datum(path)
                    .attr(&apos;fill&apos;, &apos;none&apos;)
                    .attr(&apos;stroke&apos;, colors[i % colors.length])
                    .attr(&apos;stroke-width&apos;, 2)
                    .attr(&apos;d&apos;, line);
            });
            
            // Current lambda line
            g.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, xScale(currentLambda))
                .attr(&apos;x2&apos;, xScale(currentLambda))
                .attr(&apos;y1&apos;, 0)
                .attr(&apos;y2&apos;, height)
                .attr(&apos;stroke&apos;, &apos;red&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;stroke-dasharray&apos;, &apos;5,5&apos;);
            
            // Update info
            const currentIndex = Math.round(currentLambda / 0.2);
            const currentCoeffs = coeffPaths.map(path =&gt; path[currentIndex] || 0);
            const l2Norm = Math.sqrt(currentCoeffs.reduce((sum, c) =&gt; sum + c*c, 0));
            document.getElementById(&apos;ridge-coeff-info&apos;).textContent = 
                `L2 Norm của coefficients: ${l2Norm.toFixed(3)}`;
        }
        
        function updateRidgeErrorPlot(data, lambdaRange) {
            // Simplified error computation for demo
            const svg = d3.select(&apos;#ridge-error&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Generate synthetic error curves
            const trainErrors = lambdaRange.map(lambda =&gt; 
                0.1 + 0.5 * lambda + Math.random() * 0.1
            );
            const valErrors = lambdaRange.map(lambda =&gt; 
                0.3 + 0.2 * Math.abs(lambda - 2) + Math.random() * 0.1
            );
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain(d3.extent(lambdaRange))
                .range([0, width]);
            
            const yScale = d3.scaleLinear()
                .domain([0, Math.max(...trainErrors, ...valErrors)])
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Lambda (λ)&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Error&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(lambdaRange[i]))
                .y(d =&gt; yScale(d));
            
            // Draw error curves
            g.append(&apos;path&apos;)
                .datum(trainErrors)
                .attr(&apos;fill&apos;, &apos;none&apos;)
                .attr(&apos;stroke&apos;, &apos;blue&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;d&apos;, line);
            
            g.append(&apos;path&apos;)
                .datum(valErrors)
                .attr(&apos;fill&apos;, &apos;none&apos;)
                .attr(&apos;stroke&apos;, &apos;red&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;d&apos;, line);
            
            // Legend
            const legend = g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${width - 100}, 20)`);
            
            legend.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, 0).attr(&apos;x2&apos;, 20)
                .attr(&apos;y1&apos;, 0).attr(&apos;y2&apos;, 0)
                .attr(&apos;stroke&apos;, &apos;blue&apos;).attr(&apos;stroke-width&apos;, 2);
            legend.append(&apos;text&apos;)
                .attr(&apos;x&apos;, 25).attr(&apos;y&apos;, 5)
                .text(&apos;Training&apos;);
            
            legend.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, 0).attr(&apos;x2&apos;, 20)
                .attr(&apos;y1&apos;, 15).attr(&apos;y2&apos;, 15)
                .attr(&apos;stroke&apos;, &apos;red&apos;).attr(&apos;stroke-width&apos;, 2);
            legend.append(&apos;text&apos;)
                .attr(&apos;x&apos;, 25).attr(&apos;y&apos;, 20)
                .text(&apos;Validation&apos;);
            
            // Find optimal lambda
            const optimalIndex = valErrors.indexOf(Math.min(...valErrors));
            const optimalLambda = lambdaRange[optimalIndex];
            document.getElementById(&apos;ridge-error-info&apos;).textContent = 
                `Optimal λ: ${optimalLambda.toFixed(2)}`;
        }
        
        // Event listeners
        lambdaSlider.addEventListener(&apos;input&apos;, updateRidgeDemo);
        noiseSlider.addEventListener(&apos;input&apos;, function() {
            document.getElementById(&apos;ridge-noise-value&apos;).textContent = this.value;
        });
        featuresSlider.addEventListener(&apos;input&apos;, function() {
            document.getElementById(&apos;ridge-features-value&apos;).textContent = this.value;
        });
        
        regenerateBtn.addEventListener(&apos;click&apos;, function() {
            currentData = generateRidgeData();
            updateRidgeDemo();
        });
        
        // Initial update
        updateRidgeDemo();
    }
    
    function initializeRidgeLassoComparison() {
        const lambdaSlider = document.getElementById(&apos;comparison-lambda&apos;);
        const correlationSlider = document.getElementById(&apos;comparison-correlation&apos;);
        const updateBtn = document.getElementById(&apos;comparison-update&apos;);
        
        function updateComparison() {
            const lambda = parseFloat(lambdaSlider.value);
            const correlation = parseFloat(correlationSlider.value);
            
            document.getElementById(&apos;comparison-lambda-value&apos;).textContent = lambda.toFixed(1);
            document.getElementById(&apos;comparison-correlation-value&apos;).textContent = correlation.toFixed(1);
            
            // Generate synthetic data with controlled correlation
            const p = 8; // features
            const trueCoeffs = [2, -1.5, 1, 0.5, -0.8, 0, 0, 0];
            
            // Compute Ridge and Lasso coefficients
            const ridgeCoeffs = computeRidgeCoeffs(trueCoeffs, lambda, correlation);
            const lassoCoeffs = computeLassoCoeffs(trueCoeffs, lambda, correlation);
            
            // Update visualizations
            updateComparisonPlot(&apos;ridge-comparison&apos;, ridgeCoeffs, &apos;Ridge&apos;);
            updateComparisonPlot(&apos;lasso-comparison&apos;, lassoCoeffs, &apos;Lasso&apos;);
            updateGeometryPlot(lambda);
        }
        
        function computeRidgeCoeffs(trueCoeffs, lambda, correlation) {
            // Simplified Ridge shrinkage
            const shrinkageFactor = 1 / (1 + lambda);
            return trueCoeffs.map(coeff =&gt; coeff * shrinkageFactor);
        }
        
        function computeLassoCoeffs(trueCoeffs, lambda, correlation) {
            // Simplified Lasso soft thresholding
            return trueCoeffs.map(coeff =&gt; {
                const absCoeff = Math.abs(coeff);
                if (absCoeff &lt;= lambda) return 0;
                return Math.sign(coeff) * (absCoeff - lambda);
            });
        }
        
        function updateComparisonPlot(svgId, coeffs, title) {
            const svg = d3.select(`#${svgId}`);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 40};
            const width = 300 - margin.left - margin.right;
            const height = 250 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Scales
            const xScale = d3.scaleBand()
                .domain(coeffs.map((_, i) =&gt; `w${i+1}`))
                .range([0, width])
                .padding(0.1);
            
            const yScale = d3.scaleLinear()
                .domain(d3.extent(coeffs))
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Bars
            const color = title === &apos;Ridge&apos; ? &apos;#4CAF50&apos; : &apos;#FF9800&apos;;
            g.selectAll(&apos;.bar&apos;)
                .data(coeffs)
                .enter().append(&apos;rect&apos;)
                .attr(&apos;class&apos;, &apos;bar&apos;)
                .attr(&apos;x&apos;, (d, i) =&gt; xScale(`w${i+1}`))
                .attr(&apos;width&apos;, xScale.bandwidth())
                .attr(&apos;y&apos;, d =&gt; d &gt;= 0 ? yScale(d) : yScale(0))
                .attr(&apos;height&apos;, d =&gt; Math.abs(yScale(d) - yScale(0)))
                .attr(&apos;fill&apos;, color);
            
            // Zero line
            g.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, 0)
                .attr(&apos;x2&apos;, width)
                .attr(&apos;y1&apos;, yScale(0))
                .attr(&apos;y2&apos;, yScale(0))
                .attr(&apos;stroke&apos;, &apos;black&apos;)
                .attr(&apos;stroke-width&apos;, 1);
        }
        
        function updateGeometryPlot(lambda) {
            const svg = d3.select(&apos;#regularization-geometry&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 40};
            const width = 300 - margin.left - margin.right;
            const height = 250 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            const centerX = width / 2;
            const centerY = height / 2;
            const radius = Math.min(width, height) / 3;
            
            // L2 constraint (circle)
            g.append(&apos;circle&apos;)
                .attr(&apos;cx&apos;, centerX)
                .attr(&apos;cy&apos;, centerY)
                .attr(&apos;r&apos;, radius)
                .attr(&apos;fill&apos;, &apos;none&apos;)
                .attr(&apos;stroke&apos;, &apos;#4CAF50&apos;)
                .attr(&apos;stroke-width&apos;, 3)
                .attr(&apos;opacity&apos;, 0.7);
            
            // L1 constraint (diamond)
            const diamondPoints = [
                [centerX, centerY - radius],
                [centerX + radius, centerY],
                [centerX, centerY + radius],
                [centerX - radius, centerY]
            ];
            
            const line = d3.line()
                .x(d =&gt; d[0])
                .y(d =&gt; d[1]);
            
            g.append(&apos;path&apos;)
                .datum([...diamondPoints, diamondPoints[0]])
                .attr(&apos;d&apos;, line)
                .attr(&apos;fill&apos;, &apos;none&apos;)
                .attr(&apos;stroke&apos;, &apos;#FF9800&apos;)
                .attr(&apos;stroke-width&apos;, 3)
                .attr(&apos;opacity&apos;, 0.7);
            
            // Contour lines (ellipses)
            for (let i = 1; i &lt;= 3; i++) {
                g.append(&apos;ellipse&apos;)
                    .attr(&apos;cx&apos;, centerX + 20)
                    .attr(&apos;cy&apos;, centerY - 10)
                    .attr(&apos;rx&apos;, i * 15)
                    .attr(&apos;ry&apos;, i * 25)
                    .attr(&apos;fill&apos;, &apos;none&apos;)
                    .attr(&apos;stroke&apos;, &apos;#666&apos;)
                    .attr(&apos;stroke-width&apos;, 1)
                    .attr(&apos;stroke-dasharray&apos;, &apos;3,3&apos;)
                    .attr(&apos;opacity&apos;, 0.5);
            }
            
            // Labels
            g.append(&apos;text&apos;)
                .attr(&apos;x&apos;, centerX + radius + 10)
                .attr(&apos;y&apos;, centerY + 5)
                .text(&apos;L2&apos;)
                .attr(&apos;fill&apos;, &apos;#4CAF50&apos;)
                .attr(&apos;font-weight&apos;, &apos;bold&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;x&apos;, centerX + radius/Math.sqrt(2) + 5)
                .attr(&apos;y&apos;, centerY - radius/Math.sqrt(2) - 5)
                .text(&apos;L1&apos;)
                .attr(&apos;fill&apos;, &apos;#FF9800&apos;)
                .attr(&apos;font-weight&apos;, &apos;bold&apos;);
        }
        
        // Event listeners
        lambdaSlider.addEventListener(&apos;input&apos;, updateComparison);
        correlationSlider.addEventListener(&apos;input&apos;, updateComparison);
        updateBtn.addEventListener(&apos;click&apos;, updateComparison);
        
        // Initial update
        updateComparison();
    }
    
    function initializeLossFunctionsDemo() {
        const deltaSlider = document.getElementById(&apos;loss-delta&apos;);
        const rangeSlider = document.getElementById(&apos;loss-range&apos;);
        const derivativesCheckbox = document.getElementById(&apos;show-derivatives&apos;);
        
        function updateLossFunctions() {
            const delta = parseFloat(deltaSlider.value);
            const range = parseFloat(rangeSlider.value);
            const showDerivatives = derivativesCheckbox.checked;
            
            document.getElementById(&apos;loss-delta-value&apos;).textContent = delta.toFixed(1);
            document.getElementById(&apos;loss-range-value&apos;).textContent = range.toFixed(1);
            
            updateRegressionLosses(delta, range, showDerivatives);
            updateClassificationLosses(range, showDerivatives);
        }
        
        function updateRegressionLosses(delta, range, showDerivatives) {
            const svg = d3.select(&apos;#regression-losses&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Generate error values
            const errors = d3.range(-range, range, 0.1);
            
            // Loss functions
            const mseLoss = errors.map(e =&gt; 0.5 * e * e);
            const maeLoss = errors.map(e =&gt; Math.abs(e));
            const huberLoss = errors.map(e =&gt; 
                Math.abs(e) &lt;= delta ? 0.5 * e * e : delta * Math.abs(e) - 0.5 * delta * delta
            );
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain([-range, range])
                .range([0, width]);
            
            const maxLoss = Math.max(...mseLoss, ...maeLoss, ...huberLoss);
            const yScale = d3.scaleLinear()
                .domain([0, maxLoss])
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Prediction Error&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Loss&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(errors[i]))
                .y(d =&gt; yScale(d));
            
            // Draw loss functions
            const colors = [&apos;#1f77b4&apos;, &apos;#ff7f0e&apos;, &apos;#2ca02c&apos;];
            const losses = [mseLoss, maeLoss, huberLoss];
            const names = [&apos;MSE&apos;, &apos;MAE&apos;, &apos;Huber&apos;];
            
            losses.forEach((loss, i) =&gt; {
                g.append(&apos;path&apos;)
                    .datum(loss)
                    .attr(&apos;fill&apos;, &apos;none&apos;)
                    .attr(&apos;stroke&apos;, colors[i])
                    .attr(&apos;stroke-width&apos;, 3)
                    .attr(&apos;d&apos;, line);
            });
            
            // Legend
            const legend = g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${width - 80}, 20)`);
            
            names.forEach((name, i) =&gt; {
                legend.append(&apos;line&apos;)
                    .attr(&apos;x1&apos;, 0).attr(&apos;x2&apos;, 20)
                    .attr(&apos;y1&apos;, i * 20).attr(&apos;y2&apos;, i * 20)
                    .attr(&apos;stroke&apos;, colors[i]).attr(&apos;stroke-width&apos;, 3);
                legend.append(&apos;text&apos;)
                    .attr(&apos;x&apos;, 25).attr(&apos;y&apos;, i * 20 + 5)
                    .text(name);
            });
        }
        
        function updateClassificationLosses(range, showDerivatives) {
            const svg = d3.select(&apos;#classification-losses&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Generate margin values (y * f(x))
            const margins = d3.range(-range, range, 0.1);
            
            // Loss functions
            const logisticLoss = margins.map(m =&gt; Math.log(1 + Math.exp(-m)));
            const hingeLoss = margins.map(m =&gt; Math.max(0, 1 - m));
            const zeroOneLoss = margins.map(m =&gt; m &lt;= 0 ? 1 : 0);
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain([-range, range])
                .range([0, width]);
            
            const maxLoss = Math.max(...logisticLoss, ...hingeLoss, ...zeroOneLoss);
            const yScale = d3.scaleLinear()
                .domain([0, maxLoss])
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Margin (y × f(x))&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Loss&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(margins[i]))
                .y(d =&gt; yScale(d));
            
            // Draw loss functions
            const colors = [&apos;#d62728&apos;, &apos;#9467bd&apos;, &apos;#8c564b&apos;];
            const losses = [logisticLoss, hingeLoss, zeroOneLoss];
            const names = [&apos;Logistic&apos;, &apos;Hinge&apos;, &apos;0-1 Loss&apos;];
            
            losses.forEach((loss, i) =&gt; {
                g.append(&apos;path&apos;)
                    .datum(loss)
                    .attr(&apos;fill&apos;, &apos;none&apos;)
                    .attr(&apos;stroke&apos;, colors[i])
                    .attr(&apos;stroke-width&apos;, 3)
                    .attr(&apos;d&apos;, line);
            });
            
            // Legend
            const legend = g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${width - 80}, 20)`);
            
            names.forEach((name, i) =&gt; {
                legend.append(&apos;line&apos;)
                    .attr(&apos;x1&apos;, 0).attr(&apos;x2&apos;, 20)
                    .attr(&apos;y1&apos;, i * 20).attr(&apos;y2&apos;, i * 20)
                    .attr(&apos;stroke&apos;, colors[i]).attr(&apos;stroke-width&apos;, 3);
                legend.append(&apos;text&apos;)
                    .attr(&apos;x&apos;, 25).attr(&apos;y&apos;, i * 20 + 5)
                    .text(name);
            });
        }
        
        // Event listeners
        deltaSlider.addEventListener(&apos;input&apos;, updateLossFunctions);
        rangeSlider.addEventListener(&apos;input&apos;, updateLossFunctions);
        derivativesCheckbox.addEventListener(&apos;change&apos;, updateLossFunctions);
        
        // Initial update
        updateLossFunctions();
    }
    
    function initializeRegularizationPathDemo() {
        const methodSelect = document.getElementById(&apos;path-method&apos;);
        const alphaSlider = document.getElementById(&apos;path-alpha&apos;);
        const animateBtn = document.getElementById(&apos;path-animate&apos;);
        
        let isAnimating = false;
        let animationId = null;
        
        function updateRegularizationPath() {
            const method = methodSelect.value;
            const alpha = parseFloat(alphaSlider.value);
            
            document.getElementById(&apos;path-alpha-value&apos;).textContent = alpha.toFixed(1);
            
            // Generate regularization path
            const lambdaRange = d3.range(0, 5, 0.1);
            const coeffPaths = generateRegularizationPath(method, alpha, lambdaRange);
            
            updateCoefficientPathPlot(coeffPaths, lambdaRange, method);
            updateCVCurvePlot(lambdaRange, method);
        }
        
        function generateRegularizationPath(method, alpha, lambdaRange) {
            const p = 6; // features
            const trueCoeffs = [2, -1.5, 1, 0.5, -0.8, 0.3];
            
            const paths = Array(p).fill().map(() =&gt; []);
            
            lambdaRange.forEach(lambda =&gt; {
                let coeffs;
                if (method === &apos;ridge&apos;) {
                    coeffs = trueCoeffs.map(c =&gt; c / (1 + lambda));
                } else if (method === &apos;lasso&apos;) {
                    coeffs = trueCoeffs.map(c =&gt; {
                        const abs_c = Math.abs(c);
                        return abs_c &gt; lambda ? Math.sign(c) * (abs_c - lambda) : 0;
                    });
                } else { // elastic net
                    coeffs = trueCoeffs.map(c =&gt; {
                        const abs_c = Math.abs(c);
                        const l1_part = abs_c &gt; alpha * lambda ? Math.sign(c) * (abs_c - alpha * lambda) : 0;
                        return l1_part / (1 + (1 - alpha) * lambda);
                    });
                }
                
                coeffs.forEach((coeff, i) =&gt; paths[i].push(coeff));
            });
            
            return paths;
        }
        
        function updateCoefficientPathPlot(coeffPaths, lambdaRange, method) {
            const svg = d3.select(&apos;#coefficient-path&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain(d3.extent(lambdaRange))
                .range([0, width]);
            
            const allCoeffs = coeffPaths.flat();
            const yScale = d3.scaleLinear()
                .domain(d3.extent(allCoeffs))
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Lambda (λ)&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Coefficient Value&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(lambdaRange[i]))
                .y(d =&gt; yScale(d));
            
            // Draw coefficient paths
            const colors = d3.schemeCategory10;
            coeffPaths.forEach((path, i) =&gt; {
                g.append(&apos;path&apos;)
                    .datum(path)
                    .attr(&apos;fill&apos;, &apos;none&apos;)
                    .attr(&apos;stroke&apos;, colors[i % colors.length])
                    .attr(&apos;stroke-width&apos;, 2)
                    .attr(&apos;d&apos;, line);
                
                // Add feature label at the end
                const lastValue = path[path.length - 1];
                if (Math.abs(lastValue) &gt; 0.01) {
                    g.append(&apos;text&apos;)
                        .attr(&apos;x&apos;, width + 5)
                        .attr(&apos;y&apos;, yScale(lastValue) + 3)
                        .attr(&apos;font-size&apos;, &apos;10px&apos;)
                        .text(`f${i+1}`);
                }
            });
            
            // Update info
            const currentLambda = 1.0; // example
            const activeFeatures = coeffPaths.filter(path =&gt; Math.abs(path[Math.floor(currentLambda * 10)]) &gt; 0.01).length;
            document.getElementById(&apos;path-info&apos;).textContent = 
                `Current λ: ${currentLambda.toFixed(1)}, Active features: ${activeFeatures}`;
        }
        
        function updateCVCurvePlot(lambdaRange, method) {
            const svg = d3.select(&apos;#cv-curve&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Generate synthetic CV scores
            const cvScores = lambdaRange.map(lambda =&gt; {
                const base = 0.2 + 0.1 * Math.abs(lambda - 1.5);
                return base + (Math.random() - 0.5) * 0.05;
            });
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain(d3.extent(lambdaRange))
                .range([0, width]);
            
            const yScale = d3.scaleLinear()
                .domain(d3.extent(cvScores))
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Lambda (λ)&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;CV Score&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(lambdaRange[i]))
                .y(d =&gt; yScale(d));
            
            // Draw CV curve
            g.append(&apos;path&apos;)
                .datum(cvScores)
                .attr(&apos;fill&apos;, &apos;none&apos;)
                .attr(&apos;stroke&apos;, &apos;#2196F3&apos;)
                .attr(&apos;stroke-width&apos;, 3)
                .attr(&apos;d&apos;, line);
            
            // Find and mark optimal lambda
            const minIndex = cvScores.indexOf(Math.min(...cvScores));
            const optimalLambda = lambdaRange[minIndex];
            
            g.append(&apos;circle&apos;)
                .attr(&apos;cx&apos;, xScale(optimalLambda))
                .attr(&apos;cy&apos;, yScale(cvScores[minIndex]))
                .attr(&apos;r&apos;, 5)
                .attr(&apos;fill&apos;, &apos;red&apos;);
            
            // Update info
            document.getElementById(&apos;cv-info&apos;).textContent = 
                `Optimal λ: ${optimalLambda.toFixed(2)}, CV Score: ${cvScores[minIndex].toFixed(3)}`;
        }
        
        function animatePath() {
            if (isAnimating) {
                // Stop animation
                isAnimating = false;
                if (animationId) clearInterval(animationId);
                animateBtn.textContent = &apos;Animate Path&apos;;
                return;
            }
            
            // Start animation
            isAnimating = true;
            animateBtn.textContent = &apos;Stop Animation&apos;;
            
            const lambdaRange = d3.range(0, 5, 0.1);
            let currentIndex = 0;
            
            animationId = setInterval(() =&gt; {
                if (currentIndex &gt;= lambdaRange.length) {
                    currentIndex = 0;
                }
                
                // Update visualization for current lambda
                const currentLambda = lambdaRange[currentIndex];
                // Add animation logic here
                
                currentIndex++;
            }, 100);
        }
        
        // Event listeners
        methodSelect.addEventListener(&apos;change&apos;, updateRegularizationPath);
        alphaSlider.addEventListener(&apos;input&apos;, updateRegularizationPath);
        animateBtn.addEventListener(&apos;click&apos;, animatePath);
        
        // Initial update
        updateRegularizationPath();
    }
});
&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>06-06 Gradient descent with momentum</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_06_gradent_descent_with_momentum/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_06_gradent_descent_with_momentum</id>
   <content type="html">&lt;script src=&quot;https://d3js.org/d3.v7.min.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;vấn-đề-với-gradient-descent-thuần-túy&quot;&gt;Vấn đề với Gradient Descent thuần túy&lt;/h2&gt;

&lt;p&gt;Hãy tưởng tượng bạn đang lăn một quả bóng xuống thung lũng. Gradient descent tiêu chuẩn giống như một quả bóng không có trí nhớ - tại mỗi bước, nó chỉ xem xét độ dốc hiện tại và di chuyển tương ứng. Điều này có thể dẫn đến một số vấn đề:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Hội tụ chậm trong các khe hẹp&lt;/strong&gt;: Khi hàm có gradient dốc trong một số hướng và gradient thoải trong các hướng khác&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dao động&lt;/strong&gt;: Thuật toán có thể dao động qua lại trên thung lũng thay vì tiến bộ ổn định&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bị kẹt trong các cực tiểu địa phương kém&lt;/strong&gt;: Không có momentum, thuật toán có thể ổn định ở các nghiệm không tối ưu&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Câu hỏi&lt;/strong&gt;: Điều gì sẽ xảy ra nếu quả bóng của chúng ta có thể “nhớ” hướng trước đó và duy trì một chút vận tốc?&lt;/p&gt;

&lt;h2 id=&quot;momentum-thêm-bộ-nhớ-vào-gradient-descent&quot;&gt;Momentum: Thêm bộ nhớ vào Gradient Descent&lt;/h2&gt;

&lt;p&gt;Gradient descent với momentum được lấy cảm hứng từ vật lý - cụ thể là chuyển động của một quả bóng lăn xuống đồi với ma sát. Ý tưởng chính là tích lũy một vector vận tốc kết hợp gradient hiện tại với momentum trước đó.&lt;/p&gt;

&lt;h3 id=&quot;thuật-toán-momentum&quot;&gt;Thuật toán Momentum&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Quy tắc cập nhật:&lt;/strong&gt;
\(\begin{align}
v^{(k)} &amp;amp;= \beta v^{(k-1)} + (1-\beta) \nabla f(x^{(k-1)}) \\
x^{(k)} &amp;amp;= x^{(k-1)} - t v^{(k)}
\end{align}\)&lt;/p&gt;

&lt;p&gt;trong đó:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(v^{(k)}\) là momentum (vận tốc) tại lần lặp \(k\)&lt;/li&gt;
  &lt;li&gt;\(\beta \in [0,1)\) là hệ số momentum (thường là 0.9 hoặc 0.99)&lt;/li&gt;
  &lt;li&gt;\(t &amp;gt; 0\) là tốc độ học&lt;/li&gt;
  &lt;li&gt;\(v^{(0)} = 0\) (vận tốc ban đầu bằng không)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;công-thức-thay-thế-kiểu-nesterov&quot;&gt;Công thức thay thế (kiểu Nesterov)&lt;/h3&gt;

&lt;p&gt;Một số triển khai sử dụng dạng hơi khác:
\(\begin{align}
v^{(k)} &amp;amp;= \beta v^{(k-1)} + \nabla f(x^{(k-1)}) \\
x^{(k)} &amp;amp;= x^{(k-1)} - t v^{(k)}
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ý tưởng chính&lt;/strong&gt;: Số hạng momentum \(v^{(k)}\) là trung bình động có trọng số mũ của các gradient trong quá khứ.&lt;/p&gt;

&lt;h2 id=&quot;hiểu-hệ-số-momentum-beta&quot;&gt;Hiểu hệ số Momentum \(\beta\)&lt;/h2&gt;

&lt;p&gt;Hệ số momentum \(\beta\) kiểm soát thuật toán có bao nhiều “bộ nhớ”:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(\beta = 0\)&lt;/strong&gt;: Không có momentum, giảm về gradient descent tiêu chuẩn&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\beta = 0.9\)&lt;/strong&gt;: Momentum trung bình, thường được sử dụng trong thực tế&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\beta = 0.99\)&lt;/strong&gt;: Momentum cao, được sử dụng trong một số ứng dụng deep learning&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\beta \to 1\)&lt;/strong&gt;: Momentum tối đa, nhưng có thể gây bất ổn&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;trung-bình-động-có-trọng-số-mũ&quot;&gt;Trung bình động có trọng số mũ&lt;/h3&gt;

&lt;p&gt;Momentum \(v^{(k)}\) có thể được mở rộng là:
\(v^{(k)} = (1-\beta) \sum_{i=0}^{k-1} \beta^i \nabla f(x^{(k-1-i)})\)&lt;/p&gt;

&lt;p&gt;Điều này cho thấy momentum cho trọng số giảm mũ cho các gradient cũ hơn.&lt;/p&gt;

&lt;h2 id=&quot;interactive-visualization-gradient-descent-vs-momentum&quot;&gt;Interactive Visualization: Gradient Descent vs Momentum&lt;/h2&gt;

&lt;div id=&quot;momentum-comparison&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;!-- Parameter Controls --&gt;
    &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px; margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;&quot;&gt;
        &lt;div&gt;
            &lt;label for=&quot;momentum-lr&quot;&gt;Learning Rate: &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;momentum-lr&quot; min=&quot;0.01&quot; max=&quot;0.3&quot; step=&quot;0.01&quot; value=&quot;0.1&quot; /&gt;
            &lt;span id=&quot;momentum-lr-value&quot;&gt;0.1&lt;/span&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;label for=&quot;momentum-beta&quot;&gt;Momentum (β): &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;momentum-beta&quot; min=&quot;0&quot; max=&quot;0.99&quot; step=&quot;0.01&quot; value=&quot;0.9&quot; /&gt;
            &lt;span id=&quot;momentum-beta-value&quot;&gt;0.9&lt;/span&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;label for=&quot;momentum-speed&quot;&gt;Animation Speed: &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;momentum-speed&quot; min=&quot;1&quot; max=&quot;10&quot; step=&quot;1&quot; value=&quot;5&quot; /&gt;
            &lt;span id=&quot;momentum-speed-value&quot;&gt;5&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;!-- Control Buttons --&gt;
    &lt;div style=&quot;display: flex; gap: 10px; margin-bottom: 15px; flex-wrap: wrap;&quot;&gt;
        &lt;button id=&quot;start-vanilla-gd&quot; style=&quot;background-color: #4CAF50; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Start Vanilla GD&lt;/button&gt;
        &lt;button id=&quot;start-momentum-gd&quot; style=&quot;background-color: #FF9800; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Start Momentum GD&lt;/button&gt;
        &lt;button id=&quot;start-both&quot; style=&quot;background-color: #2196F3; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Compare Both&lt;/button&gt;
        &lt;button id=&quot;reset-momentum&quot; style=&quot;background-color: #f44336; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Reset&lt;/button&gt;
    &lt;/div&gt;
    
    &lt;!-- Visualization Canvas --&gt;
    &lt;div id=&quot;momentum-canvas&quot; style=&quot;border: 1px solid #ccc; border-radius: 5px; background-color: white; position: relative; overflow: hidden;&quot;&gt;
        &lt;svg width=&quot;800&quot; height=&quot;500&quot; id=&quot;momentum-svg&quot;&gt;&lt;/svg&gt;
    &lt;/div&gt;
    
    &lt;!-- Algorithm Status --&gt;
    &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 15px;&quot;&gt;
        &lt;div style=&quot;padding: 10px; border: 1px solid #4CAF50; border-radius: 5px; background-color: #f1f8e9;&quot;&gt;
            &lt;h4 style=&quot;margin: 0 0 5px 0; color: #4CAF50;&quot;&gt;Vanilla Gradient Descent&lt;/h4&gt;
            &lt;p id=&quot;vanilla-gd-info&quot; style=&quot;margin: 0; font-size: 14px;&quot;&gt;Ready to start&lt;/p&gt;
        &lt;/div&gt;
        &lt;div style=&quot;padding: 10px; border: 1px solid #FF9800; border-radius: 5px; background-color: #fff8e1;&quot;&gt;
            &lt;h4 style=&quot;margin: 0 0 5px 0; color: #FF9800;&quot;&gt;Momentum Gradient Descent&lt;/h4&gt;
            &lt;p id=&quot;momentum-gd-info&quot; style=&quot;margin: 0; font-size: 14px;&quot;&gt;Ready to start&lt;/p&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    // Momentum visualization implementation
    const svg = d3.select(&quot;#momentum-svg&quot;);
    const width = 800, height = 500;
    const margin = {top: 20, right: 20, bottom: 40, left: 40};
    
    // Function to optimize: f(x,y) = 0.5*x^2 + 5*y^2 (elongated bowl)
    function f(x, y) {
        return 0.5 * x * x + 5 * y * y;
    }
    
    function gradient(x, y) {
        return [x, 10 * y];
    }
    
    // Scale setup
    const xScale = d3.scaleLinear()
        .domain([-6, 6])
        .range([margin.left, width - margin.right]);
    
    const yScale = d3.scaleLinear()
        .domain([-3, 3])
        .range([height - margin.bottom, margin.top]);
    
    // Create contour plot
    function createContours() {
        // Create a simple grid-based contour visualization
        const gridSize = 20;
        const contourLevels = [1, 4, 9, 16, 25, 36, 49];
        
        svg.selectAll(&quot;.contour&quot;).remove();
        
        // Draw contour ellipses for the function f(x,y) = 0.5*x^2 + 5*y^2
        contourLevels.forEach(level =&gt; {
            // For f(x,y) = 0.5*x^2 + 5*y^2 = level
            // This is an ellipse: x^2/(2*level) + y^2/(level/5) = 1
            const a = Math.sqrt(2 * level); // semi-major axis in x direction
            const b = Math.sqrt(level / 5); // semi-minor axis in y direction
            
            if (a &lt;= 6 &amp;&amp; b &lt;= 3) { // Only draw if within our domain
                svg.append(&quot;ellipse&quot;)
                    .attr(&quot;class&quot;, &quot;contour&quot;)
                    .attr(&quot;cx&quot;, xScale(0))
                    .attr(&quot;cy&quot;, yScale(0))
                    .attr(&quot;rx&quot;, xScale(a) - xScale(0))
                    .attr(&quot;ry&quot;, yScale(0) - yScale(b))
                    .attr(&quot;fill&quot;, &quot;none&quot;)
                    .attr(&quot;stroke&quot;, &quot;#ddd&quot;)
                    .attr(&quot;stroke-width&quot;, 1)
                    .attr(&quot;opacity&quot;, 0.6);
            }
        });
    }
    
    createContours();
    
    // Add global minimum marker
    svg.append(&quot;circle&quot;)
        .attr(&quot;cx&quot;, xScale(0))
        .attr(&quot;cy&quot;, yScale(0))
        .attr(&quot;r&quot;, 8)
        .attr(&quot;fill&quot;, &quot;red&quot;)
        .attr(&quot;stroke&quot;, &quot;white&quot;)
        .attr(&quot;stroke-width&quot;, 2)
        .attr(&quot;opacity&quot;, 0.8);
    
    svg.append(&quot;text&quot;)
        .attr(&quot;x&quot;, xScale(0))
        .attr(&quot;y&quot;, yScale(0) - 15)
        .attr(&quot;text-anchor&quot;, &quot;middle&quot;)
        .attr(&quot;font-size&quot;, &quot;12px&quot;)
        .attr(&quot;font-weight&quot;, &quot;bold&quot;)
        .attr(&quot;fill&quot;, &quot;red&quot;)
        .text(&quot;Global Minimum&quot;);
    
    // Add axes
    svg.append(&quot;g&quot;)
        .attr(&quot;transform&quot;, `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(xScale));
    
    svg.append(&quot;g&quot;)
        .attr(&quot;transform&quot;, `translate(${margin.left},0)`)
        .call(d3.axisLeft(yScale));
    
    // Add axis labels
    svg.append(&quot;text&quot;)
        .attr(&quot;x&quot;, width / 2)
        .attr(&quot;y&quot;, height - 5)
        .attr(&quot;text-anchor&quot;, &quot;middle&quot;)
        .attr(&quot;font-size&quot;, &quot;14px&quot;)
        .text(&quot;x&quot;);
    
    svg.append(&quot;text&quot;)
        .attr(&quot;x&quot;, 15)
        .attr(&quot;y&quot;, height / 2)
        .attr(&quot;text-anchor&quot;, &quot;middle&quot;)
        .attr(&quot;font-size&quot;, &quot;14px&quot;)
        .attr(&quot;transform&quot;, `rotate(-90, 15, ${height / 2})`)
        .text(&quot;y&quot;);
    
    // Add title
    svg.append(&quot;text&quot;)
        .attr(&quot;x&quot;, width / 2)
        .attr(&quot;y&quot;, 15)
        .attr(&quot;text-anchor&quot;, &quot;middle&quot;)
        .attr(&quot;font-size&quot;, &quot;16px&quot;)
        .attr(&quot;font-weight&quot;, &quot;bold&quot;)
        .text(&quot;f(x,y) = 0.5x² + 5y² - Optimization Paths Comparison&quot;);
    
    // Variables for animation
    let vanillaPath = [], momentumPath = [];
    let vanillaRunning = false, momentumRunning = false;
    let vanillaInterval, momentumInterval;
    
    // Algorithm implementations
    function runVanillaGD() {
        const lr = parseFloat(document.getElementById(&apos;momentum-lr&apos;).value);
        let x = -4, y = 2; // Starting point
        let iteration = 0;
        const maxIterations = 500;
        vanillaPath = [{x: x, y: y}];
        vanillaRunning = true;
        
        vanillaInterval = setInterval(() =&gt; {
            const grad = gradient(x, y);
            x -= lr * grad[0];
            y -= lr * grad[1];
            vanillaPath.push({x: x, y: y});
            iteration++;
            
            updateVisualization();
            updateStatus();
            
            // Stop if converged or max iterations reached
            if ((Math.abs(grad[0]) &lt; 0.01 &amp;&amp; Math.abs(grad[1]) &lt; 0.01) || iteration &gt;= maxIterations) {
                clearInterval(vanillaInterval);
                vanillaRunning = false;
            }
        }, 1000 / parseFloat(document.getElementById(&apos;momentum-speed&apos;).value));
    }
    
    function runMomentumGD() {
        const lr = parseFloat(document.getElementById(&apos;momentum-lr&apos;).value);
        const beta = parseFloat(document.getElementById(&apos;momentum-beta&apos;).value);
        let x = -4, y = 2; // Starting point
        let vx = 0, vy = 0; // Initial velocity
        let iteration = 0;
        const maxIterations = 500;
        momentumPath = [{x: x, y: y}];
        momentumRunning = true;
        
        momentumInterval = setInterval(() =&gt; {
            const grad = gradient(x, y);
            vx = beta * vx + (1 - beta) * grad[0];
            vy = beta * vy + (1 - beta) * grad[1];
            x -= lr * vx;
            y -= lr * vy;
            momentumPath.push({x: x, y: y});
            iteration++;
            
            updateVisualization();
            updateStatus();
            
            // Stop if converged or max iterations reached
            if ((Math.abs(grad[0]) &lt; 0.01 &amp;&amp; Math.abs(grad[1]) &lt; 0.01) || iteration &gt;= maxIterations) {
                clearInterval(momentumInterval);
                momentumRunning = false;
            }
        }, 1000 / parseFloat(document.getElementById(&apos;momentum-speed&apos;).value));
    }
    
    function updateVisualization() {
        // Remove existing paths
        svg.selectAll(&quot;.vanilla-path&quot;).remove();
        svg.selectAll(&quot;.momentum-path&quot;).remove();
        svg.selectAll(&quot;.vanilla-point&quot;).remove();
        svg.selectAll(&quot;.momentum-point&quot;).remove();
        
        // Draw vanilla GD path
        if (vanillaPath.length &gt; 1) {
            const line = d3.line()
                .x(d =&gt; xScale(d.x))
                .y(d =&gt; yScale(d.y));
            
            svg.append(&quot;path&quot;)
                .datum(vanillaPath)
                .attr(&quot;class&quot;, &quot;vanilla-path&quot;)
                .attr(&quot;d&quot;, line)
                .attr(&quot;fill&quot;, &quot;none&quot;)
                .attr(&quot;stroke&quot;, &quot;#4CAF50&quot;)
                .attr(&quot;stroke-width&quot;, 2);
            
            // Current point
            const current = vanillaPath[vanillaPath.length - 1];
            svg.append(&quot;circle&quot;)
                .attr(&quot;class&quot;, &quot;vanilla-point&quot;)
                .attr(&quot;cx&quot;, xScale(current.x))
                .attr(&quot;cy&quot;, yScale(current.y))
                .attr(&quot;r&quot;, 5)
                .attr(&quot;fill&quot;, &quot;#4CAF50&quot;);
        }
        
        // Draw momentum GD path
        if (momentumPath.length &gt; 1) {
            const line = d3.line()
                .x(d =&gt; xScale(d.x))
                .y(d =&gt; yScale(d.y));
            
            svg.append(&quot;path&quot;)
                .datum(momentumPath)
                .attr(&quot;class&quot;, &quot;momentum-path&quot;)
                .attr(&quot;d&quot;, line)
                .attr(&quot;fill&quot;, &quot;none&quot;)
                .attr(&quot;stroke&quot;, &quot;#FF9800&quot;)
                .attr(&quot;stroke-width&quot;, 2);
            
            // Current point
            const current = momentumPath[momentumPath.length - 1];
            svg.append(&quot;circle&quot;)
                .attr(&quot;class&quot;, &quot;momentum-point&quot;)
                .attr(&quot;cx&quot;, xScale(current.x))
                .attr(&quot;cy&quot;, yScale(current.y))
                .attr(&quot;r&quot;, 5)
                .attr(&quot;fill&quot;, &quot;#FF9800&quot;);
        }
    }
    
    function updateStatus() {
        // Update vanilla GD status
        if (vanillaPath.length &gt; 0) {
            const current = vanillaPath[vanillaPath.length - 1];
            const fValue = f(current.x, current.y);
            document.getElementById(&apos;vanilla-gd-info&apos;).innerHTML = 
                `Iteration: ${vanillaPath.length - 1}&lt;br&gt;Position: (${current.x.toFixed(3)}, ${current.y.toFixed(3)})&lt;br&gt;f(x,y): ${fValue.toFixed(4)}`;
        }
        
        // Update momentum GD status
        if (momentumPath.length &gt; 0) {
            const current = momentumPath[momentumPath.length - 1];
            const fValue = f(current.x, current.y);
            document.getElementById(&apos;momentum-gd-info&apos;).innerHTML = 
                `Iteration: ${momentumPath.length - 1}&lt;br&gt;Position: (${current.x.toFixed(3)}, ${current.y.toFixed(3)})&lt;br&gt;f(x,y): ${fValue.toFixed(4)}`;
        }
    }
    
    // Event listeners
    document.getElementById(&apos;start-vanilla-gd&apos;).addEventListener(&apos;click&apos;, () =&gt; {
        if (!vanillaRunning) {
            vanillaRunning = true;
            runVanillaGD();
        }
    });
    
    document.getElementById(&apos;start-momentum-gd&apos;).addEventListener(&apos;click&apos;, () =&gt; {
        if (!momentumRunning) {
            momentumRunning = true;
            runMomentumGD();
        }
    });
    
    document.getElementById(&apos;start-both&apos;).addEventListener(&apos;click&apos;, () =&gt; {
        if (!vanillaRunning &amp;&amp; !momentumRunning) {
            vanillaRunning = true;
            momentumRunning = true;
            runVanillaGD();
            runMomentumGD();
        }
    });
    
    document.getElementById(&apos;reset-momentum&apos;).addEventListener(&apos;click&apos;, () =&gt; {
        clearInterval(vanillaInterval);
        clearInterval(momentumInterval);
        vanillaRunning = false;
        momentumRunning = false;
        vanillaPath = [];
        momentumPath = [];
        updateVisualization();
        document.getElementById(&apos;vanilla-gd-info&apos;).innerHTML = &apos;Ready to start&apos;;
        document.getElementById(&apos;momentum-gd-info&apos;).innerHTML = &apos;Ready to start&apos;;
    });
    
    // Update display values
    document.getElementById(&apos;momentum-lr&apos;).addEventListener(&apos;input&apos;, function() {
        document.getElementById(&apos;momentum-lr-value&apos;).textContent = this.value;
    });
    
    document.getElementById(&apos;momentum-beta&apos;).addEventListener(&apos;input&apos;, function() {
        document.getElementById(&apos;momentum-beta-value&apos;).textContent = this.value;
    });
    
    document.getElementById(&apos;momentum-speed&apos;).addEventListener(&apos;input&apos;, function() {
        document.getElementById(&apos;momentum-speed-value&apos;).textContent = this.value;
    });
});
&lt;/script&gt;

&lt;h2 id=&quot;ưu-điểm-của-momentum&quot;&gt;Ưu điểm của Momentum&lt;/h2&gt;

&lt;h3 id=&quot;1-hội-tụ-nhanh-hơn&quot;&gt;1. &lt;strong&gt;Hội tụ nhanh hơn&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Momentum giúp thuật toán tăng tốc trong các hướng nhất quán, dẫn đến hội tụ nhanh hơn đặc biệt trong:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Các hàm có thung lũng hoặc khe hẹp&lt;/li&gt;
  &lt;li&gt;Các bài toán có điều kiện kém (số điều kiện cao)&lt;/li&gt;
  &lt;li&gt;Các hàm có nhiều cực tiểu địa phương&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-giảm-dao-động&quot;&gt;2. &lt;strong&gt;Giảm dao động&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Trong các hướng mà gradient thường xuyên đổi dấu, momentum giúp làm mượt các dao động bằng cách lấy trung bình các gradient trong quá khứ.&lt;/p&gt;

&lt;h3 id=&quot;3-thoát-khỏi-cực-tiểu-địa-phương&quot;&gt;3. &lt;strong&gt;Thoát khỏi cực tiểu địa phương&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Momentum tích lũy có thể giúp thuật toán “lăn qua” các cực tiểu địa phương nhỏ và tiếp tục hướng tới các nghiệm tốt hơn.&lt;/p&gt;

&lt;h2 id=&quot;các-biến-thể-và-mở-rộng&quot;&gt;Các biến thể và mở rộng&lt;/h2&gt;

&lt;h3 id=&quot;1-nesterov-accelerated-gradient-nag&quot;&gt;1. &lt;strong&gt;Nesterov Accelerated Gradient (NAG)&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Thay vì tính gradient tại vị trí hiện tại, NAG tính nó tại vị trí “nhìn trước”:&lt;/p&gt;

\[\begin{align}
v^{(k)} &amp;amp;= \beta v^{(k-1)} + \nabla f(x^{(k-1)} - \beta v^{(k-1)}) \\
x^{(k)} &amp;amp;= x^{(k-1)} - t v^{(k)}
\end{align}\]

&lt;p&gt;&lt;strong&gt;Trực quan&lt;/strong&gt;: “Nhìn trước khi nhảy” - kiểm tra gradient tại nơi momentum sẽ đưa bạn đến.&lt;/p&gt;

&lt;h4 id=&quot;vấn-đề-với-momentum-thông-thường&quot;&gt;Vấn đề với Momentum thông thường&lt;/h4&gt;

&lt;p&gt;Mặc dù momentum giúp quả bóng vượt qua các cực tiểu địa phương, có một hạn chế mà chúng ta có thể quan sát: khi tiến gần đến mục tiêu, momentum vẫn mất khá nhiều thời gian trước khi dừng lại. Lý do chính xác là do vận tốc tích lũy.&lt;/p&gt;

&lt;h4 id=&quot;ý-tưởng-chính&quot;&gt;Ý tưởng chính&lt;/h4&gt;

&lt;p&gt;Ý tưởng cơ bản là &lt;strong&gt;dự đoán hướng tương lai&lt;/strong&gt; - về cơ bản là nhìn trước một bước! Cụ thể, nếu chúng ta sử dụng số hạng momentum \(\beta v^{(k-1)}\) để cập nhật, chúng ta có thể xấp xỉ vị trí tiếp theo là \(x^{(k-1)} - \beta v^{(k-1)}\) (chúng ta không bao gồm số hạng gradient ở đây vì chúng ta sẽ sử dụng nó trong bước cuối).&lt;/p&gt;

&lt;p&gt;Thay vì sử dụng gradient tại vị trí hiện tại, NAG bước tiến về phía trước và sử dụng gradient tại vị trí dự kiến tiếp theo.&lt;/p&gt;

&lt;h4 id=&quot;visual-comparison&quot;&gt;Visual Comparison&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;With regular momentum&lt;/strong&gt;: The update is the sum of two vectors:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Momentum vector (from previous step)&lt;/li&gt;
  &lt;li&gt;Gradient at the current position&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;With Nesterov momentum&lt;/strong&gt;: The update is the sum of two vectors:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Momentum vector (from previous step)&lt;/li&gt;
  &lt;li&gt;Gradient at the &lt;strong&gt;look-ahead&lt;/strong&gt; position (where momentum would take us)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This “look-ahead” approach allows NAG to make more informed corrections and often leads to faster convergence.&lt;/p&gt;

&lt;h3 id=&quot;2-adaptive-moment-estimation-adam&quot;&gt;2. &lt;strong&gt;Adaptive Moment Estimation (Adam)&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Adam combines momentum with adaptive learning rates for each parameter:&lt;/p&gt;

\[\begin{align}
m^{(k)} &amp;amp;= \beta_1 m^{(k-1)} + (1-\beta_1) \nabla f(x^{(k-1)}) \\
v^{(k)} &amp;amp;= \beta_2 v^{(k-1)} + (1-\beta_2) (\nabla f(x^{(k-1)}))^2 \\
x^{(k)} &amp;amp;= x^{(k-1)} - t \frac{m^{(k)}}{\sqrt{v^{(k)}} + \epsilon}
\end{align}\]

&lt;h2 id=&quot;practical-implementation-tips&quot;&gt;Practical Implementation Tips&lt;/h2&gt;

&lt;h3 id=&quot;1-choosing-the-momentum-coefficient&quot;&gt;1. &lt;strong&gt;Choosing the Momentum Coefficient&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Start with \(\beta = 0.9\)&lt;/strong&gt;: A good default for most problems&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Increase to \(\beta = 0.99\)&lt;/strong&gt;: For very smooth optimization landscapes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Decrease to \(\beta = 0.5-0.7\)&lt;/strong&gt;: For noisy or non-smooth functions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-learning-rate-adjustment&quot;&gt;2. &lt;strong&gt;Learning Rate Adjustment&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;When using momentum, you may need to reduce the learning rate compared to vanilla gradient descent, as momentum amplifies the effective step size.&lt;/p&gt;

&lt;h3 id=&quot;3-warm-up-period&quot;&gt;3. &lt;strong&gt;Warm-up Period&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Consider starting with lower momentum and gradually increasing it, as momentum needs time to build up effective velocity.&lt;/p&gt;

&lt;h2 id=&quot;mathematical-analysis&quot;&gt;Mathematical Analysis&lt;/h2&gt;

&lt;h3 id=&quot;convergence-properties&quot;&gt;Convergence Properties&lt;/h3&gt;

&lt;p&gt;For strongly convex functions with Lipschitz gradients, momentum gradient descent achieves:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linear convergence&lt;/strong&gt;: \(f(x^{(k)}) - f^* \leq C \rho^k\) for some \(\rho &amp;lt; 1\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Improved condition number&lt;/strong&gt;: Effective condition number can be improved from \(\kappa\) to \(\sqrt{\kappa}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heavy-ball-method-connection&quot;&gt;Heavy Ball Method Connection&lt;/h3&gt;

&lt;p&gt;Momentum gradient descent is closely related to the heavy ball method from classical mechanics:
\(mx&apos;&apos; + \gamma x&apos; + \nabla f(x) = 0\)&lt;/p&gt;

&lt;p&gt;This differential equation, when discretized, leads to the momentum update rules.&lt;/p&gt;

&lt;h2 id=&quot;tóm-tắt-so-sánh&quot;&gt;Tóm tắt so sánh&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Khía cạnh&lt;/th&gt;
      &lt;th&gt;Vanilla GD&lt;/th&gt;
      &lt;th&gt;Momentum GD&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Bộ nhớ&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Không&lt;/td&gt;
      &lt;td&gt;Có (giảm mũ)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Hội tụ&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Có thể chậm&lt;/td&gt;
      &lt;td&gt;Thường nhanh hơn&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Dao động&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Dễ xảy ra hơn&lt;/td&gt;
      &lt;td&gt;Giảm&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Cực tiểu địa phương&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Có thể bị kẹt&lt;/td&gt;
      &lt;td&gt;Thoát tốt hơn&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Siêu tham số&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Tốc độ học&lt;/td&gt;
      &lt;td&gt;Tốc độ học + momentum&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Chi phí tính toán&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Thấp&lt;/td&gt;
      &lt;td&gt;Hơi cao hơn&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;những-điểm-chính&quot;&gt;Những điểm chính&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Momentum thêm bộ nhớ&lt;/strong&gt;: Nó nhớ hướng của các bước trước đó&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hội tụ nhanh hơn&lt;/strong&gt;: Đặc biệt hiệu quả cho các hàm có thung lũng hoặc khe hẹp&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Giảm dao động&lt;/strong&gt;: Làm mượt hành vi zigzag&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Được sử dụng rộng rãi&lt;/strong&gt;: Nền tảng cho nhiều thuật toán tối ưu hóa hiện đại&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Có thể điều chỉnh&lt;/strong&gt;: Hệ số momentum \(\beta\) cho phép tinh chỉnh cho các bài toán khác nhau&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Kết luận&lt;/strong&gt;: Momentum là một cải tiến đơn giản nhưng mạnh mẽ cho gradient descent đã vượt qua thử thách của thời gian và vẫn có liên quan trong các ứng dụng machine learning hiện đại.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-05 Stochastic gradient descent</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_05_stochastic_gradient_descent/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_05_stochastic_gradient_descent</id>
   <content type="html">&lt;script src=&quot;../../../public/js/script.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://d3js.org/d3.v7.min.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;động-lực-thử-thách-của-big-data&quot;&gt;Động lực: Thử thách của Big Data&lt;/h2&gt;

&lt;p&gt;Hãy tưởng tượng bạn đang huấn luyện một mô hình machine learning trên hàng triệu điểm dữ liệu. Gradient descent truyền thống yêu cầu tính toán gradient cho &lt;strong&gt;tất cả&lt;/strong&gt; các điểm dữ liệu trước khi thực hiện một lần cập nhật duy nhất. Điều này trở nên tốn kém về mặt tính toán và tiêu tốn bộ nhớ đối với các tập dữ liệu lớn.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Câu hỏi&lt;/strong&gt;: Điều gì sẽ xảy ra nếu chúng ta có thể tiến bộ bằng cách chỉ xem xét một điểm dữ liệu tại một thời điểm?&lt;/p&gt;

&lt;h2 id=&quot;nền-tảng-toán-học&quot;&gt;Nền tảng Toán học&lt;/h2&gt;

&lt;p&gt;Xem xét bài toán tối ưu hóa để tối thiểu hóa một tổng các hàm:&lt;/p&gt;

\[\begin{equation}
\min_x f(x) = \min_x \sum_{i=1}^m f_i(x)
\end{equation}\]

&lt;p&gt;&lt;strong&gt;Diễn giải thực tế&lt;/strong&gt;: Trong machine learning, \(f_i(x)\) thường đại diện cho mất mát trên ví dụ huấn luyện thứ \(i\), trong đó \(x\) là các tham số mô hình.&lt;/p&gt;

&lt;h3 id=&quot;batch-gradient-descent-phương-pháp-truyền-thống&quot;&gt;Batch Gradient Descent (Phương pháp Truyền thống)&lt;/h3&gt;

&lt;p&gt;Gradient của tổng bằng tổng các gradient:
\(\nabla f(x) = \nabla \sum_{i=1}^m f_i(x) = \sum_{i=1}^m \nabla f_i(x)\)&lt;/p&gt;

&lt;p&gt;Quy tắc cập nhật trở thành:
\(\begin{equation}
x^{(k)} = x^{(k-1)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k-1)}), \,  k=1,2,3,\dots
\end{equation}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Chi phí tính toán&lt;/strong&gt;: \(O(m)\) lần đánh giá gradient mỗi lần lặp, trong đó \(m\) là số lượng hàm (hoặc điểm dữ liệu).&lt;/p&gt;

&lt;h2 id=&quot;stochastic-gradient-descent-giải-pháp-thay-thế-hiệu-quả&quot;&gt;Stochastic Gradient Descent: Giải pháp thay thế hiệu quả&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Ý tưởng chính&lt;/strong&gt;: Thay vì tính toán gradient cho tất cả \(m\) hàm, SGD chỉ sử dụng &lt;strong&gt;một&lt;/strong&gt; hàm tại mỗi lần lặp.&lt;/p&gt;

\[\begin{equation}
x^{(k)} = x^{(k-1)} - t_k \cdot \nabla f_{i_k} (x^{(k-1)}), \quad i_k \in \{1,2,\dots,m\}
\end{equation}\]

&lt;p&gt;&lt;strong&gt;Chi phí tính toán&lt;/strong&gt;: \(O(1)\) lần đánh giá gradient mỗi lần lặp - một cải thiện to lớn!&lt;/p&gt;

&lt;h3 id=&quot;interactive-visualization-gd-vs-sgd-with-step-control&quot;&gt;Interactive Visualization: GD vs SGD with Step Control&lt;/h3&gt;

&lt;div id=&quot;gd-sgd-comparison&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;!-- Parameter Controls --&gt;
    &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px; margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;&quot;&gt;
        &lt;div&gt;
            &lt;label for=&quot;learning-rate&quot;&gt;Learning Rate: &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;learning-rate&quot; min=&quot;0.01&quot; max=&quot;0.5&quot; step=&quot;0.01&quot; value=&quot;0.1&quot; /&gt;
            &lt;span id=&quot;lr-value&quot;&gt;0.1&lt;/span&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;label for=&quot;num-functions&quot;&gt;Number of Functions (m): &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;num-functions&quot; min=&quot;3&quot; max=&quot;10&quot; step=&quot;1&quot; value=&quot;5&quot; /&gt;
            &lt;span id=&quot;m-value&quot;&gt;5&lt;/span&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;label for=&quot;animation-speed&quot;&gt;Animation Speed: &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;animation-speed&quot; min=&quot;1&quot; max=&quot;10&quot; step=&quot;1&quot; value=&quot;5&quot; /&gt;
            &lt;span id=&quot;speed-value&quot;&gt;5&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;!-- Execution Mode Selection --&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 10px; border: 1px solid #ddd; border-radius: 5px; background-color: #f0f8ff;&quot;&gt;
        &lt;h4 style=&quot;margin: 0 0 10px 0;&quot;&gt;Execution Mode:&lt;/h4&gt;
        &lt;div style=&quot;display: flex; gap: 15px;&quot;&gt;
            &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;exec-mode&quot; value=&quot;auto&quot; checked=&quot;&quot; /&gt; Auto Run&lt;/label&gt;
            &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;exec-mode&quot; value=&quot;manual&quot; /&gt; Manual Step-by-Step&lt;/label&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;!-- Control Buttons --&gt;
    &lt;div style=&quot;display: flex; gap: 10px; margin-bottom: 15px; flex-wrap: wrap;&quot;&gt;
        &lt;button id=&quot;start-gd&quot; style=&quot;background-color: #4CAF50; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Start Gradient Descent&lt;/button&gt;
        &lt;button id=&quot;start-sgd&quot; style=&quot;background-color: #FF9800; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Start SGD&lt;/button&gt;
        &lt;button id=&quot;pause-resume&quot; style=&quot;background-color: #2196F3; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot; disabled=&quot;&quot;&gt;Pause&lt;/button&gt;
        &lt;button id=&quot;step-forward&quot; style=&quot;background-color: #9C27B0; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot; disabled=&quot;&quot;&gt;Step Forward&lt;/button&gt;
        &lt;button id=&quot;reset-demo&quot; style=&quot;background-color: #f44336; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Reset&lt;/button&gt;
    &lt;/div&gt;
    
    &lt;!-- Algorithm Status --&gt;
    &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 15px;&quot;&gt;
        &lt;div style=&quot;padding: 10px; border: 1px solid #4CAF50; border-radius: 5px; background-color: #f1f8e9;&quot;&gt;
            &lt;h4 style=&quot;margin: 0 0 5px 0; color: #4CAF50;&quot;&gt;Gradient Descent Status&lt;/h4&gt;
            &lt;p id=&quot;gd-detailed-info&quot; style=&quot;margin: 0; font-size: 14px;&quot;&gt;Ready to start&lt;/p&gt;
        &lt;/div&gt;
        &lt;div style=&quot;padding: 10px; border: 1px solid #FF9800; border-radius: 5px; background-color: #fff8e1;&quot;&gt;
            &lt;h4 style=&quot;margin: 0 0 5px 0; color: #FF9800;&quot;&gt;SGD Status&lt;/h4&gt;
            &lt;p id=&quot;sgd-detailed-info&quot; style=&quot;margin: 0; font-size: 14px;&quot;&gt;Ready to start&lt;/p&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;!-- Visualization Plots --&gt;
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Gradient Descent (Batch)&lt;/h4&gt;
            &lt;svg id=&quot;gd-plot&quot; width=&quot;350&quot; height=&quot;350&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;gd-info&quot; style=&quot;margin: 0; font-weight: bold;&quot;&gt;Iterations: 0, Cost: 0&lt;/p&gt;
                &lt;p id=&quot;gd-gradient-info&quot; style=&quot;margin: 5px 0 0 0; font-size: 12px; color: #666;&quot;&gt;Gradient: [0, 0]&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Stochastic Gradient Descent&lt;/h4&gt;
            &lt;svg id=&quot;sgd-plot&quot; width=&quot;350&quot; height=&quot;350&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;sgd-info&quot; style=&quot;margin: 0; font-weight: bold;&quot;&gt;Iterations: 0, Cost: 0&lt;/p&gt;
                &lt;p id=&quot;sgd-gradient-info&quot; style=&quot;margin: 5px 0 0 0; font-size: 12px; color: #666;&quot;&gt;Selected Function: -, Gradient: [0, 0]&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;!-- Progress Visualization --&gt;
    &lt;div style=&quot;margin-top: 20px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #fafafa;&quot;&gt;
        &lt;h4&gt;Convergence Progress&lt;/h4&gt;
        &lt;div style=&quot;display: flex; gap: 20px;&quot;&gt;
            &lt;div style=&quot;flex: 1;&quot;&gt;
                &lt;p&gt;&lt;strong&gt;GD Progress:&lt;/strong&gt;&lt;/p&gt;
                &lt;div style=&quot;width: 100%; background-color: #e0e0e0; border-radius: 10px; height: 20px;&quot;&gt;
                    &lt;div id=&quot;gd-progress&quot; style=&quot;width: 0%; background-color: #4CAF50; height: 100%; border-radius: 10px; transition: width 0.3s;&quot;&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div style=&quot;flex: 1;&quot;&gt;
                &lt;p&gt;&lt;strong&gt;SGD Progress:&lt;/strong&gt;&lt;/p&gt;
                &lt;div style=&quot;width: 100%; background-color: #e0e0e0; border-radius: 10px; height: 20px;&quot;&gt;
                    &lt;div id=&quot;sgd-progress&quot; style=&quot;width: 0%; background-color: #FF9800; height: 100%; border-radius: 10px; transition: width 0.3s;&quot;&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;các-chiến-lược-lựa-chọn-cho-sgd&quot;&gt;Các chiến lược lựa chọn cho SGD&lt;/h3&gt;

&lt;p&gt;Chỉ số hàm \(i_k\) có thể được chọn bằng các chiến lược khác nhau:&lt;/p&gt;

&lt;h4 id=&quot;1-quy-tắc-vòng-tròn-cyclic-rule&quot;&gt;1. Quy tắc vòng tròn (Cyclic Rule)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Mẫu&lt;/strong&gt;: \(i_k = 1,2,\dots,m, 1,2,\dots,m, \ldots\)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ưu điểm&lt;/strong&gt;: Có tính quyết định, đảm bảo tất cả các hàm đều được thăm&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nhược điểm&lt;/strong&gt;: Có thể bị kẹt trong các mẫu tuần hoàn&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-quy-tắc-ngẫu-nhiên-randomized-rule&quot;&gt;2. Quy tắc ngẫu nhiên (Randomized Rule)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Mẫu&lt;/strong&gt;: \(i_k\) được chọn ngẫu nhiên đều từ \(\{1,2,\dots,m\}\)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ưu điểm&lt;/strong&gt;: Tránh các mẫu tuần hoàn, đảm bảo lý thuyết tốt hơn&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nhược điểm&lt;/strong&gt;: Một số hàm có thể được thăm thường xuyên hơn những hàm khác&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Trong thực tế&lt;/strong&gt;: Lựa chọn ngẫu nhiên được ưa chuộng hơn do có tính chất hội tụ tốt hơn và khả năng thoát khỏi các mẫu cục bộ.&lt;/p&gt;

&lt;h2 id=&quot;phân-tích-hội-tụ-lý-thuyết-so-với-thực-tế&quot;&gt;Phân tích hội tụ: Lý thuyết so với Thực tế&lt;/h2&gt;

&lt;h3 id=&quot;so-sánh-toán-học&quot;&gt;So sánh Toán học&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Batch GD (một epoch)&lt;/strong&gt;: 
\(x^{(k+1)} = x^{(k)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k)})\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SGD (một epoch với quy tắc vòng tròn)&lt;/strong&gt;:
\(x^{(k+m)} = x^{(k)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k+i-1)})\)&lt;/p&gt;

&lt;h3 id=&quot;hiểu-công-thức-quy-tắc-vòng-tròn-sgd&quot;&gt;Hiểu công thức quy tắc vòng tròn SGD&lt;/h3&gt;

&lt;p&gt;Hãy phân tích công thức này từng bước để hiểu điều gì xảy ra trong một epoch hoàn chỉnh của SGD với quy tắc vòng tròn:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Epoch là gì?&lt;/strong&gt; Một epoch có nghĩa là chúng ta đã xử lý tất cả \(m\) hàm đúng một lần.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Quy trình quy tắc vòng tròn:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Bắt đầu tại vị trí \(x^{(k)}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bước 1&lt;/strong&gt;: Sử dụng hàm \(f_1\), tính \(\nabla f_1(x^{(k)})\), cập nhật thành \(x^{(k+1)}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bước 2&lt;/strong&gt;: Sử dụng hàm \(f_2\), tính \(\nabla f_2(x^{(k+1)})\), cập nhật thành \(x^{(k+2)}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bước 3&lt;/strong&gt;: Sử dụng hàm \(f_3\), tính \(\nabla f_3(x^{(k+2)})\), cập nhật thành \(x^{(k+3)}\)&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bước m&lt;/strong&gt;: Sử dụng hàm \(f_m\), tính \(\nabla f_m(x^{(k+m-1)})\), cập nhật thành \(x^{(k+m)}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Các cập nhật SGD riêng lẻ:&lt;/strong&gt;
\(\begin{align}
x^{(k+1)} &amp;amp;= x^{(k)} - t_k \nabla f_1(x^{(k)}) \\
x^{(k+2)} &amp;amp;= x^{(k+1)} - t_k \nabla f_2(x^{(k+1)}) \\
x^{(k+3)} &amp;amp;= x^{(k+2)} - t_k \nabla f_3(x^{(k+2)}) \\
&amp;amp;\vdots \\
x^{(k+m)} &amp;amp;= x^{(k+m-1)} - t_k \nabla f_m(x^{(k+m-1)})
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thu gọn các cập nhật:&lt;/strong&gt;
Nếu chúng ta thay thế đệ quy và thu thập tất cả các số hạng, chúng ta được:
\(x^{(k+m)} = x^{(k)} - t_k \left[ \nabla f_1(x^{(k)}) + \nabla f_2(x^{(k+1)}) + \cdots + \nabla f_m(x^{(k+m-1)}) \right]\)&lt;/p&gt;

&lt;p&gt;This can be written compactly as:
\(x^{(k+m)} = x^{(k)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k+i-1)})\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ý tưởng chính:&lt;/strong&gt; Mỗi gradient \(\nabla f_i\) được đánh giá tại một vị trí &lt;strong&gt;khác nhau&lt;/strong&gt; \(x^{(k+i-1)}\), không phải tại cùng vị trí bắt đầu \(x^{(k)}\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key difference in update directions&lt;/strong&gt;:
\(\sum_{i=1}^{m}[ \nabla f_i (x^{(k+i-1)}) - \nabla f_i (x^{(k)})]\)&lt;/p&gt;

&lt;p&gt;This difference represents how much the SGD path deviates from what batch GD would do. If the functions don’t change much locally (Lipschitz continuous gradients), this difference is small and SGD behaves similarly to batch GD.&lt;/p&gt;

&lt;h3 id=&quot;concrete-example-with-m--3-functions&quot;&gt;Concrete Example with m = 3 Functions&lt;/h3&gt;

&lt;p&gt;Let’s illustrate with \(m = 3\) functions to make this crystal clear:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Starting position:&lt;/strong&gt; \(x^{(k)} = [1, 2]\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SGD Cyclic Rule Process:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Use \(f_1\)&lt;/strong&gt;: Compute \(\nabla f_1(x^{(k)}) = \nabla f_1([1,2])\), update:
\(x^{(k+1)} = x^{(k)} - t_k \nabla f_1(x^{(k)}) = [1,2] - t_k \nabla f_1([1,2])\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Use \(f_2\)&lt;/strong&gt;: Compute \(\nabla f_2(x^{(k+1)})\) at the &lt;strong&gt;new&lt;/strong&gt; position, update:
\(x^{(k+2)} = x^{(k+1)} - t_k \nabla f_2(x^{(k+1)})\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Use \(f_3\)&lt;/strong&gt;: Compute \(\nabla f_3(x^{(k+2)})\) at the &lt;strong&gt;newest&lt;/strong&gt; position, update:
\(x^{(k+3)} = x^{(k+2)} - t_k \nabla f_3(x^{(k+2)})\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Final SGD result after one epoch:&lt;/strong&gt;
\(x^{(k+3)} = x^{(k)} - t_k[\nabla f_1(x^{(k)}) + \nabla f_2(x^{(k+1)}) + \nabla f_3(x^{(k+2)})]\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Compare with Batch GD:&lt;/strong&gt;
\(x^{(k+1)} = x^{(k)} - t_k[\nabla f_1(x^{(k)}) + \nabla f_2(x^{(k)}) + \nabla f_3(x^{(k)})]\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The crucial difference:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Batch GD&lt;/strong&gt;: All gradients evaluated at the &lt;strong&gt;same&lt;/strong&gt; starting point \(x^{(k)}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SGD&lt;/strong&gt;: Each gradient evaluated at a &lt;strong&gt;different&lt;/strong&gt; point along the optimization path&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is why SGD can make faster initial progress (it’s already “exploring” the landscape) but can be noisier near the optimum.&lt;/p&gt;

&lt;h3 id=&quot;convergence-properties&quot;&gt;Convergence Properties&lt;/h3&gt;

&lt;div id=&quot;convergence-analysis&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr; gap: 20px;&quot;&gt;
        &lt;div style=&quot;border: 1px solid #ddd; padding: 15px; border-radius: 5px;&quot;&gt;
            &lt;h4&gt;Batch Gradient Descent&lt;/h4&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Direction&lt;/strong&gt;: Always in steepest descent direction&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Convergence&lt;/strong&gt;: Smooth, monotonic decrease&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Slower per epoch, but stable&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: Requires full dataset in memory&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;
        &lt;div style=&quot;border: 1px solid #ddd; padding: 15px; border-radius: 5px;&quot;&gt;
            &lt;h4&gt;Stochastic Gradient Descent&lt;/h4&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Direction&lt;/strong&gt;: Noisy, approximate descent direction&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Convergence&lt;/strong&gt;: Oscillatory, but faster initial progress&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Faster per epoch, especially for large datasets&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: Processes one sample at a time&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;theoretical-guarantees&quot;&gt;Theoretical Guarantees&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Lipschitz Continuity Condition&lt;/strong&gt;: If \(\nabla f_i(x)\) is Lipschitz continuous with constant \(L\):
\(\|\nabla f_i(x) - \nabla f_i(y)\| \leq L \|x - y\|\)&lt;/p&gt;

&lt;p&gt;Then SGD converges to the same optimal solution as batch GD, provided the learning rate satisfies appropriate conditions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Practical Observation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SGD excels in the &lt;strong&gt;exploration phase&lt;/strong&gt; (far from optimum)&lt;/li&gt;
  &lt;li&gt;SGD struggles in the &lt;strong&gt;exploitation phase&lt;/strong&gt; (near optimum) due to noise&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mini-batch-gradient-descent-the-best-of-both-worlds&quot;&gt;Mini-Batch Gradient Descent: The Best of Both Worlds&lt;/h2&gt;

&lt;p&gt;A compromise between batch GD and SGD uses &lt;strong&gt;mini-batches&lt;/strong&gt; of size \(b\):&lt;/p&gt;

\[x^{(k)} = x^{(k-1)} - t_k \cdot \frac{1}{b} \sum_{i \in \mathcal{B}_k} \nabla f_i (x^{(k-1)})\]

&lt;p&gt;where \(\mathcal{B}_k\) is a mini-batch of \(b\) randomly selected indices.&lt;/p&gt;

&lt;div id=&quot;minibatch-comparison&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;h4&gt;Comparison: Batch vs Mini-batch vs SGD&lt;/h4&gt;
    &lt;table style=&quot;width: 100%; border-collapse: collapse; margin: 15px 0;&quot;&gt;
        &lt;thead&gt;
            &lt;tr style=&quot;background-color: #f5f5f5;&quot;&gt;
                &lt;th style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Method&lt;/th&gt;
                &lt;th style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Batch Size&lt;/th&gt;
                &lt;th style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Computation/Update&lt;/th&gt;
                &lt;th style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Convergence&lt;/th&gt;
                &lt;th style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Memory Usage&lt;/th&gt;
            &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
            &lt;tr&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;&lt;strong&gt;Batch GD&lt;/strong&gt;&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;$$m$$ (full dataset)&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;$$O(m)$$&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Smooth, stable&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;High&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;&lt;strong&gt;Mini-batch GD&lt;/strong&gt;&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;$$b$$ (typically 32-256)&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;$$O(b)$$&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Balanced&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Medium&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;&lt;strong&gt;SGD&lt;/strong&gt;&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;1&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;$$O(1)$$&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Fast but noisy&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Low&lt;/td&gt;
            &lt;/tr&gt;
        &lt;/tbody&gt;
    &lt;/table&gt;
&lt;/div&gt;

&lt;h2 id=&quot;những-điểm-chính-và-hiểu-biết-thực-tế&quot;&gt;Những điểm chính và Hiểu biết thực tế&lt;/h2&gt;

&lt;h3 id=&quot;khi-nào-sử-dụng-sgd&quot;&gt;Khi nào sử dụng SGD&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Tập dữ liệu lớn&lt;/strong&gt; (hàng triệu mẫu)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Các tình huống học trực tuyến&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Môi trường bộ nhớ hạn chế&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Các giai đoạn huấn luyện đầu&lt;/strong&gt; để tiến bộ nhanh&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;khi-nào-sử-dụng-batch-gd&quot;&gt;Khi nào sử dụng Batch GD&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Tập dữ liệu nhỏ đến trung bình&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Yêu cầu độ chính xác cao&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cần hội tụ ổn định&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Các giai đoạn tinh chỉnh cuối cùng&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;thực-hành-tốt-nhất&quot;&gt;Thực hành tốt nhất&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Lập lịch tốc độ học&lt;/strong&gt;: Bắt đầu cao, giảm dần theo thời gian&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Xáo trộn&lt;/strong&gt;: Ngẫu nhiên hóa thứ tự dữ liệu mỗi epoch&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mini-batch&lt;/strong&gt;: Thường là lựa chọn thực tế tốt nhất&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Momentum&lt;/strong&gt;: Giúp SGD vượt qua nhiễu và tăng tốc hội tụ&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Thực tế hiện đại&lt;/strong&gt;: Hầu hết các framework deep learning sử dụng mini-batch SGD với các optimizer tinh vi (Adam, RMSprop) tự động điều chỉnh tốc độ học.&lt;/p&gt;

&lt;script&gt;
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    // Global variables for demos
    let gdData = [], sgdData = [];
    let gdPosition = [2, 2], sgdPosition = [2, 2];
    let isRunning = false;
    let isPaused = false;
    let isManualMode = false;
    let animationId;
    let currentAlgorithm = null; // &apos;gd&apos; or &apos;sgd&apos;
    let algorithmState = {
        gd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0] },
        sgd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0], selectedFunc: -1 }
    };
    
    // Initialize sliders
    const learningRateSlider = document.getElementById(&apos;learning-rate&apos;);
    const numFunctionsSlider = document.getElementById(&apos;num-functions&apos;);
    const animationSpeedSlider = document.getElementById(&apos;animation-speed&apos;);
    const lrValue = document.getElementById(&apos;lr-value&apos;);
    const mValue = document.getElementById(&apos;m-value&apos;);
    const speedValue = document.getElementById(&apos;speed-value&apos;);
    
    if (learningRateSlider) {
        learningRateSlider.addEventListener(&apos;input&apos;, function() {
            lrValue.textContent = this.value;
        });
    }
    
    if (numFunctionsSlider) {
        numFunctionsSlider.addEventListener(&apos;input&apos;, function() {
            mValue.textContent = this.value;
        });
    }
    
    if (animationSpeedSlider) {
        animationSpeedSlider.addEventListener(&apos;input&apos;, function() {
            speedValue.textContent = this.value;
        });
    }
    
    // Execution mode radio buttons
    const execModeRadios = document.querySelectorAll(&apos;input[name=&quot;exec-mode&quot;]&apos;);
    execModeRadios.forEach(radio =&gt; {
        radio.addEventListener(&apos;change&apos;, function() {
            isManualMode = this.value === &apos;manual&apos;;
            updateControlButtons();
        });
    });
    
    // Simple quadratic functions for demonstration
    function createFunctions(m) {
        const functions = [];
        for (let i = 0; i &lt; m; i++) {
            const centerX = (Math.random() - 0.5) * 4;
            const centerY = (Math.random() - 0.5) * 4;
            functions.push({
                center: [centerX, centerY],
                gradient: function(x, y) {
                    return [2 * (x - centerX), 2 * (y - centerY)];
                },
                value: function(x, y) {
                    return (x - centerX) ** 2 + (y - centerY) ** 2;
                }
            });
        }
        return functions;
    }
    
    // Setup SVG plots
    function setupPlot(svgId, width = 300, height = 300) {
        const svg = d3.select(`#${svgId}`);
        if (svg.empty()) return null;
        
        svg.selectAll(&quot;*&quot;).remove();
        
        const margin = {top: 20, right: 20, bottom: 30, left: 40};
        const plotWidth = width - margin.left - margin.right;
        const plotHeight = height - margin.top - margin.bottom;
        
        const xScale = d3.scaleLinear()
            .domain([-3, 3])
            .range([0, plotWidth]);
            
        const yScale = d3.scaleLinear()
            .domain([-3, 3])
            .range([plotHeight, 0]);
        
        const g = svg.append(&quot;g&quot;)
            .attr(&quot;transform&quot;, `translate(${margin.left},${margin.top})`);
        
        // Add axes
        g.append(&quot;g&quot;)
            .attr(&quot;transform&quot;, `translate(0,${plotHeight})`)
            .call(d3.axisBottom(xScale));
            
        g.append(&quot;g&quot;)
            .call(d3.axisLeft(yScale));
        
        // Add contour background
        const contourData = [];
        for (let i = 0; i &lt; 20; i++) {
            for (let j = 0; j &lt; 20; j++) {
                const x = -3 + (i / 19) * 6;
                const y = -3 + (j / 19) * 6;
                contourData.push({x, y, z: x*x + y*y});
            }
        }
        
        return {svg, g, xScale, yScale, plotWidth, plotHeight};
    }
    
    // Control button functions
    function updateControlButtons() {
        const pauseResumeBtn = document.getElementById(&apos;pause-resume&apos;);
        const stepForwardBtn = document.getElementById(&apos;step-forward&apos;);
        
        if (pauseResumeBtn) {
            pauseResumeBtn.disabled = !isRunning;
            pauseResumeBtn.textContent = isPaused ? &apos;Resume&apos; : &apos;Pause&apos;;
        }
        
        if (stepForwardBtn) {
            stepForwardBtn.disabled = !isManualMode &amp;&amp; !isPaused;
        }
    }
    
    // GD vs SGD Comparison Demo
    const startGDBtn = document.getElementById(&apos;start-gd&apos;);
    const startSGDBtn = document.getElementById(&apos;start-sgd&apos;);
    const pauseResumeBtn = document.getElementById(&apos;pause-resume&apos;);
    const stepForwardBtn = document.getElementById(&apos;step-forward&apos;);
    const resetBtn = document.getElementById(&apos;reset-demo&apos;);
    
    if (startGDBtn) {
        startGDBtn.addEventListener(&apos;click&apos;, function() {
            if (isRunning &amp;&amp; currentAlgorithm === &apos;gd&apos;) return;
            initializeAlgorithm(&apos;gd&apos;);
            if (!isManualMode) {
                runAlgorithm(&apos;gd&apos;);
            }
        });
    }
    
    if (startSGDBtn) {
        startSGDBtn.addEventListener(&apos;click&apos;, function() {
            if (isRunning &amp;&amp; currentAlgorithm === &apos;sgd&apos;) return;
            initializeAlgorithm(&apos;sgd&apos;);
            if (!isManualMode) {
                runAlgorithm(&apos;sgd&apos;);
            }
        });
    }
    
    if (pauseResumeBtn) {
        pauseResumeBtn.addEventListener(&apos;click&apos;, function() {
            if (isPaused) {
                isPaused = false;
                if (currentAlgorithm) {
                    runAlgorithm(currentAlgorithm);
                }
            } else {
                isPaused = true;
                if (animationId) {
                    cancelAnimationFrame(animationId);
                }
            }
            updateControlButtons();
        });
    }
    
    if (stepForwardBtn) {
        stepForwardBtn.addEventListener(&apos;click&apos;, function() {
            if (currentAlgorithm &amp;&amp; (isManualMode || isPaused)) {
                performSingleStep(currentAlgorithm);
            }
        });
    }
    
    if (resetBtn) {
        resetBtn.addEventListener(&apos;click&apos;, function() {
            resetDemo();
        });
    }
    
    // Initialize algorithm state
    function initializeAlgorithm(algorithm) {
        const m = parseInt(numFunctionsSlider.value);
        const functions = createFunctions(m);
        
        algorithmState[algorithm] = {
            iteration: 0,
            position: [2, 2],
            path: [[2, 2]],
            functions: functions,
            totalCost: 0,
            gradient: [0, 0],
            selectedFunc: algorithm === &apos;sgd&apos; ? -1 : undefined
        };
        
        currentAlgorithm = algorithm;
        isRunning = true;
        isPaused = false;
        
        // Setup plot
        const plotId = algorithm === &apos;gd&apos; ? &apos;gd-plot&apos; : &apos;sgd-plot&apos;;
        const plot = setupPlot(plotId, 350, 350);
        
        // Update status
        updateAlgorithmDisplay(algorithm);
        updateControlButtons();
        
        // Update detailed info
        const detailedInfoId = algorithm === &apos;gd&apos; ? &apos;gd-detailed-info&apos; : &apos;sgd-detailed-info&apos;;
        document.getElementById(detailedInfoId).textContent = 
            isManualMode ? &apos;Ready for manual stepping&apos; : &apos;Running automatically...&apos;;
    }
    
    // Run algorithm in auto mode
    function runAlgorithm(algorithm) {
        if (isPaused || isManualMode) return;
        
        const speed = parseInt(animationSpeedSlider.value);
        const delay = 1100 - speed * 100; // Convert speed to delay (higher speed = lower delay)
        
        function step() {
            if (isPaused || !isRunning) return;
            
            const shouldContinue = performSingleStep(algorithm);
            
            if (shouldContinue &amp;&amp; !isPaused) {
                setTimeout(() =&gt; {
                    animationId = requestAnimationFrame(step);
                }, delay);
            } else {
                isRunning = false;
                updateControlButtons();
                
                const detailedInfoId = algorithm === &apos;gd&apos; ? &apos;gd-detailed-info&apos; : &apos;sgd-detailed-info&apos;;
                document.getElementById(detailedInfoId).textContent = &apos;Converged!&apos;;
            }
        }
        
        step();
    }
    
    // Perform a single step of the algorithm
    function performSingleStep(algorithm) {
        const state = algorithmState[algorithm];
        const lr = parseFloat(learningRateSlider.value);
        
        if (algorithm === &apos;gd&apos;) {
            return performGDStep(state, lr);
        } else {
            return performSGDStep(state, lr);
        }
    }
    
    function performGDStep(state, lr) {
        // Compute full gradient (sum of all function gradients)
        let gradX = 0, gradY = 0;
        for (const func of state.functions) {
            const grad = func.gradient(state.position[0], state.position[1]);
            gradX += grad[0];
            gradY += grad[1];
        }
        
        // Average the gradients
        gradX /= state.functions.length;
        gradY /= state.functions.length;
        
        state.gradient = [gradX, gradY];
        
        // Update position
        state.position[0] -= lr * gradX;
        state.position[1] -= lr * gradY;
        state.path.push(state.position.slice());
        
        // Compute total cost
        state.totalCost = 0;
        for (const func of state.functions) {
            state.totalCost += func.value(state.position[0], state.position[1]);
        }
        state.totalCost /= state.functions.length;
        
        state.iteration++;
        
        // Update visualization
        updateAlgorithmDisplay(&apos;gd&apos;);
        
        // Check convergence
        const gradientMagnitude = Math.sqrt(gradX * gradX + gradY * gradY);
        return state.iteration &lt; 100 &amp;&amp; gradientMagnitude &gt; 0.01;
    }
    
    function performSGDStep(state, lr) {
        // Select random function
        const funcIndex = Math.floor(Math.random() * state.functions.length);
        const func = state.functions[funcIndex];
        state.selectedFunc = funcIndex;
        
        // Compute gradient for selected function only
        const grad = func.gradient(state.position[0], state.position[1]);
        state.gradient = grad;
        
        // Update position
        state.position[0] -= lr * grad[0];
        state.position[1] -= lr * grad[1];
        state.path.push(state.position.slice());
        
        // Compute total cost
        state.totalCost = 0;
        for (const func of state.functions) {
            state.totalCost += func.value(state.position[0], state.position[1]);
        }
        state.totalCost /= state.functions.length;
        
        state.iteration++;
        
        // Update visualization
        updateAlgorithmDisplay(&apos;sgd&apos;);
        
        // Check convergence (SGD needs more iterations)
        return state.iteration &lt; 300 &amp;&amp; state.totalCost &gt; 0.01;
    }
    
    function updateAlgorithmDisplay(algorithm) {
        const state = algorithmState[algorithm];
        const plotId = algorithm === &apos;gd&apos; ? &apos;gd-plot&apos; : &apos;sgd-plot&apos;;
        const color = algorithm === &apos;gd&apos; ? &apos;steelblue&apos; : &apos;orange&apos;;
        
        // Update path visualization
        const plot = {
            svg: d3.select(`#${plotId}`),
            g: d3.select(`#${plotId} g`),
            xScale: d3.scaleLinear().domain([-3, 3]).range([0, 270]),
            yScale: d3.scaleLinear().domain([-3, 3]).range([270, 0])
        };
        
        if (!plot.g.empty()) {
            updatePath(plot, state.path, color);
        }
        
        // Update info displays
        const infoId = algorithm === &apos;gd&apos; ? &apos;gd-info&apos; : &apos;sgd-info&apos;;
        const gradientInfoId = algorithm === &apos;gd&apos; ? &apos;gd-gradient-info&apos; : &apos;sgd-gradient-info&apos;;
        
        document.getElementById(infoId).textContent = 
            `Iterations: ${state.iteration}, Cost: ${state.totalCost.toFixed(4)}`;
        
        if (algorithm === &apos;gd&apos;) {
            document.getElementById(gradientInfoId).textContent = 
                `Gradient: [${state.gradient[0].toFixed(3)}, ${state.gradient[1].toFixed(3)}]`;
        } else {
            document.getElementById(gradientInfoId).textContent = 
                `Selected Function: f${state.selectedFunc + 1}, Gradient: [${state.gradient[0].toFixed(3)}, ${state.gradient[1].toFixed(3)}]`;
        }
        
        // Update progress bar
        const progressId = algorithm === &apos;gd&apos; ? &apos;gd-progress&apos; : &apos;sgd-progress&apos;;
        const maxIterations = algorithm === &apos;gd&apos; ? 100 : 300;
        const progress = Math.min((state.iteration / maxIterations) * 100, 100);
        document.getElementById(progressId).style.width = `${progress}%`;
        
        // Update detailed status
        const detailedInfoId = algorithm === &apos;gd&apos; ? &apos;gd-detailed-info&apos; : &apos;sgd-detailed-info&apos;;
        const gradMagnitude = Math.sqrt(state.gradient[0] ** 2 + state.gradient[1] ** 2);
        document.getElementById(detailedInfoId).textContent = 
            `Step ${state.iteration}: Position [${state.position[0].toFixed(3)}, ${state.position[1].toFixed(3)}], |∇| = ${gradMagnitude.toFixed(4)}`;
    }
    
    function updatePath(plot, path, color) {
        const line = d3.line()
            .x(d =&gt; plot.xScale(d[0]))
            .y(d =&gt; plot.yScale(d[1]));
        
        plot.g.selectAll(&apos;.path&apos;).remove();
        plot.g.append(&apos;path&apos;)
            .datum(path)
            .attr(&apos;class&apos;, &apos;path&apos;)
            .attr(&apos;fill&apos;, &apos;none&apos;)
            .attr(&apos;stroke&apos;, color)
            .attr(&apos;stroke-width&apos;, 2)
            .attr(&apos;d&apos;, line);
        
        // Add current position
        const current = path[path.length - 1];
        plot.g.selectAll(&apos;.current-pos&apos;).remove();
        plot.g.append(&apos;circle&apos;)
            .attr(&apos;class&apos;, &apos;current-pos&apos;)
            .attr(&apos;cx&apos;, plot.xScale(current[0]))
            .attr(&apos;cy&apos;, plot.yScale(current[1]))
            .attr(&apos;r&apos;, 5)
            .attr(&apos;fill&apos;, color);
    }
    
    function resetDemo() {
        if (animationId) {
            cancelAnimationFrame(animationId);
        }
        
        isRunning = false;
        isPaused = false;
        currentAlgorithm = null;
        
        // Reset algorithm states
        algorithmState = {
            gd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0] },
            sgd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0], selectedFunc: -1 }
        };
        
        // Clear plots
        d3.select(&apos;#gd-plot&apos;).selectAll(&quot;*&quot;).remove();
        d3.select(&apos;#sgd-plot&apos;).selectAll(&quot;*&quot;).remove();
        
        // Reset info displays
        document.getElementById(&apos;gd-info&apos;).textContent = &apos;Iterations: 0, Cost: 0&apos;;
        document.getElementById(&apos;sgd-info&apos;).textContent = &apos;Iterations: 0, Cost: 0&apos;;
        document.getElementById(&apos;gd-gradient-info&apos;).textContent = &apos;Gradient: [0, 0]&apos;;
        document.getElementById(&apos;sgd-gradient-info&apos;).textContent = &apos;Selected Function: -, Gradient: [0, 0]&apos;;
        
        // Reset detailed info
        document.getElementById(&apos;gd-detailed-info&apos;).textContent = &apos;Ready to start&apos;;
        document.getElementById(&apos;sgd-detailed-info&apos;).textContent = &apos;Ready to start&apos;;
        
        // Reset progress bars
        document.getElementById(&apos;gd-progress&apos;).style.width = &apos;0%&apos;;
        document.getElementById(&apos;sgd-progress&apos;).style.width = &apos;0%&apos;;
        
        // Update control buttons
        updateControlButtons();
    }
    
});
&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>06-04 Gradient boosting</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_04_gradient_boosting/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_04_gradient_boosting</id>
   <content type="html">&lt;h1 id=&quot;gradient-boosting&quot;&gt;Gradient boosting&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Gradient boosting&lt;/strong&gt; là một phương pháp sử dụng gradient descent để tạo ra các cây một cách tuần tự, đồng thời bù đắp cho các lỗi của các cây trước đó khi cố gắng dự đoán kết quả với một mô hình ensemble bao gồm nhiều cây. &lt;strong&gt;Gradient Boosting&lt;/strong&gt; có thể được sử dụng cho cả hồi quy và phân lớp.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Để biết thêm thông tin chi tiết, tham khảo blog &lt;a href=&quot;https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d&quot;&gt;Gradient Boosting from scratch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tham-khảo-thuật-toán-functional-gradient-descent&quot;&gt;[Tham khảo] Thuật toán functional gradient descent&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Gradient boosting&lt;/strong&gt; được giới thiệu như một thuật toán functional gradient descent bởi Llew Mason, Jonathan Baxter, Peter Bartlett và Marcus Frean. Thuật toán functional gradient descent tối ưu hóa hàm mất mát trên không gian hàm bằng cách liên tục lựa chọn các hàm có hướng âm của gradient, do đó thực hiện gradient descent.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Để biết thêm thông tin chi tiết, tham khảo &lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient_boosting&quot;&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tham-khảo-boosting-vs-bagging&quot;&gt;[Tham khảo] Boosting vs Bagging&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Boosting&lt;/strong&gt; là một kỹ thuật ensemble tạo ra các weak learner một cách tuần tự để dự đoán kết quả. Learner giai đoạn tiếp theo học từ dữ liệu mà learner giai đoạn trước đó đã dự đoán sai, và kết quả của các learner được tạo ra tuần tự được kết hợp để tạo ra kết quả cuối cùng.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bagging&lt;/strong&gt; là một kỹ thuật ensemble tạo ra các weak learner độc lập với nhau để dự đoán kết quả. Do đó, mỗi learner chạy song song và kết quả của chúng được kết hợp để tạo ra kết quả cuối cùng.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Để biết thêm thông tin chi tiết, tham khảo blog &lt;a href=&quot;https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/&quot;&gt;What is the difference between Bagging and Boosting?&lt;/a&gt;
    &lt;h2 id=&quot;gradient-boosting-1&quot;&gt;Gradient Boosting&lt;/h2&gt;
    &lt;p&gt;Hãy xem xét nền tảng về cách &lt;strong&gt;Gradient Boosting&lt;/strong&gt; được phát triển.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Giả sử có một mô hình ensemble bao gồm các cây được sử dụng cho phân lớp. Mô hình này sẽ muốn dự đoán kết quả sao cho tối thiểu hóa lỗi với các giá trị quan sát được. Gọi các giá trị quan sát được là \(y_i\), \(i=1,\dots,n\), dữ liệu đầu vào là \(x_i, i=1,\dots,n\), và các giá trị dự đoán là \(u_i\), \(i=1,\dots,n\).&lt;/p&gt;

&lt;p&gt;Như được hiển thị trong hình dưới đây, mỗi cây thuộc ensemble nhận \(x_i \in R^p\) làm đầu vào và đưa ra kết quả theo các điều kiện phân nhánh trong các nút của cây.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_04_tree_O9zyAlk.png&quot; alt=&quot;tree_O9zyAlk&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig 1] Example of Tree }T_j\text{ [3]}$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Giá trị dự đoán \(u_i\) của mô hình ensemble có thể được tính toán bằng tổng có trọng số của kết quả của mỗi cây. (Ở đây, \(T_j(x_i)\) là kết quả được đưa ra bởi cây \(j\) khi nó nhận \(x_i\) làm đầu vào.)&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
u_i = \sum_{j=1}^M \beta_j T_j(x_i)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Đối với hàm mất mát, nó có thể được định nghĩa là \(L=(y_i,u_i)=(y_i - u_i)^2\) dưới dạng tổng bình phương sai số để tối thiểu hóa lỗi giữa các giá trị quan sát và dự đoán.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
\min_{\beta} \sum_{i=1}^n L\left(y_i, \sum_{j=1}^M \beta_j T_j(x_i)\right)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Thông thường, khi xây dựng cây trong các mô hình ensemble, nhiều cây nhỏ với độ sâu cố định được tạo ra. Điều này là bởi vì việc làm cho cây nhỏ hơn sử dụng ít bộ nhớ hơn và cho phép dự đoán nhanh hơn, và khi số lượng cây tăng lên, hiệu suất của ensemble cải thiện. Thông thường, độ sâu của cây được cố định ở mức 5 hoặc ít hơn.&lt;/p&gt;

&lt;p&gt;Do đó, trong bài toán này, các điều kiện nút được định nghĩa trong mỗi cây rất đa dạng và kết quả của rất nhiều cây được kết hợp tuyến tính, làm cho không gian cây khá lớn. Vì vậy, có thể nói rằng đây là một bài toán rất khó để tối ưu hóa.&lt;/p&gt;

&lt;p&gt;Để giải quyết vấn đề này, bài toán tối ưu hóa phải được chuyển đổi thành một bài toán dễ hơn. Bài toán tối ưu hóa ban đầu là tìm \(M\) trọng số \(\beta_j\) để tối thiểu hóa hàm mất mát. Hãy nghĩ về bài toán này như một bài toán tối thiểu hóa \(\min_{u} f(u)\) của hàm \(f(u)\) đối với các giá trị dự đoán \(u\). Nếu hàm \(f(u)\) là hàm mất mát \(L(y,u)\), thì việc tìm \(u\) để tối thiểu hóa hàm mất mát có thể được coi là một bài toán được định nghĩa lại một cách dễ dàng. (Ở đây, \(n\) là số lượng điểm dữ liệu.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient boosting&lt;/strong&gt; đề cập đến kỹ thuật giải quyết bài toán tối thiểu hóa được định nghĩa lại \(\min_{u} f(u)\) sử dụng gradient descent.&lt;/p&gt;

&lt;h2 id=&quot;thuật-toán&quot;&gt;Thuật toán&lt;/h2&gt;
&lt;p&gt;Thuật toán &lt;strong&gt;Gradient boosting&lt;/strong&gt; thực hiện gradient descent theo cách sau để tìm ra nghiệm tối ưu \(u^*\) của \(\min_u L(y, u)\).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Đặt giá trị ban đầu là kết quả của một cây tùy ý: \(u^{(0)}=T_0\). Sau đó lặp lại các bước 2~4 sau đây.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Tính toán gradient âm cho \(u^{(k-1)}\), là giá trị dự đoán gần nhất cho \(n\) điểm dữ liệu.
    &lt;blockquote&gt;

\[\begin{equation}
d_i = - \left . \left[ \frac{\partial L(y_i,u_i)}{\partial u_i} \right] \right|_{u_i = u_i^{(k-1)}}, i=1,\dots,n
\end{equation}\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Tìm cây \(T_k\) có kết quả \(T(x_i)\) giống nhất với các gradient \(d_i\) cho \(n\) điểm dữ liệu.
    &lt;blockquote&gt;

\[\begin{equation}
\min_{\text{trees } T} \sum_{i=1}^n (d_i-T(x_i))^2
\end{equation}\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Tính toán kích thước bước \(a_k\) và cập nhật các giá trị dự đoán sử dụng \(T_k\) được tìm thấy ở trên.
    &lt;blockquote&gt;

\[u^{(k)}=u^{(k-1)} + \alpha_k T_k\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thuật toán này tìm gradient \(d\) đối với \(u\) để tìm nghiệm tối ưu \(u^*\) thông qua gradient descent, tìm \(T_k\) gần nhất với \(d\), và thay thế \(T_k\) thay vì gradient trong phương trình cập nhật để tìm vị trí tiếp theo.&lt;/p&gt;

&lt;p&gt;Giá trị dự đoán cuối cùng \(u^*\) thu được theo cách này có thể được thấy là giống hệt với tổng có trọng số của kết quả cây được định nghĩa trước đó. (Tức là, nếu chúng ta mở rộng phương trình cập nhật đệ quy \(u^{(k)}=u^{(k-1)} + \alpha_k T_k\) trở lại \(k=0\), chúng ta nhận được \(u^* = \sum_{k=1}^n \alpha_k T_k\), có thể được biến thành dạng tổng có trọng số của kết quả cây.)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>06-03 Phân tích hội tụ</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_03_convergence_analysis/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_03_convergence_analysis</id>
   <content type="html">&lt;p&gt;Trong phần này, chúng ta phân tích sự hội tụ của Gradient Descent. Chúng ta sẽ xem xét các cận sai số cho sự hội tụ trong trường hợp kích thước bước cố định và trong trường hợp tìm kiếm lùi. Ngoài ra, chúng ta sẽ phân tích các cận sai số khi điều kiện lồi mạnh được thỏa mãn.”&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-03-06 Can we do better?</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_03_06_can_we_do_better/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_03_06_can_we_do_better</id>
   <content type="html">&lt;p&gt;Gradient descent has a convergence rate of \(O(1/\epsilon)\) for problems represented by functions that have Lipschitz gradients and are convex and differentiable. Are there first-order methods that are faster than gradient descent?&lt;/p&gt;

&lt;h3 id=&quot;first-order-method&quot;&gt;First-order method&lt;/h3&gt;
&lt;p&gt;A first-order method can express changes at the \(x^{(k)}\)-th iteration as follows. Therefore, the change at the \(x^{(k)}\)-th iteration is expressed as the span of gradients from the initial position \(x^{(0)}\) to \(x^{(k−1)}\).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x^{(0)} +\) &lt;strong&gt;span&lt;/strong&gt;\(\{∇f(x^{(0)}),∇f(x^{(1)}),...,∇f(x^{(k−1)})\}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;theorem-nesterov&quot;&gt;Theorem (Nesterov)&lt;/h3&gt;
&lt;p&gt;Nesterov’s theorem provides a lower bound for the convergence of first-order methods.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Nesterov Theorem&lt;/strong&gt; For any \(k ≤ (n−1)/2\) and starting point \(x^{(0)}\), there exists a function \(f\) such that any first-order method satisfies the following condition (where \(n\) denotes the dimension):&lt;br /&gt;
\begin{align}
f(x^{(k)})−f^{\star} ≥ \frac{3L \lVert x^{(0)} −x^{\star} \rVert_2^2}{32(k + 1)^2 }\&lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since Nesterov’s theorem has \(k^2\) in the denominator of the lower bound, the convergence rate becomes \(O(1/k^2)\). Furthermore, the number of iterations becomes \(O(1/\sqrt{\epsilon})\). We will examine this content in detail later.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-03-05 Xem xét điều kiện & Tính thực tiễn</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_03_05_look_at_the_conditions_and_practicalities/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_03_05_look_at_the_conditions_and_practicalities</id>
   <content type="html">&lt;h2 id=&quot;điều-kiện-liên-tục-lipschitz--tính-lồi-mạnh&quot;&gt;Điều kiện liên tục Lipschitz &amp;amp; Tính lồi mạnh&lt;/h2&gt;
&lt;p&gt;Hãy xem xét các điều kiện cho tính liên tục Lipschitz và tính lồi mạnh sử dụng \(f(β) = \frac{1}{2} \lVert y−Xβ \rVert_2^2\) làm ví dụ.&lt;/p&gt;

&lt;h3 id=&quot;tính-liên-tục-lipschitz-của-f-&quot;&gt;Tính liên tục Lipschitz của \(∇f\) :&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Điều này có nghĩa là \(\nabla^2f(x) \preceq LI\). &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Vì \(∇^2f(β) = X^TX\), chúng ta có \(L = \sigma^2_{max}(X)\).&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tính-lồi-mạnh-của-f-&quot;&gt;Tính lồi mạnh của \(f\) :&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Điều này có nghĩa là \(\nabla^2f(x) \succeq mI\).&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Vì \(\nabla^2f(β) = X^TX\), chúng ta có \(m = \sigma_{min}^2(X)\).&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Nếu \(X\) là ma trận \(n \times p\) và \(p &amp;gt; n\), thì \(\sigma_{min}(X) = 0\), vậy \(f\) không thể lồi mạnh.&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Ngay cả khi \(\sigma_{min}(X) &amp;gt; 0\), số điều kiện \(L/m = \sigma_{max}^2(X)/\sigma_{min}^2(X)\) có thể rất lớn.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nếu hàm \(f\) lồi mạnh và có gradient Lipschitz, thì nó thỏa mãn điều sau. Bạn có thể nghĩ về \(f\) như được kẹp giữa hai hàm bậc hai.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(mI \preceq \nabla^2f(x) \preceq LI \text{ với mọi } x ∈ \mathbb{R}^n\) và \(L &amp;gt; m &amp;gt; 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thỏa mãn cả hai điều kiện cho mọi \(x\) có thể rất mạnh. Tuy nhiên, nếu chúng ta suy nghĩ cẩn thận hơn, chúng ta có thể thấy rằng điều kiện này chỉ cần thiết cho tập mức phụ sau đây.&lt;/p&gt;

&lt;blockquote&gt;
\[S = \{x : f(x) \leq f(x^{(0)})\}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;tính-thực-tiễn&quot;&gt;Tính thực tiễn&lt;/h2&gt;

&lt;h3 id=&quot;tiêu-chí-dừng-cho-các-thuật-toán-tối-ưu-hóa&quot;&gt;Tiêu chí dừng cho các thuật toán tối ưu hóa&lt;/h3&gt;

&lt;p&gt;Trong thực tế, các thuật toán tối ưu hóa cần các tiêu chí dừng được định nghĩa rõ ràng để xác định khi nào chấm dứt quá trình lặp. Dưới đây là những điều kiện dừng phổ biến nhất:&lt;/p&gt;

&lt;h4 id=&quot;1-độ-lớn-gradient-gần-bằng-không&quot;&gt;1. &lt;strong&gt;Độ lớn Gradient gần bằng Không:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Đây là điều kiện dừng lý tưởng cho các bài toán tối ưu hóa không ràng buộc, dựa trên thực tế rằng gradient của hàm mục tiêu bằng không tại các cực trị địa phương.
\(\|\nabla f(\mathbf{x}_k)\| \leq \epsilon_1\)
trong đó \(\mathbf{x}_k\) là điểm hiện tại tại lần lặp \(k\), và \(\epsilon_1\) là một ngưỡng dương nhỏ.&lt;/p&gt;

&lt;p&gt;Nếu \(x^{\star}\) là nghiệm, thì \(\nabla f(x^{\star}) = 0\). Nếu \(f\) lồi mạnh, thì:&lt;/p&gt;
&lt;blockquote&gt;
\[\lVert \nabla f(x) \rVert_2 ≤ \sqrt{2m \epsilon} ⇒ f(x)−f^{\star} ≤ \epsilon\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;2-thay-đổi-nhỏ-trong-giá-trị-hàm-mục-tiêu&quot;&gt;2. &lt;strong&gt;Thay đổi nhỏ trong giá trị hàm mục tiêu:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Thuật toán dừng khi giá trị hàm mục tiêu không còn thay đổi đáng kể giữa các lần lặp liên tiếp.
\(|f(\mathbf{x}_{k+1}) - f(\mathbf{x}_k)| \leq \epsilon_2\)
trong đó \(\epsilon_2\) là một ngưỡng dương nhỏ.&lt;/p&gt;

&lt;h4 id=&quot;3-thay-đổi-nhỏ-trong-biến-tham-số&quot;&gt;3. &lt;strong&gt;Thay đổi nhỏ trong biến (tham số):&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Thuật toán dừng khi các tham số mô hình không còn thay đổi đáng kể giữa các lần lặp.
\(\|\mathbf{x}_{k+1} - \mathbf{x}_k\| \leq \epsilon_3\)
trong đó \(\epsilon_3\) là một ngưỡng dương nhỏ.&lt;/p&gt;

&lt;h4 id=&quot;4-số-lần-lặp-tối-đa&quot;&gt;4. &lt;strong&gt;Số lần lặp tối đa:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Để ngăn thuật toán chạy vô hạn hoặc quá lâu, một giới hạn trên về số lần lặp được đặt.
\(k \geq \text{MaxIterations}\)
Đây là điều kiện dừng an toàn đảm bảo thuật toán sẽ chấm dứt trong thời gian hợp lý, ngay cả khi nó chưa đạt được sự hội tụ hoàn hảo.&lt;/p&gt;

&lt;h4 id=&quot;5-thời-gian-chạy-tối-đa&quot;&gt;5. &lt;strong&gt;Thời gian chạy tối đa:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Tương tự như giới hạn lần lặp tối đa, thuật toán có thể được dừng nếu nó đã chạy quá thời gian cho phép.
\(\text{ElapsedTime} \geq \text{MaxTime}\)&lt;/p&gt;

&lt;h4 id=&quot;6-điều-kiện-kết-hợp&quot;&gt;6. &lt;strong&gt;Điều kiện kết hợp:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Trong thực tế, nhiều điều kiện dừng thường được sử dụng kết hợp. Ví dụ, thuật toán dừng nếu &lt;em&gt;bất kỳ&lt;/em&gt; điều kiện nào ở trên được thỏa mãn. Điều này giúp cân bằng giữa độ chính xác và hiệu quả tính toán.&lt;/p&gt;

&lt;h3 id=&quot;tham-khảo-quá-trình-suy-dẫn&quot;&gt;[Tham khảo] Quá trình suy dẫn&lt;/h3&gt;
&lt;p&gt;Quá trình suy dẫn cho phương trình trên như sau.
Vì \(f\) thỏa mãn tính lồi mạnh, tồn tại hằng số \(m \ge 0\) sao cho:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\nabla^2 f(x) \succeq mI \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Hãy mở rộng hàm \(f\) bằng chuỗi Taylor bậc hai.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) = f(x) + \nabla f(x)^T(y−x) + \frac{1}{2} (y−x)^T \nabla^2 f(x) (y−x), \space \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Sau đó, theo \(\nabla f(x) \succeq mI\) ở trên, chúng ta có thể sắp xếp số hạng cuối như một điều kiện cận dưới.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) &amp;amp;  \ge f(x) + \nabla f(x)^T(y−x) + \frac{m}{2} \lVert y−x \rVert_2^2, \space \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Lấy đạo hàm \(f(y)\) theo \(y\) cho \(\tilde{y} = x - (1/m) \nabla f(x)\). Thay \(\tilde{y}\) vào khai triển Taylor:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y) &amp;amp;  \ge f(x) + \nabla f(x)^T(\tilde{y}−x) + \frac{m}{2} \lVert \tilde{y}−x \rVert_2^2 \\
&amp;amp;  = f(x) - \frac{1}{2m} \lVert \nabla f(x) \rVert_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Do đó, thay \(f(y)\) bằng \(f^{*}\) cho:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
 f^{*}  \ge f(x) - \frac{1}{2m} \lVert \nabla f(x) \rVert_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Quy tắc dừng trên được suy dẫn như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(x) - f^{*} \le \frac{1}{2m} \lVert \nabla f(x) \rVert^2_2 &amp;amp; \le \epsilon \\
\lVert \nabla f(x) \rVert^2_2 &amp;amp; \le 2m\epsilon \\
\lVert \nabla f(x) \rVert_2 &amp;amp; \le \sqrt{2m\epsilon} \\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;ưu-điểm-và-nhược-điểm-của-gradient-descent&quot;&gt;Ưu điểm và nhược điểm của Gradient Descent&lt;/h3&gt;

&lt;h3 id=&quot;ưu-điểm&quot;&gt;Ưu điểm&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Thuật toán đơn giản và chi phí mỗi lần lặp thấp.&lt;/li&gt;
  &lt;li&gt;Rất nhanh cho các bài toán lồi mạnh, có điều kiện tốt.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nhược-điểm&quot;&gt;Nhược điểm&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Nói chung chậm vì nhiều bài toán không lồi mạnh hoặc có điều kiện tốt.&lt;/li&gt;
  &lt;li&gt;Không thể xử lý các hàm không khả vi.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>06-03-04 Convergence analysis under strong convexity</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_03_04_convergence_analysis_under_strong_convexity/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_03_04_convergence_analysis_under_strong_convexity</id>
   <content type="html">&lt;p&gt;If \(f\) satisfies the following condition, it is strongly convex (assuming \(f\) is twice differentiable and \(m &amp;gt; 0\)):&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) \ge f(x) + \nabla f(x)^T(y-x) + \frac{m}{2} \| y-x \|_2^2, \quad \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(f\) has a quadratic lower bound, and the constant \(m\) is determined by the minimum eigenvalue of the Hessian of \(f\).&lt;/p&gt;

&lt;p&gt;For any convex function \(g\), \(f\) is strongly convex if:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
g(x) = f(x) - \frac{m}{2} \| x \|_2^2 \quad \text{is convex for all } x \text{ and } m &amp;gt; 0
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;
&lt;p&gt;Given Lipschitz continuity and strong convexity, the following theorem holds (where \(L\) is the Lipschitz constant and \(m\) is the strong convexity constant):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt; with fixed step size (\(t \le 2/(m + L)\)) or backtracking line search satisfies:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f^* \le c^k \frac{L}{2} \| x^{(0)} - x^* \|_2^2, \quad c = (1 - \frac{m}{L}), \quad 0 &amp;lt; c &amp;lt; 1
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof&quot;&gt;Proof&lt;/h2&gt;
&lt;p&gt;If \(\nabla f\) is Lipschitz continuous and \(f\) is strongly convex, then \(f\) has a quadratic upper bound (see &lt;a href=&quot;#post-not-found&quot;&gt;06-03-02&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;For gradient descent \(x^+ = x - t \nabla f(x)\), the optimal \(t\) is \(1/L\), yielding:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^+) \le f(x) -  \frac{1}{2L} \| \nabla f(x) \|_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Subtracting \(f(x^*)\) from both sides:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^+) - f(x^*) \le f(x) - f(x^*) -  \frac{1}{2L} \| \nabla f(x) \|_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Since Gradient Descent satisfies the condition:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x) - f(x^*) \le \frac{1}{2m} \| \nabla f(x) \|_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;We can substitute to get:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^+) - f(x^*) &amp;amp; \le f(x) - f(x^*) -  \frac{m}{L} ( f(x) - f(x^*) ) \\
&amp;amp; =  (1 -  \frac{m}{L} ) ( f(x) - f(x^*) ) \\
&amp;amp; = c  ( f(x) - f(x^*) ) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Iterating this process gives:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f(x^*) \le c^k ( f(x^{(0)}) - f(x^*) ) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;From the Taylor expansion of the function with \(y = x^{(0)}\) and \(x = x^*\):&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) \le f(x) + \nabla f(x)^T (y-x) + \frac{L}{2} \lVert y - x \rVert^2_2  \space \space \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;And since the function is convex, we have:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(0)}) &amp;amp; \le f(x^{*}) + \nabla f(x^{*})^T (x^{(0)}- x^{*} ) + \frac{L}{2} \lVert x^{(0)} - x^{*} \rVert^2_2 \\\\
&amp;amp; =  f(x^{*}) + \frac{L}{2} \lVert x^{(0)} - x^{*} \rVert^2_2 \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Rearranging gives:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(0)}) - f(x^{*}) &amp;amp; \le \frac{L}{2} \lVert x^{(0)} - x^{*} \rVert^2_2 \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Substituting this into the previous inequality results in:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f(x^{*}) &amp;amp; \le c^k \frac{L}{2} \lVert x^{(0)} - x^{*} \rVert^2_2  \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This proves the Convergence Theorem for Gradient Descent under Strong Convexity.&lt;/p&gt;

&lt;h2 id=&quot;linear-convergence&quot;&gt;Linear convergence&lt;/h2&gt;
&lt;p&gt;When \(f\) is strongly convex, the convergence rate becomes \(O(c^k)\), which is exponential.
To achieve \(f(x^{(k)}) - f^{*} \le \epsilon\), it requires \(O(\log(1/\epsilon)\) iterations.
(Without strong convexity, it would require \(O(1/\epsilon)\) iterations.)&lt;/p&gt;

&lt;p&gt;The convergence rate \(O(c^k)\) appears linear on a semi-log plot, as shown below.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06.03_01_01_Line_Convergence.png&quot; alt=&quot;Line_Convergence&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Linear convergence [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Here, the constant \(c\) in \(O(c^k)\) is given by \(1 - \frac{m}{L}\) and depends on the condition number \(L/m\). A larger condition number results in slower convergence (where the condition number is the ratio of the largest eigenvalue to the smallest eigenvalue).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>06-03-03 Convergence analysis for backtracking</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_03_03_convergence_analysis_for_backtracking/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_03_03_convergence_analysis_for_backtracking</id>
   <content type="html">&lt;p&gt;Suppose \(f\) is convex and differentiable with \(dom(f) = \mathbb{R}^n\), and \(\nabla f\) is Lipschitz continuous with constant \(L &amp;gt; 0\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\| \nabla f(x) - \nabla f(y) \|_2 \le L \| x - y \|_2\) for any \(x, y\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Reference: [&lt;a href=&quot;https://en.wikipedia.org/wiki/Lipschitz_continuity&quot;&gt;Wikipedia: Lipschitz continuity&lt;/a&gt;]&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt; with backtracking line search satisfies:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f^* \le \frac{\| x^{(0)} - x^* \|_2^2}{2 t_{min} k}, \quad t_{min} = \min \{ 1, \beta/L \}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The convergence rate for backtracking line search is similar to that for fixed step size, with the step size \(t\) replaced by \(t_{min}\). If \(\beta\) is not too small, the performance is comparable to fixed step size (\(\beta/L\) vs. \(1/L\)).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-03-02 Convergence analysis & Proof</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_03_02_convergence_analysis_and_proof/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_03_02_convergence_analysis_and_proof</id>
   <content type="html">&lt;p&gt;Suppose \(f\) is convex and differentiable with \(dom(f) = \mathbb{R}^n\), and \(\nabla f\) is Lipschitz continuous with constant \(L &amp;gt; 0\):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\| \nabla f(x) - \nabla f(y) \|_2 \le L \| x - y \|_2\) for any \(x, y\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Reference: [&lt;a href=&quot;https://en.wikipedia.org/wiki/Lipschitz_continuity&quot;&gt;Wikipedia: Lipschitz continuity&lt;/a&gt;]&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt; with fixed step size \(t \le 1/L\) satisfies:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f^* \le  \frac{ \| x^{(0)} - x^* \|^2_2 }{2tk}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;With fixed step size, the convergence rate is \(O(1/k)\). To achieve \(f(x^{(k)}) - f^* \le \epsilon\), \(O(1/\epsilon)\) iterations are needed.&lt;/p&gt;

&lt;h2 id=&quot;proof&quot;&gt;Proof&lt;/h2&gt;
&lt;p&gt;If \(\nabla f\) is Lipschitz continuous and \(f\) is convex, then \(f\) has a quadratic upper bound (see &lt;a href=&quot;#post-not-found&quot;&gt;06-03-02&lt;/a&gt;).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y) \le f(x) + \nabla f(x)^T (y-x) + \frac{L}{2} \| y - x \|^2_2 \quad \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For gradient descent \(x^+ = x - t \nabla f(x)\), substitute \(y = x^+\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(x^+) &amp;amp; \le f(x) - t ( 1 - \frac{Lt}{2} )\| \nabla f(x) \|^2_2 \\\
&amp;amp; \le f(x) -  \frac{t}{2} \| \nabla f(x) \|^2_2 \quad \text{if } t \le 1/L
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Thus, \(f(x^+) &amp;lt; f(x)\) and gradient descent converges.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-03-01 Cận trên bậc hai của hàm lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_03_01_convex_function_quadratic_upper_bound/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_03_01_convex_function_quadratic_upper_bound</id>
   <content type="html">&lt;h2 id=&quot;giới-thiệu&quot;&gt;Giới thiệu&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Cận trên bậc hai&lt;/strong&gt; là một tính chất cơ bản của các hàm lồi trơn, cung cấp một công cụ quan trọng để phân tích và thiết kế các thuật toán tối ưu hóa. Tính chất này thiết lập rằng bất kỳ hàm lồi trơn nào cũng có thể được chặn trên bởi một hàm bậc hai, điều này có những ý nghĩa quan trọng cho việc phân tích hội tụ của các phương pháp dựa trên gradient.&lt;/p&gt;

&lt;h2 id=&quot;động-lực&quot;&gt;Động lực&lt;/h2&gt;

&lt;p&gt;Tại sao chúng ta quan tâm đến cận trên bậc hai?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Thiết kế thuật toán&lt;/strong&gt;: Nhiều thuật toán tối ưu hóa (như gradient descent) dựa vào các xấp xỉ cục bộ của hàm mục tiêu. Cận trên bậc hai cung cấp một cách hệ thống để xây dựng các xấp xỉ này.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Phân tích hội tụ&lt;/strong&gt;: Cận trên bậc hai cho phép chúng ta chứng minh tốc độ hội tụ cho các thuật toán tối ưu hóa bằng cách chặn mức độ thay đổi của hàm.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Lựa chọn bước nhảy&lt;/strong&gt;: Hằng số Lipschitz \(L\) trong cận trực tiếp xác định bước nhảy an toàn cho gradient descent.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;tính-chất-cận-trên-bậc-hai&quot;&gt;Tính chất Cận trên Bậc hai&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Định lý&lt;/strong&gt;: Nếu \(f\) là lồi và \(\nabla f\) liên tục Lipschitz với hằng số \(L\), thì \(f\) thỏa mãn cận trên bậc hai:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y) &amp;amp; \le f(x) + \nabla f(x)^T (y-x) + \frac{L}{2} \| y - x \|^2_2 \quad \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;diễn-giải-hình-học&quot;&gt;Diễn giải Hình học&lt;/h3&gt;

&lt;p&gt;Bất đẳng thức này phát biểu rằng:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Xấp xỉ tuyến tính&lt;/strong&gt; \(f(x) + \nabla f(x)^T (y-x)\) (khai triển Taylor bậc nhất) ước lượng thấp \(f(y)\) do tính lồi&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cận trên bậc hai&lt;/strong&gt; \(f(x) + \nabla f(x)^T (y-x) + \frac{L}{2} \| y - x \|^2_2\) ước lượng cao \(f(y)\)&lt;/li&gt;
  &lt;li&gt;Hàm \(f(y)\) được “kẹp” giữa hai cận này&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;đặc-trưng-tương-đương&quot;&gt;Đặc trưng Tương đương&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Hệ quả&lt;/strong&gt;: Đối với bất kỳ hàm lồi trơn \(f\) nào, hàm sau đây là lồi:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
g(x) &amp;amp; = \frac{L}{2} \| x \|^2_2 - f(x) \quad \text{với } dom(g) = dom(f)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này có nghĩa là \(f(x)\) có thể được viết như hiệu của một hàm bậc hai và một hàm lồi.&lt;/p&gt;

&lt;h2 id=&quot;chứng-minh&quot;&gt;Chứng minh&lt;/h2&gt;

&lt;p&gt;Chúng ta sẽ chứng minh cả cận trên bậc hai và đặc trưng tương đương. Chứng minh dựa trên hai tính chất chính của các hàm lồi trơn.&lt;/p&gt;

&lt;h3 id=&quot;kiến-thức-cần-thiết&quot;&gt;Kiến thức Cần thiết&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Định nghĩa 1 (Toán tử Đơn điệu)&lt;/strong&gt;: Trong không gian vector \(X\), toán tử \(T : X \to X^*\) là đơn điệu nếu:&lt;/p&gt;
&lt;blockquote&gt;
\[(Tu - Tv, u-v) \ge 0, \quad \forall u, v \in X\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Tính chất 1 (Tính đơn điệu của Gradient)&lt;/strong&gt;: Nếu \(f\) là lồi và khả vi, thì \(\nabla f\) là toán tử đơn điệu:&lt;/p&gt;
&lt;blockquote&gt;
\[(\nabla f(y) - \nabla f(x))^T (y-x) \ge 0, \quad \forall x, y\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Tính chất 2 (Liên tục Lipschitz)&lt;/strong&gt;: \(\nabla f\) liên tục Lipschitz với hằng số \(L\):&lt;/p&gt;
&lt;blockquote&gt;
\[\| \nabla f(x) - \nabla f(y) \|_2 \le L \| x - y \|_2, \quad \forall x, y\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;chứng-minh-cận-trên-bậc-hai&quot;&gt;Chứng minh Cận trên Bậc hai&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Bước 1&lt;/strong&gt;: Xét hàm \(h(t) = f(x + t(y-x))\) với \(t \in [0,1]\). Theo định lý cơ bản của giải tích:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y) - f(x) &amp;amp;= h(1) - h(0) = \int_0^1 h&apos;(t) dt \\
&amp;amp;= \int_0^1 \nabla f(x + t(y-x))^T (y-x) dt
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Bước 2&lt;/strong&gt;: Chúng ta có thể viết lại như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) - f(x) &amp;amp;= \nabla f(x)^T (y-x) + \int_0^1 [\nabla f(x + t(y-x)) - \nabla f(x)]^T (y-x) dt
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Bước 3&lt;/strong&gt;: Sử dụng bất đẳng thức Cauchy-Schwarz và tính liên tục Lipschitz:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;[\nabla f(x + t(y-x)) - \nabla f(x)]^T (y-x) \\
&amp;amp;\le \|\nabla f(x + t(y-x)) - \nabla f(x)\| \cdot \|y-x\| \\
&amp;amp;\le L \cdot t\|y-x\| \cdot \|y-x\| = Lt\|y-x\|^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Bước 4&lt;/strong&gt;: Tích phân trên \(t \in [0,1]\):&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) - f(x) &amp;amp;\le \nabla f(x)^T (y-x) + \int_0^1 Lt\|y-x\|^2 dt \\
&amp;amp;= \nabla f(x)^T (y-x) + L\|y-x\|^2 \int_0^1 t dt \\
&amp;amp;= \nabla f(x)^T (y-x) + \frac{L}{2}\|y-x\|^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Do đó: \(f(y) \le f(x) + \nabla f(x)^T (y-x) + \frac{L}{2}\|y-x\|^2\)&lt;/p&gt;

&lt;h3 id=&quot;chứng-minh-đặc-trưng-tương-đương&quot;&gt;Chứng minh Đặc trưng Tương đương&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Định lý&lt;/strong&gt;: Hàm \(g(x) = \frac{L}{2} \| x \|^2_2 - f(x)\) là lồi.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Chứng minh&lt;/strong&gt;: Chúng ta cần chỉ ra rằng \(\nabla^2 g(x) \succeq 0\) (nửa xác định dương).&lt;/p&gt;

&lt;p&gt;Vì \(g(x) = \frac{L}{2} \| x \|^2_2 - f(x)\), ta có:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\nabla g(x) = Lx - \nabla f(x)\]
  &lt;/li&gt;
  &lt;li&gt;
\[\nabla^2 g(x) = LI - \nabla^2 f(x)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Với bất kỳ vector \(v\) nào, chúng ta cần chỉ ra \(v^T \nabla^2 g(x) v \ge 0\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
v^T \nabla^2 g(x) v &amp;amp;= v^T (LI - \nabla^2 f(x)) v \\
&amp;amp;= L\|v\|^2 - v^T \nabla^2 f(x) v
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Từ tính liên tục Lipschitz của \(\nabla f\), chúng ta có thể chỉ ra rằng \(\nabla^2 f(x) \preceq LI\), có nghĩa là:
\(v^T \nabla^2 f(x) v \le L\|v\|^2\)&lt;/p&gt;

&lt;p&gt;Do đó: \(v^T \nabla^2 g(x) v = L\|v\|^2 - v^T \nabla^2 f(x) v \ge 0\)&lt;/p&gt;

&lt;p&gt;Điều này chứng minh rằng \(g\) là lồi. \(\square\)&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ&quot;&gt;Ví dụ&lt;/h2&gt;

&lt;h3 id=&quot;ví-dụ-1-hàm-bậc-hai&quot;&gt;Ví dụ 1: Hàm Bậc hai&lt;/h3&gt;

&lt;p&gt;Xét \(f(x) = \frac{1}{2}x^T A x + b^T x + c\) với \(A \succeq 0\) (nửa xác định dương).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[\nabla f(x) = Ax + b\]
  &lt;/li&gt;
  &lt;li&gt;
\[\nabla^2 f(x) = A\]
  &lt;/li&gt;
  &lt;li&gt;Nếu \(\lambda_{max}(A) = L\), thì \(\|\nabla f(x) - \nabla f(y)\| = \|A(x-y)\| \le L\|x-y\|\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cận trên bậc hai trở thành:
\(f(y) \le f(x) + (Ax + b)^T(y-x) + \frac{L}{2}\|y-x\|^2\)&lt;/p&gt;

&lt;p&gt;Đối với hàm bậc hai, cận này là &lt;strong&gt;chặt&lt;/strong&gt; khi \(L = \lambda_{max}(A)\).&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-2-hàm-mất-mát-logistic&quot;&gt;Ví dụ 2: Hàm Mất mát Logistic&lt;/h3&gt;

&lt;p&gt;Xét hàm mất mát logistic \(f(x) = \log(1 + e^{a^T x})\) với \(a \in \mathbb{R}^n\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[\nabla f(x) = \frac{e^{a^T x}}{1 + e^{a^T x}} a = \sigma(a^T x) a\]
  &lt;/li&gt;
  &lt;li&gt;
\[\nabla^2 f(x) = \sigma(a^T x)(1 - \sigma(a^T x)) aa^T\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Vì \(\sigma(t)(1-\sigma(t)) \le \frac{1}{4}\) với mọi \(t\), ta có:
\(\nabla^2 f(x) \preceq \frac{1}{4} aa^T \preceq \frac{\|a\|^2}{4} I\)&lt;/p&gt;

&lt;p&gt;Do đó, \(L = \frac{\|a\|^2}{4}\) và cận trên bậc hai là:
\(f(y) \le f(x) + \sigma(a^T x) a^T(y-x) + \frac{\|a\|^2}{8}\|y-x\|^2\)&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-3-bình-phương-tối-thiểu&quot;&gt;Ví dụ 3: Bình phương Tối thiểu&lt;/h3&gt;

&lt;p&gt;Với \(f(x) = \frac{1}{2}\|Ax - b\|^2\) trong đó \(A \in \mathbb{R}^{m \times n}\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[\nabla f(x) = A^T(Ax - b)\]
  &lt;/li&gt;
  &lt;li&gt;
\[\nabla^2 f(x) = A^T A\]
  &lt;/li&gt;
  &lt;li&gt;\(L = \lambda_{max}(A^T A) = \sigma_{max}^2(A)\) (bình phương giá trị kỳ dị lớn nhất)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cận trên bậc hai là:
\(f(y) \le f(x) + (A^T(Ax - b))^T(y-x) + \frac{\sigma_{max}^2(A)}{2}\|y-x\|^2\)&lt;/p&gt;

&lt;h2 id=&quot;ứng-dụng-trong-tối-ưu-hóa&quot;&gt;Ứng dụng trong Tối ưu hóa&lt;/h2&gt;

&lt;h3 id=&quot;1-kích-thước-bước-nhảy-của-gradient-descent&quot;&gt;1. Kích thước Bước nhảy của Gradient Descent&lt;/h3&gt;

&lt;p&gt;Cận trên bậc hai trực tiếp xác định &lt;strong&gt;kích thước bước nhảy an toàn tối đa&lt;/strong&gt; cho gradient descent. Nếu chúng ta sử dụng kích thước bước \(\alpha \le \frac{1}{L}\), thì:&lt;/p&gt;

\[f(x - \alpha \nabla f(x)) \le f(x) - \alpha \|\nabla f(x)\|^2 + \frac{L\alpha^2}{2}\|\nabla f(x)\|^2\]

&lt;p&gt;Khi \(\alpha \le \frac{1}{L}\), vế phải đơn giản hóa thành:
\(f(x - \alpha \nabla f(x)) \le f(x) - \frac{\alpha}{2}\|\nabla f(x)\|^2\)&lt;/p&gt;

&lt;p&gt;Điều này đảm bảo &lt;strong&gt;giảm đủ&lt;/strong&gt; tại mỗi lần lặp.&lt;/p&gt;

&lt;h3 id=&quot;2-phân-tích-tốc-độ-hội-tụ&quot;&gt;2. Phân tích Tốc độ Hội tụ&lt;/h3&gt;

&lt;p&gt;Đối với gradient descent với kích thước bước \(\alpha = \frac{1}{L}\), cận trên bậc hai cho phép chúng ta chứng minh:&lt;/p&gt;

\[f(x_{k+1}) - f^* \le \left(1 - \frac{\mu}{L}\right)(f(x_k) - f^*)\]

&lt;p&gt;trong đó \(\mu\) là tham số lồi mạnh. Điều này cho &lt;strong&gt;hội tụ tuyến tính&lt;/strong&gt; với tốc độ \(\left(1 - \frac{\mu}{L}\right)\).&lt;/p&gt;

&lt;h3 id=&quot;3-phương-pháp-gradient-gần-kề&quot;&gt;3. Phương pháp Gradient Gần kề&lt;/h3&gt;

&lt;p&gt;Trong tối ưu hóa tổng hợp \(\min_x f(x) + g(x)\) với \(f\) trơn và \(g\) không trơn, cận trên bậc hai của \(f\) dẫn đến cập nhật gradient gần kề:&lt;/p&gt;

\[x_{k+1} = \text{prox}_{\alpha g}\left(x_k - \alpha \nabla f(x_k)\right)\]

&lt;p&gt;trong đó \(\alpha \le \frac{1}{L}\) đảm bảo hội tụ.&lt;/p&gt;

&lt;h3 id=&quot;4-phương-pháp-tăng-tốc&quot;&gt;4. Phương pháp Tăng tốc&lt;/h3&gt;

&lt;p&gt;Các phương pháp tiên tiến như &lt;strong&gt;gradient tăng tốc Nesterov&lt;/strong&gt; và &lt;strong&gt;FISTA&lt;/strong&gt; cũng dựa vào cận trên bậc hai để đạt được tốc độ hội tụ tối ưu \(O(1/k^2)\) cho các hàm lồi trơn.&lt;/p&gt;

&lt;h2 id=&quot;những-điểm-chính&quot;&gt;Những Điểm Chính&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tính chất Cơ bản&lt;/strong&gt;: Cận trên bậc hai là nền tảng của lý thuyết tối ưu hóa lồi trơn.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Thiết kế Thuật toán&lt;/strong&gt;: Nó cung cấp cơ sở lý thuyết để chọn kích thước bước trong các phương pháp dựa trên gradient.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Phân tích Hội tụ&lt;/strong&gt;: Nó cho phép chứng minh nghiêm ngặt tốc độ hội tụ của các thuật toán tối ưu hóa.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tác động Thực tế&lt;/strong&gt;: Hiểu biết về \(L\) giúp các nhà thực hành điều chỉnh thuật toán hiệu quả.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Trực giác Hình học&lt;/strong&gt;: Nó hình thức hóa ý tưởng rằng các hàm lồi trơn không “cong quá mức” - chúng được chặn trên bởi các parabola.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;trực-quan-tương-tác&quot;&gt;Trực quan Tương tác&lt;/h2&gt;

&lt;p&gt;Sơ đồ sau minh họa tính chất cận trên bậc hai:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      f(y)
        |
        |     Cận Trên Bậc Hai
        |    f(x) + ∇f(x)ᵀ(y-x) + (L/2)||y-x||²
        |   /
        |  /
        | /     Hàm thực f(y)
        |/     /
       /|     /
      / |    /
     /  |   /    Xấp xỉ Tuyến tính
    /   |  /     f(x) + ∇f(x)ᵀ(y-x)
   /    | /
  /     |/
 /      x        y
/       |         →
        |
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Những Quan sát Chính&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Xấp xỉ tuyến tính&lt;/strong&gt; (đường tiếp tuyến) nằm dưới \(f(y)\) do tính lồi&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cận trên bậc hai&lt;/strong&gt; nằm trên \(f(y)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hàm thực&lt;/strong&gt; \(f(y)\) được kẹp giữa hai cận này&lt;/li&gt;
  &lt;li&gt;Khoảng cách giữa các cận phụ thuộc vào \(L\) (hằng số Lipschitz) và \(\|y-x\|^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cân-nhắc-tính-toán&quot;&gt;Cân nhắc Tính toán&lt;/h2&gt;

&lt;h3 id=&quot;ước-lượng-hằng-số-lipschitz&quot;&gt;Ước lượng Hằng số Lipschitz&lt;/h3&gt;

&lt;p&gt;Trong thực tế, việc tìm hằng số Lipschitz chính xác \(L\) có thể khó khăn. Các phương pháp phổ biến:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Phân tích Lý thuyết&lt;/strong&gt;: Đối với các lớp hàm cụ thể (bậc hai, logistic, v.v.)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phương pháp Phổ&lt;/strong&gt;: \(L = \lambda_{max}(\nabla^2 f)\) khi có Hessian&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phương pháp Thích ứng&lt;/strong&gt;: Bắt đầu với ước lượng và điều chỉnh dựa trên điều kiện giảm đủ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tìm kiếm Đường&lt;/strong&gt;: Sử dụng backtracking để tìm kích thước bước phù hợp&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;triển-khai-thuật-toán-thực-tế&quot;&gt;Triển khai Thuật toán Thực tế&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient_descent_with_lipschitz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_estimate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Gradient descent với ước lượng hằng số Lipschitz thích ứng
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_estimate&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;grad_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Thử bước với ước lượng L hiện tại
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x_new&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Kiểm tra điều kiện giảm đủ
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_new&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Chấp nhận bước
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Tăng ước lượng L và thử lại
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
            
        &lt;span class=&quot;c1&quot;&gt;# Tùy chọn: giảm L nếu bước quá bảo thủ
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;
            
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Phương pháp thích ứng này đảm bảo hội tụ trong khi tự động điều chỉnh ước lượng hằng số Lipschitz.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-02 Cách chọn kích thước bước</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_02_how_to_choose_step_sizes/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_02_how_to_choose_step_sizes</id>
   <content type="html">&lt;p&gt;Khi thực hiện gradient descent, &lt;strong&gt;kích thước bước&lt;/strong&gt; quyết định cách biến \(x\) được cập nhật và ảnh hưởng đến tốc độ và sự thành công trong việc tìm giá trị tối ưu. Phần này giới thiệu ba phương pháp chính để chọn kích thước bước nhằm giúp gradient descent tìm được tối ưu nhanh hơn:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Kích thước bước cố định&lt;/li&gt;
  &lt;li&gt;Tìm kiếm đường lùi&lt;/li&gt;
  &lt;li&gt;Tìm kiếm đường chính xác&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>06-02-03 Tìm kiếm đường chính xác</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_02_03_exact_line_search/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_02_03_exact_line_search</id>
   <content type="html">&lt;p&gt;Một cách khác để thích ứng kích thước bước trong gradient descent là &lt;strong&gt;tìm kiếm đường chính xác&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;tìm-kiếm-đường-chính-xác-là-gì&quot;&gt;Tìm kiếm Đường chính xác là gì?&lt;/h3&gt;
&lt;p&gt;Trong tìm kiếm đường chính xác, chúng ta di chuyển theo hướng của gradient âm và chọn kích thước bước tốt nhất có thể.&lt;/p&gt;

&lt;p&gt;Đối với biểu thức sau, nếu \(s &amp;gt; 0\), bước tiếp theo \(x - s \nabla f(x)\) di chuyển ra khỏi vị trí hiện tại. Bằng cách thay đổi \(s\), chúng ta tìm kích thước bước \(t\) làm giảm thiểu \(f\):&lt;/p&gt;

&lt;blockquote&gt;
\[t = \arg\min_{s \ge 0} f(x - s \nabla f(x))\]
&lt;/blockquote&gt;

&lt;p&gt;Tìm kiếm đường chính xác hiệu quả cho các bài toán tối ưu hóa một biến, nhưng đối với các bài toán nhiều biến, việc tìm kiếm toàn diện kích thước bước tối ưu thường không thực tế. Trong thực tế, tìm kiếm lùi hiệu quả hơn và được sử dụng phổ biến hơn.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-02-02 Tìm kiếm đường lùi</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_02_02_backtracking_line_search/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_02_02_backtracking_line_search</id>
   <content type="html">&lt;p&gt;Quy tắc cập nhật cơ bản là:
\(x_{k+1} = x_k - t_k \nabla f(x_k),\)
trong đó \(x_k\) là vector tham số tại lần lặp \(k\), \(\nabla f(x_k)\) là gradient, và \(t_k &amp;gt; 0\) là kích thước bước (tốc độ học).&lt;/p&gt;

&lt;p&gt;Nếu sử dụng kích thước bước cố định trong gradient descent, tốc độ hội tụ luôn giống nhau, điều này có thể gây vấn đề trong các vùng điều kiện xấu (nơi cực tiểu bị bỏ lỡ hoặc tiến độ chậm). Để giải quyết điều này, kích thước bước có thể được chọn một cách thích ứng để phù hợp với độ cong của hàm. Một phương pháp như vậy là &lt;strong&gt;tìm kiếm đường lùi&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;tìm-kiếm-đường-lùi-là-gì&quot;&gt;Tìm kiếm Đường lùi là gì?&lt;/h3&gt;
&lt;p&gt;Phương pháp này thử một bước từ vị trí hiện tại, và nếu bước quá lớn, nó sẽ lùi lại. Hình dưới đây cho thấy cách tìm kiếm đường lùi xác định kích thước bước.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_02_02_Backtracking_Line_Search.png&quot; alt=&quot;backtrackinglinesearch1&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] Tìm kiếm Đường lùi [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Các phương pháp tìm kiếm đường động chọn \(t_k\) để đảm bảo tiến độ đủ, thường bằng cách giảm thiểu \(f\) dọc theo hướng tìm kiếm \(d_k = -\nabla f(x_k)\) (gradient âm cho giảm).
Tìm kiếm đường chính xác tìm \(t_k = \arg\min_{t &amp;gt; 0} f(x_k + t d_k)\), nhưng điều này tốn kém về tính toán cho \(f\) không phải bậc hai. Tìm kiếm đường không chính xác xấp xỉ điều này một cách hiệu quả, và tìm kiếm đường lùi là một phương pháp không chính xác phổ biến do tính đơn giản và đảm bảo của nó.&lt;/p&gt;

&lt;p&gt;Trong hàm lồi \(f\), vùng tìm kiếm bị giới hạn trong một đường thẳng. Đường thẳng dưới là một bước từ vị trí hiện tại \(x\) theo hướng giảm. Nếu \(f\) luôn ở trên đường thẳng, rất khó để đánh giá liệu bước có quá lớn hay phù hợp. Trong tìm kiếm đường lùi, đường thẳng trên được sử dụng, đây là một bước theo hướng giảm được tỉ lệ bởi \(t\). Nếu \(f(x + t \Delta x)\) ở trên đường thẳng, bước quá lớn; nếu ở dưới, bước phù hợp.&lt;/p&gt;

&lt;p&gt;Nếu bước quá lớn, \(t\) được giảm cho đến khi \(f\) rơi xuống dưới đường thẳng. \(t\) cuối cùng nằm trong khoảng \(0 \le t \le t_0\).&lt;/p&gt;

&lt;h3 id=&quot;thuật-toán-tìm-kiếm-đường-lùi&quot;&gt;Thuật toán Tìm kiếm Đường lùi&lt;/h3&gt;

&lt;p&gt;Tóm tắt như sau (với \(\Delta x = - \nabla f(x)\)):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Khởi tạo tham số (\(0 &amp;lt; \beta &amp;lt; 1\), \(0 &amp;lt; t \le 1/2\)).&lt;/li&gt;
  &lt;li&gt;Đối với mỗi lần lặp, đặt \(t = t_{init}\) (\(t_{init} = 1\)).&lt;/li&gt;
  &lt;li&gt;Trong khi \(f(x - t \nabla f(x)) &amp;gt; f(x) - t \|\nabla f(x)\|_2^2\), đặt \(t = \beta t\).&lt;/li&gt;
  &lt;li&gt;Cập nhật \(x^+ = x - t \nabla f(x)\).&lt;/li&gt;
  &lt;li&gt;Nếu tiêu chuẩn dừng chưa được đáp ứng, lặp lại từ bước 2.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Tìm kiếm đường lùi đơn giản và hiệu quả. Tham số \(t\) xác định hướng, và \(\beta\) xác định mức độ lùi lại. Thường \(t = 1/2\) và \(\beta\) được chọn gần 1.&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-tìm-kiếm-đường-lùi&quot;&gt;Ví dụ Tìm kiếm Đường lùi&lt;/h3&gt;
&lt;p&gt;Với kích thước bước thích ứng, sự hội tụ nhanh hơn nhiều so với kích thước bước cố định (ví dụ: 12 bước so với 100 bước cho cùng một bài toán). Bao gồm các bước lùi, tổng sự hội tụ đạt được trong khoảng 40 bước.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_02_02_Convergence.png&quot; alt=&quot;backtrackinglinesearch1&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình2] Hội tụ [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;trực-giác-về-tìm-kiếm-đường-lùi&quot;&gt;Trực giác về Tìm kiếm Đường lùi&lt;/h3&gt;
&lt;p&gt;Một xấp xỉ bậc hai cho \(f\) là:&lt;/p&gt;
&lt;blockquote&gt;
\[f(y) \approx f(x) + \nabla f(x)^T(y-x) + \frac{1}{2t} \|y - x\|_2^2\]
&lt;/blockquote&gt;

&lt;p&gt;Đối với \(y = x - t \nabla f(x)\):&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x - t \nabla f(x)) &amp;amp;\approx f(x) - t \|\nabla f(x)\|_2^2 + \frac{1}{2}t \|\nabla f(x)\|_2^2
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>06-02-01 Kích thước bước cố định</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_02_01_fixed_step_size/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_02_01_fixed_step_size</id>
   <content type="html">&lt;p&gt;Cách đơn giản nhất để chọn kích thước bước trong gradient descent là sử dụng một giá trị cố định cho tất cả các lần lặp: \(t_k = t\) với \(k = 1, 2, 3, ...\). Tuy nhiên, sự hội tụ và hành vi phụ thuộc rất nhiều vào việc lựa chọn \(t\).&lt;/p&gt;

&lt;p&gt;Ví dụ, trong hình dưới đây, gradient descent được áp dụng cho \(f(x) = (10 x_1^2 + x_2^2) / 2\) với các kích thước bước khác nhau:&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_02_01_gradientdescent4.png&quot; alt=&quot;gradientdescent4&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Các kịch bản kích thước bước [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Trong trường hợp A, kích thước bước \(t\) quá lớn, gây ra phân kỳ sau 8 bước. Không thể đạt được cực tiểu.&lt;/li&gt;
  &lt;li&gt;Trong trường hợp B, kích thước bước \(t\) quá nhỏ, vì vậy sự hội tụ rất chậm và cực tiểu không được đạt được ngay cả sau 100 bước.&lt;/li&gt;
  &lt;li&gt;Trong trường hợp C, kích thước bước là “phù hợp”, và sự hội tụ đạt được trong khoảng 40 bước. (Cách tìm giá trị “phù hợp” này được thảo luận sau trong chương này.)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>06-01 Gradient Descent</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_01_gradient_descent/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_01_gradient_descent</id>
   <content type="html">&lt;p&gt;Gradient descent là thuật toán đơn giản nhất để giải quyết các bài toán tối ưu hóa lồi và khả vi không ràng buộc.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\min_x f(x),\)
trong đó \(f\) khả vi và \(dom(f) = \mathbb{R}^n\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Giá trị tối ưu là \(f^* = \min_x f(x)\), và điểm tối ưu là \(x^*\).&lt;/p&gt;

&lt;h2 id=&quot;tại-sao-gradient-descent-quan-trọng-trong-khoa-học-dữ-liệu&quot;&gt;Tại sao Gradient Descent quan trọng trong Khoa học Dữ liệu&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Gradient descent là công cụ chủ lực của machine learning!&lt;/strong&gt; Đây là thuật toán đằng sau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Huấn luyện mạng nơ-ron&lt;/strong&gt;: Backpropagation sử dụng gradient descent để cập nhật trọng số&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hồi quy tuyến tính&lt;/strong&gt;: Tìm các hệ số tối ưu để giảm thiểu MSE&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hồi quy logistic&lt;/strong&gt;: Tối ưu hóa tham số cho phân loại&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deep learning&lt;/strong&gt;: Huấn luyện các mô hình phức tạp với hàng triệu tham số&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hệ thống gợi ý&lt;/strong&gt;: Học sở thích người dùng và đặc trưng sản phẩm&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Hiểu biết quan trọng&lt;/strong&gt;: Mỗi khi bạn thấy “training” hoặc “learning” trong ML, gradient descent (hoặc các biến thể của nó) có khả năng được sử dụng!&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent-cho-hàm-một-biến&quot;&gt;Gradient Descent cho Hàm Một Biến&lt;/h2&gt;

&lt;p&gt;Đối với hàm một biến \(f: \mathbb{R} \to \mathbb{R}\), gradient descent được đơn giản hóa đáng kể. Gradient trở thành đạo hàm, và quy tắc cập nhật trở thành:&lt;/p&gt;

&lt;blockquote&gt;
\[x^{(k)} = x^{(k-1)} - t f&apos;(x^{(k-1)}), \quad k = 1, 2, 3, ...\]
&lt;/blockquote&gt;

&lt;p&gt;trong đó \(f&apos;(x)\) là đạo hàm của \(f\) tại điểm \(x\).&lt;/p&gt;

&lt;h3 id=&quot;giải-thích-hình-học&quot;&gt;Giải thích Hình học&lt;/h3&gt;

&lt;p&gt;Trong trường hợp hàm một biến, đạo hàm \(f&apos;(x)\) biểu thị độ dốc của đường tiếp tuyến tại điểm \(x\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Nếu \(f&apos;(x) &amp;gt; 0\), hàm số đang tăng, vì vậy chúng ta di chuyển sang trái (trừ đi một giá trị dương)&lt;/li&gt;
  &lt;li&gt;Nếu \(f&apos;(x) &amp;lt; 0\), hàm số đang giảm, vì vậy chúng ta di chuyển sang phải (trừ đi một giá trị âm)&lt;/li&gt;
  &lt;li&gt;Nếu \(f&apos;(x) = 0\), chúng ta đã đạt đến điểm tới hạn (cực tiểu tiềm năng)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tốc-độ-học-t&quot;&gt;Tốc độ học \(t\)&lt;/h3&gt;

&lt;p&gt;Tốc độ học \(t\) (còn gọi là kích thước bước) là một siêu tham số quan trọng có thể được thiết lập bởi người thiết kế thuật toán. Nó kiểm soát chúng ta thực hiện các bước lớn như thế nào theo hướng của gradient âm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tác động của Tốc độ Học:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Quá nhỏ (\(t \ll 1\))&lt;/strong&gt;: Thuật toán sẽ cập nhật rất chậm, yêu cầu nhiều lần lặp để hội tụ đến nghiệm tối ưu. Mặc dù điều này đảm bảo tính ổn định, nhưng có thể tốn kém về mặt tính toán.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Quá lớn (\(t \gg 1\))&lt;/strong&gt;: Thuật toán có thể vượt quá cực tiểu và có khả năng phân kỳ, dao động xung quanh điểm tối ưu hoặc thậm chí di chuyển ra khỏi nó.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vừa phải&lt;/strong&gt;: Thuật toán hội tụ nhanh chóng và mượt mà đến nghiệm tối ưu.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Các chiến lược phổ biến để chọn tốc độ học:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Kích thước bước cố định&lt;/strong&gt;: Sử dụng một giá trị không đổi trong suốt quá trình tối ưu hóa&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tìm kiếm đường chính xác&lt;/strong&gt;: Tại mỗi lần lặp, chọn \(t\) để giảm thiểu \(f(x^{(k-1)} - t\nabla f(x^{(k-1)}))\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tìm kiếm đường lùi&lt;/strong&gt;: Bắt đầu với kích thước bước lớn và giảm dần cho đến khi đạt được sự giảm đủ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phương pháp thích ứng&lt;/strong&gt;: Điều chỉnh tốc độ học dựa trên tiến độ tối ưu hóa (ví dụ: Adam, RMSprop)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;ví-dụ-hàm-bậc-hai&quot;&gt;Ví dụ: Hàm Bậc Hai&lt;/h3&gt;

&lt;p&gt;Xem xét hàm bậc hai \(f(x) = \frac{1}{2}(x - 2)^2 + 1\) với đạo hàm \(f&apos;(x) = x - 2\).&lt;/p&gt;

&lt;p&gt;Cập nhật gradient descent trở thành:&lt;/p&gt;
&lt;blockquote&gt;
\[x^{(k)} = x^{(k-1)} - t(x^{(k-1)} - 2)\]
&lt;/blockquote&gt;

&lt;p&gt;Bắt đầu từ \(x^{(0)} = 0\) với kích thước bước \(t = 0.1\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(x^{(1)} = 0 - 0.1(0 - 2) = 0.2 \\\) 
\(x^{(2)} = 0.2 - 0.1(0.2 - 2) = 0.38\)
\(x^{(3)} = 0.38 - 0.1(0.38 - 2) = 0.542\)
…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Dãy số hội tụ về \(x^* = 2\), đây là cực tiểu toàn cục.&lt;/p&gt;

&lt;h3 id=&quot;lựa-chọn-kích-thước-bước&quot;&gt;Lựa chọn Kích thước Bước&lt;/h3&gt;

&lt;p&gt;Việc lựa chọn kích thước bước \(t\) là rất quan trọng:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Quá nhỏ&lt;/strong&gt;: Hội tụ rất chậm&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Quá lớn&lt;/strong&gt;: Thuật toán có thể vượt quá và phân kỳ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tối ưu&lt;/strong&gt;: Đối với hàm bậc hai \(f(x) = \frac{1}{2}ax^2 + bx + c\) với \(a &amp;gt; 0\), kích thước bước tối ưu là \(t = \frac{1}{a}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;trực-quan-hóa-tương-tác&quot;&gt;Trực quan Hóa Tương tác&lt;/h3&gt;

&lt;div id=&quot;single-var-gradient-descent&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
        &lt;label for=&quot;step-size-slider&quot;&gt;Kích thước Bước (t): &lt;span id=&quot;step-size-value&quot;&gt;0.1&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
        &lt;input type=&quot;range&quot; id=&quot;step-size-slider&quot; min=&quot;0.01&quot; max=&quot;0.5&quot; step=&quot;0.01&quot; value=&quot;0.1&quot; style=&quot;width: 300px;&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
        &lt;label for=&quot;start-point-slider&quot;&gt;Điểm Bắt đầu: &lt;span id=&quot;start-point-value&quot;&gt;-3&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
        &lt;input type=&quot;range&quot; id=&quot;start-point-slider&quot; min=&quot;-5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;-3&quot; style=&quot;width: 300px;&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
        &lt;button id=&quot;start-animation&quot;&gt;Bắt đầu Animation&lt;/button&gt;
        &lt;button id=&quot;reset-animation&quot;&gt;Reset&lt;/button&gt;
        &lt;button id=&quot;step-once&quot;&gt;Một Bước&lt;/button&gt;
    &lt;/div&gt;
    
    &lt;canvas id=&quot;gradient-canvas&quot; width=&quot;600&quot; height=&quot;400&quot; style=&quot;border: 1px solid #ccc; display: block; margin: 0 auto;&quot;&gt;&lt;/canvas&gt;
    
    &lt;div id=&quot;iteration-info&quot; style=&quot;text-align: center; margin-top: 10px; font-family: monospace;&quot;&gt;
Lần lặp: 0, x = -3.000, f(x) = 13.500, f&apos;(x) = -5.000
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
class SingleVarGradientDescent {
    constructor() {
        this.canvas = document.getElementById(&apos;gradient-canvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.stepSizeSlider = document.getElementById(&apos;step-size-slider&apos;);
        this.startPointSlider = document.getElementById(&apos;start-point-slider&apos;);
        this.stepSizeValue = document.getElementById(&apos;step-size-value&apos;);
        this.startPointValue = document.getElementById(&apos;start-point-value&apos;);
        this.iterationInfo = document.getElementById(&apos;iteration-info&apos;);
        
        // Animation state
        this.isAnimating = false;
        this.currentX = -3;
        this.iteration = 0;
        this.history = [];
        this.animationId = null;
        
        // Function parameters: f(x) = 0.5 * (x - 2)^2 + 1
        this.a = 0.5;
        this.b = 2;
        this.c = 1;
        
        this.setupEventListeners();
        this.reset();
    }
    
    setupEventListeners() {
        this.stepSizeSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.stepSizeValue.textContent = e.target.value;
        });
        
        this.startPointSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.startPointValue.textContent = e.target.value;
            if (!this.isAnimating) {
                this.reset();
            }
        });
        
        document.getElementById(&apos;start-animation&apos;).addEventListener(&apos;click&apos;, () =&gt; {
            this.startAnimation();
        });
        
        document.getElementById(&apos;reset-animation&apos;).addEventListener(&apos;click&apos;, () =&gt; {
            this.reset();
        });
        
        document.getElementById(&apos;step-once&apos;).addEventListener(&apos;click&apos;, () =&gt; {
            this.singleStep();
        });
    }
    
    // Function: f(x) = 0.5 * (x - 2)^2 + 1
    f(x) {
        return this.a * Math.pow(x - this.b, 2) + this.c;
    }
    
    // Derivative: f&apos;(x) = (x - 2)
    fprime(x) {
        return 2 * this.a * (x - this.b);
    }
    
    // Convert x coordinate to canvas coordinate
    xToCanvas(x) {
        const xMin = -5, xMax = 5;
        return (x - xMin) / (xMax - xMin) * this.canvas.width;
    }
    
    // Convert y coordinate to canvas coordinate
    yToCanvas(y) {
        const yMin = 0, yMax = 15;
        return this.canvas.height - (y - yMin) / (yMax - yMin) * this.canvas.height;
    }
    
    // Convert canvas x to actual x
    canvasToX(canvasX) {
        const xMin = -5, xMax = 5;
        return xMin + (canvasX / this.canvas.width) * (xMax - xMin);
    }
    
    drawFunction() {
        this.ctx.strokeStyle = &apos;#2196F3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let canvasX = 0; canvasX &lt;= this.canvas.width; canvasX += 2) {
            const x = this.canvasToX(canvasX);
            const y = this.f(x);
            const canvasY = this.yToCanvas(y);
            
            if (canvasX === 0) {
                this.ctx.moveTo(canvasX, canvasY);
            } else {
                this.ctx.lineTo(canvasX, canvasY);
            }
        }
        this.ctx.stroke();
    }
    
    drawAxes() {
        this.ctx.strokeStyle = &apos;#666&apos;;
        this.ctx.lineWidth = 1;
        
        // X-axis
        const yZero = this.yToCanvas(0);
        this.ctx.beginPath();
        this.ctx.moveTo(0, yZero);
        this.ctx.lineTo(this.canvas.width, yZero);
        this.ctx.stroke();
        
        // Y-axis
        const xZero = this.xToCanvas(0);
        this.ctx.beginPath();
        this.ctx.moveTo(xZero, 0);
        this.ctx.lineTo(xZero, this.canvas.height);
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#666&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        
        // X-axis labels
        for (let x = -4; x &lt;= 4; x += 2) {
            const canvasX = this.xToCanvas(x);
            this.ctx.fillText(x.toString(), canvasX, yZero + 15);
        }
        
        // Y-axis labels
        this.ctx.textAlign = &apos;right&apos;;
        for (let y = 2; y &lt;= 14; y += 2) {
            const canvasY = this.yToCanvas(y);
            this.ctx.fillText(y.toString(), xZero - 5, canvasY + 4);
        }
    }
    
    drawCurrentPoint() {
        const canvasX = this.xToCanvas(this.currentX);
        const canvasY = this.yToCanvas(this.f(this.currentX));
        
        // Current point
        this.ctx.fillStyle = &apos;#F44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(canvasX, canvasY, 6, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Tangent line
        const derivative = this.fprime(this.currentX);
        const tangentLength = 1;
        const x1 = this.currentX - tangentLength;
        const x2 = this.currentX + tangentLength;
        const y1 = this.f(this.currentX) + derivative * (x1 - this.currentX);
        const y2 = this.f(this.currentX) + derivative * (x2 - this.currentX);
        
        this.ctx.strokeStyle = &apos;#FF9800&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.moveTo(this.xToCanvas(x1), this.yToCanvas(y1));
        this.ctx.lineTo(this.xToCanvas(x2), this.yToCanvas(y2));
        this.ctx.stroke();
    }
    
    drawHistory() {
        if (this.history.length &lt; 2) return;
        
        this.ctx.strokeStyle = &apos;#4CAF50&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.setLineDash([5, 5]);
        this.ctx.beginPath();
        
        for (let i = 0; i &lt; this.history.length; i++) {
            const x = this.history[i];
            const canvasX = this.xToCanvas(x);
            const canvasY = this.yToCanvas(this.f(x));
            
            if (i === 0) {
                this.ctx.moveTo(canvasX, canvasY);
            } else {
                this.ctx.lineTo(canvasX, canvasY);
            }
        }
        this.ctx.stroke();
        this.ctx.setLineDash([]);
        
        // Draw history points
        this.ctx.fillStyle = &apos;#4CAF50&apos;;
        for (let i = 0; i &lt; this.history.length - 1; i++) {
            const x = this.history[i];
            const canvasX = this.xToCanvas(x);
            const canvasY = this.yToCanvas(this.f(x));
            
            this.ctx.beginPath();
            this.ctx.arc(canvasX, canvasY, 3, 0, 2 * Math.PI);
            this.ctx.fill();
        }
    }
    
    draw() {
        // Clear canvas
        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
        
        // Draw components
        this.drawAxes();
        this.drawFunction();
        this.drawHistory();
        this.drawCurrentPoint();
        
        // Update iteration info
        this.iterationInfo.textContent = 
            `Lần lặp: ${this.iteration}, x = ${this.currentX.toFixed(3)}, ` +
            `f(x) = ${this.f(this.currentX).toFixed(3)}, f&apos;(x) = ${this.fprime(this.currentX).toFixed(3)}`;
    }
    
    singleStep() {
        if (Math.abs(this.fprime(this.currentX)) &lt; 1e-6) {
            return; // Already at minimum
        }
        
        const stepSize = parseFloat(this.stepSizeSlider.value);
        const newX = this.currentX - stepSize * this.fprime(this.currentX);
        
        this.history.push(this.currentX);
        this.currentX = newX;
        this.iteration++;
        
        this.draw();
    }
    
    startAnimation() {
        if (this.isAnimating) {
            this.stopAnimation();
            return;
        }
        
        this.isAnimating = true;
        document.getElementById(&apos;start-animation&apos;).textContent = &apos;Dừng Animation&apos;;
        
        const animate = () =&gt; {
            if (!this.isAnimating) return;
            
            if (Math.abs(this.fprime(this.currentX)) &gt; 1e-6 &amp;&amp; this.iteration &lt; 100) {
                this.singleStep();
                this.animationId = setTimeout(animate, 500);
            } else {
                this.stopAnimation();
            }
        };
        
        animate();
    }
    
    stopAnimation() {
        this.isAnimating = false;
        document.getElementById(&apos;start-animation&apos;).textContent = &apos;Bắt đầu Animation&apos;;
        if (this.animationId) {
            clearTimeout(this.animationId);
            this.animationId = null;
        }
    }
    
    reset() {
        this.stopAnimation();
        this.currentX = parseFloat(this.startPointSlider.value);
        this.iteration = 0;
        this.history = [];
        this.draw();
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new SingleVarGradientDescent();
});
&lt;/script&gt;

&lt;h2 id=&quot;phương-pháp-gradient-descent-cho-hàm-nhiều-biến&quot;&gt;Phương pháp Gradient Descent cho Hàm Nhiều Biến&lt;/h2&gt;

&lt;p&gt;Gradient descent bắt đầu từ một điểm ban đầu \(x^{(0)} \in \mathbb{R}^n\) và cập nhật lặp đi lặp lại như sau cho đến khi đáp ứng tiêu chuẩn dừng:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(x^{(k)} = x^{(k-1)} - t \nabla f(x^{(k-1)}), \quad k = 1, 2, 3, ...\), \(t &amp;gt; 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Mã giả:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Cho điểm bắt đầu&lt;/strong&gt; \(x \in dom(f)\) &lt;br /&gt;
&lt;strong&gt;Lặp lại&lt;/strong&gt;  &lt;br /&gt;&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;Xác định hướng giảm \(\Delta x = -\nabla f(x)\). &lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;Tìm kiếm đường: chọn kích thước bước \(t &amp;gt; 0\). &lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;Cập nhật \(x = x + t \Delta x\). &lt;br /&gt;
&lt;strong&gt;Cho đến khi&lt;/strong&gt; tiêu chuẩn dừng được thỏa mãn &lt;br /&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;ví-dụ&quot;&gt;Ví dụ&lt;/h3&gt;

&lt;p&gt;Hình dưới đây cho thấy gradient descent trên một hàm lồi. Trong trường hợp này, cực tiểu cục bộ cũng là cực tiểu toàn cục.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_01_gradientdescent1.png&quot; alt=&quot;gradientdescent1&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Gradient descent trong hàm lồi[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Hình tiếp theo cho thấy gradient descent trên một hàm không lồi. Ở đây, điểm ban đầu quyết định cực tiểu cục bộ nào được đạt tới.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_01_gradientdescent2.png&quot; alt=&quot;gradientdescent2&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 2] Gradient descent trong hàm không lồi[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;giải-thích-gradient-descent&quot;&gt;Giải thích Gradient Descent&lt;/h2&gt;
&lt;p&gt;Gradient descent có thể được giải thích là việc chọn điểm tiếp theo bằng cách giảm thiểu một xấp xỉ bậc hai của hàm số.&lt;/p&gt;

&lt;p&gt;Đối với hàm \(f\), khai triển Taylor bậc hai quanh \(x\) là:&lt;/p&gt;
&lt;blockquote&gt;
\[f(y) \approx f(x) + \nabla f(x)^T (y - x) +  \frac{1}{2} \nabla^2 f(x)  \|y - x\|_2^2\]
&lt;/blockquote&gt;

&lt;p&gt;Nếu chúng ta xấp xỉ ma trận Hessian \(\nabla^2 f(x)\) bằng \(\frac{1}{t}I\), thì:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(y) \approx f(x) + \nabla f(x)^T (y - x) +  \frac{1}{2t}  \|y - x\|_2^2\)
trong đó \(t\) là kích thước bước.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Vì vậy, trong gradient descent, hàm số được xấp xỉ bởi một hàm bậc hai có ma trận Hessian với các giá trị riêng bằng nghịch đảo của kích thước bước. Số hạng \(f(x) + \nabla f(x)^T (y - x)\) biểu thị một xấp xỉ tuyến tính của \(f\), và \(\frac{1}{2t}  \|y - x\|_2^2\) đóng vai trò là số hảng gần kề chỉ ra \(y\) gần \(x\) như thế nào.&lt;/p&gt;

&lt;p&gt;Vị trí tiếp theo được chọn là cực tiểu của hàm bậc hai xấp xỉ này. Đặt gradient của \(f(y)\) bằng không để tìm vị trí tiếp theo \(y = x^+\) dẫn đến:&lt;/p&gt;

&lt;blockquote&gt;
\[x^+ = x - t \nabla f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Trong hình minh họa dưới đây, chấm xanh biểu thị vị trí hiện tại \(x\), và chấm đỏ biểu thị vị trí tiếp theo \(y\). Đường cong bên dưới là hàm thực tế \(f\), và đường cong bên trên là xấp xỉ bậc hai của \(f\). Vì vậy, chấm đỏ chỉ ra cực tiểu của xấp xỉ bậc hai.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_01_gradientdescent3.png&quot; alt=&quot;gradientdescent3&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$ \text{[Hình 3] Thuật toán Gradient descent : chấm đỏ là } x^+ \text{ và chấm xanh là } x \text{ [3]} $$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Độ gần kề của vị trí tiếp theo \(y\) đến vị trí hiện tại \(x\) bị ảnh hưởng bởi trọng số của số hạng gần kề \(\frac{1}{2t}\). Một \(t\) nhỏ hơn dẫn đến trọng số lớn hơn cho số hạng gần kề, dẫn đến các bước nhỏ hơn. Quá trình này có thể được biểu thị như:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^+ = \underset{y}{\arg \min} \ f(x) + \nabla f(x)^T (y - x) + \frac{1}{2t} \parallel y - x \parallel_2^2
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>06-01-05 Bài tập: Hiểu về Kích thước Bước và Độ cong</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_01_05_hessian_exercises/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_01_05_hessian_exercises</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;h2 id=&quot;bài-tập-1-suy-luận-xấp-xỉ-bậc-hai&quot;&gt;Bài tập 1: Suy luận Xấp xỉ Bậc hai&lt;/h2&gt;

&lt;p&gt;Xét xấp xỉ bậc hai được sử dụng trong gradient descent:
\(f(y) \approx f(x) + \nabla f(x)^T (y - x) + \frac{1}{2t} \|y - x\|_2^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần A&lt;/strong&gt;: Chứng minh rằng tối thiểu hóa xấp xỉ này theo \(y\) cho cập nhật gradient descent \(y = x - t\nabla f(x)\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần B&lt;/strong&gt;: Điều gì xảy ra nếu chúng ta thay đổi hệ số thành \(\frac{\alpha}{2t}\) thay vì \(\frac{1}{2t}\)? Điều này ảnh hưởng như thế nào đến kích thước bước?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần C&lt;/strong&gt;: Diễn giải số hạng \(\frac{1}{2t} \|y - x\|_2^2\) theo hình học. Nó ngăn chặn điều gì?&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;bài-tập-2-kích-thước-bước-và-độ-cong-hàm&quot;&gt;Bài tập 2: Kích thước Bước và Độ cong Hàm&lt;/h2&gt;

&lt;p&gt;Xét hai hàm bậc hai:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[f_1(x_1, x_2) = \frac{1}{2}(x_1^2 + x_2^2)\]
  &lt;/li&gt;
  &lt;li&gt;
\[f_2(x_1, x_2) = \frac{1}{2}(4x_1^2 + x_2^2)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Phần A&lt;/strong&gt;: Tính ma trận Hessian (ma trận các đạo hàm riêng bậc hai) cho cả hai hàm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần B&lt;/strong&gt;: Nếu chúng ta xấp xỉ cả hai Hessian bằng \(\frac{1}{t}I\), giá trị \(t\) nào cho xấp xỉ tốt nhất cho mỗi hàm?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần C&lt;/strong&gt;: Bắt đầu từ điểm \((2, 2)\), thực hiện 3 lần lặp gradient descent trên cả hai hàm sử dụng kích thước bước tối ưu của bạn. So sánh hành vi hội tụ.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;bài-tập-3-số-điều-kiện-và-hội-tụ&quot;&gt;Bài tập 3: Số Điều kiện và Hội tụ&lt;/h2&gt;

&lt;p&gt;Với hàm \(f(x_1, x_2) = \frac{1}{2}(ax_1^2 + bx_2^2)\) với \(a &amp;gt; b &amp;gt; 0\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần A&lt;/strong&gt;: Số điều kiện \(\kappa = \frac{a}{b}\) là gì? Điều này liên quan như thế nào đến “hình dạng” của hàm?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần B&lt;/strong&gt;: Chứng minh rằng kích thước bước tối ưu cho hội tụ nhanh nhất là \(t^* = \frac{2}{a + b}\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần C&lt;/strong&gt;: So sánh tốc độ hội tụ cho:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\kappa = 1\) (\(a = b = 1\))&lt;/li&gt;
  &lt;li&gt;\(\kappa = 4\) (\(a = 4, b = 1\))&lt;/li&gt;
  &lt;li&gt;\(\kappa = 100\) (\(a = 100, b = 1\))&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Điều gì xảy ra khi số điều kiện tăng?&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;bài-tập-4-kích-thước-bước-theo-tọa-độ&quot;&gt;Bài tập 4: Kích thước Bước theo Tọa độ&lt;/h2&gt;

&lt;p&gt;Thay vì sử dụng cùng kích thước bước cho tất cả tọa độ, xét:
\(x_1^{(k+1)} = x_1^{(k)} - t_1 \frac{\partial f}{\partial x_1}\)
\(x_2^{(k+1)} = x_2^{(k)} - t_2 \frac{\partial f}{\partial x_2}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần A&lt;/strong&gt;: Với \(f(x_1, x_2) = \frac{1}{2}(ax_1^2 + bx_2^2)\), lựa chọn \(t_1, t_2\) nào làm cho mỗi tọa độ hội tụ trong đúng một bước?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần B&lt;/strong&gt;: Điều này liên quan như thế nào đến việc xấp xỉ Hessian bằng ma trận đường chéo thay vì \(\frac{1}{t}I\)?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần C&lt;/strong&gt;: Lập trình cách tiếp cận theo tọa độ này và so sánh với gradient descent chuẩn trên hàm bậc hai điều kiện xấu.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;bài-tập-5-trực-quan-hóa-chất-lượng-xấp-xỉ&quot;&gt;Bài tập 5: Trực quan hóa Chất lượng Xấp xỉ&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Phần A&lt;/strong&gt;: Với hàm \(f(x_1, x_2) = \frac{1}{2}(4x_1^2 + x_2^2)\), vẽ đường đồng mức hàm thực và đường đồng mức của xấp xỉ bậc hai \(f(x) + \nabla f(x)^T (y - x) + \frac{1}{2t} \|y - x\|_2^2\) quanh điểm \(x = (1, 1)\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần B&lt;/strong&gt;: Thử các giá trị \(t\) khác nhau và quan sát cách chất lượng xấp xỉ thay đổi.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần C&lt;/strong&gt;: Giá trị \(t\) nào làm cho đường đồng mức xấp xỉ giống nhất với đường đồng mức hàm thực?&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;bài-tập-6-chiến-lược-chọn-kích-thước-bước&quot;&gt;Bài tập 6: Chiến lược Chọn Kích thước Bước&lt;/h2&gt;

&lt;p&gt;So sánh ba chiến lược chọn kích thước bước trên hàm \(f(x) = \frac{1}{2}x^T A x\) với:
\(A = \begin{bmatrix} 10 &amp;amp; 2 \\ 2 &amp;amp; 1 \end{bmatrix}\)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Bước cố định nhỏ&lt;/strong&gt;: \(t = 0.1\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bước cố định lớn&lt;/strong&gt;: \(t = 0.5\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bước thích ứng&lt;/strong&gt;: \(t = \frac{2}{\lambda_{\max} + \lambda_{\min}}\) với \(\lambda_{\max}, \lambda_{\min}\) là trị riêng lớn nhất và nhỏ nhất của \(A\)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Phần A&lt;/strong&gt;: Tính các trị riêng của \(A\) và xác định kích thước bước thích ứng.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần B&lt;/strong&gt;: Bắt đầu từ \((5, 5)\), chạy gradient descent với mỗi chiến lược trong 20 lần lặp.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần C&lt;/strong&gt;: Vẽ đường cong hội tụ và quỹ đạo. Chiến lược nào hoạt động tốt nhất và tại sao?&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;bài-tập-7-hàm-thực-vs-xấp-xỉ-bậc-hai&quot;&gt;Bài tập 7: Hàm Thực vs Xấp xỉ Bậc hai&lt;/h2&gt;

&lt;p&gt;Xét hàm không bậc hai \(f(x) = e^{x_1} + x_2^2\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần A&lt;/strong&gt;: Tính gradient và Hessian của hàm này.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phần B&lt;/strong&gt;: Tại điểm \(x = (0, 1)\), so sánh:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Một bước gradient descent với kích thước bước \(t = 0.1\)&lt;/li&gt;
  &lt;li&gt;Một bước sử dụng xấp xỉ bậc hai với Hessian thực&lt;/li&gt;
  &lt;li&gt;Một bước sử dụng xấp xỉ bậc hai với \(\frac{1}{t}I\) với \(t = 0.1\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Phần C&lt;/strong&gt;: Xấp xỉ nào cho kết quả gần với hướng tối thiểu thực hơn?&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;bài-tập-lập-trình&quot;&gt;Bài tập Lập trình&lt;/h2&gt;

&lt;h3 id=&quot;bài-tập-8-lập-trình-và-so-sánh&quot;&gt;Bài tập 8: Lập trình và So sánh&lt;/h3&gt;

&lt;p&gt;Lập trình và so sánh hiệu suất của chúng:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;quadratic_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Tính f(x) = 0.5 * x^T A x&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Tính gradient của f(x) = 0.5 * x^T A x&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;standard_gd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Gradient descent chuẩn&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;coordinate_wise_gd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Gradient descent theo tọa độ&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Áp dụng kích thước bước khác nhau cho mỗi tọa độ
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_sizes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Kiểm tra trên các số điều kiện khác nhau
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition_numbers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kappa&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condition_numbers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kappa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Kích thước bước tối ưu cho GD chuẩn
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;eigenvals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eigvals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t_optimal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigenvals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigenvals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Kích thước bước tối ưu theo tọa độ
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;t_coord&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Chạy cả hai phương pháp
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;history_std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;standard_gd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t_optimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;history_coord&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;coordinate_wise_gd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t_coord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Vẽ kết quả
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;semilogy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;quadratic_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history_std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GD Chuẩn&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;semilogy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;quadratic_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history_coord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r--&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GD Theo tọa độ&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Lần lặp&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Giá trị Hàm&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Hội tụ (κ = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kappa&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history_std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history_std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b-o&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GD Chuẩn&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;markersize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history_coord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history_coord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r--s&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GD Theo tọa độ&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;markersize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;x₁&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;x₂&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Quỹ đạo (κ = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kappa&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;equal&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tight_layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;bài-tập-9-trực-quan-hóa-tương-tác&quot;&gt;Bài tập 9: Trực quan hóa Tương tác&lt;/h3&gt;

&lt;p&gt;Tạo một biểu đồ tương tác hiển thị:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Đường đồng mức hàm thực&lt;/li&gt;
  &lt;li&gt;Đường đồng mức xấp xỉ bậc hai&lt;/li&gt;
  &lt;li&gt;Quỹ đạo gradient descent&lt;/li&gt;
  &lt;li&gt;Thanh trượt để điều chỉnh kích thước bước và xem nó ảnh hưởng như thế nào đến hội tụ&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Yêu cầu&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sử dụng matplotlib widgets hoặc plotly cho tính tương tác&lt;/li&gt;
  &lt;li&gt;Hiển thị cả ví dụ điều kiện tốt và điều kiện xấu&lt;/li&gt;
  &lt;li&gt;Hiển thị lỗi xấp xỉ khi kích thước bước thay đổi&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;đề-cương-lời-giải&quot;&gt;Đề cương Lời giải&lt;/h2&gt;

&lt;h3 id=&quot;lời-giải-bài-tập-1&quot;&gt;Lời giải Bài tập 1:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: Lấy \(\frac{\partial}{\partial y}[f(x) + \nabla f(x)^T (y - x) + \frac{1}{2t} \|y - x\|_2^2] = \nabla f(x) + \frac{1}{t}(y-x) = 0\)
Giải: \(y = x - t\nabla f(x)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;: Kích thước bước hiệu quả trở thành \(\frac{t}{\alpha}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;: Số hạng hoạt động như “phạt gần” - nó ngăn không cho thực hiện bước quá xa từ điểm hiện tại&lt;/p&gt;

&lt;h3 id=&quot;lời-giải-bài-tập-2&quot;&gt;Lời giải Bài tập 2:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\nabla^2 f_1 = I\]
  &lt;/li&gt;
  &lt;li&gt;
\[\nabla^2 f_2 = \begin{bmatrix} 4 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{bmatrix}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Với \(f_1\): \(t = 1\)&lt;/li&gt;
  &lt;li&gt;Với \(f_2\): \(t = 0.4\) (tối thiểu hóa \(\|(4-\frac{1}{t})^2 + (1-\frac{1}{t})^2\|\))&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lời-giải-bài-tập-3&quot;&gt;Lời giải Bài tập 3:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: \(\kappa = \frac{a}{b}\) đo lường mức độ “kéo dài” của đường đồng mức ellip&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;B&lt;/strong&gt;: Tối thiểu hóa hệ số hội tụ \(\frac{\kappa-1}{\kappa+1}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C&lt;/strong&gt;: Số điều kiện cao hơn → hội tụ chậm hơn, hành vi dao động nhiều hơn&lt;/p&gt;

&lt;h3 id=&quot;kết-quả-học-tập-chính&quot;&gt;Kết quả Học tập Chính:&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Hiểu biết trực quan&lt;/strong&gt;: Kích thước bước liên quan đến độ cong giả định&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kỹ năng thực tế&lt;/strong&gt;: Cách chọn kích thước bước cho các bài toán khác nhau&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hiểu biết lý thuyết&lt;/strong&gt;: Kết nối giữa tính chất hàm và hành vi tối ưu hóa&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kinh nghiệm lập trình&lt;/strong&gt;: Coding và so sánh các cách tiếp cận khác nhau&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Các bài tập này xây dựng hiểu biết mà không yêu cầu các khái niệm nâng cao như phương pháp Newton, thay vào đó tập trung vào mối quan hệ cơ bản giữa kích thước bước, độ cong và hành vi hội tụ.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-01-05 Tại sao Kích thước Bước lại Quan trọng?</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_01_05_hessian_approximation/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_01_05_hessian_approximation</id>
   <content type="html">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
    displayAlign: &quot;center&quot;
});
&lt;/script&gt;

&lt;p&gt;Trong gradient descent, chọn đúng kích thước bước \(t\) rất quan trọng. Nhưng tại sao? Câu trả lời nằm ở việc hiểu gradient descent thực sự đang làm gì: &lt;strong&gt;nó đang đưa ra một giả định đơn giản về độ cong của hàm số&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;ý-tưởng-cốt-lõi&quot;&gt;Ý tưởng Cốt lõi&lt;/h2&gt;

&lt;p&gt;Khi chúng ta thực hiện gradient descent:&lt;/p&gt;
&lt;blockquote&gt;
\[x^{(k+1)} = x^{(k)} - t \nabla f(x^{(k)})\]
&lt;/blockquote&gt;

&lt;p&gt;Thực ra chúng ta đang giải bài toán này:&lt;/p&gt;
&lt;blockquote&gt;
\[x^{(k+1)} = \arg\min_y \left\{ \nabla f(x^{(k)})^T (y - x^{(k)}) + \frac{1}{2t} \|y - x^{(k)}\|^2 \right\}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Điều này có nghĩa là gì?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Số hạng đầu: “Đi theo hướng dốc nhất”&lt;/li&gt;
  &lt;li&gt;Số hạng thứ hai: “Nhưng đừng đi quá xa khỏi vị trí hiện tại”&lt;/li&gt;
  &lt;li&gt;Tham số \(t\) điều khiển sự cân bằng này&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;kích-thước-bước--tin-tưởng-vào-độ-phẳng&quot;&gt;Kích thước Bước = Tin tưởng vào Độ phẳng&lt;/h2&gt;

&lt;p&gt;Hãy nghĩ về kích thước bước theo cách này:&lt;/p&gt;
&lt;blockquote&gt;
\[t = \frac{1}{\text{bạn nghĩ hàm số cong đến mức nào}}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(t\) lớn&lt;/strong&gt;: “Tôi nghĩ hàm số khá phẳng ở đây” → thực hiện bước lớn&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(t\) nhỏ&lt;/strong&gt;: “Tôi nghĩ hàm số rất cong ở đây” → thực hiện bước nhỏ, cẩn thận&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ví-dụ-đơn-giản&quot;&gt;Ví dụ Đơn giản&lt;/h2&gt;

&lt;p&gt;Xét hai hàm:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Hàm phẳng&lt;/strong&gt;: \(f(x_1, x_2) = \frac{1}{2}(x_1^2 + x_2^2)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hàm dốc&lt;/strong&gt;: \(f(x_1, x_2) = \frac{1}{2}(100x_1^2 + x_2^2)\)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Với hàm phẳng, bạn có thể dùng \(t = 1\) (bước lớn).
Với hàm dốc, bạn cần \(t = 0.01\) (bước nhỏ) để tránh vượt quá mục tiêu.&lt;/p&gt;

&lt;h2 id=&quot;tại-sao-điều-này-hoạt-động&quot;&gt;Tại sao Điều này Hoạt động&lt;/h2&gt;

&lt;p&gt;Hãy xem tại sao điều này cho chúng ta công thức gradient descent.&lt;/p&gt;

&lt;p&gt;Chúng ta muốn tối thiểu hóa:&lt;/p&gt;
&lt;blockquote&gt;
\[\nabla f(x)^T (y - x) + \frac{1}{2t} \|y - x\|^2\]
&lt;/blockquote&gt;

&lt;p&gt;Lấy đạo hàm theo \(y\) và đặt bằng không:&lt;/p&gt;
&lt;blockquote&gt;
\[\nabla f(x) + \frac{1}{t}(y - x) = 0\]
&lt;/blockquote&gt;

&lt;p&gt;Giải theo \(y\):&lt;/p&gt;
&lt;blockquote&gt;
\[y = x - t \nabla f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Đó chính xác là cập nhật gradient descent! Số hạng \(\frac{1}{2t}\) hoạt động như một “lò xo” kéo bạn về phía \(x\), ngăn bạn thực hiện những bước quá lớn.&lt;/p&gt;

&lt;h2 id=&quot;khi-nào-hoạt-động-tốt&quot;&gt;Khi nào Hoạt động Tốt?&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Trường hợp tốt:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hàm có độ “dốc” gần như nhau theo mọi hướng&lt;/li&gt;
  &lt;li&gt;Hàm hình bát như \(f(x_1, x_2) = x_1^2 + x_2^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Trường hợp xấu:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hàm rất dốc theo một hướng nhưng phẳng theo hướng khác&lt;/li&gt;
  &lt;li&gt;Hàm hình “thung lũng” như \(f(x_1, x_2) = 100x_1^2 + x_2^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cách-chọn-kích-thước-bước&quot;&gt;Cách Chọn Kích thước Bước&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Quy tắc thực tế&lt;/strong&gt;: Bắt đầu với \(t = 0.1\) và điều chỉnh:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Nếu gradient descent dao động mạnh → làm \(t\) nhỏ hơn&lt;/li&gt;
  &lt;li&gt;Nếu gradient descent hội tụ rất chậm → làm \(t\) lớn hơn&lt;/li&gt;
  &lt;li&gt;Nếu bạn hiểu rõ hàm số → dùng \(t \approx \frac{2}{\text{hướng dốc nhất + hướng phẳng nhất}}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;trực-quan-hình-ảnh&quot;&gt;Trực quan Hình ảnh&lt;/h2&gt;

&lt;p&gt;Hãy tưởng tượng bạn đang đi xuống một ngọn đồi trong bóng tối với đèn pin:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Kích thước bước lớn&lt;/strong&gt;: “Tôi nghĩ con đường phía trước mượt mà” → thực hiện bước dài (rủi ro: có thể bước vào hố)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kích thước bước nhỏ&lt;/strong&gt;: “Tôi nghĩ con đường phía trước gồ ghề” → thực hiện bước nhỏ (an toàn nhưng chậm)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Gradient descent làm điều tương tự về mặt toán học!&lt;/p&gt;

&lt;h2 id=&quot;bức-tranh-tổng-thể&quot;&gt;Bức tranh Tổng thể&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Gradient descent thực sự làm gì:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Nhìn vào độ dốc (gradient)&lt;/li&gt;
  &lt;li&gt;Giả định hàm số có dạng “bát” xung quanh bạn&lt;/li&gt;
  &lt;li&gt;Thực hiện một bước về phía đáy của cái bát tưởng tượng đó&lt;/li&gt;
  &lt;li&gt;Lặp lại&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Tại sao kích thước bước quan trọng:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Quá lớn → bạn vượt quá mục tiêu và nảy qua nảy lại&lt;/li&gt;
  &lt;li&gt;Quá nhỏ → bạn mất mãi mới đến đích&lt;/li&gt;
  &lt;li&gt;Vừa phải → hội tụ mượt mà, nhanh chóng&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;điểm-mấu-chốt&quot;&gt;Điểm Mấu chốt&lt;/h2&gt;

&lt;p&gt;Kích thước bước không phải ma thuật - nó là &lt;strong&gt;phỏng đoán của bạn về độ cong của hàm số&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(t = 0.01\) có nghĩa là “Tôi nghĩ hàm này rất cong”&lt;/li&gt;
  &lt;li&gt;\(t = 1.0\) có nghĩa là “Tôi nghĩ hàm này khá phẳng”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Phỏng đoán càng chính xác, gradient descent hội tụ càng nhanh!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06 Gradient Descent</title>
   <link href="http://localhost:4000/contents/vi/chapter06/06_00_gradient_descent/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_00_gradient_descent</id>
   <content type="html">&lt;p&gt;Trong chương này, chúng ta sẽ khám phá &lt;strong&gt;Gradient Descent&lt;/strong&gt; (Thuật toán Gradient), một trong những phương pháp cơ bản và quan trọng nhất trong tối ưu hóa.&lt;/p&gt;

&lt;p&gt;Trong các thuật toán tối ưu hóa, việc lựa chọn hướng tìm kiếm và kích thước bước là rất quan trọng đối với tốc độ hội tụ và sự thành công. Gradient descent di chuyển theo hướng của gradient âm. Kích thước bước có thể được cố định hoặc được chọn một cách thích ứng, và chúng ta sẽ thảo luận cả hai cách tiếp cận trong chương này.&lt;/p&gt;

&lt;p&gt;Để gradient descent hội tụ, một số điều kiện tiên quyết phải được đáp ứng. Nếu những điều kiện này được thỏa mãn, chúng ta có thể phân tích gradient descent hội tụ nhanh như thế nào. Nếu tính lồi mạnh được thỏa mãn, sự hội tụ thậm chí còn nhanh hơn, và chúng ta sẽ xem xét tốc độ hội tụ trong những trường hợp như vậy.&lt;/p&gt;

&lt;p&gt;Chúng ta cũng sẽ xem xét các ứng dụng của gradient descent, bao gồm gradient boosting và stochastic gradient descent.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-07 Regularization and Loss Functions</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_07_regularization_and_loss_functions/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_07_regularization_and_loss_functions</id>
   <content type="html">&lt;script src=&quot;../../../public/js/script.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://d3js.org/d3.v7.min.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;introduction-the-overfitting-problem-in-machine-learning&quot;&gt;Introduction: The Overfitting Problem in Machine Learning&lt;/h2&gt;

&lt;p&gt;In machine learning, one of the biggest challenges is &lt;strong&gt;overfitting&lt;/strong&gt; - when a model learns too much detail from training data, leading to poor performance on new data. &lt;strong&gt;Regularization&lt;/strong&gt; is a crucial technique to address this problem.&lt;/p&gt;

&lt;h3 id=&quot;why-do-we-need-regularization&quot;&gt;Why do we need Regularization?&lt;/h3&gt;

&lt;p&gt;Consider the basic linear regression problem:
\(\min_{\mathbf{w}} \frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: When the number of features is large or data is scarce, the model can find solutions with training error = 0 but poor generalization.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Add a &lt;strong&gt;regularization term&lt;/strong&gt; to “penalize” large weights:
\(\min_{\mathbf{w}} \frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2 + \lambda R(\mathbf{w})\)&lt;/p&gt;

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\lambda &amp;gt; 0\) is the &lt;strong&gt;regularization parameter&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;\(R(\mathbf{w})\) is the &lt;strong&gt;regularization function&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ridge-regression-l2-regularization&quot;&gt;Ridge Regression (L2 Regularization)&lt;/h2&gt;

&lt;h3 id=&quot;mathematical-definition&quot;&gt;Mathematical Definition&lt;/h3&gt;

&lt;p&gt;Ridge regression uses the L2 norm as the regularization term:&lt;/p&gt;

\[\min_{\mathbf{w}} \frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2 + \frac{\lambda}{2} \|\mathbf{w}\|_2^2\]

&lt;p&gt;&lt;strong&gt;Component explanation:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Loss term&lt;/strong&gt;: \(\frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2\) - measures deviation between predictions and actual values&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization term&lt;/strong&gt;: \(\frac{\lambda}{2} \|\mathbf{w}\|_2^2 = \frac{\lambda}{2} \sum_{j=1}^p w_j^2\) - penalizes large weights&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization strength&lt;/strong&gt;: \(\lambda\) controls the amount of regularization&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;analytical-solution&quot;&gt;Analytical Solution&lt;/h3&gt;

&lt;p&gt;Ridge regression has a closed-form solution:
\(\mathbf{w}^* = (\mathbf{X}^T\mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{X}^T \mathbf{y}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Advantages of this solution:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The matrix \((\mathbf{X}^T\mathbf{X} + \lambda \mathbf{I})\) is always invertible when \(\lambda &amp;gt; 0\)&lt;/li&gt;
  &lt;li&gt;Solves multicollinearity problems&lt;/li&gt;
  &lt;li&gt;Computationally efficient&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;effects-of-ridge-regularization&quot;&gt;Effects of Ridge Regularization&lt;/h3&gt;

&lt;div id=&quot;ridge-effect-demo&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;&quot;&gt;
        &lt;h4&gt;Ridge Regularization Controls&lt;/h4&gt;
        &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px;&quot;&gt;
            &lt;div&gt;
                &lt;label for=&quot;ridge-lambda&quot;&gt;Lambda (λ): &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;ridge-lambda&quot; min=&quot;0&quot; max=&quot;10&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;
                &lt;span id=&quot;ridge-lambda-value&quot;&gt;1.0&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;ridge-noise&quot;&gt;Noise Level: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;ridge-noise&quot; min=&quot;0&quot; max=&quot;0.5&quot; step=&quot;0.05&quot; value=&quot;0.1&quot; /&gt;
                &lt;span id=&quot;ridge-noise-value&quot;&gt;0.1&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;ridge-features&quot;&gt;Number of Features: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;ridge-features&quot; min=&quot;5&quot; max=&quot;20&quot; step=&quot;1&quot; value=&quot;10&quot; /&gt;
                &lt;span id=&quot;ridge-features-value&quot;&gt;10&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
            &lt;button id=&quot;ridge-regenerate&quot; style=&quot;background-color: #4CAF50; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Generate New Data&lt;/button&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Coefficients Path&lt;/h4&gt;
            &lt;svg id=&quot;ridge-coefficients&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;ridge-coeff-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;L2 Norm of coefficients: 0&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Training vs Validation Error&lt;/h4&gt;
            &lt;svg id=&quot;ridge-error&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;ridge-error-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;Optimal λ: 0&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;lasso-regression-l1-regularization&quot;&gt;Lasso Regression (L1 Regularization)&lt;/h2&gt;

&lt;h3 id=&quot;mathematical-definition-1&quot;&gt;Mathematical Definition&lt;/h3&gt;

&lt;p&gt;Lasso (Least Absolute Shrinkage and Selection Operator) uses the L1 norm:&lt;/p&gt;

\[\min_{\mathbf{w}} \frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2 + \lambda \|\mathbf{w}\|_1\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;where $$|\mathbf{w}|&lt;em&gt;1 = \sum&lt;/em&gt;{j=1}^p&lt;/td&gt;
      &lt;td&gt;w_j&lt;/td&gt;
      &lt;td&gt;$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;key-properties-of-lasso&quot;&gt;Key Properties of Lasso&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1. Sparse Solutions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lasso can set some coefficients to &lt;strong&gt;exactly zero&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Automatically performs &lt;strong&gt;feature selection&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Creates simple, interpretable models&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2. No closed-form solution:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Requires optimization algorithms (coordinate descent, proximal gradient)&lt;/li&gt;
  &lt;li&gt;More computationally complex than Ridge&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ridge-vs-lasso-comparison&quot;&gt;Ridge vs Lasso Comparison&lt;/h3&gt;

&lt;div id=&quot;ridge-lasso-comparison&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f0f8ff;&quot;&gt;
        &lt;h4&gt;Ridge vs Lasso Regularization Comparison&lt;/h4&gt;
        &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr; gap: 20px;&quot;&gt;
            &lt;div&gt;
                &lt;label for=&quot;comparison-lambda&quot;&gt;Lambda (λ): &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;comparison-lambda&quot; min=&quot;0&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;
                &lt;span id=&quot;comparison-lambda-value&quot;&gt;1.0&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;comparison-correlation&quot;&gt;Feature Correlation: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;comparison-correlation&quot; min=&quot;0&quot; max=&quot;0.9&quot; step=&quot;0.1&quot; value=&quot;0.5&quot; /&gt;
                &lt;span id=&quot;comparison-correlation-value&quot;&gt;0.5&lt;/span&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
            &lt;button id=&quot;comparison-update&quot; style=&quot;background-color: #2196F3; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Update Comparison&lt;/button&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Ridge Coefficients&lt;/h4&gt;
            &lt;svg id=&quot;ridge-comparison&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 5px; padding: 5px; background-color: #e8f5e8; border-radius: 4px;&quot;&gt;
                &lt;p style=&quot;margin: 0; font-size: 12px;&quot;&gt;Shrinkage: Uniform, never zero&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Lasso Coefficients&lt;/h4&gt;
            &lt;svg id=&quot;lasso-comparison&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 5px; padding: 5px; background-color: #fff3e0; border-radius: 4px;&quot;&gt;
                &lt;p style=&quot;margin: 0; font-size: 12px;&quot;&gt;Sparsity: Some exactly zero&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Regularization Geometry&lt;/h4&gt;
            &lt;svg id=&quot;regularization-geometry&quot; width=&quot;300&quot; height=&quot;250&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 5px; padding: 5px; background-color: #f3e5f5; border-radius: 4px;&quot;&gt;
                &lt;p style=&quot;margin: 0; font-size: 12px;&quot;&gt;L1: Diamond, L2: Circle&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;geometry-of-regularization&quot;&gt;Geometry of Regularization&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Intuitive understanding of why Lasso creates sparse solutions:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;L1 constraint&lt;/strong&gt;: \(\|\mathbf{w}\|_1 \leq t\) creates a &lt;strong&gt;diamond shape&lt;/strong&gt; in 2D&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;L2 constraint&lt;/strong&gt;: \(\|\mathbf{w}\|_2 \leq t\) creates a &lt;strong&gt;circular shape&lt;/strong&gt; in 2D&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Intersection with loss contours&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;L1: High probability of intersecting contours at corners (sparse solutions)&lt;/li&gt;
      &lt;li&gt;L2: Usually intersects at smooth points (non-sparse solutions)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;elastic-net-combining-ridge-and-lasso&quot;&gt;Elastic Net: Combining Ridge and Lasso&lt;/h2&gt;

&lt;p&gt;Elastic Net combines both L1 and L2 regularization:&lt;/p&gt;

\[\min_{\mathbf{w}} \frac{1}{2n} \|\mathbf{X}\mathbf{w} - \mathbf{y}\|_2^2 + \lambda \left[ \alpha \|\mathbf{w}\|_1 + \frac{1-\alpha}{2} \|\mathbf{w}\|_2^2 \right]\]

&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\alpha \in [0,1]\): mixing parameter&lt;/li&gt;
  &lt;li&gt;\(\alpha = 1\): Pure Lasso&lt;/li&gt;
  &lt;li&gt;\(\alpha = 0\): Pure Ridge&lt;/li&gt;
  &lt;li&gt;\(0 &amp;lt; \alpha &amp;lt; 1\): Combination&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Combines Lasso’s sparsity with Ridge’s stability&lt;/li&gt;
  &lt;li&gt;Handles grouped variables well&lt;/li&gt;
  &lt;li&gt;Works well when \(p &amp;gt; n\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;loss-functions-in-machine-learning&quot;&gt;Loss Functions in Machine Learning&lt;/h2&gt;

&lt;h3 id=&quot;1-regression-loss-functions&quot;&gt;1. Regression Loss Functions&lt;/h3&gt;

&lt;h4 id=&quot;mean-squared-error-mse&quot;&gt;Mean Squared Error (MSE)&lt;/h4&gt;
&lt;p&gt;\(L_{MSE}(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n (y_i - \mathbf{w}^T \mathbf{x}_i)^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Smooth, differentiable everywhere&lt;/li&gt;
  &lt;li&gt;Sensitive to outliers&lt;/li&gt;
  &lt;li&gt;Convex optimization problem&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;mean-absolute-error-mae&quot;&gt;Mean Absolute Error (MAE)&lt;/h4&gt;
&lt;p&gt;\(L_{MAE}(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n |y_i - \mathbf{w}^T \mathbf{x}_i|\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Robust to outliers&lt;/li&gt;
  &lt;li&gt;Non-differentiable at zero&lt;/li&gt;
  &lt;li&gt;Convex but requires subgradient methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;huber-loss&quot;&gt;Huber Loss&lt;/h4&gt;
&lt;p&gt;\(L_{Huber}(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n \begin{cases}
\frac{1}{2}(y_i - \mathbf{w}^T \mathbf{x}_i)^2 &amp;amp; \text{if } |y_i - \mathbf{w}^T \mathbf{x}_i| \leq \delta \\
\delta |y_i - \mathbf{w}^T \mathbf{x}_i| - \frac{1}{2}\delta^2 &amp;amp; \text{otherwise}
\end{cases}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Combines MSE (small errors) and MAE (large errors)&lt;/li&gt;
  &lt;li&gt;Smooth and robust&lt;/li&gt;
  &lt;li&gt;Parameter \(\delta\) controls transition point&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-classification-loss-functions&quot;&gt;2. Classification Loss Functions&lt;/h3&gt;

&lt;h4 id=&quot;logistic-loss-cross-entropy&quot;&gt;Logistic Loss (Cross-entropy)&lt;/h4&gt;
&lt;p&gt;\(L_{logistic}(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n \log(1 + \exp(-y_i \mathbf{w}^T \mathbf{x}_i))\)&lt;/p&gt;

&lt;h4 id=&quot;hinge-loss-svm&quot;&gt;Hinge Loss (SVM)&lt;/h4&gt;
&lt;p&gt;\(L_{hinge}(\mathbf{w}) = \frac{1}{n} \sum_{i=1}^n \max(0, 1 - y_i \mathbf{w}^T \mathbf{x}_i)\)&lt;/p&gt;

&lt;h3 id=&quot;interactive-loss-functions-comparison&quot;&gt;Interactive Loss Functions Comparison&lt;/h3&gt;

&lt;div id=&quot;loss-functions-demo&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;&quot;&gt;
        &lt;h4&gt;Loss Functions Comparison&lt;/h4&gt;
        &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px;&quot;&gt;
            &lt;div&gt;
                &lt;label for=&quot;loss-delta&quot;&gt;Huber Delta (δ): &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;loss-delta&quot; min=&quot;0.5&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;
                &lt;span id=&quot;loss-delta-value&quot;&gt;1.0&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;loss-range&quot;&gt;Error Range: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;loss-range&quot; min=&quot;2&quot; max=&quot;8&quot; step=&quot;0.5&quot; value=&quot;4&quot; /&gt;
                &lt;span id=&quot;loss-range-value&quot;&gt;4.0&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label&gt;
                    &lt;input type=&quot;checkbox&quot; id=&quot;show-derivatives&quot; /&gt; Show Derivatives
                &lt;/label&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Regression Loss Functions&lt;/h4&gt;
            &lt;svg id=&quot;regression-losses&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;div style=&quot;display: flex; gap: 15px; justify-content: center; font-size: 12px;&quot;&gt;
                    &lt;span style=&quot;color: #1f77b4;&quot;&gt;■ MSE&lt;/span&gt;
                    &lt;span style=&quot;color: #ff7f0e;&quot;&gt;■ MAE&lt;/span&gt;
                    &lt;span style=&quot;color: #2ca02c;&quot;&gt;■ Huber&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Classification Loss Functions&lt;/h4&gt;
            &lt;svg id=&quot;classification-losses&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;div style=&quot;display: flex; gap: 15px; justify-content: center; font-size: 12px;&quot;&gt;
                    &lt;span style=&quot;color: #d62728;&quot;&gt;■ Logistic&lt;/span&gt;
                    &lt;span style=&quot;color: #9467bd;&quot;&gt;■ Hinge&lt;/span&gt;
                    &lt;span style=&quot;color: #8c564b;&quot;&gt;■ 0-1 Loss&lt;/span&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;regularization-path-and-model-selection&quot;&gt;Regularization Path and Model Selection&lt;/h2&gt;

&lt;h3 id=&quot;cross-validation-for-regularization&quot;&gt;Cross-Validation for Regularization&lt;/h3&gt;

&lt;p&gt;Choosing optimal \(\lambda\) is typically done through cross-validation:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Split data&lt;/strong&gt;: Training, validation, test sets&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Grid search&lt;/strong&gt;: Try multiple \(\lambda\) values&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Evaluate&lt;/strong&gt;: Compute validation error for each \(\lambda\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Select&lt;/strong&gt;: Choose \(\lambda\) with lowest validation error&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;regularization-path-visualization&quot;&gt;Regularization Path Visualization&lt;/h3&gt;

&lt;div id=&quot;regularization-path-demo&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f0f8ff;&quot;&gt;
        &lt;h4&gt;Regularization Path Analysis&lt;/h4&gt;
        &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px;&quot;&gt;
            &lt;div&gt;
                &lt;label for=&quot;path-method&quot;&gt;Method: &lt;/label&gt;
                &lt;select id=&quot;path-method&quot;&gt;
                    &lt;option value=&quot;ridge&quot;&gt;Ridge&lt;/option&gt;
                    &lt;option value=&quot;lasso&quot;&gt;Lasso&lt;/option&gt;
                    &lt;option value=&quot;elastic&quot;&gt;Elastic Net&lt;/option&gt;
                &lt;/select&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;label for=&quot;path-alpha&quot;&gt;Elastic Net α: &lt;/label&gt;
                &lt;input type=&quot;range&quot; id=&quot;path-alpha&quot; min=&quot;0&quot; max=&quot;1&quot; step=&quot;0.1&quot; value=&quot;0.5&quot; /&gt;
                &lt;span id=&quot;path-alpha-value&quot;&gt;0.5&lt;/span&gt;
            &lt;/div&gt;
            &lt;div&gt;
                &lt;button id=&quot;path-animate&quot; style=&quot;background-color: #FF9800; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Animate Path&lt;/button&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Coefficient Path&lt;/h4&gt;
            &lt;svg id=&quot;coefficient-path&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;path-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;Current λ: 0, Active features: 0&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Cross-Validation Curve&lt;/h4&gt;
            &lt;svg id=&quot;cv-curve&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;cv-info&quot; style=&quot;margin: 0; font-size: 12px;&quot;&gt;Optimal λ: 0, CV Score: 0&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;practical-guidelines-and-best-practices&quot;&gt;Practical Guidelines and Best Practices&lt;/h2&gt;

&lt;h3 id=&quot;1-when-to-use-ridge-vs-lasso&quot;&gt;1. When to use Ridge vs Lasso?&lt;/h3&gt;

&lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;border: 1px solid #4CAF50; padding: 15px; border-radius: 5px; background-color: #f1f8e9;&quot;&gt;
        &lt;h4 style=&quot;color: #4CAF50;&quot;&gt;Use Ridge when:&lt;/h4&gt;
        &lt;ul&gt;
            &lt;li&gt;All features are meaningful&lt;/li&gt;
            &lt;li&gt;High multicollinearity&lt;/li&gt;
            &lt;li&gt;Need stability in predictions&lt;/li&gt;
            &lt;li&gt;Small dataset, many features&lt;/li&gt;
            &lt;li&gt;Don&apos;t need automatic feature selection&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div style=&quot;border: 1px solid #FF9800; padding: 15px; border-radius: 5px; background-color: #fff8e1;&quot;&gt;
        &lt;h4 style=&quot;color: #FF9800;&quot;&gt;Use Lasso when:&lt;/h4&gt;
        &lt;ul&gt;
            &lt;li&gt;Need automatic feature selection&lt;/li&gt;
            &lt;li&gt;Many irrelevant features&lt;/li&gt;
            &lt;li&gt;Want simple, interpretable models&lt;/li&gt;
            &lt;li&gt;Sparse solutions are preferred&lt;/li&gt;
            &lt;li&gt;High-dimensional data&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2-hyperparameter-tuning-strategy&quot;&gt;2. Hyperparameter Tuning Strategy&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Pseudo-code for regularization tuning
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;tune_regularization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lambda_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;logspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Log-spaced values
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;best_lambda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;inf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda_val&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit_regularized_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;val_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_score&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;best_lambda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda_val&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-feature-scaling&quot;&gt;3. Feature Scaling&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Regularization is sensitive to feature scales!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ridge/Lasso&lt;/strong&gt;: Require feature scaling (standardization)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reason&lt;/strong&gt;: Regularization penalty depends on coefficient magnitudes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Standardize features before applying regularization&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion-and-takeaways&quot;&gt;Conclusion and Takeaways&lt;/h2&gt;

&lt;h3 id=&quot;key-points&quot;&gt;Key Points:&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt; is a powerful tool to prevent overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ridge (L2)&lt;/strong&gt; creates smooth shrinkage, good for stability&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lasso (L1)&lt;/strong&gt; creates sparse solutions, good for feature selection&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Elastic Net&lt;/strong&gt; combines advantages of both&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Loss function choice&lt;/strong&gt; greatly affects model behavior&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cross-validation&lt;/strong&gt; is key for hyperparameter tuning&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;practical-workflow&quot;&gt;Practical Workflow:&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Data preprocessing&lt;/strong&gt;: Scale features appropriately&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Method selection&lt;/strong&gt;: Choose based on problem characteristics&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hyperparameter tuning&lt;/strong&gt;: Use cross-validation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Model evaluation&lt;/strong&gt;: Test on held-out data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: Analyze coefficient patterns&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Remember&lt;/strong&gt;: Regularization is not a magic bullet - understanding your data and problem domain is still most important!&lt;/p&gt;

&lt;script&gt;
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    // Ridge Effect Demo
    initializeRidgeEffectDemo();
    
    // Ridge vs Lasso Comparison
    initializeRidgeLassoComparison();
    
    // Loss Functions Demo
    initializeLossFunctionsDemo();
    
    // Regularization Path Demo
    initializeRegularizationPathDemo();
    
    function initializeRidgeEffectDemo() {
        const lambdaSlider = document.getElementById(&apos;ridge-lambda&apos;);
        const noiseSlider = document.getElementById(&apos;ridge-noise&apos;);
        const featuresSlider = document.getElementById(&apos;ridge-features&apos;);
        const regenerateBtn = document.getElementById(&apos;ridge-regenerate&apos;);
        
        let currentData = generateRidgeData();
        
        function generateRidgeData() {
            const n = 50; // samples
            const p = parseInt(featuresSlider.value); // features
            const noise = parseFloat(noiseSlider.value);
            
            // Generate true coefficients (sparse)
            const trueCoeffs = Array(p).fill(0).map((_, i) =&gt; 
                i &lt; 3 ? (Math.random() - 0.5) * 4 : 0
            );
            
            // Generate X matrix
            const X = Array(n).fill().map(() =&gt; 
                Array(p).fill().map(() =&gt; Math.random() * 2 - 1)
            );
            
            // Generate y with noise
            const y = X.map(row =&gt; 
                row.reduce((sum, x, i) =&gt; sum + x * trueCoeffs[i], 0) + 
                (Math.random() - 0.5) * noise * 2
            );
            
            return { X, y, trueCoeffs, n, p };
        }
        
        function updateRidgeDemo() {
            const lambda = parseFloat(lambdaSlider.value);
            document.getElementById(&apos;ridge-lambda-value&apos;).textContent = lambda.toFixed(1);
            
            // Compute Ridge coefficients for different lambda values
            const lambdaRange = Array(50).fill().map((_, i) =&gt; i * 0.2);
            const coeffPaths = computeRidgeCoefficients(currentData, lambdaRange);
            
            // Update visualizations
            updateRidgeCoefficientsPlot(coeffPaths, lambdaRange, lambda);
            updateRidgeErrorPlot(currentData, lambdaRange);
        }
        
        function computeRidgeCoefficients(data, lambdaRange) {
            const { X, y, p } = data;
            const paths = Array(p).fill().map(() =&gt; []);
            
            lambdaRange.forEach(lambda =&gt; {
                const coeffs = solveRidge(X, y, lambda);
                coeffs.forEach((coeff, i) =&gt; paths[i].push(coeff));
            });
            
            return paths;
        }
        
        function solveRidge(X, y, lambda) {
            // Simplified Ridge solution: w = (X&apos;X + λI)^(-1) X&apos;y
            const p = X[0].length;
            const n = X.length;
            
            // Compute X&apos;X
            const XtX = Array(p).fill().map(() =&gt; Array(p).fill(0));
            for (let i = 0; i &lt; p; i++) {
                for (let j = 0; j &lt; p; j++) {
                    for (let k = 0; k &lt; n; k++) {
                        XtX[i][j] += X[k][i] * X[k][j];
                    }
                }
            }
            
            // Add λI
            for (let i = 0; i &lt; p; i++) {
                XtX[i][i] += lambda;
            }
            
            // Compute X&apos;y
            const Xty = Array(p).fill(0);
            for (let i = 0; i &lt; p; i++) {
                for (let k = 0; k &lt; n; k++) {
                    Xty[i] += X[k][i] * y[k];
                }
            }
            
            // Solve linear system (simplified - using pseudo-inverse)
            return solveLinearSystem(XtX, Xty);
        }
        
        function solveLinearSystem(A, b) {
            // Simplified solution using Gaussian elimination
            const n = A.length;
            const coeffs = Array(n).fill(0);
            
            // For demo purposes, use a simplified approach
            for (let i = 0; i &lt; n; i++) {
                coeffs[i] = b[i] / (A[i][i] + 1e-10);
            }
            
            return coeffs;
        }
        
        function updateRidgeCoefficientsPlot(coeffPaths, lambdaRange, currentLambda) {
            const svg = d3.select(&apos;#ridge-coefficients&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain(d3.extent(lambdaRange))
                .range([0, width]);
            
            const allCoeffs = coeffPaths.flat();
            const yScale = d3.scaleLinear()
                .domain(d3.extent(allCoeffs))
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Lambda (λ)&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Coefficient Value&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(lambdaRange[i]))
                .y(d =&gt; yScale(d));
            
            // Draw coefficient paths
            const colors = d3.schemeCategory10;
            coeffPaths.forEach((path, i) =&gt; {
                g.append(&apos;path&apos;)
                    .datum(path)
                    .attr(&apos;fill&apos;, &apos;none&apos;)
                    .attr(&apos;stroke&apos;, colors[i % colors.length])
                    .attr(&apos;stroke-width&apos;, 2)
                    .attr(&apos;d&apos;, line);
            });
            
            // Current lambda line
            g.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, xScale(currentLambda))
                .attr(&apos;x2&apos;, xScale(currentLambda))
                .attr(&apos;y1&apos;, 0)
                .attr(&apos;y2&apos;, height)
                .attr(&apos;stroke&apos;, &apos;red&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;stroke-dasharray&apos;, &apos;5,5&apos;);
            
            // Update info
            const currentIndex = Math.round(currentLambda / 0.2);
            const currentCoeffs = coeffPaths.map(path =&gt; path[currentIndex] || 0);
            const l2Norm = Math.sqrt(currentCoeffs.reduce((sum, c) =&gt; sum + c*c, 0));
            document.getElementById(&apos;ridge-coeff-info&apos;).textContent = 
                `L2 Norm of coefficients: ${l2Norm.toFixed(3)}`;
        }
        
        function updateRidgeErrorPlot(data, lambdaRange) {
            // Simplified error computation for demo
            const svg = d3.select(&apos;#ridge-error&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Generate synthetic error curves
            const trainErrors = lambdaRange.map(lambda =&gt; 
                0.1 + 0.5 * lambda + Math.random() * 0.1
            );
            const valErrors = lambdaRange.map(lambda =&gt; 
                0.3 + 0.2 * Math.abs(lambda - 2) + Math.random() * 0.1
            );
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain(d3.extent(lambdaRange))
                .range([0, width]);
            
            const yScale = d3.scaleLinear()
                .domain([0, Math.max(...trainErrors, ...valErrors)])
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Lambda (λ)&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Error&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(lambdaRange[i]))
                .y(d =&gt; yScale(d));
            
            // Draw error curves
            g.append(&apos;path&apos;)
                .datum(trainErrors)
                .attr(&apos;fill&apos;, &apos;none&apos;)
                .attr(&apos;stroke&apos;, &apos;blue&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;d&apos;, line);
            
            g.append(&apos;path&apos;)
                .datum(valErrors)
                .attr(&apos;fill&apos;, &apos;none&apos;)
                .attr(&apos;stroke&apos;, &apos;red&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;d&apos;, line);
            
            // Legend
            const legend = g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${width - 100}, 20)`);
            
            legend.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, 0).attr(&apos;x2&apos;, 20)
                .attr(&apos;y1&apos;, 0).attr(&apos;y2&apos;, 0)
                .attr(&apos;stroke&apos;, &apos;blue&apos;).attr(&apos;stroke-width&apos;, 2);
            legend.append(&apos;text&apos;)
                .attr(&apos;x&apos;, 25).attr(&apos;y&apos;, 5)
                .text(&apos;Training&apos;);
            
            legend.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, 0).attr(&apos;x2&apos;, 20)
                .attr(&apos;y1&apos;, 15).attr(&apos;y2&apos;, 15)
                .attr(&apos;stroke&apos;, &apos;red&apos;).attr(&apos;stroke-width&apos;, 2);
            legend.append(&apos;text&apos;)
                .attr(&apos;x&apos;, 25).attr(&apos;y&apos;, 20)
                .text(&apos;Validation&apos;);
            
            // Find optimal lambda
            const optimalIndex = valErrors.indexOf(Math.min(...valErrors));
            const optimalLambda = lambdaRange[optimalIndex];
            document.getElementById(&apos;ridge-error-info&apos;).textContent = 
                `Optimal λ: ${optimalLambda.toFixed(2)}`;
        }
        
        // Event listeners
        lambdaSlider.addEventListener(&apos;input&apos;, updateRidgeDemo);
        noiseSlider.addEventListener(&apos;input&apos;, function() {
            document.getElementById(&apos;ridge-noise-value&apos;).textContent = this.value;
        });
        featuresSlider.addEventListener(&apos;input&apos;, function() {
            document.getElementById(&apos;ridge-features-value&apos;).textContent = this.value;
        });
        
        regenerateBtn.addEventListener(&apos;click&apos;, function() {
            currentData = generateRidgeData();
            updateRidgeDemo();
        });
        
        // Initial update
        updateRidgeDemo();
    }
    
    function initializeRidgeLassoComparison() {
        const lambdaSlider = document.getElementById(&apos;comparison-lambda&apos;);
        const correlationSlider = document.getElementById(&apos;comparison-correlation&apos;);
        const updateBtn = document.getElementById(&apos;comparison-update&apos;);
        
        function updateComparison() {
            const lambda = parseFloat(lambdaSlider.value);
            const correlation = parseFloat(correlationSlider.value);
            
            document.getElementById(&apos;comparison-lambda-value&apos;).textContent = lambda.toFixed(1);
            document.getElementById(&apos;comparison-correlation-value&apos;).textContent = correlation.toFixed(1);
            
            // Generate synthetic data with controlled correlation
            const p = 8; // features
            const trueCoeffs = [2, -1.5, 1, 0.5, -0.8, 0, 0, 0];
            
            // Compute Ridge and Lasso coefficients
            const ridgeCoeffs = computeRidgeCoeffs(trueCoeffs, lambda, correlation);
            const lassoCoeffs = computeLassoCoeffs(trueCoeffs, lambda, correlation);
            
            // Update visualizations
            updateComparisonPlot(&apos;ridge-comparison&apos;, ridgeCoeffs, &apos;Ridge&apos;);
            updateComparisonPlot(&apos;lasso-comparison&apos;, lassoCoeffs, &apos;Lasso&apos;);
            updateGeometryPlot(lambda);
        }
        
        function computeRidgeCoeffs(trueCoeffs, lambda, correlation) {
            // Simplified Ridge shrinkage
            const shrinkageFactor = 1 / (1 + lambda);
            return trueCoeffs.map(coeff =&gt; coeff * shrinkageFactor);
        }
        
        function computeLassoCoeffs(trueCoeffs, lambda, correlation) {
            // Simplified Lasso soft thresholding
            return trueCoeffs.map(coeff =&gt; {
                const absCoeff = Math.abs(coeff);
                if (absCoeff &lt;= lambda) return 0;
                return Math.sign(coeff) * (absCoeff - lambda);
            });
        }
        
        function updateComparisonPlot(svgId, coeffs, title) {
            const svg = d3.select(`#${svgId}`);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 40};
            const width = 300 - margin.left - margin.right;
            const height = 250 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Scales
            const xScale = d3.scaleBand()
                .domain(coeffs.map((_, i) =&gt; `w${i+1}`))
                .range([0, width])
                .padding(0.1);
            
            const yScale = d3.scaleLinear()
                .domain(d3.extent(coeffs))
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Bars
            const color = title === &apos;Ridge&apos; ? &apos;#4CAF50&apos; : &apos;#FF9800&apos;;
            g.selectAll(&apos;.bar&apos;)
                .data(coeffs)
                .enter().append(&apos;rect&apos;)
                .attr(&apos;class&apos;, &apos;bar&apos;)
                .attr(&apos;x&apos;, (d, i) =&gt; xScale(`w${i+1}`))
                .attr(&apos;width&apos;, xScale.bandwidth())
                .attr(&apos;y&apos;, d =&gt; d &gt;= 0 ? yScale(d) : yScale(0))
                .attr(&apos;height&apos;, d =&gt; Math.abs(yScale(d) - yScale(0)))
                .attr(&apos;fill&apos;, color);
            
            // Zero line
            g.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, 0)
                .attr(&apos;x2&apos;, width)
                .attr(&apos;y1&apos;, yScale(0))
                .attr(&apos;y2&apos;, yScale(0))
                .attr(&apos;stroke&apos;, &apos;black&apos;)
                .attr(&apos;stroke-width&apos;, 1);
        }
        
        function updateGeometryPlot(lambda) {
            const svg = d3.select(&apos;#regularization-geometry&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 40};
            const width = 300 - margin.left - margin.right;
            const height = 250 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            const centerX = width / 2;
            const centerY = height / 2;
            const radius = Math.min(width, height) / 3;
            
            // L2 constraint (circle)
            g.append(&apos;circle&apos;)
                .attr(&apos;cx&apos;, centerX)
                .attr(&apos;cy&apos;, centerY)
                .attr(&apos;r&apos;, radius)
                .attr(&apos;fill&apos;, &apos;none&apos;)
                .attr(&apos;stroke&apos;, &apos;#4CAF50&apos;)
                .attr(&apos;stroke-width&apos;, 3)
                .attr(&apos;opacity&apos;, 0.7);
            
            // L1 constraint (diamond)
            const diamondPoints = [
                [centerX, centerY - radius],
                [centerX + radius, centerY],
                [centerX, centerY + radius],
                [centerX - radius, centerY]
            ];
            
            const line = d3.line()
                .x(d =&gt; d[0])
                .y(d =&gt; d[1]);
            
            g.append(&apos;path&apos;)
                .datum([...diamondPoints, diamondPoints[0]])
                .attr(&apos;d&apos;, line)
                .attr(&apos;fill&apos;, &apos;none&apos;)
                .attr(&apos;stroke&apos;, &apos;#FF9800&apos;)
                .attr(&apos;stroke-width&apos;, 3)
                .attr(&apos;opacity&apos;, 0.7);
            
            // Contour lines (ellipses)
            for (let i = 1; i &lt;= 3; i++) {
                g.append(&apos;ellipse&apos;)
                    .attr(&apos;cx&apos;, centerX + 20)
                    .attr(&apos;cy&apos;, centerY - 10)
                    .attr(&apos;rx&apos;, i * 15)
                    .attr(&apos;ry&apos;, i * 25)
                    .attr(&apos;fill&apos;, &apos;none&apos;)
                    .attr(&apos;stroke&apos;, &apos;#666&apos;)
                    .attr(&apos;stroke-width&apos;, 1)
                    .attr(&apos;stroke-dasharray&apos;, &apos;3,3&apos;)
                    .attr(&apos;opacity&apos;, 0.5);
            }
            
            // Labels
            g.append(&apos;text&apos;)
                .attr(&apos;x&apos;, centerX + radius + 10)
                .attr(&apos;y&apos;, centerY + 5)
                .text(&apos;L2&apos;)
                .attr(&apos;fill&apos;, &apos;#4CAF50&apos;)
                .attr(&apos;font-weight&apos;, &apos;bold&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;x&apos;, centerX + radius/Math.sqrt(2) + 5)
                .attr(&apos;y&apos;, centerY - radius/Math.sqrt(2) - 5)
                .text(&apos;L1&apos;)
                .attr(&apos;fill&apos;, &apos;#FF9800&apos;)
                .attr(&apos;font-weight&apos;, &apos;bold&apos;);
        }
        
        // Event listeners
        lambdaSlider.addEventListener(&apos;input&apos;, updateComparison);
        correlationSlider.addEventListener(&apos;input&apos;, updateComparison);
        updateBtn.addEventListener(&apos;click&apos;, updateComparison);
        
        // Initial update
        updateComparison();
    }
    
    function initializeLossFunctionsDemo() {
        const deltaSlider = document.getElementById(&apos;loss-delta&apos;);
        const rangeSlider = document.getElementById(&apos;loss-range&apos;);
        const derivativesCheckbox = document.getElementById(&apos;show-derivatives&apos;);
        
        function updateLossFunctions() {
            const delta = parseFloat(deltaSlider.value);
            const range = parseFloat(rangeSlider.value);
            const showDerivatives = derivativesCheckbox.checked;
            
            document.getElementById(&apos;loss-delta-value&apos;).textContent = delta.toFixed(1);
            document.getElementById(&apos;loss-range-value&apos;).textContent = range.toFixed(1);
            
            updateRegressionLosses(delta, range, showDerivatives);
            updateClassificationLosses(range, showDerivatives);
        }
        
        function updateRegressionLosses(delta, range, showDerivatives) {
            const svg = d3.select(&apos;#regression-losses&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Generate error values
            const errors = d3.range(-range, range, 0.1);
            
            // Loss functions
            const mseLoss = errors.map(e =&gt; 0.5 * e * e);
            const maeLoss = errors.map(e =&gt; Math.abs(e));
            const huberLoss = errors.map(e =&gt; 
                Math.abs(e) &lt;= delta ? 0.5 * e * e : delta * Math.abs(e) - 0.5 * delta * delta
            );
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain([-range, range])
                .range([0, width]);
            
            const maxLoss = Math.max(...mseLoss, ...maeLoss, ...huberLoss);
            const yScale = d3.scaleLinear()
                .domain([0, maxLoss])
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Prediction Error&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Loss&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(errors[i]))
                .y(d =&gt; yScale(d));
            
            // Draw loss functions
            const colors = [&apos;#1f77b4&apos;, &apos;#ff7f0e&apos;, &apos;#2ca02c&apos;];
            const losses = [mseLoss, maeLoss, huberLoss];
            const names = [&apos;MSE&apos;, &apos;MAE&apos;, &apos;Huber&apos;];
            
            losses.forEach((loss, i) =&gt; {
                g.append(&apos;path&apos;)
                    .datum(loss)
                    .attr(&apos;fill&apos;, &apos;none&apos;)
                    .attr(&apos;stroke&apos;, colors[i])
                    .attr(&apos;stroke-width&apos;, 3)
                    .attr(&apos;d&apos;, line);
            });
            
            // Legend
            const legend = g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${width - 80}, 20)`);
            
            names.forEach((name, i) =&gt; {
                legend.append(&apos;line&apos;)
                    .attr(&apos;x1&apos;, 0).attr(&apos;x2&apos;, 20)
                    .attr(&apos;y1&apos;, i * 20).attr(&apos;y2&apos;, i * 20)
                    .attr(&apos;stroke&apos;, colors[i]).attr(&apos;stroke-width&apos;, 3);
                legend.append(&apos;text&apos;)
                    .attr(&apos;x&apos;, 25).attr(&apos;y&apos;, i * 20 + 5)
                    .text(name);
            });
        }
        
        function updateClassificationLosses(range, showDerivatives) {
            const svg = d3.select(&apos;#classification-losses&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Generate margin values (y * f(x))
            const margins = d3.range(-range, range, 0.1);
            
            // Loss functions
            const logisticLoss = margins.map(m =&gt; Math.log(1 + Math.exp(-m)));
            const hingeLoss = margins.map(m =&gt; Math.max(0, 1 - m));
            const zeroOneLoss = margins.map(m =&gt; m &lt;= 0 ? 1 : 0);
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain([-range, range])
                .range([0, width]);
            
            const maxLoss = Math.max(...logisticLoss, ...hingeLoss, ...zeroOneLoss);
            const yScale = d3.scaleLinear()
                .domain([0, maxLoss])
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Margin (y × f(x))&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Loss&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(margins[i]))
                .y(d =&gt; yScale(d));
            
            // Draw loss functions
            const colors = [&apos;#d62728&apos;, &apos;#9467bd&apos;, &apos;#8c564b&apos;];
            const losses = [logisticLoss, hingeLoss, zeroOneLoss];
            const names = [&apos;Logistic&apos;, &apos;Hinge&apos;, &apos;0-1 Loss&apos;];
            
            losses.forEach((loss, i) =&gt; {
                g.append(&apos;path&apos;)
                    .datum(loss)
                    .attr(&apos;fill&apos;, &apos;none&apos;)
                    .attr(&apos;stroke&apos;, colors[i])
                    .attr(&apos;stroke-width&apos;, 3)
                    .attr(&apos;d&apos;, line);
            });
            
            // Legend
            const legend = g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${width - 80}, 20)`);
            
            names.forEach((name, i) =&gt; {
                legend.append(&apos;line&apos;)
                    .attr(&apos;x1&apos;, 0).attr(&apos;x2&apos;, 20)
                    .attr(&apos;y1&apos;, i * 20).attr(&apos;y2&apos;, i * 20)
                    .attr(&apos;stroke&apos;, colors[i]).attr(&apos;stroke-width&apos;, 3);
                legend.append(&apos;text&apos;)
                    .attr(&apos;x&apos;, 25).attr(&apos;y&apos;, i * 20 + 5)
                    .text(name);
            });
        }
        
        // Event listeners
        deltaSlider.addEventListener(&apos;input&apos;, updateLossFunctions);
        rangeSlider.addEventListener(&apos;input&apos;, updateLossFunctions);
        derivativesCheckbox.addEventListener(&apos;change&apos;, updateLossFunctions);
        
        // Initial update
        updateLossFunctions();
    }
    
    function initializeRegularizationPathDemo() {
        const methodSelect = document.getElementById(&apos;path-method&apos;);
        const alphaSlider = document.getElementById(&apos;path-alpha&apos;);
        const animateBtn = document.getElementById(&apos;path-animate&apos;);
        
        let isAnimating = false;
        let animationId = null;
        
        function updateRegularizationPath() {
            const method = methodSelect.value;
            const alpha = parseFloat(alphaSlider.value);
            
            document.getElementById(&apos;path-alpha-value&apos;).textContent = alpha.toFixed(1);
            
            // Generate regularization path
            const lambdaRange = d3.range(0, 5, 0.1);
            const coeffPaths = generateRegularizationPath(method, alpha, lambdaRange);
            
            updateCoefficientPathPlot(coeffPaths, lambdaRange, method);
            updateCVCurvePlot(lambdaRange, method);
        }
        
        function generateRegularizationPath(method, alpha, lambdaRange) {
            const p = 6; // features
            const trueCoeffs = [2, -1.5, 1, 0.5, -0.8, 0.3];
            
            const paths = Array(p).fill().map(() =&gt; []);
            
            lambdaRange.forEach(lambda =&gt; {
                let coeffs;
                if (method === &apos;ridge&apos;) {
                    coeffs = trueCoeffs.map(c =&gt; c / (1 + lambda));
                } else if (method === &apos;lasso&apos;) {
                    coeffs = trueCoeffs.map(c =&gt; {
                        const abs_c = Math.abs(c);
                        return abs_c &gt; lambda ? Math.sign(c) * (abs_c - lambda) : 0;
                    });
                } else { // elastic net
                    coeffs = trueCoeffs.map(c =&gt; {
                        const abs_c = Math.abs(c);
                        const l1_part = abs_c &gt; alpha * lambda ? Math.sign(c) * (abs_c - alpha * lambda) : 0;
                        return l1_part / (1 + (1 - alpha) * lambda);
                    });
                }
                
                coeffs.forEach((coeff, i) =&gt; paths[i].push(coeff));
            });
            
            return paths;
        }
        
        function updateCoefficientPathPlot(coeffPaths, lambdaRange, method) {
            const svg = d3.select(&apos;#coefficient-path&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain(d3.extent(lambdaRange))
                .range([0, width]);
            
            const allCoeffs = coeffPaths.flat();
            const yScale = d3.scaleLinear()
                .domain(d3.extent(allCoeffs))
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Lambda (λ)&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Coefficient Value&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(lambdaRange[i]))
                .y(d =&gt; yScale(d));
            
            // Draw coefficient paths
            const colors = d3.schemeCategory10;
            coeffPaths.forEach((path, i) =&gt; {
                g.append(&apos;path&apos;)
                    .datum(path)
                    .attr(&apos;fill&apos;, &apos;none&apos;)
                    .attr(&apos;stroke&apos;, colors[i % colors.length])
                    .attr(&apos;stroke-width&apos;, 2)
                    .attr(&apos;d&apos;, line);
                
                // Add feature label at the end
                const lastValue = path[path.length - 1];
                if (Math.abs(lastValue) &gt; 0.01) {
                    g.append(&apos;text&apos;)
                        .attr(&apos;x&apos;, width + 5)
                        .attr(&apos;y&apos;, yScale(lastValue) + 3)
                        .attr(&apos;font-size&apos;, &apos;10px&apos;)
                        .text(`f${i+1}`);
                }
            });
            
            // Update info
            const currentLambda = 1.0; // example
            const activeFeatures = coeffPaths.filter(path =&gt; Math.abs(path[Math.floor(currentLambda * 10)]) &gt; 0.01).length;
            document.getElementById(&apos;path-info&apos;).textContent = 
                `Current λ: ${currentLambda.toFixed(1)}, Active features: ${activeFeatures}`;
        }
        
        function updateCVCurvePlot(lambdaRange, method) {
            const svg = d3.select(&apos;#cv-curve&apos;);
            svg.selectAll(&apos;*&apos;).remove();
            
            const margin = {top: 20, right: 20, bottom: 40, left: 50};
            const width = 400 - margin.left - margin.right;
            const height = 300 - margin.top - margin.bottom;
            
            const g = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},${margin.top})`);
            
            // Generate synthetic CV scores
            const cvScores = lambdaRange.map(lambda =&gt; {
                const base = 0.2 + 0.1 * Math.abs(lambda - 1.5);
                return base + (Math.random() - 0.5) * 0.05;
            });
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain(d3.extent(lambdaRange))
                .range([0, width]);
            
            const yScale = d3.scaleLinear()
                .domain(d3.extent(cvScores))
                .nice()
                .range([height, 0]);
            
            // Axes
            g.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height})`)
                .call(d3.axisBottom(xScale));
            
            g.append(&apos;g&apos;)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, `translate(${width/2},${height + 35})`)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;Lambda (λ)&apos;);
            
            g.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;y&apos;, 0 - margin.left)
                .attr(&apos;x&apos;, 0 - height/2)
                .attr(&apos;dy&apos;, &apos;1em&apos;)
                .style(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;CV Score&apos;);
            
            // Line generator
            const line = d3.line()
                .x((d, i) =&gt; xScale(lambdaRange[i]))
                .y(d =&gt; yScale(d));
            
            // Draw CV curve
            g.append(&apos;path&apos;)
                .datum(cvScores)
                .attr(&apos;fill&apos;, &apos;none&apos;)
                .attr(&apos;stroke&apos;, &apos;#2196F3&apos;)
                .attr(&apos;stroke-width&apos;, 3)
                .attr(&apos;d&apos;, line);
            
            // Find and mark optimal lambda
            const minIndex = cvScores.indexOf(Math.min(...cvScores));
            const optimalLambda = lambdaRange[minIndex];
            
            g.append(&apos;circle&apos;)
                .attr(&apos;cx&apos;, xScale(optimalLambda))
                .attr(&apos;cy&apos;, yScale(cvScores[minIndex]))
                .attr(&apos;r&apos;, 5)
                .attr(&apos;fill&apos;, &apos;red&apos;);
            
            // Update info
            document.getElementById(&apos;cv-info&apos;).textContent = 
                `Optimal λ: ${optimalLambda.toFixed(2)}, CV Score: ${cvScores[minIndex].toFixed(3)}`;
        }
        
        function animatePath() {
            if (isAnimating) {
                // Stop animation
                isAnimating = false;
                if (animationId) clearInterval(animationId);
                animateBtn.textContent = &apos;Animate Path&apos;;
                return;
            }
            
            // Start animation
            isAnimating = true;
            animateBtn.textContent = &apos;Stop Animation&apos;;
            
            const lambdaRange = d3.range(0, 5, 0.1);
            let currentIndex = 0;
            
            animationId = setInterval(() =&gt; {
                if (currentIndex &gt;= lambdaRange.length) {
                    currentIndex = 0;
                }
                
                // Update visualization for current lambda
                const currentLambda = lambdaRange[currentIndex];
                // Add animation logic here
                
                currentIndex++;
            }, 100);
        }
        
        // Event listeners
        methodSelect.addEventListener(&apos;change&apos;, updateRegularizationPath);
        alphaSlider.addEventListener(&apos;input&apos;, updateRegularizationPath);
        animateBtn.addEventListener(&apos;click&apos;, animatePath);
        
        // Initial update
        updateRegularizationPath();
    }
});
&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>06-06 Gradient descent with momentum</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_06_gradent_descent_with_momentum/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_06_gradent_descent_with_momentum</id>
   <content type="html">&lt;script src=&quot;https://d3js.org/d3.v7.min.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;the-problem-with-vanilla-gradient-descent&quot;&gt;The Problem with Vanilla Gradient Descent&lt;/h2&gt;

&lt;p&gt;Imagine you’re rolling a ball down a valley. Standard gradient descent is like a ball with no memory - at each step, it only considers the current slope and moves accordingly. This can lead to several problems:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Slow convergence in ravines&lt;/strong&gt;: When the function has steep gradients in some directions and shallow gradients in others&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Oscillations&lt;/strong&gt;: The algorithm may zigzag back and forth across the valley instead of making steady progress&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Getting stuck in poor local minima&lt;/strong&gt;: Without momentum, the algorithm may settle in suboptimal solutions&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: What if our ball could “remember” its previous direction and maintain some velocity?&lt;/p&gt;

&lt;h2 id=&quot;momentum-adding-memory-to-gradient-descent&quot;&gt;Momentum: Adding Memory to Gradient Descent&lt;/h2&gt;

&lt;p&gt;Gradient descent with momentum is inspired by physics - specifically, the motion of a ball rolling down a hill with friction. The key insight is to accumulate a velocity vector that combines the current gradient with the previous momentum.&lt;/p&gt;

&lt;h3 id=&quot;the-momentum-algorithm&quot;&gt;The Momentum Algorithm&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Update rules:&lt;/strong&gt;
\(\begin{align}
v^{(k)} &amp;amp;= \beta v^{(k-1)} + (1-\beta) \nabla f(x^{(k-1)}) \\
x^{(k)} &amp;amp;= x^{(k-1)} - t v^{(k)}
\end{align}\)&lt;/p&gt;

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(v^{(k)}\) is the momentum (velocity) at iteration \(k\)&lt;/li&gt;
  &lt;li&gt;\(\beta \in [0,1)\) is the momentum coefficient (typically 0.9 or 0.99)&lt;/li&gt;
  &lt;li&gt;\(t &amp;gt; 0\) is the learning rate&lt;/li&gt;
  &lt;li&gt;\(v^{(0)} = 0\) (initial velocity is zero)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;alternative-formulation-nesterov-style&quot;&gt;Alternative Formulation (Nesterov-style)&lt;/h3&gt;

&lt;p&gt;Some implementations use a slightly different form:
\(\begin{align}
v^{(k)} &amp;amp;= \beta v^{(k-1)} + \nabla f(x^{(k-1)}) \\
x^{(k)} &amp;amp;= x^{(k-1)} - t v^{(k)}
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key insight&lt;/strong&gt;: The momentum term \(v^{(k)}\) is an exponentially weighted moving average of past gradients.&lt;/p&gt;

&lt;h2 id=&quot;understanding-the-momentum-coefficient-beta&quot;&gt;Understanding the Momentum Coefficient \(\beta\)&lt;/h2&gt;

&lt;p&gt;The momentum coefficient \(\beta\) controls how much “memory” the algorithm has:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(\beta = 0\)&lt;/strong&gt;: No momentum, reduces to standard gradient descent&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\beta = 0.9\)&lt;/strong&gt;: Moderate momentum, commonly used in practice&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\beta = 0.99\)&lt;/strong&gt;: High momentum, used in some deep learning applications&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\beta \to 1\)&lt;/strong&gt;: Maximum momentum, but may cause instability&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;exponentially-weighted-moving-average&quot;&gt;Exponentially Weighted Moving Average&lt;/h3&gt;

&lt;p&gt;The momentum \(v^{(k)}\) can be expanded as:
\(v^{(k)} = (1-\beta) \sum_{i=0}^{k-1} \beta^i \nabla f(x^{(k-1-i)})\)&lt;/p&gt;

&lt;p&gt;This shows that momentum gives exponentially decreasing weights to older gradients.&lt;/p&gt;

&lt;h2 id=&quot;interactive-visualization-gradient-descent-vs-momentum&quot;&gt;Interactive Visualization: Gradient Descent vs Momentum&lt;/h2&gt;

&lt;div id=&quot;momentum-comparison&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;!-- Parameter Controls --&gt;
    &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px; margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;&quot;&gt;
        &lt;div&gt;
            &lt;label for=&quot;momentum-lr&quot;&gt;Learning Rate: &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;momentum-lr&quot; min=&quot;0.01&quot; max=&quot;0.3&quot; step=&quot;0.01&quot; value=&quot;0.1&quot; /&gt;
            &lt;span id=&quot;momentum-lr-value&quot;&gt;0.1&lt;/span&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;label for=&quot;momentum-beta&quot;&gt;Momentum (β): &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;momentum-beta&quot; min=&quot;0&quot; max=&quot;0.99&quot; step=&quot;0.01&quot; value=&quot;0.9&quot; /&gt;
            &lt;span id=&quot;momentum-beta-value&quot;&gt;0.9&lt;/span&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;label for=&quot;momentum-speed&quot;&gt;Animation Speed: &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;momentum-speed&quot; min=&quot;1&quot; max=&quot;10&quot; step=&quot;1&quot; value=&quot;5&quot; /&gt;
            &lt;span id=&quot;momentum-speed-value&quot;&gt;5&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;!-- Control Buttons --&gt;
    &lt;div style=&quot;display: flex; gap: 10px; margin-bottom: 15px; flex-wrap: wrap;&quot;&gt;
        &lt;button id=&quot;start-vanilla-gd&quot; style=&quot;background-color: #4CAF50; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Start Vanilla GD&lt;/button&gt;
        &lt;button id=&quot;start-momentum-gd&quot; style=&quot;background-color: #FF9800; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Start Momentum GD&lt;/button&gt;
        &lt;button id=&quot;start-both&quot; style=&quot;background-color: #2196F3; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Compare Both&lt;/button&gt;
        &lt;button id=&quot;reset-momentum&quot; style=&quot;background-color: #f44336; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Reset&lt;/button&gt;
    &lt;/div&gt;
    
    &lt;!-- Visualization Canvas --&gt;
    &lt;div id=&quot;momentum-canvas&quot; style=&quot;border: 1px solid #ccc; border-radius: 5px; background-color: white; position: relative; overflow: hidden;&quot;&gt;
        &lt;svg width=&quot;800&quot; height=&quot;500&quot; id=&quot;momentum-svg&quot;&gt;&lt;/svg&gt;
    &lt;/div&gt;
    
    &lt;!-- Algorithm Status --&gt;
    &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-top: 15px;&quot;&gt;
        &lt;div style=&quot;padding: 10px; border: 1px solid #4CAF50; border-radius: 5px; background-color: #f1f8e9;&quot;&gt;
            &lt;h4 style=&quot;margin: 0 0 5px 0; color: #4CAF50;&quot;&gt;Vanilla Gradient Descent&lt;/h4&gt;
            &lt;p id=&quot;vanilla-gd-info&quot; style=&quot;margin: 0; font-size: 14px;&quot;&gt;Ready to start&lt;/p&gt;
        &lt;/div&gt;
        &lt;div style=&quot;padding: 10px; border: 1px solid #FF9800; border-radius: 5px; background-color: #fff8e1;&quot;&gt;
            &lt;h4 style=&quot;margin: 0 0 5px 0; color: #FF9800;&quot;&gt;Momentum Gradient Descent&lt;/h4&gt;
            &lt;p id=&quot;momentum-gd-info&quot; style=&quot;margin: 0; font-size: 14px;&quot;&gt;Ready to start&lt;/p&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    // Momentum visualization implementation
    const svg = d3.select(&quot;#momentum-svg&quot;);
    const width = 800, height = 500;
    const margin = {top: 20, right: 20, bottom: 40, left: 40};
    
    // Function to optimize: f(x,y) = 0.5*x^2 + 5*y^2 (elongated bowl)
    function f(x, y) {
        return 0.5 * x * x + 5 * y * y;
    }
    
    function gradient(x, y) {
        return [x, 10 * y];
    }
    
    // Scale setup
    const xScale = d3.scaleLinear()
        .domain([-6, 6])
        .range([margin.left, width - margin.right]);
    
    const yScale = d3.scaleLinear()
        .domain([-3, 3])
        .range([height - margin.bottom, margin.top]);
    
    // Create contour plot
    function createContours() {
        // Create a simple grid-based contour visualization
        const gridSize = 20;
        const contourLevels = [1, 4, 9, 16, 25, 36, 49];
        
        svg.selectAll(&quot;.contour&quot;).remove();
        
        // Draw contour ellipses for the function f(x,y) = 0.5*x^2 + 5*y^2
        contourLevels.forEach(level =&gt; {
            // For f(x,y) = 0.5*x^2 + 5*y^2 = level
            // This is an ellipse: x^2/(2*level) + y^2/(level/5) = 1
            const a = Math.sqrt(2 * level); // semi-major axis in x direction
            const b = Math.sqrt(level / 5); // semi-minor axis in y direction
            
            if (a &lt;= 6 &amp;&amp; b &lt;= 3) { // Only draw if within our domain
                svg.append(&quot;ellipse&quot;)
                    .attr(&quot;class&quot;, &quot;contour&quot;)
                    .attr(&quot;cx&quot;, xScale(0))
                    .attr(&quot;cy&quot;, yScale(0))
                    .attr(&quot;rx&quot;, xScale(a) - xScale(0))
                    .attr(&quot;ry&quot;, yScale(0) - yScale(b))
                    .attr(&quot;fill&quot;, &quot;none&quot;)
                    .attr(&quot;stroke&quot;, &quot;#ddd&quot;)
                    .attr(&quot;stroke-width&quot;, 1)
                    .attr(&quot;opacity&quot;, 0.6);
            }
        });
    }
    
    createContours();
    
    // Add global minimum marker
    svg.append(&quot;circle&quot;)
        .attr(&quot;cx&quot;, xScale(0))
        .attr(&quot;cy&quot;, yScale(0))
        .attr(&quot;r&quot;, 8)
        .attr(&quot;fill&quot;, &quot;red&quot;)
        .attr(&quot;stroke&quot;, &quot;white&quot;)
        .attr(&quot;stroke-width&quot;, 2)
        .attr(&quot;opacity&quot;, 0.8);
    
    svg.append(&quot;text&quot;)
        .attr(&quot;x&quot;, xScale(0))
        .attr(&quot;y&quot;, yScale(0) - 15)
        .attr(&quot;text-anchor&quot;, &quot;middle&quot;)
        .attr(&quot;font-size&quot;, &quot;12px&quot;)
        .attr(&quot;font-weight&quot;, &quot;bold&quot;)
        .attr(&quot;fill&quot;, &quot;red&quot;)
        .text(&quot;Global Minimum&quot;);
    
    // Add axes
    svg.append(&quot;g&quot;)
        .attr(&quot;transform&quot;, `translate(0,${height - margin.bottom})`)
        .call(d3.axisBottom(xScale));
    
    svg.append(&quot;g&quot;)
        .attr(&quot;transform&quot;, `translate(${margin.left},0)`)
        .call(d3.axisLeft(yScale));
    
    // Add axis labels
    svg.append(&quot;text&quot;)
        .attr(&quot;x&quot;, width / 2)
        .attr(&quot;y&quot;, height - 5)
        .attr(&quot;text-anchor&quot;, &quot;middle&quot;)
        .attr(&quot;font-size&quot;, &quot;14px&quot;)
        .text(&quot;x&quot;);
    
    svg.append(&quot;text&quot;)
        .attr(&quot;x&quot;, 15)
        .attr(&quot;y&quot;, height / 2)
        .attr(&quot;text-anchor&quot;, &quot;middle&quot;)
        .attr(&quot;font-size&quot;, &quot;14px&quot;)
        .attr(&quot;transform&quot;, `rotate(-90, 15, ${height / 2})`)
        .text(&quot;y&quot;);
    
    // Add title
    svg.append(&quot;text&quot;)
        .attr(&quot;x&quot;, width / 2)
        .attr(&quot;y&quot;, 15)
        .attr(&quot;text-anchor&quot;, &quot;middle&quot;)
        .attr(&quot;font-size&quot;, &quot;16px&quot;)
        .attr(&quot;font-weight&quot;, &quot;bold&quot;)
        .text(&quot;f(x,y) = 0.5x² + 5y² - Optimization Paths Comparison&quot;);
    
    // Variables for animation
    let vanillaPath = [], momentumPath = [];
    let vanillaRunning = false, momentumRunning = false;
    let vanillaInterval, momentumInterval;
    
    // Algorithm implementations
    function runVanillaGD() {
        const lr = parseFloat(document.getElementById(&apos;momentum-lr&apos;).value);
        let x = -4, y = 2; // Starting point
        let iteration = 0;
        const maxIterations = 500;
        vanillaPath = [{x: x, y: y}];
        vanillaRunning = true;
        
        vanillaInterval = setInterval(() =&gt; {
            const grad = gradient(x, y);
            x -= lr * grad[0];
            y -= lr * grad[1];
            vanillaPath.push({x: x, y: y});
            iteration++;
            
            updateVisualization();
            updateStatus();
            
            // Stop if converged or max iterations reached
            if ((Math.abs(grad[0]) &lt; 0.01 &amp;&amp; Math.abs(grad[1]) &lt; 0.01) || iteration &gt;= maxIterations) {
                clearInterval(vanillaInterval);
                vanillaRunning = false;
            }
        }, 1000 / parseFloat(document.getElementById(&apos;momentum-speed&apos;).value));
    }
    
    function runMomentumGD() {
        const lr = parseFloat(document.getElementById(&apos;momentum-lr&apos;).value);
        const beta = parseFloat(document.getElementById(&apos;momentum-beta&apos;).value);
        let x = -4, y = 2; // Starting point
        let vx = 0, vy = 0; // Initial velocity
        let iteration = 0;
        const maxIterations = 500;
        momentumPath = [{x: x, y: y}];
        momentumRunning = true;
        
        momentumInterval = setInterval(() =&gt; {
            const grad = gradient(x, y);
            vx = beta * vx + (1 - beta) * grad[0];
            vy = beta * vy + (1 - beta) * grad[1];
            x -= lr * vx;
            y -= lr * vy;
            momentumPath.push({x: x, y: y});
            iteration++;
            
            updateVisualization();
            updateStatus();
            
            // Stop if converged or max iterations reached
            if ((Math.abs(grad[0]) &lt; 0.01 &amp;&amp; Math.abs(grad[1]) &lt; 0.01) || iteration &gt;= maxIterations) {
                clearInterval(momentumInterval);
                momentumRunning = false;
            }
        }, 1000 / parseFloat(document.getElementById(&apos;momentum-speed&apos;).value));
    }
    
    function updateVisualization() {
        // Remove existing paths
        svg.selectAll(&quot;.vanilla-path&quot;).remove();
        svg.selectAll(&quot;.momentum-path&quot;).remove();
        svg.selectAll(&quot;.vanilla-point&quot;).remove();
        svg.selectAll(&quot;.momentum-point&quot;).remove();
        
        // Draw vanilla GD path
        if (vanillaPath.length &gt; 1) {
            const line = d3.line()
                .x(d =&gt; xScale(d.x))
                .y(d =&gt; yScale(d.y));
            
            svg.append(&quot;path&quot;)
                .datum(vanillaPath)
                .attr(&quot;class&quot;, &quot;vanilla-path&quot;)
                .attr(&quot;d&quot;, line)
                .attr(&quot;fill&quot;, &quot;none&quot;)
                .attr(&quot;stroke&quot;, &quot;#4CAF50&quot;)
                .attr(&quot;stroke-width&quot;, 2);
            
            // Current point
            const current = vanillaPath[vanillaPath.length - 1];
            svg.append(&quot;circle&quot;)
                .attr(&quot;class&quot;, &quot;vanilla-point&quot;)
                .attr(&quot;cx&quot;, xScale(current.x))
                .attr(&quot;cy&quot;, yScale(current.y))
                .attr(&quot;r&quot;, 5)
                .attr(&quot;fill&quot;, &quot;#4CAF50&quot;);
        }
        
        // Draw momentum GD path
        if (momentumPath.length &gt; 1) {
            const line = d3.line()
                .x(d =&gt; xScale(d.x))
                .y(d =&gt; yScale(d.y));
            
            svg.append(&quot;path&quot;)
                .datum(momentumPath)
                .attr(&quot;class&quot;, &quot;momentum-path&quot;)
                .attr(&quot;d&quot;, line)
                .attr(&quot;fill&quot;, &quot;none&quot;)
                .attr(&quot;stroke&quot;, &quot;#FF9800&quot;)
                .attr(&quot;stroke-width&quot;, 2);
            
            // Current point
            const current = momentumPath[momentumPath.length - 1];
            svg.append(&quot;circle&quot;)
                .attr(&quot;class&quot;, &quot;momentum-point&quot;)
                .attr(&quot;cx&quot;, xScale(current.x))
                .attr(&quot;cy&quot;, yScale(current.y))
                .attr(&quot;r&quot;, 5)
                .attr(&quot;fill&quot;, &quot;#FF9800&quot;);
        }
    }
    
    function updateStatus() {
        // Update vanilla GD status
        if (vanillaPath.length &gt; 0) {
            const current = vanillaPath[vanillaPath.length - 1];
            const fValue = f(current.x, current.y);
            document.getElementById(&apos;vanilla-gd-info&apos;).innerHTML = 
                `Iteration: ${vanillaPath.length - 1}&lt;br&gt;Position: (${current.x.toFixed(3)}, ${current.y.toFixed(3)})&lt;br&gt;f(x,y): ${fValue.toFixed(4)}`;
        }
        
        // Update momentum GD status
        if (momentumPath.length &gt; 0) {
            const current = momentumPath[momentumPath.length - 1];
            const fValue = f(current.x, current.y);
            document.getElementById(&apos;momentum-gd-info&apos;).innerHTML = 
                `Iteration: ${momentumPath.length - 1}&lt;br&gt;Position: (${current.x.toFixed(3)}, ${current.y.toFixed(3)})&lt;br&gt;f(x,y): ${fValue.toFixed(4)}`;
        }
    }
    
    // Event listeners
    document.getElementById(&apos;start-vanilla-gd&apos;).addEventListener(&apos;click&apos;, () =&gt; {
        if (!vanillaRunning) {
            vanillaRunning = true;
            runVanillaGD();
        }
    });
    
    document.getElementById(&apos;start-momentum-gd&apos;).addEventListener(&apos;click&apos;, () =&gt; {
        if (!momentumRunning) {
            momentumRunning = true;
            runMomentumGD();
        }
    });
    
    document.getElementById(&apos;start-both&apos;).addEventListener(&apos;click&apos;, () =&gt; {
        if (!vanillaRunning &amp;&amp; !momentumRunning) {
            vanillaRunning = true;
            momentumRunning = true;
            runVanillaGD();
            runMomentumGD();
        }
    });
    
    document.getElementById(&apos;reset-momentum&apos;).addEventListener(&apos;click&apos;, () =&gt; {
        clearInterval(vanillaInterval);
        clearInterval(momentumInterval);
        vanillaRunning = false;
        momentumRunning = false;
        vanillaPath = [];
        momentumPath = [];
        updateVisualization();
        document.getElementById(&apos;vanilla-gd-info&apos;).innerHTML = &apos;Ready to start&apos;;
        document.getElementById(&apos;momentum-gd-info&apos;).innerHTML = &apos;Ready to start&apos;;
    });
    
    // Update display values
    document.getElementById(&apos;momentum-lr&apos;).addEventListener(&apos;input&apos;, function() {
        document.getElementById(&apos;momentum-lr-value&apos;).textContent = this.value;
    });
    
    document.getElementById(&apos;momentum-beta&apos;).addEventListener(&apos;input&apos;, function() {
        document.getElementById(&apos;momentum-beta-value&apos;).textContent = this.value;
    });
    
    document.getElementById(&apos;momentum-speed&apos;).addEventListener(&apos;input&apos;, function() {
        document.getElementById(&apos;momentum-speed-value&apos;).textContent = this.value;
    });
});
&lt;/script&gt;

&lt;h2 id=&quot;advantages-of-momentum&quot;&gt;Advantages of Momentum&lt;/h2&gt;

&lt;h3 id=&quot;1-faster-convergence&quot;&gt;1. &lt;strong&gt;Faster Convergence&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Momentum helps the algorithm build up speed in consistent directions, leading to faster convergence especially in:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Functions with valleys or ravines&lt;/li&gt;
  &lt;li&gt;Ill-conditioned problems (high condition number)&lt;/li&gt;
  &lt;li&gt;Functions with many local minima&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-reduced-oscillations&quot;&gt;2. &lt;strong&gt;Reduced Oscillations&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;In directions where the gradient changes sign frequently, momentum helps smooth out the oscillations by averaging past gradients.&lt;/p&gt;

&lt;h3 id=&quot;3-escape-from-local-minima&quot;&gt;3. &lt;strong&gt;Escape from Local Minima&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;The accumulated momentum can help the algorithm “roll through” small local minima and continue toward better solutions.&lt;/p&gt;

&lt;h2 id=&quot;variants-and-extensions&quot;&gt;Variants and Extensions&lt;/h2&gt;

&lt;h3 id=&quot;1-nesterov-accelerated-gradient-nag&quot;&gt;1. &lt;strong&gt;Nesterov Accelerated Gradient (NAG)&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Instead of computing the gradient at the current position, NAG computes it at the “look-ahead” position:&lt;/p&gt;

\[\begin{align}
v^{(k)} &amp;amp;= \beta v^{(k-1)} + \nabla f(x^{(k-1)} - \beta v^{(k-1)}) \\
x^{(k)} &amp;amp;= x^{(k-1)} - t v^{(k)}
\end{align}\]

&lt;p&gt;&lt;strong&gt;Intuition&lt;/strong&gt;: “Look before you leap” - check the gradient at where momentum would take you.&lt;/p&gt;

&lt;h4 id=&quot;the-problem-with-regular-momentum&quot;&gt;The Problem with Regular Momentum&lt;/h4&gt;

&lt;p&gt;While momentum helps the ball overcome local minima, there’s a limitation we can observe: when approaching the target, momentum still takes considerable time before stopping. The reason is precisely because of the accumulated velocity.&lt;/p&gt;

&lt;h4 id=&quot;the-key-insight&quot;&gt;The Key Insight&lt;/h4&gt;

&lt;p&gt;The fundamental idea is to &lt;strong&gt;predict the future direction&lt;/strong&gt; - essentially looking ahead one step! Specifically, if we use the momentum term \(\beta v^{(k-1)}\) for updating, we can approximate the next position as \(x^{(k-1)} - \beta v^{(k-1)}\) (we don’t include the gradient term here as we’ll use it in the final step).&lt;/p&gt;

&lt;p&gt;Instead of using the gradient at the current position, NAG takes a step forward and uses the gradient at the anticipated next position.&lt;/p&gt;

&lt;h4 id=&quot;visual-comparison&quot;&gt;Visual Comparison&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;With regular momentum&lt;/strong&gt;: The update is the sum of two vectors:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Momentum vector (from previous step)&lt;/li&gt;
  &lt;li&gt;Gradient at the current position&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;With Nesterov momentum&lt;/strong&gt;: The update is the sum of two vectors:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Momentum vector (from previous step)&lt;/li&gt;
  &lt;li&gt;Gradient at the &lt;strong&gt;look-ahead&lt;/strong&gt; position (where momentum would take us)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This “look-ahead” approach allows NAG to make more informed corrections and often leads to faster convergence.&lt;/p&gt;

&lt;h3 id=&quot;2-adaptive-moment-estimation-adam&quot;&gt;2. &lt;strong&gt;Adaptive Moment Estimation (Adam)&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Adam combines momentum with adaptive learning rates for each parameter:&lt;/p&gt;

\[\begin{align}
m^{(k)} &amp;amp;= \beta_1 m^{(k-1)} + (1-\beta_1) \nabla f(x^{(k-1)}) \\
v^{(k)} &amp;amp;= \beta_2 v^{(k-1)} + (1-\beta_2) (\nabla f(x^{(k-1)}))^2 \\
x^{(k)} &amp;amp;= x^{(k-1)} - t \frac{m^{(k)}}{\sqrt{v^{(k)}} + \epsilon}
\end{align}\]

&lt;h2 id=&quot;practical-implementation-tips&quot;&gt;Practical Implementation Tips&lt;/h2&gt;

&lt;h3 id=&quot;1-choosing-the-momentum-coefficient&quot;&gt;1. &lt;strong&gt;Choosing the Momentum Coefficient&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Start with \(\beta = 0.9\)&lt;/strong&gt;: A good default for most problems&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Increase to \(\beta = 0.99\)&lt;/strong&gt;: For very smooth optimization landscapes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Decrease to \(\beta = 0.5-0.7\)&lt;/strong&gt;: For noisy or non-smooth functions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-learning-rate-adjustment&quot;&gt;2. &lt;strong&gt;Learning Rate Adjustment&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;When using momentum, you may need to reduce the learning rate compared to vanilla gradient descent, as momentum amplifies the effective step size.&lt;/p&gt;

&lt;h3 id=&quot;3-warm-up-period&quot;&gt;3. &lt;strong&gt;Warm-up Period&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Consider starting with lower momentum and gradually increasing it, as momentum needs time to build up effective velocity.&lt;/p&gt;

&lt;h2 id=&quot;mathematical-analysis&quot;&gt;Mathematical Analysis&lt;/h2&gt;

&lt;h3 id=&quot;convergence-properties&quot;&gt;Convergence Properties&lt;/h3&gt;

&lt;p&gt;For strongly convex functions with Lipschitz gradients, momentum gradient descent achieves:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linear convergence&lt;/strong&gt;: \(f(x^{(k)}) - f^* \leq C \rho^k\) for some \(\rho &amp;lt; 1\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Improved condition number&lt;/strong&gt;: Effective condition number can be improved from \(\kappa\) to \(\sqrt{\kappa}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heavy-ball-method-connection&quot;&gt;Heavy Ball Method Connection&lt;/h3&gt;

&lt;p&gt;Momentum gradient descent is closely related to the heavy ball method from classical mechanics:
\(mx&apos;&apos; + \gamma x&apos; + \nabla f(x) = 0\)&lt;/p&gt;

&lt;p&gt;This differential equation, when discretized, leads to the momentum update rules.&lt;/p&gt;

&lt;h2 id=&quot;comparison-summary&quot;&gt;Comparison Summary&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Aspect&lt;/th&gt;
      &lt;th&gt;Vanilla GD&lt;/th&gt;
      &lt;th&gt;Momentum GD&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Memory&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Yes (exponential decay)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Convergence&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Can be slow&lt;/td&gt;
      &lt;td&gt;Often faster&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Oscillations&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;More prone&lt;/td&gt;
      &lt;td&gt;Reduced&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Local minima&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;May get stuck&lt;/td&gt;
      &lt;td&gt;Better escape&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Hyperparameters&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Learning rate&lt;/td&gt;
      &lt;td&gt;Learning rate + momentum&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Computational cost&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Low&lt;/td&gt;
      &lt;td&gt;Slightly higher&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Momentum adds memory&lt;/strong&gt;: It remembers the direction of previous steps&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Faster convergence&lt;/strong&gt;: Especially effective for functions with valleys or ravines&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reduced oscillations&lt;/strong&gt;: Smooths out zigzag behavior&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Widely used&lt;/strong&gt;: Foundation for many modern optimization algorithms&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tunable&lt;/strong&gt;: The momentum coefficient \(\beta\) allows fine-tuning for different problems&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Bottom line&lt;/strong&gt;: Momentum is a simple yet powerful enhancement to gradient descent that has stood the test of time and remains relevant in modern machine learning applications.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-05 Stochastic gradient descent</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_05_stochastic_gradient_descent/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_05_stochastic_gradient_descent</id>
   <content type="html">&lt;script src=&quot;../../../public/js/script.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://d3js.org/d3.v7.min.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;motivation-the-big-data-challenge&quot;&gt;Motivation: The Big Data Challenge&lt;/h2&gt;

&lt;p&gt;Imagine you’re training a machine learning model on millions of data points. Traditional gradient descent requires computing gradients for &lt;strong&gt;all&lt;/strong&gt; data points before making a single update. This becomes computationally expensive and memory-intensive for large datasets.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: What if we could make progress by looking at just one data point at a time?&lt;/p&gt;

&lt;h2 id=&quot;the-mathematical-foundation&quot;&gt;The Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;Consider the optimization problem of minimizing a sum of functions:&lt;/p&gt;

\[\begin{equation}
\min_x f(x) = \min_x \sum_{i=1}^m f_i(x)
\end{equation}\]

&lt;p&gt;&lt;strong&gt;Real-world interpretation&lt;/strong&gt;: In machine learning, \(f_i(x)\) often represents the loss on the \(i\)-th training example, where \(x\) are the model parameters.&lt;/p&gt;

&lt;h3 id=&quot;batch-gradient-descent-traditional-approach&quot;&gt;Batch Gradient Descent (Traditional Approach)&lt;/h3&gt;

&lt;p&gt;The gradient of the sum equals the sum of gradients:
\(\nabla f(x) = \nabla \sum_{i=1}^m f_i(x) = \sum_{i=1}^m \nabla f_i(x)\)&lt;/p&gt;

&lt;p&gt;The update rule becomes:
\(\begin{equation}
x^{(k)} = x^{(k-1)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k-1)}), \,  k=1,2,3,\dots
\end{equation}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computational cost&lt;/strong&gt;: \(O(m)\) gradient evaluations per iteration, where \(m\) is the number of functions (or data points).&lt;/p&gt;

&lt;h2 id=&quot;stochastic-gradient-descent-the-efficient-alternative&quot;&gt;Stochastic Gradient Descent: The Efficient Alternative&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Key Insight&lt;/strong&gt;: Instead of computing gradients for all \(m\) functions, SGD uses only &lt;strong&gt;one&lt;/strong&gt; function at each iteration.&lt;/p&gt;

\[\begin{equation}
x^{(k)} = x^{(k-1)} - t_k \cdot \nabla f_{i_k} (x^{(k-1)}), \quad i_k \in \{1,2,\dots,m\}
\end{equation}\]

&lt;p&gt;&lt;strong&gt;Computational cost&lt;/strong&gt;: \(O(1)\) gradient evaluation per iteration - a massive improvement!&lt;/p&gt;

&lt;h3 id=&quot;interactive-visualization-gd-vs-sgd-with-step-control&quot;&gt;Interactive Visualization: GD vs SGD with Step Control&lt;/h3&gt;

&lt;div id=&quot;gd-sgd-comparison&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;!-- Parameter Controls --&gt;
    &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px; margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;&quot;&gt;
        &lt;div&gt;
            &lt;label for=&quot;learning-rate&quot;&gt;Learning Rate: &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;learning-rate&quot; min=&quot;0.01&quot; max=&quot;0.5&quot; step=&quot;0.01&quot; value=&quot;0.1&quot; /&gt;
            &lt;span id=&quot;lr-value&quot;&gt;0.1&lt;/span&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;label for=&quot;num-functions&quot;&gt;Number of Functions (m): &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;num-functions&quot; min=&quot;3&quot; max=&quot;10&quot; step=&quot;1&quot; value=&quot;5&quot; /&gt;
            &lt;span id=&quot;m-value&quot;&gt;5&lt;/span&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;label for=&quot;animation-speed&quot;&gt;Animation Speed: &lt;/label&gt;
            &lt;input type=&quot;range&quot; id=&quot;animation-speed&quot; min=&quot;1&quot; max=&quot;10&quot; step=&quot;1&quot; value=&quot;5&quot; /&gt;
            &lt;span id=&quot;speed-value&quot;&gt;5&lt;/span&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;!-- Execution Mode Selection --&gt;
    &lt;div style=&quot;margin-bottom: 15px; padding: 10px; border: 1px solid #ddd; border-radius: 5px; background-color: #f0f8ff;&quot;&gt;
        &lt;h4 style=&quot;margin: 0 0 10px 0;&quot;&gt;Execution Mode:&lt;/h4&gt;
        &lt;div style=&quot;display: flex; gap: 15px;&quot;&gt;
            &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;exec-mode&quot; value=&quot;auto&quot; checked=&quot;&quot; /&gt; Auto Run&lt;/label&gt;
            &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;exec-mode&quot; value=&quot;manual&quot; /&gt; Manual Step-by-Step&lt;/label&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;!-- Control Buttons --&gt;
    &lt;div style=&quot;display: flex; gap: 10px; margin-bottom: 15px; flex-wrap: wrap;&quot;&gt;
        &lt;button id=&quot;start-gd&quot; style=&quot;background-color: #4CAF50; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Start Gradient Descent&lt;/button&gt;
        &lt;button id=&quot;start-sgd&quot; style=&quot;background-color: #FF9800; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Start SGD&lt;/button&gt;
        &lt;button id=&quot;pause-resume&quot; style=&quot;background-color: #2196F3; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot; disabled=&quot;&quot;&gt;Pause&lt;/button&gt;
        &lt;button id=&quot;step-forward&quot; style=&quot;background-color: #9C27B0; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot; disabled=&quot;&quot;&gt;Step Forward&lt;/button&gt;
        &lt;button id=&quot;reset-demo&quot; style=&quot;background-color: #f44336; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Reset&lt;/button&gt;
    &lt;/div&gt;
    
    &lt;!-- Algorithm Status --&gt;
    &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 15px;&quot;&gt;
        &lt;div style=&quot;padding: 10px; border: 1px solid #4CAF50; border-radius: 5px; background-color: #f1f8e9;&quot;&gt;
            &lt;h4 style=&quot;margin: 0 0 5px 0; color: #4CAF50;&quot;&gt;Gradient Descent Status&lt;/h4&gt;
            &lt;p id=&quot;gd-detailed-info&quot; style=&quot;margin: 0; font-size: 14px;&quot;&gt;Ready to start&lt;/p&gt;
        &lt;/div&gt;
        &lt;div style=&quot;padding: 10px; border: 1px solid #FF9800; border-radius: 5px; background-color: #fff8e1;&quot;&gt;
            &lt;h4 style=&quot;margin: 0 0 5px 0; color: #FF9800;&quot;&gt;SGD Status&lt;/h4&gt;
            &lt;p id=&quot;sgd-detailed-info&quot; style=&quot;margin: 0; font-size: 14px;&quot;&gt;Ready to start&lt;/p&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;!-- Visualization Plots --&gt;
    &lt;div style=&quot;display: flex; gap: 20px; justify-content: center;&quot;&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Gradient Descent (Batch)&lt;/h4&gt;
            &lt;svg id=&quot;gd-plot&quot; width=&quot;350&quot; height=&quot;350&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;gd-info&quot; style=&quot;margin: 0; font-weight: bold;&quot;&gt;Iterations: 0, Cost: 0&lt;/p&gt;
                &lt;p id=&quot;gd-gradient-info&quot; style=&quot;margin: 5px 0 0 0; font-size: 12px; color: #666;&quot;&gt;Gradient: [0, 0]&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
        &lt;div style=&quot;text-align: center;&quot;&gt;
            &lt;h4&gt;Stochastic Gradient Descent&lt;/h4&gt;
            &lt;svg id=&quot;sgd-plot&quot; width=&quot;350&quot; height=&quot;350&quot; style=&quot;border: 1px solid #ddd;&quot;&gt;&lt;/svg&gt;
            &lt;div style=&quot;margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;&quot;&gt;
                &lt;p id=&quot;sgd-info&quot; style=&quot;margin: 0; font-weight: bold;&quot;&gt;Iterations: 0, Cost: 0&lt;/p&gt;
                &lt;p id=&quot;sgd-gradient-info&quot; style=&quot;margin: 5px 0 0 0; font-size: 12px; color: #666;&quot;&gt;Selected Function: -, Gradient: [0, 0]&lt;/p&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    
    &lt;!-- Progress Visualization --&gt;
    &lt;div style=&quot;margin-top: 20px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #fafafa;&quot;&gt;
        &lt;h4&gt;Convergence Progress&lt;/h4&gt;
        &lt;div style=&quot;display: flex; gap: 20px;&quot;&gt;
            &lt;div style=&quot;flex: 1;&quot;&gt;
                &lt;p&gt;&lt;strong&gt;GD Progress:&lt;/strong&gt;&lt;/p&gt;
                &lt;div style=&quot;width: 100%; background-color: #e0e0e0; border-radius: 10px; height: 20px;&quot;&gt;
                    &lt;div id=&quot;gd-progress&quot; style=&quot;width: 0%; background-color: #4CAF50; height: 100%; border-radius: 10px; transition: width 0.3s;&quot;&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            &lt;div style=&quot;flex: 1;&quot;&gt;
                &lt;p&gt;&lt;strong&gt;SGD Progress:&lt;/strong&gt;&lt;/p&gt;
                &lt;div style=&quot;width: 100%; background-color: #e0e0e0; border-radius: 10px; height: 20px;&quot;&gt;
                    &lt;div id=&quot;sgd-progress&quot; style=&quot;width: 0%; background-color: #FF9800; height: 100%; border-radius: 10px; transition: width 0.3s;&quot;&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;selection-strategies-for-sgd&quot;&gt;Selection Strategies for SGD&lt;/h3&gt;

&lt;p&gt;The function index \(i_k\) can be selected using different strategies:&lt;/p&gt;

&lt;h4 id=&quot;1-cyclic-rule&quot;&gt;1. Cyclic Rule&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Pattern&lt;/strong&gt;: \(i_k = 1,2,\dots,m, 1,2,\dots,m, \ldots\)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Advantages&lt;/strong&gt;: Deterministic, ensures all functions are visited&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;: May get stuck in periodic patterns&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-randomized-rule&quot;&gt;2. Randomized Rule&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Pattern&lt;/strong&gt;: \(i_k\) chosen uniformly at random from \(\{1,2,\dots,m\}\)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Advantages&lt;/strong&gt;: Avoids periodic patterns, better theoretical guarantees&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Disadvantages&lt;/strong&gt;: Some functions may be visited more frequently than others&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In practice&lt;/strong&gt;: Randomized selection is preferred due to better convergence properties and ability to escape local patterns.&lt;/p&gt;

&lt;h2 id=&quot;convergence-analysis-theory-vs-practice&quot;&gt;Convergence Analysis: Theory vs Practice&lt;/h2&gt;

&lt;h3 id=&quot;mathematical-comparison&quot;&gt;Mathematical Comparison&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Batch GD (one epoch)&lt;/strong&gt;: 
\(x^{(k+1)} = x^{(k)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k)})\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SGD (one epoch with cyclic rule)&lt;/strong&gt;:
\(x^{(k+m)} = x^{(k)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k+i-1)})\)&lt;/p&gt;

&lt;h3 id=&quot;understanding-the-sgd-cyclic-rule-formula&quot;&gt;Understanding the SGD Cyclic Rule Formula&lt;/h3&gt;

&lt;p&gt;Let’s break down this formula step by step to understand what happens during one complete epoch of SGD with cyclic rule:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is an epoch?&lt;/strong&gt; One epoch means we’ve processed all \(m\) functions exactly once.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The cyclic rule process:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Start at position \(x^{(k)}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: Use function \(f_1\), compute \(\nabla f_1(x^{(k)})\), update to \(x^{(k+1)}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: Use function \(f_2\), compute \(\nabla f_2(x^{(k+1)})\), update to \(x^{(k+2)}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 3&lt;/strong&gt;: Use function \(f_3\), compute \(\nabla f_3(x^{(k+2)})\), update to \(x^{(k+3)}\)&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step m&lt;/strong&gt;: Use function \(f_m\), compute \(\nabla f_m(x^{(k+m-1)})\), update to \(x^{(k+m)}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Individual SGD updates:&lt;/strong&gt;
\(\begin{align}
x^{(k+1)} &amp;amp;= x^{(k)} - t_k \nabla f_1(x^{(k)}) \\
x^{(k+2)} &amp;amp;= x^{(k+1)} - t_k \nabla f_2(x^{(k+1)}) \\
x^{(k+3)} &amp;amp;= x^{(k+2)} - t_k \nabla f_3(x^{(k+2)}) \\
&amp;amp;\vdots \\
x^{(k+m)} &amp;amp;= x^{(k+m-1)} - t_k \nabla f_m(x^{(k+m-1)})
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Telescoping the updates:&lt;/strong&gt;
If we substitute recursively and collect all terms, we get:
\(x^{(k+m)} = x^{(k)} - t_k \left[ \nabla f_1(x^{(k)}) + \nabla f_2(x^{(k+1)}) + \cdots + \nabla f_m(x^{(k+m-1)}) \right]\)&lt;/p&gt;

&lt;p&gt;This can be written compactly as:
\(x^{(k+m)} = x^{(k)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k+i-1)})\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key insight:&lt;/strong&gt; Each gradient \(\nabla f_i\) is evaluated at a &lt;strong&gt;different&lt;/strong&gt; position \(x^{(k+i-1)}\), not at the same starting position \(x^{(k)}\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key difference in update directions&lt;/strong&gt;:
\(\sum_{i=1}^{m}[ \nabla f_i (x^{(k+i-1)}) - \nabla f_i (x^{(k)})]\)&lt;/p&gt;

&lt;p&gt;This difference represents how much the SGD path deviates from what batch GD would do. If the functions don’t change much locally (Lipschitz continuous gradients), this difference is small and SGD behaves similarly to batch GD.&lt;/p&gt;

&lt;h3 id=&quot;concrete-example-with-m--3-functions&quot;&gt;Concrete Example with m = 3 Functions&lt;/h3&gt;

&lt;p&gt;Let’s illustrate with \(m = 3\) functions to make this crystal clear:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Starting position:&lt;/strong&gt; \(x^{(k)} = [1, 2]\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SGD Cyclic Rule Process:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Use \(f_1\)&lt;/strong&gt;: Compute \(\nabla f_1(x^{(k)}) = \nabla f_1([1,2])\), update:
\(x^{(k+1)} = x^{(k)} - t_k \nabla f_1(x^{(k)}) = [1,2] - t_k \nabla f_1([1,2])\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Use \(f_2\)&lt;/strong&gt;: Compute \(\nabla f_2(x^{(k+1)})\) at the &lt;strong&gt;new&lt;/strong&gt; position, update:
\(x^{(k+2)} = x^{(k+1)} - t_k \nabla f_2(x^{(k+1)})\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Use \(f_3\)&lt;/strong&gt;: Compute \(\nabla f_3(x^{(k+2)})\) at the &lt;strong&gt;newest&lt;/strong&gt; position, update:
\(x^{(k+3)} = x^{(k+2)} - t_k \nabla f_3(x^{(k+2)})\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Final SGD result after one epoch:&lt;/strong&gt;
\(x^{(k+3)} = x^{(k)} - t_k[\nabla f_1(x^{(k)}) + \nabla f_2(x^{(k+1)}) + \nabla f_3(x^{(k+2)})]\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Compare with Batch GD:&lt;/strong&gt;
\(x^{(k+1)} = x^{(k)} - t_k[\nabla f_1(x^{(k)}) + \nabla f_2(x^{(k)}) + \nabla f_3(x^{(k)})]\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The crucial difference:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Batch GD&lt;/strong&gt;: All gradients evaluated at the &lt;strong&gt;same&lt;/strong&gt; starting point \(x^{(k)}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SGD&lt;/strong&gt;: Each gradient evaluated at a &lt;strong&gt;different&lt;/strong&gt; point along the optimization path&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is why SGD can make faster initial progress (it’s already “exploring” the landscape) but can be noisier near the optimum.&lt;/p&gt;

&lt;h3 id=&quot;convergence-properties&quot;&gt;Convergence Properties&lt;/h3&gt;

&lt;div id=&quot;convergence-analysis&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr; gap: 20px;&quot;&gt;
        &lt;div style=&quot;border: 1px solid #ddd; padding: 15px; border-radius: 5px;&quot;&gt;
            &lt;h4&gt;Batch Gradient Descent&lt;/h4&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Direction&lt;/strong&gt;: Always in steepest descent direction&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Convergence&lt;/strong&gt;: Smooth, monotonic decrease&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Slower per epoch, but stable&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: Requires full dataset in memory&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;
        &lt;div style=&quot;border: 1px solid #ddd; padding: 15px; border-radius: 5px;&quot;&gt;
            &lt;h4&gt;Stochastic Gradient Descent&lt;/h4&gt;
            &lt;ul&gt;
                &lt;li&gt;&lt;strong&gt;Direction&lt;/strong&gt;: Noisy, approximate descent direction&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Convergence&lt;/strong&gt;: Oscillatory, but faster initial progress&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Faster per epoch, especially for large datasets&lt;/li&gt;
                &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: Processes one sample at a time&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;theoretical-guarantees&quot;&gt;Theoretical Guarantees&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Lipschitz Continuity Condition&lt;/strong&gt;: If \(\nabla f_i(x)\) is Lipschitz continuous with constant \(L\):
\(\|\nabla f_i(x) - \nabla f_i(y)\| \leq L \|x - y\|\)&lt;/p&gt;

&lt;p&gt;Then SGD converges to the same optimal solution as batch GD, provided the learning rate satisfies appropriate conditions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Practical Observation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;SGD excels in the &lt;strong&gt;exploration phase&lt;/strong&gt; (far from optimum)&lt;/li&gt;
  &lt;li&gt;SGD struggles in the &lt;strong&gt;exploitation phase&lt;/strong&gt; (near optimum) due to noise&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mini-batch-gradient-descent-the-best-of-both-worlds&quot;&gt;Mini-Batch Gradient Descent: The Best of Both Worlds&lt;/h2&gt;

&lt;p&gt;A compromise between batch GD and SGD uses &lt;strong&gt;mini-batches&lt;/strong&gt; of size \(b\):&lt;/p&gt;

\[x^{(k)} = x^{(k-1)} - t_k \cdot \frac{1}{b} \sum_{i \in \mathcal{B}_k} \nabla f_i (x^{(k-1)})\]

&lt;p&gt;where \(\mathcal{B}_k\) is a mini-batch of \(b\) randomly selected indices.&lt;/p&gt;

&lt;div id=&quot;minibatch-comparison&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;h4&gt;Comparison: Batch vs Mini-batch vs SGD&lt;/h4&gt;
    &lt;table style=&quot;width: 100%; border-collapse: collapse; margin: 15px 0;&quot;&gt;
        &lt;thead&gt;
            &lt;tr style=&quot;background-color: #f5f5f5;&quot;&gt;
                &lt;th style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Method&lt;/th&gt;
                &lt;th style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Batch Size&lt;/th&gt;
                &lt;th style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Computation/Update&lt;/th&gt;
                &lt;th style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Convergence&lt;/th&gt;
                &lt;th style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Memory Usage&lt;/th&gt;
            &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
            &lt;tr&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;&lt;strong&gt;Batch GD&lt;/strong&gt;&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;$$m$$ (full dataset)&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;$$O(m)$$&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Smooth, stable&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;High&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;&lt;strong&gt;Mini-batch GD&lt;/strong&gt;&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;$$b$$ (typically 32-256)&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;$$O(b)$$&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Balanced&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Medium&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;&lt;strong&gt;SGD&lt;/strong&gt;&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;1&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;$$O(1)$$&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Fast but noisy&lt;/td&gt;
                &lt;td style=&quot;border: 1px solid #ddd; padding: 10px;&quot;&gt;Low&lt;/td&gt;
            &lt;/tr&gt;
        &lt;/tbody&gt;
    &lt;/table&gt;
&lt;/div&gt;

&lt;h2 id=&quot;key-takeaways-and-practical-insights&quot;&gt;Key Takeaways and Practical Insights&lt;/h2&gt;

&lt;h3 id=&quot;when-to-use-sgd&quot;&gt;When to Use SGD&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Large datasets&lt;/strong&gt; (millions of samples)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Online learning&lt;/strong&gt; scenarios&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Limited memory&lt;/strong&gt; environments&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Early training phases&lt;/strong&gt; for quick progress&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;when-to-use-batch-gd&quot;&gt;When to Use Batch GD&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Small to medium datasets&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;High precision requirements&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stable convergence needed&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Final fine-tuning phases&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;best-practices&quot;&gt;Best Practices&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Learning rate scheduling&lt;/strong&gt;: Start high, decay over time&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Shuffling&lt;/strong&gt;: Randomize data order each epoch&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mini-batches&lt;/strong&gt;: Often the best practical choice&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Momentum&lt;/strong&gt;: Helps SGD overcome noise and accelerate convergence&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Modern reality&lt;/strong&gt;: Most deep learning frameworks use mini-batch SGD with sophisticated optimizers (Adam, RMSprop) that adapt the learning rate automatically.&lt;/p&gt;

&lt;script&gt;
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    // Global variables for demos
    let gdData = [], sgdData = [];
    let gdPosition = [2, 2], sgdPosition = [2, 2];
    let isRunning = false;
    let isPaused = false;
    let isManualMode = false;
    let animationId;
    let currentAlgorithm = null; // &apos;gd&apos; or &apos;sgd&apos;
    let algorithmState = {
        gd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0] },
        sgd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0], selectedFunc: -1 }
    };
    
    // Initialize sliders
    const learningRateSlider = document.getElementById(&apos;learning-rate&apos;);
    const numFunctionsSlider = document.getElementById(&apos;num-functions&apos;);
    const animationSpeedSlider = document.getElementById(&apos;animation-speed&apos;);
    const lrValue = document.getElementById(&apos;lr-value&apos;);
    const mValue = document.getElementById(&apos;m-value&apos;);
    const speedValue = document.getElementById(&apos;speed-value&apos;);
    
    if (learningRateSlider) {
        learningRateSlider.addEventListener(&apos;input&apos;, function() {
            lrValue.textContent = this.value;
        });
    }
    
    if (numFunctionsSlider) {
        numFunctionsSlider.addEventListener(&apos;input&apos;, function() {
            mValue.textContent = this.value;
        });
    }
    
    if (animationSpeedSlider) {
        animationSpeedSlider.addEventListener(&apos;input&apos;, function() {
            speedValue.textContent = this.value;
        });
    }
    
    // Execution mode radio buttons
    const execModeRadios = document.querySelectorAll(&apos;input[name=&quot;exec-mode&quot;]&apos;);
    execModeRadios.forEach(radio =&gt; {
        radio.addEventListener(&apos;change&apos;, function() {
            isManualMode = this.value === &apos;manual&apos;;
            updateControlButtons();
        });
    });
    
    // Simple quadratic functions for demonstration
    function createFunctions(m) {
        const functions = [];
        for (let i = 0; i &lt; m; i++) {
            const centerX = (Math.random() - 0.5) * 4;
            const centerY = (Math.random() - 0.5) * 4;
            functions.push({
                center: [centerX, centerY],
                gradient: function(x, y) {
                    return [2 * (x - centerX), 2 * (y - centerY)];
                },
                value: function(x, y) {
                    return (x - centerX) ** 2 + (y - centerY) ** 2;
                }
            });
        }
        return functions;
    }
    
    // Setup SVG plots
    function setupPlot(svgId, width = 300, height = 300) {
        const svg = d3.select(`#${svgId}`);
        if (svg.empty()) return null;
        
        svg.selectAll(&quot;*&quot;).remove();
        
        const margin = {top: 20, right: 20, bottom: 30, left: 40};
        const plotWidth = width - margin.left - margin.right;
        const plotHeight = height - margin.top - margin.bottom;
        
        const xScale = d3.scaleLinear()
            .domain([-3, 3])
            .range([0, plotWidth]);
            
        const yScale = d3.scaleLinear()
            .domain([-3, 3])
            .range([plotHeight, 0]);
        
        const g = svg.append(&quot;g&quot;)
            .attr(&quot;transform&quot;, `translate(${margin.left},${margin.top})`);
        
        // Add axes
        g.append(&quot;g&quot;)
            .attr(&quot;transform&quot;, `translate(0,${plotHeight})`)
            .call(d3.axisBottom(xScale));
            
        g.append(&quot;g&quot;)
            .call(d3.axisLeft(yScale));
        
        // Add contour background
        const contourData = [];
        for (let i = 0; i &lt; 20; i++) {
            for (let j = 0; j &lt; 20; j++) {
                const x = -3 + (i / 19) * 6;
                const y = -3 + (j / 19) * 6;
                contourData.push({x, y, z: x*x + y*y});
            }
        }
        
        return {svg, g, xScale, yScale, plotWidth, plotHeight};
    }
    
    // Control button functions
    function updateControlButtons() {
        const pauseResumeBtn = document.getElementById(&apos;pause-resume&apos;);
        const stepForwardBtn = document.getElementById(&apos;step-forward&apos;);
        
        if (pauseResumeBtn) {
            pauseResumeBtn.disabled = !isRunning;
            pauseResumeBtn.textContent = isPaused ? &apos;Resume&apos; : &apos;Pause&apos;;
        }
        
        if (stepForwardBtn) {
            stepForwardBtn.disabled = !isManualMode &amp;&amp; !isPaused;
        }
    }
    
    // GD vs SGD Comparison Demo
    const startGDBtn = document.getElementById(&apos;start-gd&apos;);
    const startSGDBtn = document.getElementById(&apos;start-sgd&apos;);
    const pauseResumeBtn = document.getElementById(&apos;pause-resume&apos;);
    const stepForwardBtn = document.getElementById(&apos;step-forward&apos;);
    const resetBtn = document.getElementById(&apos;reset-demo&apos;);
    
    if (startGDBtn) {
        startGDBtn.addEventListener(&apos;click&apos;, function() {
            if (isRunning &amp;&amp; currentAlgorithm === &apos;gd&apos;) return;
            initializeAlgorithm(&apos;gd&apos;);
            if (!isManualMode) {
                runAlgorithm(&apos;gd&apos;);
            }
        });
    }
    
    if (startSGDBtn) {
        startSGDBtn.addEventListener(&apos;click&apos;, function() {
            if (isRunning &amp;&amp; currentAlgorithm === &apos;sgd&apos;) return;
            initializeAlgorithm(&apos;sgd&apos;);
            if (!isManualMode) {
                runAlgorithm(&apos;sgd&apos;);
            }
        });
    }
    
    if (pauseResumeBtn) {
        pauseResumeBtn.addEventListener(&apos;click&apos;, function() {
            if (isPaused) {
                isPaused = false;
                if (currentAlgorithm) {
                    runAlgorithm(currentAlgorithm);
                }
            } else {
                isPaused = true;
                if (animationId) {
                    cancelAnimationFrame(animationId);
                }
            }
            updateControlButtons();
        });
    }
    
    if (stepForwardBtn) {
        stepForwardBtn.addEventListener(&apos;click&apos;, function() {
            if (currentAlgorithm &amp;&amp; (isManualMode || isPaused)) {
                performSingleStep(currentAlgorithm);
            }
        });
    }
    
    if (resetBtn) {
        resetBtn.addEventListener(&apos;click&apos;, function() {
            resetDemo();
        });
    }
    
    // Initialize algorithm state
    function initializeAlgorithm(algorithm) {
        const m = parseInt(numFunctionsSlider.value);
        const functions = createFunctions(m);
        
        algorithmState[algorithm] = {
            iteration: 0,
            position: [2, 2],
            path: [[2, 2]],
            functions: functions,
            totalCost: 0,
            gradient: [0, 0],
            selectedFunc: algorithm === &apos;sgd&apos; ? -1 : undefined
        };
        
        currentAlgorithm = algorithm;
        isRunning = true;
        isPaused = false;
        
        // Setup plot
        const plotId = algorithm === &apos;gd&apos; ? &apos;gd-plot&apos; : &apos;sgd-plot&apos;;
        const plot = setupPlot(plotId, 350, 350);
        
        // Update status
        updateAlgorithmDisplay(algorithm);
        updateControlButtons();
        
        // Update detailed info
        const detailedInfoId = algorithm === &apos;gd&apos; ? &apos;gd-detailed-info&apos; : &apos;sgd-detailed-info&apos;;
        document.getElementById(detailedInfoId).textContent = 
            isManualMode ? &apos;Ready for manual stepping&apos; : &apos;Running automatically...&apos;;
    }
    
    // Run algorithm in auto mode
    function runAlgorithm(algorithm) {
        if (isPaused || isManualMode) return;
        
        const speed = parseInt(animationSpeedSlider.value);
        const delay = 1100 - speed * 100; // Convert speed to delay (higher speed = lower delay)
        
        function step() {
            if (isPaused || !isRunning) return;
            
            const shouldContinue = performSingleStep(algorithm);
            
            if (shouldContinue &amp;&amp; !isPaused) {
                setTimeout(() =&gt; {
                    animationId = requestAnimationFrame(step);
                }, delay);
            } else {
                isRunning = false;
                updateControlButtons();
                
                const detailedInfoId = algorithm === &apos;gd&apos; ? &apos;gd-detailed-info&apos; : &apos;sgd-detailed-info&apos;;
                document.getElementById(detailedInfoId).textContent = &apos;Converged!&apos;;
            }
        }
        
        step();
    }
    
    // Perform a single step of the algorithm
    function performSingleStep(algorithm) {
        const state = algorithmState[algorithm];
        const lr = parseFloat(learningRateSlider.value);
        
        if (algorithm === &apos;gd&apos;) {
            return performGDStep(state, lr);
        } else {
            return performSGDStep(state, lr);
        }
    }
    
    function performGDStep(state, lr) {
        // Compute full gradient (sum of all function gradients)
        let gradX = 0, gradY = 0;
        for (const func of state.functions) {
            const grad = func.gradient(state.position[0], state.position[1]);
            gradX += grad[0];
            gradY += grad[1];
        }
        
        // Average the gradients
        gradX /= state.functions.length;
        gradY /= state.functions.length;
        
        state.gradient = [gradX, gradY];
        
        // Update position
        state.position[0] -= lr * gradX;
        state.position[1] -= lr * gradY;
        state.path.push(state.position.slice());
        
        // Compute total cost
        state.totalCost = 0;
        for (const func of state.functions) {
            state.totalCost += func.value(state.position[0], state.position[1]);
        }
        state.totalCost /= state.functions.length;
        
        state.iteration++;
        
        // Update visualization
        updateAlgorithmDisplay(&apos;gd&apos;);
        
        // Check convergence
        const gradientMagnitude = Math.sqrt(gradX * gradX + gradY * gradY);
        return state.iteration &lt; 100 &amp;&amp; gradientMagnitude &gt; 0.01;
    }
    
    function performSGDStep(state, lr) {
        // Select random function
        const funcIndex = Math.floor(Math.random() * state.functions.length);
        const func = state.functions[funcIndex];
        state.selectedFunc = funcIndex;
        
        // Compute gradient for selected function only
        const grad = func.gradient(state.position[0], state.position[1]);
        state.gradient = grad;
        
        // Update position
        state.position[0] -= lr * grad[0];
        state.position[1] -= lr * grad[1];
        state.path.push(state.position.slice());
        
        // Compute total cost
        state.totalCost = 0;
        for (const func of state.functions) {
            state.totalCost += func.value(state.position[0], state.position[1]);
        }
        state.totalCost /= state.functions.length;
        
        state.iteration++;
        
        // Update visualization
        updateAlgorithmDisplay(&apos;sgd&apos;);
        
        // Check convergence (SGD needs more iterations)
        return state.iteration &lt; 300 &amp;&amp; state.totalCost &gt; 0.01;
    }
    
    function updateAlgorithmDisplay(algorithm) {
        const state = algorithmState[algorithm];
        const plotId = algorithm === &apos;gd&apos; ? &apos;gd-plot&apos; : &apos;sgd-plot&apos;;
        const color = algorithm === &apos;gd&apos; ? &apos;steelblue&apos; : &apos;orange&apos;;
        
        // Update path visualization
        const plot = {
            svg: d3.select(`#${plotId}`),
            g: d3.select(`#${plotId} g`),
            xScale: d3.scaleLinear().domain([-3, 3]).range([0, 270]),
            yScale: d3.scaleLinear().domain([-3, 3]).range([270, 0])
        };
        
        if (!plot.g.empty()) {
            updatePath(plot, state.path, color);
        }
        
        // Update info displays
        const infoId = algorithm === &apos;gd&apos; ? &apos;gd-info&apos; : &apos;sgd-info&apos;;
        const gradientInfoId = algorithm === &apos;gd&apos; ? &apos;gd-gradient-info&apos; : &apos;sgd-gradient-info&apos;;
        
        document.getElementById(infoId).textContent = 
            `Iterations: ${state.iteration}, Cost: ${state.totalCost.toFixed(4)}`;
        
        if (algorithm === &apos;gd&apos;) {
            document.getElementById(gradientInfoId).textContent = 
                `Gradient: [${state.gradient[0].toFixed(3)}, ${state.gradient[1].toFixed(3)}]`;
        } else {
            document.getElementById(gradientInfoId).textContent = 
                `Selected Function: f${state.selectedFunc + 1}, Gradient: [${state.gradient[0].toFixed(3)}, ${state.gradient[1].toFixed(3)}]`;
        }
        
        // Update progress bar
        const progressId = algorithm === &apos;gd&apos; ? &apos;gd-progress&apos; : &apos;sgd-progress&apos;;
        const maxIterations = algorithm === &apos;gd&apos; ? 100 : 300;
        const progress = Math.min((state.iteration / maxIterations) * 100, 100);
        document.getElementById(progressId).style.width = `${progress}%`;
        
        // Update detailed status
        const detailedInfoId = algorithm === &apos;gd&apos; ? &apos;gd-detailed-info&apos; : &apos;sgd-detailed-info&apos;;
        const gradMagnitude = Math.sqrt(state.gradient[0] ** 2 + state.gradient[1] ** 2);
        document.getElementById(detailedInfoId).textContent = 
            `Step ${state.iteration}: Position [${state.position[0].toFixed(3)}, ${state.position[1].toFixed(3)}], |∇| = ${gradMagnitude.toFixed(4)}`;
    }
    
    function updatePath(plot, path, color) {
        const line = d3.line()
            .x(d =&gt; plot.xScale(d[0]))
            .y(d =&gt; plot.yScale(d[1]));
        
        plot.g.selectAll(&apos;.path&apos;).remove();
        plot.g.append(&apos;path&apos;)
            .datum(path)
            .attr(&apos;class&apos;, &apos;path&apos;)
            .attr(&apos;fill&apos;, &apos;none&apos;)
            .attr(&apos;stroke&apos;, color)
            .attr(&apos;stroke-width&apos;, 2)
            .attr(&apos;d&apos;, line);
        
        // Add current position
        const current = path[path.length - 1];
        plot.g.selectAll(&apos;.current-pos&apos;).remove();
        plot.g.append(&apos;circle&apos;)
            .attr(&apos;class&apos;, &apos;current-pos&apos;)
            .attr(&apos;cx&apos;, plot.xScale(current[0]))
            .attr(&apos;cy&apos;, plot.yScale(current[1]))
            .attr(&apos;r&apos;, 5)
            .attr(&apos;fill&apos;, color);
    }
    
    function resetDemo() {
        if (animationId) {
            cancelAnimationFrame(animationId);
        }
        
        isRunning = false;
        isPaused = false;
        currentAlgorithm = null;
        
        // Reset algorithm states
        algorithmState = {
            gd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0] },
            sgd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0], selectedFunc: -1 }
        };
        
        // Clear plots
        d3.select(&apos;#gd-plot&apos;).selectAll(&quot;*&quot;).remove();
        d3.select(&apos;#sgd-plot&apos;).selectAll(&quot;*&quot;).remove();
        
        // Reset info displays
        document.getElementById(&apos;gd-info&apos;).textContent = &apos;Iterations: 0, Cost: 0&apos;;
        document.getElementById(&apos;sgd-info&apos;).textContent = &apos;Iterations: 0, Cost: 0&apos;;
        document.getElementById(&apos;gd-gradient-info&apos;).textContent = &apos;Gradient: [0, 0]&apos;;
        document.getElementById(&apos;sgd-gradient-info&apos;).textContent = &apos;Selected Function: -, Gradient: [0, 0]&apos;;
        
        // Reset detailed info
        document.getElementById(&apos;gd-detailed-info&apos;).textContent = &apos;Ready to start&apos;;
        document.getElementById(&apos;sgd-detailed-info&apos;).textContent = &apos;Ready to start&apos;;
        
        // Reset progress bars
        document.getElementById(&apos;gd-progress&apos;).style.width = &apos;0%&apos;;
        document.getElementById(&apos;sgd-progress&apos;).style.width = &apos;0%&apos;;
        
        // Update control buttons
        updateControlButtons();
    }
    
});
&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>06-04 Gradient boosting</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_04_gradient_boosting/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_04_gradient_boosting</id>
   <content type="html">&lt;h1 id=&quot;gradient-boosting&quot;&gt;Gradient boosting&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Gradient boosting&lt;/strong&gt; is a method that uses gradient descent to sequentially create trees while compensating for the errors of previous trees when trying to predict results with an ensemble model composed of multiple trees. &lt;strong&gt;Gradient Boosting&lt;/strong&gt; can be used for both regression and classification.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, refer to the &lt;a href=&quot;https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d&quot;&gt;Gradient Boosting from scratch&lt;/a&gt; blog&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reference-functional-gradient-descent-algorithm&quot;&gt;[Reference] Functional gradient descent algorithm&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Gradient boosting&lt;/strong&gt; was introduced as a functional gradient descent algorithm by Llew Mason, Jonathan Baxter, Peter Bartlett and Marcus Frean. The functional gradient descent algorithm optimizes the loss function over function space by repeatedly selecting functions that have the negative direction of the gradient, thus performing gradient descent.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, refer to &lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient_boosting&quot;&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reference-boosting-vs-bagging&quot;&gt;[Reference] Boosting vs Bagging&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Boosting&lt;/strong&gt; is an ensemble technique that sequentially generates weak learners to predict results. The next stage learner learns from the data that the previous stage learner predicted incorrectly, and the results of sequentially generated learners are combined to create the final result.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bagging&lt;/strong&gt; is an ensemble technique that generates weak learners independently from each other to predict results. Therefore, each learner runs in parallel and their results are combined to create the final result.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For detailed information, refer to the &lt;a href=&quot;https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/&quot;&gt;What is the difference between Bagging and Boosting?&lt;/a&gt; blog
    &lt;h2 id=&quot;gradient-boosting-1&quot;&gt;Gradient Boosting&lt;/h2&gt;
    &lt;p&gt;Let’s examine the background of how &lt;strong&gt;Gradient Boosting&lt;/strong&gt; came to be developed.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Suppose there is an ensemble model composed of trees that is used for classification. This model will want to predict results that minimize the error with the observed values. Let the observed values be \(y_i\), \(i=1,\dots,n\), the input data be \(x_i, i=1,\dots,n\), and the predicted values be \(u_i\), \(i=1,\dots,n\).&lt;/p&gt;

&lt;p&gt;As shown in the figure below, each tree belonging to the ensemble receives \(x_i \in R^p\) as input and outputs results according to the branching conditions in the tree’s nodes.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_04_tree_O9zyAlk.png&quot; alt=&quot;tree_O9zyAlk&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig 1] Example of Tree }T_j\text{ [3]}$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;The predicted value \(u_i\) of the ensemble model can be calculated by weighted summation of each tree’s results. (Here, \(T_j(x_i)\) is the result output by tree \(j\) when it receives \(x_i\) as input.)&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{equation}
u_i = \sum_{j=1}^M \beta_j T_j(x_i)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;For the loss function, it can be defined as \(L=(y_i,u_i)=(y_i - u_i)^2\) in the form of sum of squared errors to minimize the error between observed and predicted values.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{equation}
\min_{\beta} \sum_{i=1}^n L\left(y_i, \sum_{j=1}^M \beta_j T_j(x_i)\right)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Generally, when constructing trees in ensemble models, many small trees with fixed depth are created. This is because making trees smaller uses less memory and enables faster prediction, and as the number of trees increases, the performance of the ensemble improves. Generally, the depth of trees is fixed at 5 or less.&lt;/p&gt;

&lt;p&gt;Therefore, in this problem, the node conditions defined in each tree are very diverse and the results of very many trees are linearly combined, making the tree space quite large. Thus, it can be said that this is a very difficult problem to optimize.&lt;/p&gt;

&lt;p&gt;To solve this problem, the optimization problem must be transformed into an easier one. The original optimization problem is to find \(M\) weights \(\beta_j\) that minimize the loss function. Let’s think of this problem as a minimization problem \(\min_{u} f(u)\) of function \(f(u)\) with respect to predicted values \(u\). If function \(f(u)\) is the loss function \(L(y,u)\), then finding \(u\) that minimizes the loss function can be said to be an easily redefined problem. (Here, \(n\) is the number of data points.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient boosting&lt;/strong&gt; refers to the technique of solving the redefined minimization problem \(\min_{u} f(u)\) using gradient descent.&lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;Gradient boosting&lt;/strong&gt; algorithm performs gradient descent in the following way to find the optimal solution \(u^*\) of \(\min_u L(y, u)\).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Set the initial value as the result of an arbitrary tree: \(u^{(0)}=T_0\). Then repeat the following steps 2~4.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Calculate the negative gradient for \(u^{(k-1)}\), which is the most recent predicted value for \(n\) data points.
    &lt;blockquote&gt;

\[\begin{equation}
d_i = - \left . \left[ \frac{\partial L(y_i,u_i)}{\partial u_i} \right] \right|_{u_i = u_i^{(k-1)}}, i=1,\dots,n
\end{equation}\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Find the tree \(T_k\) whose results \(T(x_i)\) are most similar to the gradients \(d_i\) for \(n\) data points.
    &lt;blockquote&gt;

\[\begin{equation}
\min_{\text{trees } T} \sum_{i=1}^n (d_i-T(x_i))^2
\end{equation}\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Calculate the step size \(a_k\) and update the predicted values using the \(T_k\) found above.
    &lt;blockquote&gt;

\[u^{(k)}=u^{(k-1)} + \alpha_k T_k\]
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This algorithm finds the gradient \(d\) with respect to \(u\) to find the optimal solution \(u^*\) through gradient descent, finds \(T_k\) closest to \(d\), and substitutes \(T_k\) instead of gradient in the update equation to find the next position.&lt;/p&gt;

&lt;p&gt;The final predicted value \(u^*\) obtained in this way can be seen to be identical to the weighted summation of tree results defined earlier. (That is, if we expand the recursive update equation \(u^{(k)}=u^{(k-1)} + \alpha_k T_k\) back to \(k=0\), we get \(u^* = \sum_{k=1}^n \alpha_k T_k\), which can be made into the form of weighted summation of tree results.)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>06-03 Convergence analysis</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_03_convergence_analysis/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_03_convergence_analysis</id>
   <content type="html">&lt;p&gt;In this section, we analyze the convergence of Gradient Descent. We will examine the error bounds for convergence in the case of a fixed step size and in the case of backtracking. In addition, we will analyze the error bounds when the strong convexity condition is satisfied.”&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-03-06 Can we do better?</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_03_06_can_we_do_better/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_03_06_can_we_do_better</id>
   <content type="html">&lt;p&gt;Gradient descent has a convergence rate of \(O(1/\epsilon)\) for problems represented by functions that have Lipschitz gradients and are convex and differentiable. Are there first-order methods that are faster than gradient descent?&lt;/p&gt;

&lt;h3 id=&quot;first-order-method&quot;&gt;First-order method&lt;/h3&gt;
&lt;p&gt;A first-order method can express changes at the \(x^{(k)}\)-th iteration as follows. Therefore, the change at the \(x^{(k)}\)-th iteration is expressed as the span of gradients from the initial position \(x^{(0)}\) to \(x^{(k−1)}\).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x^{(0)} +\) &lt;strong&gt;span&lt;/strong&gt;\(\{∇f(x^{(0)}),∇f(x^{(1)}),...,∇f(x^{(k−1)})\}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;theorem-nesterov&quot;&gt;Theorem (Nesterov)&lt;/h3&gt;
&lt;p&gt;Nesterov’s theorem provides a lower bound for the convergence of first-order methods.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Nesterov Theorem&lt;/strong&gt; For any \(k ≤ (n−1)/2\) and starting point \(x^{(0)}\), there exists a function \(f\) such that any first-order method satisfies the following condition (where \(n\) denotes the dimension):&lt;br /&gt;
\begin{align}
f(x^{(k)})−f^{\star} ≥ \frac{3L \lVert x^{(0)} −x^{\star} \rVert_2^2}{32(k + 1)^2 }\&lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since Nesterov’s theorem has \(k^2\) in the denominator of the lower bound, the convergence rate becomes \(O(1/k^2)\). Furthermore, the number of iterations becomes \(O(1/\sqrt{\epsilon})\). We will examine this content in detail later.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-03-05 A look at the conditions & Practicalities</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_03_05_look_at_the_conditions_and_practicalities/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_03_05_look_at_the_conditions_and_practicalities</id>
   <content type="html">&lt;h2 id=&quot;lipschitz-continuity--strong-convexity-conditions&quot;&gt;Lipschitz continuity &amp;amp; Strong convexity conditions&lt;/h2&gt;
&lt;p&gt;Let’s examine the conditions for Lipschitz continuity and Strong convexity using \(f(β) = \frac{1}{2} \lVert y−Xβ \rVert_2^2\) as an example.&lt;/p&gt;

&lt;h3 id=&quot;lipschitz-continuity-of-f-&quot;&gt;Lipschitz continuity of \(∇f\) :&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;This means \(\nabla^2f(x) \preceq LI\). &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Since \(∇^2f(β) = X^TX\), we have \(L = \sigma^2_{max}(X)\).&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;strong-convexity-of-f-&quot;&gt;Strong convexity of \(f\) :&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;This means \(\nabla^2f(x) \succeq mI\).&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Since \(\nabla^2f(β) = X^TX\), we have \(m = \sigma_{min}^2(X)\).&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;If \(X\) is an \(n \times p\) matrix and \(p &amp;gt; n\), then \(\sigma_{min}(X) = 0\), so \(f\) cannot be strongly convex.&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Even if \(\sigma_{min}(X) &amp;gt; 0\), the condition number \(L/m = \sigma_{max}^2(X)/\sigma_{min}^2(X)\) can be very large.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If function \(f\) is strongly convex and has a Lipschitz gradient, then it satisfies the following. You can think of \(f\) as being sandwiched between two quadratic functions.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(mI \preceq \nabla^2f(x) \preceq LI \text{ for all } x ∈ \mathbb{R}^n\) and \(L &amp;gt; m &amp;gt; 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Satisfying both conditions for all \(x\) can be very strong. However, if we think more carefully, we can see that this condition is only needed for the following sublevel set.&lt;/p&gt;

&lt;blockquote&gt;
\[S = \{x : f(x) \leq f(x^{(0)})\}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;practicalities&quot;&gt;Practicalities&lt;/h2&gt;

&lt;h3 id=&quot;stopping-criteria-for-optimization-algorithms&quot;&gt;Stopping Criteria for Optimization Algorithms&lt;/h3&gt;

&lt;p&gt;In practice, optimization algorithms need well-defined stopping criteria to determine when to terminate the iterative process. Here are the most common stopping conditions:&lt;/p&gt;

&lt;h4 id=&quot;1-gradient-magnitude-near-zero&quot;&gt;1. &lt;strong&gt;Gradient Magnitude Near Zero:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;This is the ideal stopping condition for unconstrained optimization problems, based on the fact that the gradient of the objective function equals zero at local extrema.
\(\|\nabla f(\mathbf{x}_k)\| \leq \epsilon_1\)
where \(\mathbf{x}_k\) is the current point at iteration \(k\), and \(\epsilon_1\) is a small positive threshold.&lt;/p&gt;

&lt;p&gt;If \(x^{\star}\) is the solution, then \(\nabla f(x^{\star}) = 0\). If \(f\) is strongly convex, then:&lt;/p&gt;
&lt;blockquote&gt;
\[\lVert \nabla f(x) \rVert_2 ≤ \sqrt{2m \epsilon} ⇒ f(x)−f^{\star} ≤ \epsilon\]
&lt;/blockquote&gt;

&lt;h4 id=&quot;2-small-change-in-objective-function-value&quot;&gt;2. &lt;strong&gt;Small Change in Objective Function Value:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;The algorithm stops when the objective function value no longer changes significantly between consecutive iterations.
\(|f(\mathbf{x}_{k+1}) - f(\mathbf{x}_k)| \leq \epsilon_2\)
where \(\epsilon_2\) is a small positive threshold.&lt;/p&gt;

&lt;h4 id=&quot;3-small-change-in-variables-parameters&quot;&gt;3. &lt;strong&gt;Small Change in Variables (Parameters):&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;The algorithm stops when the model parameters no longer change significantly between iterations.
\(\|\mathbf{x}_{k+1} - \mathbf{x}_k\| \leq \epsilon_3\)
where \(\epsilon_3\) is a small positive threshold.&lt;/p&gt;

&lt;h4 id=&quot;4-maximum-number-of-iterations&quot;&gt;4. &lt;strong&gt;Maximum Number of Iterations:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;To prevent the algorithm from running indefinitely or for too long, an upper limit on the number of iterations is set.
\(k \geq \text{MaxIterations}\)
This is a safety stopping condition that ensures the algorithm will terminate within a reasonable time, even if it hasn’t achieved perfect convergence.&lt;/p&gt;

&lt;h4 id=&quot;5-maximum-runtime&quot;&gt;5. &lt;strong&gt;Maximum Runtime:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Similar to the maximum iteration limit, the algorithm can be stopped if it has been running for more than an allowed time period.
\(\text{ElapsedTime} \geq \text{MaxTime}\)&lt;/p&gt;

&lt;h4 id=&quot;6-combined-conditions&quot;&gt;6. &lt;strong&gt;Combined Conditions:&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In practice, multiple stopping conditions are often used in combination. For example, the algorithm stops if &lt;em&gt;any&lt;/em&gt; of the above conditions is satisfied. This helps balance between accuracy and computational efficiency.&lt;/p&gt;

&lt;h3 id=&quot;reference-derivation-process&quot;&gt;[Reference] Derivation Process&lt;/h3&gt;
&lt;p&gt;The derivation process for the above equation is as follows.
Since \(f\) satisfies Strong Convexity, there exists a constant \(m \ge 0\) such that:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
\nabla^2 f(x) \succeq mI \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Let’s expand function \(f\) using the second-order Taylor series.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) = f(x) + \nabla f(x)^T(y−x) + \frac{1}{2} (y−x)^T \nabla^2 f(x) (y−x), \space \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Then, according to the above \(\nabla f(x) \succeq mI\), we can arrange the last term as a lower bound condition.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) &amp;amp;  \ge f(x) + \nabla f(x)^T(y−x) + \frac{m}{2} \lVert y−x \rVert_2^2, \space \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Differentiating \(f(y)\) with respect to \(y\) gives \(\tilde{y} = x - (1/m) \nabla f(x)\). Substituting \(\tilde{y}\) into the Taylor expansion gives:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y) &amp;amp;  \ge f(x) + \nabla f(x)^T(\tilde{y}−x) + \frac{m}{2} \lVert \tilde{y}−x \rVert_2^2 \\
&amp;amp;  = f(x) - \frac{1}{2m} \lVert \nabla f(x) \rVert_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, replacing \(f(y)\) with \(f^{*}\) gives:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
 f^{*}  \ge f(x) - \frac{1}{2m} \lVert \nabla f(x) \rVert_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The above stopping rule is derived as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(x) - f^{*} \le \frac{1}{2m} \lVert \nabla f(x) \rVert^2_2 &amp;amp; \le \epsilon \\
\lVert \nabla f(x) \rVert^2_2 &amp;amp; \le 2m\epsilon \\
\lVert \nabla f(x) \rVert_2 &amp;amp; \le \sqrt{2m\epsilon} \\
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;advantages-and-disadvantages-of-gradient-descent&quot;&gt;Advantages and Disadvantages of Gradient Descent&lt;/h3&gt;

&lt;h3 id=&quot;pros&quot;&gt;Pros&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;The algorithm is simple and the cost per iteration is low.&lt;/li&gt;
  &lt;li&gt;Very fast for well-conditioned, strongly convex problems.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cons&quot;&gt;Cons&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Generally slow because many problems are not strongly convex or well-conditioned.&lt;/li&gt;
  &lt;li&gt;Cannot handle non-differentiable functions.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>06-03-04 Convergence analysis under strong convexity</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_03_04_convergence_analysis_under_strong_convexity/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_03_04_convergence_analysis_under_strong_convexity</id>
   <content type="html">&lt;p&gt;If \(f\) satisfies the following condition, it is strongly convex (assuming \(f\) is twice differentiable and \(m &amp;gt; 0\)):&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) \ge f(x) + \nabla f(x)^T(y-x) + \frac{m}{2} \| y-x \|_2^2, \quad \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(f\) has a quadratic lower bound, and the constant \(m\) is determined by the minimum eigenvalue of the Hessian of \(f\).&lt;/p&gt;

&lt;p&gt;For any convex function \(g\), \(f\) is strongly convex if:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
g(x) = f(x) - \frac{m}{2} \| x \|_2^2 \quad \text{is convex for all } x \text{ and } m &amp;gt; 0
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;
&lt;p&gt;Given Lipschitz continuity and strong convexity, the following theorem holds (where \(L\) is the Lipschitz constant and \(m\) is the strong convexity constant):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt; with fixed step size (\(t \le 2/(m + L)\)) or backtracking line search satisfies:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f^* \le c^k \frac{L}{2} \| x^{(0)} - x^* \|_2^2, \quad c = (1 - \frac{m}{L}), \quad 0 &amp;lt; c &amp;lt; 1
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof&quot;&gt;Proof&lt;/h2&gt;
&lt;p&gt;If \(\nabla f\) is Lipschitz continuous and \(f\) is strongly convex, then \(f\) has a quadratic upper bound (see &lt;a href=&quot;#post-not-found&quot;&gt;06-03-02&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;For gradient descent \(x^+ = x - t \nabla f(x)\), the optimal \(t\) is \(1/L\), yielding:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^+) \le f(x) -  \frac{1}{2L} \| \nabla f(x) \|_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Subtracting \(f(x^*)\) from both sides:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^+) - f(x^*) \le f(x) - f(x^*) -  \frac{1}{2L} \| \nabla f(x) \|_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Since Gradient Descent satisfies the condition:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x) - f(x^*) \le \frac{1}{2m} \| \nabla f(x) \|_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;We can substitute to get:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^+) - f(x^*) &amp;amp; \le f(x) - f(x^*) -  \frac{m}{L} ( f(x) - f(x^*) ) \\
&amp;amp; =  (1 -  \frac{m}{L} ) ( f(x) - f(x^*) ) \\
&amp;amp; = c  ( f(x) - f(x^*) ) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Iterating this process gives:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f(x^*) \le c^k ( f(x^{(0)}) - f(x^*) ) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;From the Taylor expansion of the function with \(y = x^{(0)}\) and \(x = x^*\):&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) \le f(x) + \nabla f(x)^T (y-x) + \frac{L}{2} \lVert y - x \rVert^2_2  \space \space \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;And since the function is convex, we have:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(0)}) &amp;amp; \le f(x^{*}) + \nabla f(x^{*})^T (x^{(0)}- x^{*} ) + \frac{L}{2} \lVert x^{(0)} - x^{*} \rVert^2_2 \\\\
&amp;amp; =  f(x^{*}) + \frac{L}{2} \lVert x^{(0)} - x^{*} \rVert^2_2 \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Rearranging gives:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(0)}) - f(x^{*}) &amp;amp; \le \frac{L}{2} \lVert x^{(0)} - x^{*} \rVert^2_2 \\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Substituting this into the previous inequality results in:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f(x^{*}) &amp;amp; \le c^k \frac{L}{2} \lVert x^{(0)} - x^{*} \rVert^2_2  \\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This proves the Convergence Theorem for Gradient Descent under Strong Convexity.&lt;/p&gt;

&lt;h2 id=&quot;linear-convergence&quot;&gt;Linear convergence&lt;/h2&gt;
&lt;p&gt;When \(f\) is strongly convex, the convergence rate becomes \(O(c^k)\), which is exponential.
To achieve \(f(x^{(k)}) - f^{*} \le \epsilon\), it requires \(O(\log(1/\epsilon)\) iterations.
(Without strong convexity, it would require \(O(1/\epsilon)\) iterations.)&lt;/p&gt;

&lt;p&gt;The convergence rate \(O(c^k)\) appears linear on a semi-log plot, as shown below.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06.03_01_01_Line_Convergence.png&quot; alt=&quot;Line_Convergence&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Linear convergence [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Here, the constant \(c\) in \(O(c^k)\) is given by \(1 - \frac{m}{L}\) and depends on the condition number \(L/m\). A larger condition number results in slower convergence (where the condition number is the ratio of the largest eigenvalue to the smallest eigenvalue).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>06-03-03 Convergence analysis for backtracking</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_03_03_convergence_analysis_for_backtracking/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_03_03_convergence_analysis_for_backtracking</id>
   <content type="html">&lt;p&gt;Suppose \(f\) is convex and differentiable with \(dom(f) = \mathbb{R}^n\), and \(\nabla f\) is Lipschitz continuous with constant \(L &amp;gt; 0\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\| \nabla f(x) - \nabla f(y) \|_2 \le L \| x - y \|_2\) for any \(x, y\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Reference: [&lt;a href=&quot;https://en.wikipedia.org/wiki/Lipschitz_continuity&quot;&gt;Wikipedia: Lipschitz continuity&lt;/a&gt;]&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt; with backtracking line search satisfies:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f^* \le \frac{\| x^{(0)} - x^* \|_2^2}{2 t_{min} k}, \quad t_{min} = \min \{ 1, \beta/L \}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The convergence rate for backtracking line search is similar to that for fixed step size, with the step size \(t\) replaced by \(t_{min}\). If \(\beta\) is not too small, the performance is comparable to fixed step size (\(\beta/L\) vs. \(1/L\)).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-03-02 Convergence analysis & Proof</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_03_02_convergence_analysis_and_proof/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_03_02_convergence_analysis_and_proof</id>
   <content type="html">&lt;p&gt;Suppose \(f\) is convex and differentiable with \(dom(f) = \mathbb{R}^n\), and \(\nabla f\) is Lipschitz continuous with constant \(L &amp;gt; 0\):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\| \nabla f(x) - \nabla f(y) \|_2 \le L \| x - y \|_2\) for any \(x, y\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Reference: [&lt;a href=&quot;https://en.wikipedia.org/wiki/Lipschitz_continuity&quot;&gt;Wikipedia: Lipschitz continuity&lt;/a&gt;]&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt; with fixed step size \(t \le 1/L\) satisfies:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(x^{(k)}) - f^* \le  \frac{ \| x^{(0)} - x^* \|^2_2 }{2tk}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;With fixed step size, the convergence rate is \(O(1/k)\). To achieve \(f(x^{(k)}) - f^* \le \epsilon\), \(O(1/\epsilon)\) iterations are needed.&lt;/p&gt;

&lt;h2 id=&quot;proof&quot;&gt;Proof&lt;/h2&gt;
&lt;p&gt;If \(\nabla f\) is Lipschitz continuous and \(f\) is convex, then \(f\) has a quadratic upper bound (see &lt;a href=&quot;#post-not-found&quot;&gt;06-03-02&lt;/a&gt;).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y) \le f(x) + \nabla f(x)^T (y-x) + \frac{L}{2} \| y - x \|^2_2 \quad \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;For gradient descent \(x^+ = x - t \nabla f(x)\), substitute \(y = x^+\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(x^+) &amp;amp; \le f(x) - t ( 1 - \frac{Lt}{2} )\| \nabla f(x) \|^2_2 \\\
&amp;amp; \le f(x) -  \frac{t}{2} \| \nabla f(x) \|^2_2 \quad \text{if } t \le 1/L
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Thus, \(f(x^+) &amp;lt; f(x)\) and gradient descent converges.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-03-01 Convex function quadratic upper bound</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_03_01_convex_function_quadratic_upper_bound/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_03_01_convex_function_quadratic_upper_bound</id>
   <content type="html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;quadratic upper bound&lt;/strong&gt; is a fundamental property of smooth convex functions that provides a crucial tool for analyzing and designing optimization algorithms. This property establishes that any smooth convex function can be bounded above by a quadratic function, which has important implications for convergence analysis of gradient-based methods.&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Why do we care about quadratic upper bounds?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Algorithm Design&lt;/strong&gt;: Many optimization algorithms (like gradient descent) rely on local approximations of the objective function. The quadratic upper bound provides a systematic way to construct these approximations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Convergence Analysis&lt;/strong&gt;: The quadratic upper bound allows us to prove convergence rates for optimization algorithms by bounding how much the function can change.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Step Size Selection&lt;/strong&gt;: The Lipschitz constant \(L\) in the bound directly determines safe step sizes for gradient descent.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;quadratic-upper-bound-property&quot;&gt;Quadratic Upper Bound Property&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: If \(f\) is convex and \(\nabla f\) is Lipschitz continuous with constant \(L\), then \(f\) satisfies the quadratic upper bound:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y) &amp;amp; \le f(x) + \nabla f(x)^T (y-x) + \frac{L}{2} \| y - x \|^2_2 \quad \forall x, y
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

&lt;p&gt;This inequality states that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;linear approximation&lt;/strong&gt; \(f(x) + \nabla f(x)^T (y-x)\) (first-order Taylor expansion) underestimates \(f(y)\) due to convexity&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;quadratic upper bound&lt;/strong&gt; \(f(x) + \nabla f(x)^T (y-x) + \frac{L}{2} \| y - x \|^2_2\) overestimates \(f(y)\)&lt;/li&gt;
  &lt;li&gt;The function \(f(y)\) is “sandwiched” between these two bounds&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;equivalent-characterization&quot;&gt;Equivalent Characterization&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Corollary&lt;/strong&gt;: For any smooth convex function \(f\), the following function is convex:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
g(x) &amp;amp; = \frac{L}{2} \| x \|^2_2 - f(x) \quad \text{where } dom(g) = dom(f)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;This means that \(f(x)\) can be written as the difference between a quadratic function and a convex function.&lt;/p&gt;

&lt;h2 id=&quot;proof&quot;&gt;Proof&lt;/h2&gt;

&lt;p&gt;We will prove both the quadratic upper bound and the equivalent characterization. The proof relies on two key properties of smooth convex functions.&lt;/p&gt;

&lt;h3 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Definition 1 (Monotone Operator)&lt;/strong&gt;: In vector space \(X\), an operator \(T : X \to X^*\) is monotone if:&lt;/p&gt;
&lt;blockquote&gt;
\[(Tu - Tv, u-v) \ge 0, \quad \forall u, v \in X\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Property 1 (Monotonicity of Gradient)&lt;/strong&gt;: If \(f\) is convex and differentiable, then \(\nabla f\) is a monotone operator:&lt;/p&gt;
&lt;blockquote&gt;
\[(\nabla f(y) - \nabla f(x))^T (y-x) \ge 0, \quad \forall x, y\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Property 2 (Lipschitz Continuity)&lt;/strong&gt;: \(\nabla f\) is Lipschitz continuous with constant \(L\):&lt;/p&gt;
&lt;blockquote&gt;
\[\| \nabla f(x) - \nabla f(y) \|_2 \le L \| x - y \|_2, \quad \forall x, y\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;proof-of-quadratic-upper-bound&quot;&gt;Proof of Quadratic Upper Bound&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: Consider the function \(h(t) = f(x + t(y-x))\) for \(t \in [0,1]\). By the fundamental theorem of calculus:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
f(y) - f(x) &amp;amp;= h(1) - h(0) = \int_0^1 h&apos;(t) dt \\
&amp;amp;= \int_0^1 \nabla f(x + t(y-x))^T (y-x) dt
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: We can rewrite this as:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) - f(x) &amp;amp;= \nabla f(x)^T (y-x) + \int_0^1 [\nabla f(x + t(y-x)) - \nabla f(x)]^T (y-x) dt
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 3&lt;/strong&gt;: Using the Cauchy-Schwarz inequality and Lipschitz continuity:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;[\nabla f(x + t(y-x)) - \nabla f(x)]^T (y-x) \\
&amp;amp;\le \|\nabla f(x + t(y-x)) - \nabla f(x)\| \cdot \|y-x\| \\
&amp;amp;\le L \cdot t\|y-x\| \cdot \|y-x\| = Lt\|y-x\|^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 4&lt;/strong&gt;: Integrating over \(t \in [0,1]\):&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
f(y) - f(x) &amp;amp;\le \nabla f(x)^T (y-x) + \int_0^1 Lt\|y-x\|^2 dt \\
&amp;amp;= \nabla f(x)^T (y-x) + L\|y-x\|^2 \int_0^1 t dt \\
&amp;amp;= \nabla f(x)^T (y-x) + \frac{L}{2}\|y-x\|^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore: \(f(y) \le f(x) + \nabla f(x)^T (y-x) + \frac{L}{2}\|y-x\|^2\)&lt;/p&gt;

&lt;h3 id=&quot;proof-of-equivalent-characterization&quot;&gt;Proof of Equivalent Characterization&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: The function \(g(x) = \frac{L}{2} \| x \|^2_2 - f(x)\) is convex.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof&lt;/strong&gt;: We need to show that \(\nabla^2 g(x) \succeq 0\) (positive semidefinite).&lt;/p&gt;

&lt;p&gt;Since \(g(x) = \frac{L}{2} \| x \|^2_2 - f(x)\), we have:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\nabla g(x) = Lx - \nabla f(x)\]
  &lt;/li&gt;
  &lt;li&gt;
\[\nabla^2 g(x) = LI - \nabla^2 f(x)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For any vector \(v\), we need to show \(v^T \nabla^2 g(x) v \ge 0\):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
v^T \nabla^2 g(x) v &amp;amp;= v^T (LI - \nabla^2 f(x)) v \\
&amp;amp;= L\|v\|^2 - v^T \nabla^2 f(x) v
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;From the Lipschitz continuity of \(\nabla f\), we can show that \(\nabla^2 f(x) \preceq LI\), which means:
\(v^T \nabla^2 f(x) v \le L\|v\|^2\)&lt;/p&gt;

&lt;p&gt;Therefore: \(v^T \nabla^2 g(x) v = L\|v\|^2 - v^T \nabla^2 f(x) v \ge 0\)&lt;/p&gt;

&lt;p&gt;This proves that \(g\) is convex. \(\square\)&lt;/p&gt;

&lt;h2 id=&quot;examples&quot;&gt;Examples&lt;/h2&gt;

&lt;h3 id=&quot;example-1-quadratic-function&quot;&gt;Example 1: Quadratic Function&lt;/h3&gt;

&lt;p&gt;Consider \(f(x) = \frac{1}{2}x^T A x + b^T x + c\) where \(A \succeq 0\) (positive semidefinite).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[\nabla f(x) = Ax + b\]
  &lt;/li&gt;
  &lt;li&gt;
\[\nabla^2 f(x) = A\]
  &lt;/li&gt;
  &lt;li&gt;If \(\lambda_{max}(A) = L\), then \(\|\nabla f(x) - \nabla f(y)\| = \|A(x-y)\| \le L\|x-y\|\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The quadratic upper bound becomes:
\(f(y) \le f(x) + (Ax + b)^T(y-x) + \frac{L}{2}\|y-x\|^2\)&lt;/p&gt;

&lt;p&gt;For quadratic functions, this bound is &lt;strong&gt;tight&lt;/strong&gt; when \(L = \lambda_{max}(A)\).&lt;/p&gt;

&lt;h3 id=&quot;example-2-logistic-loss&quot;&gt;Example 2: Logistic Loss&lt;/h3&gt;

&lt;p&gt;Consider the logistic loss \(f(x) = \log(1 + e^{a^T x})\) where \(a \in \mathbb{R}^n\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[\nabla f(x) = \frac{e^{a^T x}}{1 + e^{a^T x}} a = \sigma(a^T x) a\]
  &lt;/li&gt;
  &lt;li&gt;
\[\nabla^2 f(x) = \sigma(a^T x)(1 - \sigma(a^T x)) aa^T\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since \(\sigma(t)(1-\sigma(t)) \le \frac{1}{4}\) for all \(t\), we have:
\(\nabla^2 f(x) \preceq \frac{1}{4} aa^T \preceq \frac{\|a\|^2}{4} I\)&lt;/p&gt;

&lt;p&gt;Therefore, \(L = \frac{\|a\|^2}{4}\) and the quadratic upper bound is:
\(f(y) \le f(x) + \sigma(a^T x) a^T(y-x) + \frac{\|a\|^2}{8}\|y-x\|^2\)&lt;/p&gt;

&lt;h3 id=&quot;example-3-least-squares&quot;&gt;Example 3: Least Squares&lt;/h3&gt;

&lt;p&gt;For \(f(x) = \frac{1}{2}\|Ax - b\|^2\) where \(A \in \mathbb{R}^{m \times n}\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[\nabla f(x) = A^T(Ax - b)\]
  &lt;/li&gt;
  &lt;li&gt;
\[\nabla^2 f(x) = A^T A\]
  &lt;/li&gt;
  &lt;li&gt;\(L = \lambda_{max}(A^T A) = \sigma_{max}^2(A)\) (largest singular value squared)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The quadratic upper bound is:
\(f(y) \le f(x) + (A^T(Ax - b))^T(y-x) + \frac{\sigma_{max}^2(A)}{2}\|y-x\|^2\)&lt;/p&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;h3 id=&quot;1-gradient-descent-step-size&quot;&gt;1. Gradient Descent Step Size&lt;/h3&gt;

&lt;p&gt;The quadratic upper bound directly determines the &lt;strong&gt;maximum safe step size&lt;/strong&gt; for gradient descent. If we use step size \(\alpha \le \frac{1}{L}\), then:&lt;/p&gt;

\[f(x - \alpha \nabla f(x)) \le f(x) - \alpha \|\nabla f(x)\|^2 + \frac{L\alpha^2}{2}\|\nabla f(x)\|^2\]

&lt;p&gt;When \(\alpha \le \frac{1}{L}\), the right-hand side simplifies to:
\(f(x - \alpha \nabla f(x)) \le f(x) - \frac{\alpha}{2}\|\nabla f(x)\|^2\)&lt;/p&gt;

&lt;p&gt;This guarantees &lt;strong&gt;sufficient decrease&lt;/strong&gt; at each iteration.&lt;/p&gt;

&lt;h3 id=&quot;2-convergence-rate-analysis&quot;&gt;2. Convergence Rate Analysis&lt;/h3&gt;

&lt;p&gt;For gradient descent with step size \(\alpha = \frac{1}{L}\), the quadratic upper bound enables us to prove:&lt;/p&gt;

\[f(x_{k+1}) - f^* \le \left(1 - \frac{\mu}{L}\right)(f(x_k) - f^*)\]

&lt;p&gt;where \(\mu\) is the strong convexity parameter. This gives &lt;strong&gt;linear convergence&lt;/strong&gt; with rate \(\left(1 - \frac{\mu}{L}\right)\).&lt;/p&gt;

&lt;h3 id=&quot;3-proximal-gradient-methods&quot;&gt;3. Proximal Gradient Methods&lt;/h3&gt;

&lt;p&gt;In composite optimization \(\min_x f(x) + g(x)\) where \(f\) is smooth and \(g\) is non-smooth, the quadratic upper bound of \(f\) leads to the proximal gradient update:&lt;/p&gt;

\[x_{k+1} = \text{prox}_{\alpha g}\left(x_k - \alpha \nabla f(x_k)\right)\]

&lt;p&gt;where \(\alpha \le \frac{1}{L}\) ensures convergence.&lt;/p&gt;

&lt;h3 id=&quot;4-accelerated-methods&quot;&gt;4. Accelerated Methods&lt;/h3&gt;

&lt;p&gt;Advanced methods like &lt;strong&gt;Nesterov’s accelerated gradient&lt;/strong&gt; and &lt;strong&gt;FISTA&lt;/strong&gt; also rely on the quadratic upper bound to achieve optimal \(O(1/k^2)\) convergence rates for smooth convex functions.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Fundamental Property&lt;/strong&gt;: The quadratic upper bound is a cornerstone of smooth convex optimization theory.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Algorithm Design&lt;/strong&gt;: It provides the theoretical foundation for choosing step sizes in gradient-based methods.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Convergence Analysis&lt;/strong&gt;: It enables rigorous proofs of convergence rates for optimization algorithms.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Practical Impact&lt;/strong&gt;: Understanding \(L\) helps practitioners tune algorithms effectively.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Geometric Intuition&lt;/strong&gt;: It formalizes the idea that smooth convex functions don’t “curve too much” - they’re bounded above by parabolas.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;interactive-visualization&quot;&gt;Interactive Visualization&lt;/h2&gt;

&lt;p&gt;The following diagram illustrates the quadratic upper bound property:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      f(y)
        |
        |     Quadratic Upper Bound
        |    f(x) + ∇f(x)ᵀ(y-x) + (L/2)||y-x||²
        |   /
        |  /
        | /     True function f(y)
        |/     /
       /|     /
      / |    /
     /  |   /    Linear Approximation
    /   |  /     f(x) + ∇f(x)ᵀ(y-x)
   /    | /
  /     |/
 /      x        y
/       |         →
        |
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Key Observations&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;linear approximation&lt;/strong&gt; (tangent line) lies below \(f(y)\) due to convexity&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;quadratic upper bound&lt;/strong&gt; lies above \(f(y)\)&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;true function&lt;/strong&gt; \(f(y)\) is sandwiched between these bounds&lt;/li&gt;
  &lt;li&gt;The gap between bounds depends on \(L\) (Lipschitz constant) and \(\|y-x\|^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;computational-considerations&quot;&gt;Computational Considerations&lt;/h2&gt;

&lt;h3 id=&quot;estimating-the-lipschitz-constant&quot;&gt;Estimating the Lipschitz Constant&lt;/h3&gt;

&lt;p&gt;In practice, finding the exact Lipschitz constant \(L\) can be challenging. Common approaches:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Theoretical Analysis&lt;/strong&gt;: For specific function classes (quadratic, logistic, etc.)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Spectral Methods&lt;/strong&gt;: \(L = \lambda_{max}(\nabla^2 f)\) when Hessian is available&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Adaptive Methods&lt;/strong&gt;: Start with estimate and adjust based on sufficient decrease condition&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Line Search&lt;/strong&gt;: Use backtracking to find appropriate step sizes&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;practical-algorithm-implementation&quot;&gt;Practical Algorithm Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient_descent_with_lipschitz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_estimate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Gradient descent with adaptive Lipschitz constant estimation
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_estimate&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;grad_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Try step with current L estimate
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x_new&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Check sufficient decrease condition
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_new&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Accept step
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Increase L estimate and retry
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
            
        &lt;span class=&quot;c1&quot;&gt;# Optional: decrease L if step was very conservative
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;
            
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This adaptive approach ensures convergence while automatically tuning the Lipschitz constant estimate.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-02 How to choose step sizes</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_02_how_to_choose_step_sizes/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_02_how_to_choose_step_sizes</id>
   <content type="html">&lt;p&gt;When performing gradient descent, the &lt;strong&gt;step size&lt;/strong&gt; determines how the variable \(x\) is updated and affects the speed and success of finding the optimal value. This section introduces three main methods for choosing the step size to help gradient descent find the optimum more quickly:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fixed step size&lt;/li&gt;
  &lt;li&gt;Backtracking line search&lt;/li&gt;
  &lt;li&gt;Exact line search&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>06-02-03 Exact line search</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_02_03_exact_line_search/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_02_03_exact_line_search</id>
   <content type="html">&lt;p&gt;Another way to adapt the step size in gradient descent is &lt;strong&gt;exact line search&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;what-is-exact-line-search&quot;&gt;What is Exact Line Search?&lt;/h3&gt;
&lt;p&gt;In exact line search, we move in the direction of the negative gradient and choose the best possible step size.&lt;/p&gt;

&lt;p&gt;For the following expression, if \(s &amp;gt; 0\), the next step \(x - s \nabla f(x)\) moves away from the current position. By varying \(s\), we find the step size \(t\) that minimizes \(f\):&lt;/p&gt;

&lt;blockquote&gt;
\[t = \arg\min_{s \ge 0} f(x - s \nabla f(x))\]
&lt;/blockquote&gt;

&lt;p&gt;Exact line search is efficient for single-variable minimization problems, but for multivariable problems, searching exhaustively for the optimal step size is often impractical. In practice, backtracking is more efficient and commonly used.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-02-02 Backtracking line search</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_02_02_backtracking_line_search/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_02_02_backtracking_line_search</id>
   <content type="html">&lt;h2 id=&quot;introduction-the-step-size-problem&quot;&gt;Introduction: The Step Size Problem&lt;/h2&gt;

&lt;p&gt;In gradient descent, we use the update rule:
\(x_{k+1} = x_k - t_k \nabla f(x_k)\)&lt;/p&gt;

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(x_k\) is our current position at iteration \(k\)&lt;/li&gt;
  &lt;li&gt;\(\nabla f(x_k)\) is the gradient (tells us the direction of steepest ascent)&lt;/li&gt;
  &lt;li&gt;\(t_k &amp;gt; 0\) is the &lt;strong&gt;step size&lt;/strong&gt; (how far we move in that direction)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;why-do-we-need-adaptive-step-sizes&quot;&gt;Why Do We Need Adaptive Step Sizes?&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;The Problem with Fixed Step Sizes:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If \(t_k\) is too small → we make slow progress (many tiny steps)&lt;/li&gt;
  &lt;li&gt;If \(t_k\) is too large → we might overshoot the minimum or even diverge&lt;/li&gt;
  &lt;li&gt;A fixed step size can’t adapt to different regions of the function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; Use an &lt;strong&gt;adaptive step size&lt;/strong&gt; that automatically adjusts based on the function’s behavior. One of the most popular methods is &lt;strong&gt;backtracking line search&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;what-is-backtracking-line-search&quot;&gt;What is Backtracking Line Search?&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;The Core Idea:&lt;/strong&gt; Start with a large step size and progressively make it smaller until we find a “good enough” step.&lt;/p&gt;

&lt;p&gt;Think of it like this:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Try a big step&lt;/strong&gt; - Maybe we can make fast progress!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Check if it’s too big&lt;/strong&gt; - Did we overshoot or not improve enough?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;If yes, backtrack&lt;/strong&gt; - Make the step smaller and try again&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Repeat until satisfied&lt;/strong&gt; - Stop when we find an acceptable step&lt;/li&gt;
&lt;/ol&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_02_02_Backtracking_Line_Search.png&quot; alt=&quot;backtrackinglinesearch1&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Backtracking Line Search: The red line shows the &quot;acceptance threshold&quot; - if our function value (blue curve) goes below this line, we accept the step size [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;the-mathematical-condition&quot;&gt;The Mathematical Condition&lt;/h3&gt;

&lt;p&gt;We accept a step size \(t\) if it provides &lt;strong&gt;sufficient decrease&lt;/strong&gt; in the function value:&lt;/p&gt;

\[f(x - t \nabla f(x)) \leq f(x) - \alpha t \|\nabla f(x)\|_2^2\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Left side:&lt;/strong&gt; The actual function value after taking the step&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Right side:&lt;/strong&gt; The current function value minus a threshold for “sufficient decrease”&lt;/li&gt;
  &lt;li&gt;\(\alpha \in (0, 0.5)\) is a parameter that controls how much decrease we require (typically \(\alpha = 0.5\))&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Intuition:&lt;/strong&gt; The right side represents a linear approximation of how much the function &lt;em&gt;should&lt;/em&gt; decrease. If the actual decrease (left side) is at least this much, we accept the step.&lt;/p&gt;

&lt;h2 id=&quot;the-backtracking-line-search-algorithm&quot;&gt;The Backtracking Line Search Algorithm&lt;/h2&gt;

&lt;h3 id=&quot;parameters&quot;&gt;Parameters&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;\(\alpha \in (0, 0.5)\): Controls how much decrease we require (typically \(\alpha = 0.5\))&lt;/li&gt;
  &lt;li&gt;\(\beta \in (0, 1)\): Controls how much we shrink the step size when backtracking (typically \(\beta = 0.8\) or \(\beta = 0.9\))&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;algorithm-steps&quot;&gt;Algorithm Steps&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt; Current point \(x\), gradient \(\nabla f(x)\)
&lt;strong&gt;Output:&lt;/strong&gt; Good step size \(t\)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Initialize:&lt;/strong&gt; Set \(t = 1\) (start with a full step)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Check the condition:&lt;/strong&gt; While the sufficient decrease condition is NOT satisfied:
\(f(x - t \nabla f(x)) &amp;gt; f(x) - \alpha t \|\nabla f(x)\|_2^2\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Backtrack:&lt;/strong&gt; Set \(t = \beta \cdot t\) (shrink the step size)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; Use the final \(t\) to update: \(x^+ = x - t \nabla f(x)\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;step-by-step-example&quot;&gt;Step-by-Step Example&lt;/h3&gt;

&lt;p&gt;Let’s say we’re at point \(x\) with gradient \(\nabla f(x)\):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Try \(t = 1\):&lt;/strong&gt; Check if \(f(x - 1 \cdot \nabla f(x)) \leq f(x) - \alpha \|\nabla f(x)\|_2^2\)
    &lt;ul&gt;
      &lt;li&gt;If YES → Accept \(t = 1\)&lt;/li&gt;
      &lt;li&gt;If NO → Continue to step 2&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Try \(t = 0.8\):&lt;/strong&gt; Check if \(f(x - 0.8 \nabla f(x)) \leq f(x) - 0.8\alpha \|\nabla f(x)\|_2^2\)
    &lt;ul&gt;
      &lt;li&gt;If YES → Accept \(t = 0.8\)&lt;/li&gt;
      &lt;li&gt;If NO → Continue to step 3&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Try \(t = 0.64\):&lt;/strong&gt; Check if \(f(x - 0.64 \nabla f(x)) \leq f(x) - 0.64\alpha \|\nabla f(x)\|_2^2\)
    &lt;ul&gt;
      &lt;li&gt;And so on…&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;why-does-this-work-the-mathematical-intuition&quot;&gt;Why Does This Work? The Mathematical Intuition&lt;/h2&gt;

&lt;h3 id=&quot;the-sufficient-decrease-condition-explained&quot;&gt;The Sufficient Decrease Condition Explained&lt;/h3&gt;

&lt;p&gt;The condition \(f(x - t \nabla f(x)) \leq f(x) - \alpha t \|\nabla f(x)\|_2^2\) can be understood as:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Left side:&lt;/strong&gt; \(f(x - t \nabla f(x))\) = The actual function value after taking the step&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Right side:&lt;/strong&gt; \(f(x) - \alpha t \|\nabla f(x)\|_2^2\) = Current value minus expected decrease&lt;/p&gt;

&lt;p&gt;The expected decrease \(\alpha t \|\nabla f(x)\|_2^2\) comes from the &lt;strong&gt;linear approximation&lt;/strong&gt;:
\(f(x - t \nabla f(x)) \approx f(x) - t \|\nabla f(x)\|_2^2\)&lt;/p&gt;

&lt;p&gt;We require the actual decrease to be at least a fraction \(\alpha\) of this predicted decrease.&lt;/p&gt;

&lt;h3 id=&quot;why-this-guarantees-progress&quot;&gt;Why This Guarantees Progress&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Prevents tiny steps:&lt;/strong&gt; The condition ensures we don’t accept arbitrarily small step sizes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Prevents overshooting:&lt;/strong&gt; If we overshoot, the function value won’t decrease enough&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Balances speed and stability:&lt;/strong&gt; We get reasonably large steps while maintaining convergence&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;performance-comparison&quot;&gt;Performance Comparison&lt;/h3&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_02_02_Convergence.png&quot; alt=&quot;backtrackinglinesearch1&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Convergence comparison: Backtracking line search (adaptive) vs Fixed step size. Notice how the adaptive method converges much faster! [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;practical-example-minimizing-a-quadratic-function&quot;&gt;Practical Example: Minimizing a Quadratic Function&lt;/h2&gt;

&lt;p&gt;Let’s work through a detailed example to see backtracking line search in action!&lt;/p&gt;

&lt;h3 id=&quot;example-1-simple-quadratic-lucky-case&quot;&gt;Example 1: Simple Quadratic (Lucky Case)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Minimize \(f(x) = \frac{1}{2}x^2\) starting from \(x_0 = 4\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Parameters: \(\alpha = 0.5\), \(\beta = 0.8\)&lt;/li&gt;
  &lt;li&gt;Gradient: \(\nabla f(x) = x\)&lt;/li&gt;
  &lt;li&gt;Optimal solution: \(x^* = 0\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Iteration 1:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Current: \(x = 4\), \(\nabla f(x) = 4\), \(f(x) = 8\)&lt;/li&gt;
  &lt;li&gt;Try \(t = 1\):
    &lt;ul&gt;
      &lt;li&gt;New point: \(x - t\nabla f(x) = 4 - 1 \cdot 4 = 0\)&lt;/li&gt;
      &lt;li&gt;Function value: \(f(0) = 0\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Check sufficient decrease:&lt;/strong&gt; \(f(0) \leq f(4) - \alpha t \|\nabla f(4)\|^2\)
    &lt;ul&gt;
      &lt;li&gt;Left side: \(0\)&lt;/li&gt;
      &lt;li&gt;Right side: \(8 - 0.5 \cdot 1 \cdot 16 = 0\)&lt;/li&gt;
      &lt;li&gt;\(0 \leq 0\) ✓ (Accept \(t = 1\))&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Update: \(x_1 = 0\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt; We reached the optimum in one step! This is because the quadratic function is “well-behaved.”&lt;/p&gt;

&lt;h3 id=&quot;example-2-more-realistic-scenario&quot;&gt;Example 2: More Realistic Scenario&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Minimize \(f(x) = x^2 + 10\sin(x)\) starting from \(x_0 = 3\)&lt;/p&gt;

&lt;p&gt;This function has local minima and is more challenging. Let’s see how backtracking handles it:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Parameters: \(\alpha = 0.3\), \(\beta = 0.7\)&lt;/li&gt;
  &lt;li&gt;Gradient: \(\nabla f(x) = 2x + 10\cos(x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Iteration 1:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Current: \(x = 3\), \(\nabla f(x) = 6 + 10\cos(3) \approx 6 - 9.9 = -3.9\), \(f(x) \approx 7.41\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Try \(t = 1\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 1 \cdot (-3.9) = 6.9\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(6.9) \approx 46.37\)&lt;/li&gt;
  &lt;li&gt;Check: \(46.37 \leq 7.41 - 0.3 \cdot 1 \cdot 15.21 \approx 2.85\) ✗ (Too big step!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 2: Try \(t = 0.7\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.7 \cdot (-3.9) = 5.73\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(5.73) \approx 31.87\)&lt;/li&gt;
  &lt;li&gt;Check: \(31.87 \leq 7.41 - 0.3 \cdot 0.7 \cdot 15.21 \approx 4.21\) ✗ (Still too big!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 3: Try \(t = 0.49\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.49 \cdot (-3.9) = 4.91\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(4.91) \approx 23.16\)&lt;/li&gt;
  &lt;li&gt;Check: \(23.16 \leq 7.41 - 0.3 \cdot 0.49 \cdot 15.21 \approx 5.17\) ✗ (Still too big!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 4: Try \(t = 0.34\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.34 \cdot (-3.9) = 4.33\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(4.33) \approx 17.26\)&lt;/li&gt;
  &lt;li&gt;Check: \(17.26 \leq 7.41 - 0.3 \cdot 0.34 \cdot 15.21 \approx 5.85\) ✗ (Still too big!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 5: Try \(t = 0.24\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.24 \cdot (-3.9) = 3.94\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.94) \approx 14.12\)&lt;/li&gt;
  &lt;li&gt;Check: \(14.12 \leq 7.41 - 0.3 \cdot 0.24 \cdot 15.21 \approx 6.31\) ✗ (Getting closer!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 6: Try \(t = 0.17\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.17 \cdot (-3.9) = 3.66\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.66) \approx 12.51\)&lt;/li&gt;
  &lt;li&gt;Check: \(12.51 \leq 7.41 - 0.3 \cdot 0.17 \cdot 15.21 \approx 6.63\) ✗ (Almost there!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 7: Try \(t = 0.12\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.12 \cdot (-3.9) = 3.47\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.47) \approx 11.58\)&lt;/li&gt;
  &lt;li&gt;Check: \(11.58 \leq 7.41 - 0.3 \cdot 0.12 \cdot 15.21 \approx 6.86\) ✗ (Very close!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 8: Try \(t = 0.08\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.08 \cdot (-3.9) = 3.31\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.31) \approx 10.54\)&lt;/li&gt;
  &lt;li&gt;Check: \(10.54 \leq 7.41 - 0.3 \cdot 0.08 \cdot 15.21 \approx 7.05\) ✗ (So close!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 9: Try \(t = 0.056\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.056 \cdot (-3.9) = 3.22\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.22) \approx 9.93\)&lt;/li&gt;
  &lt;li&gt;Check: \(9.93 \leq 7.41 - 0.3 \cdot 0.056 \cdot 15.21 \approx 7.15\) ✗ (Almost!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 10: Try \(t = 0.039\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.039 \cdot (-3.9) = 3.15\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.15) \approx 9.33\)&lt;/li&gt;
  &lt;li&gt;Check: \(9.33 \leq 7.41 - 0.3 \cdot 0.039 \cdot 15.21 \approx 7.23\) ✗ (Getting very small steps now…)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 11: Try \(t = 0.027\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.027 \cdot (-3.9) = 3.11\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.11) \approx 8.81\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.81 \leq 7.41 - 0.3 \cdot 0.027 \cdot 15.21 \approx 7.29\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 12: Try \(t = 0.019\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.019 \cdot (-3.9) = 3.074\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.074) \approx 8.51\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.51 \leq 7.41 - 0.3 \cdot 0.019 \cdot 15.21 \approx 7.32\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 13: Try \(t = 0.013\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.013 \cdot (-3.9) = 3.051\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.051) \approx 8.36\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.36 \leq 7.41 - 0.3 \cdot 0.013 \cdot 15.21 \approx 7.35\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 14: Try \(t = 0.009\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.009 \cdot (-3.9) = 3.035\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.035) \approx 8.28\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.28 \leq 7.41 - 0.3 \cdot 0.009 \cdot 15.21 \approx 7.37\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 15: Try \(t = 0.006\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.006 \cdot (-3.9) = 3.023\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.023) \approx 8.23\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.23 \leq 7.41 - 0.3 \cdot 0.006 \cdot 15.21 \approx 7.38\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 16: Try \(t = 0.004\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.004 \cdot (-3.9) = 3.016\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.016) \approx 8.20\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.20 \leq 7.41 - 0.3 \cdot 0.004 \cdot 15.21 \approx 7.39\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 17: Try \(t = 0.003\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.003 \cdot (-3.9) = 3.012\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.012) \approx 8.18\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.18 \leq 7.41 - 0.3 \cdot 0.003 \cdot 15.21 \approx 7.396\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 18: Try \(t = 0.002\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.002 \cdot (-3.9) = 3.008\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.008) \approx 8.17\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.17 \leq 7.41 - 0.3 \cdot 0.002 \cdot 15.21 \approx 7.40\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 19: Try \(t = 0.001\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.001 \cdot (-3.9) = 3.004\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.004) \approx 8.16\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.16 \leq 7.41 - 0.3 \cdot 0.001 \cdot 15.21 \approx 7.405\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 20: Try \(t = 0.0007\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(x - t\nabla f(x) = 3 - 0.0007 \cdot (-3.9) = 3.003\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(3.003) \approx 8.155\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.155 \leq 7.41 - 0.3 \cdot 0.0007 \cdot 15.21 \approx 7.407\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Wait, let me recalculate this more carefully. I think there might be an error in my calculations. Let me redo this with a simpler but more accurate approach.&lt;/p&gt;

&lt;h3 id=&quot;example-2-corrected-a-more-realistic-function&quot;&gt;Example 2 (Corrected): A More Realistic Function&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Minimize \(f(x) = x^2 + 0.1x^4\) starting from \(x_0 = 2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Parameters: \(\alpha = 0.5\), \(\beta = 0.8\)&lt;/li&gt;
  &lt;li&gt;Gradient: \(\nabla f(x) = 2x + 0.4x^3\)&lt;/li&gt;
  &lt;li&gt;At \(x = 2\): \(\nabla f(2) = 4 + 3.2 = 7.2\), \(f(2) = 4 + 1.6 = 5.6\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Iteration 1:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Try \(t = 1\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(2 - 1 \cdot 7.2 = -5.2\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(-5.2) = 27.04 + 73.44 = 100.48\)&lt;/li&gt;
  &lt;li&gt;Check: \(100.48 \leq 5.6 - 0.5 \cdot 1 \cdot 51.84 = -20.32\) ✗ (Way too big!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Try \(t = 0.8\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(2 - 0.8 \cdot 7.2 = -3.76\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(-3.76) = 14.14 + 20.06 = 34.2\)&lt;/li&gt;
  &lt;li&gt;Check: \(34.2 \leq 5.6 - 0.5 \cdot 0.8 \cdot 51.84 = -15.14\) ✗ (Still too big!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Try \(t = 0.64\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(2 - 0.64 \cdot 7.2 = -2.61\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(-2.61) = 6.81 + 4.63 = 11.44\)&lt;/li&gt;
  &lt;li&gt;Check: \(11.44 \leq 5.6 - 0.5 \cdot 0.64 \cdot 51.84 = -11.0\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Try \(t = 0.51\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(2 - 0.51 \cdot 7.2 = -1.67\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(-1.67) = 2.79 + 0.78 = 3.57\)&lt;/li&gt;
  &lt;li&gt;Check: \(3.57 \leq 5.6 - 0.5 \cdot 0.51 \cdot 51.84 = -7.62\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Try \(t = 0.41\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(2 - 0.41 \cdot 7.2 = -0.95\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(-0.95) = 0.90 + 0.08 = 0.98\)&lt;/li&gt;
  &lt;li&gt;Check: \(0.98 \leq 5.6 - 0.5 \cdot 0.41 \cdot 51.84 = -5.02\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Try \(t = 0.33\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(2 - 0.33 \cdot 7.2 = -0.38\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(-0.38) = 0.14 + 0.002 = 0.142\)&lt;/li&gt;
  &lt;li&gt;Check: \(0.142 \leq 5.6 - 0.5 \cdot 0.33 \cdot 51.84 = -3.0\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Try \(t = 0.26\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(2 - 0.26 \cdot 7.2 = 0.13\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(0.13) = 0.017 + 0.000003 = 0.017\)&lt;/li&gt;
  &lt;li&gt;Check: \(0.017 \leq 5.6 - 0.5 \cdot 0.26 \cdot 51.84 = -1.14\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Try \(t = 0.21\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(2 - 0.21 \cdot 7.2 = 0.49\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(0.49) = 0.24 + 0.006 = 0.246\)&lt;/li&gt;
  &lt;li&gt;Check: \(0.246 \leq 5.6 - 0.5 \cdot 0.21 \cdot 51.84 = 0.157\) ✗&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Try \(t = 0.17\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New point: \(2 - 0.17 \cdot 7.2 = 0.78\)&lt;/li&gt;
  &lt;li&gt;Function value: \(f(0.78) = 0.61 + 0.037 = 0.647\)&lt;/li&gt;
  &lt;li&gt;Check: \(0.647 \leq 5.6 - 0.5 \cdot 0.17 \cdot 51.84 = 1.19\) ✓ &lt;strong&gt;Accept!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt; After 8 backtracking steps, we accept \(t = 0.17\) and update to \(x_1 = 0.78\)&lt;/p&gt;

&lt;h3 id=&quot;key-insights-from-these-examples&quot;&gt;Key Insights from These Examples&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Simple functions&lt;/strong&gt; (like pure quadratics) may converge in one step&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Complex functions&lt;/strong&gt; require multiple backtracking steps to find safe step sizes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The algorithm is robust&lt;/strong&gt; - it automatically finds appropriate step sizes without manual tuning&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Each backtracking iteration&lt;/strong&gt; makes the step size smaller by factor \(\beta\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The sufficient decrease condition&lt;/strong&gt; prevents both overshooting and accepting tiny progress&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;why-this-beats-fixed-step-sizes&quot;&gt;Why This Beats Fixed Step Sizes&lt;/h3&gt;

&lt;p&gt;Let’s see a head-to-head comparison! We’ll minimize \(f(x) = x^2 - 2x + 5\) starting from \(x_0 = 4\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Function details:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Gradient: \(\nabla f(x) = 2x - 2\)&lt;/li&gt;
  &lt;li&gt;Optimal solution: \(x^* = 1\) with \(f(x^*) = 4\)&lt;/li&gt;
  &lt;li&gt;Starting point: \(x_0 = 4\), \(f(x_0) = 13\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;comparison-fixed-step-size-vs-backtracking-line-search&quot;&gt;Comparison: Fixed Step Size vs Backtracking Line Search&lt;/h2&gt;

&lt;h3 id=&quot;method-1-fixed-small-step-size-t--01&quot;&gt;Method 1: Fixed Small Step Size (\(t = 0.1\))&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Iteration&lt;/th&gt;
      &lt;th&gt;\(x_k\)&lt;/th&gt;
      &lt;th&gt;\(\nabla f(x_k)\)&lt;/th&gt;
      &lt;th&gt;\(x_{k+1} = x_k - 0.1 \nabla f(x_k)\)&lt;/th&gt;
      &lt;th&gt;\(f(x_{k+1})\)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;3.4&lt;/td&gt;
      &lt;td&gt;8.96&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3.4&lt;/td&gt;
      &lt;td&gt;4.8&lt;/td&gt;
      &lt;td&gt;2.92&lt;/td&gt;
      &lt;td&gt;6.4864&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2.92&lt;/td&gt;
      &lt;td&gt;3.84&lt;/td&gt;
      &lt;td&gt;2.536&lt;/td&gt;
      &lt;td&gt;5.548896&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2.536&lt;/td&gt;
      &lt;td&gt;3.072&lt;/td&gt;
      &lt;td&gt;2.2288&lt;/td&gt;
      &lt;td&gt;5.103194&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;2.2288&lt;/td&gt;
      &lt;td&gt;2.4576&lt;/td&gt;
      &lt;td&gt;1.98304&lt;/td&gt;
      &lt;td&gt;4.835481&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1.98304&lt;/td&gt;
      &lt;td&gt;1.96608&lt;/td&gt;
      &lt;td&gt;1.786432&lt;/td&gt;
      &lt;td&gt;4.693904&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;1.24537&lt;/td&gt;
      &lt;td&gt;0.49074&lt;/td&gt;
      &lt;td&gt;1.196296&lt;/td&gt;
      &lt;td&gt;4.192934&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;50&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;1.049&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;0.098&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;1.0392&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;4.0038&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt; After 50 iterations, we’re still not very close to the optimum!&lt;/p&gt;

&lt;h3 id=&quot;method-2-fixed-large-step-size-t--15&quot;&gt;Method 2: Fixed Large Step Size (\(t = 1.5\))&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Iteration&lt;/th&gt;
      &lt;th&gt;\(x_k\)&lt;/th&gt;
      &lt;th&gt;\(\nabla f(x_k)\)&lt;/th&gt;
      &lt;th&gt;\(x_{k+1} = x_k - 1.5 \nabla f(x_k)\)&lt;/th&gt;
      &lt;th&gt;\(f(x_{k+1})\)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;-5.0&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;-5.0&lt;/td&gt;
      &lt;td&gt;-12.0&lt;/td&gt;
      &lt;td&gt;13.0&lt;/td&gt;
      &lt;td&gt;148&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;13.0&lt;/td&gt;
      &lt;td&gt;24.0&lt;/td&gt;
      &lt;td&gt;-23.0&lt;/td&gt;
      &lt;td&gt;568&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;-23.0&lt;/td&gt;
      &lt;td&gt;-48.0&lt;/td&gt;
      &lt;td&gt;49.0&lt;/td&gt;
      &lt;td&gt;2308&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;49.0&lt;/td&gt;
      &lt;td&gt;96.0&lt;/td&gt;
      &lt;td&gt;-95.0&lt;/td&gt;
      &lt;td&gt;9028&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt; Diverges catastrophically! The algorithm explodes and never converges.&lt;/p&gt;

&lt;h3 id=&quot;method-3-fixed-medium-step-size-t--05&quot;&gt;Method 3: Fixed Medium Step Size (\(t = 0.5\))&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Iteration&lt;/th&gt;
      &lt;th&gt;\(x_k\)&lt;/th&gt;
      &lt;th&gt;\(\nabla f(x_k)\)&lt;/th&gt;
      &lt;th&gt;\(x_{k+1} = x_k - 0.5 \nabla f(x_k)\)&lt;/th&gt;
      &lt;th&gt;\(f(x_{k+1})\)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt; Lucky guess! Converges in 2 steps, but this only works because we happened to choose exactly the right step size for this particular function.&lt;/p&gt;

&lt;h3 id=&quot;method-4-backtracking-line-search-alpha--05-beta--08&quot;&gt;Method 4: Backtracking Line Search (\(\alpha = 0.5\), \(\beta = 0.8\))&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Iteration 1:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Current: \(x = 4\), \(\nabla f(x) = 6\), \(f(x) = 13\)&lt;/li&gt;
  &lt;li&gt;Try \(t = 1\): \(x - t\nabla f(x) = 4 - 1 \cdot 6 = -2\), \(f(-2) = 13\)&lt;/li&gt;
  &lt;li&gt;Check: \(13 \leq 13 - 0.5 \cdot 1 \cdot 36 = -5\) ✗ (Too big!)&lt;/li&gt;
  &lt;li&gt;Try \(t = 0.8\): \(x - t\nabla f(x) = 4 - 0.8 \cdot 6 = -0.8\), \(f(-0.8) = 8.44\)&lt;/li&gt;
  &lt;li&gt;Check: \(8.44 \leq 13 - 0.5 \cdot 0.8 \cdot 36 = -1.4\) ✗ (Still too big!)&lt;/li&gt;
  &lt;li&gt;Try \(t = 0.64\): \(x - t\nabla f(x) = 4 - 0.64 \cdot 6 = 0.16\), \(f(0.16) = 4.3344\)&lt;/li&gt;
  &lt;li&gt;Check: \(4.3344 \leq 13 - 0.5 \cdot 0.64 \cdot 36 = 1.48\) ✗ (Still too big!)&lt;/li&gt;
  &lt;li&gt;Try \(t = 0.51\): \(x - t\nabla f(x) = 4 - 0.51 \cdot 6 = 0.94\), \(f(0.94) = 4.0036\)&lt;/li&gt;
  &lt;li&gt;Check: \(4.0036 \leq 13 - 0.5 \cdot 0.51 \cdot 36 = 3.82\) ✓ &lt;strong&gt;Accept!&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Update: \(x_1 = 0.94\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Iteration 2:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Current: \(x = 0.94\), \(\nabla f(x) = -0.12\), \(f(x) = 4.0036\)&lt;/li&gt;
  &lt;li&gt;Try \(t = 1\): \(x - t\nabla f(x) = 0.94 - 1 \cdot (-0.12) = 1.06\), \(f(1.06) = 4.0036\)&lt;/li&gt;
  &lt;li&gt;Check: \(4.0036 \leq 4.0036 - 0.5 \cdot 1 \cdot 0.0144 = 3.9964\) ✗ (Very close!)&lt;/li&gt;
  &lt;li&gt;Try \(t = 0.8\): \(x - t\nabla f(x) = 0.94 - 0.8 \cdot (-0.12) = 1.036\), \(f(1.036) = 4.001296\)&lt;/li&gt;
  &lt;li&gt;Check: \(4.001296 \leq 4.0036 - 0.5 \cdot 0.8 \cdot 0.0144 = 3.997824\) ✗&lt;/li&gt;
  &lt;li&gt;Try \(t = 0.64\): \(x - t\nabla f(x) = 0.94 - 0.64 \cdot (-0.12) = 1.0168\), \(f(1.0168) = 4.00028\)&lt;/li&gt;
  &lt;li&gt;Check: \(4.00028 \leq 4.0036 - 0.5 \cdot 0.64 \cdot 0.0144 = 3.99899\) ✗&lt;/li&gt;
  &lt;li&gt;Try \(t = 0.51\): \(x - t\nabla f(x) = 0.94 - 0.51 \cdot (-0.12) = 1.0012\), \(f(1.0012) = 4.0000144\)&lt;/li&gt;
  &lt;li&gt;Check: \(4.0000144 \leq 4.0036 - 0.5 \cdot 0.51 \cdot 0.0144 = 3.999923\) ✗&lt;/li&gt;
  &lt;li&gt;Try \(t = 0.41\): \(x - t\nabla f(x) = 0.94 - 0.41 \cdot (-0.12) = 0.9908\), \(f(0.9908) = 4.0000846\)&lt;/li&gt;
  &lt;li&gt;Check: \(4.0000846 \leq 4.0036 - 0.5 \cdot 0.41 \cdot 0.0144 = 4.000648\) ✓ &lt;strong&gt;Accept!&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Update: \(x_2 = 0.9908\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Iteration 3:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Current: \(x = 0.9908\), \(\nabla f(x) = -0.0184\), \(f(x) = 4.0000846\)&lt;/li&gt;
  &lt;li&gt;The gradient is very small, so we’re very close to the optimum&lt;/li&gt;
  &lt;li&gt;After one more step: \(x_3 \approx 1.000\) (essentially converged!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt; Converges to the optimum in just &lt;strong&gt;3 iterations&lt;/strong&gt;!&lt;/p&gt;

&lt;h2 id=&quot;performance-summary&quot;&gt;Performance Summary&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Method&lt;/th&gt;
      &lt;th&gt;Iterations to Convergence&lt;/th&gt;
      &lt;th&gt;Final Error&lt;/th&gt;
      &lt;th&gt;Comments&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Fixed Small (\(t = 0.1\))&lt;/td&gt;
      &lt;td&gt;50+&lt;/td&gt;
      &lt;td&gt;High&lt;/td&gt;
      &lt;td&gt;Very slow, conservative&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fixed Large (\(t = 1.5\))&lt;/td&gt;
      &lt;td&gt;∞&lt;/td&gt;
      &lt;td&gt;∞&lt;/td&gt;
      &lt;td&gt;Diverges completely&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fixed Medium (\(t = 0.5\))&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Very Low&lt;/td&gt;
      &lt;td&gt;Lucky guess only!&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Backtracking&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Very Low&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Robust and fast&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;key-insights&quot;&gt;Key Insights&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Fixed small steps:&lt;/strong&gt; Safe but painfully slow&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fixed large steps:&lt;/strong&gt; Fast when they work, catastrophic when they don’t&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fixed “perfect” steps:&lt;/strong&gt; Impossible to find without knowing the answer&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Backtracking:&lt;/strong&gt; Automatically finds good step sizes, robust across different functions&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;the-real-power-robustness-across-functions&quot;&gt;The Real Power: Robustness Across Functions&lt;/h3&gt;

&lt;p&gt;The magic of backtracking line search is that it works well for ANY function:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Gentle functions:&lt;/strong&gt; Takes appropriately large steps for fast progress&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Steep functions:&lt;/strong&gt; Automatically reduces step size to prevent overshooting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Varying functions:&lt;/strong&gt; Adapts step size throughout the optimization process&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Unknown functions:&lt;/strong&gt; No need to guess the “right” step size beforehand&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Bottom line:&lt;/strong&gt; Backtracking line search gives you the speed of large steps when safe, and the stability of small steps when necessary - automatically!&lt;/p&gt;

&lt;h2 id=&quot;advantages-and-practical-considerations&quot;&gt;Advantages and Practical Considerations&lt;/h2&gt;

&lt;h3 id=&quot;advantages&quot;&gt;Advantages:&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Automatic adaptation:&lt;/strong&gt; No need to manually tune step sizes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Convergence guarantees:&lt;/strong&gt; Theoretical guarantees for convex functions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Simple implementation:&lt;/strong&gt; Easy to code and understand&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Robust:&lt;/strong&gt; Works well across different types of problems&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;practical-tips&quot;&gt;Practical Tips:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Typical parameter values:&lt;/strong&gt; \(\alpha = 0.5\), \(\beta = 0.8\) or \(\beta = 0.9\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Computational cost:&lt;/strong&gt; Each backtracking step requires one function evaluation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;When to use:&lt;/strong&gt; Especially useful when the function’s “landscape” varies significantly&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Backtracking line search&lt;/strong&gt; solves the fundamental problem of choosing good step sizes in gradient descent:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Start optimistic:&lt;/strong&gt; Try a large step size (\(t = 1\))&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Test rigorously:&lt;/strong&gt; Check if the step provides sufficient decrease&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Adapt intelligently:&lt;/strong&gt; If not, shrink the step size and try again&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Guarantee progress:&lt;/strong&gt; The mathematical condition ensures we always make meaningful progress&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This simple yet powerful technique transforms gradient descent from a method that requires careful tuning into a robust, adaptive algorithm that works well out of the box.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Next time&lt;/strong&gt; you implement gradient descent, consider adding backtracking line search - your algorithm will converge faster and be much more reliable!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06-02-01 Fixed step size</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_02_01_fixed_step_size/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_02_01_fixed_step_size</id>
   <content type="html">&lt;p&gt;The simplest way to choose the step size in gradient descent is to use a fixed value for all iterations: \(t_k = t\) for \(k = 1, 2, 3, ...\). However, the convergence and behavior depend heavily on the choice of \(t\).&lt;/p&gt;

&lt;p&gt;For example, in the figure below, gradient descent is applied to \(f(x) = (10 x_1^2 + x_2^2) / 2\) with different step sizes:&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_02_01_gradientdescent4.png&quot; alt=&quot;gradientdescent4&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Step size scenarios [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;In case A, the step size \(t\) is too large, causing divergence after 8 steps. The minimum cannot be reached.&lt;/li&gt;
  &lt;li&gt;In case B, the step size \(t\) is too small, so convergence is very slow and the minimum is not reached even after 100 steps.&lt;/li&gt;
  &lt;li&gt;In case C, the step size is “appropriate,” and convergence is achieved in about 40 steps. (How to find this “appropriate” value is discussed later in this chapter.)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>06-01 Gradient Descent</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_01_gradient_descent/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_01_gradient_descent</id>
   <content type="html">&lt;p&gt;Gradient descent is the simplest algorithm for solving unconstrained convex and differentiable optimization problems.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\min_x f(x),\)
where \(f\) is differentiable and \(dom(f) = \mathbb{R}^n\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The optimal value is \(f^* = \min_x f(x)\), and the optimizer is \(x^*\).&lt;/p&gt;

&lt;h2 id=&quot;why-gradient-descent-matters-in-data-science&quot;&gt;Why Gradient Descent Matters in Data Science&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Gradient descent is the workhorse of machine learning!&lt;/strong&gt; It’s the algorithm behind:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Training neural networks&lt;/strong&gt;: Backpropagation uses gradient descent to update weights&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Linear regression&lt;/strong&gt;: Finding optimal coefficients to minimize MSE&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Logistic regression&lt;/strong&gt;: Optimizing parameters for classification&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deep learning&lt;/strong&gt;: Training complex models with millions of parameters&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Recommendation systems&lt;/strong&gt;: Learning user preferences and item features&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Key insight&lt;/strong&gt;: Every time you see “training” or “learning” in ML, gradient descent (or its variants) is likely involved!&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent-for-single-variable-functions&quot;&gt;Gradient Descent for Single Variable Functions&lt;/h2&gt;

&lt;p&gt;For functions of a single variable \(f: \mathbb{R} \to \mathbb{R}\), gradient descent simplifies significantly. The gradient becomes the derivative, and the update rule becomes:&lt;/p&gt;

&lt;blockquote&gt;
\[x^{(k)} = x^{(k-1)} - t f&apos;(x^{(k-1)}), \quad k = 1, 2, 3, ...\]
&lt;/blockquote&gt;

&lt;p&gt;where \(f&apos;(x)\) is the derivative of \(f\) at point \(x\).&lt;/p&gt;

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

&lt;p&gt;In the single variable case, the derivative \(f&apos;(x)\) represents the slope of the tangent line at point \(x\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If \(f&apos;(x) &amp;gt; 0\), the function is increasing, so we move left (subtract a positive value)&lt;/li&gt;
  &lt;li&gt;If \(f&apos;(x) &amp;lt; 0\), the function is decreasing, so we move right (subtract a negative value)&lt;/li&gt;
  &lt;li&gt;If \(f&apos;(x) = 0\), we have reached a critical point (potential minimum)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;learning-rate-t&quot;&gt;Learning rate \(t\)&lt;/h3&gt;

&lt;p&gt;The learning rate \(t\) (also called step size) is a crucial hyperparameter that can be set by the algorithm designer. It controls how large steps we take in the direction of the negative gradient.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Impact of Learning Rate:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Too small (\(t \ll 1\))&lt;/strong&gt;: The algorithm will update very slowly, requiring many iterations to converge to the optimal solution. While this ensures stability, it can be computationally expensive.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Too large (\(t \gg 1\))&lt;/strong&gt;: The algorithm may overshoot the minimum and potentially diverge, oscillating around the optimal point or even moving away from it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Just right&lt;/strong&gt;: The algorithm converges quickly and smoothly to the optimal solution.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Common strategies for choosing learning rate:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Fixed step size&lt;/strong&gt;: Use a constant value throughout the optimization&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Exact line search&lt;/strong&gt;: At each iteration, choose \(t\) to minimize \(f(x^{(k-1)} - t\nabla f(x^{(k-1)}))\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Backtracking line search&lt;/strong&gt;: Start with a large step size and reduce it until sufficient decrease is achieved&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Adaptive methods&lt;/strong&gt;: Adjust the learning rate based on the optimization progress (e.g., Adam, RMSprop)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;example-quadratic-function&quot;&gt;Example: Quadratic Function&lt;/h3&gt;

&lt;p&gt;Consider the quadratic function \(f(x) = \frac{1}{2}(x - 2)^2 + 1\) with derivative \(f&apos;(x) = x - 2\).&lt;/p&gt;

&lt;p&gt;The gradient descent update becomes:&lt;/p&gt;
&lt;blockquote&gt;
\[x^{(k)} = x^{(k-1)} - t(x^{(k-1)} - 2)\]
&lt;/blockquote&gt;

&lt;p&gt;Starting from \(x^{(0)} = 0\) with step size \(t = 0.1\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(x^{(1)} = 0 - 0.1(0 - 2) = 0.2 \\\) 
\(x^{(2)} = 0.2 - 0.1(0.2 - 2) = 0.38\)
\(x^{(3)} = 0.38 - 0.1(0.38 - 2) = 0.542\)
…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The sequence converges to \(x^* = 2\), which is the global minimum.&lt;/p&gt;

&lt;h3 id=&quot;step-size-selection&quot;&gt;Step Size Selection&lt;/h3&gt;

&lt;p&gt;The choice of step size \(t\) is crucial:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Too small&lt;/strong&gt;: Convergence is very slow&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Too large&lt;/strong&gt;: The algorithm may overshoot and diverge&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Optimal&lt;/strong&gt;: For quadratic functions \(f(x) = \frac{1}{2}ax^2 + bx + c\) with \(a &amp;gt; 0\), the optimal step size is \(t = \frac{1}{a}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;interactive-visualization&quot;&gt;Interactive Visualization&lt;/h3&gt;

&lt;div id=&quot;single-var-gradient-descent&quot; style=&quot;margin: 20px 0;&quot;&gt;
    &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
        &lt;label for=&quot;step-size-slider&quot;&gt;Step Size (t): &lt;span id=&quot;step-size-value&quot;&gt;0.1&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
        &lt;input type=&quot;range&quot; id=&quot;step-size-slider&quot; min=&quot;0.01&quot; max=&quot;0.5&quot; step=&quot;0.01&quot; value=&quot;0.1&quot; style=&quot;width: 300px;&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
        &lt;label for=&quot;start-point-slider&quot;&gt;Starting Point: &lt;span id=&quot;start-point-value&quot;&gt;-3&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
        &lt;input type=&quot;range&quot; id=&quot;start-point-slider&quot; min=&quot;-5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;-3&quot; style=&quot;width: 300px;&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
        &lt;button id=&quot;start-animation&quot;&gt;Start Animation&lt;/button&gt;
        &lt;button id=&quot;reset-animation&quot;&gt;Reset&lt;/button&gt;
        &lt;button id=&quot;step-once&quot;&gt;Single Step&lt;/button&gt;
    &lt;/div&gt;
    
    &lt;canvas id=&quot;gradient-canvas&quot; width=&quot;600&quot; height=&quot;400&quot; style=&quot;border: 1px solid #ccc; display: block; margin: 0 auto;&quot;&gt;&lt;/canvas&gt;
    
    &lt;div id=&quot;iteration-info&quot; style=&quot;text-align: center; margin-top: 10px; font-family: monospace;&quot;&gt;
        Iteration: 0, x = -3.000, f(x) = 13.500, f&apos;(x) = -5.000
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
class SingleVarGradientDescent {
    constructor() {
        this.canvas = document.getElementById(&apos;gradient-canvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.stepSizeSlider = document.getElementById(&apos;step-size-slider&apos;);
        this.startPointSlider = document.getElementById(&apos;start-point-slider&apos;);
        this.stepSizeValue = document.getElementById(&apos;step-size-value&apos;);
        this.startPointValue = document.getElementById(&apos;start-point-value&apos;);
        this.iterationInfo = document.getElementById(&apos;iteration-info&apos;);
        
        // Animation state
        this.isAnimating = false;
        this.currentX = -3;
        this.iteration = 0;
        this.history = [];
        this.animationId = null;
        
        // Function parameters: f(x) = 0.5 * (x - 2)^2 + 1
        this.a = 0.5;
        this.b = 2;
        this.c = 1;
        
        this.setupEventListeners();
        this.reset();
    }
    
    setupEventListeners() {
        this.stepSizeSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.stepSizeValue.textContent = e.target.value;
        });
        
        this.startPointSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.startPointValue.textContent = e.target.value;
            if (!this.isAnimating) {
                this.reset();
            }
        });
        
        document.getElementById(&apos;start-animation&apos;).addEventListener(&apos;click&apos;, () =&gt; {
            this.startAnimation();
        });
        
        document.getElementById(&apos;reset-animation&apos;).addEventListener(&apos;click&apos;, () =&gt; {
            this.reset();
        });
        
        document.getElementById(&apos;step-once&apos;).addEventListener(&apos;click&apos;, () =&gt; {
            this.singleStep();
        });
    }
    
    // Function: f(x) = 0.5 * (x - 2)^2 + 1
    f(x) {
        return this.a * Math.pow(x - this.b, 2) + this.c;
    }
    
    // Derivative: f&apos;(x) = (x - 2)
    fprime(x) {
        return 2 * this.a * (x - this.b);
    }
    
    // Convert x coordinate to canvas coordinate
    xToCanvas(x) {
        const xMin = -5, xMax = 5;
        return (x - xMin) / (xMax - xMin) * this.canvas.width;
    }
    
    // Convert y coordinate to canvas coordinate
    yToCanvas(y) {
        const yMin = 0, yMax = 15;
        return this.canvas.height - (y - yMin) / (yMax - yMin) * this.canvas.height;
    }
    
    // Convert canvas x to actual x
    canvasToX(canvasX) {
        const xMin = -5, xMax = 5;
        return xMin + (canvasX / this.canvas.width) * (xMax - xMin);
    }
    
    drawFunction() {
        this.ctx.strokeStyle = &apos;#2196F3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let canvasX = 0; canvasX &lt;= this.canvas.width; canvasX += 2) {
            const x = this.canvasToX(canvasX);
            const y = this.f(x);
            const canvasY = this.yToCanvas(y);
            
            if (canvasX === 0) {
                this.ctx.moveTo(canvasX, canvasY);
            } else {
                this.ctx.lineTo(canvasX, canvasY);
            }
        }
        this.ctx.stroke();
    }
    
    drawAxes() {
        this.ctx.strokeStyle = &apos;#666&apos;;
        this.ctx.lineWidth = 1;
        
        // X-axis
        const yZero = this.yToCanvas(0);
        this.ctx.beginPath();
        this.ctx.moveTo(0, yZero);
        this.ctx.lineTo(this.canvas.width, yZero);
        this.ctx.stroke();
        
        // Y-axis
        const xZero = this.xToCanvas(0);
        this.ctx.beginPath();
        this.ctx.moveTo(xZero, 0);
        this.ctx.lineTo(xZero, this.canvas.height);
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#666&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        
        // X-axis labels
        for (let x = -4; x &lt;= 4; x += 2) {
            const canvasX = this.xToCanvas(x);
            this.ctx.fillText(x.toString(), canvasX, yZero + 15);
        }
        
        // Y-axis labels
        this.ctx.textAlign = &apos;right&apos;;
        for (let y = 2; y &lt;= 14; y += 2) {
            const canvasY = this.yToCanvas(y);
            this.ctx.fillText(y.toString(), xZero - 5, canvasY + 4);
        }
    }
    
    drawCurrentPoint() {
        const canvasX = this.xToCanvas(this.currentX);
        const canvasY = this.yToCanvas(this.f(this.currentX));
        
        // Current point
        this.ctx.fillStyle = &apos;#F44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(canvasX, canvasY, 6, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Tangent line
        const derivative = this.fprime(this.currentX);
        const tangentLength = 1;
        const x1 = this.currentX - tangentLength;
        const x2 = this.currentX + tangentLength;
        const y1 = this.f(this.currentX) + derivative * (x1 - this.currentX);
        const y2 = this.f(this.currentX) + derivative * (x2 - this.currentX);
        
        this.ctx.strokeStyle = &apos;#FF9800&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.moveTo(this.xToCanvas(x1), this.yToCanvas(y1));
        this.ctx.lineTo(this.xToCanvas(x2), this.yToCanvas(y2));
        this.ctx.stroke();
    }
    
    drawHistory() {
        if (this.history.length &lt; 2) return;
        
        this.ctx.strokeStyle = &apos;#4CAF50&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.setLineDash([5, 5]);
        this.ctx.beginPath();
        
        for (let i = 0; i &lt; this.history.length; i++) {
            const x = this.history[i];
            const canvasX = this.xToCanvas(x);
            const canvasY = this.yToCanvas(this.f(x));
            
            if (i === 0) {
                this.ctx.moveTo(canvasX, canvasY);
            } else {
                this.ctx.lineTo(canvasX, canvasY);
            }
        }
        this.ctx.stroke();
        this.ctx.setLineDash([]);
        
        // Draw history points
        this.ctx.fillStyle = &apos;#4CAF50&apos;;
        for (let i = 0; i &lt; this.history.length - 1; i++) {
            const x = this.history[i];
            const canvasX = this.xToCanvas(x);
            const canvasY = this.yToCanvas(this.f(x));
            
            this.ctx.beginPath();
            this.ctx.arc(canvasX, canvasY, 3, 0, 2 * Math.PI);
            this.ctx.fill();
        }
    }
    
    draw() {
        // Clear canvas
        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
        
        // Draw components
        this.drawAxes();
        this.drawFunction();
        this.drawHistory();
        this.drawCurrentPoint();
        
        // Update iteration info
        this.iterationInfo.textContent = 
            `Iteration: ${this.iteration}, x = ${this.currentX.toFixed(3)}, ` +
            `f(x) = ${this.f(this.currentX).toFixed(3)}, f&apos;(x) = ${this.fprime(this.currentX).toFixed(3)}`;
    }
    
    singleStep() {
        if (Math.abs(this.fprime(this.currentX)) &lt; 1e-6) {
            return; // Already at minimum
        }
        
        const stepSize = parseFloat(this.stepSizeSlider.value);
        const newX = this.currentX - stepSize * this.fprime(this.currentX);
        
        this.history.push(this.currentX);
        this.currentX = newX;
        this.iteration++;
        
        this.draw();
    }
    
    startAnimation() {
        if (this.isAnimating) {
            this.stopAnimation();
            return;
        }
        
        this.isAnimating = true;
        document.getElementById(&apos;start-animation&apos;).textContent = &apos;Stop Animation&apos;;
        
        const animate = () =&gt; {
            if (!this.isAnimating) return;
            
            if (Math.abs(this.fprime(this.currentX)) &gt; 1e-6 &amp;&amp; this.iteration &lt; 100) {
                this.singleStep();
                this.animationId = setTimeout(animate, 500);
            } else {
                this.stopAnimation();
            }
        };
        
        animate();
    }
    
    stopAnimation() {
        this.isAnimating = false;
        document.getElementById(&apos;start-animation&apos;).textContent = &apos;Start Animation&apos;;
        if (this.animationId) {
            clearTimeout(this.animationId);
            this.animationId = null;
        }
    }
    
    reset() {
        this.stopAnimation();
        this.currentX = parseFloat(this.startPointSlider.value);
        this.iteration = 0;
        this.history = [];
        this.draw();
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new SingleVarGradientDescent();
});
&lt;/script&gt;

&lt;h2 id=&quot;gradient-descent-method-for-multivariables-function&quot;&gt;Gradient Descent Method for Multivariables function&lt;/h2&gt;

&lt;p&gt;Gradient descent starts from an initial point \(x^{(0)} \in \mathbb{R}^n\) and iteratively updates as follows until a stopping criterion is met:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(x^{(k)} = x^{(k-1)} - t \nabla f(x^{(k-1)}), \quad k = 1, 2, 3, ...\), \(t &amp;gt; 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Pseudocode:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Given a starting point&lt;/strong&gt; \(x \in dom(f)\) &lt;br /&gt;
&lt;strong&gt;Repeat&lt;/strong&gt;  &lt;br /&gt;&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;Determine descent direction \(\Delta x = -\nabla f(x)\). &lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;Line search: choose step size \(t &amp;gt; 0\). &lt;br /&gt;&lt;/li&gt;
    &lt;li&gt;Update \(x = x + t \Delta x\). &lt;br /&gt;
&lt;strong&gt;Until&lt;/strong&gt; stopping criterion is satisfied &lt;br /&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;examples&quot;&gt;Examples&lt;/h3&gt;

&lt;p&gt;The figure below shows gradient descent on a convex function. In this case, the local minimum is also the global minimum.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_01_gradientdescent1.png&quot; alt=&quot;gradientdescent1&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Gradient descent in convex functions[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;The next figure shows gradient descent on a non-convex function. Here, the initial point determines which local minimum is reached.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_01_gradientdescent2.png&quot; alt=&quot;gradientdescent2&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] Gradient descent in non-convex functions[3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;gradient-descent-interpretation&quot;&gt;Gradient Descent Interpretation&lt;/h2&gt;
&lt;p&gt;Gradient descent can be interpreted as choosing the next point by minimizing a quadratic approximation of the function.&lt;/p&gt;

&lt;p&gt;For a function \(f\), the second-order Taylor expansion around \(x\) is:&lt;/p&gt;

&lt;blockquote&gt;
\[f(y) = f(x) + \nabla f(x)^T (y - x) + \frac{1}{2} (y - x)^T \nabla^2 f(x) (y - x) + \text{higher-order terms}.\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[f(y) \approx f(x) + \nabla f(x)^T (y - x) +  \frac{1}{2} \nabla^2 f(x)  \|y - x\|_2^2\]
&lt;/blockquote&gt;

&lt;p&gt;If we approximate the Hessian \(\nabla^2 f(x)\) by \(\frac{1}{t}I\), then:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(y) \approx f(x) + \nabla f(x)^T (y - x) +  \frac{1}{2t}  \|y - x\|_2^2\)
where \(t\) is the step size.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thus, in gradient descent, the function is approximated by a quadratic function whose Hessian matrix has eigenvalues equal to the reciprocal of the step size. The term \(f(x) + \nabla f(x)^T (y - x)\) represents a linear approximation of \(f\), and \(\frac{1}{2t}  \|y - x\|_2^2\) serves as a proximity term indicating how close \(y\) is to \(x\).&lt;/p&gt;

&lt;p&gt;The next position is chosen as the minimum of this approximated quadratic function. Setting the gradient of \(f(y)\) to zero to find the next position \(y = x^+\) leads to:&lt;/p&gt;

&lt;blockquote&gt;
\[x^+ = x - t \nabla f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;In the illustration below, the blue dot represents the current position \(x\), and the red dot represents the next position \(y\). The curve below is the actual function \(f\), and the curve above is the quadratic approximation of \(f\). Hence, the red dot indicates the minimum of the quadratic approximation.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_01_gradientdescent3.png&quot; alt=&quot;gradientdescent3&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$ \text{[Fig 3] Gradient descent algorithm : red dot is } x^+ \text{ and blue dot } x \text{ [3]} $$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;The proximity of the next position \(y\) to the current position \(x\) is influenced by the weight of the proximity term \(\frac{1}{2t}\). A smaller \(t\) results in a larger weight for the proximity term, leading to smaller steps. This process can be expressed as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^+ = \underset{y}{\arg \min} \ f(x) + \nabla f(x)^T (y - x) + \frac{1}{2t} \parallel y - x \parallel_2^2
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>06 Gradient Descent</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_00_gradient_descent/"/>
   <updated>2021-03-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_00_gradient_descent</id>
   <content type="html">&lt;p&gt;In this chapter, we explore &lt;strong&gt;Gradient Descent&lt;/strong&gt;, one of the most fundamental and important methods in optimization.&lt;/p&gt;

&lt;p&gt;In optimization algorithms, choosing the search direction and step size is crucial for convergence speed and success. Gradient descent moves in the direction of the negative gradient. The step size can be fixed or adaptively chosen, and we will discuss both approaches in this chapter.&lt;/p&gt;

&lt;p&gt;For gradient descent to converge, certain preconditions must be met. If these conditions are satisfied, we can analyze how quickly gradient descent converges. If strong convexity holds, convergence is even faster, and we will examine the convergence rate in such cases.&lt;/p&gt;

&lt;p&gt;We will also look at applications of gradient descent, including gradient boosting and stochastic gradient descent.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-01-04 Chuẩn Euclidean - L2 - là Lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_07_euclidean_norm_convexity_proof/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_07_euclidean_norm_convexity_proof</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Chuẩn Euclidean&lt;/strong&gt; (còn gọi là chuẩn \(\ell_2\)) của một vector \(x \in \mathbb{R}^n\) được định nghĩa là:&lt;/p&gt;

\[\|x\|_2 = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2} = \sqrt{x^T x}\]

&lt;p&gt;Chúng ta sẽ chứng minh rằng hàm này là lồi sử dụng ba phương pháp khác nhau:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Chứng minh dựa trên định nghĩa&lt;/strong&gt; sử dụng bất đẳng thức Jensen&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kiểm tra đạo hàm bậc hai&lt;/strong&gt; (phân tích Hessian)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phương pháp bất đẳng thức tam giác&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;phương-pháp-1-chứng-minh-dựa-trên-định-nghĩa&quot;&gt;Phương pháp 1: Chứng minh Dựa trên Định nghĩa&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Định lý&lt;/strong&gt;: Chuẩn Euclidean \(f(x) = \|x\|_2\) là lồi trên \(\mathbb{R}^n\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Chứng minh&lt;/strong&gt;: 
Để chứng minh tính lồi, chúng ta cần chỉ ra rằng với bất kỳ \(x, y \in \mathbb{R}^n\) và \(\theta \in [0,1]\):&lt;/p&gt;

\[\|\theta x + (1-\theta) y\|_2 \leq \theta \|x\|_2 + (1-\theta) \|y\|_2\]

&lt;p&gt;Let \(z = \theta x + (1-\theta) y\). Then:&lt;/p&gt;

\[\begin{align}
\|z\|_2^2 &amp;amp;= \|\theta x + (1-\theta) y\|_2^2 \\
&amp;amp;= (\theta x + (1-\theta) y)^T (\theta x + (1-\theta) y) \\
&amp;amp;= \theta^2 x^T x + 2\theta(1-\theta) x^T y + (1-\theta)^2 y^T y \\
&amp;amp;= \theta^2 \|x\|_2^2 + 2\theta(1-\theta) x^T y + (1-\theta)^2 \|y\|_2^2
\end{align}\]

&lt;p&gt;By the &lt;strong&gt;Cauchy-Schwarz inequality&lt;/strong&gt;: \(x^T y \leq \|x\|_2 \|y\|_2\)&lt;/p&gt;

&lt;p&gt;Therefore:
\(\|z\|_2^2 \leq \theta^2 \|x\|_2^2 + 2\theta(1-\theta) \|x\|_2 \|y\|_2 + (1-\theta)^2 \|y\|_2^2\)&lt;/p&gt;

&lt;p&gt;The right-hand side can be factored as:
\(\theta^2 \|x\|_2^2 + 2\theta(1-\theta) \|x\|_2 \|y\|_2 + (1-\theta)^2 \|y\|_2^2 = (\theta \|x\|_2 + (1-\theta) \|y\|_2)^2\)&lt;/p&gt;

&lt;p&gt;Taking square roots of both sides:
\(\|\theta x + (1-\theta) y\|_2 \leq \theta \|x\|_2 + (1-\theta) \|y\|_2\)&lt;/p&gt;

&lt;p&gt;This proves that the Euclidean norm is convex. \(\square\)&lt;/p&gt;

&lt;h2 id=&quot;method-2-second-derivative-test-hessian-analysis&quot;&gt;Method 2: Second Derivative Test (Hessian Analysis)&lt;/h2&gt;

&lt;p&gt;For twice-differentiable functions, we can use the &lt;strong&gt;second derivative test&lt;/strong&gt;: a function is convex if its Hessian matrix is positive semidefinite.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analysis&lt;/strong&gt;: 
The Euclidean norm \(f(x) = \|x\|_2 = \sqrt{x^T x}\) is not differentiable at \(x = 0\). However, for \(x \neq 0\), we can compute:&lt;/p&gt;

\[\frac{\partial f}{\partial x_i} = \frac{x_i}{\|x\|_2}\]

\[\frac{\partial^2 f}{\partial x_i \partial x_j} = \frac{1}{\|x\|_2} \delta_{ij} - \frac{x_i x_j}{\|x\|_2^3}\]

&lt;p&gt;The Hessian matrix is:
\(H = \frac{1}{\|x\|_2} I - \frac{1}{\|x\|_2^3} x x^T = \frac{1}{\|x\|_2} \left( I - \frac{x x^T}{\|x\|_2^2} \right)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Verification of positive semidefiniteness&lt;/strong&gt;:
For any vector \(v \in \mathbb{R}^n\):
\(v^T H v = \frac{1}{\|x\|_2} \left( \|v\|_2^2 - \frac{(x^T v)^2}{\|x\|_2^2} \right)\)&lt;/p&gt;

&lt;p&gt;By Cauchy-Schwarz inequality: \((x^T v)^2 \leq \|x\|_2^2 \|v\|_2^2\)&lt;/p&gt;

&lt;p&gt;Therefore: \(\|v\|_2^2 - \frac{(x^T v)^2}{\|x\|_2^2} \geq 0\)&lt;/p&gt;

&lt;p&gt;This shows \(H \succeq 0\), confirming convexity for \(x \neq 0\).&lt;/p&gt;

&lt;h2 id=&quot;method-3-triangle-inequality-approach&quot;&gt;Method 3: Triangle Inequality Approach&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Alternative Proof using Minkowski Inequality&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;The Euclidean norm satisfies the &lt;strong&gt;triangle inequality&lt;/strong&gt;:
\(\|x + y\|_2 \leq \|x\|_2 + \|y\|_2\)&lt;/p&gt;

&lt;p&gt;For convexity, let \(u = \theta x\) and \(v = (1-\theta) y\) where \(\theta \in [0,1]\):
\(\|\theta x + (1-\theta) y\|_2 = \|u + v\|_2 \leq \|u\|_2 + \|v\|_2 = \theta \|x\|_2 + (1-\theta) \|y\|_2\)&lt;/p&gt;

&lt;p&gt;This directly establishes the convexity condition.&lt;/p&gt;

&lt;h2 id=&quot;key-properties-and-applications&quot;&gt;Key Properties and Applications&lt;/h2&gt;

&lt;h3 id=&quot;properties-of-euclidean-norm-convexity&quot;&gt;Properties of Euclidean Norm Convexity&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Strict Convexity&lt;/strong&gt;: The Euclidean norm is actually &lt;strong&gt;strictly convex&lt;/strong&gt; on any line not passing through the origin.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Homogeneity&lt;/strong&gt;: \(\|\alpha x\|_2 = \lvert\alpha\rvert \|x\|_2\) for any scalar \(\alpha\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Subadditivity&lt;/strong&gt;: \(\|x + y\|_2 \leq \|x\|_2 + \|y\|_2\) (Triangle inequality).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h3&gt;

&lt;p&gt;The convexity of the Euclidean norm has important implications:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Least Squares Problems&lt;/strong&gt;: The objective function \(\|Ax - b\|_2^2\) is convex.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: \(\ell_2\)-regularization terms like \(\lambda \|x\|_2\) preserve convexity.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Constrained Optimization&lt;/strong&gt;: Norm constraints \(\|x\|_2 \leq r\) define convex feasible sets.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We have proven that the Euclidean norm is convex using three different approaches:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Direct definition&lt;/strong&gt;: Using Jensen’s inequality and Cauchy-Schwarz&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second derivative test&lt;/strong&gt;: Showing the Hessian is positive semidefinite&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Triangle inequality&lt;/strong&gt;: Leveraging the fundamental norm property&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This convexity property is fundamental in optimization theory and has wide-ranging applications in machine learning, signal processing, and numerical analysis.&lt;/p&gt;

&lt;p&gt;The interactive visualization above demonstrates how the convexity condition \(\|\theta x + (1-\theta) y\|_2 \leq \theta \|x\|_2 + (1-\theta) \|y\|_2\) holds for any choice of points and convex combination parameter \(\theta\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-06 Tính lồi đối với bất đẳng thức tổng quát</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_06_convexity_with_respect_to_generalized_inequalities/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_06_convexity_with_respect_to_generalized_inequalities</id>
   <content type="html">&lt;p&gt;Phần này thảo luận tính lồi đối với bất đẳng thức tổng quát, mở rộng khái niệm tính lồi vượt ra ngoài các hàm giá trị thực chuẩn.&lt;/p&gt;

&lt;p&gt;Trong các không gian khác với \(\mathbb{R}\), chúng ta sử dụng định nghĩa của nón cho các biểu thức bất đẳng thức tổng quát mở rộng khái niệm thứ tự thường được sử dụng trong không gian \(\mathbb{R}\) (xem &lt;a href=&quot;/contents/vi/chapter02/02_01_04_Convex_cone/&quot;&gt;02-01-04&lt;/a&gt;). Trong phần này, chúng ta xem xét các khái niệm về tính đơn điệu và tính lồi mở rộng ra ngoài không gian \(\mathbb{R}\) sử dụng khái niệm nón.&lt;/p&gt;

&lt;h2 id=&quot;tính-đơn-điệu-đối-với-bất-đẳng-thức-tổng-quát&quot;&gt;Tính đơn điệu đối với bất đẳng thức tổng quát&lt;/h2&gt;

&lt;p&gt;Giả sử \(K \subseteq \mathbb{R}^n\) là một nón thích hợp được biểu thị bởi \(\preceq_K\). Một nón lồi \(K \subseteq \mathbb{R}^n\) là một &lt;strong&gt;nón thích hợp&lt;/strong&gt; nếu nó thỏa mãn các điều kiện sau:&lt;/p&gt;

&lt;p&gt;• \(K\) đóng (chứa biên của nó)
• \(K\) rắn (có nội tâm khác rỗng)
• \(K\) nhọn (không chứa đường thẳng)&lt;/p&gt;

&lt;p&gt;Chúng ta định nghĩa &lt;strong&gt;không giảm theo \(K\)&lt;/strong&gt; như sau:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \mapsto \mathbb{R}\) là không giảm theo \(K\) nếu \(x \preceq_K y \Rightarrow f(x) \leq f(y)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Cũng vậy, khi điều kiện sau được thỏa mãn, chúng ta nói nó là &lt;strong&gt;tăng theo \(K\)&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \mapsto \mathbb{R}\) là tăng theo \(K\) nếu \(x \preceq_K y, x \neq y \Rightarrow f(x) &amp;lt; f(y)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;điều-kiện-gradient-cho-tính-đơn-điệu&quot;&gt;Điều kiện gradient cho tính đơn điệu&lt;/h3&gt;

&lt;p&gt;Với một hàm khả vi \(f : \mathbb{R} \mapsto \mathbb{R}\) không giảm trên miền lồi (tức là khoảng) có nghĩa là \(f&apos;(x) \geq 0\) với mọi \(x \in \text{dom}f\), và nếu \(f&apos;(x) &amp;gt; 0\) với mọi \(x \in \text{dom}f\), thì nó là tăng. Tương tự, tính đơn điệu có thể được biểu thị như một khái niệm mở rộng trong bất đẳng thức tổng quát.&lt;/p&gt;

&lt;p&gt;Khi miền là lồi, một hàm khả vi \(f\) không giảm theo \(K\) có nghĩa là thỏa mãn phương trình sau. Lưu ý rằng khác với vô hướng đơn giản, gradient \(\nabla f(x)\) phải không âm trong bất đẳng thức đối ngẫu.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Một hàm khả vi \(f\) không giảm theo \(K\) \(\Longleftrightarrow\) \(\nabla f(x) \succeq_{K^*} 0\) với mọi \(x \in \text{dom}f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nếu điều kiện sau được thỏa mãn, \(f\) được gọi là &lt;strong&gt;tăng theo \(K\)&lt;/strong&gt;. Như với vô hướng, điều ngược lại không đúng.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\nabla f(x) \succ_{K^*} 0\) với mọi \(x \in \text{dom}f\) \(\Rightarrow\) \(f\) tăng theo \(K\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;tính-lồi-đối-với-bất-đẳng-thức-tổng-quát&quot;&gt;Tính lồi đối với bất đẳng thức tổng quát&lt;/h3&gt;

&lt;p&gt;Gọi \(K \subseteq \mathbb{R}^m\) là một nón thích hợp liên kết với bất đẳng thức tổng quát \(\preceq_K\).
Khi đó, nếu \(f : \mathbb{R}^n \mapsto \mathbb{R}^m\) được gọi là &lt;strong&gt;lồi theo \(K\)&lt;/strong&gt; với mọi \(x, y\) và \(0 \leq \theta \leq 1\), bất đẳng thức sau đây đúng:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \mapsto \mathbb{R}^m\) là lồi theo \(K\) \(\Rightarrow\) \(f(\theta x + (1 - \theta) y) \preceq_K \theta f(x) + (1 - \theta) f(y)\) với \(0 &amp;lt; \theta &amp;lt; 1\) cho mọi \(x, y\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Cũng vậy, điều kiện cho &lt;strong&gt;lồi chặt theo \(K\)&lt;/strong&gt; là như sau:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(\theta x + (1 - \theta) y) \prec_K \theta f(x) + (1 - \theta) f(y)\) với mọi \(x \neq y\) và \(0 &amp;lt; \theta &amp;lt; 1\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Khi \(m = 1\) và \(K = \mathbb{R}_+\), điều này trở thành bất đẳng thức thỏa mãn tính lồi tổng quát mà chúng ta đã thảo luận trước đó.&lt;/p&gt;

&lt;h3 id=&quot;đặc-trưng-đối-ngẫu-của-tính-lồi-theo-k&quot;&gt;Đặc trưng đối ngẫu của tính lồi theo \(K\)&lt;/h3&gt;

&lt;p&gt;\(f\) là lồi theo \(K\) có nghĩa là hàm (giá trị thực) \(w^T f\) là lồi với mọi \(w \succeq_{K^*} 0\). \(f\) là lồi chặt theo \(K\) có nghĩa là hàm (giá trị thực) \(w^T f\) là lồi chặt với mọi \(w \succeq_{K^*} 0\). Điều này theo sau từ định nghĩa và tính chất của bất đẳng thức đối ngẫu.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;các-hàm-lồi-theo-k-khả-vi&quot;&gt;Các hàm lồi theo \(K\) khả vi&lt;/h3&gt;

&lt;p&gt;Nếu một hàm khả vi \(f\) là lồi theo \(K\) và miền hàm là lồi, thì phương trình sau đây đúng:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(y) \succeq_K f(x) + Df(x)(y - x)\) với mọi \(x, y \in \text{dom}f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(Df(x) \in \mathbb{R}^{m \times n}\) là đạo hàm hoặc ma trận Jacobian của \(f\) tại điểm \(x\).&lt;/p&gt;

&lt;p&gt;Nếu \(f\) là lồi chặt theo \(K\) và miền hàm là lồi, thì phương trình sau đây đúng:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(y) \succ_K f(x) + Df(x)(y - x)\) với mọi \(x, y \in \text{dom}f\), \(x \neq y\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;định-lý-hợp-thành&quot;&gt;Định lý hợp thành&lt;/h3&gt;

&lt;p&gt;Nhiều kết quả từ hợp thành có thể được tổng quát hóa cho tính lồi theo \(K\).
Ví dụ, nếu \(g : \mathbb{R}^n \mapsto \mathbb{R}^p\) là lồi theo \(K\), \(h : \mathbb{R}^p \rightarrow \mathbb{R}\) là lồi, và phần mở rộng giá trị mở rộng \(\widetilde{h}\) của \(h\) là không giảm theo \(K\), thì \(h \circ g\) là lồi. Điều này tổng quát hóa sự thật rằng hợp thành của một hàm lồi với một hàm lồi không giảm là lồi.
(Điều kiện \(\widetilde{h}\) không giảm theo \(K\) có nghĩa là \(\text{dom}h - K = \text{dom}h\).)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-05 Hàm log-lõm và log-lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_05_log_concave_and_log_convex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_05_log_concave_and_log_convex_functions</id>
   <content type="html">&lt;p&gt;Phần này giới thiệu các hàm log-lõm và log-lồi, quan trọng trong xác suất, thống kê và tối ưu hóa.&lt;/p&gt;

&lt;h2 id=&quot;định-nghĩa&quot;&gt;Định nghĩa&lt;/h2&gt;

&lt;p&gt;Các định nghĩa của hàm log-lõm và log-lồi như sau.&lt;/p&gt;

&lt;h3 id=&quot;f--mathbbrn-rightarrow-mathbbr-là-lõm-logarithm-hoặc-log-lõm&quot;&gt;\(f : \mathbb{R}^n \rightarrow \mathbb{R}\) là Lõm logarithm hoặc log-lõm&lt;/h3&gt;
&lt;p&gt;Nếu \(f(x) &amp;gt; 0\) với mọi \(x \in \text{dom}f\) và \(\log f\) là lõm, thì \(f : \mathbb{R}^n \rightarrow \mathbb{R}\) được gọi là lõm logarithm hoặc log-lõm.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) là log-lõm với \(f(x) &amp;gt; 0\) cho mọi \(x \in \text{dom}f\) : &lt;br /&gt;
\(f(\theta x + (1 - \theta) y) \geq f(x)^\theta f(y)^{1-\theta}\) với \(0 \leq \theta \leq 1\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;f--mathbbrn-mapsto-mathbbr-là-lồi-logarithm-hoặc-log-lồi&quot;&gt;\(f : \mathbb{R}^n \mapsto \mathbb{R}\) là Lồi logarithm hoặc log-lồi&lt;/h3&gt;
&lt;p&gt;Nếu \(f(x) &amp;gt; 0\) với mọi \(x \in \text{dom}f\) và \(\log f\) là lồi, thì \(f : \mathbb{R}^n \mapsto \mathbb{R}\) được gọi là lồi logarithm hoặc log-lồi. Do đó, nếu \(f\) là log-lồi, thì \(1/f\) là log-lõm.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) là log-lồi với \(f(x) &amp;gt; 0\) cho mọi \(x \in \text{dom}f\) \(\Longleftrightarrow \frac{1}{f}\) là log-lõm.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Đôi khi tiện lợi khi cho phép giá trị \(f\) bằng 0, trong trường hợp này \(\log f(x) = -\infty\). Trong các trường hợp như vậy, nếu hàm giá trị mở rộng \(\log f\) là lõm, thì \(f\) có thể được gọi là log-lõm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Các hàm log-lồi và log-lõm lần lượt là giả lồi và giả lõm, vì logarithm là hàm đơn điệu tăng.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ&quot;&gt;Ví dụ&lt;/h2&gt;
&lt;h3 id=&quot;hàm-affine&quot;&gt;Hàm affine&lt;/h3&gt;
&lt;p&gt;Nếu \(f\) được định nghĩa như sau, thì nó là log-lõm.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x) = a^Tx + b\) trên \(\{x \mid a^Tx + b &amp;gt; 0\}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;lũy-thừa&quot;&gt;Lũy thừa&lt;/h3&gt;
&lt;p&gt;\(f(x) = x^a\) trên \(\mathbb{R}_{++}\) là log-lồi khi \(a \leq 0\) và log-lõm khi \(a \geq 0\).&lt;/p&gt;

&lt;h3 id=&quot;hàm-mũ&quot;&gt;Hàm mũ&lt;/h3&gt;
&lt;p&gt;\(f(x) = e^{ax}\) vừa là log-lồi vừa là log-lõm.&lt;/p&gt;

&lt;h3 id=&quot;hàm-phân-phối-tích-lũy-của-mật-độ-gauss&quot;&gt;Hàm phân phối tích lũy của mật độ Gauss&lt;/h3&gt;
&lt;p&gt;\(\Phi(x) = \frac{1}{ \sqrt{2 \pi } }  \int_ {-\infty} ^x e^{-u^2/2} du\) là log-lõm.&lt;/p&gt;

&lt;h3 id=&quot;hàm-gamma&quot;&gt;Hàm Gamma&lt;/h3&gt;
&lt;p&gt;\(\Gamma (x) = \int_0^\infty u^{x-1}e^{-u} du\)
là log-lồi với \(x \geq 1\).&lt;/p&gt;

&lt;h3 id=&quot;định-thức&quot;&gt;Định thức&lt;/h3&gt;
&lt;p&gt;\(\det X\) là log-lõm trên \(S^n_{++}\).&lt;/p&gt;

&lt;h3 id=&quot;định-thức-chia-vết&quot;&gt;Định thức chia vết&lt;/h3&gt;
&lt;p&gt;\(\det X / \text{tr} X\) là log-lõm trên \(S^n_{++}\).&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;tính-chất&quot;&gt;Tính chất&lt;/h2&gt;

&lt;h3 id=&quot;các-hàm-log-lồi--lõm-khả-vi-hai-lần&quot;&gt;Các hàm log-lồi / lõm khả vi hai lần&lt;/h3&gt;
&lt;p&gt;Nếu \(f\) khả vi hai lần và \(\text{dom} f\) lồi, thì phương trình sau đây đúng:&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\nabla ^2 \log f(x) = \frac{1}{f(x)} \nabla ^2f(x) - \frac{1}{f(x)^2}\nabla f(x) \nabla f(x)^T\]
&lt;/blockquote&gt;

&lt;p&gt;\(f\) là log-lồi \(\Longleftrightarrow\) \(f(x) \nabla ^2 f(x) \succeq \nabla f(x)\nabla f(x)^T\) với mọi \(x \in \text{dom} f\), và &lt;br /&gt;
\(f\) là log-lõm \(\Longleftrightarrow\) \(f(x) \nabla ^2 f(x) \preceq \nabla f(x)\nabla f(x)^T\) với mọi \(x \in \text{dom} f\).&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;nhân&quot;&gt;Nhân&lt;/h3&gt;
&lt;p&gt;Tính log-lồi và log-lõm đóng dưới phép nhân và nhân với số dương. 
Nếu \(f\) và \(g\) là log-lõm, thì tích theo điểm \(h(x) = f(x)g(x)\) cũng là log-lõm. 
Điều này là vì \(\log h(x) = \log f(x) + \log g(x)\), và cả \(\log f(x)\) và \(\log g(x)\) đều là các hàm lõm.&lt;/p&gt;

&lt;h3 id=&quot;cộng-và-tích-phân&quot;&gt;Cộng và Tích phân&lt;/h3&gt;
&lt;p&gt;Nói chung, tổng của các hàm log-lõm không phải là log-lõm. Tuy nhiên, tính log-lồi được bảo toàn dưới phép cộng.
Ví dụ, gọi \(f\) và \(g\) là các hàm log-lồi, tức là \(F = \log f\) và \(G = \log g\) là lồi.
Bằng các quy tắc hợp thành cho hàm lồi, điều sau đây đúng:&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
\[\log(exp F + exp G) = \log(f + g)\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này là lồi. (Vế trái là lồi vì: 1. các hàm log-lồi là lồi, 2. áp dụng hàm mũ cho hàm lồi bảo toàn tính lồi, 3. tổng của các hàm lồi là lồi, và 4. logarithm của hàm lồi là lồi.
Do đó, toàn bộ kết quả là lồi.) Kết luận, tổng của hai hàm log-lồi là log-lồi.&lt;/p&gt;

&lt;p&gt;Tổng quát hóa điều này, nếu \(f(x, y)\) là log-lồi với mọi \(y \in C\), thì \(g(x)\) là log-lồi.&lt;/p&gt;
&lt;blockquote&gt;
\[g(x) = \int_C^{} f(x,y) dy\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;tích-phân-của-các-hàm-log-lõm&quot;&gt;Tích phân của các hàm log-lõm&lt;/h3&gt;
&lt;p&gt;Trong một số trường hợp, tính log-lõm cũng được bảo toàn dưới phép tích phân. Nếu \(f : \mathbb{R}^n \times \mathbb{R}^m \mapsto \mathbb{R}\) là log-lõm, thì \(g(x)\) là một hàm log-lõm với \(x \in \mathbb{R}^n\).&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \mapsto \mathbb{R}\) là log-lõm \(\Longrightarrow\) \(g(x) = \int_{}^{} f(x,y) dy\) là log-lõm , \(x \in \mathbb{R}^n\) với mọi \(y \in C\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Dựa trên điều này, chúng ta có thể xác nhận rằng phân phối biên của một mật độ xác suất log-lõm là log-lõm.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Tính log-lõm cũng đóng dưới các phép toán tích chập. Nếu \(f\) và \(g\) là log-lõm trên \(\mathbb{R}^n\), thì tích chập của chúng cũng là log-lõm.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\), \(g\) là log-lõm trên \(\mathbb{R}^n \Longrightarrow (f \ast g)(x) = \int_{}^{} f(x-y)g(y) dy\) là log-lõm.&lt;br /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>03-04-04 Các phép toán bảo toàn tính giả lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_04_04_operations_that_preserve_quasiconvexity/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_04_04_operations_that_preserve_quasiconvexity</id>
   <content type="html">&lt;p&gt;Phần này thảo luận các phép toán bảo toàn tính giả lồi của các hàm.&lt;/p&gt;

&lt;h2 id=&quot;maximum-trọng-số-không-âm&quot;&gt;Maximum trọng số không âm&lt;/h2&gt;

&lt;p&gt;Khi \(f\) là một hàm giả lồi, maximum trọng số không âm \(f\) là giả lồi.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f = \max\{w_1f_1, ... ,w_mf_m\}\) với \(w_i \geq 0\) là giả lồi&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Khái niệm này có thể được mở rộng như sau:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x) = \sup_{y \in C}(w(y)g(x,y))\) với \(w(y) \geq 0\), 
trong đó \(g(x,y)\) là giả lồi theo \(x\) với mọi \(y\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;hợp-thành&quot;&gt;Hợp thành&lt;/h2&gt;

&lt;p&gt;Nếu \(g : \mathbb{R}^n \mapsto \mathbb{R}\) là giả lồi và \(h : \mathbb{R} \mapsto \mathbb{R}\) không giảm, thì hợp thành \(f\) thỏa mãn tính giả lồi.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f = h \circ g\) là giả lồi nếu \(h\) không giảm và \(g\) là giả lồi.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hợp thành một hàm giả lồi với các biến đổi affine hoặc tuyến tính-phân thức cho ra một hàm giả lồi.
Nếu \(f\) là giả lồi, thì \(g(x) = f(Ax + b)\) cũng là giả lồi, và \(\tilde{g}(x) = f((Ax + b)/(c^Tx + d))\) cũng là giả lồi trên tập \(\{x \mid c^Tx + d &amp;gt; 0, (Ax + b)/(c^Tx + d) \in \text{dom}f\}\).&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;cực-tiểu-hóa&quot;&gt;Cực tiểu hóa&lt;/h2&gt;

&lt;p&gt;Nếu \(f(x, y)\) thỏa mãn tính giả lồi và \(C\) là một tập lồi, thì điều kiện sau đây đúng:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(g(x) = \inf_{y \in C} f(x,y)\) là giả lồi nếu \(f\) là giả lồi theo \((x,y)\) và \(C\) là một tập lồi.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;biểu-diễn-thông-qua-họ-các-hàm-lồi&quot;&gt;Biểu diễn thông qua họ các hàm lồi&lt;/h2&gt;

&lt;p&gt;Các tập mức dưới của một hàm giả lồi \(f\) có thể được biểu diễn bằng các bất đẳng thức của các hàm lồi. Một họ các hàm lồi là \(\phi_t : \mathbb{R}^n \mapsto \mathbb{R}\) với \(t \in \mathbb{R}\), được định nghĩa như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[f(x) \leq t \Longleftrightarrow \phi_t(x) \leq 0\]
&lt;/blockquote&gt;

&lt;p&gt;Tức là, tập mức dưới \(t\) của hàm giả lồi \(f(x)\) trở thành tập mức dưới 0 của hàm lồi \(\phi_t\). Ở đây, \(t\) biểu thị chỉ số của hàm lồi \(\phi\). Với mọi \(x \in \mathbb{R}^n\), điều sau được thỏa mãn:&lt;/p&gt;
&lt;blockquote&gt;
\[\phi_t(x) \leq 0 \Rightarrow \phi_s(x) \leq 0 \text{ với } s \geq t\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>03-04-03 Hàm giả lồi khả vi</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_04_03_differentiable_quasiconvex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_04_03_differentiable_quasiconvex_functions</id>
   <content type="html">&lt;p&gt;Phần này thảo luận các tính chất và đặc trưng của các hàm giả lồi khả vi.&lt;/p&gt;

&lt;h2 id=&quot;điều-kiện-bậc-nhất&quot;&gt;Điều kiện bậc nhất&lt;/h2&gt;
&lt;p&gt;Gọi \(f : \mathbb{R}^n \rightarrow \mathbb{R}\) là một hàm khả vi. Nếu \(\text{dom}f\) lồi và điều kiện sau được thỏa mãn, thì \(f\) là giả lồi.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) là giả lồi \(\iff\) \(f(y) \leq f(x) \Rightarrow \nabla f(x)^T(y-x) \leq 0\) với mọi \(x, y \in \text{dom}f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/3.12_Three_level_curves_OV6vtPq.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Ba đường mức của một hàm giả lồi \(f\). \(\nabla f(x)\) là vector pháp tuyến định nghĩa siêu phẳng hỗ trợ của tập mức dưới \(\{z \mid f(z) \leq f(x)\}\) tại \(x\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Điều kiện bậc nhất cho tính giả lồi có vẻ tương tự như đặc trưng bậc nhất của tính lồi (xem &lt;a href=&quot;/contents/vi/chapter03/03_01_03_key_properties_of_convex_functions/&quot;&gt;03-01-03&lt;/a&gt;), nhưng có những khác biệt quan trọng. Ví dụ, nếu \(f\) lồi và \(\nabla f(x) = 0\), thì \(x\) là điểm cực tiểu toàn cục của \(f\), nhưng điều này không luôn đúng cho các hàm giả lồi.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;điều-kiện-bậc-hai&quot;&gt;Điều kiện bậc hai&lt;/h2&gt;

&lt;p&gt;Khi \(f\) khả vi hai lần, các điều kiện bậc hai được áp dụng. Nếu \(f\) là giả lồi, thì với mọi \(x \in \text{dom}f\) và mọi \(y \in \mathbb{R}^n\), điều sau đây đúng:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) là giả lồi, \(y^T \nabla f(x) = 0 \Longrightarrow y^T \nabla^2 f(x)y \geq 0\) với mọi \(x \in \text{dom} f\), mọi \(y \in \mathbb{R}^n\) &lt;br /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Với các hàm giả lồi trên \(\mathbb{R}\):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f\) là giả lồi, \(f&apos;(x) = 0 \Rightarrow f&apos;&apos;(x) \geq 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Tức là, nếu tồn tại bất kỳ điểm nào có độ dốc bằng không, giá trị đạo hàm bậc hai là không âm. Quay lại với \(\mathbb{R}^n\), điều kiện bậc hai cũng thỏa mãn các tính chất sau:&lt;/p&gt;

&lt;p&gt;1) Khi \(\nabla f(x) = 0\), chúng ta phải luôn có \(\nabla^2f(x) \succeq 0\).
2) Nếu \(\nabla f(x) \neq 0\), thì \(y^T \nabla f(x) = 0 \Rightarrow y^T \nabla^2 f(x)y \geq 0\), trong đó \(\nabla^2 f(x)\) hoạt động như ma trận Hessian và là nửa xác định dương trên không gian con \((n-1)\) chiều \(\nabla f(x)^\perp\).&lt;/p&gt;

&lt;p&gt;(Không gian con \((n-1)\) chiều \(\nabla f(x)^\perp\) có nghĩa là không gian con \((n-1)\) chiều vuông góc với \(\nabla f(x)\). Nó có \((n-1)\) chiều vì \(\nabla f(x)\) là gradient của hàm \(n\) chiều \(f\), làm giảm chiều đi một.)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-04-02 Các tính chất cơ bản của hàm giả lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_04_02_basic_properties_of_quasiconvex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_04_02_basic_properties_of_quasiconvex_functions</id>
   <content type="html">&lt;p&gt;Phần này đề cập các tính chất cơ bản của hàm giả lồi, bao gồm mối quan hệ của chúng với hàm lồi và hành vi của chúng dưới các phép toán khác nhau.&lt;/p&gt;

&lt;h2 id=&quot;bất-đẳng-thức-jensen-biến-đổi&quot;&gt;Bất đẳng thức Jensen biến đổi&lt;/h2&gt;
&lt;p&gt;Các hàm giả lồi có thể được định nghĩa thông qua bất đẳng thức Jensen như sau:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(\theta x + (1 - \theta)y) \leq \max\{f(x), f(y)\}\) với mọi \(x, y \in \text{dom}f, 0 \leq \theta \leq 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hình dưới đây cho thấy rằng nếu hàm \(f\) là giả lồi, thì giá trị của \(f\) dọc theo đoạn thẳng giữa hai điểm không vượt quá giá trị lớn nhất của \(f\) tại các điểm cuối.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/Fig.3.10_quasiconvex_function_on_R_4uChnEm.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;hàm giả lồi trên \(\mathbb{R}\). Các giá trị của \(f\) giữa \(x\) và \(y\) nhỏ hơn \(\max\{f(x), f(y)\}\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;hàm-giả-lồi-trên-mathbbr&quot;&gt;Hàm giả lồi trên \(\mathbb{R}\)&lt;/h2&gt;
&lt;p&gt;Một hàm liên tục \(f : \mathbb{R} \mapsto \mathbb{R}\) là giả lồi khi và chỉ khi nó thỏa mãn ít nhất một trong các điều kiện sau:&lt;/p&gt;

&lt;p&gt;• \(f\) không giảm
• \(f\) không tăng&lt;br /&gt;
• Tồn tại một điểm \(c \in \text{dom} f\) sao cho \(f\) không tăng trên \(\{t \in \text{dom}f \mid t \leq c\}\) và không giảm trên \(\{t \in \text{dom}f \mid t \geq c\}\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/Fig.3.11_quasiconvex_function_on_R_2_PPQpNiU.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;hàm giả lồi trên \(\mathbb{R}\). Nó không tăng với \(t \leq c\) trong đó \(t \in \text{dom} f\), và không giảm với \(t \geq c\) trong đó \(t \in \text{dom} f\).&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-04-01 Hàm giả lồi: định nghĩa và ví dụ</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_04_01_quasiconvex_functions_definition_and_examples/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_04_01_quasiconvex_functions_definition_and_examples</id>
   <content type="html">&lt;p&gt;Một hàm \(f:\mathbb{R}^n \rightarrow \mathbb{R}\) là giả lồi nếu tất cả các tập mức dưới \(\{x \mid f(x) \leq \alpha\}\) đều lồi với mọi \(\alpha \in \mathbb{R}\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Các hàm giả lồi tổng quát hóa các hàm lồi&lt;/strong&gt; và xuất hiện thường xuyên trong các bài toán tối ưu.&lt;/p&gt;

&lt;h2 id=&quot;định-nghĩa&quot;&gt;Định nghĩa&lt;/h2&gt;

&lt;p&gt;Một hàm \(f: \mathbb{R}^n \rightarrow \mathbb{R}\) được gọi là &lt;strong&gt;giả lồi&lt;/strong&gt; (hoặc &lt;strong&gt;đơn môđ&lt;/strong&gt;) nếu miền xác định \(\text{dom}f\) và tất cả các tập mức dưới \(S_{\alpha}\) (xem &lt;a href=&quot;/contents/vi/chapter03/03_01_03_key_properties_of_convex_functions/&quot;&gt;03-01-03&lt;/a&gt;) đều lồi.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \rightarrow \mathbb{R}\) là giả lồi nếu \(\text{dom}f\) và
\(S_{\alpha} =\{x \in \text{dom}f \mid f(x) \leq \alpha\}\) với \(\alpha \in \mathbb{R}\) đều lồi.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nếu hàm \(-f\) là giả lồi, thì \(f\) được gọi là &lt;strong&gt;giả lõm&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \rightarrow \mathbb{R}\) là giả lõm nếu \(\text{dom}f\) và
\(S_{\alpha} = \{ x \in \text{dom}f \mid f(x) \geq \alpha \}\) với \(\alpha \in \mathbb{R}\) đều lồi.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Khi \(f\) vừa giả lồi vừa giả lõm, nó được gọi là &lt;strong&gt;giả tuyến tính&lt;/strong&gt;, và miền xác định của hàm và tất cả các tập mức \(\{x \mid f(x)=\alpha\}\) đều lồi. Hình dưới đây cho thấy một ví dụ về hàm giả lồi.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/Fig3.9_quasiconvex_ftn_cAsoUpr.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] hàm giả lồi trên R [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Với \(\alpha\), tập mức dưới \(\alpha\) là \(S_{\alpha}\) lồi, cụ thể là khoảng \([a,b]\). Tập mức dưới \(\beta\) là \(S_{\beta}\) là khoảng \((-\infty,c]\). &lt;strong&gt;Các hàm lồi có các tập mức dưới lồi và là giả lồi, nhưng điều ngược lại không đúng.&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) : lồi \(\Longrightarrow\) \(f\) : giả lồi&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;ví-dụ&quot;&gt;Ví dụ&lt;/h2&gt;

&lt;p&gt;Hãy xem xét các ví dụ khác nhau về hàm giả lồi.&lt;/p&gt;

&lt;h3 id=&quot;logarithm&quot;&gt;Logarithm&lt;/h3&gt;
&lt;p&gt;\(\log x\) trên \(\mathbb{R}_{++}\) là giả lồi. (Nó cũng là giả lõm, nên nó có tính chất giả tuyến tính.)&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\log x\) trên \(\mathbb{R}_{++}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;hàm-lấy-phần-nguyên-trên&quot;&gt;Hàm lấy phần nguyên trên&lt;/h3&gt;
&lt;p&gt;Hàm lấy phần nguyên trên là giả lồi (và cũng là giả lõm).&lt;/p&gt;
&lt;blockquote&gt;
\[\text{ceil}(x) = \inf \{z \in \mathbb{Z} \mid z \geq x\}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;độ-dài-của-vector&quot;&gt;Độ dài của vector&lt;/h3&gt;
&lt;p&gt;Nếu chúng ta định nghĩa độ dài của \(x \in \mathbb{R}^n\) là chỉ số lớn nhất của các thành phần khác không,&lt;/p&gt;
&lt;blockquote&gt;
\[f(x) = \max\{i \mid x_i \neq 0\}\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này thỏa mãn&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x) \leq \alpha \iff x_i = 0\) với \(i = \lfloor\alpha\rfloor + 1,...,n\) trên \(\mathbb{R}^n\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;điều này định nghĩa một không gian con, nên nó là giả lồi.
(Lưu ý: Một không gian con đóng dưới phép cộng và nhân vô hướng. Bất kỳ không gian con nào của \(\mathbb{R}^n\) cũng là một tập lồi.)&lt;/p&gt;

&lt;h3 id=&quot;hàm-tuyến-tính-phân-thức&quot;&gt;Hàm tuyến tính-phân thức&lt;/h3&gt;
&lt;p&gt;Dưới các điều kiện sau, hàm \(f\) vừa giả lồi vừa giả lõm, tức là giả tuyến tính.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x) = \frac{a^Tx+b}{c^Tx+d}\) với \(\text{dom}f =\{x \mid c^Tx + d &amp;gt; 0\}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;hàm-tỉ-lệ-khoảng-cách&quot;&gt;Hàm tỉ lệ khoảng cách&lt;/h3&gt;
&lt;p&gt;Với \(a, b \in \mathbb{R}^n\), khi hàm \(f\) được định nghĩa như sau, biểu thị tỉ lệ của khoảng cách Euclidean từ \(x\) đến \(a\) và từ \(x\) đến \(b\),
\(f\) là giả lồi trên nửa không gian \(\{x \mid \|x - a\|_2 \leq \|x - b\|_2 \}\).&lt;/p&gt;

&lt;blockquote&gt;
\[f(x) = \frac{\|x - a\|_2}{\|x - b\|_2}\]
&lt;/blockquote&gt;

&lt;p&gt;Dưới điều kiện \(\alpha \leq 1\), điều này trở thành một tập lồi dưới dạng một quả cầu Euclidean, nên \(f\) là giả lồi.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-04 Hàm giả lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_04_00_Quasiconvex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_04_00_Quasiconvex_functions</id>
   <content type="html">&lt;p&gt;Phần này giới thiệu các hàm giả lồi, định nghĩa, ví dụ và các tính chất cơ bản của chúng.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-03 Hàm liên hợp</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_03_the_conjugate_function/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_03_the_conjugate_function</id>
   <content type="html">&lt;p&gt;Phần này giới thiệu hàm liên hợp (còn gọi là liên hợp lồi hoặc liên hợp Fenchel), một khái niệm cơ bản trong giải tích lồi và lý thuyết đối ngẫu, cung cấp một công cụ mạnh mẽ để biến đổi các bài toán tối ưu.&lt;/p&gt;

&lt;h2 id=&quot;định-nghĩa-và-nền-tảng-toán-học&quot;&gt;Định nghĩa và Nền tảng Toán học&lt;/h2&gt;

&lt;p&gt;Với một hàm \(f: \mathbb{R}^n \to \mathbb{R}\), &lt;strong&gt;hàm liên hợp&lt;/strong&gt; \(f^*: \mathbb{R}^n \to \mathbb{R}\) được định nghĩa là:&lt;/p&gt;

\[f^*(y) = \sup_{x \in \text{dom}(f)} \{y^T x - f(x)\}\]

&lt;p&gt;trong đó \(\sup\) biểu thị supremum (cận trên nhỏ nhất) trên tất cả \(x\) trong miền xác định của \(f\).&lt;/p&gt;

&lt;h3 id=&quot;giải-thích-hình-học&quot;&gt;Giải thích Hình học&lt;/h3&gt;

&lt;p&gt;Hàm liên hợp có một giải thích hình học đẹp:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(f^*(y)\) biểu thị &lt;strong&gt;khoảng cách tối đa&lt;/strong&gt; giữa hàm tuyến tính \(y^T x\) và hàm gốc \(f(x)\)&lt;/li&gt;
  &lt;li&gt;Về mặt hình học, nó đo lường mức độ siêu phẳng với độ dốc \(y\) có thể được “nâng lên trên” đồ thị của \(f\)&lt;/li&gt;
  &lt;li&gt;Liên hợp biến đổi hàm từ “không gian nguyên thủy” sang “không gian đối ngẫu” của các độ dốc&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tại-sao-nó-quan-trọng&quot;&gt;Tại sao nó quan trọng?&lt;/h3&gt;

&lt;p&gt;Hàm liên hợp được sử dụng để:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Biến đổi các bài toán tối ưu thành các &lt;strong&gt;bài toán đối ngẫu&lt;/strong&gt; tương ứng&lt;/li&gt;
  &lt;li&gt;Cung cấp các công cụ phân tích cho &lt;strong&gt;lý thuyết đối ngẫu&lt;/strong&gt; (được đề cập trong Chương 11)&lt;/li&gt;
  &lt;li&gt;Cho phép thế trực tiếp trong &lt;strong&gt;Đối ngẫu Lagrange&lt;/strong&gt; mà không cần lấy đạo hàm rõ ràng&lt;/li&gt;
  &lt;li&gt;Thiết lập kết nối giữa các nghiệm tối ưu nguyên thủy và đối ngẫu&lt;/li&gt;
&lt;/ol&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/conjugate_function.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Hàm liên hợp [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;các-tính-chất-cơ-bản&quot;&gt;Các Tính chất Cơ bản&lt;/h2&gt;

&lt;p&gt;Hàm liên hợp có nhiều tính chất đáng chú ý khiến nó trở thành một công cụ phân tích mạnh mẽ:&lt;/p&gt;

&lt;h3 id=&quot;1-tính-chất-lồi&quot;&gt;1. Tính chất Lồi&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(f^*\) luôn lồi&lt;/strong&gt;, bất kể \(f\) có lồi hay không&lt;/li&gt;
  &lt;li&gt;Điều này là do \(f^*(y)\) là supremum theo điểm của các hàm affine \(y^T x - f(x)\)&lt;/li&gt;
  &lt;li&gt;Supremum của bất kỳ tập hợp nào các hàm lồi (affine) đều lồi&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-bất-đẳng-thức-fenchel&quot;&gt;2. Bất đẳng thức Fenchel&lt;/h3&gt;
&lt;p&gt;Với bất kỳ \(x\) và \(y\):
\(f(x) + f^*(y) \geq x^T y\)&lt;/p&gt;

&lt;p&gt;Bất đẳng thức cơ bản này thiết lập mối quan hệ cận dưới giữa một hàm và liên hợp của nó.&lt;/p&gt;

&lt;h3 id=&quot;3-liên-hợp-của-liên-hợp-liên-hợp-kép&quot;&gt;3. Liên hợp của Liên hợp (Liên hợp kép)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Nói chung: \(f^{**} \leq f\) (liên hợp kép là một cận dưới)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nếu \(f\) đóng và lồi&lt;/strong&gt;: \(f^{**} = f\) (phục hồi hoàn hảo)&lt;/li&gt;
  &lt;li&gt;Tính chất này rất quan trọng cho lý thuyết đối ngẫu&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-mối-quan-hệ-dưới-vi-phân&quot;&gt;4. Mối quan hệ Dưới vi phân&lt;/h3&gt;
&lt;p&gt;Nếu \(f\) đóng và lồi, thì với bất kỳ \(x, y\):
\(y \in \partial f(x) \iff x \in \partial f^*(y) \iff f(x) + f^*(y) = x^T y\)&lt;/p&gt;

&lt;p&gt;Điều này thiết lập một sự đối xứng đẹp giữa không gian nguyên thủy và đối ngẫu.&lt;/p&gt;

&lt;h2 id=&quot;các-ví-dụ-chi-tiết&quot;&gt;Các Ví dụ Chi tiết&lt;/h2&gt;

&lt;h3 id=&quot;ví-dụ-1-logarithm-âm&quot;&gt;Ví dụ 1: Logarithm Âm&lt;/h3&gt;
&lt;p&gt;Xem xét \(f(x) = -\log x\) với \(x &amp;gt; 0\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tính toán từng bước:&lt;/strong&gt;
\(f^*(y) = \sup_{x&amp;gt;0} \{xy + \log x\}\)&lt;/p&gt;

&lt;p&gt;Để tìm supremum, chúng ta lấy đạo hàm theo \(x\):
\(\frac{d}{dx}(xy + \log x) = y + \frac{1}{x} = 0\)&lt;/p&gt;

&lt;p&gt;Điều này cho ta \(x^* = -\frac{1}{y}\) (chỉ hợp lệ khi \(y &amp;lt; 0\)).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kết quả:&lt;/strong&gt;
\(f^*(y) = \begin{cases}
-1 - \log(-y), &amp;amp; \text{nếu } y &amp;lt; 0 \\
+\infty, &amp;amp; \text{nếu } y \geq 0
\end{cases}\)&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-2-hàm-bậc-hai&quot;&gt;Ví dụ 2: Hàm Bậc hai&lt;/h3&gt;
&lt;p&gt;Xem xét \(f(x) = \frac{1}{2}x^T Q x\) trong đó \(Q \succ 0\) (xác định dương).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tính toán từng bước:&lt;/strong&gt;
\(f^*(y) = \sup_{x} \{y^T x - \frac{1}{2}x^T Q x\}\)&lt;/p&gt;

&lt;p&gt;Lấy gradient và đặt bằng không:
\(\nabla_x (y^T x - \frac{1}{2}x^T Q x) = y - Qx = 0\)&lt;/p&gt;

&lt;p&gt;Điều này cho ta \(x^* = Q^{-1}y\).&lt;/p&gt;

&lt;p&gt;Thế ngược lại:
\(f^*(y) = y^T Q^{-1} y - \frac{1}{2}(Q^{-1}y)^T Q (Q^{-1}y) = \frac{1}{2}y^T Q^{-1} y\)&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-3-giá-trị-tuyệt-đối-trường-hợp-1d&quot;&gt;Ví dụ 3: Giá trị Tuyệt đối (trường hợp 1D)&lt;/h3&gt;
&lt;p&gt;Xem xét \(f(x) = \lvert x \rvert\) với \(x \in \mathbb{R}\).&lt;/p&gt;

\[f^*(y) = \sup_{x} \{yx - \lvert x \rvert\}\]

&lt;p&gt;&lt;strong&gt;Phân tích theo trường hợp:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Nếu \(\lvert y \rvert \leq 1\): Supremum là hữu hạn và bằng 0&lt;/li&gt;
  &lt;li&gt;Nếu \(\lvert y \rvert &amp;gt; 1\): Supremum là \(+\infty\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Kết quả:&lt;/strong&gt;
\(f^*(y) = \begin{cases}
0, &amp;amp; \text{nếu } \lvert y \rvert \leq 1 \\
+\infty, &amp;amp; \text{nếu } \lvert y \rvert &amp;gt; 1
\end{cases}\)&lt;/p&gt;

&lt;p&gt;Đây là &lt;strong&gt;hàm chỉ thị&lt;/strong&gt; của khoảng \([-1, 1]\).&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-4-hàm-mũ&quot;&gt;Ví dụ 4: Hàm Mũ&lt;/h3&gt;
&lt;p&gt;Xem xét \(f(x) = e^x\) với \(x \in \mathbb{R}\).&lt;/p&gt;

\[f^*(y) = \sup_{x} \{yx - e^x\}\]

&lt;p&gt;Đặt đạo hàm bằng không: \(y - e^x = 0\), vậy \(x^* = \log y\) (hợp lệ với \(y &amp;gt; 0\)).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kết quả:&lt;/strong&gt;
\(f^*(y) = \begin{cases}
y \log y - y, &amp;amp; \text{nếu } y &amp;gt; 0 \\
0, &amp;amp; \text{nếu } y = 0 \\
+\infty, &amp;amp; \text{nếu } y &amp;lt; 0
\end{cases}\)&lt;/p&gt;

&lt;h2 id=&quot;ứng-dụng-trong-tối-ưu-hóa&quot;&gt;Ứng dụng trong Tối ưu hóa&lt;/h2&gt;

&lt;p&gt;Hàm liên hợp đóng vai trò quan trọng trong:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Đối ngẫu Lagrange&lt;/strong&gt;: Chuyển đổi các bài toán nguyên thủy thành bài toán đối ngẫu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Đối ngẫu Fenchel&lt;/strong&gt;: Một khung tổng quát cho đối ngẫu tối ưu lồi&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Toán tử Gần kề&lt;/strong&gt;: Được sử dụng trong các thuật toán tối ưu hiện đại&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phân tích Biến phân&lt;/strong&gt;: Nghiên cứu các bài toán tối ưu thông qua các cặp liên hợp&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Các ứng dụng này sẽ được khám phá chi tiết trong Chương 11 và 13.&lt;/p&gt;

&lt;h2 id=&quot;trực-quan-hóa-tương-tác&quot;&gt;Trực quan Hóa Tương tác&lt;/h2&gt;

&lt;p&gt;Để hiểu rõ hơn cách hàm liên hợp hoạt động, hãy khám phá trực quan hóa tương tác của chúng tôi:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 20px 0;&quot;&gt;
    &lt;a href=&quot;../conjugate_function_interactive.html&quot; target=&quot;_blank&quot; style=&quot;display: inline-block; padding: 12px 24px; background-color: #3498db; color: white; text-decoration: none; border-radius: 6px; font-weight: bold; box-shadow: 0 2px 4px rgba(0,0,0,0.2);&quot;&gt;
        🎯 Khởi động Công cụ Khám phá Hàm Liên hợp Tương tác
    &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Công cụ tương tác cho phép bạn:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Trực quan hóa các loại hàm khác nhau&lt;/strong&gt; và liên hợp của chúng cạnh nhau&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Điều chỉnh tham số&lt;/strong&gt; để xem chúng ảnh hưởng đến liên hợp như thế nào&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Khám phá các đường tiếp tuyến&lt;/strong&gt; để hiểu giải thích hình học&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;So sánh nhiều ví dụ&lt;/strong&gt; với giải thích toán học chi tiết&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tóm-tắt-và-những-điểm-chính&quot;&gt;Tóm tắt và Những Điểm Chính&lt;/h2&gt;

&lt;p&gt;Hàm liên hợp là một công cụ toán học mạnh mẽ:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Biến đổi hàm&lt;/strong&gt; từ không gian nguyên thủy sang không gian đối ngẫu thông qua phép toán \(f^*(y) = \sup_x \{y^T x - f(x)\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Luôn tạo ra các hàm lồi&lt;/strong&gt;, bất kể tính lồi của hàm gốc&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Thiết lập các bất đẳng thức cơ bản&lt;/strong&gt; như bất đẳng thức Fenchel: \(f(x) + f^*(y) \geq x^T y\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kích hoạt lý thuyết đối ngẫu&lt;/strong&gt; bằng cách kết nối các bài toán tối ưu nguyên thủy và đối ngẫu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cung cấp các công cụ phân tích&lt;/strong&gt; để giải các bài toán tối ưu phức tạp&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hiểu biết về hàm liên hợp là thiết yếu cho:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Lý thuyết tối ưu lồi&lt;/strong&gt; và phát triển thuật toán&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Đối ngẫu Lagrange&lt;/strong&gt; và xây dựng bài toán đối ngẫu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Các phương pháp tối ưu hiện đại&lt;/strong&gt; như thuật toán gần kề&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phân tích biến phân&lt;/strong&gt; và kinh tế toán học&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Trực giác hình học về “khoảng cách tối đa giữa hàm tuyến tính và phi tuyến” cung cấp sự hiểu biết trực quan bổ sung cho định nghĩa phân tích, làm cho khái niệm trừu tượng này dễ tiếp cận hơn cho người học.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>03-02 Các phép toán bảo toàn tính lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_02_operations_that_preserve_convexity/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_02_operations_that_preserve_convexity</id>
   <content type="html">&lt;p&gt;Phần này thảo luận các phép toán bảo toàn tính lồi của các hàm lồi.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tổng trọng số không âm&lt;/li&gt;
  &lt;li&gt;Hợp thành với hàm affine&lt;/li&gt;
  &lt;li&gt;Maximum theo điểm&lt;/li&gt;
  &lt;li&gt;Hàm phối cảnh&lt;/li&gt;
  &lt;li&gt;Hàm tuyến tính-phân thức&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tổng-trọng-số-không-âm&quot;&gt;Tổng trọng số không âm&lt;/h2&gt;
&lt;p&gt;Các hàm lồi có các tính chất sau đối với phép nhân vô hướng và phép cộng:&lt;/p&gt;

&lt;p&gt;• Khi một hàm lồi \(f\) tồn tại, nhân nó với bất kỳ số không âm nào vẫn cho ra một hàm lồi \(f\).&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) lồi \(\Rightarrow \alpha f\) lồi với \(\alpha \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;• Khi hai hàm lồi (\(f_1, f_2\)) tồn tại, tổng của chúng cũng lồi.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f_1, f_2\) lồi \(\Rightarrow f_1 + f_2\) lồi&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;• Tổng trọng số không âm của các hàm lồi \(f_1, ..., f_m\) là hàm lồi.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f_1, ..., f_n\) lồi \(\Rightarrow \alpha_1f_1 + \cdots + \alpha_nf_n\) lồi, \(\alpha_1, ..., \alpha_n \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;hợp-thành&quot;&gt;Hợp thành&lt;/h2&gt;
&lt;h3 id=&quot;1-hợp-thành-affine&quot;&gt;1. Hợp thành affine&lt;/h3&gt;
&lt;p&gt;Nếu hàm \(f\) lồi, thì \(f(Ax + b)\) cũng lồi.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) lồi \(\Rightarrow f(Ax + b)\) lồi&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;2-hợp-thành-tổng-quát&quot;&gt;2. Hợp thành tổng quát&lt;/h3&gt;
&lt;p&gt;Giả sử chúng ta có hàm \(g\) ánh xạ từ không gian \(n\) chiều sang không gian 1 chiều và hàm \(h\) ánh xạ từ không gian 1 chiều sang không gian 1 chiều.
Hàm hợp thành \(f(x)=h(g(x))\) lồi hoặc lõm trong các trường hợp sau:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;hợp thành của \(g:\mathbb{R}^n \mapsto \mathbb{R}\) và \(h:\mathbb{R}\mapsto \mathbb{R}\):
\(f(x)=h(g(x))\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;• Nếu \(g\) lồi, \(h\) lồi, và \(h\) không giảm, thì \(f\) lồi.
• Nếu \(g\) lõm, \(h\) lồi, và \(h\) không tăng, thì \(f\) lồi.
• Nếu \(g\) lõm, \(h\) lõm, và \(h\) không giảm, thì \(f\) lõm.
• Nếu \(g\) lồi, \(h\) lõm, và \(h\) không tăng, thì \(f\) lõm.&lt;/p&gt;

&lt;h3 id=&quot;lưu-ý&quot;&gt;[Lưu ý]&lt;/h3&gt;
&lt;p&gt;Tính đơn điệu của phần mở rộng giá trị mở rộng \(\tilde{h}\) phải được bảo toàn.&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ&quot;&gt;Ví dụ&lt;/h3&gt;
&lt;p&gt;• Nếu \(g\) lồi, thì \(\exp g(x)\) lồi.
• Nếu \(g\) lõm và dương, thì \(1/g(x)\) lồi.&lt;/p&gt;

&lt;h3 id=&quot;3-hợp-thành-vector&quot;&gt;3. Hợp thành vector&lt;/h3&gt;
&lt;p&gt;Giả sử chúng ta có hàm \(g\) ánh xạ từ không gian \(n\) chiều sang không gian \(k\) chiều và hàm \(h\) ánh xạ từ không gian \(k\) chiều sang không gian 1 chiều.
Khi đó hàm hợp thành \(f(x)=h(g(x))=h(g_1(x),g_2(x),...,g_k(x))\) lồi hoặc lõm trong các trường hợp sau:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;hợp thành của \(g:\mathbb{R}^n\mapsto\mathbb{R}^k\) và \(h:\mathbb{R}^k\mapsto\mathbb{R}\):
\(f(x)=h(g(x))=h(g_1(x),g_2(x),...,g_k(x))\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;• Nếu \(g\) lồi và \(h\) lồi, và \(h\) không giảm theo từng đối số, thì \(f\) lồi.
• Nếu \(g\) lồi và \(h\) lõm, và \(h\) không tăng theo từng đối số, thì \(f\) lõm.&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-1&quot;&gt;Ví dụ&lt;/h3&gt;
&lt;p&gt;• Nếu \(g_i\) lõm và dương, thì \(\sum_{i=1}^{m} \log g_i(x)\) lõm.
• Nếu \(g_i\) lồi, thì \(\log \sum_{i=1}^{m} \exp g_i(x)\) lồi.&lt;/p&gt;

&lt;h2 id=&quot;maximum-theo-điểm&quot;&gt;Maximum theo điểm&lt;/h2&gt;
&lt;p&gt;Maximum theo điểm của các hàm được định nghĩa như sau và là hàm lồi:&lt;/p&gt;
&lt;h3 id=&quot;1-maximum-theo-điểm&quot;&gt;1. Maximum theo điểm&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f_1, f_2\) là các hàm lồi \(\Rightarrow f(x) = \max \{ f_1(x), f_2(x) \}\), \(\text{dom } f = \text{dom } f_1 \cap \text{dom } f_2\) là hàm lồi&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;2-supremum-theo-điểm&quot;&gt;2. Supremum theo điểm&lt;/h3&gt;
&lt;p&gt;Nếu \(f(x, y)\) lồi theo \(x\) với mọi \(y \in A\), thì \(g(x) = \sup_{y\in A} f(x, y)\) lồi.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f(x, y)\) lồi theo \(x\) với mọi \(y \in A\)
\(\Rightarrow g(x) = \sup_{y\in A} f(x, y)\) với \(\text{dom } g = \{x | (x, y) \in \text{dom} f \text{ với mọi } y \in A, \sup &amp;lt; \infty \}\) lồi theo \(x\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;phối-cảnh&quot;&gt;Phối cảnh&lt;/h2&gt;
&lt;p&gt;Nếu hàm \(f: \mathbb{R}^n \rightarrow \mathbb{R}\) lồi, thì phép toán phối cảnh \(g: \mathbb{R}^{n+1} \mapsto \mathbb{R}\) bảo toàn tính lồi.&lt;/p&gt;

&lt;p&gt;Hàm phối cảnh \(g: \mathbb{R}^n×\mathbb{R} \mapsto \mathbb{R}\) của hàm \(f: \mathbb{R}^n \mapsto \mathbb{R}\) là:&lt;/p&gt;

\[g(x,t) = tf\left(\frac{x}{t}\right), \quad \text{dom } g = \left\{(x,t) \left| \frac{x}{t} \in \text{dom } f, t&amp;gt;0 \right.\right\}\]

&lt;p&gt;Nếu hàm \(f\) lồi, thì \(g\) cũng lồi.&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-2&quot;&gt;Ví dụ&lt;/h3&gt;
&lt;p&gt;• Khi \(t\) dương, nếu \(g(x,t)=x^Tx/t\) lồi, thì \(f(x)=x^Tx\) lồi.&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;Logarithm âm&lt;/strong&gt;
Khi entropy tương đối \(g(x,t) =t\log t − t\log x\) lồi trên \(\mathbb{R}_{++}^2\), thì \(f(x)=−\log x\) lồi.&lt;/p&gt;

&lt;p&gt;• Nếu \(f\) lồi, thì \(g(x)=(c^Tx+d)f\left(\frac{Ax+b}{c^Tx+d}\right)\) lồi dưới điều kiện sau:&lt;/p&gt;
&lt;blockquote&gt;
\[\left\{x \left| c^Tx+d&amp;gt;0, \frac{Ax+b}{c^Tx+d} \in \text{dom } f\right.\right\}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>03-01-03 Các tính chất chính của hàm lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_01_03_key_properties_of_convex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_01_03_key_properties_of_convex_functions</id>
   <content type="html">&lt;h2 id=&quot;đặc-trưng-epigraph&quot;&gt;Đặc trưng epigraph&lt;/h2&gt;
&lt;p&gt;Như đã thảo luận trong Mục 1.2, \(f\) lồi khi và chỉ khi epigraph của nó là một tập lồi, và ngược lại.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f\) lồi \(\iff epi(f) = \{(x,t) \in \mathbb{R}^{n+1} \mid x \in \text{dom} f, f(x) \le t \}\) là một tập lồi&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;tập-mức-dưới-lồi&quot;&gt;Tập mức dưới lồi&lt;/h2&gt;
&lt;p&gt;Nếu một hàm \(f\) lồi, các tập mức dưới của nó cũng lồi.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\{x \in \text{dom } f: f(x) \leq t\}\), với mọi \(t \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;lưu-ý-tập-mức-dưới&quot;&gt;[Lưu ý] Tập mức dưới&lt;/h3&gt;
&lt;p&gt;Với một hàm \(f:\mathbb{R}^n \mapsto \mathbb{R}\), \(C_\alpha = \{x \in \text{dom} f | f(x) \leq \alpha\}\) được gọi là &lt;em&gt;tập mức dưới \(\alpha\)&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;đặc-trưng-bậc-nhất&quot;&gt;Đặc trưng bậc nhất&lt;/h2&gt;
&lt;p&gt;Nếu một hàm \(f\) &lt;strong&gt;khả vi&lt;/strong&gt;, điều sau đây đúng:
Nếu miền \(\text{dom} f\) lồi và với mọi \(x, y \in \text{dom} f\), \(f(y) \geq f(x) +\nabla f(x)^T(y-x)\), thì \(f\) lồi, và ngược lại.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f\) lồi \(\iff \text{dom}f\) lồi, và \(f(y) \geq f(x) +\nabla f(x)^T(y-x)\) với mọi \(x,y \in \text{dom} f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hình dưới đây minh họa điều kiện bậc nhất cho một hàm lồi khả vi \(f\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/1st_order_condition.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Hàm Lồi [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Điều kiện này được gọi là &lt;strong&gt;điều kiện đường tiếp tuyến&lt;/strong&gt; (hoặc điều kiện siêu phẳng tiếp tuyến trong không gian nhiều chiều). Nó cơ bản nói rằng một hàm lồi luôn nằm trên hoặc trên tất cả các đường tiếp tuyến (hoặc siêu phẳng) của nó. Bất kể bạn vẽ đường tiếp tuyến ở đâu trên hàm lồi, giá trị thực tế của hàm sẽ không bao giờ xuống dưới đường tiếp tuyến đó.&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ&quot;&gt;Ví dụ&lt;/h3&gt;

&lt;p&gt;Xem xét hàm lồi đơn giản \(f(x) = x^2\). Đạo hàm của nó (là gradient trong 1D) là \(f&apos;(x) = 2x\).&lt;/p&gt;

&lt;p&gt;Hãy chọn một điểm tùy ý \(x_0\). Phương trình của đường tiếp tuyến với \(f(x)\) tại \(x_0\) được cho bởi:
\(L(x) = f(x_0) + f&apos;(x_0)(x - x_0)\)&lt;/p&gt;

&lt;p&gt;Thế \(f(x_0) = x_0^2\) và \(f&apos;(x_0) = 2x_0\):
\(L(x) = x_0^2 + 2x_0(x - x_0)\)&lt;/p&gt;

&lt;p&gt;Điều kiện lồi yêu cầu rằng với mọi \(x\):
\(f(x) \geq L(x)\)
\(x^2 \geq x_0^2 + 2x_0(x - x_0)\)&lt;/p&gt;

&lt;p&gt;Hãy rút gọn vế phải:
\(x^2 \geq x_0^2 + 2x_0x - 2x_0^2\)
\(x^2 \geq 2x_0x - x_0^2\)&lt;/p&gt;

&lt;p&gt;Bây giờ, chuyển tất cả các số hạng sang một bên:
\(x^2 - 2x_0x + x_0^2 \geq 0\)&lt;/p&gt;

&lt;p&gt;Biểu thức này là một bình phương hoàn hảo:
\((x - x_0)^2 \geq 0\)&lt;/p&gt;

&lt;p&gt;Bất đẳng thức này luôn đúng với bất kỳ số thực \(x\) và \(x_0\), vì bình phương của bất kỳ số thực nào luôn không âm. Điều này xác nhận rằng \(f(x) = x^2\) thỏa mãn điều kiện đường tiếp tuyến và thực sự là một hàm lồi.&lt;/p&gt;

&lt;h2 id=&quot;đặc-trưng-bậc-hai&quot;&gt;Đặc trưng bậc hai&lt;/h2&gt;
&lt;p&gt;Nếu một hàm \(f\) khả vi hai lần, nó có tính chất sau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nếu đạo hàm bậc hai \(\nabla^2f(x)\) là nửa xác định dương với mọi \(x \in \text{dom} f\) và \(\text{dom} f\) lồi, thì \(f\) lồi, và ngược lại.
    &lt;blockquote&gt;
      &lt;p&gt;\(f\) lồi \(\iff \nabla^2f(x) \succeq 0\) với mọi \(x \in \text{dom} f, \text{dom} f\): lồi&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Nếu đạo hàm bậc hai \(\nabla^2f(x)\) là xác định dương với mọi \(x \in \text{dom} f\), thì \(f\) lồi chặt.
    &lt;blockquote&gt;
      &lt;p&gt;nếu \(\nabla^2f(x) \succ 0\) với mọi \(x \in \text{dom} f\), thì \(f\) lồi chặt&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Nói cách khác, độ cong luôn không âm.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bất-đẳng-thức-jensen&quot;&gt;Bất đẳng thức Jensen&lt;/h2&gt;

&lt;p&gt;Gọi \(f\) là một hàm lồi và \(w_1, ..., w_n\) là các trọng số dương sao cho \(\sum_{i=1}^{n} w_i = 1\). Khi đó, bất đẳng thức sau đây đúng:&lt;/p&gt;

\[\sum_{i=1}^{n} w_i f(x_i) \geq f \left ( \sum_{i=1}^{n} w_i x_i \right )\]

&lt;p&gt;Nếu một hàm \(f\) lồi, nó thỏa mãn bất đẳng thức sau:&lt;/p&gt;
&lt;blockquote&gt;
\[f(tx_1 + (1 - t)x_2) \le tf(x_1) + (1 - t)f(x_2) \text{ với } 0 \le t \le 1\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Mở rộng&lt;/em&gt;:&lt;br /&gt;
\(X\) là một biến ngẫu nhiên được hỗ trợ trên \(\text{dom } f\), thì \(f(E[X]) \le E[f(X)]\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/jensen_inequality.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 2] Bất đẳng thức Jensen [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;bất-đẳng-thức-jensen-có-phải-chính-xác-là-định-nghĩa-của-hàm-lồi-không&quot;&gt;&lt;strong&gt;Bất đẳng thức Jensen có phải chính xác là định nghĩa của hàm lồi không?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Câu trả lời là không—Bất đẳng thức Jensen là một hệ quả và sự tổng quát hóa của định nghĩa tính lồi, chứ không phải là định nghĩa.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Điều này mở rộng trường hợp hai điểm (\(k=2\)) trong định nghĩa thành bất kỳ số hữu hạn điểm (và có thể được tổng quát hóa thêm thành tích phân cho các đo lường xác suất).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tại sao đây là một sự tổng quát hóa:&lt;/strong&gt; Định nghĩa cơ bản là cho hai điểm (tổ hợp lồi nhị phân). Jensen áp dụng nó một cách lặp đi lặp lại cho nhiều điểm hơn. Ví dụ:
    &lt;ul&gt;
      &lt;li&gt;Với \(k=2\), Jensen rút gọn chính xác thành định nghĩa.&lt;/li&gt;
      &lt;li&gt;Với \(k=3\), bạn có thể áp dụng định nghĩa một cách đệ quy: Trước tiên kết hợp hai điểm, sau đó với điểm thứ ba.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;ví-dụ-ngắn&quot;&gt;Ví dụ ngắn&lt;/h3&gt;

&lt;p&gt;Hãy sử dụng hàm lồi \(f(x) = x^2\).
Xem xét hai số: \(x_1 = 1\) và \(x_2 = 3\).
Chúng ta muốn so sánh \(f\left(\frac{x_1+x_2}{2}\right)\) với \(\frac{f(x_1)+f(x_2)}{2}\).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tính hàm của giá trị trung bình:&lt;/strong&gt;
Giá trị trung bình của \(x_1\) và \(x_2\) là \(\frac{1+3}{2} = \frac{4}{2} = 2\).
Áp dụng hàm: \(f(2) = 2^2 = 4\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tính giá trị trung bình của các giá trị hàm:&lt;/strong&gt;
\(f(x_1) = f(1) = 1^2 = 1\).
\(f(x_2) = f(3) = 3^2 = 9\).
Giá trị trung bình của các giá trị hàm này là \(\frac{1+9}{2} = \frac{10}{2} = 5\).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So sánh hai kết quả: \(4 \le 5\).
Điều này minh họa bất đẳng thức Jensen: \(f\left(\frac{1+3}{2}\right) \le \frac{f(1)+f(3)}{2}\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-01-02 Ví dụ về hàm lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_01_02_examples_of_convex_function/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_01_02_examples_of_convex_function</id>
   <content type="html">&lt;p&gt;Phần này xem xét các ví dỡ điển hình của hàm lồi, bao gồm:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hàm mũ&lt;/li&gt;
  &lt;li&gt;Hàm lũy thừa&lt;/li&gt;
  &lt;li&gt;Hàm affine&lt;/li&gt;
  &lt;li&gt;Hàm bậc hai&lt;/li&gt;
  &lt;li&gt;Hàm mất mát bình phương nhỏ nhất&lt;/li&gt;
  &lt;li&gt;Chuẩn&lt;/li&gt;
  &lt;li&gt;Hàm chỉ thị&lt;/li&gt;
  &lt;li&gt;Hàm hỗ trợ&lt;/li&gt;
  &lt;li&gt;Hàm max&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hàm-một-biến&quot;&gt;Hàm một biến&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Hàm mũ:
Với bất kỳ số thực \(a\), \(e^{ax}\) là hàm lồi.
    &lt;blockquote&gt;
      &lt;p&gt;\(e^{ax}\) là hàm lồi với mọi \(a \in \mathbb{R}\)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Hàm lũy thừa:
Với \(x, a \in \mathbb{R}_{+}\), tùy thuộc vào khoảng giá trị của \(a\), \(x^a\) có thể là hàm lồi hoặc lõm.
    &lt;blockquote&gt;
      &lt;p&gt;\(x^{a}\) là hàm lồi trên \(\mathbb{R}_{+}\) với mọi \(a \geq 1\) hoặc \(a \leq 0\)
\(x^{a}\) là hàm lõm trên \(\mathbb{R}_{+}\) với mọi \(0 \leq a \leq 1\)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hàm-affine&quot;&gt;Hàm affine&lt;/h2&gt;
&lt;p&gt;Như đã đề cập trong &lt;a href=&quot;/contents/vi/chapter03/03_01_01_convex_functions_definition/&quot;&gt;03-01-01&lt;/a&gt;, tất cả các hàm affine đều vừa lồi vừa lõm.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trên \(\mathbb{R}\) và \(\mathbb{R}^n\):
    &lt;blockquote&gt;
      &lt;p&gt;\(a^Tx + b\) vừa lồi vừa lõm&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Trên \(\mathbb{R}^{m \times n}\):
    &lt;blockquote&gt;
      &lt;p&gt;\(\text{tr}(A^TX) + b = \sum_{i=1}^m\sum_{j=1}^n A_{ij}X_{ij} + b\) vừa lồi vừa lõm&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hàm-bậc-hai&quot;&gt;Hàm bậc hai&lt;/h2&gt;
&lt;p&gt;Xem xét hàm bậc hai \(f(x)=\frac{1}{2}x^TPx+q^Tx+r\), trong đó \(\nabla f(x)= Px+q\) và \(\nabla^2f(x) = P\). Nếu \(P\) là ma trận nửa xác định dương, thì \(f(x)\) là hàm lồi.
Với \(P \succeq 0\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x)=\frac{1}{2}x^TPx+q^Tx+r\) là hàm lồi với \(P \in \mathbb{S}^n, q \in \mathbb{R}^n, r \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;H: Tại sao \(f(x)\) lồi nếu \(P\) là ma trận nửa xác định dương?&lt;/strong&gt;
Đáp: Trong hàm bậc hai, đạo hàm bậc hai là ma trận Hessian. Ma trận Hessian xác định độ cong của hàm, và nếu nó là nửa xác định dương, hàm sẽ cong lên trên. (Tức là, độ cong theo hướng của các vector riêng của Hessian là không âm.) Do đó, nếu đạo hàm bậc hai là nửa xác định dương, hàm sẽ lồi.&lt;/p&gt;

&lt;h2 id=&quot;hàm-mất-mát-bình-phương-nhỏ-nhất&quot;&gt;Hàm mất mát bình phương nhỏ nhất&lt;/h2&gt;
&lt;p&gt;Với bất kỳ ma trận \(A\), \(A^TA\) luôn là ma trận nửa xác định dương, có nghĩa là \(\left \| Ax - b \right \|_{2}^{2}\) luôn là hàm lồi.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f(x) = \| Ax - b \|_{2}^{2}\) là hàm lồi với mọi \(A\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;chuẩn&quot;&gt;Chuẩn&lt;/h2&gt;
&lt;p&gt;Tất cả các chuẩn trên \(\mathbb{R}^n\) đều là hàm lồi.
Gọi \(f:\mathbb{R}^n \mapsto \mathbb{R}\) là một chuẩn. Theo định nghĩa,&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{aligned}
f(\theta x+(1−\theta)y) \le \theta f(x)+(1−\theta)f(y), \text{  với } 0 \le \theta \le 1, \text{ cho mọi } x,y \in \text{dom} f,
\end{aligned}\)
\(\begin{aligned}
\|x\|_{p} = \left(\sum_{i=1}^{n} x_i^p\right)^{1/p} \text{ với } p \geq 1, \|x\| = \max_{i=1,.., n} |x_i|\\
\end{aligned}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;hàm-chỉ-thị&quot;&gt;Hàm chỉ thị&lt;/h2&gt;
&lt;p&gt;Với một tập \(C\) cho trước, nếu hàm chỉ thị được định nghĩa là vô cực (\(\infty\)) cho các phần tử không thuộc \(C\) và bằng không cho các phần tử thuộc \(C\), thì hàm chỉ thị là hàm lồi.&lt;/p&gt;

&lt;p&gt;Nói cách khác, bằng cách định nghĩa hàm có giá trị vô cực bên ngoài tập \(C\) và bằng không bên trong nó, tính chất lồi được bảo toàn.&lt;/p&gt;

&lt;blockquote&gt;
\[I_{C} (x) =
\begin{cases}
0, &amp;amp; x \in C\\
\infty, &amp;amp; x \notin C\\
\end{cases}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;hàm-hỗ-trợ&quot;&gt;Hàm hỗ trợ&lt;/h2&gt;
&lt;p&gt;Xem xét một tập \(C\). Bất kể \(C\) có lồi hay không, hàm hỗ trợ của \(C\) đều là hàm lồi.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(I_{C}^{*} (x)\) = \(\max_{y\in C} x^Ty\) là hàm lồi&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Để tìm hiểu thêm về định nghĩa hàm hỗ trợ, tham khảo &lt;a href=&quot;https://en.wikipedia.org/wiki/Support_function&quot;&gt;định nghĩa trên Wikipedia&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;hàm-max&quot;&gt;Hàm max&lt;/h2&gt;
&lt;p&gt;Hàm max của một tập hữu hạn các hàm lồi là hàm lồi.
Nói cách khác, đường bao trên được hình thành bằng cách nối các giá trị lớn nhất của một tập các hàm lồi là hàm lồi.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x) = \max \{x_1,..., x_n\}\) là hàm lồi&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>03-01-01 Định nghĩa</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_01_01_convex_functions_definition/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_01_01_convex_functions_definition</id>
   <content type="html">&lt;h2 id=&quot;hàm-lồi&quot;&gt;Hàm lồi&lt;/h2&gt;

&lt;p&gt;Một hàm \(f:\mathbb{R}^n \rightarrow \mathbb{R}\) được gọi là lồi nếu miền xác định của nó là một tập lồi và với bất kỳ hai điểm \(x, y \in \text{dom}f\), hàm thỏa mãn:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f(\theta x+(1-\theta)y) \le \theta f(x)+(1-\theta)f(y)\),&lt;/p&gt;

  &lt;p&gt;với \(0 \le \theta \le 1\), cho mọi \(x,y \in \text{dom} f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Điều này có nghĩa là với bất kỳ hai điểm \(x, y\), giá trị của \(f\) tại tổ hợp lồi của chúng nhỏ hơn hoặc bằng tổ hợp lồi của các giá trị hàm tương ứng. Về mặt hình học, đồ thị của \(f\) nằm dưới đoạn thẳng nối \(f(x)\) và \(f(y)\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/convex_function2.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Hàm Lồi [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;hàm-lồi-chặt&quot;&gt;Hàm lồi chặt&lt;/h2&gt;
&lt;p&gt;Một hàm \(f:\mathbb{R}^n \rightarrow \mathbb{R}\) được gọi là lồi chặt nếu với bất kỳ hai điểm phân biệt \(x, y \in \text{dom}f\) và \(0 &amp;lt; \theta &amp;lt; 1\):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f(\theta x+(1-\theta)y)&amp;lt;\theta f(x)+(1-\theta)f(y)\),&lt;/p&gt;

  &lt;p&gt;với \(0&amp;lt;\theta&amp;lt;1\), \(x \neq y\), cho mọi \(x, y \in \text{dom}f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;hàm-lồi-mạnh&quot;&gt;Hàm lồi mạnh&lt;/h2&gt;
&lt;p&gt;Một hàm \(f\) được gọi là lồi mạnh nếu \(f - \frac{m}{2}\| x \|_{2}^{2}\), với \(m &amp;gt; 0\), là hàm lồi.&lt;/p&gt;

&lt;h3 id=&quot;lưu-ý-lồi-mạnh--lồi-chặt--lồi&quot;&gt;[Lưu ý] lồi mạnh ⇒ lồi chặt ⇒ lồi&lt;/h3&gt;

&lt;h2 id=&quot;hàm-lõm&quot;&gt;Hàm lõm&lt;/h2&gt;
&lt;p&gt;Một hàm \(f\) được gọi là lõm nếu \(-f\) là hàm lồi.&lt;/p&gt;

&lt;p&gt;Tất cả các hàm affine \(f(x) = a^T x+b\) đều thỏa mãn:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{aligned}
f(\theta x+(1-\theta)y) &amp;amp;= a^T (\theta x+(1-\theta)y) +b \\
&amp;amp;= \theta a^T x + (1-\theta) a^T y + \theta b + (1-\theta) b \\
&amp;amp;= \theta f(x)+(1-\theta)f(y) \\
\end{aligned}\)
\(\text{với mọi } x,y \in \text{dom} f, \text{và } 0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Tức là, các hàm affine luôn vừa lồi vừa lõm.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-01 Tính chất cơ bản và ví dụ</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_01_00_Basic_properties_and_examples/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_01_00_Basic_properties_and_examples</id>
   <content type="html">&lt;p&gt;Phần này bao gồm định nghĩa của hàm lồi, các loại hàm lồi tiêu biểu, và các tính chất chính của chúng.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03 Hàm lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter03/03_00_Convex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/03_00_Convex_functions</id>
   <content type="html">&lt;p&gt;Trong chương này, chúng ta sẽ nghiên cứu định nghĩa, các ví dụ, tính chất chính của hàm lồi, và các phép toán bảo toàn tính lồi.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-01-04 Euclidean Norm - L2 - is Convex</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_07_euclidean_norm_convexity_proof/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_07_euclidean_norm_convexity_proof</id>
   <content type="html">&lt;p&gt;The &lt;strong&gt;Euclidean norm&lt;/strong&gt; (also called the \(\ell_2\)-norm) of a vector \(x \in \mathbb{R}^n\) is defined as:&lt;/p&gt;

\[\|x\|_2 = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2} = \sqrt{x^T x}\]

&lt;p&gt;We will prove that this function is convex using three different methods:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Definition-based proof&lt;/strong&gt; using Jensen’s inequality&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second derivative test&lt;/strong&gt; (Hessian analysis)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Triangle inequality approach&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;method-1-definition-based-proof&quot;&gt;Method 1: Definition-Based Proof&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: The Euclidean norm \(f(x) = \|x\|_2\) is convex on \(\mathbb{R}^n\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof&lt;/strong&gt;: 
To prove convexity, we need to show that for any \(x, y \in \mathbb{R}^n\) and \(\theta \in [0,1]\):&lt;/p&gt;

\[\|\theta x + (1-\theta) y\|_2 \leq \theta \|x\|_2 + (1-\theta) \|y\|_2\]

&lt;p&gt;Let \(z = \theta x + (1-\theta) y\). Then:&lt;/p&gt;

\[\begin{align}
\|z\|_2^2 &amp;amp;= \|\theta x + (1-\theta) y\|_2^2 \\
&amp;amp;= (\theta x + (1-\theta) y)^T (\theta x + (1-\theta) y) \\
&amp;amp;= \theta^2 x^T x + 2\theta(1-\theta) x^T y + (1-\theta)^2 y^T y \\
&amp;amp;= \theta^2 \|x\|_2^2 + 2\theta(1-\theta) x^T y + (1-\theta)^2 \|y\|_2^2
\end{align}\]

&lt;p&gt;By the &lt;strong&gt;Cauchy-Schwarz inequality&lt;/strong&gt;: \(x^T y \leq \|x\|_2 \|y\|_2\)&lt;/p&gt;

&lt;p&gt;Therefore:
\(\|z\|_2^2 \leq \theta^2 \|x\|_2^2 + 2\theta(1-\theta) \|x\|_2 \|y\|_2 + (1-\theta)^2 \|y\|_2^2\)&lt;/p&gt;

&lt;p&gt;The right-hand side can be factored as:
\(\theta^2 \|x\|_2^2 + 2\theta(1-\theta) \|x\|_2 \|y\|_2 + (1-\theta)^2 \|y\|_2^2 = (\theta \|x\|_2 + (1-\theta) \|y\|_2)^2\)&lt;/p&gt;

&lt;p&gt;Taking square roots of both sides:
\(\|\theta x + (1-\theta) y\|_2 \leq \theta \|x\|_2 + (1-\theta) \|y\|_2\)&lt;/p&gt;

&lt;p&gt;This proves that the Euclidean norm is convex. \(\square\)&lt;/p&gt;

&lt;h2 id=&quot;method-2-second-derivative-test-hessian-analysis&quot;&gt;Method 2: Second Derivative Test (Hessian Analysis)&lt;/h2&gt;

&lt;p&gt;For twice-differentiable functions, we can use the &lt;strong&gt;second derivative test&lt;/strong&gt;: a function is convex if its Hessian matrix is positive semidefinite.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analysis&lt;/strong&gt;: 
The Euclidean norm \(f(x) = \|x\|_2 = \sqrt{x^T x}\) is not differentiable at \(x = 0\). However, for \(x \neq 0\), we can compute:&lt;/p&gt;

\[\frac{\partial f}{\partial x_i} = \frac{x_i}{\|x\|_2}\]

\[\frac{\partial^2 f}{\partial x_i \partial x_j} = \frac{1}{\|x\|_2} \delta_{ij} - \frac{x_i x_j}{\|x\|_2^3}\]

&lt;p&gt;The Hessian matrix is:
\(H = \frac{1}{\|x\|_2} I - \frac{1}{\|x\|_2^3} x x^T = \frac{1}{\|x\|_2} \left( I - \frac{x x^T}{\|x\|_2^2} \right)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Verification of positive semidefiniteness&lt;/strong&gt;:
For any vector \(v \in \mathbb{R}^n\):
\(v^T H v = \frac{1}{\|x\|_2} \left( \|v\|_2^2 - \frac{(x^T v)^2}{\|x\|_2^2} \right)\)&lt;/p&gt;

&lt;p&gt;By Cauchy-Schwarz inequality: \((x^T v)^2 \leq \|x\|_2^2 \|v\|_2^2\)&lt;/p&gt;

&lt;p&gt;Therefore: \(\|v\|_2^2 - \frac{(x^T v)^2}{\|x\|_2^2} \geq 0\)&lt;/p&gt;

&lt;p&gt;This shows \(H \succeq 0\), confirming convexity for \(x \neq 0\).&lt;/p&gt;

&lt;h2 id=&quot;method-3-triangle-inequality-approach&quot;&gt;Method 3: Triangle Inequality Approach&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Alternative Proof using Minkowski Inequality&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;The Euclidean norm satisfies the &lt;strong&gt;triangle inequality&lt;/strong&gt;:
\(\|x + y\|_2 \leq \|x\|_2 + \|y\|_2\)&lt;/p&gt;

&lt;p&gt;For convexity, let \(u = \theta x\) and \(v = (1-\theta) y\) where \(\theta \in [0,1]\):
\(\|\theta x + (1-\theta) y\|_2 = \|u + v\|_2 \leq \|u\|_2 + \|v\|_2 = \theta \|x\|_2 + (1-\theta) \|y\|_2\)&lt;/p&gt;

&lt;p&gt;This directly establishes the convexity condition.&lt;/p&gt;

&lt;h2 id=&quot;key-properties-and-applications&quot;&gt;Key Properties and Applications&lt;/h2&gt;

&lt;h3 id=&quot;properties-of-euclidean-norm-convexity&quot;&gt;Properties of Euclidean Norm Convexity&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Strict Convexity&lt;/strong&gt;: The Euclidean norm is actually &lt;strong&gt;strictly convex&lt;/strong&gt; on any line not passing through the origin.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Homogeneity&lt;/strong&gt;: \(\|\alpha x\|_2 = \lvert\alpha\rvert \|x\|_2\) for any scalar \(\alpha\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Subadditivity&lt;/strong&gt;: \(\|x + y\|_2 \leq \|x\|_2 + \|y\|_2\) (Triangle inequality).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h3&gt;

&lt;p&gt;The convexity of the Euclidean norm has important implications:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Least Squares Problems&lt;/strong&gt;: The objective function \(\|Ax - b\|_2^2\) is convex.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: \(\ell_2\)-regularization terms like \(\lambda \|x\|_2\) preserve convexity.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Constrained Optimization&lt;/strong&gt;: Norm constraints \(\|x\|_2 \leq r\) define convex feasible sets.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We have proven that the Euclidean norm is convex using three different approaches:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Direct definition&lt;/strong&gt;: Using Jensen’s inequality and Cauchy-Schwarz&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second derivative test&lt;/strong&gt;: Showing the Hessian is positive semidefinite&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Triangle inequality&lt;/strong&gt;: Leveraging the fundamental norm property&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This convexity property is fundamental in optimization theory and has wide-ranging applications in machine learning, signal processing, and numerical analysis.&lt;/p&gt;

&lt;p&gt;The interactive visualization above demonstrates how the convexity condition \(\|\theta x + (1-\theta) y\|_2 \leq \theta \|x\|_2 + (1-\theta) \|y\|_2\) holds for any choice of points and convex combination parameter \(\theta\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-06 Convexity with respect to generalized inequalities</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_06_convexity_with_respect_to_generalized_inequalities/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_06_convexity_with_respect_to_generalized_inequalities</id>
   <content type="html">&lt;p&gt;This section discusses convexity with respect to generalized inequalities, extending the concept of convexity beyond standard real-valued functions.&lt;/p&gt;

&lt;p&gt;In spaces other than \(\mathbb{R}\), we use the definition of cones for generalized inequality expressions that extend the ordering concept commonly used in \(\mathbb{R}\) space (see &lt;a href=&quot;/contents/en/chapter02/02_01_04_Convex_cone/&quot;&gt;02-01-04&lt;/a&gt;). In this section, we examine the concepts of monotonicity and convexity that extend beyond \(\mathbb{R}\) space using the concept of cones.&lt;/p&gt;

&lt;h2 id=&quot;monotonicity-with-respect-to-a-generalized-inequality&quot;&gt;Monotonicity with respect to a generalized inequality&lt;/h2&gt;

&lt;p&gt;Suppose \(K \subseteq \mathbb{R}^n\) is a proper cone represented by \(\preceq_K\). A convex cone \(K \subseteq \mathbb{R}^n\) is a &lt;strong&gt;proper cone&lt;/strong&gt; if it satisfies the following conditions:&lt;/p&gt;

&lt;p&gt;• \(K\) is closed (contains its boundary)
• \(K\) is solid (has nonempty interior)
• \(K\) is pointed (contains no line)&lt;/p&gt;

&lt;p&gt;We define &lt;strong&gt;\(K\)-nondecreasing&lt;/strong&gt; as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \mapsto \mathbb{R}\) is \(K\)-nondecreasing if \(x \preceq_K y \Rightarrow f(x) \leq f(y)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Also, when the following condition is satisfied, we say it is &lt;strong&gt;\(K\)-increasing&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \mapsto \mathbb{R}\) is \(K\)-increasing if \(x \preceq_K y, x \neq y \Rightarrow f(x) &amp;lt; f(y)\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;gradient-conditions-for-monotonicity&quot;&gt;Gradient conditions for monotonicity&lt;/h3&gt;

&lt;p&gt;For a differentiable function \(f : \mathbb{R} \mapsto \mathbb{R}\) to be nondecreasing on a convex (i.e., interval) domain means that \(f&apos;(x) \geq 0\) for all \(x \in \text{dom}f\), and if \(f&apos;(x) &amp;gt; 0\) for all \(x \in \text{dom}f\), then it is increasing. Similarly, monotonicity can be expressed as an extended concept in generalized inequalities.&lt;/p&gt;

&lt;p&gt;When the domain is convex, a differentiable function \(f\) being \(K\)-nondecreasing means satisfying the following equation. Note that unlike simple scalars, the gradient \(\nabla f(x)\) must be nonnegative in the dual inequality.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;A differentiable function \(f\) is \(K\)-nondecreasing \(\Longleftrightarrow\) \(\nabla f(x) \succeq_{K^*} 0\) for all \(x \in \text{dom}f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If the following condition is satisfied, \(f\) is called &lt;strong&gt;\(K\)-increasing&lt;/strong&gt;. As with scalars, the converse does not hold.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\nabla f(x) \succ_{K^*} 0\) for all \(x \in \text{dom}f\) \(\Rightarrow\) \(f\) is \(K\)-increasing.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;convexity-with-respect-to-generalized-inequality&quot;&gt;Convexity with respect to generalized inequality&lt;/h3&gt;

&lt;p&gt;Let \(K \subseteq \mathbb{R}^m\) be a proper cone associated with the generalized inequality \(\preceq_K\).
Then, if \(f : \mathbb{R}^n \mapsto \mathbb{R}^m\) is called &lt;strong&gt;\(K\)-convex&lt;/strong&gt; for all \(x, y\) and \(0 \leq \theta \leq 1\), the following inequality holds:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \mapsto \mathbb{R}^m\) is \(K\)-convex \(\Rightarrow\) \(f(\theta x + (1 - \theta) y) \preceq_K \theta f(x) + (1 - \theta) f(y)\) with \(0 &amp;lt; \theta &amp;lt; 1\) for all \(x, y\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Also, the condition for &lt;strong&gt;strictly \(K\)-convex&lt;/strong&gt; is as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(\theta x + (1 - \theta) y) \prec_K \theta f(x) + (1 - \theta) f(y)\) for all \(x \neq y\) and \(0 &amp;lt; \theta &amp;lt; 1\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When \(m = 1\) and \(K = \mathbb{R}_+\), this becomes the inequality that satisfies the general convexity we have discussed earlier.&lt;/p&gt;

&lt;h3 id=&quot;dual-characterization-of-k-convexity&quot;&gt;Dual characterization of \(K\)-convexity&lt;/h3&gt;

&lt;p&gt;\(f\) being \(K\)-convex means that the (real-valued) function \(w^T f\) is convex for all \(w \succeq_{K^*} 0\). \(f\) being strictly \(K\)-convex means that the (real-valued) function \(w^T f\) is strictly convex for all \(w \succeq_{K^*} 0\). This follows from the definition and properties of dual inequalities.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;differentiable-k-convex-functions&quot;&gt;Differentiable \(K\)-convex functions&lt;/h3&gt;

&lt;p&gt;If a differentiable function \(f\) is \(K\)-convex and the function domain is convex, then the following equation holds:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(y) \succeq_K f(x) + Df(x)(y - x)\) for all \(x, y \in \text{dom}f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, \(Df(x) \in \mathbb{R}^{m \times n}\) is the derivative or Jacobian matrix of \(f\) at point \(x\).&lt;/p&gt;

&lt;p&gt;If \(f\) is strictly \(K\)-convex and the function domain is convex, then the following equation holds:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(y) \succ_K f(x) + Df(x)(y - x)\) for all \(x, y \in \text{dom}f\), \(x \neq y\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;composition-theorem&quot;&gt;Composition theorem&lt;/h3&gt;

&lt;p&gt;Many results from composition can be generalized to \(K\)-convexity.
For example, if \(g : \mathbb{R}^n \mapsto \mathbb{R}^p\) is \(K\)-convex, \(h : \mathbb{R}^p \rightarrow \mathbb{R}\) is convex, and the extended-value extension \(\widetilde{h}\) of \(h\) is \(K\)-nondecreasing, then \(h \circ g\) is convex. This generalizes the fact that the composition of a convex function with a nondecreasing convex function is convex.
(The condition that \(\widetilde{h}\) is \(K\)-nondecreasing means that \(\text{dom}h - K = \text{dom}h\).)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-05 Log-concave and log-convex functions</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_05_log_concave_and_log_convex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_05_log_concave_and_log_convex_functions</id>
   <content type="html">&lt;p&gt;This section introduces log-concave and log-convex functions, which are important in probability, statistics, and optimization.&lt;/p&gt;

&lt;h2 id=&quot;definition&quot;&gt;Definition&lt;/h2&gt;

&lt;p&gt;The definitions of log-concave and log-convex functions are as follows.&lt;/p&gt;

&lt;h3 id=&quot;f--mathbbrn-rightarrow-mathbbr-is-logarithmically-concave-or-log-concave&quot;&gt;\(f : \mathbb{R}^n \rightarrow \mathbb{R}\) is Logarithmically concave or log-concave&lt;/h3&gt;
&lt;p&gt;If \(f(x) &amp;gt; 0\) for all \(x \in \text{dom}f\) and \(\log f\) is concave, then \(f : \mathbb{R}^n \rightarrow \mathbb{R}\) is called logarithmically concave or log-concave.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) is log-concave for \(f(x) &amp;gt; 0\) for all \(x \in \text{dom}f\) : &lt;br /&gt;
\(f(\theta x + (1 - \theta) y) \geq f(x)^\theta f(y)^{1-\theta}\) for \(0 \leq \theta \leq 1\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;f--mathbbrn-mapsto-mathbbr-is-logarithmically-convex-or-log-convex&quot;&gt;\(f : \mathbb{R}^n \mapsto \mathbb{R}\) is Logarithmically convex or log-convex&lt;/h3&gt;
&lt;p&gt;If \(f(x) &amp;gt; 0\) for all \(x \in \text{dom}f\) and \(\log f\) is convex, then \(f : \mathbb{R}^n \mapsto \mathbb{R}\) is called logarithmically convex or log-convex. Therefore, if \(f\) is log-convex, then \(1/f\) is log-concave.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) is log-convex for \(f(x) &amp;gt; 0\) for all \(x \in \text{dom}f\) \(\Longleftrightarrow \frac{1}{f}\) is log-concave.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It is sometimes convenient to allow \(f\) values to be 0, in which case \(\log f(x) = -\infty\). In such cases, if the extended-value function \(\log f\) is concave, then \(f\) can be called log-concave.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Log-convex functions and log-concave functions are quasiconvex and quasiconcave, respectively, because the logarithm is monotonically increasing.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;examples&quot;&gt;Examples&lt;/h2&gt;
&lt;h3 id=&quot;affine-function&quot;&gt;Affine function&lt;/h3&gt;
&lt;p&gt;If \(f\) is defined as follows, then it is log-concave.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x) = a^Tx + b\) on \(\{x \mid a^Tx + b &amp;gt; 0\}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;powers&quot;&gt;Powers&lt;/h3&gt;
&lt;p&gt;\(f(x) = x^a\) on \(\mathbb{R}_{++}\) is log-convex when \(a \leq 0\) and log-concave when \(a \geq 0\).&lt;/p&gt;

&lt;h3 id=&quot;exponentials&quot;&gt;Exponentials&lt;/h3&gt;
&lt;p&gt;\(f(x) = e^{ax}\) is both log-convex and log-concave.&lt;/p&gt;

&lt;h3 id=&quot;the-cumulative-distribution-function-of-a-gaussian-density&quot;&gt;The cumulative distribution function of a Gaussian density&lt;/h3&gt;
&lt;p&gt;\(\Phi(x) = \frac{1}{ \sqrt{2 \pi } }  \int_ {-\infty} ^x e^{-u^2/2} du\) is log-concave.&lt;/p&gt;

&lt;h3 id=&quot;gamma-function&quot;&gt;Gamma function&lt;/h3&gt;
&lt;p&gt;\(\Gamma (x) = \int_0^\infty u^{x-1}e^{-u} du\)
is log-convex for \(x \geq 1\).&lt;/p&gt;

&lt;h3 id=&quot;determinant&quot;&gt;Determinant&lt;/h3&gt;
&lt;p&gt;\(\det X\) is log-concave on \(S^n_{++}\).&lt;/p&gt;

&lt;h3 id=&quot;determinant-over-trace&quot;&gt;Determinant over trace&lt;/h3&gt;
&lt;p&gt;\(\det X / \text{tr} X\) is log-concave on \(S^n_{++}\).&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;properties&quot;&gt;Properties&lt;/h2&gt;

&lt;h3 id=&quot;twice-differentiable-log-convex--concave-functions&quot;&gt;Twice differentiable log-convex / concave functions&lt;/h3&gt;
&lt;p&gt;If \(f\) is twice differentiable and \(\text{dom} f\) is convex, then the following equation holds:&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\nabla ^2 \log f(x) = \frac{1}{f(x)} \nabla ^2f(x) - \frac{1}{f(x)^2}\nabla f(x) \nabla f(x)^T\]
&lt;/blockquote&gt;

&lt;p&gt;\(f\) is log-convex \(\Longleftrightarrow\) \(f(x) \nabla ^2 f(x) \succeq \nabla f(x)\nabla f(x)^T\) for all \(x \in \text{dom} f\), and &lt;br /&gt;
\(f\) is log-concave \(\Longleftrightarrow\) \(f(x) \nabla ^2 f(x) \preceq \nabla f(x)\nabla f(x)^T\) for all \(x \in \text{dom} f\).&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&quot;multiplication&quot;&gt;Multiplication&lt;/h3&gt;
&lt;p&gt;Log-convexity and log-concavity are closed under multiplication and positive scaling. 
If \(f\) and \(g\) are log-concave, then the pointwise product \(h(x) = f(x)g(x)\) is also log-concave. 
This is because \(\log h(x) = \log f(x) + \log g(x)\), and both \(\log f(x)\) and \(\log g(x)\) are concave functions.&lt;/p&gt;

&lt;h3 id=&quot;addition-and-integration&quot;&gt;Addition and Integration&lt;/h3&gt;
&lt;p&gt;In general, the sum of log-concave functions is not log-concave. However, log-convexity is preserved under addition.
For example, let \(f\) and \(g\) be log-convex functions, i.e., \(F = \log f\) and \(G = \log g\) are convex.
By the composition rules for convex functions, the following holds:&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
\[\log(exp F + exp G) = \log(f + g)\]
&lt;/blockquote&gt;

&lt;p&gt;This is convex. (The left side is convex because: 1. log-convex functions are convex, 2. applying the exponential function to convex functions preserves convexity, 3. the sum of convex functions is convex, and 4. the logarithm of convex functions is convex.
Therefore, the entire result is convex.) In conclusion, the sum of two log-convex functions is log-convex.&lt;/p&gt;

&lt;p&gt;Generalizing this, if \(f(x, y)\) is log-convex for each \(y \in C\), then \(g(x)\) is log-convex.&lt;/p&gt;
&lt;blockquote&gt;
\[g(x) = \int_C^{} f(x,y) dy\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;integration-of-log-concave-functions&quot;&gt;Integration of log-concave functions&lt;/h3&gt;
&lt;p&gt;In certain cases, log-concavity is also preserved under integration. If \(f : \mathbb{R}^n \times \mathbb{R}^m \mapsto \mathbb{R}\) is log-concave, then \(g(x)\) is a log-concave function for \(x \in \mathbb{R}^n\).&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \mapsto \mathbb{R}\) is log-concave \(\Longrightarrow\) \(g(x) = \int_{}^{} f(x,y) dy\) is log-concave , \(x \in \mathbb{R}^n\) for each \(y \in C\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Based on this, we can confirm that the marginal distribution of a log-concave probability density is log-concave.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Log-concavity is also closed under convolution operations. If \(f\) and \(g\) are log-concave on \(\mathbb{R}^n\), then their convolution is also log-concave.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\), \(g\) are log-concave on \(\mathbb{R}^n \Longrightarrow (f \ast g)(x) = \int_{}^{} f(x-y)g(y) dy\) is log-concave.&lt;br /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>03-04-04 Operations that preserve quasiconvexity</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_04_04_operations_that_preserve_quasiconvexity/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_04_04_operations_that_preserve_quasiconvexity</id>
   <content type="html">&lt;p&gt;This section discusses operations that preserve the quasiconvexity of functions.&lt;/p&gt;

&lt;h2 id=&quot;nonnegative-weighted-maximum&quot;&gt;Nonnegative weighted maximum&lt;/h2&gt;

&lt;p&gt;When \(f\) is a quasiconvex function, the nonnegative weighted maximum \(f\) is quasiconvex.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f = \max\{w_1f_1, ... ,w_mf_m\}\) with \(w_i \geq 0\) is quasiconvex&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This concept can be extended as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x) = \sup_{y \in C}(w(y)g(x,y))\) with \(w(y) \geq 0\), 
where \(g(x,y)\) is quasiconvex in \(x\) for each \(y\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;composition&quot;&gt;Composition&lt;/h2&gt;

&lt;p&gt;If \(g : \mathbb{R}^n \mapsto \mathbb{R}\) is quasiconvex and \(h : \mathbb{R} \mapsto \mathbb{R}\) is nondecreasing, then the composition \(f\) satisfies quasiconvexity.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f = h \circ g\) is quasiconvex if \(h\) is nondecreasing and \(g\) is quasiconvex.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Composing a quasiconvex function with affine or linear-fractional transformations results in a quasiconvex function.
If \(f\) is quasiconvex, then \(g(x) = f(Ax + b)\) is also quasiconvex, and \(\tilde{g}(x) = f((Ax + b)/(c^Tx + d))\) is also quasiconvex on the set \(\{x \mid c^Tx + d &amp;gt; 0, (Ax + b)/(c^Tx + d) \in \text{dom}f\}\).&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;minimization&quot;&gt;Minimization&lt;/h2&gt;

&lt;p&gt;If \(f(x, y)\) satisfies quasiconvexity and \(C\) is a convex set, then the following condition holds:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(g(x) = \inf_{y \in C} f(x,y)\) is quasiconvex if \(f\) is quasiconvex in \((x,y)\) and \(C\) is a convex set.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;representation-via-family-of-convex-functions&quot;&gt;Representation via family of convex functions&lt;/h2&gt;

&lt;p&gt;The sublevel sets of a quasiconvex function \(f\) can be represented by inequalities of convex functions. A family of convex functions is \(\phi_t : \mathbb{R}^n \mapsto \mathbb{R}\) for \(t \in \mathbb{R}\), defined as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[f(x) \leq t \Longleftrightarrow \phi_t(x) \leq 0\]
&lt;/blockquote&gt;

&lt;p&gt;That is, the \(t\)-sublevel set of quasiconvex function \(f(x)\) becomes the 0-sublevel set of convex function \(\phi_t\). Here, \(t\) represents the index of convex function \(\phi\). For all \(x \in \mathbb{R}^n\), the following is satisfied:&lt;/p&gt;
&lt;blockquote&gt;
\[\phi_t(x) \leq 0 \Rightarrow \phi_s(x) \leq 0 \text{ for } s \geq t\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>03-04-03 Differentiable quasiconvex functions</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_04_03_differentiable_quasiconvex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_04_03_differentiable_quasiconvex_functions</id>
   <content type="html">&lt;p&gt;This section discusses the properties and characterizations of differentiable quasiconvex functions.&lt;/p&gt;

&lt;h2 id=&quot;first-order-conditions&quot;&gt;First-order conditions&lt;/h2&gt;
&lt;p&gt;Let \(f : \mathbb{R}^n \rightarrow \mathbb{R}\) be a differentiable function. If \(\text{dom}f\) is convex and the following condition is satisfied, then \(f\) is quasiconvex.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) is quasiconvex \(\iff\) \(f(y) \leq f(x) \Rightarrow \nabla f(x)^T(y-x) \leq 0\) for all \(x, y \in \text{dom}f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/3.12_Three_level_curves_OV6vtPq.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Three level curves of a quasiconvex function \(f\). \(\nabla f(x)\) is the normal vector that defines the supporting hyperplane of the sublevel set \(\{z \mid f(z) \leq f(x)\}\) at \(x\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The first-order condition for quasiconvexity appears similar to the first-order characterization of convexity (see &lt;a href=&quot;/contents/en/chapter03/03_01_03_key_properties_of_convex_functions/&quot;&gt;03-01-03&lt;/a&gt;), but there are important differences. For example, if \(f\) is convex and \(\nabla f(x) = 0\), then \(x\) is a global minimizer of \(f\), but this does not always hold for quasiconvex functions.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;second-order-conditions&quot;&gt;Second-order conditions&lt;/h2&gt;

&lt;p&gt;When \(f\) is twice differentiable, second-order conditions apply. If \(f\) is quasiconvex, then for all \(x \in \text{dom}f\) and all \(y \in \mathbb{R}^n\), the following holds:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) is quasiconvex, \(y^T \nabla f(x) = 0 \Longrightarrow y^T \nabla^2 f(x)y \geq 0\) for all \(x \in \text{dom} f\), all \(y \in \mathbb{R}^n\) &lt;br /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For quasiconvex functions on \(\mathbb{R}\):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f\) is quasiconvex, \(f&apos;(x) = 0 \Rightarrow f&apos;&apos;(x) \geq 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That is, if there exists any point with zero slope, the second derivative value is non-negative. Returning to \(\mathbb{R}^n\), the second-order condition also satisfies the following properties:&lt;/p&gt;

&lt;p&gt;1) When \(\nabla f(x) = 0\), we must always have \(\nabla^2f(x) \succeq 0\).
2) If \(\nabla f(x) \neq 0\), then \(y^T \nabla f(x) = 0 \Rightarrow y^T \nabla^2 f(x)y \geq 0\), where \(\nabla^2 f(x)\) acts as the Hessian matrix and is positive semidefinite on the \((n-1)\)-dimensional subspace \(\nabla f(x)^\perp\).&lt;/p&gt;

&lt;p&gt;(The \((n-1)\)-dimensional subspace \(\nabla f(x)^\perp\) means the \((n-1)\)-dimensional subspace orthogonal to \(\nabla f(x)\). It is \((n-1)\)-dimensional because \(\nabla f(x)\) is the gradient of an \(n\)-dimensional function \(f\), reducing the dimension by one.)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-04-02 Basic properties of quasiconvex functions</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_04_02_basic_properties_of_quasiconvex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_04_02_basic_properties_of_quasiconvex_functions</id>
   <content type="html">&lt;p&gt;This section covers the basic properties of quasiconvex functions, including their relationship to convex functions and their behavior under various operations.&lt;/p&gt;

&lt;h2 id=&quot;modified-jensens-inequality&quot;&gt;Modified Jensen’s inequality&lt;/h2&gt;
&lt;p&gt;Quasiconvex functions can be defined through Jensen’s inequality as follows:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(\theta x + (1 - \theta)y) \leq \max\{f(x), f(y)\}\) for all \(x, y \in \text{dom}f, 0 \leq \theta \leq 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The figure below shows that if function \(f\) is quasiconvex, then the value of \(f\) along the line segment between two points does not exceed the maximum of \(f\) at the endpoints.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/Fig.3.10_quasiconvex_function_on_R_4uChnEm.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;quasiconvex function on \(\mathbb{R}\). The values of \(f\) between \(x\) and \(y\) are less than \(\max\{f(x), f(y)\}\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;quasiconvex-function-on-mathbbr&quot;&gt;Quasiconvex function on \(\mathbb{R}\)&lt;/h2&gt;
&lt;p&gt;A continuous function \(f : \mathbb{R} \mapsto \mathbb{R}\) is quasiconvex if and only if it satisfies at least one of the following conditions:&lt;/p&gt;

&lt;p&gt;• \(f\) is nondecreasing
• \(f\) is nonincreasing&lt;br /&gt;
• There exists a point \(c \in \text{dom} f\) such that \(f\) is nonincreasing on \(\{t \in \text{dom}f \mid t \leq c\}\) and nondecreasing on \(\{t \in \text{dom}f \mid t \geq c\}\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/Fig.3.11_quasiconvex_function_on_R_2_PPQpNiU.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;quasiconvex function on \(\mathbb{R}\). It is nonincreasing for \(t \leq c\) where \(t \in \text{dom} f\), and nondecreasing for \(t \geq c\) where \(t \in \text{dom} f\).&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-04-01 Quasiconvex functions: definition and examples</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_04_01_quasiconvex_functions_definition_and_examples/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_04_01_quasiconvex_functions_definition_and_examples</id>
   <content type="html">&lt;p&gt;A function \(f:\mathbb{R}^n \rightarrow \mathbb{R}\) is quasiconvex if all its sublevel sets \(\{x \mid f(x) \leq \alpha\}\) are convex for every \(\alpha \in \mathbb{R}\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Quasiconvex functions generalize convex functions&lt;/strong&gt; and appear frequently in optimization problems.&lt;/p&gt;

&lt;h2 id=&quot;definition&quot;&gt;Definition&lt;/h2&gt;

&lt;p&gt;A function \(f: \mathbb{R}^n \rightarrow \mathbb{R}\) is called &lt;strong&gt;quasiconvex&lt;/strong&gt; (or &lt;strong&gt;unimodal&lt;/strong&gt;) if its domain \(\text{dom}f\) and all sublevel sets \(S_{\alpha}\) (see &lt;a href=&quot;/contents/en/chapter03/03_01_03_key_properties_of_convex_functions/&quot;&gt;03-01-03&lt;/a&gt;) are convex.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \rightarrow \mathbb{R}\) is quasiconvex if \(\text{dom}f\) and
\(S_{\alpha} =\{x \in \text{dom}f \mid f(x) \leq \alpha\}\) for \(\alpha \in \mathbb{R}\) are convex.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If function \(-f\) is quasiconvex, then \(f\) is called &lt;strong&gt;quasiconcave&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f : \mathbb{R}^n \rightarrow \mathbb{R}\) is quasiconcave if \(\text{dom}f\) and
\(S_{\alpha} = \{ x \in \text{dom}f \mid f(x) \geq \alpha \}\) for \(\alpha \in \mathbb{R}\) are convex.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When \(f\) is both quasiconvex and quasiconcave, it is called &lt;strong&gt;quasilinear&lt;/strong&gt;, and the function’s domain and all level sets \(\{x \mid f(x)=\alpha\}\) are convex. The following figure shows an example of a quasiconvex function.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/Fig3.9_quasiconvex_ftn_cAsoUpr.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] quasiconvex function on R [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;For \(\alpha\), the \(\alpha\)-sublevel set \(S_{\alpha}\) is convex, namely the interval \([a,b]\). The \(\beta\)-sublevel set \(S_{\beta}\) is the interval \((-\infty,c]\). &lt;strong&gt;Convex functions have convex sublevel sets and are quasiconvex, but the converse is not true.&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) : convex \(\Longrightarrow\) \(f\) : quasiconvex&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;examples&quot;&gt;Examples&lt;/h2&gt;

&lt;p&gt;Let’s examine various examples of quasiconvex functions.&lt;/p&gt;

&lt;h3 id=&quot;logarithm&quot;&gt;Logarithm&lt;/h3&gt;
&lt;p&gt;\(\log x\) on \(\mathbb{R}_{++}\) is quasiconvex. (It is also quasiconcave, so it has the property of being quasilinear.)&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\log x\) on \(\mathbb{R}_{++}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;ceiling-function&quot;&gt;Ceiling function&lt;/h3&gt;
&lt;p&gt;The ceiling function is quasiconvex (and also quasiconcave).&lt;/p&gt;
&lt;blockquote&gt;
\[\text{ceil}(x) = \inf \{z \in \mathbb{Z} \mid z \geq x\}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;length-of-vector&quot;&gt;Length of vector&lt;/h3&gt;
&lt;p&gt;If we define the length of \(x \in \mathbb{R}^n\) as the largest index of nonzero components,&lt;/p&gt;
&lt;blockquote&gt;
\[f(x) = \max\{i \mid x_i \neq 0\}\]
&lt;/blockquote&gt;

&lt;p&gt;This satisfies&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x) \leq \alpha \iff x_i = 0\) for \(i = \lfloor\alpha\rfloor + 1,...,n\) on \(\mathbb{R}^n\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;which defines a subspace, so it is quasiconvex.
(Note: A subspace is closed under addition and scalar multiplication. Any subspace of \(\mathbb{R}^n\) is also a convex set.)&lt;/p&gt;

&lt;h3 id=&quot;linear-fractional-function&quot;&gt;Linear-fractional function&lt;/h3&gt;
&lt;p&gt;Under the following conditions, function \(f\) is both quasiconvex and quasiconcave, i.e., quasilinear.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x) = \frac{a^Tx+b}{c^Tx+d}\) with \(\text{dom}f =\{x \mid c^Tx + d &amp;gt; 0\}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;distance-ratio-function&quot;&gt;Distance ratio function&lt;/h3&gt;
&lt;p&gt;For \(a, b \in \mathbb{R}^n\), when function \(f\) is defined as follows, representing the ratio of Euclidean distances from \(x\) to \(a\) and from \(x\) to \(b\),
\(f\) is quasiconvex on the halfspace \(\{x \mid \|x - a\|_2 \leq \|x - b\|_2 \}\).&lt;/p&gt;

&lt;blockquote&gt;
\[f(x) = \frac{\|x - a\|_2}{\|x - b\|_2}\]
&lt;/blockquote&gt;

&lt;p&gt;Under the condition \(\alpha \leq 1\), this becomes a convex set in the form of a Euclidean ball, so \(f\) is quasiconvex.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-04 Quasiconvex functions</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_04_00_Quasiconvex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_04_00_Quasiconvex_functions</id>
   <content type="html">&lt;p&gt;This section introduces quasiconvex functions, their definitions, examples, and basic properties.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-03 The conjugate function</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_03_the_conjugate_function/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_03_the_conjugate_function</id>
   <content type="html">&lt;p&gt;This section introduces the conjugate function (also known as the convex conjugate or Fenchel conjugate), a fundamental concept in convex analysis and duality theory that provides a powerful tool for transforming optimization problems.&lt;/p&gt;

&lt;h2 id=&quot;definition-and-mathematical-foundation&quot;&gt;Definition and Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;For a function \(f: \mathbb{R}^n \to \mathbb{R}\), the &lt;strong&gt;conjugate function&lt;/strong&gt; \(f^*: \mathbb{R}^n \to \mathbb{R}\) is defined as:&lt;/p&gt;

\[f^*(y) = \sup_{x \in \text{dom}(f)} \{y^T x - f(x)\}\]

&lt;p&gt;where \(\sup\) denotes the supremum (least upper bound) over all \(x\) in the domain of \(f\).&lt;/p&gt;

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

&lt;p&gt;The conjugate function has a beautiful geometric interpretation:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(f^*(y)\) represents the &lt;strong&gt;maximum gap&lt;/strong&gt; between the linear function \(y^T x\) and the original function \(f(x)\)&lt;/li&gt;
  &lt;li&gt;Geometrically, it measures how much the hyperplane with slope \(y\) can be “lifted above” the graph of \(f\)&lt;/li&gt;
  &lt;li&gt;The conjugate transforms the function from the “primal space” to the “dual space” of slopes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;why-is-it-important&quot;&gt;Why is it Important?&lt;/h3&gt;

&lt;p&gt;The conjugate function is used to:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Transform optimization problems into their corresponding &lt;strong&gt;dual problems&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Provide analytical tools for &lt;strong&gt;duality theory&lt;/strong&gt; (covered in Chapter 11)&lt;/li&gt;
  &lt;li&gt;Enable direct substitution in &lt;strong&gt;Lagrange Duality&lt;/strong&gt; without explicit differentiation&lt;/li&gt;
  &lt;li&gt;Establish connections between primal and dual optimal solutions&lt;/li&gt;
&lt;/ol&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/conjugate_function.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Conjugate function [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;fundamental-properties&quot;&gt;Fundamental Properties&lt;/h2&gt;

&lt;p&gt;The conjugate function has several remarkable properties that make it a powerful analytical tool:&lt;/p&gt;

&lt;h3 id=&quot;1-convexity-property&quot;&gt;1. Convexity Property&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(f^*\) is always convex&lt;/strong&gt;, regardless of whether \(f\) is convex or not&lt;/li&gt;
  &lt;li&gt;This is because \(f^*(y)\) is the pointwise supremum of affine functions \(y^T x - f(x)\)&lt;/li&gt;
  &lt;li&gt;The supremum of any collection of convex (affine) functions is convex&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-fenchels-inequality&quot;&gt;2. Fenchel’s Inequality&lt;/h3&gt;
&lt;p&gt;For any \(x\) and \(y\):
\(f(x) + f^*(y) \geq x^T y\)&lt;/p&gt;

&lt;p&gt;This fundamental inequality establishes a lower bound relationship between a function and its conjugate.&lt;/p&gt;

&lt;h3 id=&quot;3-conjugate-of-conjugate-biconjugate&quot;&gt;3. Conjugate of Conjugate (Biconjugate)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;In general: \(f^{**} \leq f\) (the biconjugate is a lower bound)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;If \(f\) is closed and convex&lt;/strong&gt;: \(f^{**} = f\) (perfect recovery)&lt;/li&gt;
  &lt;li&gt;This property is crucial for duality theory&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-subdifferential-relationship&quot;&gt;4. Subdifferential Relationship&lt;/h3&gt;
&lt;p&gt;If \(f\) is closed and convex, then for any \(x, y\):
\(y \in \partial f(x) \iff x \in \partial f^*(y) \iff f(x) + f^*(y) = x^T y\)&lt;/p&gt;

&lt;p&gt;This establishes a beautiful symmetry between primal and dual spaces.&lt;/p&gt;

&lt;h2 id=&quot;detailed-examples&quot;&gt;Detailed Examples&lt;/h2&gt;

&lt;h3 id=&quot;example-1-negative-logarithm&quot;&gt;Example 1: Negative Logarithm&lt;/h3&gt;
&lt;p&gt;Consider \(f(x) = -\log x\) for \(x &amp;gt; 0\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step-by-step calculation:&lt;/strong&gt;
\(f^*(y) = \sup_{x&amp;gt;0} \{xy + \log x\}\)&lt;/p&gt;

&lt;p&gt;To find the supremum, we differentiate with respect to \(x\):
\(\frac{d}{dx}(xy + \log x) = y + \frac{1}{x} = 0\)&lt;/p&gt;

&lt;p&gt;This gives us \(x^* = -\frac{1}{y}\) (valid only when \(y &amp;lt; 0\)).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt;
\(f^*(y) = \begin{cases}
-1 - \log(-y), &amp;amp; \text{if } y &amp;lt; 0 \\
+\infty, &amp;amp; \text{if } y \geq 0
\end{cases}\)&lt;/p&gt;

&lt;h3 id=&quot;example-2-quadratic-function&quot;&gt;Example 2: Quadratic Function&lt;/h3&gt;
&lt;p&gt;Consider \(f(x) = \frac{1}{2}x^T Q x\) where \(Q \succ 0\) (positive definite).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step-by-step calculation:&lt;/strong&gt;
\(f^*(y) = \sup_{x} \{y^T x - \frac{1}{2}x^T Q x\}\)&lt;/p&gt;

&lt;p&gt;Taking the gradient and setting it to zero:
\(\nabla_x (y^T x - \frac{1}{2}x^T Q x) = y - Qx = 0\)&lt;/p&gt;

&lt;p&gt;This gives us \(x^* = Q^{-1}y\).&lt;/p&gt;

&lt;p&gt;Substituting back:
\(f^*(y) = y^T Q^{-1} y - \frac{1}{2}(Q^{-1}y)^T Q (Q^{-1}y) = \frac{1}{2}y^T Q^{-1} y\)&lt;/p&gt;

&lt;h3 id=&quot;example-3-absolute-value-1d-case&quot;&gt;Example 3: Absolute Value (1D case)&lt;/h3&gt;
&lt;p&gt;Consider \(f(x) = \lvert x \rvert\) for \(x \in \mathbb{R}\).&lt;/p&gt;

\[f^*(y) = \sup_{x} \{yx - \lvert x \rvert\}\]

&lt;p&gt;&lt;strong&gt;Analysis by cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If \(\lvert y \rvert \leq 1\): The supremum is finite and equals 0&lt;/li&gt;
  &lt;li&gt;If \(\lvert y \rvert &amp;gt; 1\): The supremum is \(+\infty\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt;
\(f^*(y) = \begin{cases}
0, &amp;amp; \text{if } \lvert y \rvert \leq 1 \\
+\infty, &amp;amp; \text{if } \lvert y \rvert &amp;gt; 1
\end{cases}\)&lt;/p&gt;

&lt;p&gt;This is the &lt;strong&gt;indicator function&lt;/strong&gt; of the interval \([-1, 1]\).&lt;/p&gt;

&lt;h3 id=&quot;example-4-exponential-function&quot;&gt;Example 4: Exponential Function&lt;/h3&gt;
&lt;p&gt;Consider \(f(x) = e^x\) for \(x \in \mathbb{R}\).&lt;/p&gt;

\[f^*(y) = \sup_{x} \{yx - e^x\}\]

&lt;p&gt;Setting the derivative to zero: \(y - e^x = 0\), so \(x^* = \log y\) (valid for \(y &amp;gt; 0\)).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt;
\(f^*(y) = \begin{cases}
y \log y - y, &amp;amp; \text{if } y &amp;gt; 0 \\
0, &amp;amp; \text{if } y = 0 \\
+\infty, &amp;amp; \text{if } y &amp;lt; 0
\end{cases}\)&lt;/p&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;p&gt;The conjugate function plays a crucial role in:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Lagrange Duality&lt;/strong&gt;: Converting primal problems to dual problems&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fenchel Duality&lt;/strong&gt;: A general framework for convex optimization duality&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Proximal Operators&lt;/strong&gt;: Used in modern optimization algorithms&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Variational Analysis&lt;/strong&gt;: Studying optimization problems through conjugate pairs&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These applications will be explored in detail in Chapters 11 and 13.&lt;/p&gt;

&lt;h2 id=&quot;interactive-visualization&quot;&gt;Interactive Visualization&lt;/h2&gt;

&lt;p&gt;To better understand how conjugate functions work, explore our interactive visualization:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 20px 0;&quot;&gt;
    &lt;a href=&quot;../conjugate_function_interactive.html&quot; target=&quot;_blank&quot; style=&quot;display: inline-block; padding: 12px 24px; background-color: #3498db; color: white; text-decoration: none; border-radius: 6px; font-weight: bold; box-shadow: 0 2px 4px rgba(0,0,0,0.2);&quot;&gt;
        🎯 Launch Interactive Conjugate Function Explorer
    &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;The interactive tool allows you to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Visualize different function types&lt;/strong&gt; and their conjugates side-by-side&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Adjust parameters&lt;/strong&gt; to see how they affect the conjugate&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Explore tangent lines&lt;/strong&gt; to understand the geometric interpretation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compare multiple examples&lt;/strong&gt; with detailed mathematical explanations&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary-and-key-takeaways&quot;&gt;Summary and Key Takeaways&lt;/h2&gt;

&lt;p&gt;The conjugate function is a powerful mathematical tool that:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Transforms functions&lt;/strong&gt; from primal to dual space through the operation \(f^*(y) = \sup_x \{y^T x - f(x)\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Always produces convex functions&lt;/strong&gt;, regardless of the original function’s convexity&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Establishes fundamental inequalities&lt;/strong&gt; like Fenchel’s inequality: \(f(x) + f^*(y) \geq x^T y\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Enables duality theory&lt;/strong&gt; by connecting primal and dual optimization problems&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Provides analytical tools&lt;/strong&gt; for solving complex optimization problems&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Understanding conjugate functions is essential for:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Convex optimization theory&lt;/strong&gt; and algorithm development&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lagrange duality&lt;/strong&gt; and dual problem formulation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Modern optimization methods&lt;/strong&gt; like proximal algorithms&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Variational analysis&lt;/strong&gt; and mathematical economics&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The geometric intuition of “maximum gap between linear and nonlinear functions” provides a visual understanding that complements the analytical definition, making this abstract concept more accessible to learners.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>03-02 Operations that preserve convexity</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_02_operations_that_preserve_convexity/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_02_operations_that_preserve_convexity</id>
   <content type="html">&lt;p&gt;This section discusses operations that preserve the convexity of convex functions.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nonnegative weighted sum&lt;/li&gt;
  &lt;li&gt;Composition with affine functions&lt;/li&gt;
  &lt;li&gt;Pointwise maximum&lt;/li&gt;
  &lt;li&gt;Perspective function&lt;/li&gt;
  &lt;li&gt;Linear-fractional function&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;nonnegative-weighted-sum&quot;&gt;Nonnegative weighted sum&lt;/h2&gt;
&lt;p&gt;Convex functions have the following properties with respect to scalar multiplication and addition:&lt;/p&gt;

&lt;p&gt;• When a convex function \(f\) exists, multiplying it by any nonnegative number still results in a convex function \(f\).&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) is convex \(\Rightarrow \alpha f\) is convex for \(\alpha \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;• When two convex functions (\(f_1, f_2\)) exist, their sum is also convex.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f_1, f_2\) are convex \(\Rightarrow f_1 + f_2\) is convex&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;• A nonnegative weighted sum of convex functions \(f_1, ..., f_m\) is convex.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f_1, ..., f_n\) are convex \(\Rightarrow \alpha_1f_1 + \cdots + \alpha_nf_n\) is convex, \(\alpha_1, ..., \alpha_n \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;composition&quot;&gt;Composition&lt;/h2&gt;
&lt;h3 id=&quot;1-affine-composition&quot;&gt;1. Affine composition&lt;/h3&gt;
&lt;p&gt;If function \(f\) is convex, then \(f(Ax + b)\) is also convex.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f\) is convex \(\Rightarrow f(Ax + b)\) is convex&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;2-general-composition&quot;&gt;2. General composition&lt;/h3&gt;
&lt;p&gt;Suppose we have function \(g\) that maps from \(n\)-dimensional to 1-dimensional space and function \(h\) that maps from 1-dimensional to 1-dimensional space.
The composition function \(f(x)=h(g(x))\) is convex or concave in the following cases:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;composition of \(g:\mathbb{R}^n \mapsto \mathbb{R}\) and \(h:\mathbb{R}\mapsto \mathbb{R}\):
\(f(x)=h(g(x))\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;• If \(g\) is convex, \(h\) is convex, and \(h\) is nondecreasing, then \(f\) is convex.
• If \(g\) is concave, \(h\) is convex, and \(h\) is nonincreasing, then \(f\) is convex.
• If \(g\) is concave, \(h\) is concave, and \(h\) is nondecreasing, then \(f\) is concave.
• If \(g\) is convex, \(h\) is concave, and \(h\) is nonincreasing, then \(f\) is concave.&lt;/p&gt;

&lt;h3 id=&quot;note&quot;&gt;[Note]&lt;/h3&gt;
&lt;p&gt;The monotonicity of the extended-value extension \(\tilde{h}\) must be preserved.&lt;/p&gt;

&lt;h3 id=&quot;example&quot;&gt;Example&lt;/h3&gt;
&lt;p&gt;• If \(g\) is convex, then \(\exp g(x)\) is convex.
• If \(g\) is concave and positive, then \(1/g(x)\) is convex.&lt;/p&gt;

&lt;h3 id=&quot;3-vector-composition&quot;&gt;3. Vector composition&lt;/h3&gt;
&lt;p&gt;Suppose we have function \(g\) that maps from \(n\)-dimensional to \(k\)-dimensional space and function \(h\) that maps from \(k\)-dimensional to 1-dimensional space.
Then the composition function \(f(x)=h(g(x))=h(g_1(x),g_2(x),...,g_k(x))\) is convex or concave in the following cases:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;composition of \(g:\mathbb{R}^n\mapsto\mathbb{R}^k\) and \(h:\mathbb{R}^k\mapsto\mathbb{R}\):
\(f(x)=h(g(x))=h(g_1(x),g_2(x),...,g_k(x))\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;• If \(g\) is convex and \(h\) is convex, and \(h\) is nondecreasing in each argument, then \(f\) is convex.
• If \(g\) is convex and \(h\) is concave, and \(h\) is nonincreasing in each argument, then \(f\) is concave.&lt;/p&gt;

&lt;h3 id=&quot;example-1&quot;&gt;Example&lt;/h3&gt;
&lt;p&gt;• If \(g_i\) are concave and positive, then \(\sum_{i=1}^{m} \log g_i(x)\) is concave.
• If \(g_i\) are convex, then \(\log \sum_{i=1}^{m} \exp g_i(x)\) is convex.&lt;/p&gt;

&lt;h2 id=&quot;pointwise-maximum&quot;&gt;Pointwise maximum&lt;/h2&gt;
&lt;p&gt;The pointwise maximum of functions is defined as follows and is convex:&lt;/p&gt;
&lt;h3 id=&quot;1-pointwise-maximum&quot;&gt;1. Pointwise maximum&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f_1, f_2\) are convex functions \(\Rightarrow f(x) = \max \{ f_1(x), f_2(x) \}\), \(\text{dom } f = \text{dom } f_1 \cap \text{dom } f_2\) is convex&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;2-pointwise-supremum&quot;&gt;2. Pointwise supremum&lt;/h3&gt;
&lt;p&gt;If \(f(x, y)\) is convex in \(x\) for each \(y \in A\), then \(g(x) = \sup_{y\in A} f(x, y)\) is convex.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f(x, y)\) is convex in \(x\) for each \(y \in A\)
\(\Rightarrow g(x) = \sup_{y\in A} f(x, y)\) with \(\text{dom } g = \{x | (x, y) \in \text{dom} f \text{ for all } y \in A, \sup &amp;lt; \infty \}\) is convex in \(x\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;perspective&quot;&gt;Perspective&lt;/h2&gt;
&lt;p&gt;If function \(f: \mathbb{R}^n \rightarrow \mathbb{R}\) is convex, then the perspective operation \(g: \mathbb{R}^{n+1} \mapsto \mathbb{R}\) preserves convexity.&lt;/p&gt;

&lt;p&gt;The perspective function \(g: \mathbb{R}^n×\mathbb{R} \mapsto \mathbb{R}\) of function \(f: \mathbb{R}^n \mapsto \mathbb{R}\) is:&lt;/p&gt;

\[g(x,t) = tf\left(\frac{x}{t}\right), \quad \text{dom } g = \left\{(x,t) \left| \frac{x}{t} \in \text{dom } f, t&amp;gt;0 \right.\right\}\]

&lt;p&gt;If function \(f\) is convex, then \(g\) is also convex.&lt;/p&gt;

&lt;h3 id=&quot;example-2&quot;&gt;Example&lt;/h3&gt;
&lt;p&gt;• When \(t\) is positive, if \(g(x,t)=x^Tx/t\) is convex, then \(f(x)=x^Tx\) is convex.&lt;/p&gt;

&lt;p&gt;• &lt;strong&gt;Negative logarithm&lt;/strong&gt;
When relative entropy \(g(x,t) =t\log t − t\log x\) is convex on \(\mathbb{R}_{++}^2\), then \(f(x)=−\log x\) is convex.&lt;/p&gt;

&lt;p&gt;• If \(f\) is convex, then \(g(x)=(c^Tx+d)f\left(\frac{Ax+b}{c^Tx+d}\right)\) is convex under the following condition:&lt;/p&gt;
&lt;blockquote&gt;
\[\left\{x \left| c^Tx+d&amp;gt;0, \frac{Ax+b}{c^Tx+d} \in \text{dom } f\right.\right\}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>03-01-03 Key properties of convex functions</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_01_03_key_properties_of_convex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_01_03_key_properties_of_convex_functions</id>
   <content type="html">&lt;h2 id=&quot;epigraph-characterization&quot;&gt;Epigraph characterization&lt;/h2&gt;
&lt;p&gt;As discussed in Section 1.2, \(f\) is convex if and only if its epigraph is a convex set, and vice versa.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f\) is convex \(\iff epi(f) = \{(x,t) \in \mathbb{R}^{n+1} \mid x \in \text{dom} f, f(x) \le t \}\) is a convex set&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;convex-sublevel-sets&quot;&gt;Convex sublevel sets&lt;/h2&gt;
&lt;p&gt;If a function \(f\) is convex, its sublevel sets are also convex.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\{x \in \text{dom } f: f(x) \leq t\}\), for all \(t \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;note-sublevel-set&quot;&gt;[Note] Sublevel set&lt;/h3&gt;
&lt;p&gt;For a function \(f:\mathbb{R}^n \mapsto \mathbb{R}\), \(C_\alpha = \{x \in \text{dom} f | f(x) \leq \alpha\}\) is called the &lt;em&gt;\(\alpha\)-sublevel set&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;first-order-characterization&quot;&gt;First-order characterization&lt;/h2&gt;
&lt;p&gt;If a function \(f\) is &lt;strong&gt;differentiable&lt;/strong&gt;, the following holds:
If the domain \(\text{dom} f\) is convex and for all \(x, y \in \text{dom} f\), \(f(y) \geq f(x) +\nabla f(x)^T(y-x)\), then \(f\) is convex, and vice versa.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f\) is convex \(\iff \text{dom}f\) is convex, and \(f(y) \geq f(x) +\nabla f(x)^T(y-x)\) for all \(x,y \in \text{dom} f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The figure below illustrates the first-order condition for a differentiable convex function \(f\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/1st_order_condition.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Convex Function [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;This condition is known as the &lt;strong&gt;tangent line condition&lt;/strong&gt; (or tangent hyperplane condition in higher dimensions). It essentially states that a convex function always lies above or on all of its tangent lines (or hyperplanes). No matter where you draw a tangent to a convex function, the function’s actual values will never dip below that tangent.&lt;/p&gt;

&lt;h3 id=&quot;example&quot;&gt;Example&lt;/h3&gt;

&lt;p&gt;Consider the simple convex function \(f(x) = x^2\). Its derivative (which is its gradient in 1D) is \(f&apos;(x) = 2x\).&lt;/p&gt;

&lt;p&gt;Let’s pick an arbitrary point \(x_0\). The equation of the tangent line to \(f(x)\) at \(x_0\) is given by:
\(L(x) = f(x_0) + f&apos;(x_0)(x - x_0)\)&lt;/p&gt;

&lt;p&gt;Substituting \(f(x_0) = x_0^2\) and \(f&apos;(x_0) = 2x_0\):
\(L(x) = x_0^2 + 2x_0(x - x_0)\)&lt;/p&gt;

&lt;p&gt;The convexity condition requires that for any \(x\):
\(f(x) \geq L(x)\)
\(x^2 \geq x_0^2 + 2x_0(x - x_0)\)&lt;/p&gt;

&lt;p&gt;Let’s simplify the right side:
\(x^2 \geq x_0^2 + 2x_0x - 2x_0^2\)
\(x^2 \geq 2x_0x - x_0^2\)&lt;/p&gt;

&lt;p&gt;Now, move all terms to one side:
\(x^2 - 2x_0x + x_0^2 \geq 0\)&lt;/p&gt;

&lt;p&gt;This expression is a perfect square:
\((x - x_0)^2 \geq 0\)&lt;/p&gt;

&lt;p&gt;This inequality is always true for any real numbers \(x\) and \(x_0\), because the square of any real number is always non-negative. This confirms that \(f(x) = x^2\) satisfies the tangent line condition and is indeed a convex function.&lt;/p&gt;

&lt;h2 id=&quot;second-order-characterization&quot;&gt;Second-order characterization&lt;/h2&gt;
&lt;p&gt;If a function \(f\) is twice differentiable, it has the following property:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If the second derivative \(\nabla^2f(x)\) is positive semidefinite for all \(x \in \text{dom} f\) and \(\text{dom} f\) is convex, then \(f\) is convex, and vice versa.
    &lt;blockquote&gt;
      &lt;p&gt;\(f\) is convex \(\iff \nabla^2f(x) \succeq 0\) for all \(x \in \text{dom} f, \text{dom} f\): convex&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;If the second derivative \(\nabla^2f(x)\) is positive definite for all \(x \in \text{dom} f\), then \(f\) is strictly convex.
    &lt;blockquote&gt;
      &lt;p&gt;if \(\nabla^2f(x) \succ 0\) for all \(x \in \text{dom} f\), then \(f\) is strictly convex&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;In other words, the curvature is always nonnegative.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;jensens-inequality&quot;&gt;Jensen’s inequality&lt;/h2&gt;

&lt;p&gt;Let \(f\) be a convex function and \(w_1, ..., w_n\) be positive weights such that \(\sum_{i=1}^{n} w_i = 1\). Then, the following inequality holds:&lt;/p&gt;

\[\sum_{i=1}^{n} w_i f(x_i) \geq f \left ( \sum_{i=1}^{n} w_i x_i \right )\]

&lt;p&gt;If a function \(f\) is convex, it satisfies the following inequality:&lt;/p&gt;
&lt;blockquote&gt;
\[f(tx_1 + (1 - t)x_2) \le tf(x_1) + (1 - t)f(x_2) \text{ for } 0 \le t \le 1\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Extension&lt;/em&gt;:&lt;br /&gt;
\(X\) is a random variable supported on \(\text{dom } f\), then \(f(E[X]) \le E[f(X)]\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/jensen_inequality.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Jensen&apos;s Inequality [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;isnt-jensens-inequality-exactly-the-definition-of-a-convex-function&quot;&gt;&lt;strong&gt;Isn’t Jensen’s inequality exactly the definition of a convex function?&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;The answer is no—Jensen’s inequality is a consequence and generalization of the convexity definition, not the definition itself.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;This extends the two-point case (\(k=2\)) in the definition to any finite number of points (and can be further generalized to integrals for probability measures).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Why It’s a Generalization:&lt;/strong&gt; The basic definition is for two points (binary convex combination). Jensen applies it iteratively to more points. For instance:
    &lt;ul&gt;
      &lt;li&gt;For \(k=2\), Jensen reduces exactly to the definition.&lt;/li&gt;
      &lt;li&gt;For \(k=3\), you can apply the definition recursively: First combine two points, then with the third.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;short-example&quot;&gt;Short Example&lt;/h3&gt;

&lt;p&gt;Let’s use the convex function \(f(x) = x^2\).
Consider two numbers: \(x_1 = 1\) and \(x_2 = 3\).
We want to compare \(f\left(\frac{x_1+x_2}{2}\right)\) with \(\frac{f(x_1)+f(x_2)}{2}\).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Calculate the function of the average:&lt;/strong&gt;
The average of \(x_1\) and \(x_2\) is \(\frac{1+3}{2} = \frac{4}{2} = 2\).
Applying the function: \(f(2) = 2^2 = 4\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Calculate the average of the function values:&lt;/strong&gt;
\(f(x_1) = f(1) = 1^2 = 1\).
\(f(x_2) = f(3) = 3^2 = 9\).
The average of these function values is \(\frac{1+9}{2} = \frac{10}{2} = 5\).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Comparing the two results: \(4 \le 5\).
This demonstrates Jensen’s inequality: \(f\left(\frac{1+3}{2}\right) \le \frac{f(1)+f(3)}{2}\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-01-02 Examples of convex functions</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_01_02_examples_of_convex_function/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_01_02_examples_of_convex_function</id>
   <content type="html">&lt;p&gt;This section reviews representative examples of convex functions, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Exponential function&lt;/li&gt;
  &lt;li&gt;Power function&lt;/li&gt;
  &lt;li&gt;Affine&lt;/li&gt;
  &lt;li&gt;Quadratic&lt;/li&gt;
  &lt;li&gt;Least squares loss&lt;/li&gt;
  &lt;li&gt;Norm&lt;/li&gt;
  &lt;li&gt;Indicator function&lt;/li&gt;
  &lt;li&gt;Support function&lt;/li&gt;
  &lt;li&gt;Max function&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;univariate-function&quot;&gt;Univariate function&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Exponential function:
For any real number \(a\), \(e^{ax}\) is convex.
    &lt;blockquote&gt;
      &lt;p&gt;\(e^{ax}\) is convex for any \(a \in \mathbb{R}\)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;Power function:
For \(x, a \in \mathbb{R}_{+}\), depending on the range of \(a\), \(x^a\) can be convex or concave.
    &lt;blockquote&gt;
      &lt;p&gt;\(x^{a}\) is convex on \(\mathbb{R}_{+}\) for any \(a \geq 1\) or \(a \leq 0\)
\(x^{a}\) is concave on \(\mathbb{R}_{+}\) for any \(0 \leq a \leq 1\)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;affine-function&quot;&gt;Affine function&lt;/h2&gt;
&lt;p&gt;As covered in &lt;a href=&quot;/contents/en/chapter03/03_01_01_convex_functions_definition/&quot;&gt;03-01-01&lt;/a&gt;, all affine functions are both convex and concave.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On \(\mathbb{R}\) and \(\mathbb{R}^n\):
    &lt;blockquote&gt;
      &lt;p&gt;\(a^Tx + b\) is convex and concave&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;On \(\mathbb{R}^{m \times n}\):
    &lt;blockquote&gt;
      &lt;p&gt;\(\text{tr}(A^TX) + b = \sum_{i=1}^m\sum_{j=1}^n A_{ij}X_{ij} + b\) is convex and concave&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;quadratic-function&quot;&gt;Quadratic function&lt;/h2&gt;
&lt;p&gt;Consider the quadratic function \(f(x)=\frac{1}{2}x^TPx+q^Tx+r\), where \(\nabla f(x)= Px+q\) and \(\nabla^2f(x) = P\). If \(P\) is positive semidefinite, then \(f(x)\) is convex.
For \(P \succeq 0\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x)=\frac{1}{2}x^TPx+q^Tx+r\) is convex with \(P \in \mathbb{S}^n, q \in \mathbb{R}^n, r \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Q: Why is \(f(x)\) convex if \(P\) is positive semidefinite?&lt;/strong&gt;
A: In a quadratic function, the second derivative is the Hessian matrix. The Hessian determines the curvature of the function, and if it is positive semidefinite, the function curves upwards. (That is, the curvature in the direction of the Hessian’s eigenvectors is nonnegative.) Thus, if the second derivative is positive semidefinite, the function is convex.&lt;/p&gt;

&lt;h2 id=&quot;least-squares-loss&quot;&gt;Least squares loss&lt;/h2&gt;
&lt;p&gt;For any matrix \(A\), \(A^TA\) is always positive semidefinite, which means that \(\left \| Ax - b \right \|_{2}^{2}\) is always convex.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f(x) = \| Ax - b \|_{2}^{2}\) is convex for any \(A\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;norm&quot;&gt;Norm&lt;/h2&gt;
&lt;p&gt;All norms on \(\mathbb{R}^n\) are convex.
Let \(f:\mathbb{R}^n \mapsto \mathbb{R}\) be a norm. By definition,&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{aligned}
f(\theta x+(1−\theta)y) \le \theta f(x)+(1−\theta)f(y), \text{  with } \theta \le \theta \le 1, \text{ for all } x,y \in \text{dom} f,
\end{aligned}\)
\(\begin{aligned}
\|x\|_{p} = \left(\sum_{i=1}^{n} x_i^p\right)^{1/p} \text{ for } p \geq 1, \|x\| = \max_{i=1,.., n} |x_i|\\
\end{aligned}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;indicator-function&quot;&gt;Indicator function&lt;/h2&gt;
&lt;p&gt;For a given set \(C\), if the indicator function is defined as infinity (\(\infty\)) for elements not in \(C\) and as zero for elements in \(C\), then the indicator function is convex.&lt;/p&gt;

&lt;p&gt;In other words, by defining the function to be infinitely large outside the set \(C\) and zero within it, the convexity property is preserved.&lt;/p&gt;

&lt;blockquote&gt;
\[I_{C} (x) =
\begin{cases}
0, &amp;amp; x \in C\\
\infty, &amp;amp; x \notin C\\
\end{cases}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;support-function&quot;&gt;Support function&lt;/h2&gt;
&lt;p&gt;Consider a set \(C\). Regardless of whether \(C\) is convex, the support function of \(C\) is convex.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(I_{C}^{*} (x)\) = \(\max_{y\in C} x^Ty\) is convex&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For more on the definition of the support function, refer to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Support_function&quot;&gt;Wikipedia definition&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;max-function&quot;&gt;Max function&lt;/h2&gt;
&lt;p&gt;The max function of a finite collection of convex functions is convex.
In other words, the upper envelope formed by connecting the maxima of a set of convex functions is convex.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(f(x) = \max \{x_1,..., x_n\}\) is convex&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>03-01-01 Definition</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_01_01_convex_functions_definition/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_01_01_convex_functions_definition</id>
   <content type="html">&lt;h2 id=&quot;convex-function&quot;&gt;Convex function&lt;/h2&gt;

&lt;p&gt;A function \(f:\mathbb{R}^n \rightarrow \mathbb{R}\) is convex if its domain is a convex set and for any two points \(x, y \in \text{dom}f\), the function satisfies:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f(\theta x+(1-\theta)y) \le \theta f(x)+(1-\theta)f(y)\),&lt;/p&gt;

  &lt;p&gt;with \(0 \le \theta \le 1\), for all \(x,y \in \text{dom} f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This means that for any two points \(x, y\), the value of \(f\) at their convex combination is less than or equal to the convex combination of their function values. Geometrically, the graph of \(f\) lies below the line segment connecting \(f(x)\) and \(f(y)\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter03/convex_function2.png&quot; alt=&quot;&quot; width=&quot;70%&quot; height=&quot;70%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Convex Function [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;strictly-convex&quot;&gt;Strictly convex&lt;/h2&gt;
&lt;p&gt;A function \(f:\mathbb{R}^n \rightarrow \mathbb{R}\) is strictly convex if for any two distinct points \(x, y \in \text{dom}f\) and \(0 &amp;lt; \theta &amp;lt; 1\):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f(\theta x+(1-\theta)y)&amp;lt;\theta f(x)+(1-\theta)f(y)\),&lt;/p&gt;

  &lt;p&gt;with \(0&amp;lt;\theta&amp;lt;1\), \(x \neq y\), for all \(x, y \in \text{dom}f\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;strongly-convex&quot;&gt;Strongly convex&lt;/h2&gt;
&lt;p&gt;A function \(f\) is strongly convex if \(f - \frac{m}{2}\| x \|_{2}^{2}\), with \(m &amp;gt; 0\), is convex.&lt;/p&gt;

&lt;h3 id=&quot;note-strongly-convex--strictly-convex--convex&quot;&gt;[Note] strongly convex ⇒ strictly convex ⇒ convex&lt;/h3&gt;

&lt;h2 id=&quot;concave-function&quot;&gt;Concave function&lt;/h2&gt;
&lt;p&gt;A function \(f\) is concave if \(-f\) is convex.&lt;/p&gt;

&lt;p&gt;All affine functions \(f(x) = a^T x+b\) satisfy:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\begin{aligned}
f(\theta x+(1-\theta)y) &amp;amp;= a^T (\theta x+(1-\theta)y) +b \\
&amp;amp;= \theta a^T x + (1-\theta) a^T y + \theta b + (1-\theta) b \\
&amp;amp;= \theta f(x)+(1-\theta)f(y) \\
\end{aligned}\)
\(\text{for all } x,y \in \text{dom} f, \text{with } \theta \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That is, affine functions are always convex, and simultaneously concave.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-01 Basic properties and examples</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_01_00_Basic_properties_and_examples/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_01_00_Basic_properties_and_examples</id>
   <content type="html">&lt;p&gt;This section covers the definition of convex functions, representative types of convex functions, and their key properties.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03 Convex functions</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_00_Convex_functions/"/>
   <updated>2021-02-12T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter03/03_00_Convex_functions</id>
   <content type="html">&lt;p&gt;In this chapter, we will study the definition, examples, key properties of convex functions, and operations that preserve convexity.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02 Tập Lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_Convex_sets/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_Convex_sets</id>
   <content type="html">&lt;p&gt;Trong chương này, chúng ta sẽ nghiên cứu khái niệm về tập lồi, tạo nền tảng cho tối ưu hóa lồi.&lt;/p&gt;

&lt;h3 id=&quot;bối-cảnh&quot;&gt;Bối cảnh&lt;/h3&gt;
&lt;p&gt;Tối ưu hóa lồi đề cập đến các kỹ thuật tìm cực đại hoặc cực tiểu bằng cách định nghĩa các bài toán sử dụng hàm lồi.
Tập lồi có liên quan chặt chẽ với hàm lồi theo hai cách chính:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hàm lồi được định nghĩa trên tập lồi. Miền xác định và miền giá trị của một hàm được định nghĩa như các tập lồi, và các tính chất chính của hàm lồi được xác định bởi những tập hợp này.&lt;/li&gt;
  &lt;li&gt;Nếu bạn có thể biến đổi một bài toán tối ưu hóa thành bài toán liên quan đến hàm lồi, nó sẽ trở nên dễ giải hơn. Đôi khi, khó xác định liệu một bài toán có được định nghĩa bởi hàm lồi hay không. Trong những trường hợp như vậy, bạn có thể kiểm tra xem epigraph của hàm có phải là tập lồi hay không để xác định hàm có lồi không.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nội-dung&quot;&gt;Nội dung&lt;/h3&gt;
&lt;p&gt;Trong chương này, chúng ta sẽ đề cập đến định nghĩa và ví dụ về tập lồi, các tính chất chính của chúng, và các phép toán bảo toàn tính lồi.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-06 Hình nón đối ngẫu và bất đẳng thức tổng quát</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_06_Dual_cones_and_generalized_inequalities/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_06_Dual_cones_and_generalized_inequalities</id>
   <content type="html">&lt;p&gt;Phần này thảo luận về hình nón đối ngẫu được ghép đôi với hình nón, và bất đẳng thức tổng quát đối ngẫu. Sử dụng bất đẳng thức tổng quát đối ngẫu cho phép so sánh bằng cách sử dụng tích vô hướng, làm cho việc so sánh trở nên dễ dàng hơn nhiều.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-06-02 Bất đẳng thức tổng quát đối ngẫu</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_06_02_Dual_generalized_inequalities/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_06_02_Dual_generalized_inequalities</id>
   <content type="html">&lt;p&gt;Nếu chúng ta có thể định nghĩa một bất đẳng thức tổng quát sử dụng một hình nón thích hợp, chúng ta cũng có thể định nghĩa một bất đẳng thức tổng quát đối ngẫu sử dụng hình nón đối ngẫu, với điều kiện hình nón đối ngẫu là thích hợp.&lt;/p&gt;

&lt;p&gt;Phần này định nghĩa bất đẳng thức tổng quát đối ngẫu sử dụng một hình nón đối ngẫu thích hợp và định nghĩa lại các phần tử tối tiểu và cực tiểu sử dụng bất đẳng thức đối ngẫu.&lt;/p&gt;

&lt;h2 id=&quot;bất-đẳng-thức-tổng-quát-đối-ngẫu&quot;&gt;Bất đẳng thức tổng quát đối ngẫu&lt;/h2&gt;

&lt;p&gt;Cho một hình nón đối ngẫu thích hợp, bất đẳng thức tổng quát được định nghĩa như sau. Với một điểm \(y\), nếu tích vô hướng với mọi \(x\) trong \(K\) đều không âm, thì \(y\) là không âm trong hình nón đối ngẫu \(K^*\).&lt;/p&gt;

&lt;p&gt;Ở đây, \(\succeq_{K^*}\) được gọi là &lt;strong&gt;đối ngẫu&lt;/strong&gt; của \(\succeq_K\), tức là &lt;strong&gt;bất đẳng thức tổng quát đối ngẫu&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(y \succeq_{K^*} 0 \iff y^T x \ge 0\) với mọi \(x \succeq_K 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;tính-chất-chính-của-bất-đẳng-thức-tổng-quát-và-đối-ngẫu&quot;&gt;Tính chất chính của bất đẳng thức tổng quát và đối ngẫu&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\(x \preceq_K y\) khi và chỉ khi \(\lambda^T x \le \lambda^T y\) với mọi \(\lambda \succeq_{K^*} 0\).&lt;/li&gt;
  &lt;li&gt;\(x \prec_K y\) khi và chỉ khi \(\lambda^T x &amp;lt; \lambda^T y\) với mọi \(\lambda \succeq_{K^*} 0, \lambda \ne 0\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nếu \(K = K^{**}\), bất đẳng thức tổng quát đối ngẫu liên kết với \(\preceq_K^*\) là \(\preceq_K\), vậy các tính chất này được bảo toàn ngay cả khi vai trò của bất đẳng thức tổng quát và đối ngẫu được hoán đổi.&lt;/p&gt;

&lt;p&gt;Ví dụ, \(\lambda \preceq_K^* \mu\) khi và chỉ khi \(\lambda^T x \le \mu^T x\) với mọi \(x \succeq_K 0\).&lt;/p&gt;

&lt;h2 id=&quot;phần-tử-tối-tiểu-và-cực-tiểu-thông-qua-bất-đẳng-thức-đối-ngẫu&quot;&gt;Phần tử tối tiểu và cực tiểu thông qua bất đẳng thức đối ngẫu&lt;/h2&gt;

&lt;p&gt;Với một bất đẳng thức tổng quát được cảm sinh bởi một hình nón thích hợp \(K\), chúng ta có thể sử dụng bất đẳng thức tổng quát đối ngẫu để đặc trưng cho các phần tử tối tiểu và cực tiểu của một tập (có thể không lồi) \(S \subseteq \mathbb{R}^m\).&lt;/p&gt;

&lt;h3 id=&quot;phần-tử-tối-tiểu&quot;&gt;Phần tử tối tiểu&lt;/h3&gt;

&lt;p&gt;Với mọi \(\lambda \succ_K^* 0\) và \(z \in S\),&lt;/p&gt;

&lt;p&gt;Nếu \(x\) là bộ tối ưu hóa duy nhất của \(\lambda^T z\), thì đối với bất đẳng thức tổng quát \(\succ_K^*\), \(x\) là tối tiểu của \(S\). (Bộ tối ưu hóa là một giá trị của biến phụ thuộc làm tối thiểu hóa một hàm; ở đây, hàm là \(\lambda^T z\), biến là \(z\), và bộ tối ưu hóa là \(x\).)&lt;/p&gt;

&lt;p&gt;Về mặt hình học, điều này có nghĩa là với một số \(\lambda \succ_K^* 0\), siêu phẳng \(\{ z \mid  \lambda^T (z-x) = 0 \}\) là một siêu phẳng hỗ trợ nghiêm ngặt cho \(S\) tại \(x\). (Siêu phẳng hỗ trợ nghiêm ngặt có nghĩa là siêu phẳng giao với \(S\) chỉ tại \(x\).) \(S\) không cần phải lồi. Hình dưới đây cho thấy một tối tiểu \(x\) và một siêu phẳng hỗ trợ nghiêm ngặt.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_02_Minimum_element.png&quot; alt=&quot;[Hình1] Phần tử tối tiểu [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] Phần tử tối tiểu [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;phần-tử-cực-tiểu&quot;&gt;Phần tử cực tiểu&lt;/h3&gt;

&lt;p&gt;Các điều kiện cần và đủ cho phần tử cực tiểu hơi khác một chút.&lt;/p&gt;

&lt;p&gt;Với \(\lambda \succ_K^* 0\) và \(z \in S\), nếu \(x\) là bộ tối ưu hóa của \(\lambda^T z\), thì \(x \in S\) là cực tiểu. Nói cách khác, nếu \(x\) là cực tiểu, thì \(\lambda^T z\) không có bộ tối ưu hóa duy nhất. Do đó, với cùng một \(\lambda\), có thể có nhiều phần tử cực tiểu, và có thể có nhiều phần tử cực tiểu cho các \(\lambda\) khác nhau.&lt;/p&gt;

&lt;p&gt;Hình dưới đây minh họa sự tồn tại của nhiều phần tử cực tiểu. Vùng có đường màu đen dày ở phía dưới bên trái chỉ ra khu vực mà các phần tử cực tiểu tồn tại.
Ở đây, \(x_1\) là bộ tối ưu hóa của \(\lambda^T_1 z\) và vì \(\lambda_1 \succ_K^* 0\), nó là cực tiểu. Một bộ tối ưu hóa khác, \(x_2\), cũng tồn tại.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_05_Minimal_element.png&quot; alt=&quot;[Hình2] Phần tử cực tiểu [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình2] Phần tử cực tiểu [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Tuy nhiên, điều ngược lại không đúng. Ngay cả khi một điểm \(x\) là cực tiểu trong một tập \(S\), nó có thể không phải là bộ tối ưu hóa của \(\lambda^T z\) với một số \(\lambda\) và \(z \in S\). Hình dưới đây cho thấy một ví dụ về phần tử cực tiểu không phải là bộ tối ưu hóa. Ở đây, tính lồi của tập hợp dường như đóng vai trò quan trọng trong việc điều ngược lại này không đúng.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_06_Minimal_element2.png&quot; alt=&quot;[Hình3] Một ví dụ về phần tử cực tiểu không phải là bộ tối ưu hóa [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình3] Một ví dụ về phần tử cực tiểu không phải là bộ tối ưu hóa [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Định lý ngược lại này không được tăng cường với \(\lambda_1 \succ_K^* 0\). Trong hình bên trái dưới đây, \(x_1 \in S_1\) là cực tiểu, nhưng không phải là bộ tối ưu hóa của \(\lambda_1^T x_1\). Hình bên phải cho thấy \(x_2 \in S_2\) không phải là cực tiểu, nhưng là bộ tối ưu hóa của \(\lambda_2^T x_2\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_07_Minimal_element3.png&quot; alt=&quot;[Hình4] Các ví dụ mà điều ngược lại không được tăng cường với $$\lambda_1 \succ_K^* 0$$ [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Hình4] Các ví dụ mà điều ngược lại không được tăng cường với } \lambda_1 \succ_K^* 0 \text{ [1]}$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;biên-sản-xuất-tối-ưu&quot;&gt;Biên sản xuất tối ưu&lt;/h3&gt;
&lt;p&gt;Xét một sản phẩm cần được sản xuất sử dụng n tài nguyên (lao động, điện, khí tự nhiên, nước, v.v.).
Sản phẩm này có thể được sản xuất theo nhiều cách. Với mỗi phương pháp sản xuất, có một vector tài nguyên \(x \in \mathbb{R}\), trong đó \(x_i\) biểu thị lượng tài nguyên \(i\) được tiêu thụ. Giả định rằng tiêu thụ tài nguyên \(x_i\) không âm, và các tài nguyên có giá trị cao.&lt;/p&gt;

&lt;p&gt;Tập sản xuất \(P \subseteq \mathbb{R}^n\) được định nghĩa là tập hợp tất cả các vector tài nguyên \(x\). Một phương pháp sản xuất với vector tài nguyên cực tiểu được gọi là &lt;strong&gt;tối ưu Pareto&lt;/strong&gt; hoặc &lt;strong&gt;hiệu quả&lt;/strong&gt;. Tập hợp các phần tử cực tiểu của \(P\) được gọi là &lt;strong&gt;biên sản xuất hiệu quả&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Hãy xem xét ngắn gọn về tính tối ưu Pareto.&lt;/p&gt;

&lt;p&gt;Giả sử có hai phương pháp sản xuất, một với vector tài nguyên \(x\) (\(P_x\)) và một với vector tài nguyên \(y\) (\(P_y\)). Nếu với mọi \(i\), \(x_i \le y_i\), và với một số \(i\), \(x_i \lt y_i\), thì chúng ta có thể nói rằng \(P_x\) tốt hơn \(P_y\). Nói cách khác, một phương pháp không sử dụng nhiều tài nguyên hơn phương pháp khác, hoặc sử dụng ít nhất một tài nguyên ít hơn, được coi là tốt hơn. Tức là, điều này tương ứng với trường hợp \(x \preceq y\) và \(x \ne y\).
Nếu không có phương pháp nào tốt hơn \(P_x\), thì \(P_x\) được gọi là tối ưu Pareto.&lt;/p&gt;

&lt;p&gt;Bằng cách tối thiểu hóa biểu thức sau, chúng ta có thể tìm phương pháp sản xuất tối ưu Pareto. Ở đây, \(\lambda_i\) có thể được coi như giá của tài nguyên \(i\). Tối thiểu hóa \(\lambda^T x\) đối với \(P\) cho ra phương pháp sản xuất rẻ nhất. Vì các giá cả đều dương, kết quả của việc tối thiểu hóa luôn là tối ưu Pareto.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\lambda^T x =\) \(\lambda^T_1 x_1 + \lambda^T_2 x_2 + ... + \lambda^T_n x_n, \lambda \succ 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hình dưới đây minh họa tình huống này một cách rõ ràng. Trong hình, \(x_1, x_2, x_3\) là tối ưu Pareto, trong khi \(x_4, x_5\) thì không.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_08_Pareto_optimal.png&quot; alt=&quot;[Hình5] Biên sản xuất tối ưu [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình5] Biên sản xuất tối ưu [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>02-06-01 Hình nón đối ngẫu</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_06_01_Dual_cones/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_06_01_Dual_cones</id>
   <content type="html">&lt;h2 id=&quot;hình-nón-đối-ngẫu&quot;&gt;Hình nón đối ngẫu&lt;/h2&gt;

&lt;p&gt;Hình nón đối ngẫu được định nghĩa như một cặp với một hình nón, ký hiệu là \(K\) cho hình nón và \(K^*\) cho hình nón đối ngẫu. Hình nón đối ngẫu luôn lồi, bất kể \(K\) có lồi hay không. Hình nón đối ngẫu được định nghĩa là tập hợp các điểm \(y\) sao cho tích vô hướng với bất kỳ \(x\) nào trong \(K\) đều không âm:&lt;/p&gt;

&lt;blockquote&gt;
\[K^* = \{y \mid x^T y \ge 0 \text{ với mọi } x \in K\}\]
&lt;/blockquote&gt;

&lt;p&gt;Với \(x\) và \(y\), tích vô hướng không âm có nghĩa là góc giữa các vector nằm trong phạm vi mà \(\cos\theta \ge 0\), tức là \(0 \le \theta \le 90\) và \(270 \le \theta \le 360\). Do đó, biên của hình nón đối ngẫu được hình thành theo hướng của vector pháp tuyến âm của siêu phẳng hỗ trợ của hình nón. Hình dưới đây cho thấy vùng mà hình nón đối ngẫu được định nghĩa. Tóm lại, vùng của hình nón đối ngẫu là tập hợp tất cả các hướng của vector pháp tuyến âm của các siêu phẳng hỗ trợ của hình nón tại gốc tọa độ.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_01_2_dual_cone.png&quot; alt=&quot;[Hình1] Vùng định nghĩa hình nón đối ngẫu&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] Vùng định nghĩa hình nón đối ngẫu&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Về mặt hình học, nếu \(y \in K^*\), thì \(-y\) là pháp tuyến của siêu phẳng hỗ trợ của \(K\) tại gốc tọa độ. Hình tiếp theo cho thấy ở bên trái, nửa không gian với pháp tuyến hướng vào trong \(y\) chứa hình nón \(K\), vậy \(y \in K^*\). Ở bên phải, nửa không gian với pháp tuyến hướng vào trong \(z\) không chứa \(K\), vậy \(y \notin K^*\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_01_dual_cone.png&quot; alt=&quot;[Hình2] Hình nón đối ngẫu và pháp tuyến siêu phẳng hỗ trợ [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình2] Hình nón đối ngẫu và pháp tuyến siêu phẳng hỗ trợ [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;ví-dụ-về-hình-nón-đối-ngẫu&quot;&gt;Ví dụ về hình nón đối ngẫu&lt;/h2&gt;

&lt;p&gt;Dưới đây là một số ví dụ về hình nón và đối ngẫu của chúng. Ba ví dụ đầu tiên là &lt;strong&gt;tự đối ngẫu&lt;/strong&gt;, có nghĩa là hình nón và đối ngẫu của nó giống nhau. Ví dụ cuối cùng cho thấy rằng đối ngẫu của hình nón \(l_\infty\) là hình nón \(l_1\), và ngược lại.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$K = \mathbb{R}^n_+, K^* = \mathbb{R}^n_+$&lt;/li&gt;
  &lt;li&gt;$K = S^n_+, K^* = S^n_+$&lt;/li&gt;
  &lt;li&gt;$K = {(x, t) \mid  |x|_2 \le t }, K^* = {(x, t)\mid  |x|_2 \le t }$&lt;/li&gt;
  &lt;li&gt;$K = {(x, t) \mid  | x |&lt;em&gt;1 \le t }, K^* = {(x, t) \mid  | x |&lt;/em&gt;{\infty} \le t }$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hình-nón-l_2-là-tự-đối-ngẫu&quot;&gt;Hình nón \(l_2\) là tự đối ngẫu&lt;/h3&gt;

&lt;p&gt;Hình dưới đây cho thấy rằng hình nón \(l_2\) là tự đối ngẫu. Tức là, với \(x \in K\) trên biên, pháp tuyến \(-y\) của siêu phẳng hỗ trợ tại \(x\) khớp với biên của \(K\), và \(y\) là biên của hình nón đối ngẫu \(K^*\), vậy \(K\) và \(K^*\) trùng nhau.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_03_L2_self-dual.png&quot; alt=&quot;[Hình3] Hình nón $$l_2$$ và hình nón đối ngẫu&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Hình3] Hình nón } l_2 \text{ và hình nón đối ngẫu}$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;hình-nón-đối-ngẫu-của-hình-nón-l_infty-là-hình-nón-l_1&quot;&gt;Hình nón đối ngẫu của hình nón \(l_\infty\) là hình nón \(l_1\)&lt;/h3&gt;

&lt;p&gt;Hình dưới đây cho thấy rằng hình nón đối ngẫu của hình nón \(l_\infty\) là hình nón \(l_1\). Tức là, khi \(x \in K\) là một điểm biên, pháp tuyến \(-y\) của siêu phẳng hỗ trợ tại \(x\) đi vào phần trong của \(K\) và trùng với biên của hình nón \(l_1\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_04_L_inf_dual_norm.png&quot; alt=&quot;[Hình4] Hình nón $$l_\infty$$ và hình nón đối ngẫu&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Hình4] Hình nón } l_\infty \text{ và hình nón đối ngẫu}$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>02-05 Siêu phẳng phân tách và hỗ trợ</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_05_Separating_and_supporting_hyperplanes/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_05_Separating_and_supporting_hyperplanes</id>
   <content type="html">&lt;p&gt;Phần này giới thiệu hai định lý đặc trưng cho tập lồi: &lt;strong&gt;định lý siêu phẳng phân tách&lt;/strong&gt; và &lt;strong&gt;định lý siêu phẳng hỗ trợ&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;định-lý-siêu-phẳng-phân-tách&quot;&gt;Định lý siêu phẳng phân tách&lt;/h2&gt;

&lt;p&gt;Giả sử có một số tập lồi rời rạc không có giao điểm. Làm thế nào chúng ta có thể phân tách chúng? Cách đơn giản nhất là vẽ một đường thẳng giữa các tập hợp. Phương pháp này được sử dụng rộng rãi trong phân loại và được hỗ trợ bởi &lt;strong&gt;định lý siêu phẳng phân tách&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Nếu có hai tập lồi rời rạc \(C\) và \(D\), thì với \(x \in C\), \(a^T x \le b\) và với \(x \in D\), \(a^T x \ge b\) với một số \(a \ne 0\) và \(b\). Nói cách khác, hàm affine \(a^T x - b\) không dương trên \(C\) và không âm trên \(D\). Siêu phẳng \(\{ x \mid a^T x = b\}\) được gọi là &lt;strong&gt;siêu phẳng phân tách&lt;/strong&gt; cho \(C\) và \(D\).&lt;/p&gt;

&lt;p&gt;Hình dưới đây cho thấy một siêu phẳng phân tách chia hai tập lồi rời rạc \(C\) và \(D\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.05_01_Seperating_hyperplan_theorem.png&quot; alt=&quot;[Hình1] Định lý siêu phẳng phân tách [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] Định lý siêu phẳng phân tách [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Điều ngược lại của định lý siêu phẳng phân tách không đúng. Tức là, sự tồn tại của một siêu phẳng phân tách không đảm bảo rằng các tập hợp là rời rạc. Ví dụ, nếu \(C = D = \{0\} \subseteq \mathbb{R}\), thì \(x = 0\) phân tách \(C\) và \(D\).&lt;/p&gt;

&lt;h3 id=&quot;phân-tách-nghiêm-ngặt&quot;&gt;Phân tách nghiêm ngặt&lt;/h3&gt;

&lt;p&gt;Nếu siêu phẳng phân tách thỏa mãn điều kiện mạnh hơn \(x \in C\) suy ra \(a^T x &amp;lt; b\) và \(x \in D\) suy ra \(a^T x &amp;gt; b\), điều này được gọi là &lt;strong&gt;phân tách nghiêm ngặt&lt;/strong&gt;. Các tập lồi đóng rời rạc không phải lúc nào cũng yêu cầu phân tách nghiêm ngặt, nhưng trong nhiều trường hợp, điều kiện này được thỏa mãn.&lt;/p&gt;

&lt;h2 id=&quot;định-lý-siêu-phẳng-hỗ-trợ&quot;&gt;Định lý siêu phẳng hỗ trợ&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Định lý siêu phẳng hỗ trợ&lt;/strong&gt; phát biểu rằng với bất kỳ tập lồi không rỗng \(C\) và bất kỳ điểm \(x_0\) nào trên biên &lt;strong&gt;bd&lt;/strong&gt; \(C\), tồn tại một siêu phẳng hỗ trợ tại \(x_0\).&lt;/p&gt;

&lt;p&gt;Siêu phẳng hỗ trợ là gì? Giả sử \(x_0\) là một điểm biên của \(C\). Nếu với mọi \(x \in C\), \(a^T x \le a^T x_0\) (\(a \ne 0\)), thì siêu phẳng \(\{x \mid a^T x = a^T x_0 \}\) là &lt;strong&gt;siêu phẳng hỗ trợ&lt;/strong&gt; cho \(C\) tại \(x_0\).&lt;/p&gt;

&lt;p&gt;[Lưu ý] Biên được định nghĩa là \(x_0 \in\) &lt;strong&gt;bd&lt;/strong&gt; \(C =\) &lt;strong&gt;cl&lt;/strong&gt; \(C\) \(\setminus\) &lt;strong&gt;int&lt;/strong&gt; \(C\), tức là bao đóng trừ đi phần trong.&lt;/p&gt;

&lt;p&gt;Về mặt hình học, siêu phẳng hỗ trợ \(\{x \mid a^T x = a^T x_0\}\) tiếp xúc với \(C\) tại \(x_0\) và nửa không gian \(a^T x \le a^T x_0\) chứa \(C\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.05_02_Supporting_hyperplane_theorem.png&quot; alt=&quot;[Hình 2] Siêu phẳng hỗ trợ [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 2] Siêu phẳng hỗ trợ [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>02-04 Bất đẳng thức tổng quát</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_04_Generalized_inequalities/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_04_Generalized_inequalities</id>
   <content type="html">&lt;p&gt;Trong không gian thực một chiều \(\mathbb{R}\), cho hai số 1 và 2, chúng ta có thể nói 2 lớn hơn 1. Nhưng trong không gian thực \(n\) chiều \(\mathbb{R}^n\), cho hai điểm \(x_1\) và \(x_2\), liệu chúng ta có thể nói điểm nào lớn hơn? Điều này không đơn giản.&lt;/p&gt;

&lt;p&gt;Phần này giới thiệu &lt;strong&gt;bất đẳng thức tổng quát&lt;/strong&gt; để so sánh thứ tự giữa hai điểm trong \(\mathbb{R}^n\), và cũng thảo luận về các khái niệm phần tử cực tiểu và tối tiểu của một tập hợp.&lt;/p&gt;

&lt;h2 id=&quot;hình-nón-thích-hợp&quot;&gt;Hình nón thích hợp&lt;/h2&gt;

&lt;p&gt;Một hình nón lồi \(K \subseteq \mathbb{R}^n\) được gọi là &lt;strong&gt;hình nón thích hợp&lt;/strong&gt; nếu nó thỏa mãn:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;K là đóng (bao gồm biên của nó).&lt;/li&gt;
  &lt;li&gt;K là rắn (phần trong của nó không rỗng).&lt;/li&gt;
  &lt;li&gt;K là nhọn (không chứa bất kỳ đường thẳng nào) (tức là \(x \in K, -x \in K \implies x = 0\)).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nếu một hình nón lồi nhọn &amp;amp; đóng được định nghĩa trong một không gian con có chiều \(n-1\) hoặc ít hơn, phần trong của nó sẽ rỗng, vì nó không thể chứa một hình cầu mở trong \(n\) chiều. Do đó, nó không rắn và không thể là hình nón thích hợp. Ví dụ, một hình nón lồi nhọn &amp;amp; đóng hình quạt 2D trong \(\mathbb{R}^3\) không phải là hình nón thích hợp.&lt;/p&gt;

&lt;p&gt;Xem &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Interior_(topology)&quot;&gt;Wikipedia: Interior (topology)&lt;/a&gt;&lt;/em&gt; để biết định nghĩa về phần trong.&lt;/p&gt;

&lt;h2 id=&quot;bất-đẳng-thức-tổng-quát&quot;&gt;Bất đẳng thức tổng quát&lt;/h2&gt;

&lt;p&gt;Sử dụng một hình nón thích hợp, chúng ta có thể định nghĩa một thứ tự từng phần trong \(\mathbb{R}^n\) được gọi là &lt;strong&gt;bất đẳng thức tổng quát&lt;/strong&gt;. Nó có các tính chất tương tự như thứ tự tiêu chuẩn trong \(\mathbb{R}\):&lt;/p&gt;

&lt;blockquote&gt;
\[x \preceq_{K} y \iff y − x \in K\]
&lt;/blockquote&gt;

&lt;p&gt;Tương tự, thứ tự từng phần nghiêm ngặt được định nghĩa như:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x \prec_{K} y \iff y − x \in\) &lt;strong&gt;int&lt;/strong&gt; \(K\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nếu \(K = \mathbb{R}_{+}\), thì \(\preceq_{K}\) là \(\le\) thông thường trong \(\mathbb{R}\).&lt;/p&gt;

&lt;h3 id=&quot;tính-chất-của-bất-đẳng-thức-tổng-quát&quot;&gt;Tính chất của bất đẳng thức tổng quát&lt;/h3&gt;

&lt;p&gt;Bất đẳng thức tổng quát \(\preceq_{K}\) thỏa mãn:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Bảo toàn dưới phép cộng&lt;/strong&gt;: nếu \(x \preceq_{K} y\) và \(u \preceq_{K} v\), thì \(x+u \preceq_{K} y +v\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bắc cầu&lt;/strong&gt;: nếu \(x \preceq_{K} y\) và \(y \preceq_{K} z\) thì \(x \preceq_{K}  z\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bảo toàn dưới co giãn không âm&lt;/strong&gt;: nếu \(x \preceq_{K} y\) và \(α \ge 0\) thì \(αx \preceq_{K} αy\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phản xạ&lt;/strong&gt;: \(x \preceq_{K} x\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phản đối xứng&lt;/strong&gt;: nếu \(x \preceq_{K} y\) và \(y \preceq_{K} x\), thì \(x = y\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bảo toàn dưới giới hạn&lt;/strong&gt;: nếu \(x_i \preceq_{K}  y_i\) với \(i = 1, 2, ..., x_i \to x\) và \(y_i \to y\) khi \(i \to ∞\), thì \(x \preceq_{K} y\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bất đẳng thức tổng quát nghiêm ngặt có các tính chất tương ứng.&lt;/p&gt;

&lt;h2 id=&quot;phần-tử-tối-tiểu-và-cực-tiểu&quot;&gt;Phần tử tối tiểu và cực tiểu&lt;/h2&gt;

&lt;p&gt;Sự khác biệt quan trọng nhất giữa thứ tự trong \(\mathbb{R}\) và thứ tự tổng quát trong \(\mathbb{R}^n\) là &lt;strong&gt;thứ tự tuyến tính&lt;/strong&gt;. Trong \(\mathbb{R}\), chúng ta có thể so sánh bất kỳ hai điểm nào với \(x \lt y\) hoặc \(x \gt y\), nhưng bất đẳng thức tổng quát không thể luôn làm điều này. Do đó, việc định nghĩa các khái niệm cực đại và cực tiểu trong bối cảnh bất đẳng thức tổng quát được dự kiến sẽ phức tạp hơn nhiều.&lt;/p&gt;

&lt;h3 id=&quot;phần-tử-tối-tiểu&quot;&gt;Phần tử tối tiểu&lt;/h3&gt;

&lt;p&gt;Nếu \(x \in S\) thỏa mãn \(x \preceq_{K} y\) với mọi \(y \in S\), thì \(x\) là phần tử &lt;strong&gt;tối tiểu&lt;/strong&gt; của tập \(S\). Tương tự, &lt;strong&gt;tối đại&lt;/strong&gt; có thể được định nghĩa theo cách tương tự. Nếu một tối tiểu tồn tại trong một tập hợp, nó là duy nhất. Tức là, chỉ tồn tại một tối tiểu.&lt;/p&gt;

&lt;p&gt;Nếu một điểm \(x \in S\) là tối tiểu của \(S\), thì \(S \subseteq x + K\). Ở đây, \(x + K\) có nghĩa là (theo \(\preceq_{K}\)) tất cả các điểm đều có thể so sánh với \(x\) và lớn hơn hoặc bằng \(x\).&lt;/p&gt;

&lt;h3 id=&quot;phần-tử-cực-tiểu&quot;&gt;Phần tử cực tiểu&lt;/h3&gt;

&lt;p&gt;Một khái niệm tương tự là &lt;strong&gt;cực tiểu&lt;/strong&gt;. Nếu \(x \in S\) và với mọi \(y \in S\), điều kiện \(y \preceq_{K} x\) chỉ đúng khi \(y=x\), thì \(x\) là phần tử &lt;strong&gt;cực tiểu&lt;/strong&gt; của tập \(S\). Tương tự, &lt;strong&gt;cực đại&lt;/strong&gt; có thể được định nghĩa theo cách tương tự. Một tập hợp có thể có nhiều phần tử cực tiểu.&lt;/p&gt;

&lt;p&gt;Nếu một điểm \(x \in S\) là cực tiểu trong \(S\), thì \((x - K) \cap S = \{x\}\). Ở đây, \(x - K\) có nghĩa là (theo \(\preceq_{K}\)) tất cả các điểm đều có thể so sánh với \(x\) và nhỏ hơn hoặc bằng \(x\).&lt;/p&gt;

&lt;p&gt;Trong trường hợp \(K = \mathbb{R}_{+}\), cực tiểu và tối tiểu là giống nhau và tương ứng với định nghĩa chung của tối tiểu.&lt;/p&gt;

&lt;h3 id=&quot;tối-tiểu-và-cực-tiểu-trong-hình-nón-mathbbr2_&quot;&gt;Tối tiểu và cực tiểu trong hình nón \(\mathbb{R}^2_{+}\)&lt;/h3&gt;

&lt;p&gt;Xét hình nón \(\mathbb{R}^2_{+}\) \(K\). Bất đẳng thức \(x \preceq_{K} y\) có nghĩa là \(y\) nằm ở phía trên bên phải của \(x\). Khi \(x \in S\), nói rằng \(x\) là tối tiểu có nghĩa là tất cả các điểm trong \(S\) đều nằm ở phía trên bên phải của \(x\). Nói rằng \(x\) là cực tiểu có nghĩa là không có điểm nào trong \(S\) nằm ở phía dưới bên trái của \(x\).&lt;/p&gt;

&lt;p&gt;Trong hình dưới đây, \(S_1\) có một tối tiểu \(x_1\). Tập \(x + K\) được hiển thị bằng màu xám nhạt, và vì \(S_1 \subseteq x + K\), \(x_1\) là tối tiểu. \(S_2\) có một phần tử cực tiểu \(x_2\). Tập \(x - K\) được hiển thị bằng màu xám nhạt, và vì \((x - K) \cap S = \{x\}\), \(x_2\) là cực tiểu.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_01_Minimum_and_minimal.png&quot; alt=&quot;[Hình1] Phần tử tối tiểu và cực tiểu [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] Phần tử tối tiểu và cực tiểu [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>02-03 Các phép toán bảo toàn tính lồi của tập lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_03_Operations_that_preserve_convexity/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_03_Operations_that_preserve_convexity</id>
   <content type="html">&lt;p&gt;Phần này thảo luận về các phép toán bảo toàn tính lồi của tập lồi. Những phép toán này hữu ích để xác định tính lồi hoặc xây dựng các tập lồi mong muốn từ những tập đơn giản như siêu phẳng, nửa không gian và hình cầu chuẩn.&lt;/p&gt;

&lt;p&gt;Các phép toán bảo toàn tính lồi bao gồm:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Giao&lt;/li&gt;
  &lt;li&gt;Hàm affine&lt;/li&gt;
  &lt;li&gt;Hàm phối cảnh&lt;/li&gt;
  &lt;li&gt;Hàm tuyến tính-phân thức&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;giao&quot;&gt;Giao&lt;/h2&gt;

&lt;p&gt;Giao của các tập lồi là lồi. Tức là, nếu \(S_1\) và \(S_2\) là lồi, thì \(S_1 \cap S_2\) là lồi. Tính chất này đúng ngay cả với vô số tập hợp. (Không gian con, tập affine và hình nón lồi cũng đóng kín dưới phép giao.)&lt;/p&gt;

&lt;p&gt;Tính lồi có thể được biểu diễn như giao của vô số nửa không gian, và điều ngược lại cũng đúng. Tức là, một tập lồi đóng \(S\) có thể được định nghĩa như giao của tất cả các nửa không gian chứa \(S\):&lt;/p&gt;

&lt;blockquote&gt;
\[S = \bigcap \{\mathcal{H} \mid \mathcal{H} \text{ là nửa không gian }, S \subseteq \mathcal{H}\}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;hàm-affine&quot;&gt;Hàm affine&lt;/h2&gt;

&lt;p&gt;Cho \(A \in \mathbb{R}^{m \times n}\) và \(b \in \mathbb{R}^{m}\). Hàm \(f : \mathbb{R}^n \to \mathbb{R}^m\) được định nghĩa bởi \(f(x) = Ax + b\) được gọi là hàm affine.&lt;/p&gt;

&lt;p&gt;Nếu \(C \subseteq \mathbb{R}^n\) là lồi và \(D \subseteq \mathbb{R}^m\) là lồi, thì:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ảnh affine \(f(C) = \{f(x) \mid x \in C\}\) là lồi.&lt;/li&gt;
  &lt;li&gt;Nghịch ảnh affine \(f^{-1}(D) = \{x \mid f(x) \in D\}\) là lồi.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Áp dụng các hàm affine như co giãn và tịnh tiến, phép chiếu, tổng của hai tập hợp, và tổng từng phần lên các tập lồi sẽ cho kết quả là các tập lồi.&lt;/p&gt;

&lt;p&gt;Tập nghiệm của một bất đẳng thức ma trận tuyến tính \(\{x \mid x_1 A_1 + \cdots + x_m A_m \preceq B\}\) (với \(A_i, B \in S^n\)) cũng là lồi.&lt;/p&gt;

&lt;p&gt;Một hình nón hyperbolic \(\{x \mid x^T P x &amp;lt; (c^T x)^2, c^T x &amp;gt; 0\}\) (với \(P \subseteq S^n_+\), \(c \in \mathbb{R}^n\)) cũng là lồi.&lt;/p&gt;

&lt;h2 id=&quot;hàm-phối-cảnh&quot;&gt;Hàm phối cảnh&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Hàm phối cảnh&lt;/strong&gt; mô hình hóa cách các vật thể xuất hiện nhỏ hơn khi ở xa và lớn hơn khi ở gần, tương tự như cách máy ảnh chiếu hình ảnh. Vật thể nằm trong \(\mathbb{R}^{n+1}\) và ảnh của nó nằm trong \(\mathbb{R}^n\).&lt;/p&gt;

&lt;p&gt;Hàm phối cảnh được định nghĩa là \(P : \mathbb{R}^{n+1} \to \mathbb{R}^{n}\) với &lt;strong&gt;dom&lt;/strong&gt; \(P = \mathbb{R}^{n} \times \mathbb{R}_{++}\) và \(P(z,t) = z/t\), trong đó \(\mathbb{R}_{++} = \{x \in \mathbb{R} \mid x &amp;gt; 0\}\). Hàm này chuẩn hóa tọa độ cuối cùng về 1 và bỏ qua nó, giảm chiều từ \(\mathbb{R}^{n+1}\) xuống \(\mathbb{R}^n\). Nếu \(C \subseteq\) &lt;strong&gt;dom&lt;/strong&gt; \(P\) là lồi, thì ảnh \(P(C) = \{P(x) \mid x \in C\}\) cũng là lồi.&lt;/p&gt;

&lt;p&gt;Hàm phối cảnh hoạt động như một máy ảnh lỗ kim: các vật thể xa hơn từ lỗ kim được chiếu nhỏ hơn. Hình dưới đây minh họa nguyên lý này, cho thấy rằng các vật thể trong cùng một tia bị bắt sẽ được chiếu giống hệt nhau.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-02 Một số ví dụ quan trọng</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_02_Some_important_examples/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_02_Some_important_examples</id>
   <content type="html">&lt;p&gt;Phần này xem xét các ví dụ chính về tập lồi.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Các tập hợp tầm thường: tập rỗng, điểm, đường thẳng, đoạn thẳng, tia&lt;/li&gt;
  &lt;li&gt;Siêu phẳng: \(\{x : a^T x = b\}\), với \(a, b\) cho trước, \(a \ne 0\)&lt;/li&gt;
  &lt;li&gt;Nửa không gian: \(\{x : a^T x \le b \}\) với \(a \ne 0\)&lt;/li&gt;
  &lt;li&gt;Không gian Affine: \(\{x : Ax = b\}\), với \(A, b\) cho trước&lt;/li&gt;
  &lt;li&gt;Hình cầu Euclidean và ellipsoid&lt;/li&gt;
  &lt;li&gt;Hình cầu chuẩn: \(\{x : \| x \| \le r\}\), với chuẩn \(\|·\|\) và bán kính \(r\) cho trước&lt;/li&gt;
  &lt;li&gt;Hình nón lồi: nón chuẩn, nón pháp tuyến, nón nửa xác định dương&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>02-02-02 Ví dụ về hình nón lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_02_02_Convex_cone_examples/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_02_02_Convex_cone_examples</id>
   <content type="html">&lt;p&gt;Các ví dụ về hình nón lồi bao gồm hình nón chuẩn, hình nón pháp tuyến và hình nón nửa xác định dương.&lt;/p&gt;

&lt;h2 id=&quot;hình-nón-chuẩn&quot;&gt;Hình nón chuẩn&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Hình nón chuẩn&lt;/strong&gt; là một hình nón được định nghĩa bởi tất cả các điểm \((x, t)\) sao cho \(\| x \| \le t\) trong \(\mathbb{R}^{n+1}\), trong đó chuẩn có thể là bất kỳ chuẩn nào.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(C = \{(x, t) : \| x \| \le t\} \subseteq \mathbb{R}^{n+1}\), với chuẩn \(\|·\|\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hình dưới đây cho thấy hình nón chuẩn cho chuẩn \(l_2\) \(\|·\|_2\), còn được gọi là hình nón bậc hai hoặc hình nón kem.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.08_Norm_Cone.png&quot; alt=&quot;[Hình1] Hình Nón Chuẩn [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] Hình Nón Chuẩn [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;hình-nón-pháp-tuyến&quot;&gt;Hình nón pháp tuyến&lt;/h2&gt;

&lt;p&gt;Với một tập \(C\) và một điểm \(x \in C\), &lt;strong&gt;hình nón pháp tuyến&lt;/strong&gt; được định nghĩa như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[N_C(x) = \{ g: g^T (y - x) \le 0, \text{ với mọi } y \in C \}\]
&lt;/blockquote&gt;

&lt;p&gt;Hình nón pháp tuyến bao gồm tất cả các vector \(g\) sao cho tích vô hướng với \(y-x\) luôn nhỏ hơn hoặc bằng không với mọi \(y \in C\). Điều này có nghĩa là góc giữa \(g\) và \(y-x\) nằm trong khoảng từ 90 đến 270 độ (tức là \(\cos\theta &amp;lt; 0\)).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nếu \(x\) nằm trên biên, thì \(g\) duy nhất là pháp tuyến của siêu phẳng hỗ trợ.&lt;/li&gt;
  &lt;li&gt;Nếu \(x\) là một đỉnh, có nhiều siêu phẳng hỗ trợ, vậy \(g\) tạo thành hình quạt.&lt;/li&gt;
  &lt;li&gt;Nếu \(x\) nằm trong phần trong, thì \(g\) duy nhất là vector không.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hình dưới đây cho thấy vector pháp tuyến.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.04_2_Normal_Cone.png&quot; alt=&quot;[Hình2] Hình Nón Pháp Tuyến [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình2] Hình Nón Pháp Tuyến [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;hình-nón-nửa-xác-định-dương&quot;&gt;Hình nón nửa xác định dương&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Hình nón nửa xác định dương&lt;/strong&gt; \(\mathbb{S}^n_+\) được định nghĩa như sau, trong đó \(\mathbb{S}^n\) biểu diễn các ma trận đối xứng \(n \times n\):&lt;/p&gt;

&lt;blockquote&gt;
\[\mathbb{S}^n_+ = \{ X \in \mathbb{S}^n : X \succeq 0 \}\]
&lt;/blockquote&gt;

&lt;p&gt;\(\mathbb{S}^n_+\) là một hình nón lồi vì với \(\theta_1, \theta_2 \ge 0\) và \(A, B \in \mathbb{S}^n_+\), ta có \(\theta_1 A + \theta_2 B \in \mathbb{S}^n_+\). Đây được gọi là &lt;strong&gt;hình nón nửa xác định dương&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Hình dưới đây cho thấy biên của hình nón nửa xác định dương trong \(\mathbb{S}^2_+\) được vẽ trong \((x, y, z) \in \mathbb{R}^3\). Vì ma trận \(X\) là nửa xác định dương, định thức của nó phải không âm.&lt;/p&gt;

\[X = 
\begin{bmatrix}
x, y \\
y, z
\end{bmatrix}
\in \mathbb{S}^2_+ \iff x \ge 0, z \ge 0, xz \ge y^2\]

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.10_Positive_Semidefinite_Cone.png&quot; alt=&quot;[Hình3] Hình nón nửa xác định dương [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình3] Hình nón nửa xác định dương [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>02-02-01 Ví dụ về tập lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_02_01_Convex_sets_examples/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_02_01_Convex_sets_examples</id>
   <content type="html">&lt;p&gt;Tập lồi bao gồm nhiều dạng khác nhau, từ những dạng tầm thường như điểm và đường thẳng đến siêu phẳng, nửa không gian, hình cầu, ellipsoid, đa diện và hình nón.&lt;/p&gt;

&lt;h2 id=&quot;siêu-phẳng&quot;&gt;Siêu phẳng&lt;/h2&gt;

&lt;p&gt;Siêu phẳng là một tập con \((n-1)\) chiều chia không gian \(n\) chiều thành hai phần, được định nghĩa như sau. Ở đây, \(a\) là vector pháp tuyến và \(b\) là độ lệch từ gốc tọa độ. Siêu phẳng vừa là tập lồi vừa là tập affine.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;{\(x : a^T x = b\)} với \(a \in \mathbb{R}^n, a \ne 0, b \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Trong hình dưới đây, bất kỳ \(x\) nào trên siêu phẳng đều thỏa mãn \((x - x_0)\) vuông góc với \(a\). Do đó, \(a^T (x - x_0) = 0\), vậy nếu \(a^T x = b\), thì \(b = a^T x_0\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.05_Hyperplane.png&quot; alt=&quot;[Hình1] Siêu phẳng [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] Siêu phẳng [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;nửa-không-gian&quot;&gt;Nửa không gian&lt;/h2&gt;

&lt;p&gt;Nửa không gian là một phía của không gian được chia bởi siêu phẳng. Do đó, một siêu phẳng \(a^T x = b\) định nghĩa hai nửa không gian. Nửa không gian là tập lồi nhưng không phải tập affine.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;{\(x : a^T x \le b\)} hoặc {\(x : a^T x \ge b\)}  với \(a \in \mathbb{R}^n, a \ne 0, b \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Đối với siêu phẳng \(a^T x = b\), nửa không gian \(a^T x \ge b\) nằm theo hướng của vector pháp tuyến \(a\), trong khi \(a^T x \le b\) nằm theo hướng của \(-a\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_Halfspace.png&quot; alt=&quot;[Hình2] Nửa không gian [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình2] Nửa không gian [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Lưu ý: Phần trong của \(\{x : a^T x \le b\}\), tức là \(\{x : a^T x \lt b\}\), được gọi là nửa không gian mở.&lt;/p&gt;

&lt;h3 id=&quot;tính-chất-quan-trọng-nửa-không-gian-là-lồi&quot;&gt;Tính chất quan trọng: Nửa không gian là Lồi&lt;/h3&gt;

&lt;p&gt;Lấy hai điểm bất kỳ $x_1$ và $x_2$ trong nửa không gian:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Cả hai đều thỏa mãn: $a^T x_1 \leq b$ và $a^T x_2 \leq b$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Với bất kỳ tổ hợp lồi nào: $x_\theta = \theta x_1 + (1 - \theta)x_2$ với $\theta \in [0, 1]$&lt;/p&gt;

&lt;p&gt;Kiểm tra xem điểm này có nằm trong nửa không gian hay không:
\(a^T x_\theta = a^T(\theta x_1 + (1 - \theta)x_2) = \theta(a^T x_1) + (1 - \theta)(a^T x_2) \leq \theta b + (1 - \theta)b = b\)&lt;/p&gt;

&lt;p&gt;Vì $x_\theta$ thỏa mãn bất đẳng thức, tất cả các điểm giữa $x_1$ và $x_2$ đều nằm trong nửa không gian → nửa không gian là lồi.&lt;/p&gt;

&lt;h2 id=&quot;hình-cầu-euclidean&quot;&gt;Hình cầu Euclidean&lt;/h2&gt;

&lt;p&gt;Hình cầu Euclidean là một tập lồi khác, được định nghĩa như sau. (\(\| . \|_2\) là chuẩn Euclidean, \(\|u\|_2 = (u^T u)^{1/2}\).) \(x_c\) là tâm và \(r\) là bán kính. Do đó, \(B(x_c, r)\) chứa tất cả các điểm trong bán kính \(r\) từ tâm \(x_c\).&lt;/p&gt;

&lt;blockquote&gt;
\[B(x_c, r) = \{ x \mid \|x - x_c \|_2 \le r \} = \{ x \mid (x - x_c)^T (x - x_c) \le r^2 \} \text{ với } r \ge 0\]
&lt;/blockquote&gt;

&lt;p&gt;Hoặc, hình cầu Euclidean có thể được biểu diễn như:&lt;/p&gt;

&lt;blockquote&gt;
\[B(x_c, r) = \{ x_c + ru \mid \| u \|_2 \le 1 \}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;ellipsoid&quot;&gt;Ellipsoid&lt;/h2&gt;

&lt;p&gt;Ellipsoid là một tập lồi liên quan đến hình cầu Euclidean, được định nghĩa như:&lt;/p&gt;

&lt;blockquote&gt;
\[\mathcal{E} = \{x \mid (x - x_c)^T P^{-1} (x - x_c) \le 1 \}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(P = P^T \succ 0\) có nghĩa là \(P\) đối xứng và xác định dương. Vector \(x_c\) là tâm của ellipsoid, và ma trận \(P\) xác định ellipsoid kéo dài bao xa theo mỗi hướng từ tâm. Các trục của ellipsoid là \(\sqrt{\lambda_i}\), trong đó \(\lambda_i\) là các giá trị riêng của \(P\). Do đó, hình cầu là trường hợp đặc biệt của ellipsoid với \(P = r^2 I\).&lt;/p&gt;

&lt;p&gt;Hình dưới đây cho thấy một ellipsoid. Tâm \(x_c\) là một điểm, và các trục chính và phụ được vẽ như các đoạn thẳng.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.07_Ellipsoid.png&quot; alt=&quot;[Hình3] Ellipsoid [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình3] Ellipsoid [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Ellipsoid cũng có thể được biểu diễn như:&lt;/p&gt;

&lt;blockquote&gt;
\[\mathcal{E} = \{ x_c + Au \mid \|u\|_2 \le 1 \}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(A\) là ma trận vuông không suy biến. Nếu \(A = P^{1/2}\), biểu thức khớp với biểu thức trước đó, và \(A\) đối xứng và xác định dương. Nếu \(A\) đối xứng nửa xác định dương và suy biến, nó được gọi là ellipsoid suy biến, và chiều affine của nó bằng hạng của \(A\). Ellipsoid suy biến vẫn là lồi.&lt;/p&gt;

&lt;h2 id=&quot;hình-cầu-chuẩn&quot;&gt;Hình cầu chuẩn&lt;/h2&gt;

&lt;p&gt;Hình cầu chuẩn là tập hợp các điểm trong bán kính \(r\) từ tâm \(x_c\), được định nghĩa sử dụng một chuẩn tùy ý. Trong khi hình cầu Euclidean sử dụng chuẩn Euclidean, hình cầu chuẩn có thể sử dụng bất kỳ chuẩn nào. Nếu \(\|.\|\) là bất kỳ chuẩn nào trên \(\mathbb{R}^n\), hình cầu chuẩn được định nghĩa như:&lt;/p&gt;

&lt;blockquote&gt;
\[\{ x \mid \|x - x_c \| \le r  \}\]
&lt;/blockquote&gt;

&lt;p&gt;Khi p-chuẩn được định nghĩa như:&lt;/p&gt;

&lt;blockquote&gt;
\[\| x  \|_{p} = \left( \sum_{i=0}^n |x_i|^{p} \right)^{1/p} \text{ với  } p \ge 1\]
&lt;/blockquote&gt;

&lt;p&gt;Hình dạng của hình cầu chuẩn phụ thuộc vào giá trị của \(p\). Hình dưới đây cho thấy hình dạng của hình cầu chuẩn trong 3D với các giá trị khác nhau của \(p\). Hình cầu chuẩn là lồi nếu \(p \ge 1\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.07_2_norm_ball.png&quot; alt=&quot;[Hình4] Hình cầu chuẩn [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình4] Hình cầu chuẩn [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Hình tiếp theo cho thấy hình dạng của hình cầu chuẩn trong 2D với các giá trị khác nhau của \(p\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.07_3_norm_ball2.png&quot; alt=&quot;[Hình4] Hình cầu chuẩn [2]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình4] Hình cầu chuẩn [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;đa-diện&quot;&gt;Đa diện&lt;/h2&gt;

&lt;p&gt;Đa diện được định nghĩa như giao của các bất đẳng thức và đẳng thức tuyến tính. Tập affine (không gian con, siêu phẳng, đường thẳng), tia, đoạn thẳng và nửa không gian đều là đa diện. Đa diện là tập lồi, và một đa diện bị chặn được gọi là polytope.&lt;/p&gt;

&lt;blockquote&gt;
\[\mathcal{P} = \{ x \mid a^T_i x \le b_i, i = 1, ..., m, c_j^Tx  = d_j, j = 1, ..., p\}\]
&lt;/blockquote&gt;

&lt;p&gt;Một đẳng thức đơn \(c_j^Tx  = d_j\) có thể được biểu diễn bằng hai bất đẳng thức \(c^T_jx \le d_j\) và \(c^T_jx \ge d_j\). Do đó, đa diện có thể được định nghĩa chỉ sử dụng các bất đẳng thức.&lt;/p&gt;

&lt;p&gt;Hình dưới đây cho thấy một đa diện ngũ giác được hình thành bởi giao của năm nửa không gian, với các vector pháp tuyến hướng ra ngoài \(a_1, ..., a_5\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.09_Polyhedra.png&quot; alt=&quot;[Hình5] Đa diện [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình5] Đa diện [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Dưới dạng ma trận, một đa diện có thể được định nghĩa như:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\mathcal{P} =  \{ x \mid A^Tx \preceq b, C^Tx  = d \}\)
trong đó
\(A = 
\begin{bmatrix}
a^T_1 \\
\vdots \\
a^T_m
\end{bmatrix},\)
\(C = 
\begin{bmatrix}
c^T_1 \\
\vdots \\
c^T_p
\end{bmatrix}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;đơn-hình&quot;&gt;Đơn hình&lt;/h3&gt;

&lt;p&gt;Đơn hình là đa giác đơn giản nhất có thể được hình thành trong không gian \(n\) chiều, được xây dựng từ \(n+1\) điểm.&lt;/p&gt;

&lt;p&gt;Nếu có \(k + 1\) điểm \(v_0, ..., v_k \in \mathbb{R}^n\) độc lập affine, đơn hình được định nghĩa như bao lồi của những \(k+1\) điểm này. Độc lập affine có nghĩa là \(v_1 − v_0, ..., v_k − v_0\) độc lập tuyến tính.&lt;/p&gt;

&lt;blockquote&gt;
\[C = \mathbb{conv} \{v_0, ... , v_k\} = \{ \theta_0 v_0 + \cdots + \theta_k v_k  \mid \theta \succeq 0, 1^T \theta = 1 \}\]
&lt;/blockquote&gt;

&lt;p&gt;Hình dưới đây cho thấy các đơn hình từ 0 đến 3 chiều: một điểm trong 0D, một đoạn thẳng trong 1D, một tam giác trong 2D, và một tứ diện trong 3D.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.02_10_Simplex.png&quot; alt=&quot;[Hình6] Đơn hình [nguồn - wikipedia]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình6] Đơn hình [nguồn - wikipedia]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Một ví dụ phổ biến của đơn hình là đơn hình xác suất:&lt;/p&gt;

&lt;blockquote&gt;
\[C = \mathbb{conv} \{e_1, ..., e_n \} = \{ \theta \mid \theta \succeq 0, 1^T \theta = 1\}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>02 Convex Sets</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_Convex_sets/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_Convex_sets</id>
   <content type="html">&lt;p&gt;In this chapter, we will study the concept of convex sets, which form the foundation of convex optimization.&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;Convex optimization refers to techniques for finding maxima or minima by defining problems using convex functions.
Convex sets are closely related to convex functions in two main ways:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Convex functions are defined over convex sets. The domain and range of a function are defined as convex sets, and the main properties of convex functions are determined by these sets.&lt;/li&gt;
  &lt;li&gt;If you can transform an optimization problem into one involving a convex function, it becomes easier to solve. Sometimes, it is difficult to determine whether a problem is defined by a convex function. In such cases, you can check whether the epigraph of the function is a convex set to determine if the function is convex.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;content&quot;&gt;Content&lt;/h3&gt;
&lt;p&gt;In this chapter, we will cover the definition and examples of convex sets, their main properties, and operations that preserve convexity.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-06 Dual cones and generalized inequalities</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_06_Dual_cones_and_generalized_inequalities/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_06_Dual_cones_and_generalized_inequalities</id>
   <content type="html">&lt;p&gt;This section discusses dual cones paired with cones, and dual generalized inequalities. Using dual generalized inequalities allows comparison using scalar inner products, making comparisons much easier.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-06-02 Dual generalized inequalities</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_06_02_Dual_generalized_inequalities/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_06_02_Dual_generalized_inequalities</id>
   <content type="html">&lt;p&gt;If we can define a generalized inequality using a proper cone, we can also define a dual generalized inequality using the dual cone, provided the dual cone is proper.&lt;/p&gt;

&lt;p&gt;This section defines dual generalized inequalities using a proper dual cone and redefines minimum and minimal elements using dual inequalities.&lt;/p&gt;

&lt;h2 id=&quot;dual-generalized-inequalities&quot;&gt;Dual generalized inequalities&lt;/h2&gt;

&lt;p&gt;Given a proper dual cone, the generalized inequality is defined as follows. For a point \(y\), if the inner product with every \(x\) in \(K\) is nonnegative, then \(y\) is nonnegative in the dual cone \(K^*\).&lt;/p&gt;

&lt;p&gt;Here, \(\succeq_{K^*}\) is called the &lt;strong&gt;dual&lt;/strong&gt; of \(\succeq_K\), i.e., the &lt;strong&gt;dual generalized inequality&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(y \succeq_{K^*} 0 \iff y^T x \ge 0\) for all \(x \succeq_K 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;key-properties-of-generalized-and-dual-inequalities&quot;&gt;Key properties of generalized and dual inequalities&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\(x \preceq_K y\) if and only if \(\lambda^T x \le \lambda^T y\) for all \(\lambda \succeq_{K^*} 0\).&lt;/li&gt;
  &lt;li&gt;\(x \prec_K y\) if and only if \(\lambda^T x &amp;lt; \lambda^T y\) for all \(\lambda \succeq_{K^*} 0, \lambda \ne 0\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If \(K = K^{**}\), the dual generalized inequality associated with \(\preceq_K^*\) is \(\preceq_K\), so these properties are preserved even if the roles of generalized and dual inequalities are switched.&lt;/p&gt;

&lt;p&gt;For example, \(\lambda \preceq_K^* \mu\) if and only if \(\lambda^T x \le \mu^T x\) for all \(x \succeq_K 0\).&lt;/p&gt;

&lt;h2 id=&quot;minimum-and-minimal-elements-via-dual-inequalities&quot;&gt;Minimum and minimal elements via dual inequalities&lt;/h2&gt;

&lt;p&gt;For a generalized inequality induced by a proper cone \(K\), we can use dual generalized inequalities to characterize the minimum and minimal elements of a (possibly nonconvex) set \(S \subseteq \mathbb{R}^m\).&lt;/p&gt;

&lt;h3 id=&quot;minimum-element&quot;&gt;Minimum element&lt;/h3&gt;

&lt;p&gt;For all \(\lambda \succ_K^* 0\) and \(z \in S\),&lt;/p&gt;

&lt;p&gt;If \(x\) is the unique minimizer of \(\lambda^T z\), then with respect to the generalized inequality \(\succ_K^*\), \(x\) is the minimum of \(S\). (A minimizer is a value of the dependent variable that minimizes a function; here, the function is \(\lambda^T z\), the variable is \(z\), and the minimizer is \(x\).)&lt;/p&gt;

&lt;p&gt;Geometrically, this means that for some \(\lambda \succ_K^* 0\), the hyperplane \(\{ z \mid  \lambda^T (z-x) = 0 \}\) is a strict supporting hyperplane for \(S\) at \(x\). (A strict supporting hyperplane means the hyperplane intersects \(S\) only at \(x\).) \(S\) need not be convex. The figure below shows a minimum \(x\) and a strict supporting hyperplane.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_02_Minimum_element.png&quot; alt=&quot;[Fig1] Minimum element [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Minimum element [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;minimal-element&quot;&gt;Minimal element&lt;/h3&gt;

&lt;p&gt;The necessary and sufficient conditions for minimal elements differ slightly.&lt;/p&gt;

&lt;p&gt;For \(\lambda \succ_K^* 0\) and \(z \in S\), if \(x\) is a minimizer of \(\lambda^T z\), then \(x \in S\) is minimal. In other words, if \(x\) is minimal, then \(\lambda^T z\) does not have a unique minimizer. Therefore, for the same \(\lambda\), there can be multiple minimal elements, and there can be multiple minimal elements for different \(\lambda\).&lt;/p&gt;

&lt;p&gt;The figure below illustrates the existence of multiple minimal elements. The region with the thick black line at the bottom left indicates the area where minimal elements exist.
Here, \(x_1\) is the minimizer of \(\lambda^T_1 z\) and since \(\lambda_1 \succ_K^* 0\), it is minimal. Another minimizer, \(x_2\), also exists.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_05_Minimal_element.png&quot; alt=&quot;[Fig2] Minimal element [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Minimal element [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;However, the converse is not true. Even if a point \(x\) is minimal in a set \(S\), it may not be the minimizer of \(\lambda^T z\) for some \(\lambda\) and \(z \in S\). The figure below shows an example of a minimal element that is not a minimizer. Here, the convexity of the set seems to play a crucial role in this converse not being true.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_06_Minimal_element2.png&quot; alt=&quot;[Fig3] An example of a minimal element that is not a minimizer [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig3] An example of a minimal element that is not a minimizer [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;This converse theorem does not strengthen with \(\lambda_1 \succ_K^* 0\). In the left figure below, \(x_1 \in S_1\) is minimal, but not the minimizer of \(\lambda_1^T x_1\). The right figure shows that \(x_2 \in S_2\) is not minimal, but is the minimizer of \(\lambda_2^T x_2\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_07_Minimal_element3.png&quot; alt=&quot;[Fig4] Examples where the converse does not strengthen with $$\lambda_1 \succ_K^* 0$$ [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig4] Examples where the converse does not strengthen with } \lambda_1 \succ_K^* 0 \text{ [1]}$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;optimal-production-frontier&quot;&gt;Optimal production frontier&lt;/h3&gt;
&lt;p&gt;Consider a product that needs to be produced using n resources (labor, electricity, natural gas, water, etc.).
This product can be produced in several ways. For each production method, there is a resource vector \(x \in \mathbb{R}\), where \(x_i\) denotes the amount of resource \(i\) consumed. It is assumed that the resource consumption \(x_i\) is nonnegative, and the resources have high value.&lt;/p&gt;

&lt;p&gt;The production set \(P \subseteq \mathbb{R}^n\) is defined as the set of all resource vectors \(x\). A production method with a minimal resource vector is called &lt;strong&gt;Pareto optimal&lt;/strong&gt; or &lt;strong&gt;efficient&lt;/strong&gt;. The set of minimal elements of \(P\) is called the &lt;strong&gt;efficient production frontier&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Let’s briefly look at Pareto optimality.&lt;/p&gt;

&lt;p&gt;Suppose there are two production methods, one with resource vector \(x\) (\(P_x\)) and the other with resource vector \(y\) (\(P_y\)). If for all \(i\), \(x_i \le y_i\), and for some \(i\), \(x_i \lt y_i\), then we can say that \(P_x\) is better than \(P_y\). In other words, a method that does not use more resources than another, or uses at least one resource less, is considered better. That is, this corresponds to the case where \(x \preceq y\) and \(x \ne y\).
If there is no method better than \(P_x\), then \(P_x\) is said to be Pareto optimal.&lt;/p&gt;

&lt;p&gt;By minimizing the following expression, we can find the Pareto optimal production method. Here, \(\lambda_i\) can be considered as the price of resource \(i\). Minimizing \(\lambda^T x\) with respect to \(P\) yields the cheapest production method. Since the prices are positive, the result of the minimization is always Pareto optimal.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\lambda^T x =\) \(\lambda^T_1 x_1 + \lambda^T_2 x_2 + ... + \lambda^T_n x_n, \lambda \succ 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The figure below illustrates this situation well. In the figure, \(x_1, x_2, x_3\) are Pareto optimal, while \(x_4, x_5\) are not.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_08_Pareto_optimal.png&quot; alt=&quot;[Fig5] Optimal production frontier [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig5] Optimal production frontier [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

</content>
 </entry>
 
 <entry>
   <title>02-06-01 Dual cones</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_06_01_Dual_cones/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_06_01_Dual_cones</id>
   <content type="html">&lt;h2 id=&quot;dual-cones&quot;&gt;Dual cones&lt;/h2&gt;

&lt;p&gt;A dual cone is defined as a pair with a cone, denoted as \(K\) for the cone and \(K^*\) for the dual cone. The dual cone is always convex, regardless of whether \(K\) is convex. The dual cone is defined as the set of points \(y\) such that the inner product with any \(x\) in \(K\) is nonnegative:&lt;/p&gt;

&lt;blockquote&gt;
\[K^* = \{y \mid x^T y \ge 0 \text{ for all } x \in K\}\]
&lt;/blockquote&gt;

&lt;p&gt;For \(x\) and \(y\), the inner product being nonnegative means the angle between the vectors is in the range where \(\cos\theta \ge 0\), i.e., \(0 \le \theta \le 90\) and \(270 \le \theta \le 360\). Thus, the boundary of the dual cone is formed in the direction of the negative normal vector of the supporting hyperplane of the cone. The figure below shows the region where the dual cone is defined. In summary, the region of the dual cone is the set of all directions of the negative normal vectors of supporting hyperplanes of the cone at the origin.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_01_2_dual_cone.png&quot; alt=&quot;[Fig1] Dual cone definition region&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Dual cone definition region&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Geometrically, if \(y \in K^*\), then \(-y\) is the normal of the supporting hyperplane of \(K\) at the origin. The next figure shows that on the left, the halfspace with inward normal \(y\) contains the cone \(K\), so \(y \in K^*\). On the right, the halfspace with inward normal \(z\) does not contain \(K\), so \(y \notin K^*\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_01_dual_cone.png&quot; alt=&quot;[Fig2] Dual cone and supporting hyperplane normal [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Dual cone and supporting hyperplane normal [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;dual-cones-examples&quot;&gt;Dual cones examples&lt;/h2&gt;

&lt;p&gt;Here are some examples of cones and their duals. The first three are &lt;strong&gt;self-dual&lt;/strong&gt;, meaning the cone and its dual are the same. The last example shows that the dual of the \(l_\infty\) cone is the \(l_1\) cone, and vice versa.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$K = \mathbb{R}^n_+, K^* = \mathbb{R}^n_+$&lt;/li&gt;
  &lt;li&gt;$K = S^n_+, K^* = S^n_+$&lt;/li&gt;
  &lt;li&gt;$K = {(x, t) \mid  |x|_2 \le t }, K^* = {(x, t)\mid  |x|_2 \le t }$&lt;/li&gt;
  &lt;li&gt;$K = {(x, t) \mid  | x |&lt;em&gt;1 \le t }, K^* = {(x, t) \mid  | x |&lt;/em&gt;{\infty} \le t }$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;l_2-cone-is-self-dual&quot;&gt;\(l_2\) cone is self-dual&lt;/h3&gt;

&lt;p&gt;The figure below shows that the \(l_2\) cone is self-dual. That is, for \(x \in K\) on the boundary, the normal \(-y\) of the supporting hyperplane at \(x\) matches the boundary of \(K\), and \(y\) is the boundary of the dual cone \(K^*\), so \(K\) and \(K^*\) coincide.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_03_L2_self-dual.png&quot; alt=&quot;[Fig3] $$l_2$$ cone and dual cone&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig3] } l_2 \text{ cone and dual cone}$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;the-dual-cone-of-l_infty-cone-is-l_1-cone&quot;&gt;The dual cone of \(l_\infty\) cone is \(l_1\) cone&lt;/h3&gt;

&lt;p&gt;The figure below shows that the dual cone of the \(l_\infty\) cone is the \(l_1\) cone. That is, when \(x \in K\) is a boundary point, the normal \(-y\) of the supporting hyperplane at \(x\) enters the interior of \(K\) and coincides with the boundary of the \(l_1\) cone.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_04_L_inf_dual_norm.png&quot; alt=&quot;[Fig4] $$l_\infty$$ cone과 dual cone&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig4] } l_\infty \text{ cone and dual cone}$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>02-05 Separating and supporting hyperplanes</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_05_Separating_and_supporting_hyperplanes/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_05_Separating_and_supporting_hyperplanes</id>
   <content type="html">&lt;p&gt;This section introduces two theorems that characterize convex sets: the &lt;strong&gt;separating hyperplane theorem&lt;/strong&gt; and the &lt;strong&gt;supporting hyperplane theorem&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;separating-hyperplane-theorem&quot;&gt;Separating hyperplane theorem&lt;/h2&gt;

&lt;p&gt;Suppose there are several disjoint convex sets with no intersection. How can we separate them? The simplest way is to draw a line between the sets. This method is widely used in classification and is supported by the &lt;strong&gt;separating hyperplane theorem&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;If there are two disjoint convex sets \(C\) and \(D\), then for \(x \in C\), \(a^T x \le b\) and for \(x \in D\), \(a^T x \ge b\) for some \(a \ne 0\) and \(b\). In other words, the affine function \(a^T x - b\) is nonpositive on \(C\) and nonnegative on \(D\). The hyperplane \(\{ x \mid a^T x = b\}\) is called a &lt;strong&gt;separating hyperplane&lt;/strong&gt; for \(C\) and \(D\).&lt;/p&gt;

&lt;p&gt;The figure below shows a separating hyperplane dividing two disjoint convex sets \(C\) and \(D\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.05_01_Seperating_hyperplan_theorem.png&quot; alt=&quot;[Fig1] Separating hyperplane theorem [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Separating hyperplane theorem [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;The converse of the separating hyperplane theorem does not hold. That is, the existence of a separating hyperplane does not guarantee that the sets are disjoint. For example, if \(C = D = \{0\} \subseteq \mathbb{R}\), then \(x = 0\) separates \(C\) and \(D\).&lt;/p&gt;

&lt;h3 id=&quot;strict-separation&quot;&gt;Strict separation&lt;/h3&gt;

&lt;p&gt;If the separating hyperplane satisfies the stronger condition \(x \in C\) implies \(a^T x &amp;lt; b\) and \(x \in D\) implies \(a^T x &amp;gt; b\), this is called &lt;strong&gt;strict separation&lt;/strong&gt;. Disjoint closed convex sets do not always require strict separation, but in many cases, this condition holds.&lt;/p&gt;

&lt;h2 id=&quot;supporting-hyperplanes-theorem&quot;&gt;Supporting hyperplanes theorem&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;supporting hyperplane theorem&lt;/strong&gt; states that for any nonempty convex set \(C\) and any point \(x_0\) on the boundary &lt;strong&gt;bd&lt;/strong&gt; \(C\), there exists a supporting hyperplane at \(x_0\).&lt;/p&gt;

&lt;p&gt;What is a supporting hyperplane? Suppose \(x_0\) is a boundary point of \(C\). If for all \(x \in C\), \(a^T x \le a^T x_0\) (\(a \ne 0\)), then the hyperplane \(\{x \mid a^T x = a^T x_0 \}\) is a &lt;strong&gt;supporting hyperplane&lt;/strong&gt; for \(C\) at \(x_0\).&lt;/p&gt;

&lt;p&gt;[Note] The boundary is defined as \(x_0 \in\) &lt;strong&gt;bd&lt;/strong&gt; \(C =\) &lt;strong&gt;cl&lt;/strong&gt; \(C\) \(\setminus\) &lt;strong&gt;int&lt;/strong&gt; \(C\), i.e., the closure minus the interior.&lt;/p&gt;

&lt;p&gt;Geometrically, the supporting hyperplane \(\{x \mid a^T x = a^T x_0\}\) is tangent to \(C\) at \(x_0\) and the halfspace \(a^T x \le a^T x_0\) contains \(C\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.05_02_Supporting_hyperplane_theorem.png&quot; alt=&quot;[Fig 2] Supporting hyperplane [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] Supporting hyperplane [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

</content>
 </entry>
 
 <entry>
   <title>02-04 Generalized inequalities</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_04_Generalized_inequalities/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_04_Generalized_inequalities</id>
   <content type="html">&lt;p&gt;In one-dimensional real space \(\mathbb{R}\), given two numbers 1 and 2, we can say 2 is greater than 1. But in \(n\)-dimensional real space \(\mathbb{R}^n\), given two points \(x_1\) and \(x_2\), can we say which is greater? This is not straightforward.&lt;/p&gt;

&lt;p&gt;This section introduces &lt;strong&gt;generalized inequalities&lt;/strong&gt; for comparing order between two points in \(\mathbb{R}^n\), and also discusses the concepts of minimum and minimal elements of a set.&lt;/p&gt;

&lt;h2 id=&quot;proper-cone&quot;&gt;Proper cone&lt;/h2&gt;

&lt;p&gt;A convex cone \(K \subseteq \mathbb{R}^n\) is called a &lt;strong&gt;proper cone&lt;/strong&gt; if it satisfies:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;K is closed (includes its boundary).&lt;/li&gt;
  &lt;li&gt;K is solid (its interior is nonempty).&lt;/li&gt;
  &lt;li&gt;K is pointed (does not contain any line) (i.e., \(x \in K, -x \in K \implies x = 0\)).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If a pointed &amp;amp; closed convex cone is defined in a subspace of dimension \(n-1\) or less, its interior is empty, since it cannot contain an open ball in \(n\) dimensions. Thus, it is not solid and cannot be a proper cone. For example, a 2D pie-shaped pointed &amp;amp; closed convex cone in \(\mathbb{R}^3\) is not a proper cone.&lt;/p&gt;

&lt;p&gt;See &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Interior_(topology)&quot;&gt;Wikipedia: Interior (topology)&lt;/a&gt;&lt;/em&gt; for the definition of interior.&lt;/p&gt;

&lt;h2 id=&quot;generalized-inequality&quot;&gt;Generalized inequality&lt;/h2&gt;

&lt;p&gt;Using a proper cone, we can define a partial ordering in \(\mathbb{R}^n\) called a &lt;strong&gt;generalized inequality&lt;/strong&gt;. It has properties similar to the standard ordering in \(\mathbb{R}\):&lt;/p&gt;

&lt;blockquote&gt;
\[x \preceq_{K} y \iff y − x \in K\]
&lt;/blockquote&gt;

&lt;p&gt;Similarly, strict partial ordering is defined as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x \prec_{K} y \iff y − x \in\) &lt;strong&gt;int&lt;/strong&gt; \(K\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If \(K = \mathbb{R}_{+}\), then \(\preceq_{K}\) is the usual \(\le\) in \(\mathbb{R}\).&lt;/p&gt;

&lt;h3 id=&quot;properties-of-generalized-inequalities&quot;&gt;Properties of generalized inequalities&lt;/h3&gt;

&lt;p&gt;Generalized inequality \(\preceq_{K}\) satisfies:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Preserved under addition&lt;/strong&gt;: if \(x \preceq_{K} y\) and \(u \preceq_{K} v\), then \(x+u \preceq_{K} y +v\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transitive&lt;/strong&gt;: if \(x \preceq_{K} y\) and \(y \preceq_{K} z\) then \(x \preceq_{K}  z\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Preserved under nonnegative scaling&lt;/strong&gt;: if \(x \preceq_{K} y\) and \(α \ge 0\) then \(αx \preceq_{K} αy\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reflexive&lt;/strong&gt;: \(x \preceq_{K} x\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Antisymmetric&lt;/strong&gt;: if \(x \preceq_{K} y\) and \(y \preceq_{K} x\), then \(x = y\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Preserved under limits&lt;/strong&gt;: if \(x_i \preceq_{K}  y_i\) for \(i = 1, 2, ..., x_i \to x\) and \(y_i \to y\) as \(i \to ∞\), then \(x \preceq_{K} y\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Strict generalized inequalities have corresponding properties.&lt;/p&gt;

&lt;h2 id=&quot;minimum-and-minimal-elements&quot;&gt;Minimum and minimal elements&lt;/h2&gt;

&lt;p&gt;The most significant difference between ordering in \(\mathbb{R}\) and generalized ordering in \(\mathbb{R}^n\) is &lt;strong&gt;linear ordering&lt;/strong&gt;. In \(\mathbb{R}\), we can compare any two points with \(x \lt y\) or \(x \gt y\), but generalized inequality cannot always do this. Therefore, defining the concepts of maximum and minimum in the context of generalized inequality is expected to be much more complex.&lt;/p&gt;

&lt;h3 id=&quot;minimum-elements&quot;&gt;Minimum elements&lt;/h3&gt;

&lt;p&gt;If \(x \in S\) satisfies \(x \preceq_{K} y\) for all \(y \in S\), then \(x\) is a &lt;strong&gt;minimum&lt;/strong&gt; element of set \(S\). Similarly, &lt;strong&gt;maximum&lt;/strong&gt; can be defined in the same manner. If a minimum exists in a set, it is unique. That is, there exists only one minimum.&lt;/p&gt;

&lt;p&gt;If a point \(x \in S\) is the minimum of \(S\), then \(S \subseteq x + K\). Here, \(x + K\) means that (according to \(\preceq_{K}\)) all points are comparable with \(x\) and are greater than or equal to \(x\).&lt;/p&gt;

&lt;h3 id=&quot;minimal-elements&quot;&gt;Minimal elements&lt;/h3&gt;

&lt;p&gt;A similar concept is &lt;strong&gt;minimal&lt;/strong&gt;. If \(x \in S\) and for all \(y \in S\), the condition \(y \preceq_{K} x\) holds only when \(y=x\), then \(x\) is a &lt;strong&gt;minimal&lt;/strong&gt; element of set \(S\). Similarly, &lt;strong&gt;maximal&lt;/strong&gt; can be defined in the same manner. A set can have multiple minimal elements.&lt;/p&gt;

&lt;p&gt;If a point \(x \in S\) is minimal in \(S\), then \((x - K) \cap S = \{x\}\). Here, \(x - K\) means that (according to \(\preceq_{K}\)) all points are comparable with \(x\) and are less than or equal to \(x\).&lt;/p&gt;

&lt;p&gt;In the case of \(K = \mathbb{R}_{+}\), minimal and minimum are the same and correspond to the general definition of minimum.&lt;/p&gt;

&lt;h3 id=&quot;minimum-and-minimal-in-mathbbr2_-cone&quot;&gt;Minimum and minimal in \(\mathbb{R}^2_{+}\) cone&lt;/h3&gt;

&lt;p&gt;Consider the \(\mathbb{R}^2_{+}\) cone \(K\). The inequality \(x \preceq_{K} y\) means that \(y\) is to the upper right of \(x\). When \(x \in S\), saying that \(x\) is the minimum means that all points in \(S\) are to the upper right of \(x\). Saying that \(x\) is minimal means that there are no points in \(S\) to the lower left of \(x\).&lt;/p&gt;

&lt;p&gt;In the figure below, \(S_1\) has a minimum \(x_1\). The set \(x + K\) is shown in light gray, and since \(S_1 \subseteq x + K\), \(x_1\) is the minimum. \(S_2\) has a minimal element \(x_2\). The set \(x - K\) is shown in light gray, and since \((x - K) \cap S = \{x\}\), \(x_2\) is minimal.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_01_Minimum_and_minimal.png&quot; alt=&quot;[Fig1] Minimum and minimal elements [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Minimum and minimal elements [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

</content>
 </entry>
 
 <entry>
   <title>02-03 Operations that preserve convexity of convex set</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_03_Operations_that_preserve_convexity/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_03_Operations_that_preserve_convexity</id>
   <content type="html">&lt;p&gt;This section discusses operations that preserve the convexity of convex sets. These operations are useful for determining convexity or constructing desired convex sets from simple ones like hyperplanes, halfspaces, and norm balls.&lt;/p&gt;

&lt;p&gt;Operations that preserve convexity include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Intersection&lt;/li&gt;
  &lt;li&gt;Affine functions&lt;/li&gt;
  &lt;li&gt;Perspective function&lt;/li&gt;
  &lt;li&gt;Linear-fractional functions&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;intersection&quot;&gt;Intersection&lt;/h2&gt;

&lt;p&gt;The intersection of convex sets is convex. That is, if \(S_1\) and \(S_2\) are convex, then \(S_1 \cap S_2\) is convex. This property holds even for infinitely many sets. (Subspaces, affine sets, and convex cones are also closed under intersection.)&lt;/p&gt;

&lt;p&gt;Convexity can be expressed as the intersection of infinitely many halfspaces, and the converse also holds. That is, a closed convex set \(S\) can be defined as the intersection of all halfspaces containing \(S\):&lt;/p&gt;

&lt;blockquote&gt;
\[S = \bigcap \{\mathcal{H} \mid \mathcal{H} \text{ halfspace }, S \subseteq \mathcal{H}\}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;affine-functions&quot;&gt;Affine functions&lt;/h2&gt;

&lt;p&gt;Let \(A \in \mathbb{R}^{m \times n}\) and \(b \in \mathbb{R}^{m}\). The function \(f : \mathbb{R}^n \to \mathbb{R}^m\) defined by \(f(x) = Ax + b\) is called an affine function.&lt;/p&gt;

&lt;p&gt;If \(C \subseteq \mathbb{R}^n\) is convex and \(D \subseteq \mathbb{R}^m\) is convex, then:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The affine image \(f(C) = \{f(x) \mid x \in C\}\) is convex.&lt;/li&gt;
  &lt;li&gt;The affine preimage \(f^{-1}(D) = \{x \mid f(x) \in D\}\) is convex.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Applying affine functions such as scaling and translation, projection, sum of two sets, and partial sum to convex sets results in convex sets.&lt;/p&gt;

&lt;p&gt;The solution set of a linear matrix inequality \(\{x \mid x_1 A_1 + \cdots + x_m A_m \preceq B\}\) (with \(A_i, B \in S^n\)) is also convex.&lt;/p&gt;

&lt;p&gt;A hyperbolic cone \(\{x \mid x^T P x &amp;lt; (c^T x)^2, c^T x &amp;gt; 0\}\) (with \(P \subseteq S^n_+\), \(c \in \mathbb{R}^n\)) is also convex.&lt;/p&gt;

&lt;h2 id=&quot;perspective-function&quot;&gt;Perspective function&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;perspective function&lt;/strong&gt; models how objects appear smaller when farther away and larger when closer, similar to how a camera projects images. The object is in \(\mathbb{R}^{n+1}\) and its image is in \(\mathbb{R}^n\).&lt;/p&gt;

&lt;p&gt;The perspective function is defined as \(P : \mathbb{R}^{n+1} \to \mathbb{R}^{n}\) with &lt;strong&gt;dom&lt;/strong&gt; \(P = \mathbb{R}^{n} \times \mathbb{R}_{++}\) and \(P(z,t) = z/t\), where \(\mathbb{R}_{++} = \{x \in \mathbb{R} \mid x &amp;gt; 0\}\). This function normalizes the last coordinate to 1 and drops it, reducing the dimension from \(\mathbb{R}^{n+1}\) to \(\mathbb{R}^n\). If \(C \subseteq\) &lt;strong&gt;dom&lt;/strong&gt; \(P\) is convex, then the image \(P(C) = \{P(x) \mid x \in C\}\) is also convex.&lt;/p&gt;

&lt;p&gt;The perspective function works like a pinhole camera: objects farther from the pinhole are projected smaller. The figure below illustrates this principle, showing that objects within the same captured ray are projected identically.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-02 Some important examples</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_02_Some_important_examples/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_02_Some_important_examples</id>
   <content type="html">&lt;p&gt;This section reviews major examples of convex sets.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trivial ones: empty set, point, line, line segment, ray&lt;/li&gt;
  &lt;li&gt;Hyperplane: \(\{x : a^T x = b\}\), for given \(a, b\), \(a \ne 0\)&lt;/li&gt;
  &lt;li&gt;Halfspace: \(\{x : a^T x \le b \}\) for \(a \ne 0\)&lt;/li&gt;
  &lt;li&gt;Affine space: \(\{x : Ax = b\}\), for given \(A, b\)&lt;/li&gt;
  &lt;li&gt;Euclidean ball &amp;amp; ellipsoid&lt;/li&gt;
  &lt;li&gt;Norm ball: \(\{x : \| x \| \le r\}\), for given norm \(\|·\|\), radius \(r\)&lt;/li&gt;
  &lt;li&gt;Convex cone: norm cone, normal cone, positive semidefinite cone&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>02-02-02 Convex Cone examples</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_02_02_Convex_cone_examples/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_02_02_Convex_cone_examples</id>
   <content type="html">&lt;p&gt;Examples of convex cones include the norm cone, normal cone, and positive semidefinite cone.&lt;/p&gt;

&lt;h2 id=&quot;norm-cone&quot;&gt;Norm cone&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;norm cone&lt;/strong&gt; is a cone defined by all points \((x, t)\) such that \(\| x \| \le t\) in \(\mathbb{R}^{n+1}\), where the norm can be arbitrary.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(C = \{(x, t) : \| x \| \le t\} \subseteq \mathbb{R}^{n+1}\), for a norm \(\|·\|\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The figure below shows the norm cone for the \(l_2\) norm \(\|·\|_2\), also called the second-order cone or ice cream cone.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.08_Norm_Cone.png&quot; alt=&quot;[Fig1] Norm Cone [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Norm Cone [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;normal-cone&quot;&gt;Normal Cone&lt;/h2&gt;

&lt;p&gt;For a set \(C\) and a point \(x \in C\), the &lt;strong&gt;normal cone&lt;/strong&gt; is defined as:&lt;/p&gt;

&lt;blockquote&gt;
\[N_C(x) = \{ g: g^T (y - x) \le 0, \text{ for all } y \in C \}\]
&lt;/blockquote&gt;

&lt;p&gt;The normal cone consists of all vectors \(g\) such that the inner product with \(y-x\) is always less than or equal to zero for all \(y \in C\). This means the angle between \(g\) and \(y-x\) is between 90 and 270 degrees (i.e., \(\cos\theta &amp;lt; 0\)).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If \(x\) is on the boundary, the only \(g\) is the normal of the supporting hyperplane.&lt;/li&gt;
  &lt;li&gt;If \(x\) is a vertex, there are multiple supporting hyperplanes, so \(g\) forms a pie shape.&lt;/li&gt;
  &lt;li&gt;If \(x\) is in the interior, the only \(g\) is the zero vector.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The figure below shows the normal vector.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.04_2_Normal_Cone.png&quot; alt=&quot;[Fig2] Normal Cone [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Normal Cone [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;positive-semidefinite-cone&quot;&gt;Positive semidefinite cone&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;positive semidefinite cone&lt;/strong&gt; \(\mathbb{S}^n_+\) is defined as follows, where \(\mathbb{S}^n\) represents \(n \times n\) symmetric matrices:&lt;/p&gt;

&lt;blockquote&gt;
\[\mathbb{S}^n_+ = \{ X \in \mathbb{S}^n : X \succeq 0 \}\]
&lt;/blockquote&gt;

&lt;p&gt;\(\mathbb{S}^n_+\) is a convex cone because for \(\theta_1, \theta_2 \ge 0\) and \(A, B \in \mathbb{S}^n_+\), we have \(\theta_1 A + \theta_2 B \in \mathbb{S}^n_+\). This is called the &lt;strong&gt;positive semidefinite cone&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The following figure shows the boundary of the positive semidefinite cone in \(\mathbb{S}^2_+\) plotted in \((x, y, z) \in \mathbb{R}^3\). Since matrix \(X\) is positive semidefinite, its determinant must be non-negative.&lt;/p&gt;

\[X = 
\begin{bmatrix}
x, y \\\
y, z
\end{bmatrix}
\in \mathbb{S}^2_+ \iff x \ge 0, z \ge 0, xz \ge y^2\]

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.10_Positive_Semidefinite_Cone.png&quot; alt=&quot;[Fig3] Positive semidefinite cone [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig3] Positive semidefinite cone [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

</content>
 </entry>
 
 <entry>
   <title>02-02-01 Convex set examples</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_02_01_Convex_sets_examples/"/>
   <updated>2021-02-11T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_02_01_Convex_sets_examples</id>
   <content type="html">&lt;p&gt;Convex sets include a variety of forms, from trivial ones like points and lines to hyperplanes, halfspaces, balls, ellipsoids, polyhedra, and cones.&lt;/p&gt;

&lt;h2 id=&quot;hyperplanes&quot;&gt;Hyperplanes&lt;/h2&gt;

&lt;p&gt;A hyperplane is an \((n-1)\)-dimensional subset that divides an \(n\)-dimensional space in half, defined as follows. Here, \(a\) is the normal vector and \(b\) is the offset from the origin. A hyperplane is both a convex set and an affine set.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;{\(x : a^T x = b\)} with \(a \in \mathbb{R}^n, a \ne 0, b \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the figure below, any \(x\) on the hyperplane satisfies that \((x - x_0)\) is orthogonal to \(a\). Thus, \(a^T (x - x_0) = 0\), so if \(a^T x = b\), then \(b = a^T x_0\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.05_Hyperplane.png&quot; alt=&quot;[Fig1] Hyperplane [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Hyperplane [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;halfspaces&quot;&gt;Halfspaces&lt;/h2&gt;

&lt;p&gt;A halfspace is one side of a space divided by a hyperplane. Thus, a single hyperplane \(a^T x = b\) defines two halfspaces. A halfspace is a convex set but not an affine set.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;{\(x : a^T x \le b\)} or {\(x : a^T x \ge b\)}  with \(a \in \mathbb{R}^n, a \ne 0, b \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For the hyperplane \(a^T x = b\), the halfspace \(a^T x \ge b\) is in the direction of the normal vector \(a\), while \(a^T x \le b\) is in the direction of \(-a\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.06_Halfspace.png&quot; alt=&quot;[Fig2] Halfspace [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Halfspace [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Note: The interior of \(\{x : a^T x \le b\}\), that is \(\{x : a^T x \lt b\}\), is called an open halfspace.&lt;/p&gt;

&lt;h3 id=&quot;key-property-halfspaces-are-convex&quot;&gt;Key Property: Halfspaces are Convex&lt;/h3&gt;

&lt;p&gt;Take any two points $x_1$ and $x_2$ in the halfspace:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Both satisfy: $a^T x_1 \leq b$ and $a^T x_2 \leq b$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For any convex combination: $x_\theta = \theta x_1 + (1 - \theta)x_2$ where $\theta \in [0, 1]$&lt;/p&gt;

&lt;p&gt;Check if this point is in the halfspace:
\(a^T x_\theta = a^T(\theta x_1 + (1 - \theta)x_2) = \theta(a^T x_1) + (1 - \theta)(a^T x_2) \leq \theta b + (1 - \theta)b = b\)&lt;/p&gt;

&lt;p&gt;Since $x_\theta$ satisfies the inequality, all points between $x_1$ and $x_2$ are in the halfspace → halfspace is convex.&lt;/p&gt;

&lt;h2 id=&quot;euclidean-balls&quot;&gt;Euclidean balls&lt;/h2&gt;

&lt;p&gt;A Euclidean ball is another convex set, defined as follows. (\(\| . \|_2\) is the Euclidean norm, \(\|u\|_2 = (u^T u)^{1/2}\).) \(x_c\) is the center and \(r\) is the radius. Thus, \(B(x_c, r)\) contains all points within radius \(r\) from center \(x_c\).&lt;/p&gt;

&lt;blockquote&gt;
\[B(x_c, r) = \{ x \mid \|x - x_c \|_2 \le r \} = \{ x \mid (x - x_c)^T (x - x_c) \le r^2 \} \text{ with } r \ge 0\]
&lt;/blockquote&gt;

&lt;p&gt;Alternatively, the Euclidean ball can be expressed as:&lt;/p&gt;

&lt;blockquote&gt;
\[B(x_c, r) = \{ x_c + ru \mid \| u \|_2 \le 1 \}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;ellipsoids&quot;&gt;Ellipsoids&lt;/h2&gt;

&lt;p&gt;An ellipsoid is a convex set related to the Euclidean ball, defined as:&lt;/p&gt;

&lt;blockquote&gt;
\[\mathcal{E} = \{x \mid (x - x_c)^T P^{-1} (x - x_c) \le 1 \}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(P = P^T \succ 0\) means \(P\) is symmetric and positive definite. The vector \(x_c\) is the center of the ellipsoid, and the matrix \(P\) determines how far the ellipsoid extends in each direction from the center. The axes of the ellipsoid are \(\sqrt{\lambda_i}\), where \(\lambda_i\) are the eigenvalues of \(P\). Thus, a ball is a special case of an ellipsoid with \(P = r^2 I\).&lt;/p&gt;

&lt;p&gt;The figure below shows an ellipsoid. The center \(x_c\) is a point, and the major and minor axes are drawn as line segments.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.07_Ellipsoid.png&quot; alt=&quot;[Fig3] Ellipsoid [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig3] Ellipsoid [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;The ellipsoid can also be expressed as:&lt;/p&gt;

&lt;blockquote&gt;
\[\mathcal{E} = \{ x_c + Au \mid \|u\|_2 \le 1 \}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(A\) is a square nonsingular matrix. If \(A = P^{1/2}\), the expression matches the previous one, and \(A\) is symmetric and positive definite. If \(A\) is symmetric positive semidefinite and singular, it is called a degenerate ellipsoid, and its affine dimension equals the rank of \(A\). A degenerate ellipsoid is still convex.&lt;/p&gt;

&lt;h2 id=&quot;norm-balls&quot;&gt;Norm balls&lt;/h2&gt;

&lt;p&gt;A norm ball is the set of points within radius \(r\) from center \(x_c\), defined using an arbitrary norm. While a Euclidean ball uses the Euclidean norm, a norm ball can use any norm. If \(\|.\|\) is any norm on \(\mathbb{R}^n\), the norm ball is defined as:&lt;/p&gt;

&lt;blockquote&gt;
\[\{ x \mid \|x - x_c \| \le r  \}\]
&lt;/blockquote&gt;

&lt;p&gt;When the p-norm is defined as:&lt;/p&gt;

&lt;blockquote&gt;
\[\| x  \|_{p} = \left( \sum_{i=0}^n |x_i|^{p} \right)^{1/p} \text{ for  } p \ge 1\]
&lt;/blockquote&gt;

&lt;p&gt;The shape of the norm ball depends on the value of \(p\). The figure below shows the shape of the norm ball in 3D for different values of \(p\). The norm ball is convex if \(p \ge 1\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.07_2_norm_ball.png&quot; alt=&quot;[Fig4] Norm ball [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig4] Norm ball [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;The next figure shows the shape of the norm ball in 2D for different values of \(p\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.07_3_norm_ball2.png&quot; alt=&quot;[Fig4] Norm ball [2]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig4] Norm ball [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;polyhedra&quot;&gt;Polyhedra&lt;/h2&gt;

&lt;p&gt;A polyhedron is defined as the intersection of linear inequalities and equalities. Affine sets (subspaces, hyperplanes, lines), rays, line segments, and halfspaces are all polyhedra. Polyhedra are convex sets, and a bounded polyhedron is called a polytope.&lt;/p&gt;

&lt;blockquote&gt;
\[\mathcal{P} = \{ x \mid a^T_i x \le b_i, i = 1, ..., m, c_j^Tx  = d_j, j = 1, ..., p\}\]
&lt;/blockquote&gt;

&lt;p&gt;A single equality \(c_j^Tx  = d_j\) can be represented by two inequalities \(c^T_jx \le d_j\) and \(c^T_jx \ge d_j\). Thus, polyhedra can be defined using only inequalities.&lt;/p&gt;

&lt;p&gt;The figure below shows a pentagonal polyhedron formed by the intersection of five halfspaces, with outward normal vectors \(a_1, ..., a_5\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.09_Polyhedra.png&quot; alt=&quot;[Fig5] Polyhedra [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig5] Polyhedra [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;In matrix form, a polyhedron can be defined as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\mathcal{P} =  \{ x \mid A^Tx \preceq b, C^Tx  = d \}\)
where
\(A = 
\begin{bmatrix}
a^T_1 \\
\vdots \\
a^T_m
\end{bmatrix},\)
\(C = 
\begin{bmatrix}
c^T_1 \\
\vdots \\
c^T_p
\end{bmatrix}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;simplexes&quot;&gt;Simplexes&lt;/h3&gt;

&lt;p&gt;A simplex is the simplest polygon that can be formed in \(n\)-dimensional space, constructed from \(n+1\) points.&lt;/p&gt;

&lt;p&gt;If there are \(k + 1\) points \(v_0, ..., v_k \in \mathbb{R}^n\) that are affinely independent, the simplex is defined as the convex hull of these \(k+1\) points. Affinely independent means \(v_1 − v_0, ..., v_k − v_0\) are linearly independent.&lt;/p&gt;

&lt;blockquote&gt;
\[C = \mathbb{conv} \{v_0, ... , v_k\} = \{ \theta_0 v_0 + \cdots + \theta_k v_k  \mid \theta \succeq 0, 1^T \theta = 1 \}\]
&lt;/blockquote&gt;

&lt;p&gt;The figure below shows simplexes from 0 to 3 dimensions: a point in 0D, a line segment in 1D, a triangle in 2D, and a tetrahedron in 3D.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.02_10_Simplex.png&quot; alt=&quot;[Fig6] Simplex [source - wikipedia]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig6] Simplex [source - wikipedia]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;A common example of a simplex is the probability simplex:&lt;/p&gt;

&lt;blockquote&gt;
\[C = \mathbb{conv} \{e_1, ..., e_n \} = \{ \theta \mid \theta \succeq 0, 1^T \theta = 1\}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>05-06 Quy Hoạch Nón (CP)</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_06_Conic_Programming_(CP)/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_06_Conic_Programming_(CP)</id>
   <content type="html">&lt;p&gt;Nếu ràng buộc bất đẳng thức trong một LP tổng quát được thay thế bằng một ràng buộc bất đẳng thức tổng quát, bài toán được gọi là &lt;em&gt;Chương trình Nón&lt;/em&gt; (CP).&lt;/p&gt;

&lt;h3 id=&quot;chương-trình-nón&quot;&gt;Chương trình Nón&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Fx + g \preceq_K 0} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;c, x \in \mathbb{R}^{n}, A \in \mathbb{R}^{p \times n}, \text{ và } b \in \mathbb{R}^{p}.
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;\(F: \mathbb{R}^n \rightarrow Y\) là một ánh xạ tuyến tính, \(g \in Y\), với không gian Euclidean \(Y\).&lt;/li&gt;
  &lt;li&gt;LP là trường hợp đặc biệt khi \(K = \mathbb{R}_{+}^n\), tức là, LP \(\subseteq\) CP.&lt;/li&gt;
  &lt;li&gt;SDP là trường hợp đặc biệt khi \(K = \mathbb{S}_{+}^n\), tức là, SDP \(\subseteq\) CP.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>05-05 Quy Hoạch Bán Xác Định (SDP)</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_05_Semidefinite_Programming_(SDP)/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_05_Semidefinite_Programming_(SDP)</id>
   <content type="html">&lt;p&gt;Nếu ràng buộc bất đẳng thức trong một LP tổng quát được thay thế bằng một bất đẳng thức ma trận tuyến tính (LMI), bài toán được gọi là &lt;em&gt;Chương trình Bán xác định&lt;/em&gt; (SDP).&lt;/p&gt;

&lt;h3 id=&quot;chương-trình-bán-xác-định&quot;&gt;Chương trình Bán xác định&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{x_1 F_1 + \dotsb + x_n F_n + G \preceq 0} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;G, F_1, \dotsb, F_n \in \mathbb{S}^{k} \text{ và } A \in \mathbb{R}^{p \times n}.
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Nếu \(G, F_1, \dotsb, F_n\) đều là các ma trận đường chéo, ràng buộc bất đẳng thức trên tương đương với \(n\) bất đẳng thức tuyến tính, và SDP rút gọn thành một LP.&lt;/li&gt;
  &lt;li&gt;Nhiều LMI có thể được biểu diễn thành một LMI duy nhất sử dụng các ma trận đường chéo khối:
    &lt;blockquote&gt;
      &lt;p&gt;\(x_1\hat{F_1} + \dotsb + x_n\hat{F_n} + \hat{G} \preceq 0, \quad x_1\tilde{F_1} + \dotsb + x_n\tilde{F_n} + \tilde{G} \preceq 0\)
is equivalent to a single LMI:
\(x_1
\begin{bmatrix}
    \hat{F_1} &amp;amp; 0 \\\\
    0 &amp;amp; \tilde{F_1} \\\\
\end{bmatrix} + 
x_2
\begin{bmatrix}
    \hat{F_2} &amp;amp; 0 \\\\
    0 &amp;amp; \tilde{F_2} \\\\
\end{bmatrix} + 
\dotsb
+
x_n
\begin{bmatrix}
    \hat{F_n} &amp;amp; 0 \\\\
    0 &amp;amp; \tilde{F_n} \\\\
\end{bmatrix} + 
\begin{bmatrix}
    \hat{G} &amp;amp; 0 \\\\
    0 &amp;amp; \tilde{G} \\\\
\end{bmatrix}
\preceq 0\)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sdp-ở-dạng-chuẩn&quot;&gt;SDP ở Dạng chuẩn&lt;/h2&gt;
&lt;p&gt;Khi được biểu diễn như sau, nó được gọi là dạng chuẩn của một chương trình bán xác định.&lt;/p&gt;

&lt;h3 id=&quot;sdp-dạng-chuẩn&quot;&gt;SDP dạng chuẩn&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{X} &amp;amp;&amp;amp;{\mathrm{tr}(CX)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\mathrm{tr}(A_i X) = b_i, \quad i = 1, \dotsc, m} \\\\
   &amp;amp; &amp;amp;&amp;amp;{X \succeq 0},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;C, A_i \in \mathbb{S}^n, X \in \mathbb{S}^n.
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Nhắc lại: \(\mathrm{tr}(CX) = \sum_{i,j=1}^n C_{ij}X_{ij}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tất cả các SDP đều có thể được biến đổi thành SDP dạng chuẩn thông qua quá trình sau.&lt;/p&gt;

&lt;h3 id=&quot;chuyển-đổi-sdp-về-dạng-chuẩn&quot;&gt;Chuyển đổi SDP về dạng chuẩn&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Step1.&lt;/strong&gt;  Use a slack variable S to convert the inequality constraint into an equality constraint.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\sum_{l=1}^n F_l x_l+ S = -G} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b}\\\\
   &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step2.&lt;/strong&gt; Transform the equality constraints derived in Step 1 into component-wise equations.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\sum_{l=1}^n (F_l x_l)_{ij} + S_{ij} = -G_{ij}, i,j = 1, \dotsc, k} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b}\\\\
   &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step3.&lt;/strong&gt; Replace x with two nonnegative variables.
\(x = x^{+}  - x^{-}\), where \(x^{+} \text{ and } x^{-} \succeq 0.\)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T (x^{+}  - x^{-}) + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\sum_{l=1}^n (F_l x^{+} _l)_{ij} - \sum_{l=1}^n (F_l x^{-} _l)_{ij} + S_{ij} = -G_{ij}, i,j = 1, \dotsc, k} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax^{+}  - Ax^{-} = b}\\\\
   &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}\\\\
   &amp;amp; &amp;amp;&amp;amp;{x^{+} \text{, } x^{-} \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step4.&lt;/strong&gt; Define \(X, C, \tilde{A}, \tilde{b}\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;All the blanks are zero.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(X = 
\begin{bmatrix}
diag(x^{+})\\\\
 &amp;amp; diag(x^{-})\\\\
&amp;amp;&amp;amp; s_{11}\\\\
&amp;amp;&amp;amp;&amp;amp; s_{12}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;\dotsc\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;s_{ij}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;\dotsc \\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;s_{kk}\\\\
\end{bmatrix}
,\)
\(C = 
\begin{bmatrix}
diag(c)\\\\
&amp;amp; -diag(c) &amp;amp;\\\\
&amp;amp; &amp;amp; O_{k^2 \text{ x } k^2}\\\\
\end{bmatrix}
,\)
\(P_{ij} = 
\begin{bmatrix}
(F_1)_{ij}\\\\
&amp;amp;(F_2)_{ij}\\\\
&amp;amp;&amp;amp;\dotsc\\\\
&amp;amp;&amp;amp;&amp;amp;(F_n)_{ij}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;-(F_1)_{ij}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;-(F_2)_{ij}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;\dotsc\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;-(F_n)_{ij}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0&amp;amp;\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;\dotsc\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;1 \phantom{1} (\text{ij th position})\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;\dotsc\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0\\\\
\end{bmatrix}
,\)&lt;/p&gt;

  &lt;p&gt;\(Q_{i}= 
\begin{bmatrix}
diag(A_i)\\\\
&amp;amp;-diag(A_i)\\\\
&amp;amp;&amp;amp;O_{k^2 \text{ x } k^2}\\\\
\end{bmatrix}\)
(\(A_i\) is ith row of A),
\(\tilde{A} = 
\begin{bmatrix}
P_{11}\\\\
\dotsc\\\\
P_{kk}\\\\
Q_{1}\\\\
\dotsc\\\\
Q_{p}\\\\
\end{bmatrix}
-G_{ij} = \mathrm{tr}(P_{ij}X)
,\)&lt;/p&gt;

  &lt;p&gt;\(b_i = \mathrm{tr}(Q_iX)\),&lt;/p&gt;

  &lt;p&gt;\(\tilde{b} = 
\begin{bmatrix}
-G_{11}\\\\
\dotsc\\\\
-G_{kk}\\\\
b_{1}\\\\
\dotsc\\\\
b_{p}\\\\
\end{bmatrix}\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step5.&lt;/strong&gt; Substitute the problem from &lt;em&gt;Step3&lt;/em&gt; with \(X, C, \tilde{A}, \tilde{b}\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{X} &amp;amp;&amp;amp;{\mathrm{tr}(CX)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\mathrm{tr}(\tilde{A}_iX) = \tilde{b}_i, \quad i=1,\dotsc,k^2+p} \\\\
   &amp;amp; &amp;amp;&amp;amp;{X \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;socp-và-sdp-tương-đương&quot;&gt;SOCP và SDP tương đương&lt;/h2&gt;
&lt;p&gt;Bằng cách sử dụng bù Schur[&lt;a href=&quot;https://en.wikipedia.org/wiki/Schur_complement&quot;&gt;8&lt;/a&gt;], ràng buộc bất đẳng thức của SOCP có thể được biểu diễn theo cách mà SOCP được biến đổi thành một trường hợp đặc biệt của SDP. Tức là, có một mối quan hệ bao hàm: SOCP \(\subseteq\) SDP.&lt;/p&gt;

&lt;h3 id=&quot;nhắc-lại-chương-trình-nón-bậc-hai&quot;&gt;Nhắc lại: Chương trình Nón Bậc hai&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{f^T x} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\| A_i x + b_i \|_2 \leq c_i^T x + d_i, i = 1, \dotsc, m}\\\\
   &amp;amp; &amp;amp;&amp;amp;{Fx = g}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;socp-thành-sdp-bằng-bù-schur&quot;&gt;SOCP thành SDP bằng bù Schur&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{f^T x} \\\\
   &amp;amp;\text{subject to } 
   &amp;amp;&amp;amp;
   \begin{bmatrix}
   (c_i^T x + d)I    &amp;amp; A_i x + b_i \\\\
   (A_i x + b_i)^T &amp;amp; c_i^T x + d \\\\
   \end{bmatrix} \succeq 0, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Fx = g}.
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>05-04 Quy Hoạch Nón Bậc Hai (SOCP)</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_04_Second_Order_Cone_Programming_(SOCP)/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_04_Second_Order_Cone_Programming_(SOCP)</id>
   <content type="html">&lt;p&gt;Nếu các ràng buộc bất đẳng thức trong một LP tổng quát được thay thế bằng các ràng buộc nón bậc hai (là các hàm affine), bài toán được gọi là &lt;em&gt;Chương trình Nón Bậc hai&lt;/em&gt; (SOCP).&lt;/p&gt;

&lt;h3 id=&quot;chương-trình-nón-bậc-hai&quot;&gt;Chương trình Nón Bậc hai&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{f^T x} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\| A_i x + b_i \|_2 \leq c_i^T x + d_i, i = 1, \dotsc, m}\\\\
   &amp;amp; &amp;amp;&amp;amp;{Fx = g},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;x \in \mathbb{R}^n \text{ là biến tối ưu, } A_i  \in \mathbb{R}^{n_i \times n}, \text{ và } F \in \mathbb{R}^{p \times n}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;nhắc-lại-nón-chuẩn&quot;&gt;Nhắc lại: Nón chuẩn&lt;/h3&gt;
&lt;p&gt;Một &lt;em&gt;nón chuẩn&lt;/em&gt; là một nón lồi trong \(\mathbb{R}^{n+1}\) được định nghĩa bởi tất cả các điểm \((x, t)\) sao cho \(\| x \| \le t\) với một chuẩn nào đó \(\| \cdot \|\).&lt;/p&gt;

&lt;blockquote&gt;
\[\left\{(x, t) : \| x \| \le t \right\} \text{, với chuẩn } \| \cdot \|\]
&lt;/blockquote&gt;

&lt;p&gt;Hình dưới đây cho thấy nón chuẩn cho chuẩn \(l_2\) \(\| \cdot \|_2\), cũng được gọi là nón bậc hai hoặc nón kem.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter05/05_04_Norm_Cone.png&quot; alt=&quot;[Fig1] Nón Chuẩn [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Nón Chuẩn [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;qcqp-và-socp-tương-đương&quot;&gt;QCQP và SOCP tương đương&lt;/h2&gt;
&lt;p&gt;Một QCQP có thể được tái công thức thành một SOCP trong một số trường hợp, tức là, \(QCQP \subseteq SOCP\).&lt;/p&gt;

&lt;h3 id=&quot;nhắc-lại-chương-trình-bậc-hai-với-ràng-buộc-bậc-hai&quot;&gt;Nhắc lại: Chương trình Bậc hai với Ràng buộc Bậc hai&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{(1/2)x^T P_0 x + q_0^T x + r_0} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{(1/2)x^T P_i x + q_i^T x + r_i \leq 0}, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;P_i \in \mathbb{S}_{+}^n \text{ với } i = 0, \dotsc, m, \text{ và } A \in \mathbb{R}^{p \times n}
\end{align}\]

  &lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; For convenience, QCQP can be reformulated in different ways to fit SOCP structure.
\(\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{x^T P_0 x + 2q_0^T x + r_0} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{x^T P_i x + 2q_i^T x + r_i \leq 0}, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp; P_i \in \mathbb{S}_{+}^n \text{ for } i = 0, \dotsc, m \text{, and } A \in \mathbb{R}^{\text{p x n}}.
\end{align}\\\)&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; Since \(P_0\) is a positive semidefinite matrix, any \(\tilde{P_0}\) satisfying \(P_0 = \tilde{P_0}\tilde{P_0}\) is also a positive semidefinite matrix. This \(\tilde{P_0}\) can be obtained through eigendecomposition. Using this, the objective function of the QCQP can be transformed as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[P_0 = Q_0 \Lambda_0 \Lambda_0 Q_0^T\]
  &lt;/li&gt;
  &lt;li&gt;
\[I = Q_0 \Lambda_0 \Lambda_0^{-1} Q_0^{-1} = Q_0 \Lambda_0^{-1} \Lambda_0 Q_0^{-1}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\begin{align}
{x^T P_0 x + 2q_0^T x + r_0} &amp;amp;= {x^T P_0 x + q_0^T x + x^T q_0 + q_0^T P_0^{-1} q_0 - q_0^T P_0^{-1} q_0 + r_0}\\\\
&amp;amp;= {x^T Q_0 \Lambda_0 \Lambda_0 Q_0^T x} +
     {q_0^T Q_0 \Lambda_0^{-1} \Lambda_0 Q_0^{-1} x} + {x^T Q_0 \Lambda_0 \Lambda_0^{-1} Q_0^{-1} q_0} +
     {q_0^T Q_0 \Lambda_0^{-1} \Lambda_0^{-1} Q_0^T q_0} - {q_0^T P_0^{-1} q_0 + r_0}\\\\
&amp;amp;=(\Lambda_0 Q_0^T x + \Lambda_0^{-1} Q_0^T q_0)^T(\Lambda_0 Q_0^T x + \Lambda_0^{-1} Q_0^T q_0) - {q_0^T P_0^{-1} q_0 + r_0}\\\\
&amp;amp;=\| \Lambda_0 Q_0^T x + \Lambda_0^{-1} Q_0^T q_0 \|_2^2 - {q_0^T P_0^{-1} q_0 + r_0}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; The same procedure as in Step 2 is applied to the inequality constraint functions, and then substituted into the QCQP from Step 1.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{\| \Lambda_0 Q_0^T x + \Lambda_0^{-1} Q_0^T q_0 \|_2^2 - {q_0^T P_0^{-1} q_0 + r_0}} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\| \Lambda_i Q_i^T x + \Lambda_i^{-1} Q_i^T q_i \|_2^2 \leq {q_i^T P_i^{-1} q_i + r_i}}, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b}.\\\\
\end{align}\]

&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt; The term \({q_0^T P_0^{-1} q_0 + r_0}\) in the objective function is a constant and can be omitted.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{\| \Lambda_0 Q_0^T x + \Lambda_0^{-1} Q_0^T q_0 \|_2^2} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\| \Lambda_i Q_i^T x + \Lambda_i^{-1} Q_i^T q_i \|_2^2 \leq {q_i^T P_i^{-1} q_i + r_i} }, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 5.&lt;/strong&gt; Introducing a scalar variable \(t\), the same problem as in Step 4 can be defined.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x, t} &amp;amp;&amp;amp;{t} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;\lVert{\Lambda_{0} Q_0^T x + \Lambda_0^{-1} Q_0^T q_0} \rVert_2^2 \leq t\\\\
   &amp;amp; &amp;amp;&amp;amp;{\| \Lambda_i Q_i^T x + \Lambda_i^{-1} Q_i^T q_i \|_2^2 \leq {q_i^T P_i^{-1} q_i + r_i} }, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Phần trên đại diện cho một trường hợp đặc biệt của SOCP. Do đó, mối quan hệ \(QCQP \subseteq SOCP\) được thỏa mãn.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>05-03 Quy Hoạch Bậc Hai với Ràng buộc Bậc Hai (QCQP)</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_03_Quadratically_Constrained_Quadratic_Programming_(QCQP)/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_03_Quadratically_Constrained_Quadratic_Programming_(QCQP)</id>
   <content type="html">&lt;p&gt;Nếu các hàm ràng buộc bất đẳng thức trong một chương trình bậc hai được thay thế bằng các hàm bậc hai lồi, bài toán được gọi là &lt;em&gt;Chương trình Bậc hai với Ràng buộc Bậc hai&lt;/em&gt; (QCQP).&lt;/p&gt;

&lt;h3 id=&quot;chương-trình-bậc-hai-với-ràng-buộc-bậc-hai&quot;&gt;Chương trình Bậc hai với Ràng buộc Bậc hai&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{(1/2)x^T P_0 x + q_0^T x + r_0} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{(1/2)x^T P_i x + q_i^T x + r_i \leq 0}, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;P_i \in \mathbb{S}_{+}^n \text{ với } i = 0, \dotsc, m, \text{ và } A \in \mathbb{R}^{p \times n}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;qp-và-qcqp-tương-đương&quot;&gt;QP và QCQP tương đương&lt;/h2&gt;
&lt;p&gt;Nếu \(P_i = 0\) với mọi \(i = 1, \dotsc, m\) trong các ràng buộc QCQP, bài toán rút gọn thành một QP. Do đó, QP là một trường hợp đặc biệt của QCQP, và \(QP \subseteq QCQP\).&lt;/p&gt;

&lt;h3 id=&quot;nhắc-lại-chương-trình-bậc-hai&quot;&gt;Nhắc lại: Chương trình Bậc hai&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{(1/2)x^T P x + q^T x + r} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Gx \preceq h} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;P \in \mathbb{S}_{+}^n, G \in \mathbb{R}^{m \times n}, \text{ và } A \in \mathbb{R}^{p \times n}.
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>05-02 Quy Hoạch Bậc Hai (QP)</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_02_Quadratic_Programming_(QP)-copy/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_02_Quadratic_Programming_(QP) copy</id>
   <content type="html">&lt;p&gt;Một &lt;strong&gt;Chương trình Bậc hai&lt;/strong&gt; (QP) là một bài toán tối ưu lồi trong đó hàm mục tiêu là một hàm bậc hai lồi và tất cả các hàm ràng buộc đều là affine. Chương trình bậc hai tổng quát được phát biểu như:&lt;/p&gt;

&lt;h3 id=&quot;chương-trình-bậc-hai-tổng-quát&quot;&gt;Chương trình Bậc hai Tổng quát&lt;/h3&gt;
&lt;p&gt;\(\begin{align}
    \text{minimize}_{x} \quad &amp;amp;\frac{1}{2}x^T P x + q^T x + r \\
    \text{subject to} \quad &amp;amp;Gx \preceq h \\
    &amp;amp;Ax = b
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;trong đó:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(P \in \mathbb{S}_{+}^n\) (ma trận bán xác định dương)&lt;/li&gt;
  &lt;li&gt;\(G \in \mathbb{R}^{m \times n}\) (ma trận ràng buộc bất đẳng thức)&lt;/li&gt;
  &lt;li&gt;\(A \in \mathbb{R}^{p \times n}\) (ma trận ràng buộc đẳng thức)&lt;/li&gt;
  &lt;li&gt;\(x \in \mathbb{R}^n\) (biến quyết định)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Tính chất Chính của QP:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hằng số \(r\) trong hàm mục tiêu không ảnh hưởng đến quá trình tối ưu hóa hoặc kết quả và có thể bỏ qua.&lt;/li&gt;
  &lt;li&gt;Nếu \(P \in \mathbb{S}_{+}^n\) không được thỏa mãn, bài toán không lồi.&lt;/li&gt;
  &lt;li&gt;Ngay cả khi không được nêu rõ, QP giả định \(P \in \mathbb{S}_{+}^n\).&lt;/li&gt;
  &lt;li&gt;Bài toán trên tìm nghiệm tối ưu \(x^*\) của hàm bậc hai lồi \(\frac{1}{2}x^T P x + q^T x + r\) trên một tập khả thi đa diện.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hiểu-về-mathbbs_n-nón-bán-xác-định-dương&quot;&gt;Hiểu về \(\mathbb{S}_{+}^n\) (Nón Bán xác định Dương)&lt;/h3&gt;

&lt;p&gt;Ký hiệu \(\mathbb{S}_{+}^n\) đại diện cho &lt;strong&gt;nón bán xác định dương&lt;/strong&gt;, đây là một khái niệm cơ bản trong tối ưu lồi:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Định nghĩa:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\mathbb{S}_{+}^n = \{ X \in \mathbb{S}^n : X \succeq 0 \}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;trong đó:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbb{S}^n\) là tập tất cả các &lt;strong&gt;ma trận đối xứng&lt;/strong&gt; \(n \times n\)&lt;/li&gt;
  &lt;li&gt;\(X \succeq 0\) có nghĩa là ma trận \(X\) là &lt;strong&gt;bán xác định dương&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Tính chất Chính:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Điều kiện bán xác định dương&lt;/strong&gt;: Một ma trận \(P\) là bán xác định dương nếu:
    &lt;ul&gt;
      &lt;li&gt;Tất cả các giá trị riêng của \(P\) đều không âm (\(\lambda_i \geq 0\))&lt;/li&gt;
      &lt;li&gt;Với mọi vector \(v\), chúng ta có \(v^T P v \geq 0\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tính chất nón lồi&lt;/strong&gt;: \(\mathbb{S}_{+}^n\) là một nón lồi vì nếu \(\theta_1, \theta_2 \geq 0\) và \(A, B \in \mathbb{S}_{+}^n\), thì \(\theta_1 A + \theta_2 B \in \mathbb{S}_{+}^n\)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ cho \(n=2\):&lt;/strong&gt;
Với ma trận \(2 \times 2\) \(P = \begin{bmatrix} a &amp;amp; b \\ b &amp;amp; c \end{bmatrix}\), điều kiện \(P \in \mathbb{S}_{+}^2\) yêu cầu:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(a \geq 0\) (các phần tử đường chéo không âm)&lt;/li&gt;
  &lt;li&gt;\(c \geq 0\) (các phần tử đường chéo không âm)&lt;/li&gt;
  &lt;li&gt;\(ac \geq b^2\) (định thức không âm)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Tại sao điều này quan trọng đối với QP?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Điều kiện \(P \in \mathbb{S}_{+}^n\) đảm bảo rằng hàm bậc hai \((1/2)x^T P x + q^T x + r\) là &lt;strong&gt;lồi&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Không có điều kiện này, bài toán có thể có nhiều cực tiểu địa phương và sẽ không là một bài toán tối ưu lồi&lt;/li&gt;
  &lt;li&gt;Điều này đảm bảo rằng bất kỳ cực tiểu địa phương nào cũng là cực tiểu toàn cục&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hiểu-về-gx-preceq-h-bất-đẳng-thức-theo-thành-phần&quot;&gt;Hiểu về \(Gx \preceq h\) (Bất đẳng thức Theo thành phần)&lt;/h3&gt;

&lt;p&gt;Ký hiệu \(Gx \preceq h\) đại diện cho &lt;strong&gt;ràng buộc bất đẳng thức theo thành phần&lt;/strong&gt;, đây là cách gọn gàng để viết nhiều ràng buộc bất đẳng thức tuyến tính:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Định nghĩa:&lt;/strong&gt;
\(Gx \preceq h \quad \Leftrightarrow \quad (Gx)_i \leq h_i \text{ với mọi } i = 1, 2, \ldots, m\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;where:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(G \in \mathbb{R}^{m \times n}\) is the constraint matrix&lt;/li&gt;
  &lt;li&gt;\(x \in \mathbb{R}^n\) is the decision variable vector&lt;/li&gt;
  &lt;li&gt;\(h \in \mathbb{R}^m\) is the right-hand side vector&lt;/li&gt;
  &lt;li&gt;\(m\) is the number of inequality constraints&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Expanded Form:&lt;/strong&gt;
The single matrix inequality \(Gx \preceq h\) is equivalent to the system:
\(\begin{align}
g_1^T x &amp;amp;\leq h_1 \\
g_2^T x &amp;amp;\leq h_2 \\
&amp;amp;\vdots \\
g_m^T x &amp;amp;\leq h_m
\end{align}\)&lt;/p&gt;

&lt;p&gt;where \(g_i^T\) is the \(i\)-th row of matrix \(G\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
Consider \(G = \begin{bmatrix} 1 &amp;amp; 2 \\ -1 &amp;amp; 3 \\ 0 &amp;amp; -1 \end{bmatrix}\), \(x = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}\), and \(h = \begin{bmatrix} 5 \\ 2 \\ -1 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;Then \(Gx \preceq h\) means:
\(\begin{align}
x_1 + 2x_2 &amp;amp;\leq 5 \\
-x_1 + 3x_2 &amp;amp;\leq 2 \\
-x_2 &amp;amp;\leq -1 \quad \text{(i.e., } x_2 \geq 1\text{)}
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Geometric Interpretation:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Each inequality \(g_i^T x \leq h_i\) defines a &lt;strong&gt;half-space&lt;/strong&gt; in \(\mathbb{R}^n\)&lt;/li&gt;
  &lt;li&gt;The feasible region is the &lt;strong&gt;intersection&lt;/strong&gt; of all these half-spaces&lt;/li&gt;
  &lt;li&gt;This intersection forms a &lt;strong&gt;polyhedron&lt;/strong&gt; (or polytope if bounded)&lt;/li&gt;
  &lt;li&gt;The constraint \(Gx \preceq h\) defines the &lt;strong&gt;polyhedral feasible set&lt;/strong&gt; for the QP&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter05/05_02_geometric_interpretation_of_QP.png&quot; alt=&quot;[Fig 1] Geometric interpretation of QP [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Geometric interpretation of QP [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;qp-in-standard-form&quot;&gt;QP in Standard Form&lt;/h2&gt;

&lt;p&gt;The standard form of a quadratic program is:&lt;/p&gt;

&lt;h3 id=&quot;standard-form-qp&quot;&gt;Standard Form QP&lt;/h3&gt;
&lt;p&gt;\(\begin{align}
    \text{minimize}_{x} \quad &amp;amp;\frac{1}{2}x^T P x + q^T x + r \\
    \text{subject to} \quad &amp;amp;A x = b \\
    &amp;amp;x \succeq 0
\end{align}\)&lt;/p&gt;

&lt;p&gt;Any general quadratic program can be converted to standard form using the following steps:&lt;/p&gt;

&lt;h3 id=&quot;converting-qps-to-standard-form&quot;&gt;Converting QPs to Standard Form&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; Use slack variables \(s\) to convert inequality constraints into equality constraints:
\(\begin{align}
    \text{minimize}_{x, s} \quad &amp;amp;\frac{1}{2}x^T P x + q^T x + r \\
    \text{subject to} \quad &amp;amp;Gx + s = h \\
    &amp;amp;Ax = b \\
    &amp;amp;s \succeq 0
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; Replace \(x\) with two nonnegative variables:
\(x = x^{+} - x^{-}, \quad \text{where } x^{+}, x^{-} \succeq 0\)&lt;/p&gt;

\[\begin{align}
    \text{minimize}_{x^{+}, x^{-}, s} \quad &amp;amp;\frac{1}{2}(x^{+} - x^{-})^T P (x^{+} - x^{-}) + q^T x^{+} - q^T x^{-} + r\\
    \text{subject to} \quad &amp;amp;Gx^{+} - Gx^{-} + s = h \\
    &amp;amp;Ax^{+} - Ax^{-} = b \\
    &amp;amp;s \succeq 0 \\
    &amp;amp;x^{+} \succeq 0, \quad x^{-} \succeq 0
\end{align}\]

&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; Define \(\tilde{x}\), \(\tilde{q}\), \(\tilde{b}\), \(\tilde{A}\), \(\tilde{P}\):&lt;/p&gt;

\[\tilde{x} =
\begin{bmatrix}
x^{+} \\
x^{-} \\
s
\end{bmatrix}, \quad
\tilde{q} =
\begin{bmatrix}
q \\
-q \\
0
\end{bmatrix}, \quad
\tilde{b} =
\begin{bmatrix}
h \\
b
\end{bmatrix}\]

\[\tilde{A} =
\begin{bmatrix}
G &amp;amp; -G &amp;amp; I \\
A &amp;amp; -A &amp;amp; O
\end{bmatrix}, \quad
\tilde{P} =
\begin{bmatrix}
 P &amp;amp; -P &amp;amp; O \\
-P &amp;amp;  P &amp;amp; O \\
 O &amp;amp;  O &amp;amp; O
\end{bmatrix}\]

&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt; Substitute the expressions from Step 3 into the formulation:&lt;/p&gt;

\[\begin{align}
    \text{minimize}_{\tilde{x}} \quad &amp;amp;\frac{1}{2}\tilde{x}^T \tilde{P} \tilde{x} + \tilde{q}^T \tilde{x} + r \\
    \text{subject to} \quad &amp;amp;\tilde{A} \tilde{x} = \tilde{b} \\
    &amp;amp;\tilde{x} \succeq 0
\end{align}\]

&lt;h2 id=&quot;linear-programming-as-a-special-case-of-qp&quot;&gt;Linear Programming as a Special Case of QP&lt;/h2&gt;

&lt;p&gt;If the quadratic term is removed from the objective function of a quadratic program, it takes the form of a linear program. Thus, LP is a special case of QP, denoted as LP \(\subseteq\) QP.&lt;/p&gt;

&lt;h3 id=&quot;recall-general-lp&quot;&gt;Recall: General LP&lt;/h3&gt;
&lt;p&gt;\(\begin{align}
    \text{minimize}_{x} \quad &amp;amp;c^T x + d \\
    \text{subject to} \quad &amp;amp;Gx \preceq h \\
    &amp;amp;Ax = b
\end{align}\)
where \(G \in \mathbb{R}^{m \times n}\) and \(A \in \mathbb{R}^{p \times n}\).&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-1-tối-ưu-hóa-danh-mục-đầu-tư&quot;&gt;Ví dụ 1: Tối ưu hóa Danh mục Đầu tư&lt;/h3&gt;

&lt;p&gt;Bài toán này bao gồm việc cân bằng hợp lý giữa hiệu suất và rủi ro khi tạo một danh mục tài chính.&lt;/p&gt;

\[\begin{align}
    \text{maximize}_{x} \quad &amp;amp;\mu^T x - \frac{\gamma}{2}x^T P x \\
    \text{subject to} \quad &amp;amp;\mathbf{1}^Tx = 1 \\
    &amp;amp;x \succeq 0
\end{align}\]

&lt;p&gt;&lt;strong&gt;trong đó:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mu\): lợi nhuận kỳ vọng của các tài sản&lt;/li&gt;
  &lt;li&gt;\(P\): ma trận hiệp phương sai của lợi nhuận tài sản&lt;/li&gt;
  &lt;li&gt;\(\gamma\): tham số tránh rủi ro (siêu tham số)&lt;/li&gt;
  &lt;li&gt;\(x\): nắm giữ danh mục (phần trăm)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ví-dụ-2-máy-vector-hỗ-trợ&quot;&gt;Ví dụ 2: Máy Vector Hỗ trợ&lt;/h3&gt;

&lt;p&gt;Máy Vector Hỗ trợ (SVM) là một ví dụ của chương trình bậc hai. Dưới đây là C-SVM, một biến thể của SVM. Giải thích chi tiết về SVM nằm ngoài phạm vi của chương này và do đó sẽ được bỏ qua.&lt;/p&gt;

\[\begin{align}
    \text{minimize}_{\beta, \beta_0, \xi} \quad &amp;amp;\frac{1}{2} \| \beta \|_2^2 + C \sum_{i=1}^{n} \xi_i \\
    \text{subject to} \quad &amp;amp;\xi_i \geq 0, \quad i = 1, \ldots, n \\
    &amp;amp;y_i (x_i^T \beta + \beta_0) \geq 1 - \xi_i, \quad i = 1, \ldots, n
\end{align}\]

&lt;p&gt;&lt;strong&gt;cho trước:&lt;/strong&gt; \(y \in \{-1, 1\}^n\) và \(X \in \mathbb{R}^{n \times p}\) có các hàng \(x_1, \ldots, x_n\).&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-3-bình-phương-tối-thiểu-trong-hồi-quy&quot;&gt;Ví dụ 3: Bình phương Tối thiểu trong Hồi quy&lt;/h3&gt;

&lt;p&gt;Bài toán tối thiểu hóa hàm bậc hai lồi sau tương ứng với một QP (không ràng buộc):
\(\| Ax - b \|_2^2 = x^T A^TA x - 2b^TAx + b^Tb\)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>05-02-03 Hồi Quy Tuyến Tính từ Góc Nhìn Thống Kê</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_02_03_Linear_Regression_Statistical_View/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_02_03_Linear_Regression_Statistical_View</id>
   <content type="html">&lt;h2 id=&quot;hồi-quy-tuyến-tính-từ-góc-nhìn-thống-kê&quot;&gt;Hồi Quy Tuyến Tính từ Góc Nhìn Thống Kê&lt;/h2&gt;

&lt;p&gt;Trong bài học này, chúng ta khám phá hồi quy tuyến tính từ góc nhìn xác suất và thống kê, chứng minh tại sao việc tối thiểu hóa tổng bình phương sai số (MSE) không chỉ trực quan mà còn được chứng minh lý thuyết thông qua ước lượng hợp lý tối đa.&lt;/p&gt;

&lt;h3 id=&quot;1-diễn-giải-xác-suất-của-hồi-quy-tuyến-tính&quot;&gt;1. Diễn Giải Xác Suất của Hồi Quy Tuyến Tính&lt;/h3&gt;

&lt;p&gt;Dưới góc nhìn xác suất, chúng ta có thể chứng minh rằng các ước lượng đạt được từ hồi quy tuyến tính dựa trên việc tối thiểu hóa tổng bình phương sai số từ hàm MSE là hoàn toàn tự nhiên và hợp lý.&lt;/p&gt;

&lt;p&gt;Thật vậy, chúng ta giả định biến mục tiêu và biến đầu vào liên hệ với nhau qua phương trình:&lt;/p&gt;

\[y_i = \mathbf{w}^\top \mathbf{x}_i + \epsilon_i\]

&lt;p&gt;trong đó $\epsilon_i$ đại diện cho sai số ngẫu nhiên mà bất kỳ phương trình nào cũng có. Đây là những yếu tố không thể giải thích bởi mô hình. Do ước lượng của chúng ta là không chệch, sai số ngẫu nhiên này được giả định thỏa mãn các tính chất theo giả thuyết của Gauss-Markov:&lt;/p&gt;

&lt;h4 id=&quot;giả-thuyết-1-sai-số-có-kỳ-vọng-bằng-không&quot;&gt;Giả Thuyết 1: Sai Số Có Kỳ Vọng Bằng Không&lt;/h4&gt;
&lt;p&gt;Các sai số $\epsilon_i$ là đại lượng ngẫu nhiên có kỳ vọng bằng 0:&lt;/p&gt;

\[\mathbb{E}(\epsilon_i) = 0\]

&lt;h4 id=&quot;giả-thuyết-2-các-sai-số-không-tương-quan&quot;&gt;Giả Thuyết 2: Các Sai Số Không Tương Quan&lt;/h4&gt;
&lt;p&gt;Các sai số ngẫu nhiên không có sự tương quan:&lt;/p&gt;

\[\mathbb{E}(\epsilon_i \epsilon_j) = 0, \quad \forall i \neq j\]

&lt;h4 id=&quot;giả-thuyết-3-phương-sai-đồng-nhất-homoscedasticity&quot;&gt;Giả Thuyết 3: Phương Sai Đồng Nhất (Homoscedasticity)&lt;/h4&gt;
&lt;p&gt;Phương sai của sai số ngẫu nhiên là bất biến:&lt;/p&gt;

\[\text{Var}(\epsilon_i) = \sigma^2\]

&lt;h4 id=&quot;giả-thuyết-4-độc-lập-giữa-sai-số-và-đặc-trưng&quot;&gt;Giả Thuyết 4: Độc Lập Giữa Sai Số và Đặc Trưng&lt;/h4&gt;
&lt;p&gt;Sai số ngẫu nhiên $\epsilon_i$ và các biến đầu vào $\mathbf{x}_i$ không có sự tương quan:&lt;/p&gt;

\[\text{Cov}(\mathbf{x}_i, \epsilon_i) = 0, \quad \forall i = 1, \dots, p\]

&lt;h3 id=&quot;2-phân-phối-gaussian-của-sai-số&quot;&gt;2. Phân Phối Gaussian của Sai Số&lt;/h3&gt;

&lt;p&gt;Dưới các giả thuyết này, các sai số ngẫu nhiên $\epsilon_i$ tạo thành một phân phối Gaussian (phân phối chuẩn) với trung bình bằng 0 và phương sai $\sigma^2$, ký hiệu là $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. Hàm mật độ xác suất tại mỗi điểm $\epsilon_i$ là:&lt;/p&gt;

\[p(\epsilon_i) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{\epsilon_i^2}{2\sigma^2} \right)\]

&lt;p&gt;Thay $\epsilon_i = y_i - \mathbf{w}^\top \mathbf{x}_i$ vào hàm mật độ xác suất, ta được:&lt;/p&gt;

\[p(y_i \mid \mathbf{x}_i; \mathbf{w}) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{(y_i - \mathbf{w}^\top \mathbf{x}_i)^2}{2\sigma^2} \right)\]

&lt;p&gt;Ký hiệu $p(y_i \mid \mathbf{x}_i; \mathbf{w})$ cho biết xác suất của $y_i$ tương ứng với $\mathbf{x}_i$, được tham số hóa bởi $\mathbf{w}$. Ở đây, $\mathbf{w}$ là đã biết và không được xem như điều kiện của $y_i$, do đó sử dụng dấu ; thay vì ,.&lt;/p&gt;

&lt;h3 id=&quot;3-ước-lượng-hợp-lý-tối-đa&quot;&gt;3. Ước Lượng Hợp Lý Tối Đa&lt;/h3&gt;

&lt;p&gt;Dưới góc độ xác suất, $p(y_i \mid \mathbf{x}_i; \mathbf{w})$ là hàm phụ thuộc vào dữ liệu đầu vào $\mathbf{x}_i$ khi đã biết trọng số $\mathbf{w}$. Khi xem xác suất dưới góc nhìn của một hàm theo $\mathbf{w}$, ta gọi đó là hàm hợp lý (likelihood):&lt;/p&gt;

\[L(\mathbf{w}) = L(\mathbf{w}; \mathbf{X}, \mathbf{y}) = p(\mathbf{y} \mid \mathbf{X}; \mathbf{w})\]

&lt;p&gt;Theo điều kiện 2 của giả thuyết Gauss-Markov, các sai số là độc lập, nên xác suất đồng thời của dữ liệu bằng tích các mật độ xác suất của từng điểm dữ liệu:&lt;/p&gt;

\[\begin{align}
L(\mathbf{w}) &amp;amp;= \prod_{i=1}^{n} p(y_i \mid \mathbf{x}_i; \mathbf{w}) \\
&amp;amp;= \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{\epsilon_i^2}{2\sigma^2} \right)
\end{align}\]

&lt;p&gt;Hàm hợp lý phản ánh mối quan hệ xác suất giữa $\mathbf{y}$ và $\mathbf{X}$. Để tìm $\mathbf{w}$ sao cho mối quan hệ này phù hợp nhất, theo ước lượng hợp lý tối đa (Maximum Likelihood Estimation), ta chọn $\mathbf{w}$ sao cho $L(\mathbf{w})$ lớn nhất.&lt;/p&gt;

&lt;h3 id=&quot;4-tối-ưu-hóa-log-likelihood&quot;&gt;4. Tối Ưu Hóa Log-Likelihood&lt;/h3&gt;

&lt;p&gt;Lấy logarit hai vế để đơn giản hóa bài toán tối ưu:&lt;/p&gt;

\[\begin{align}
\hat{\mathbf{w}} &amp;amp;= \arg \max \log L(\mathbf{w}) \\
&amp;amp;= \arg \max \log \left[ \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{\epsilon_i^2}{2\sigma^2} \right) \right] \\
&amp;amp;= \arg \max \sum_{i=1}^{n} \log \left[ \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{\epsilon_i^2}{2\sigma^2} \right) \right] \\
&amp;amp;= \arg \max \sum_{i=1}^{n} \left[ -\frac{\epsilon_i^2}{2\sigma^2} - \log \sqrt{2\pi \sigma^2} \right] \\
&amp;amp;= \arg \max \left[ -\frac{1}{2\sigma^2} \sum_{i=1}^{n} \epsilon_i^2 - n \log \sqrt{2\pi \sigma^2} \right]
\end{align}\]

&lt;p&gt;Vì $\sigma^2$ và $2\pi$ là hằng số, tối ưu hóa hàm trên tương đương với tối thiểu hóa:&lt;/p&gt;

\[\sum_{i=1}^{n} \epsilon_i^2 = \sum_{i=1}^{n} (y_i - \mathbf{w}^\top \mathbf{x}_i)^2\]

&lt;p&gt;Điều này tương đương với việc tối thiểu hóa hàm MSE:&lt;/p&gt;

\[\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2\]

&lt;h3 id=&quot;5-chứng-minh-lý-thuyết&quot;&gt;5. Chứng Minh Lý Thuyết&lt;/h3&gt;

&lt;p&gt;Như vậy, dưới góc nhìn xác suất, ta đã chứng minh rằng hồi quy tuyến tính dựa trên tối thiểu hóa tổng bình phương sai số tương đương với tối ưu hóa hàm hợp lý. Khi các điều kiện của giả thuyết Gauss-Markov được thỏa mãn, ước lượng của chúng ta là ước lượng không chệch tốt nhất (best linear unbiased estimator - BLUE). Các giả thuyết về khoảng tin cậy của giá trị dự báo và đánh giá ý nghĩa của các trọng số thông qua P-value có thể được thực hiện dựa trên phân phối chuẩn.&lt;/p&gt;

&lt;div id=&quot;mle-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Trực Quan Hóa Ước Lượng Hợp Lý Tối Đa&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;!-- Canvas for visualization --&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;mleCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Trực quan hóa:&lt;/strong&gt; Các chấm xanh là điểm dữ liệu, đường đỏ là đường khớp, và các đường cong thể hiện phân phối Gaussian của sai số.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;!-- Controls --&gt;
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Tham Số&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;noise-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Mức Nhiễu (σ): &lt;span id=&quot;noise-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;noise-slider&quot; min=&quot;0.1&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0.5&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;slope-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Hệ Số Góc Thực: &lt;span id=&quot;true-slope-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;slope-slider&quot; min=&quot;-2&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;intercept-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Hệ Số Chặn Thực: &lt;span id=&quot;true-intercept-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;intercept-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-data&quot; style=&quot;width: 100%; padding: 10px; background: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 10px;&quot;&gt;Tạo Dữ Liệu Mới&lt;/button&gt;
                
                &lt;div id=&quot;mle-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Ước Lượng MLE:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Hệ số góc: &lt;span id=&quot;mle-slope&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Hệ số chặn: &lt;span id=&quot;mle-intercept&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Log-Likelihood: &lt;span id=&quot;log-likelihood&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;6-huấn-luyện-mô-hình-hồi-quy-tuyến-tính-trên-sklearn&quot;&gt;6. Huấn Luyện Mô Hình Hồi Quy Tuyến Tính trên Sklearn&lt;/h3&gt;

&lt;p&gt;Sklearn là một thư viện toàn diện của Python về khoa học dữ liệu, hỗ trợ huấn luyện hầu hết các mô hình học máy, xây dựng pipeline, chuẩn hóa dữ liệu, và thực hiện kiểm định chéo (cross-validation).&lt;/p&gt;

&lt;p&gt;Trong phần này, chúng ta sẽ tìm hiểu cách huấn luyện mô hình hồi quy tuyến tính trên sklearn. Quay lại bài toán trước, nếu thêm thông tin về khoảng cách tới trung tâm:&lt;/p&gt;

\[\mathbf{x}_2 = [20, 18, 17, 16, 15, 14, 12, 10, 8, 7, 5, 2, 1]\]

&lt;p&gt;khi đó bài toán trở thành hồi quy đa biến. Quy trình xây dựng và huấn luyện mô hình gồm các bước:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Thu thập dữ liệu&lt;/li&gt;
  &lt;li&gt;Làm sạch dữ liệu&lt;/li&gt;
  &lt;li&gt;Lựa chọn dữ liệu đầu vào&lt;/li&gt;
  &lt;li&gt;Chuẩn hóa dữ liệu&lt;/li&gt;
  &lt;li&gt;Phân chia tập huấn luyện/kiểm tra (train/test)&lt;/li&gt;
  &lt;li&gt;Huấn luyện và đánh giá mô hình&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Ở bài toán này, chúng ta tập trung vào bước 6 để hiểu cách huấn luyện mô hình.&lt;/p&gt;

&lt;div id=&quot;sklearn-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Ví Dụ Sklearn Hồi Quy Tuyến Tính&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;!-- Code example --&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;pre style=&quot;background: #f8f9fa; padding: 15px; border-radius: 5px; overflow-x: auto; font-size: 12px;&quot;&gt;&lt;code id=&quot;sklearn-code&quot;&gt;import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Dữ liệu mẫu: giá nhà
# Đặc trưng: [diện_tích, khoảng_cách_tới_trung_tâm]
X = np.array([
    [50, 20], [60, 18], [70, 17], [80, 16], [90, 15],
    [100, 14], [110, 12], [120, 10], [130, 8], [140, 7],
    [150, 5], [160, 2], [170, 1]
])

# Mục tiêu: giá (nghìn đô la)
y = np.array([150, 180, 210, 240, 270, 300, 330, 360, 390, 420, 450, 480, 510])

# Chia dữ liệu
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Tạo và huấn luyện mô hình
model = LinearRegression()
model.fit(X_train, y_train)

# Dự đoán
y_pred = model.predict(X_test)

# Đánh giá mô hình
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f&quot;Hệ số: {model.coef_}&quot;)
print(f&quot;Hệ số chặn: {model.intercept_}&quot;)
print(f&quot;MSE: {mse:.2f}&quot;)
print(f&quot;R²: {r2:.3f}&quot;)
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        
        &lt;!-- Interactive results --&gt;
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Kết Quả Mô Hình&lt;/h5&gt;
                
                &lt;button id=&quot;run-sklearn&quot; style=&quot;width: 100%; padding: 10px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Chạy Ví Dụ Sklearn&lt;/button&gt;
                
                &lt;div id=&quot;sklearn-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Tham Số Mô Hình:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Hệ số diện tích: &lt;span id=&quot;area-coeff&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Hệ số khoảng cách: &lt;span id=&quot;distance-coeff&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Hệ số chặn: &lt;span id=&quot;sklearn-intercept&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;Hiệu Suất:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;MSE: &lt;span id=&quot;sklearn-mse&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;R²: &lt;span id=&quot;sklearn-r2&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-top: 15px;&quot;&gt;
                    &lt;h6 style=&quot;margin-bottom: 10px; color: #444;&quot;&gt;Máy Tính Dự Đoán&lt;/h6&gt;
                    &lt;div style=&quot;margin-bottom: 10px;&quot;&gt;
                        &lt;label style=&quot;display: block; margin-bottom: 5px;&quot;&gt;Diện tích (m²):&lt;/label&gt;
                        &lt;input type=&quot;number&quot; id=&quot;pred-area&quot; value=&quot;100&quot; min=&quot;50&quot; max=&quot;200&quot; style=&quot;width: 100%; padding: 5px; border: 1px solid #ddd; border-radius: 3px;&quot; /&gt;
                    &lt;/div&gt;
                    &lt;div style=&quot;margin-bottom: 10px;&quot;&gt;
                        &lt;label style=&quot;display: block; margin-bottom: 5px;&quot;&gt;Khoảng cách tới trung tâm (km):&lt;/label&gt;
                        &lt;input type=&quot;number&quot; id=&quot;pred-distance&quot; value=&quot;10&quot; min=&quot;1&quot; max=&quot;20&quot; style=&quot;width: 100%; padding: 5px; border: 1px solid #ddd; border-radius: 3px;&quot; /&gt;
                    &lt;/div&gt;
                    &lt;button id=&quot;make-prediction&quot; style=&quot;width: 100%; padding: 8px; background: #17a2b8; color: white; border: none; border-radius: 3px; cursor: pointer;&quot;&gt;Dự Đoán Giá&lt;/button&gt;
                    &lt;div id=&quot;prediction-result&quot; style=&quot;margin-top: 10px; padding: 10px; background: #e9ecef; border-radius: 3px; text-align: center; font-weight: bold;&quot;&gt;
                        Giá Dự Đoán: --
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;những-hiểu-biết-quan-trọng&quot;&gt;Những Hiểu Biết Quan Trọng&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Nền Tảng Lý Thuyết&lt;/strong&gt;: Ước lượng hợp lý tối đa cung cấp nền tảng lý thuyết vững chắc cho việc tại sao chúng ta tối thiểu hóa sai số bình phương trong hồi quy tuyến tính.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Giả Thuyết Gaussian&lt;/strong&gt;: Hiệu quả của hồi quy tuyến tính dựa trên các giả thuyết Gauss-Markov, đặc biệt là sai số được phân phối chuẩn.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ước Lượng Không Chệch Tốt Nhất&lt;/strong&gt;: Dưới điều kiện phù hợp, OLS cung cấp BLUE - ước lượng tuyến tính không chệch hiệu quả nhất.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Triển Khai Thực Tế&lt;/strong&gt;: Các công cụ hiện đại như sklearn giúp dễ dàng triển khai các khái niệm lý thuyết này trong thực tế.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Đánh Giá Mô Hình&lt;/strong&gt;: Hiểu nền tảng thống kê giúp đánh giá mô hình đúng cách sử dụng các chỉ số như R², khoảng tin cậy và p-values.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;script&gt;
// MLE Visualization
class MLEVisualization {
    constructor() {
        this.canvas = document.getElementById(&apos;mleCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        // Parameters
        this.trueSlope = 1.0;
        this.trueIntercept = 0.0;
        this.noiseLevel = 0.5;
        this.dataPoints = [];
        
        this.setupControls();
        this.generateData();
        this.draw();
    }
    
    setupControls() {
        const noiseSlider = document.getElementById(&apos;noise-slider&apos;);
        const slopeSlider = document.getElementById(&apos;slope-slider&apos;);
        const interceptSlider = document.getElementById(&apos;intercept-slider&apos;);
        const generateBtn = document.getElementById(&apos;generate-data&apos;);
        
        noiseSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.noiseLevel = parseFloat(e.target.value);
            document.getElementById(&apos;noise-value&apos;).textContent = this.noiseLevel.toFixed(1);
            this.generateData();
            this.draw();
        });
        
        slopeSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.trueSlope = parseFloat(e.target.value);
            document.getElementById(&apos;true-slope-value&apos;).textContent = this.trueSlope.toFixed(1);
            this.generateData();
            this.draw();
        });
        
        interceptSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.trueIntercept = parseFloat(e.target.value);
            document.getElementById(&apos;true-intercept-value&apos;).textContent = this.trueIntercept.toFixed(1);
            this.generateData();
            this.draw();
        });
        
        generateBtn.addEventListener(&apos;click&apos;, () =&gt; {
            this.generateData();
            this.draw();
        });
    }
    
    generateData() {
        this.dataPoints = [];
        const n = 20;
        
        for (let i = 0; i &lt; n; i++) {
            const x = (i / (n - 1)) * 4 - 2; // x from -2 to 2
            const trueY = this.trueSlope * x + this.trueIntercept;
            const noise = (Math.random() - 0.5) * 2 * this.noiseLevel;
            const y = trueY + noise;
            
            this.dataPoints.push({ x, y, trueY });
        }
    }
    
    calculateMLE() {
        const n = this.dataPoints.length;
        let sumX = 0, sumY = 0, sumXY = 0, sumX2 = 0;
        
        for (const point of this.dataPoints) {
            sumX += point.x;
            sumY += point.y;
            sumXY += point.x * point.y;
            sumX2 += point.x * point.x;
        }
        
        const slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
        const intercept = (sumY - slope * sumX) / n;
        
        // Calculate log-likelihood
        let logLikelihood = 0;
        for (const point of this.dataPoints) {
            const predicted = slope * point.x + intercept;
            const error = point.y - predicted;
            logLikelihood -= 0.5 * Math.log(2 * Math.PI * this.noiseLevel * this.noiseLevel);
            logLikelihood -= (error * error) / (2 * this.noiseLevel * this.noiseLevel);
        }
        
        return { slope, intercept, logLikelihood };
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const mle = this.calculateMLE();
        
        // Update display
        document.getElementById(&apos;mle-slope&apos;).textContent = mle.slope.toFixed(3);
        document.getElementById(&apos;mle-intercept&apos;).textContent = mle.intercept.toFixed(3);
        document.getElementById(&apos;log-likelihood&apos;).textContent = mle.logLikelihood.toFixed(2);
        
        // Transform coordinates
        const transform = (x, y) =&gt; ({
            x: (x + 2.5) * this.width / 5,
            y: this.height - (y + 2.5) * this.height / 5
        });
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(0, this.height / 2);
        this.ctx.lineTo(this.width, this.height / 2);
        this.ctx.moveTo(this.width / 2, 0);
        this.ctx.lineTo(this.width / 2, this.height);
        this.ctx.stroke();
        
        // Draw fitted line
        this.ctx.strokeStyle = &apos;#ff4444&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        const start = transform(-2, mle.slope * (-2) + mle.intercept);
        const end = transform(2, mle.slope * 2 + mle.intercept);
        this.ctx.moveTo(start.x, start.y);
        this.ctx.lineTo(end.x, end.y);
        this.ctx.stroke();
        
        // Draw data points and error distributions
        for (const point of this.dataPoints) {
            const pos = transform(point.x, point.y);
            
            // Draw Gaussian error distribution
            const predicted = mle.slope * point.x + mle.intercept;
            const errorCenter = transform(point.x, predicted);
            
            this.ctx.strokeStyle = &apos;#cccccc&apos;;
            this.ctx.lineWidth = 1;
            this.ctx.beginPath();
            for (let i = 0; i &lt;= 20; i++) {
                const t = i / 20;
                const gaussY = predicted + (t - 0.5) * 4 * this.noiseLevel;
                const gaussVal = Math.exp(-0.5 * Math.pow((gaussY - predicted) / this.noiseLevel, 2));
                const gaussPos = transform(point.x + gaussVal * 0.3, gaussY);
                
                if (i === 0) {
                    this.ctx.moveTo(gaussPos.x, gaussPos.y);
                } else {
                    this.ctx.lineTo(gaussPos.x, gaussPos.y);
                }
            }
            this.ctx.stroke();
            
            // Draw data point
            this.ctx.fillStyle = &apos;#4444ff&apos;;
            this.ctx.beginPath();
            this.ctx.arc(pos.x, pos.y, 4, 0, 2 * Math.PI);
            this.ctx.fill();
            
            // Draw error line
            this.ctx.strokeStyle = &apos;#888&apos;;
            this.ctx.lineWidth = 1;
            this.ctx.beginPath();
            this.ctx.moveTo(pos.x, pos.y);
            this.ctx.lineTo(errorCenter.x, errorCenter.y);
            this.ctx.stroke();
        }
    }
}

// Sklearn Demo
class SklearnDemo {
    constructor() {
        this.setupControls();
        this.model = null;
        this.data = this.generateSampleData();
    }
    
    generateSampleData() {
        return {
            X: [
                [50, 20], [60, 18], [70, 17], [80, 16], [90, 15],
                [100, 14], [110, 12], [120, 10], [130, 8], [140, 7],
                [150, 5], [160, 2], [170, 1]
            ],
            y: [150, 180, 210, 240, 270, 300, 330, 360, 390, 420, 450, 480, 510]
        };
    }
    
    setupControls() {
        const runBtn = document.getElementById(&apos;run-sklearn&apos;);
        const predBtn = document.getElementById(&apos;make-prediction&apos;);
        
        runBtn.addEventListener(&apos;click&apos;, () =&gt; this.runSklearnExample());
        predBtn.addEventListener(&apos;click&apos;, () =&gt; this.makePrediction());
    }
    
    runSklearnExample() {
        // Simulate sklearn linear regression
        const { X, y } = this.data;
        
        // Calculate means
        const meanX1 = X.reduce((sum, row) =&gt; sum + row[0], 0) / X.length;
        const meanX2 = X.reduce((sum, row) =&gt; sum + row[1], 0) / X.length;
        const meanY = y.reduce((sum, val) =&gt; sum + val, 0) / y.length;
        
        // Calculate coefficients using normal equation
        let sumX1X1 = 0, sumX2X2 = 0, sumX1X2 = 0;
        let sumX1Y = 0, sumX2Y = 0;
        
        for (let i = 0; i &lt; X.length; i++) {
            const x1 = X[i][0] - meanX1;
            const x2 = X[i][1] - meanX2;
            const yVal = y[i] - meanY;
            
            sumX1X1 += x1 * x1;
            sumX2X2 += x2 * x2;
            sumX1X2 += x1 * x2;
            sumX1Y += x1 * yVal;
            sumX2Y += x2 * yVal;
        }
        
        // Solve 2x2 system
        const det = sumX1X1 * sumX2X2 - sumX1X2 * sumX1X2;
        const coeff1 = (sumX2X2 * sumX1Y - sumX1X2 * sumX2Y) / det;
        const coeff2 = (sumX1X1 * sumX2Y - sumX1X2 * sumX1Y) / det;
        const intercept = meanY - coeff1 * meanX1 - coeff2 * meanX2;
        
        // Calculate MSE and R²
        let mse = 0, tss = 0;
        for (let i = 0; i &lt; X.length; i++) {
            const predicted = coeff1 * X[i][0] + coeff2 * X[i][1] + intercept;
            const error = y[i] - predicted;
            mse += error * error;
            tss += (y[i] - meanY) * (y[i] - meanY);
        }
        mse /= X.length;
        const r2 = 1 - (mse * X.length) / tss;
        
        this.model = { coeff1, coeff2, intercept };
        
        // Update display
        document.getElementById(&apos;area-coeff&apos;).textContent = coeff1.toFixed(3);
        document.getElementById(&apos;distance-coeff&apos;).textContent = coeff2.toFixed(3);
        document.getElementById(&apos;sklearn-intercept&apos;).textContent = intercept.toFixed(3);
        document.getElementById(&apos;sklearn-mse&apos;).textContent = mse.toFixed(2);
        document.getElementById(&apos;sklearn-r2&apos;).textContent = r2.toFixed(3);
    }
    
    makePrediction() {
        if (!this.model) {
            alert(&apos;Vui lòng chạy ví dụ sklearn trước!&apos;);
            return;
        }
        
        const area = parseFloat(document.getElementById(&apos;pred-area&apos;).value);
        const distance = parseFloat(document.getElementById(&apos;pred-distance&apos;).value);
        
        const prediction = this.model.coeff1 * area + this.model.coeff2 * distance + this.model.intercept;
        
        document.getElementById(&apos;prediction-result&apos;).innerHTML = 
            `Giá Dự Đoán: &lt;strong&gt;$${prediction.toFixed(0)}k&lt;/strong&gt;`;
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new MLEVisualization();
    new SklearnDemo();
});
&lt;/script&gt;

&lt;style&gt;
#mle-demo canvas {
    border-radius: 5px;
}

#sklearn-demo pre {
    max-height: 400px;
    overflow-y: auto;
}

.demo-container {
    margin: 20px 0;
}

input[type=&quot;range&quot;] {
    -webkit-appearance: none;
    appearance: none;
    height: 5px;
    background: #ddd;
    outline: none;
    border-radius: 5px;
}

input[type=&quot;range&quot;]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
}

input[type=&quot;range&quot;]::-moz-range-thumb {
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
    border: none;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>05-02-02 Quy Hoạch Hình Học</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_02_02_Geometric_Programming/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_02_02_Geometric_Programming</id>
   <content type="html">&lt;p&gt;Trong phần này, chúng ta sẽ thấy một lớp các bài toán có vẻ không lồi khi nhìn vào hàm mục tiêu và các hàm ràng buộc, nhưng có thể được biến đổi thành dạng lồi thông qua nhiều kỹ thuật.&lt;/p&gt;

&lt;p&gt;Trước tiên, chúng ta cần một số định nghĩa:&lt;/p&gt;

&lt;h2 id=&quot;521-đơn-thức-và-đa-thức-dương&quot;&gt;5.2.1. Đơn thức và Đa thức dương&lt;/h2&gt;

&lt;p&gt;Một hàm \(f: \mathbb{R}^n \to \mathbb{R}\) với miền \(\text{dom } f = \mathbb{R}^n_{++}\) (tất cả các phần tử đều dương) có dạng:&lt;/p&gt;

\[f(x) = c x_1^{a_1} x_2^{a_2} \ldots x_n^{a_n} \quad \quad (24)\]

&lt;p&gt;trong đó \(c &amp;gt; 0\) và \(a_i \in \mathbb{R}\), được gọi là &lt;strong&gt;hàm đơn thức&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Một tổng các đơn thức:&lt;/p&gt;

\[f(x) = \sum_{k=1}^K c_k x_1^{a_{1k}} x_2^{a_{2k}} \ldots x_n^{a_{nk}} \quad \quad (25)\]

&lt;p&gt;trong đó \(c_k &amp;gt; 0\), được gọi là &lt;strong&gt;hàm đa thức dương&lt;/strong&gt;, hoặc đơn giản là &lt;strong&gt;đa thức dương&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;522-quy-hoạch-hình-học&quot;&gt;5.2.2. Quy hoạch Hình học&lt;/h2&gt;

&lt;p&gt;Một bài toán tối ưu có dạng:&lt;/p&gt;

\[\begin{align}
x &amp;amp;= \arg\min_x f_0(x) \\
\text{subject to: } &amp;amp;f_i(x) \leq 1, \quad i = 1, 2, \ldots, m \quad \quad (26) \\
&amp;amp;h_j(x) = 1, \quad j = 1, 2, \ldots, p
\end{align}\]

&lt;p&gt;trong đó \(f_0, f_1, \ldots, f_m\) là các đa thức dương và \(h_1, \ldots, h_p\) là các đơn thức, được gọi là &lt;strong&gt;Quy hoạch Hình học (GP)&lt;/strong&gt;. Điều kiện \(x \succ 0\) là ngầm định.&lt;/p&gt;

&lt;p&gt;Lưu ý rằng nếu \(f\) là một đa thức dương và \(h\) là một đơn thức, thì \(f/h\) là một đa thức dương.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt;&lt;/p&gt;

\[\begin{align}
(x, y, z) &amp;amp;= \arg\min_{x,y,z} x/y \\
\text{subject to: } &amp;amp;1 \leq x \leq 2 \\
&amp;amp;x^3 + 2y/z \leq \sqrt{y} \\
&amp;amp;x/y = z
\end{align}\]

&lt;p&gt;Điều này có thể được viết lại dưới dạng GP:&lt;/p&gt;

\[\begin{align}
(x, y, z) &amp;amp;= \arg\min_{x,y,z} xy^{-1} \\
\text{subject to: } &amp;amp;x^{-1} \leq 1 \\
&amp;amp;(1/2)x \leq 1 \\
&amp;amp;x^3 y^{-1/2} + 2y^{1/2}z^{-1} \leq 1 \\
&amp;amp;xy^{-1}z^{-1} = 1
\end{align}\]

&lt;p&gt;Bài toán này rõ ràng là không lồi vì cả hàm mục tiêu và các hàm ràng buộc đều không lồi.&lt;/p&gt;

&lt;h2 id=&quot;523-biến-đổi-gp-về-dạng-lồi&quot;&gt;5.2.3. Biến đổi GP về Dạng Lồi&lt;/h2&gt;

&lt;p&gt;GP có thể được biến đổi về dạng lồi như sau:&lt;/p&gt;

&lt;p&gt;Gọi \(y_i = \log(x_i)\), tức là, \(x_i = \exp(y_i)\). Nếu \(f\) là một hàm đơn thức của \(x\), thì:&lt;/p&gt;

\[f(x) = c(\exp(y_1))^{a_1} \ldots (\exp(y_n))^{a_n} = \exp(a^T y + b)\]

&lt;p&gt;trong đó \(b = \log(c)\). Bây giờ, hàm \(g(y) = \exp(a^T y + b)\) là một hàm lồi theo \(y\). (Người đọc có thể chứng minh bằng định nghĩa rằng hợp thành của hai hàm lồi là một hàm lồi. Trong trường hợp này, cả hàm \(\exp\) và hàm affine đều là các hàm lồi.)&lt;/p&gt;

&lt;p&gt;Tương tự, đa thức dương trong phương trình (25) có thể được viết như:&lt;/p&gt;

\[f(x) = \sum_{k=1}^K \exp(a_k^T y + b_k)\]

&lt;p&gt;trong đó \(a_k = [a_{1k}, \ldots, a_{nk}]^T\) và \(b_k = \log(c_k)\). Bây giờ, đa thức dương đã được viết dưới dạng tổng các hàm \(\exp\) của các hàm affine (và do đó là một hàm lồi, nhớ lại rằng tổng các hàm lồi là lồi).&lt;/p&gt;

&lt;p&gt;The GP problem (26) is rewritten as:&lt;/p&gt;

\[\begin{align}
y &amp;amp;= \arg\min_y \sum_{k=1}^{K_0} \exp(a_{0k}^T y + b_{0k}) \\
\text{subject to: } &amp;amp;\sum_{k=1}^{K_i} \exp(a_{ik}^T y + b_{ik}) \leq 1, \quad i = 1, \ldots, m \quad \quad (27) \\
&amp;amp;\exp(g_j^T y + h_j) = 1, \quad j = 1, \ldots, p
\end{align}\]

&lt;p&gt;where \(a_{ik} \in \mathbb{R}^n\), \(i = 1, \ldots, p\) and \(g_i \in \mathbb{R}^n\).&lt;/p&gt;

&lt;p&gt;Với nhận xét rằng hàm \(\log \sum_{i=1}^m \exp(g_i(x))\) là một hàm lồi nếu \(g_i\) là các hàm lồi (chúng ta bỏ qua chứng minh), chúng ta có thể viết lại bài toán (27) dưới dạng lồi bằng cách lấy \(\log\) của các hàm như sau:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GP ở dạng lồi:&lt;/strong&gt;&lt;/p&gt;

\[\begin{align}
\text{minimize}_y \quad &amp;amp;\tilde{f}_0(y) = \log\left(\sum_{k=1}^{K_0} \exp(a_{0k}^T y + b_{0k})\right) \\
\text{subject to: } &amp;amp;\tilde{f}_i(y) = \log\left(\sum_{k=1}^{K_i} \exp(a_{ik}^T y + b_{ik})\right) \leq 0, \quad i = 1, \ldots, m \quad \quad (28) \\
&amp;amp;\tilde{h}_j(y) = g_j^T y + h_j = 0, \quad j = 1, \ldots, p
\end{align}\]

&lt;p&gt;Bây giờ chúng ta có thể nói rằng GP tương đương với một bài toán tối ưu lồi vì hàm mục tiêu và các hàm ràng buộc bất đẳng thức trong (28) đều là các hàm lồi, trong khi các ràng buộc đẳng thức ở dạng affine. Dạng này thường được gọi là &lt;strong&gt;chương trình hình học ở dạng lồi&lt;/strong&gt; (để phân biệt với định nghĩa gốc của GP).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>05-02-01 Bài Toán Bình Phương Tối Thiểu Tuyến Tính</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_02_01_Least_Square/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_02_01_Least_Square</id>
   <content type="html">&lt;h2 id=&quot;bài-toán-bình-phương-tối-thiểu-tuyến-tính&quot;&gt;Bài Toán Bình Phương Tối Thiểu Tuyến Tính&lt;/h2&gt;

&lt;p&gt;Bài toán bình phương tối thiểu tuyến tính là một bài toán tối ưu không có ràng buộc, trong đó chúng ta tối thiểu hóa tổng các sai số bình phương:&lt;/p&gt;

\[\text{minimize}_{x} \quad f_0(x) = \|Ax - b\|_2^2 = \sum_{i=1}^{k} (a_i^T x - b_i)^2\]

&lt;p&gt;&lt;strong&gt;trong đó:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(A \in \mathbb{R}^{k \times n}\) là một ma trận với \(k \geq n\)&lt;/li&gt;
  &lt;li&gt;\(a_i^T\) là các hàng của \(A\)&lt;/li&gt;
  &lt;li&gt;\(x \in \mathbb{R}^n\) là biến chúng ta muốn tìm&lt;/li&gt;
  &lt;li&gt;\(b \in \mathbb{R}^k\) là vector mục tiêu&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Mục tiêu:&lt;/strong&gt; Tìm \(x\) để tối thiểu hóa tổng các phần dư bình phương.&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-hồi-quy-tuyến-tính-với-hàm-một-biến&quot;&gt;Ví dụ: Hồi quy Tuyến tính với hàm một biến&lt;/h3&gt;

&lt;p&gt;Tìm đường thẳng khớp nhất \(y = mx + c\) đi qua các điểm dữ liệu. Chúng ta tối thiểu hóa tổng các khoảng cách thẳng đứng bình phương từ các điểm đến đường thẳng.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mục tiêu:&lt;/strong&gt; Tìm \(m, c\).&lt;/p&gt;

&lt;div id=&quot;linear-regression-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Minh họa Hồi quy Tuyến tính Tương tác&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;!-- Canvas for visualization --&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;regressionCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white; cursor: crosshair;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Hướng dẫn:&lt;/strong&gt; Nhấp vào canvas để thêm các điểm dữ liệu. Đường thẳng đỏ hiển thị đường khớp nhất.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;!-- Controls and information --&gt;
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Tham số Hồi quy&lt;/h5&gt;
                &lt;div id=&quot;regression-params&quot; style=&quot;font-family: monospace; font-size: 14px; line-height: 1.6;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Hệ số góc (m):&lt;/strong&gt; &lt;span id=&quot;slope-value&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;Tung độ gốc (c):&lt;/strong&gt; &lt;span id=&quot;intercept-value&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;Điểm R²:&lt;/strong&gt; &lt;span id=&quot;r2-value&quot;&gt;N/A&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;MSE:&lt;/strong&gt; &lt;span id=&quot;mse-value&quot;&gt;N/A&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-top: 15px;&quot;&gt;
                    &lt;h5 style=&quot;color: #444;&quot;&gt;Phương trình&lt;/h5&gt;
                    &lt;div id=&quot;equation&quot; style=&quot;font-family: monospace; font-size: 16px; background: #f0f0f0; padding: 8px; border-radius: 4px;&quot;&gt;
                        y = 0.000x + 0.000
                    &lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-top: 15px;&quot;&gt;
                    &lt;button onclick=&quot;clearPoints()&quot; style=&quot;background: #ff6b6b; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; margin-right: 10px;&quot;&gt;Xóa Điểm&lt;/button&gt;
                    &lt;button onclick=&quot;addRandomPoints()&quot; style=&quot;background: #4ecdc4; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Thêm Điểm Ngẫu nhiên&lt;/button&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-top: 15px;&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Công thức Toán học&lt;/h5&gt;
                &lt;div style=&quot;font-size: 13px; line-height: 1.5;&quot;&gt;
                    &lt;p&gt;&lt;strong&gt;Mục tiêu:&lt;/strong&gt; Tối thiểu hóa tổng các phần dư bình phương&lt;/p&gt;
                    &lt;div style=&quot;background: #f8f8f8; padding: 8px; border-radius: 4px; font-family: monospace;&quot;&gt;
                        S(m,c) = Σ(yᵢ - mxᵢ - c)²
                    &lt;/div&gt;
                    &lt;p style=&quot;margin-top: 10px;&quot;&gt;&lt;strong&gt;Nghiệm:&lt;/strong&gt;&lt;/p&gt;
                    &lt;div style=&quot;background: #f8f8f8; padding: 8px; border-radius: 4px; font-family: monospace; font-size: 11px;&quot;&gt;
                        m = Σ(xᵢ-x̄)(yᵢ-ȳ) / Σ(xᵢ-x̄)²&lt;br /&gt;
                        c = ȳ - mx̄
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
// Linear Regression Interactive Demo
class LinearRegressionDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;regressionCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.points = [];
        this.slope = 0;
        this.intercept = 0;
        
        // Set up canvas
        this.canvas.addEventListener(&apos;click&apos;, (e) =&gt; this.addPoint(e));
        
        // Initialize with some sample points
        this.addRandomPoints();
        this.draw();
    }
    
    addPoint(event) {
        const rect = this.canvas.getBoundingClientRect();
        const x = event.clientX - rect.left;
        const y = event.clientY - rect.top;
        
        // Convert canvas coordinates to data coordinates
        const dataX = (x / this.canvas.width) * 10;
        const dataY = ((this.canvas.height - y) / this.canvas.height) * 10;
        
        this.points.push({x: dataX, y: dataY});
        this.calculateRegression();
        this.draw();
        this.updateDisplay();
    }
    
    addRandomPoints() {
        // Add some sample points with a trend
        const baseSlope = 0.8;
        const baseIntercept = 2;
        
        for (let i = 0; i &lt; 8; i++) {
            const x = Math.random() * 8 + 1;
            const y = baseSlope * x + baseIntercept + (Math.random() - 0.5) * 2;
            this.points.push({x: x, y: Math.max(0, Math.min(10, y))});
        }
        
        this.calculateRegression();
        this.draw();
        this.updateDisplay();
    }
    
    clearPoints() {
        this.points = [];
        this.slope = 0;
        this.intercept = 0;
        this.draw();
        this.updateDisplay();
    }
    
    calculateRegression() {
        if (this.points.length &lt; 2) {
            this.slope = 0;
            this.intercept = 0;
            return;
        }
        
        const n = this.points.length;
        const sumX = this.points.reduce((sum, p) =&gt; sum + p.x, 0);
        const sumY = this.points.reduce((sum, p) =&gt; sum + p.y, 0);
        const sumXY = this.points.reduce((sum, p) =&gt; sum + p.x * p.y, 0);
        const sumXX = this.points.reduce((sum, p) =&gt; sum + p.x * p.x, 0);
        
        const meanX = sumX / n;
        const meanY = sumY / n;
        
        const numerator = sumXY - n * meanX * meanY;
        const denominator = sumXX - n * meanX * meanX;
        
        if (Math.abs(denominator) &lt; 1e-10) {
            this.slope = 0;
            this.intercept = meanY;
        } else {
            this.slope = numerator / denominator;
            this.intercept = meanY - this.slope * meanX;
        }
    }
    
    calculateR2() {
        if (this.points.length &lt; 2) return 0;
        
        const meanY = this.points.reduce((sum, p) =&gt; sum + p.y, 0) / this.points.length;
        let ssRes = 0;
        let ssTot = 0;
        
        for (const point of this.points) {
            const predicted = this.slope * point.x + this.intercept;
            ssRes += Math.pow(point.y - predicted, 2);
            ssTot += Math.pow(point.y - meanY, 2);
        }
        
        return ssTot === 0 ? 1 : 1 - (ssRes / ssTot);
    }
    
    calculateMSE() {
        if (this.points.length === 0) return 0;
        
        let mse = 0;
        for (const point of this.points) {
            const predicted = this.slope * point.x + this.intercept;
            mse += Math.pow(point.y - predicted, 2);
        }
        
        return mse / this.points.length;
    }
    
    draw() {
        // Clear canvas
        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
        
        // Draw grid
        this.drawGrid();
        
        // Draw regression line
        if (this.points.length &gt;= 2) {
            this.drawRegressionLine();
        }
        
        // Draw points and residuals
        this.drawPoints();
        
        // Draw axes labels
        this.drawLabels();
    }
    
    drawGrid() {
        this.ctx.strokeStyle = &apos;#f0f0f0&apos;;
        this.ctx.lineWidth = 1;
        
        // Vertical lines
        for (let i = 0; i &lt;= 10; i++) {
            const x = (i / 10) * this.canvas.width;
            this.ctx.beginPath();
            this.ctx.moveTo(x, 0);
            this.ctx.lineTo(x, this.canvas.height);
            this.ctx.stroke();
        }
        
        // Horizontal lines
        for (let i = 0; i &lt;= 10; i++) {
            const y = (i / 10) * this.canvas.height;
            this.ctx.beginPath();
            this.ctx.moveTo(0, y);
            this.ctx.lineTo(this.canvas.width, y);
            this.ctx.stroke();
        }
    }
    
    drawRegressionLine() {
        this.ctx.strokeStyle = &apos;#ff4757&apos;;
        this.ctx.lineWidth = 2;
        
        const x1 = 0;
        const y1 = this.intercept;
        const x2 = 10;
        const y2 = this.slope * x2 + this.intercept;
        
        const canvasX1 = (x1 / 10) * this.canvas.width;
        const canvasY1 = this.canvas.height - (y1 / 10) * this.canvas.height;
        const canvasX2 = (x2 / 10) * this.canvas.width;
        const canvasY2 = this.canvas.height - (y2 / 10) * this.canvas.height;
        
        this.ctx.beginPath();
        this.ctx.moveTo(canvasX1, canvasY1);
        this.ctx.lineTo(canvasX2, canvasY2);
        this.ctx.stroke();
    }
    
    drawPoints() {
        for (const point of this.points) {
            const canvasX = (point.x / 10) * this.canvas.width;
            const canvasY = this.canvas.height - (point.y / 10) * this.canvas.height;
            
            // Draw residual line (vertical distance to regression line)
            if (this.points.length &gt;= 2) {
                const predictedY = this.slope * point.x + this.intercept;
                const predictedCanvasY = this.canvas.height - (predictedY / 10) * this.canvas.height;
                
                this.ctx.strokeStyle = &apos;#ff6b6b&apos;;
                this.ctx.lineWidth = 1;
                this.ctx.setLineDash([2, 2]);
                this.ctx.beginPath();
                this.ctx.moveTo(canvasX, canvasY);
                this.ctx.lineTo(canvasX, predictedCanvasY);
                this.ctx.stroke();
                this.ctx.setLineDash([]);
            }
            
            // Draw point
            this.ctx.fillStyle = &apos;#2f3542&apos;;
            this.ctx.beginPath();
            this.ctx.arc(canvasX, canvasY, 4, 0, 2 * Math.PI);
            this.ctx.fill();
        }
    }
    
    drawLabels() {
        this.ctx.fillStyle = &apos;#666&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        
        // X-axis labels
        for (let i = 0; i &lt;= 10; i += 2) {
            const x = (i / 10) * this.canvas.width;
            this.ctx.fillText(i.toString(), x - 5, this.canvas.height - 5);
        }
        
        // Y-axis labels
        for (let i = 0; i &lt;= 10; i += 2) {
            const y = this.canvas.height - (i / 10) * this.canvas.height;
            this.ctx.fillText(i.toString(), 5, y + 3);
        }
    }
    
    updateDisplay() {
        document.getElementById(&apos;slope-value&apos;).textContent = this.slope.toFixed(3);
        document.getElementById(&apos;intercept-value&apos;).textContent = this.intercept.toFixed(3);
        document.getElementById(&apos;equation&apos;).textContent = `y = ${this.slope.toFixed(3)}x + ${this.intercept.toFixed(3)}`;
        
        if (this.points.length &gt;= 2) {
            document.getElementById(&apos;r2-value&apos;).textContent = this.calculateR2().toFixed(3);
            document.getElementById(&apos;mse-value&apos;).textContent = this.calculateMSE().toFixed(3);
        } else {
            document.getElementById(&apos;r2-value&apos;).textContent = &apos;N/A&apos;;
            document.getElementById(&apos;mse-value&apos;).textContent = &apos;N/A&apos;;
        }
    }
}

// Global functions for buttons
function clearPoints() {
    if (window.regressionDemo) {
        window.regressionDemo.clearPoints();
    }
}

function addRandomPoints() {
    if (window.regressionDemo) {
        window.regressionDemo.clearPoints();
        window.regressionDemo.addRandomPoints();
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    if (document.getElementById(&apos;regressionCanvas&apos;)) {
        window.regressionDemo = new LinearRegressionDemo();
    }
});

// Initialize immediately if DOM is already loaded
if (document.readyState === &apos;loading&apos;) {
    document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
        if (document.getElementById(&apos;regressionCanvas&apos;)) {
            window.regressionDemo = new LinearRegressionDemo();
        }
    });
} else {
    if (document.getElementById(&apos;regressionCanvas&apos;)) {
        window.regressionDemo = new LinearRegressionDemo();
    }
}
&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Bài toán:&lt;/strong&gt; Cho \(n\) điểm dữ liệu \((x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)\), tìm đường thẳng \(y = mx + c\) tối thiểu hóa tổng các khoảng cách thẳng đứng bình phương từ các điểm đến đường thẳng.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hàm Mục tiêu:&lt;/strong&gt; Chúng ta muốn tối thiểu hóa
\(S(m,c) = \sum_{i=1}^{n} (y_i - mx_i - c)^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Nghiệm:&lt;/strong&gt; Để tìm cực tiểu, chúng ta lấy đạo hàm riêng và cho bằng không.&lt;/p&gt;

&lt;p&gt;Lấy đạo hàm riêng theo \(c\):&lt;/p&gt;
&lt;blockquote&gt;
\[\frac{\partial S}{\partial c} = \sum_{i=1}^{n} 2(y_i - mx_i - c)(-1) = -2\sum_{i=1}^{n} (y_i - mx_i - c) = 0\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này cho ta:
\(\sum_{i=1}^{n} y_i = m\sum_{i=1}^{n} x_i + nc\)&lt;/p&gt;

&lt;p&gt;Do đó:&lt;/p&gt;

&lt;blockquote&gt;
\[c = \frac{1}{n}\sum_{i=1}^{n} y_i - m\frac{1}{n}\sum_{i=1}^{n} x_i = \bar{y} - m\bar{x}\]
&lt;/blockquote&gt;

&lt;p&gt;trong đó \(\bar{x}\) và \(\bar{y}\) là giá trị trung bình của các giá trị \(x\) và \(y\).&lt;/p&gt;

&lt;p&gt;Lấy đạo hàm riêng theo \(m\):&lt;/p&gt;

&lt;blockquote&gt;
\[\frac{\partial S}{\partial m} = \sum_{i=1}^{n} 2(y_i - mx_i - c)(-x_i) = -2\sum_{i=1}^{n} x_i(y_i - mx_i - c) = 0\]
&lt;/blockquote&gt;

&lt;p&gt;Thay thế \(c = \bar{y} - m\bar{x}\):
\(\sum_{i=1}^{n} x_i(y_i - mx_i - \bar{y} + m\bar{x}) = 0\)&lt;/p&gt;

&lt;p&gt;Sắp xếp lại:
\(\sum_{i=1}^{n} x_iy_i - m\sum_{i=1}^{n} x_i^2 - \bar{y}\sum_{i=1}^{n} x_i + m\bar{x}\sum_{i=1}^{n} x_i = 0\)&lt;/p&gt;

&lt;p&gt;Vì \(\sum_{i=1}^{n} x_i = n\bar{x}\) và \(\sum_{i=1}^{n} x_iy_i - \bar{y}\sum_{i=1}^{n} x_i = \sum_{i=1}^{n} x_i(y_i - \bar{y})\):&lt;/p&gt;

&lt;blockquote&gt;
\[\sum_{i=1}^{n} x_i(y_i - \bar{y}) = m\left(\sum_{i=1}^{n} x_i^2 - n\bar{x}^2\right)\]
&lt;/blockquote&gt;

&lt;p&gt;Lưu ý rằng \(\sum_{i=1}^{n} x_i^2 - n\bar{x}^2 = \sum_{i=1}^{n} (x_i - \bar{x})^2\)&lt;/p&gt;

&lt;p&gt;Do đó:&lt;/p&gt;

&lt;blockquote&gt;
\[m = \frac{\sum_{i=1}^{n} x_i(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2} = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Kết quả Cuối cùng:&lt;/strong&gt; Đường thẳng khớp nhất có các tham số:&lt;/p&gt;

&lt;blockquote&gt;
\[\boxed{m = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2} \quad \text{và} \quad c = \bar{y} - m\bar{x}}\]
&lt;/blockquote&gt;

&lt;p&gt;Đây là nghiệm bình phương tối thiểu kinh điển cho hồi quy tuyến tính, cũng được biết đến với tên gọi &lt;strong&gt;Phương trình Chuẩn&lt;/strong&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;nghiệm-tối-ưu-của-hồi-quy-tuyến-tính-với-hàm-nhiều-biến&quot;&gt;Nghiệm Tối ưu của Hồi quy Tuyến tính với hàm nhiều biến&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Phát biểu Bài toán:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Trong Hồi quy Tuyến tính, chúng ta muốn tìm một vector các hệ số \(\mathbf{w}\) khớp nhất với một mô hình tuyến tính cho một tập dữ liệu cho trước. Chúng ta có \(n\) điểm dữ liệu, mỗi điểm có \(p\) đặc trưng.&lt;/p&gt;

&lt;p&gt;Gọi \(X\) là ma trận thiết kế kích thước \(n \times p\), trong đó mỗi hàng đại diện cho một điểm dữ liệu và mỗi cột đại diện cho một đặc trưng.&lt;/p&gt;

&lt;p&gt;Gọi \(\mathbf{y}\) là vector các giá trị mục tiêu kích thước \(n \times 1\).&lt;/p&gt;

&lt;p&gt;Mô hình tuyến tính của chúng ta dự đoán các giá trị mục tiêu \(\hat{\mathbf{y}}\) như:
\(\hat{\mathbf{y}} = X\mathbf{w}\)
trong đó \(\mathbf{w}\) là vector các hệ số chưa biết kích thước \(p \times 1\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hàm Mục tiêu (Hàm Chi phí):&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Mục tiêu là tối thiểu hóa tổng các sai số bình phương (phần dư) giữa các giá trị mục tiêu thực tế \(\mathbf{y}\) và các giá trị dự đoán \(\hat{\mathbf{y}}\). Điều này được biết đến với tên gọi hàm mục tiêu Bình phương Tối thiểu Thông thường (OLS):
\(J(\mathbf{w}) = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \| \mathbf{y} - X\mathbf{w} \|^2\)&lt;/p&gt;

&lt;p&gt;Chúng ta có thể biểu diễn điều này dưới dạng ma trận bằng cách khai triển chuẩn Euclidean bình phương:
\(J(\mathbf{w}) = (\mathbf{y} - X\mathbf{w})^{\text{T}}(\mathbf{y} - X\mathbf{w})\)&lt;/p&gt;

&lt;p&gt;Khai triển biểu thức này:
\(J(\mathbf{w}) = \mathbf{y}^{\text{T}}\mathbf{y} - \mathbf{y}^{\text{T}}X\mathbf{w} - (X\mathbf{w})^{\text{T}}\mathbf{y} + (X\mathbf{w})^{\text{T}}X\mathbf{w}\)&lt;/p&gt;

&lt;p&gt;Sử dụng tính chất \((AB)^{\text{T}} = B^{\text{T}}A^{\text{T}}\), chúng ta có \((X\mathbf{w})^{\text{T}} = \mathbf{w}^{\text{T}}X^{\text{T}}\).&lt;/p&gt;

&lt;p&gt;Ngoài ra, vì \(\mathbf{y}^{\text{T}}X\mathbf{w}\) là một số vô hướng, chuyển vị của nó chính là nó: \((\mathbf{y}^{\text{T}}X\mathbf{w})^{\text{T}} = \mathbf{w}^{\text{T}}X^{\text{T}}\mathbf{y}\).&lt;/p&gt;

&lt;p&gt;Do đó, hai số hạng ở giữa là giống nhau:
\(J(\mathbf{w}) = \mathbf{y}^{\text{T}}\mathbf{y} - 2\mathbf{w}^{\text{T}}X^{\text{T}}\mathbf{y} + \mathbf{w}^{\text{T}}X^{\text{T}}X\mathbf{w}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tối thiểu hóa sử dụng Giải tích:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Để tìm \(\mathbf{w}\) tối ưu tối thiểu hóa \(J(\mathbf{w})\), chúng ta lấy đạo hàm của \(J(\mathbf{w})\) theo \(\mathbf{w}\) và cho bằng không. Chúng ta sử dụng các quy tắc giải tích ma trận sau:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
\[\frac{\partial (\mathbf{a}^{\text{T}}\mathbf{x})}{\partial \mathbf{x}} = \mathbf{a}\]
  &lt;/li&gt;
  &lt;li&gt;\(\frac{\partial (\mathbf{x}^{\text{T}}A\mathbf{x})}{\partial \mathbf{x}} = (A + A^{\text{T}})\mathbf{x}\) (Nếu \(A\) đối xứng, điều này được rút gọn thành \(2A\mathbf{x}\))&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Áp dụng các quy tắc này cho \(J(\mathbf{w})\):
\(\frac{\partial J(\mathbf{w})}{\partial \mathbf{w}} = \frac{\partial (\mathbf{y}^{\text{T}}\mathbf{y})}{\partial \mathbf{w}} - \frac{\partial (2\mathbf{w}^{\text{T}}X^{\text{T}}\mathbf{y})}{\partial \mathbf{w}} + \frac{\partial (\mathbf{w}^{\text{T}}X^{\text{T}}X\mathbf{w})}{\partial \mathbf{w}}\)&lt;/p&gt;

&lt;p&gt;Hãy tính từng số hạng:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\frac{\partial (\mathbf{y}^{\text{T}}\mathbf{y})}{\partial \mathbf{w}} = 0\) (vì \(\mathbf{y}^{\text{T}}\mathbf{y}\) là một hằng số vô hướng đối với \(\mathbf{w}\))&lt;/li&gt;
  &lt;li&gt;\(\frac{\partial (2\mathbf{w}^{\text{T}}X^{\text{T}}\mathbf{y})}{\partial \mathbf{w}} = 2X^{\text{T}}\mathbf{y}\) (sử dụng quy tắc 1, với \(\mathbf{a} = X^{\text{T}}\mathbf{y}\))&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Đối với số hạng thứ ba, đặt \(A = X^{\text{T}}X\). Lưu ý rằng \(A\) là ma trận đối xứng vì \((X^{\text{T}}X)^{\text{T}} = X^{\text{T}}(X^{\text{T}})^{\text{T}} = X^{\text{T}}X\).&lt;/p&gt;

    &lt;p&gt;Vậy, \(\frac{\partial (\mathbf{w}^{\text{T}}X^{\text{T}}X\mathbf{w})}{\partial \mathbf{w}} = 2X^{\text{T}}X\mathbf{w}\) (sử dụng quy tắc 2 cho ma trận đối xứng \(A\))&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kết hợp các thành phần này, đạo hàm là:&lt;/p&gt;

&lt;blockquote&gt;
\[\frac{\partial J(\mathbf{w})}{\partial \mathbf{w}} = 0 - 2X^{\text{T}}\mathbf{y} + 2X^{\text{T}}X\mathbf{w} = 2X^{\text{T}}X\mathbf{w} - 2X^{\text{T}}\mathbf{y}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Tìm Nghiệm Tối ưu:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Để tìm cực tiểu của \(J(\mathbf{w})\), chúng ta cho đạo hàm bằng không:&lt;/p&gt;

\[\frac{\partial J(\mathbf{w})}{\partial \mathbf{w}} = 2X^{\text{T}}X\mathbf{w} - 2X^{\text{T}}\mathbf{y} = 0\]

&lt;p&gt;Chia cho 2 và sắp xếp lại:
\(X^{\text{T}}X\mathbf{w} = X^{\text{T}}\mathbf{y}\)&lt;/p&gt;

&lt;p&gt;Đây được gọi là &lt;strong&gt;Phương trình Chuẩn&lt;/strong&gt;. Nếu \(X^{\text{T}}X\) khả nghịch (điều này xảy ra khi \(X\) có hạng cột đầy đủ), chúng ta có thể giải để tìm \(\mathbf{w}\):&lt;/p&gt;

&lt;blockquote&gt;
\[\boxed{\mathbf{w}^* = (X^{\text{T}}X)^{-1}X^{\text{T}}\mathbf{y}}\]
&lt;/blockquote&gt;

&lt;p&gt;Đây là &lt;strong&gt;nghiệm dạng đóng&lt;/strong&gt; cho hồi quy bình phương tối thiểu tuyến tính, còn được gọi là &lt;strong&gt;nghiệm Phương trình Chuẩn&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tính chất Quan trọng:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Tính duy nhất:&lt;/strong&gt; Nếu \(X^{\text{T}}X\) khả nghịch, nghiệm là duy nhất.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ý nghĩa Hình học:&lt;/strong&gt; Nghiệm \(\mathbf{w}^*\) làm cho vector phần dư \(\mathbf{y} - X\mathbf{w}^*\) vuông góc với không gian cột của \(X\).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Độ phức tạp Tính toán:&lt;/strong&gt; \(O(p^3 + np^2)\) trong đó \(n\) là số mẫu và \(p\) là số đặc trưng.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Khi \(X^{\text{T}}X\) không khả nghịch:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Điều này xảy ra khi \(X\) không có hạng cột đầy đủ (tức là một số đặc trưng phụ thuộc tuyến tính)&lt;/li&gt;
  &lt;li&gt;Trong trường hợp này, chúng ta có thể sử dụng &lt;strong&gt;nghịch đảo giả Moore-Penrose&lt;/strong&gt;: \(\mathbf{w}^* = X^{\dagger}\mathbf{y}\)&lt;/li&gt;
  &lt;li&gt;Hoặc thêm điều chuẩn hóa (Ridge regression): \(\mathbf{w}^* = (X^{\text{T}}X + \lambda I)^{-1}X^{\text{T}}\mathbf{y}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Hiệu suất:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Độ phức tạp thời gian: khoảng \(n^2k\) phép toán&lt;/li&gt;
  &lt;li&gt;Một máy tính tiêu chuẩn giải quyết các bài toán với hàng trăm biến và hàng nghìn số hạng trong vài giây&lt;/li&gt;
  &lt;li&gt;Ma trận thưa (nhiều phần tử bằng không) có thể được giải nhanh hơn nhiều&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt; Một ma trận thưa để xử lý ảnh có thể chỉ có 5 phần tử khác không trên mỗi hàng trong ma trận 10,000 × 10,000.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>05-01 Quy Hoạch Tuyến Tính (LP)</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_01_Linear_Programming_(LP)/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_01_Linear_Programming_(LP)</id>
   <content type="html">&lt;script src=&quot;https://d3js.org/d3.v7.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;

&lt;script id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Quy hoạch tuyến tính (LP) là một trong những kỹ thuật tối ưu hóa cơ bản và được sử dụng rộng rãi nhất trong toán học, kinh tế học và kỹ thuật. Hãy tưởng tượng bạn là một quản lý nhà máy đang cố gắng tối đa hóa lợi nhuận trong khi phải đối phó với các tài nguyên hạn chế - đây chính xác là loại bài toán mà LP được thiết kế để giải quyết!&lt;/p&gt;

&lt;h3 id=&quot;điều-gì-làm-cho-một-bài-toán-tuyến-tính&quot;&gt;Điều gì làm cho một bài toán “Tuyến tính”?&lt;/h3&gt;

&lt;p&gt;Một bài toán là tuyến tính khi:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Hàm mục tiêu&lt;/strong&gt; (thứ bạn muốn tối ưu hóa) có mối quan hệ đường thẳng&lt;/li&gt;
  &lt;li&gt;Tất cả &lt;strong&gt;ràng buộc&lt;/strong&gt; (giới hạn) cũng có mối quan hệ đường thẳng&lt;/li&gt;
  &lt;li&gt;Không có biến nào được nhân với nhau (không có các số hạng \(x_1 \cdot x_2\))&lt;/li&gt;
  &lt;li&gt;Không có biến nào xuất hiện trong số mũ hoặc dưới căn bậc hai&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ví-dụ-đơn-giản-bài-toán-của-nông-dân&quot;&gt;Ví dụ Đơn giản: Bài toán của Nông dân&lt;/h3&gt;

&lt;p&gt;Hãy bắt đầu với một ví dụ trực quan. Một nông dân có 100 mẫu đất và muốn trồng ngô và lúa mì để tối đa hóa lợi nhuận:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ngô&lt;/strong&gt;: Lợi nhuận $300 mỗi mẫu, cần 2 giờ lao động mỗi mẫu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lúa mì&lt;/strong&gt;: Lợi nhuận $200 mỗi mẫu, cần 1 giờ lao động mỗi mẫu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lao động có sẵn&lt;/strong&gt;: Tổng cộng 150 giờ&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Câu hỏi&lt;/strong&gt;: Nông dân nên trồng bao nhiêu mẫu mỗi loại cây trồng?&lt;/p&gt;

&lt;div id=&quot;farmer-problem-viz&quot; style=&quot;margin: 20px 0;&quot;&gt;&lt;/div&gt;

&lt;div class=&quot;content-box exercise-box&quot;&gt;
&lt;strong&gt;Bài tập Tương tác:&lt;/strong&gt; Sử dụng các thanh trượt bên dưới để khám phá các tổ hợp khác nhau của ngô và lúa mì. Quan sát cách lợi nhuận thay đổi và liệu các ràng buộc có được thỏa mãn hay không!

&lt;div style=&quot;margin: 10px 0;&quot;&gt;
  &lt;label for=&quot;corn-acres&quot;&gt;Số mẫu ngô: &lt;span id=&quot;corn-value&quot;&gt;50&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
  &lt;input type=&quot;range&quot; id=&quot;corn-acres&quot; min=&quot;0&quot; max=&quot;100&quot; value=&quot;50&quot; style=&quot;width: 300px;&quot; /&gt;
&lt;/div&gt;

&lt;div style=&quot;margin: 10px 0;&quot;&gt;
  &lt;label for=&quot;wheat-acres&quot;&gt;Số mẫu lúa mì: &lt;span id=&quot;wheat-value&quot;&gt;50&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
  &lt;input type=&quot;range&quot; id=&quot;wheat-acres&quot; min=&quot;0&quot; max=&quot;100&quot; value=&quot;50&quot; style=&quot;width: 300px;&quot; /&gt;
&lt;/div&gt;

&lt;div id=&quot;farmer-results&quot; style=&quot;margin-top: 15px; font-family: monospace;&quot;&gt;
  &lt;div&gt;Tổng diện tích sử dụng: &lt;span id=&quot;land-used&quot;&gt;100&lt;/span&gt; / 100 mẫu&lt;/div&gt;
  &lt;div&gt;Tổng lao động sử dụng: &lt;span id=&quot;labor-used&quot;&gt;150&lt;/span&gt; / 150 giờ&lt;/div&gt;
  &lt;div&gt;Tổng lợi nhuận: $&lt;span id=&quot;total-profit&quot;&gt;25000&lt;/span&gt;&lt;/div&gt;
  &lt;div id=&quot;feasibility-status&quot; style=&quot;font-weight: bold; color: green;&quot;&gt;✓ Nghiệm khả thi&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Bây giờ hãy chính thức hóa trực giác này. Nếu cả hàm mục tiêu và các hàm ràng buộc đều là affine, bài toán tối ưu được gọi là &lt;em&gt;chương trình tuyến tính&lt;/em&gt; (LP). Chương trình tuyến tính tổng quát được phát biểu như sau:&lt;/p&gt;

&lt;h3 id=&quot;lp-tổng-quát&quot;&gt;LP Tổng quát&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Gx \preceq h}\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp;\text{where } &amp;amp;&amp;amp;G \in \mathbb{R}^{m \times n} \text{ and } A \in \mathbb{R}^{p \times n}.
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Hằng số \(+d\) trong hàm mục tiêu không ảnh hưởng đến quá trình tối ưu hóa hoặc kết quả và có thể bỏ qua.&lt;/li&gt;
  &lt;li&gt;Nếu bạn muốn tối đa hóa \(c^T x + d\) dưới cùng các ràng buộc, bạn có thể tương đương tối thiểu hóa \(-c^T x - d\).&lt;/li&gt;
  &lt;li&gt;Bài toán trên tìm nghiệm tối ưu \(x^*\) của hàm affine \(c^T x + d\) trên một tập khả thi đa diện.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;giải-thích-hình-học&quot;&gt;Giải thích Hình học&lt;/h3&gt;

&lt;p&gt;Sức mạnh của quy hoạch tuyến tính trở nên rõ ràng khi chúng ta trực quan hóa nó theo hình học. Mỗi ràng buộc định nghĩa một nửa không gian, và vùng khả thi là giao của tất cả các nửa không gian này - tạo thành một &lt;strong&gt;đa diện&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Thông tin quan trọng:&lt;/strong&gt; Nghiệm tối ưu của một chương trình tuyến tính luôn xuất hiện tại một &lt;strong&gt;đỉnh&lt;/strong&gt; (góc) của vùng khả thi! Đây là lý do tại sao phương pháp simplex hoạt động bằng cách di chuyển từ đỉnh này sang đỉnh khác.
&lt;/div&gt;

&lt;div id=&quot;geometric-lp-viz&quot; style=&quot;margin: 20px 0; text-align: center;&quot;&gt;&lt;/div&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter05/05_01_geometric_interpretation_of_LP.png&quot; alt=&quot;[Fig1] Giải thích hình học của LP [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Giải thích hình học truyền thống của LP [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;lp-ở-dạng-chuẩn&quot;&gt;LP ở Dạng chuẩn&lt;/h2&gt;

&lt;p&gt;Tại sao chúng ta cần một dạng chuẩn? Nhiều thuật toán LP (như phương pháp simplex) được thiết kế để làm việc với một định dạng cụ thể. Việc chuyển đổi về dạng chuẩn cho phép chúng ta sử dụng các thuật toán mạnh mẽ này một cách nhất quán.&lt;/p&gt;

&lt;h3 id=&quot;lp-dạng-chuẩn&quot;&gt;LP dạng chuẩn&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{A x = b} \\\\
   &amp;amp; &amp;amp;&amp;amp;{x \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Đặc điểm chính của dạng chuẩn:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Mục tiêu&lt;/strong&gt;: Luôn là tối thiểu hóa (các bài toán tối đa hóa được chuyển đổi bằng cách lấy âm)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ràng buộc&lt;/strong&gt;: Chỉ có ràng buộc đẳng thức (bất đẳng thức được chuyển đổi sử dụng biến slack)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Biến&lt;/strong&gt;: Tất cả các biến phải không âm&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Tại sao Dạng chuẩn?&lt;/strong&gt; 
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hiệu quả thuật toán:&lt;/strong&gt; Phương pháp Simplex làm việc trực tiếp trên dạng chuẩn&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Phân tích lý thuyết:&lt;/strong&gt; Dễ dàng hơn để chứng minh các điều kiện tối ưu&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Triển khai phần mềm:&lt;/strong&gt; Hầu hết các bộ giải LP mong đợi đầu vào dạng chuẩn&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;Tất cả các LP tổng quát đều có thể được chuyển đổi về dạng chuẩn sử dụng các bước sau:&lt;/p&gt;

&lt;h3 id=&quot;chuyển-đổi-lp-về-dạng-chuẩn&quot;&gt;Chuyển đổi LP về dạng chuẩn&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Bước 1.&lt;/strong&gt; Sử dụng biến slack \(s\) để chuyển đổi ràng buộc bất đẳng thức thành ràng buộc đẳng thức:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
    &amp;amp;\text{minimize}_{x, s} &amp;amp;&amp;amp;{c^T x + d} \\\\
    &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Gx + s = h} \\\\
    &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
    &amp;amp; &amp;amp;&amp;amp;{s \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Bước 2.&lt;/strong&gt; Thay thế mỗi biến \(x\) bằng hai biến không âm:
\(x = x^{+}  - x^{-}\), trong đó \(x^{+} \text{, } x^{-} \succeq 0\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
    &amp;amp;\text{minimize}_{x^{+}, x^{-}, s} &amp;amp;&amp;amp;{c^Tx^{+} - c^Tx^{-} + d} \\\\
    &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Gx^{+} - Gx^{-} + s = h} \\\\
    &amp;amp; &amp;amp;&amp;amp;{Ax^{+} - Ax^{-} = b},\\\\
    &amp;amp; &amp;amp;&amp;amp;{s \succeq 0}\\\\
    &amp;amp; &amp;amp;&amp;amp;{x^{+} \succeq 0}, {x^{-} \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Bước 3.&lt;/strong&gt; Định nghĩa \(\tilde{x}\), \(\tilde{c}\), \(\tilde{b}\), và \(\tilde{A}\) như sau:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\tilde{x} =
\begin{bmatrix}
x^{+} \\\\
x^{-} \\\\
s
\end{bmatrix}, 
\tilde{c} =
\begin{bmatrix}
c \\\\
-c \\\\
0
\end{bmatrix},
\tilde{b} =
\begin{bmatrix}
h \\\\
b
\end{bmatrix}\), 
\(\tilde{A} =
\begin{bmatrix}
G &amp;amp; -G &amp;amp; I\\\\
A &amp;amp; -A &amp;amp; O
\end{bmatrix}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Bước 4.&lt;/strong&gt; Thế \(\tilde{x}\), \(\tilde{c}\), \(\tilde{b}\), và \(\tilde{A}\) vào bài toán từ Bước 2:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
    &amp;amp;\text{minimize}_{\tilde{x}} &amp;amp;&amp;amp;{\tilde{c}^T \tilde{x} + d} \\\\
    &amp;amp;\text{subject to} &amp;amp;&amp;amp;{\tilde{A} \tilde{x} = \tilde{b}} \\\\
    &amp;amp; &amp;amp;&amp;amp;{\tilde{x} \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;ví-dụ---chương-trình-chế-độ-ăn-uống&quot;&gt;Ví dụ - Chương trình chế độ ăn uống&lt;/h3&gt;

&lt;p&gt;Bài toán chế độ ăn uống là một ứng dụng kinh điển của quy hoạch tuyến tính, lần đầu tiên được nghiên cứu trong Thế chiến thứ hai để tìm cách nuôi dưỡng binh sĩ một cách kinh tế nhất trong khi vẫn đáp ứng các yêu cầu dinh dưỡng.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thiết lập bài toán:&lt;/strong&gt; Tìm sự kết hợp thức ăn rẻ nhất đáp ứng tất cả các yêu cầu dinh dưỡng.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
    &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x} \\\\
    &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Dx \succeq d} \\\\
    &amp;amp; &amp;amp;&amp;amp;{x \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Biến và Tham số:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(c_j\): Chi phí trên mỗi đơn vị thức phẩm j ($/đơn vị)&lt;/li&gt;
  &lt;li&gt;\(d_i\): Lượng tiêu thụ tối thiểu khuyến nghị cho chất dinh dưỡng i (đơn vị/ngày)&lt;/li&gt;
  &lt;li&gt;\(D_{ij}\): Lượng chất dinh dưỡng i trong thức phẩm j (đơn vị chất dinh dưỡng trên đơn vị thức phẩm)&lt;/li&gt;
  &lt;li&gt;\(x_j\): Lượng thức phẩm j trong chế độ ăn uống (đơn vị/ngày)&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;content-box exercise-box&quot;&gt;
&lt;strong&gt;Bộ Tối ưu hóa Chế độ ăn uống Tương tác:&lt;/strong&gt; Hãy giải một bài toán chế độ ăn uống đơn giản với 3 loại thức phẩm và 2 chất dinh dưỡng!

&lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px; margin: 15px 0;&quot;&gt;
  &lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;strong&gt;Bánh mì&lt;/strong&gt;&lt;br /&gt;
    Chi phí: $2/ổ&lt;br /&gt;
    Protein: 4g/ổ&lt;br /&gt;
    Calories: 200/ổ
  &lt;/div&gt;
  &lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;strong&gt;Sữa&lt;/strong&gt;&lt;br /&gt;
    Chi phí: $3/lít&lt;br /&gt;
    Protein: 8g/lít&lt;br /&gt;
    Calories: 150/lít
  &lt;/div&gt;
  &lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;strong&gt;Thịt&lt;/strong&gt;&lt;br /&gt;
    Chi phí: $8/kg&lt;br /&gt;
    Protein: 20g/kg&lt;br /&gt;
    Calories: 300/kg
  &lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;margin: 15px 0;&quot;&gt;
  &lt;strong&gt;Yêu cầu:&lt;/strong&gt;
  &lt;div&gt;Protein tối thiểu: &lt;input type=&quot;number&quot; id=&quot;min-protein&quot; value=&quot;20&quot; min=&quot;10&quot; max=&quot;50&quot; style=&quot;width: 60px;&quot; /&gt; gram/ngày&lt;/div&gt;
  &lt;div&gt;Calories tối thiểu: &lt;input type=&quot;number&quot; id=&quot;min-calories&quot; value=&quot;800&quot; min=&quot;500&quot; max=&quot;1500&quot; style=&quot;width: 80px;&quot; /&gt; calories/ngày&lt;/div&gt;
&lt;/div&gt;

&lt;button id=&quot;solve-diet&quot; style=&quot;background-color: #4CAF50; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer;&quot;&gt;Giải Bài toán Chế độ ăn uống&lt;/button&gt;

&lt;div id=&quot;diet-results&quot; style=&quot;margin-top: 15px; font-family: monospace; background-color: #f9f9f9; padding: 10px; border-radius: 4px;&quot;&gt;
  &lt;div&gt;Nhấp &quot;Giải Bài toán Chế độ ăn uống&quot; để xem nghiệm tối ưu!&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Ứng dụng thực tế:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hậu cần quân sự:&lt;/strong&gt; Nuôi quân đội một cách hiệu quả về chi phí&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lập kế hoạch bữa ăn bệnh viện:&lt;/strong&gt; Đáp ứng yêu cầu chế độ ăn uống của bệnh nhân&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tối ưu hóa thức ăn gia súc:&lt;/strong&gt; Dinh dưỡng gia súc với chi phí tối thiểu&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Chương trình bữa trưa học đường:&lt;/strong&gt; Bữa ăn bổ dưỡng trong phạm vi ngân sách&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;h2 id=&quot;thuật-toán-simplex&quot;&gt;Thuật toán Simplex&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Thuật toán Simplex&lt;/strong&gt;, được phát triển bởi George Dantzig năm 1947, là một trong những thuật toán quan trọng nhất trong lịch sử tối ưu hóa. Nó đã cách mạng hóa quy hoạch tuyến tính bằng cách cung cấp một phương pháp hiệu quả để giải các bài toán LP một cách hệ thống.&lt;/p&gt;

&lt;h3 id=&quot;tại-sao-simplex-hoạt-động-định-lý-cơ-bản&quot;&gt;Tại sao Simplex hoạt động: Định lý Cơ bản&lt;/h3&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Định lý Cơ bản của Quy hoạch Tuyến tính:&lt;/strong&gt; Nếu một chương trình tuyến tính có nghiệm tối ưu, thì tồn tại một nghiệm tối ưu xuất hiện tại một đỉnh (cực điểm) của vùng khả thi.
&lt;/div&gt;

&lt;p&gt;Định lý này là thông tin quan trọng đằng sau thuật toán Simplex. Thay vì tìm kiếm toàn bộ vùng khả thi (có thể vô hạn), chúng ta chỉ cần kiểm tra số hữu hạn các đỉnh!&lt;/p&gt;

&lt;h3 id=&quot;how-simplex-works-the-strategy&quot;&gt;How Simplex Works: The Strategy&lt;/h3&gt;

&lt;p&gt;The Simplex algorithm follows this elegant strategy:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Start&lt;/strong&gt; at any vertex of the feasible region&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Check&lt;/strong&gt; if the current vertex is optimal&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Move&lt;/strong&gt; to an adjacent vertex that improves the objective function&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Repeat&lt;/strong&gt; until no improvement is possible (optimal solution found)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;simplex-algorithm-steps&quot;&gt;Simplex Algorithm Steps&lt;/h3&gt;

&lt;p&gt;Let’s walk through the algorithm step by step using our standard form LP:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
    &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x} \\\\
    &amp;amp;\text{subject to } &amp;amp;&amp;amp;{A x = b} \\\\
    &amp;amp; &amp;amp;&amp;amp;{x \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Initial Setup&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Convert the LP to standard form (if not already)&lt;/li&gt;
  &lt;li&gt;Find an initial basic feasible solution (vertex)&lt;/li&gt;
  &lt;li&gt;Set up the simplex tableau&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 2: Optimality Test&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Check if the current solution is optimal&lt;/li&gt;
  &lt;li&gt;If all reduced costs are non-negative, we’re done!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 3: Choose Entering Variable&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Select the variable with the most negative reduced cost&lt;/li&gt;
  &lt;li&gt;This determines the direction to move&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 4: Choose Leaving Variable&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Use the minimum ratio test to avoid infeasibility&lt;/li&gt;
  &lt;li&gt;This determines how far to move&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 5: Pivot Operation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Update the tableau using Gaussian elimination&lt;/li&gt;
  &lt;li&gt;Move to the new vertex&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 6: Repeat&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Go back to Step 2 until optimal&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;interactive-simplex-example&quot;&gt;Interactive Simplex Example&lt;/h3&gt;

&lt;p&gt;Let’s solve a simple 2D problem step by step to see how Simplex works in practice:&lt;/p&gt;

&lt;div class=&quot;content-box exercise-box&quot;&gt;
&lt;strong&gt;Interactive Simplex Solver:&lt;/strong&gt; Watch the algorithm move from vertex to vertex!

**Problem:**
$$\begin{align}
\text{maximize } &amp;amp; 3x_1 + 2x_2 \\
\text{subject to } &amp;amp; x_1 + x_2 \leq 4 \\
&amp;amp; 2x_1 + x_2 \leq 6 \\
&amp;amp; x_1, x_2 \geq 0
\end{align}$$

&lt;div id=&quot;simplex-interactive&quot; style=&quot;margin: 20px 0;&quot;&gt;&lt;/div&gt;

&lt;div style=&quot;margin: 15px 0;&quot;&gt;
  &lt;button id=&quot;simplex-step&quot; style=&quot;background-color: #2196F3; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; margin-right: 10px;&quot;&gt;Next Step&lt;/button&gt;
  &lt;button id=&quot;simplex-reset&quot; style=&quot;background-color: #f44336; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer;&quot;&gt;Reset&lt;/button&gt;
&lt;/div&gt;

&lt;div id=&quot;simplex-status&quot; style=&quot;margin-top: 15px; font-family: monospace; background-color: #f9f9f9; padding: 15px; border-radius: 4px;&quot;&gt;
  &lt;div&gt;&lt;strong&gt;Step 0:&lt;/strong&gt; Starting at origin (0, 0)&lt;/div&gt;
  &lt;div&gt;Current objective value: 0&lt;/div&gt;
  &lt;div&gt;Click &quot;Next Step&quot; to begin the Simplex algorithm!&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;simplex-tableau&quot; style=&quot;margin-top: 15px; font-family: monospace; background-color: #f0f8ff; padding: 15px; border-radius: 4px;&quot;&gt;
  &lt;strong&gt;Current Simplex Tableau:&lt;/strong&gt;
  &lt;div id=&quot;tableau-content&quot; style=&quot;margin-top: 10px;&quot;&gt;
    Click &quot;Next Step&quot; to see the tableau!
  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;why-simplex-is-efficient&quot;&gt;Why Simplex is Efficient&lt;/h3&gt;

&lt;p&gt;Despite having potentially exponential worst-case complexity, Simplex is remarkably efficient in practice:&lt;/p&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Simplex Efficiency:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Average case:&lt;/strong&gt; Typically visits only 2-3 times the number of constraints&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Practical problems:&lt;/strong&gt; Often solves in polynomial time&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Warm starts:&lt;/strong&gt; Can reuse previous solutions when problem changes slightly&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Degeneracy handling:&lt;/strong&gt; Modern implementations handle degenerate cases well&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;h3 id=&quot;simplex-variants-and-modern-developments&quot;&gt;Simplex Variants and Modern Developments&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Revised Simplex Method:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;More numerically stable&lt;/li&gt;
  &lt;li&gt;Better for sparse matrices&lt;/li&gt;
  &lt;li&gt;Used in most commercial solvers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Dual Simplex Method:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Starts with dual feasible solution&lt;/li&gt;
  &lt;li&gt;Useful for sensitivity analysis&lt;/li&gt;
  &lt;li&gt;Better for certain problem types&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Interior Point Methods:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Polynomial-time complexity guarantee&lt;/li&gt;
  &lt;li&gt;Better for very large problems&lt;/li&gt;
  &lt;li&gt;Complement rather than replace Simplex&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;impact-and-applications&quot;&gt;Impact and Applications&lt;/h3&gt;

&lt;p&gt;The Simplex algorithm has transformed numerous industries:&lt;/p&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Simplex Success Stories:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Airlines:&lt;/strong&gt; Crew scheduling, route optimization, fleet assignment&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Manufacturing:&lt;/strong&gt; Production planning, supply chain optimization&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Finance:&lt;/strong&gt; Portfolio optimization, risk management&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Telecommunications:&lt;/strong&gt; Network flow optimization, bandwidth allocation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Energy:&lt;/strong&gt; Power grid optimization, resource allocation&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;script&gt;
/**
 * Interactive Linear Programming Visualizations
 * Implements farmer problem, geometric interpretation, diet optimizer, and norm comparisons
 */

// Wait for DOM to be fully loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    
    // ==================== FARMER PROBLEM INTERACTIVE ====================
    
    function initializeFarmerProblem() {
        const cornSlider = document.getElementById(&apos;corn-acres&apos;);
        const wheatSlider = document.getElementById(&apos;wheat-acres&apos;);
        
        if (!cornSlider || !wheatSlider) return;
        
        function updateFarmerResults() {
            const corn = parseFloat(cornSlider.value);
            const wheat = parseFloat(wheatSlider.value);
            
            // Update display values
            document.getElementById(&apos;corn-value&apos;).textContent = corn;
            document.getElementById(&apos;wheat-value&apos;).textContent = wheat;
            
            // Calculate metrics
            const landUsed = corn + wheat;
            const laborUsed = corn * 2 + wheat * 1; // 2 hours per corn acre, 1 hour per wheat acre
            const profit = corn * 300 + wheat * 200; // $300 per corn acre, $200 per wheat acre
            
            // Update results
            document.getElementById(&apos;land-used&apos;).textContent = landUsed;
            document.getElementById(&apos;labor-used&apos;).textContent = laborUsed;
            document.getElementById(&apos;total-profit&apos;).textContent = profit;
            
            // Check feasibility
            const feasibilityStatus = document.getElementById(&apos;feasibility-status&apos;);
            if (landUsed &lt;= 100 &amp;&amp; laborUsed &lt;= 150) {
                feasibilityStatus.textContent = &apos;✓ Feasible solution&apos;;
                feasibilityStatus.style.color = &apos;green&apos;;
            } else {
                feasibilityStatus.textContent = &apos;✗ Infeasible solution&apos;;
                feasibilityStatus.style.color = &apos;red&apos;;
            }
        }
        
        cornSlider.addEventListener(&apos;input&apos;, updateFarmerResults);
        wheatSlider.addEventListener(&apos;input&apos;, updateFarmerResults);
        
        // Initialize
        updateFarmerResults();
    }
    
    // ==================== DIET PROBLEM SOLVER ====================
    
    function initializeDietSolver() {
        const solveButton = document.getElementById(&apos;solve-diet&apos;);
        if (!solveButton) return;
        
        solveButton.addEventListener(&apos;click&apos;, function() {
            const minProtein = parseFloat(document.getElementById(&apos;min-protein&apos;).value);
            const minCalories = parseFloat(document.getElementById(&apos;min-calories&apos;).value);
            
            // Simple heuristic solver (in practice, would use simplex method)
            // Food data: [cost, protein, calories]
            const bread = [2, 4, 200];
            const milk = [3, 8, 150];
            const meat = [8, 20, 300];
            
            // Try different combinations and find minimum cost feasible solution
            let bestCost = Infinity;
            let bestSolution = null;
            
            for (let b = 0; b &lt;= 20; b += 0.5) {
                for (let m = 0; m &lt;= 10; m += 0.5) {
                    for (let mt = 0; mt &lt;= 5; mt += 0.5) {
                        const protein = b * bread[1] + m * milk[1] + mt * meat[1];
                        const calories = b * bread[2] + m * milk[2] + mt * meat[2];
                        const cost = b * bread[0] + m * milk[0] + mt * meat[0];
                        
                        if (protein &gt;= minProtein &amp;&amp; calories &gt;= minCalories &amp;&amp; cost &lt; bestCost) {
                            bestCost = cost;
                            bestSolution = [b, m, mt];
                        }
                    }
                }
            }
            
            const resultsDiv = document.getElementById(&apos;diet-results&apos;);
            if (bestSolution) {
                const [bread_amt, milk_amt, meat_amt] = bestSolution;
                const totalProtein = bread_amt * bread[1] + milk_amt * milk[1] + meat_amt * meat[1];
                const totalCalories = bread_amt * bread[2] + milk_amt * milk[2] + meat_amt * meat[2];
                
                resultsDiv.innerHTML = `
                    &lt;div&gt;&lt;strong&gt;Optimal Diet Solution:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Bread: ${bread_amt.toFixed(1)} loaves&lt;/div&gt;
                    &lt;div&gt;Milk: ${milk_amt.toFixed(1)} liters&lt;/div&gt;
                    &lt;div&gt;Meat: ${meat_amt.toFixed(1)} kg&lt;/div&gt;
                    &lt;div&gt;---&lt;/div&gt;
                    &lt;div&gt;Total cost: $${bestCost.toFixed(2)}&lt;/div&gt;
                    &lt;div&gt;Total protein: ${totalProtein.toFixed(1)}g (required: ${minProtein}g)&lt;/div&gt;
                    &lt;div&gt;Total calories: ${totalCalories.toFixed(0)} (required: ${minCalories})&lt;/div&gt;
                `;
            } else {
                resultsDiv.innerHTML = &apos;&lt;div style=&quot;color: red;&quot;&gt;No feasible solution found!&lt;/div&gt;&apos;;
            }
        });
    }
    
    // ==================== SIMPLEX ALGORITHM VISUALIZATION ====================
    
    function initializeSimplexVisualization() {
        const stepButton = document.getElementById(&apos;simplex-step&apos;);
        const resetButton = document.getElementById(&apos;simplex-reset&apos;);
        const statusDiv = document.getElementById(&apos;simplex-status&apos;);
        const tableauDiv = document.getElementById(&apos;tableau-content&apos;);
        const interactiveDiv = document.getElementById(&apos;simplex-interactive&apos;);
        
        if (!stepButton || !resetButton || !statusDiv || !tableauDiv || !interactiveDiv) return;
        
        // Simplex algorithm state
        let currentStep = 0;
        let currentVertex = [0, 0]; // Starting at origin
        let isOptimal = false;
        
        // Problem: maximize 3x1 + 2x2 subject to x1 + x2 &lt;= 4, 2x1 + x2 &lt;= 6, x1,x2 &gt;= 0
        // In standard form: minimize -3x1 - 2x2 subject to x1 + x2 + s1 = 4, 2x1 + x2 + s2 = 6
        
        const vertices = [
            [0, 0, 4, 6], // (x1, x2, s1, s2) - origin
            [0, 4, 0, 2], // (0, 4, 0, 2) - intersection with x1 + x2 = 4
            [2, 2, 0, 0], // (2, 2, 0, 0) - intersection of both constraints
            [3, 0, 1, 0]  // (3, 0, 1, 0) - intersection with 2x1 + x2 = 6
        ];
        
        const objectiveValues = [0, 8, 10, 9]; // 3x1 + 2x2 at each vertex
        const simplexPath = [0, 3, 2]; // Path: origin -&gt; (3,0) -&gt; (2,2) optimal
        
        function createVisualization() {
            const width = 400;
            const height = 300;
            const margin = {top: 20, right: 20, bottom: 40, left: 40};
            
            // Clear previous content
            interactiveDiv.innerHTML = &apos;&apos;;
            
            const svg = d3.select(&apos;#simplex-interactive&apos;)
                .append(&apos;svg&apos;)
                .attr(&apos;width&apos;, width)
                .attr(&apos;height&apos;, height);
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain([0, 4])
                .range([margin.left, width - margin.right]);
            
            const yScale = d3.scaleLinear()
                .domain([0, 6])
                .range([height - margin.bottom, margin.top]);
            
            // Draw feasible region
            const feasibleRegion = [
                [0, 0], [0, 4], [2, 2], [3, 0], [0, 0]
            ];
            
            svg.append(&apos;path&apos;)
                .datum(feasibleRegion)
                .attr(&apos;fill&apos;, &apos;lightblue&apos;)
                .attr(&apos;fill-opacity&apos;, 0.3)
                .attr(&apos;stroke&apos;, &apos;blue&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;d&apos;, d3.line()
                    .x(d =&gt; xScale(d[0]))
                    .y(d =&gt; yScale(d[1]))
                );
            
            // Draw constraint lines
            // x1 + x2 = 4
            svg.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, xScale(0))
                .attr(&apos;y1&apos;, yScale(4))
                .attr(&apos;x2&apos;, xScale(4))
                .attr(&apos;y2&apos;, yScale(0))
                .attr(&apos;stroke&apos;, &apos;red&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;stroke-dasharray&apos;, &apos;5,5&apos;);
            
            // 2x1 + x2 = 6
            svg.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, xScale(0))
                .attr(&apos;y1&apos;, yScale(6))
                .attr(&apos;x2&apos;, xScale(3))
                .attr(&apos;y2&apos;, yScale(0))
                .attr(&apos;stroke&apos;, &apos;green&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;stroke-dasharray&apos;, &apos;5,5&apos;);
            
            // Draw vertices
            const vertexPoints = [[0,0], [0,4], [2,2], [3,0]];
            svg.selectAll(&apos;.vertex&apos;)
                .data(vertexPoints)
                .enter()
                .append(&apos;circle&apos;)
                .attr(&apos;class&apos;, &apos;vertex&apos;)
                .attr(&apos;cx&apos;, d =&gt; xScale(d[0]))
                .attr(&apos;cy&apos;, d =&gt; yScale(d[1]))
                .attr(&apos;r&apos;, 6)
                .attr(&apos;fill&apos;, &apos;orange&apos;)
                .attr(&apos;stroke&apos;, &apos;black&apos;)
                .attr(&apos;stroke-width&apos;, 2);
            
            // Current position indicator
            svg.append(&apos;circle&apos;)
                .attr(&apos;id&apos;, &apos;current-position&apos;)
                .attr(&apos;cx&apos;, xScale(currentVertex[0]))
                .attr(&apos;cy&apos;, yScale(currentVertex[1]))
                .attr(&apos;r&apos;, 8)
                .attr(&apos;fill&apos;, &apos;red&apos;)
                .attr(&apos;stroke&apos;, &apos;darkred&apos;)
                .attr(&apos;stroke-width&apos;, 3);
            
            // Axes
            svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height - margin.bottom})`)
                .call(d3.axisBottom(xScale));
            
            svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},0)`)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            svg.append(&apos;text&apos;)
                .attr(&apos;x&apos;, width / 2)
                .attr(&apos;y&apos;, height - 5)
                .attr(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;x₁&apos;);
            
            svg.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;x&apos;, -height / 2)
                .attr(&apos;y&apos;, 15)
                .attr(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;x₂&apos;);
            
            // Legend
            const legend = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${width - 150}, 30)`);
            
            legend.append(&apos;text&apos;)
                .attr(&apos;x&apos;, 0)
                .attr(&apos;y&apos;, 0)
                .text(&apos;Constraints:&apos;)
                .attr(&apos;font-weight&apos;, &apos;bold&apos;);
            
            legend.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, 0)
                .attr(&apos;y1&apos;, 15)
                .attr(&apos;x2&apos;, 20)
                .attr(&apos;y2&apos;, 15)
                .attr(&apos;stroke&apos;, &apos;red&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;stroke-dasharray&apos;, &apos;5,5&apos;);
            
            legend.append(&apos;text&apos;)
                .attr(&apos;x&apos;, 25)
                .attr(&apos;y&apos;, 19)
                .text(&apos;x₁ + x₂ ≤ 4&apos;)
                .attr(&apos;font-size&apos;, &apos;12px&apos;);
            
            legend.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, 0)
                .attr(&apos;y1&apos;, 30)
                .attr(&apos;x2&apos;, 20)
                .attr(&apos;y2&apos;, 30)
                .attr(&apos;stroke&apos;, &apos;green&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;stroke-dasharray&apos;, &apos;5,5&apos;);
            
            legend.append(&apos;text&apos;)
                .attr(&apos;x&apos;, 25)
                .attr(&apos;y&apos;, 34)
                .text(&apos;2x₁ + x₂ ≤ 6&apos;)
                .attr(&apos;font-size&apos;, &apos;12px&apos;);
        }
        
        function updateTableau(step) {
            let tableauHTML = &apos;&apos;;
            
            switch(step) {
                case 0:
                    tableauHTML = `
                        &lt;table style=&quot;border-collapse: collapse; margin: 10px 0;&quot;&gt;
                            &lt;tr style=&quot;background-color: #e0e0e0;&quot;&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;Basic&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;RHS&lt;/th&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;4&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;2&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;6&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #fff2cc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;z&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; color: red;&quot;&gt;&lt;strong&gt;-3&lt;/strong&gt;&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; color: red;&quot;&gt;-2&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                            &lt;/tr&gt;
                        &lt;/table&gt;
                        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
                            &lt;strong&gt;Analysis:&lt;/strong&gt; Most negative coefficient is -3 (x₁ column). x₁ enters the basis.
                        &lt;/div&gt;
                    `;
                    break;
                case 1:
                    tableauHTML = `
                        &lt;table style=&quot;border-collapse: collapse; margin: 10px 0;&quot;&gt;
                            &lt;tr style=&quot;background-color: #e0e0e0;&quot;&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;Basic&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;RHS&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;Ratio&lt;/th&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; background-color: #ffcccc;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;4&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;4/1 = 4&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #ccffcc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; background-color: #ffcccc;&quot;&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;6&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;&lt;strong&gt;6/2 = 3&lt;/strong&gt;&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #fff2cc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;z&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; background-color: #ffcccc;&quot;&gt;-3&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;-2&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;-&lt;/td&gt;
                            &lt;/tr&gt;
                        &lt;/table&gt;
                        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
                            &lt;strong&gt;Minimum ratio test:&lt;/strong&gt; min{4/1, 6/2} = min{4, 3} = 3. s₂ leaves the basis.
                        &lt;/div&gt;
                    `;
                    break;
                case 2:
                    tableauHTML = `
                        &lt;table style=&quot;border-collapse: collapse; margin: 10px 0;&quot;&gt;
                            &lt;tr style=&quot;background-color: #e0e0e0;&quot;&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;Basic&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;RHS&lt;/th&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; color: red;&quot;&gt;&lt;strong&gt;0.5&lt;/strong&gt;&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;-0.5&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0.5&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0.5&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;3&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #fff2cc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;z&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; color: red;&quot;&gt;&lt;strong&gt;-0.5&lt;/strong&gt;&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1.5&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;9&lt;/td&gt;
                            &lt;/tr&gt;
                        &lt;/table&gt;
                        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
                            &lt;strong&gt;Current solution:&lt;/strong&gt; x₁ = 3, x₂ = 0, objective = 9&lt;br&gt;
                            &lt;strong&gt;Analysis:&lt;/strong&gt; x₂ has negative coefficient (-0.5), so x₂ enters the basis.
                        &lt;/div&gt;
                    `;
                    break;
                case 3:
                    tableauHTML = `
                        &lt;table style=&quot;border-collapse: collapse; margin: 10px 0;&quot;&gt;
                            &lt;tr style=&quot;background-color: #e0e0e0;&quot;&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;Basic&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;RHS&lt;/th&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #ccffcc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₂&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;2&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;-1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;2&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;-1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;2&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #ccffcc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;z&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;10&lt;/td&gt;
                            &lt;/tr&gt;
                        &lt;/table&gt;
                        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
                            &lt;strong&gt;OPTIMAL SOLUTION FOUND!&lt;/strong&gt;&lt;br&gt;
                            x₁ = 2, x₂ = 2, Maximum objective value = 10&lt;br&gt;
                            All coefficients in the objective row are non-negative.
                        &lt;/div&gt;
                    `;
                    break;
            }
            
            tableauDiv.innerHTML = tableauHTML;
        }
        
        function updateStatus(step) {
            let statusHTML = &apos;&apos;;
            
            switch(step) {
                case 0:
                    statusHTML = `
                        &lt;div&gt;&lt;strong&gt;Step 0:&lt;/strong&gt; Initial basic feasible solution&lt;/div&gt;
                        &lt;div&gt;Current vertex: (0, 0)&lt;/div&gt;
                        &lt;div&gt;Current objective value: 0&lt;/div&gt;
                        &lt;div&gt;Basic variables: s₁ = 4, s₂ = 6&lt;/div&gt;
                    `;
                    currentVertex = [0, 0];
                    break;
                case 1:
                    statusHTML = `
                        &lt;div&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Choose entering variable&lt;/div&gt;
                        &lt;div&gt;Most negative coefficient: -3 (x₁ column)&lt;/div&gt;
                        &lt;div&gt;x₁ enters the basis&lt;/div&gt;
                        &lt;div&gt;Performing minimum ratio test...&lt;/div&gt;
                    `;
                    break;
                case 2:
                    statusHTML = `
                        &lt;div&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; First iteration complete&lt;/div&gt;
                        &lt;div&gt;Current vertex: (3, 0)&lt;/div&gt;
                        &lt;div&gt;Current objective value: 9&lt;/div&gt;
                        &lt;div&gt;Basic variables: x₁ = 3, s₁ = 1&lt;/div&gt;
                    `;
                    currentVertex = [3, 0];
                    break;
                case 3:
                    statusHTML = `
                        &lt;div&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; OPTIMAL SOLUTION FOUND!&lt;/div&gt;
                        &lt;div&gt;Current vertex: (2, 2)&lt;/div&gt;
                        &lt;div&gt;Maximum objective value: 10&lt;/div&gt;
                        &lt;div&gt;Basic variables: x₁ = 2, x₂ = 2&lt;/div&gt;
                    `;
                    currentVertex = [2, 2];
                    isOptimal = true;
                    break;
            }
            
            statusDiv.innerHTML = statusHTML;
            
            // Update visualization
            const currentPos = d3.select(&apos;#current-position&apos;);
            if (currentPos.node()) {
                const xScale = d3.scaleLinear().domain([0, 4]).range([40, 360]);
                const yScale = d3.scaleLinear().domain([0, 6]).range([260, 40]);
                
                currentPos
                    .transition()
                    .duration(500)
                    .attr(&apos;cx&apos;, xScale(currentVertex[0]))
                    .attr(&apos;cy&apos;, yScale(currentVertex[1]));
            }
        }
        
        function nextStep() {
            if (currentStep &lt; 3) {
                currentStep++;
                updateStatus(currentStep);
                updateTableau(currentStep);
                
                if (currentStep === 3) {
                    stepButton.textContent = &apos;Algorithm Complete!&apos;;
                    stepButton.disabled = true;
                    stepButton.style.backgroundColor = &apos;#4CAF50&apos;;
                }
            }
        }
        
        function reset() {
            currentStep = 0;
            currentVertex = [0, 0];
            isOptimal = false;
            
            stepButton.textContent = &apos;Next Step&apos;;
            stepButton.disabled = false;
            stepButton.style.backgroundColor = &apos;#2196F3&apos;;
            
            updateStatus(0);
            updateTableau(0);
            createVisualization();
        }
        
        // Event listeners
        stepButton.addEventListener(&apos;click&apos;, nextStep);
        resetButton.addEventListener(&apos;click&apos;, reset);
        
        // Initialize
        createVisualization();
        updateStatus(0);
        updateTableau(0);
    }
    
    // Initialize all interactive elements
    initializeFarmerProblem();
    initializeDietSolver();
    initializeSimplexVisualization();
    
    // Trigger MathJax re-rendering if needed
    if (window.MathJax) {
        MathJax.typesetPromise();
    }
});
&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>05-01-01 Quy Hoạch Tuyến Tính - Thuật Toán Simplex</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_01_01_LP_Simple_Algorithm/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_01_01_LP_Simple_Algorithm</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>05 Các Bài Toán Chuẩn</title>
   <link href="http://localhost:4000/contents/vi/chapter05/05_00_Canonical_Problems/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/05_00_Canonical_Problems</id>
   <content type="html">&lt;h1 id=&quot;các-bài-toán-chuẩn&quot;&gt;Các Bài Toán Chuẩn&lt;/h1&gt;

&lt;p&gt;Trong &lt;a href=&quot;/chapter01/2021/01/07/optimization_problems/&quot;&gt;Chương 1&lt;/a&gt;, chúng ta đã học rằng một bài toán tối ưu lồi được định nghĩa như sau:&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter05/05_00_optimization_problem.png&quot; alt=&quot;[Fig1] Bài toán tối ưu lồi ở dạng chuẩn [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Bài toán tối ưu lồi ở dạng chuẩn [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Tập miền xác định là lồi&lt;/li&gt;
  &lt;li&gt;Hàm mục tiêu \(f\) và hàm ràng buộc bất đẳng thức \(g_i\) là lồi&lt;/li&gt;
  &lt;li&gt;Hàm ràng buộc đẳng thức \(h_j\) là affine&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tùy thuộc vào loại hàm mục tiêu và hàm ràng buộc, các bài toán tối ưu được phân loại thành nhiều danh mục khác nhau. Trong chương này, chúng ta sẽ tìm hiểu về sáu lớp con chính:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Quy hoạch tuyến tính (Linear Programming - LP)&lt;/li&gt;
  &lt;li&gt;Quy hoạch bậc hai (Quadratic Programming - QP)&lt;/li&gt;
  &lt;li&gt;Quy hoạch bậc hai với ràng buộc bậc hai (Quadratically Constrained Quadratic Programming - QCQP)&lt;/li&gt;
  &lt;li&gt;Quy hoạch nón bậc hai (Second-Order Cone Programming - SOCP)&lt;/li&gt;
  &lt;li&gt;Quy hoạch bán xác định (Semidefinite Programming - SDP)&lt;/li&gt;
  &lt;li&gt;Quy hoạch nón (Conic Programming - CP)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Các bài toán này có mối quan hệ bao hàm như sau và trở nên tổng quát hơn khi di chuyển xuống dưới trong danh sách:&lt;/p&gt;

&lt;p&gt;\(LP \subseteq QP \subseteq QCQP \subseteq SOCP \subseteq SDP \subseteq CP\)&lt;/p&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter05/05_00_canonical_problems.jpeg&quot; alt=&quot;[Fig2] Các Bài Toán Chuẩn&quot; width=&quot;90%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Các Bài Toán Chuẩn&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>02-01-05 Siêu phẳng</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_01_05_Hyperplane/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_01_05_Hyperplane</id>
   <content type="html">&lt;p&gt;Siêu phẳng là một trong những đối tượng hình học cơ bản nhất trong tối ưu hóa lồi và đại số tuyến tính. Nó đóng vai trò như một khối xây dựng để hiểu các tập lồi phức tạp hơn và đóng vai trò quan trọng trong các thuật toán tối ưu hóa, machine learning và phân tích hình học.&lt;/p&gt;

&lt;h2 id=&quot;định-nghĩa-siêu-phẳng&quot;&gt;Định nghĩa Siêu phẳng&lt;/h2&gt;

&lt;p&gt;Một &lt;strong&gt;siêu phẳng&lt;/strong&gt; trong \(\mathbb{R}^n\) là một tập hợp có dạng:&lt;/p&gt;

&lt;blockquote&gt;
\[\mathcal{H} = \{x \in \mathbb{R}^n : a^T x = b\}\]
&lt;/blockquote&gt;

&lt;p&gt;trong đó \(a \in \mathbb{R}^n\) là một vector khác không (\(a \neq 0\)) và \(b \in \mathbb{R}\) là một số vô hướng.&lt;/p&gt;

&lt;p&gt;Vector \(a\) được gọi là &lt;strong&gt;vector pháp tuyến&lt;/strong&gt; của siêu phẳng, và nó xác định hướng của siêu phẳng. Số vô hướng \(b\) xác định vị trí của siêu phẳng so với gốc tọa độ.&lt;/p&gt;

&lt;h3 id=&quot;giải-thích-hình-học&quot;&gt;Giải thích Hình học&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Trong \(\mathbb{R}^2\): Một siêu phẳng là một &lt;strong&gt;đường thẳng&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Trong \(\mathbb{R}^3\): Một siêu phẳng là một &lt;strong&gt;mặt phẳng&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Trong \(\mathbb{R}^n\) (\(n &amp;gt; 3\)): Một siêu phẳng là một không gian con \((n-1)\) chiều&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Siêu phẳng chia toàn bộ không gian \(\mathbb{R}^n\) thành hai &lt;strong&gt;nửa không gian&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Nửa không gian dương&lt;/strong&gt;: \(\{x : a^T x \geq b\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nửa không gian âm&lt;/strong&gt;: \(\{x : a^T x \leq b\}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tính-chất-của-siêu-phẳng&quot;&gt;Tính chất của Siêu phẳng&lt;/h2&gt;

&lt;h3 id=&quot;1-tính-chất-tập-affine&quot;&gt;1. Tính chất Tập Affine&lt;/h3&gt;
&lt;p&gt;Mọi siêu phẳng đều là &lt;strong&gt;tập affine&lt;/strong&gt;. Điều này có nghĩa là nếu \(x_1, x_2 \in \mathcal{H}\), thì toàn bộ đường thẳng đi qua chúng cũng được chứa trong \(\mathcal{H}\):&lt;/p&gt;

\[\theta x_1 + (1-\theta) x_2 \in \mathcal{H} \quad \forall \theta \in \mathbb{R}\]

&lt;p&gt;&lt;strong&gt;Chứng minh&lt;/strong&gt;: Nếu \(a^T x_1 = b\) và \(a^T x_2 = b\), thì:
\(a^T(\theta x_1 + (1-\theta) x_2) = \theta a^T x_1 + (1-\theta) a^T x_2 = \theta b + (1-\theta) b = b\)&lt;/p&gt;

&lt;h3 id=&quot;2-tính-chất-tập-lồi&quot;&gt;2. Tính chất Tập Lồi&lt;/h3&gt;
&lt;p&gt;Vì mọi tập affine đều là lồi, siêu phẳng là &lt;strong&gt;tập lồi&lt;/strong&gt;. Với bất kỳ \(x_1, x_2 \in \mathcal{H}\) và \(\lambda \in [0,1]\):&lt;/p&gt;

\[\lambda x_1 + (1-\lambda) x_2 \in \mathcal{H}\]

&lt;h3 id=&quot;3-tính-chất-tập-đóng&quot;&gt;3. Tính chất Tập Đóng&lt;/h3&gt;
&lt;p&gt;Siêu phẳng là &lt;strong&gt;tập đóng&lt;/strong&gt; vì chúng là tập mức của các hàm tuyến tính liên tục.&lt;/p&gt;

&lt;h3 id=&quot;4-chiều&quot;&gt;4. Chiều&lt;/h3&gt;
&lt;p&gt;Một siêu phẳng trong \(\mathbb{R}^n\) có chiều \(n-1\).&lt;/p&gt;

&lt;h2 id=&quot;các-cách-biểu-diễn-khác&quot;&gt;Các cách biểu diễn khác&lt;/h2&gt;

&lt;h3 id=&quot;1-dạng-điểm-pháp-tuyến&quot;&gt;1. Dạng Điểm-Pháp tuyến&lt;/h3&gt;
&lt;p&gt;Nếu chúng ta biết một điểm \(x_0\) trên siêu phẳng và vector pháp tuyến \(a\), siêu phẳng có thể được viết như:&lt;/p&gt;

\[\mathcal{H} = \{x : a^T (x - x_0) = 0\}\]

&lt;p&gt;Điều này tương đương với \(a^T x = a^T x_0\), vậy \(b = a^T x_0\).&lt;/p&gt;

&lt;h3 id=&quot;2-dạng-ma-trận&quot;&gt;2. Dạng Ma trận&lt;/h3&gt;
&lt;p&gt;Một siêu phẳng cũng có thể được biểu diễn bằng ký hiệu ma trận. Nếu \(A\) là ma trận \(1 \times n\) (vector hàng), thì:&lt;/p&gt;

\[\mathcal{H} = \{x : Ax = b\}\]

&lt;h3 id=&quot;3-dạng-tham-số&quot;&gt;3. Dạng Tham số&lt;/h3&gt;
&lt;p&gt;Một siêu phẳng có thể được tham số hóa bằng cách sử dụng một cơ sở cho không gian null của nó. Nếu \(\{v_1, v_2, \ldots, v_{n-1}\}\) là một cơ sở trực chuẩn cho không gian null của \(a^T\), và \(x_0\) là bất kỳ điểm nào trên siêu phẳng, thì:&lt;/p&gt;

\[\mathcal{H} = \{x_0 + t_1 v_1 + t_2 v_2 + \cdots + t_{n-1} v_{n-1} : t_i \in \mathbb{R}\}\]

&lt;h2 id=&quot;khoảng-cách-từ-điểm-đến-siêu-phẳng&quot;&gt;Khoảng cách từ Điểm đến Siêu phẳng&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Khoảng cách&lt;/strong&gt; từ một điểm \(x_0\) đến siêu phẳng \(\{x : a^T x = b\}\) được cho bởi:&lt;/p&gt;

\[d(x_0, \mathcal{H}) = \frac{\lvert a^T x_0 - b \rvert}{\lVert a \rVert_2}\]

&lt;p&gt;Công thức này xuất phát từ việc chiếu vector từ bất kỳ điểm nào trên siêu phẳng đến \(x_0\) lên hướng pháp tuyến.&lt;/p&gt;

&lt;h3 id=&quot;suy-dẫn&quot;&gt;Suy dẫn&lt;/h3&gt;
&lt;p&gt;Gọi \(x^*\) là điểm gần nhất trên siêu phẳng với \(x_0\). Thì \(x^* - x_0\) song song với vector pháp tuyến \(a\):&lt;/p&gt;

\[x^* - x_0 = t \frac{a}{\lVert a \rVert_2}\]

&lt;p&gt;Vì \(x^* \in \mathcal{H}\), ta có \(a^T x^* = b\). Thay thế:&lt;/p&gt;

\[a^T \left(x_0 + t \frac{a}{\lVert a \rVert_2}\right) = b\]

&lt;p&gt;Giải tìm \(t\): \(t = \frac{b - a^T x_0}{\lVert a \rVert_2}\)&lt;/p&gt;

&lt;p&gt;Khoảng cách là \(\lvert t \rvert = \frac{\lvert a^T x_0 - b \rvert}{\lVert a \rVert_2}\).&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ&quot;&gt;Ví dụ&lt;/h2&gt;

&lt;h3 id=&quot;ví-dụ-1-đường-thẳng-trong-mathbbr2&quot;&gt;Ví dụ 1: Đường thẳng trong \(\mathbb{R}^2\)&lt;/h3&gt;
&lt;p&gt;Siêu phẳng \(2x_1 + 3x_2 = 6\) biểu diễn một đường thẳng trong mặt phẳng.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Vector pháp tuyến: \(a = (2, 3)\)&lt;/li&gt;
  &lt;li&gt;Đường thẳng đi qua các điểm \((3, 0)\) và \((0, 2)\)&lt;/li&gt;
  &lt;li&gt;Khoảng cách từ gốc tọa độ: \(\frac{\lvert 2 \cdot 0 + 3 \cdot 0 - 6 \rvert}{\sqrt{2^2 + 3^2}} = \frac{6}{\sqrt{13}}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ví-dụ-2-mặt-phẳng-trong-mathbbr3&quot;&gt;Ví dụ 2: Mặt phẳng trong \(\mathbb{R}^3\)&lt;/h3&gt;
&lt;p&gt;Siêu phẳng \(x_1 - 2x_2 + x_3 = 4\) biểu diễn một mặt phẳng trong không gian 3D.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Vector pháp tuyến: \(a = (1, -2, 1)\)&lt;/li&gt;
  &lt;li&gt;Mặt phẳng đi qua các điểm \((4, 0, 0)\), \((0, -2, 0)\), và \((0, 0, 4)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ví-dụ-3-siêu-phẳng-đi-qua-gốc-tọa-độ&quot;&gt;Ví dụ 3: Siêu phẳng đi qua Gốc tọa độ&lt;/h3&gt;
&lt;p&gt;Siêu phẳng \(a^T x = 0\) luôn đi qua gốc tọa độ và thực sự là một &lt;strong&gt;không gian con&lt;/strong&gt; có chiều \(n-1\).&lt;/p&gt;

&lt;h2 id=&quot;trực-quan-hóa-tương-tác&quot;&gt;Trực quan hóa Tương tác&lt;/h2&gt;

&lt;p&gt;[Ghi chú: Phần này chứa mã JavaScript để tạo trực quan hóa tương tác về siêu phẳng. Phần này sẽ được dịch riêng do tính phức tạp của mã.]&lt;/p&gt;

&lt;h2 id=&quot;mối-quan-hệ-với-các-khái-niệm-khác&quot;&gt;Mối quan hệ với các Khái niệm khác&lt;/h2&gt;

&lt;h3 id=&quot;kết-nối-với-tập-affine&quot;&gt;Kết nối với Tập Affine&lt;/h3&gt;
&lt;p&gt;Mọi siêu phẳng đều là tập affine, nhưng không phải mọi tập affine đều là siêu phẳng. Siêu phẳng là các tập affine có chiều \((n-1)\) cụ thể trong \(\mathbb{R}^n\).&lt;/p&gt;

&lt;h3 id=&quot;kết-nối-với-đại-số-tuyến-tính&quot;&gt;Kết nối với Đại số Tuyến tính&lt;/h3&gt;
&lt;p&gt;Siêu phẳng \(\{x : a^T x = b\}\) là &lt;strong&gt;tập mức&lt;/strong&gt; của hàm tuyến tính \(f(x) = a^T x\) tại mức \(b\). Gradient của hàm này là hằng số và bằng \(a\), điều này giải thích tại sao \(a\) vuông góc với siêu phẳng.&lt;/p&gt;

&lt;h3 id=&quot;kết-nối-với-tối-ưu-hóa&quot;&gt;Kết nối với Tối ưu hóa&lt;/h3&gt;
&lt;p&gt;Trong tối ưu hóa có ràng buộc, các ràng buộc đẳng thức thường định nghĩa các siêu phẳng hạn chế miền khả thi. Phương pháp nhân tử Lagrange khai thác thực tế rằng tại điểm tối ưu, gradient của hàm mục tiêu song song với vector pháp tuyến của siêu phẳng ràng buộc.&lt;/p&gt;

&lt;h2 id=&quot;interactive-visualization&quot;&gt;Interactive Visualization&lt;/h2&gt;

&lt;div id=&quot;hyperplane-container&quot; style=&quot;width: 100%; max-width: 800px; margin: 20px auto;&quot;&gt;
    &lt;div id=&quot;controls&quot; style=&quot;margin-bottom: 20px; text-align: center;&quot;&gt;
        &lt;label&gt;Normal vector a₁: &lt;input type=&quot;range&quot; id=&quot;a1-slider&quot; min=&quot;-3&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;&lt;/label&gt;
        &lt;span id=&quot;a1-value&quot;&gt;1.0&lt;/span&gt;&lt;br /&gt;
        &lt;label&gt;Normal vector a₂: &lt;input type=&quot;range&quot; id=&quot;a2-slider&quot; min=&quot;-3&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;&lt;/label&gt;
        &lt;span id=&quot;a2-value&quot;&gt;1.0&lt;/span&gt;&lt;br /&gt;
        &lt;label&gt;Offset b: &lt;input type=&quot;range&quot; id=&quot;b-slider&quot; min=&quot;-5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;0&quot; /&gt;&lt;/label&gt;
        &lt;span id=&quot;b-value&quot;&gt;0.0&lt;/span&gt;&lt;br /&gt;
        &lt;button id=&quot;reset-btn&quot;&gt;Reset&lt;/button&gt;
    &lt;/div&gt;
    &lt;canvas id=&quot;hyperplane-canvas&quot; width=&quot;600&quot; height=&quot;400&quot; style=&quot;border: 1px solid #ccc; display: block; margin: 0 auto;&quot;&gt;&lt;/canvas&gt;
    &lt;div id=&quot;info&quot; style=&quot;text-align: center; margin-top: 10px; font-family: monospace;&quot;&gt;
        &lt;p&gt;Hyperplane equation: &lt;span id=&quot;equation&quot;&gt;x₁ + x₂ = 0&lt;/span&gt;&lt;/p&gt;
        &lt;p&gt;Distance from origin: &lt;span id=&quot;distance&quot;&gt;0.0&lt;/span&gt;&lt;/p&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
class HyperplaneVisualizer {
    constructor() {
        this.canvas = document.getElementById(&apos;hyperplane-canvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        // Parameters
        this.a1 = 1;
        this.a2 = 1;
        this.b = 0;
        
        // Scale and offset for coordinate system
        this.scale = 40;
        this.centerX = this.width / 2;
        this.centerY = this.height / 2;
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const a1Slider = document.getElementById(&apos;a1-slider&apos;);
        const a2Slider = document.getElementById(&apos;a2-slider&apos;);
        const bSlider = document.getElementById(&apos;b-slider&apos;);
        const resetBtn = document.getElementById(&apos;reset-btn&apos;);
        
        a1Slider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.a1 = parseFloat(e.target.value);
            document.getElementById(&apos;a1-value&apos;).textContent = this.a1.toFixed(1);
            this.updateDisplay();
        });
        
        a2Slider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.a2 = parseFloat(e.target.value);
            document.getElementById(&apos;a2-value&apos;).textContent = this.a2.toFixed(1);
            this.updateDisplay();
        });
        
        bSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.b = parseFloat(e.target.value);
            document.getElementById(&apos;b-value&apos;).textContent = this.b.toFixed(1);
            this.updateDisplay();
        });
        
        resetBtn.addEventListener(&apos;click&apos;, () =&gt; {
            this.a1 = 1;
            this.a2 = 1;
            this.b = 0;
            a1Slider.value = 1;
            a2Slider.value = 1;
            bSlider.value = 0;
            document.getElementById(&apos;a1-value&apos;).textContent = &apos;1.0&apos;;
            document.getElementById(&apos;a2-value&apos;).textContent = &apos;1.0&apos;;
            document.getElementById(&apos;b-value&apos;).textContent = &apos;0.0&apos;;
            this.updateDisplay();
        });
    }
    
    updateDisplay() {
        this.draw();
        this.updateInfo();
    }
    
    updateInfo() {
        // Update equation
        const eq = `${this.a1.toFixed(1)}x₁ + ${this.a2.toFixed(1)}x₂ = ${this.b.toFixed(1)}`;
        document.getElementById(&apos;equation&apos;).textContent = eq;
        
        // Update distance from origin
        const distance = Math.abs(this.b) / Math.sqrt(this.a1 * this.a1 + this.a2 * this.a2);
        document.getElementById(&apos;distance&apos;).textContent = distance.toFixed(3);
    }
    
    worldToScreen(x, y) {
        return {
            x: this.centerX + x * this.scale,
            y: this.centerY - y * this.scale
        };
    }
    
    draw() {
        // Clear canvas
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        // Draw coordinate system
        this.drawCoordinateSystem();
        
        // Draw hyperplane (line in 2D)
        this.drawHyperplane();
        
        // Draw normal vector
        this.drawNormalVector();
        
        // Draw distance from origin
        this.drawDistanceFromOrigin();
    }
    
    drawCoordinateSystem() {
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        
        // Grid lines
        for (let i = -10; i &lt;= 10; i++) {
            if (i === 0) continue;
            
            // Vertical lines
            const x = this.centerX + i * this.scale;
            this.ctx.beginPath();
            this.ctx.moveTo(x, 0);
            this.ctx.lineTo(x, this.height);
            this.ctx.stroke();
            
            // Horizontal lines
            const y = this.centerY + i * this.scale;
            this.ctx.beginPath();
            this.ctx.moveTo(0, y);
            this.ctx.lineTo(this.width, y);
            this.ctx.stroke();
        }
        
        // Axes
        this.ctx.strokeStyle = &apos;#666&apos;;
        this.ctx.lineWidth = 2;
        
        // X-axis
        this.ctx.beginPath();
        this.ctx.moveTo(0, this.centerY);
        this.ctx.lineTo(this.width, this.centerY);
        this.ctx.stroke();
        
        // Y-axis
        this.ctx.beginPath();
        this.ctx.moveTo(this.centerX, 0);
        this.ctx.lineTo(this.centerX, this.height);
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#666&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.fillText(&apos;x₁&apos;, this.width - 20, this.centerY - 10);
        this.ctx.fillText(&apos;x₂&apos;, this.centerX + 10, 15);
    }
    
    drawHyperplane() {
        if (Math.abs(this.a1) &lt; 1e-10 &amp;&amp; Math.abs(this.a2) &lt; 1e-10) return;
        
        this.ctx.strokeStyle = &apos;#2196F3&apos;;
        this.ctx.lineWidth = 3;
        
        // Find two points on the line a1*x1 + a2*x2 = b
        let x1_start, y1_start, x1_end, y1_end;
        
        if (Math.abs(this.a2) &gt; 1e-10) {
            // Line is not vertical
            x1_start = -10;
            y1_start = (this.b - this.a1 * x1_start) / this.a2;
            x1_end = 10;
            y1_end = (this.b - this.a1 * x1_end) / this.a2;
        } else {
            // Line is vertical
            x1_start = x1_end = this.b / this.a1;
            y1_start = -10;
            y1_end = 10;
        }
        
        const start = this.worldToScreen(x1_start, y1_start);
        const end = this.worldToScreen(x1_end, y1_end);
        
        this.ctx.beginPath();
        this.ctx.moveTo(start.x, start.y);
        this.ctx.lineTo(end.x, end.y);
        this.ctx.stroke();
        
        // Label
        const midX = (start.x + end.x) / 2;
        const midY = (start.y + end.y) / 2;
        this.ctx.fillStyle = &apos;#2196F3&apos;;
        this.ctx.font = &apos;bold 14px Arial&apos;;
        this.ctx.fillText(&apos;Hyperplane&apos;, midX + 10, midY - 10);
    }
    
    drawNormalVector() {
        if (Math.abs(this.a1) &lt; 1e-10 &amp;&amp; Math.abs(this.a2) &lt; 1e-10) return;
        
        // Normalize the normal vector for display
        const norm = Math.sqrt(this.a1 * this.a1 + this.a2 * this.a2);
        const na1 = this.a1 / norm;
        const na2 = this.a2 / norm;
        
        // Find a point on the hyperplane closest to origin
        const t = this.b / (this.a1 * this.a1 + this.a2 * this.a2);
        const px = t * this.a1;
        const py = t * this.a2;
        
        const startPoint = this.worldToScreen(px, py);
        const endPoint = this.worldToScreen(px + na1 * 2, py + na2 * 2);
        
        // Draw normal vector
        this.ctx.strokeStyle = &apos;#FF5722&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.moveTo(startPoint.x, startPoint.y);
        this.ctx.lineTo(endPoint.x, endPoint.y);
        this.ctx.stroke();
        
        // Draw arrowhead
        const angle = Math.atan2(endPoint.y - startPoint.y, endPoint.x - startPoint.x);
        const arrowLength = 10;
        this.ctx.beginPath();
        this.ctx.moveTo(endPoint.x, endPoint.y);
        this.ctx.lineTo(
            endPoint.x - arrowLength * Math.cos(angle - Math.PI / 6),
            endPoint.y - arrowLength * Math.sin(angle - Math.PI / 6)
        );
        this.ctx.moveTo(endPoint.x, endPoint.y);
        this.ctx.lineTo(
            endPoint.x - arrowLength * Math.cos(angle + Math.PI / 6),
            endPoint.y - arrowLength * Math.sin(angle + Math.PI / 6)
        );
        this.ctx.stroke();
        
        // Label
        this.ctx.fillStyle = &apos;#FF5722&apos;;
        this.ctx.font = &apos;bold 12px Arial&apos;;
        this.ctx.fillText(&apos;Normal vector a&apos;, endPoint.x + 5, endPoint.y - 5);
    }
    
    drawDistanceFromOrigin() {
        if (Math.abs(this.a1) &lt; 1e-10 &amp;&amp; Math.abs(this.a2) &lt; 1e-10) return;
        
        // Find closest point on hyperplane to origin
        const t = this.b / (this.a1 * this.a1 + this.a2 * this.a2);
        const px = t * this.a1;
        const py = t * this.a2;
        
        const origin = this.worldToScreen(0, 0);
        const closestPoint = this.worldToScreen(px, py);
        
        // Draw distance line
        this.ctx.strokeStyle = &apos;#4CAF50&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.setLineDash([5, 5]);
        this.ctx.beginPath();
        this.ctx.moveTo(origin.x, origin.y);
        this.ctx.lineTo(closestPoint.x, closestPoint.y);
        this.ctx.stroke();
        this.ctx.setLineDash([]);
        
        // Draw origin point
        this.ctx.fillStyle = &apos;#4CAF50&apos;;
        this.ctx.beginPath();
        this.ctx.arc(origin.x, origin.y, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Draw closest point
        this.ctx.beginPath();
        this.ctx.arc(closestPoint.x, closestPoint.y, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Label
        const midX = (origin.x + closestPoint.x) / 2;
        const midY = (origin.y + closestPoint.y) / 2;
        this.ctx.fillStyle = &apos;#4CAF50&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.fillText(&apos;Distance&apos;, midX + 5, midY + 5);
    }
}

// Initialize visualization when page loads
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new HyperplaneVisualizer();
});
&lt;/script&gt;

&lt;h2 id=&quot;relationship-to-other-concepts&quot;&gt;Relationship to Other Concepts&lt;/h2&gt;

&lt;h3 id=&quot;connection-to-affine-sets&quot;&gt;Connection to Affine Sets&lt;/h3&gt;
&lt;p&gt;Every hyperplane is an affine set, but not every affine set is a hyperplane. Hyperplanes are specifically \((n-1)\)-dimensional affine sets in \(\mathbb{R}^n\).&lt;/p&gt;

&lt;h3 id=&quot;connection-to-linear-algebra&quot;&gt;Connection to Linear Algebra&lt;/h3&gt;
&lt;p&gt;The hyperplane \(\{x : a^T x = b\}\) is the &lt;strong&gt;level set&lt;/strong&gt; of the linear function \(f(x) = a^T x\) at level \(b\). The gradient of this function is constant and equal to \(a\), which explains why \(a\) is perpendicular to the hyperplane.&lt;/p&gt;

&lt;h3 id=&quot;connection-to-optimization&quot;&gt;Connection to Optimization&lt;/h3&gt;
&lt;p&gt;In constrained optimization, equality constraints often define hyperplanes that restrict the feasible region. The method of Lagrange multipliers exploits the fact that at an optimal point, the gradient of the objective function is parallel to the normal vector of the constraint hyperplane.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-01-04 Hình Nón</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_01_04_Convex_cone/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_01_04_Convex_cone</id>
   <content type="html">&lt;p&gt;Hình nón là một tập hợp kéo dài vô hạn theo những hướng nhất định, giống như một chùm ánh sáng từ một nguồn, nhưng không được định nghĩa theo hướng ngược lại. Để xác định xem một tập hợp có phải là hình nón hay không, hãy kiểm tra xem tia bắt đầu từ gốc tọa độ và đi qua bất kỳ điểm nào trong tập hợp đó có được chứa trong tập hợp hay không. (Do đó, một hình nón phải bao gồm gốc tọa độ.) Vì hình nón có biên giới, nó không thể là một tập affine. Hãy định nghĩa điều này một cách toán học.&lt;/p&gt;

&lt;h2 id=&quot;hình-nón&quot;&gt;Hình Nón&lt;/h2&gt;

&lt;p&gt;Một tập \(C\) là một &lt;strong&gt;hình nón&lt;/strong&gt; (hoặc &lt;strong&gt;tập đồng nhất không âm&lt;/strong&gt;) nếu với bất kỳ điểm \(x \in C\), tia \(\theta x\) cũng nằm trong \(C\) với \(\theta \ge 0\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\theta x \in C\) với \(x \in C\), \(\theta \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;[Tham khảo] Khác với tập affine hoặc tập lồi, khi định nghĩa hình nón, điểm bắt đầu của tia được giả định là gốc tọa độ, vì vậy chỉ sử dụng một điểm.&lt;/p&gt;

&lt;h2 id=&quot;hình-nón-lồi&quot;&gt;Hình Nón Lồi&lt;/h2&gt;

&lt;p&gt;Một tập \(C\) là một &lt;strong&gt;hình nón lồi&lt;/strong&gt; nếu nó vừa là hình nón vừa là tập lồi:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\theta_1 x_1 + \theta_2 x_2 \in C\) với \(x_1, x_2 \in C\), \(\theta_1, \theta_2 \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hình dưới đây cho thấy một hình nón lồi có dạng hình quạt. Trong hình, \(x_1\) và \(x_2\) là các điểm trong hình nón, và \(\theta_1\) và \(\theta_2\) là các vô hướng không âm.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.04_Convex_Cone.png&quot; alt=&quot;[Hình1] Hình Nón Lồi [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] Hình Nón Lồi [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;tổ-hợp-nón&quot;&gt;Tổ hợp Nón&lt;/h2&gt;

&lt;p&gt;Một tổ hợp tuyến tính của nhiều điểm trong đó tất cả các hệ số đều không âm được gọi là &lt;strong&gt;tổ hợp nón&lt;/strong&gt; (hoặc &lt;strong&gt;tổ hợp tuyến tính không âm&lt;/strong&gt;):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Một điểm có dạng \(\theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_k x_k\) với \(\theta_i \ge 0, i = 1,  ..., k\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nếu mọi tổ hợp nón của các điểm trong tập \(C\) cũng nằm trong \(C\), thì \(C\) là một tập nón.&lt;/p&gt;

&lt;h2 id=&quot;bao-nón&quot;&gt;Bao Nón&lt;/h2&gt;

&lt;p&gt;Tập hợp tất cả các tổ hợp nón của các điểm trong \(C \subseteq \mathbb{R}^n\) được gọi là &lt;strong&gt;bao nón&lt;/strong&gt; của \(C\). Bao nón luôn là hình nón lồi nhỏ nhất chứa \(C\):&lt;/p&gt;
&lt;blockquote&gt;
\[\{ \theta_1 x_1 + \cdots + \theta_k x_k \mid x_i \in C, \theta_i \ge 0, i = 1, ..., k \}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>02-01-03 Tập Lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_01_03_Convex-set/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_01_03_Convex-set</id>
   <content type="html">&lt;p&gt;Bây giờ hãy xem xét khái niệm cốt lõi của chương này: tập lồi. Một cách trực quan, tập lồi là một tập hợp không có “vết lõm” hoặc “lỗ hổng” bên trong. Để xác định xem một tập hợp có lồi hay không, hãy kiểm tra xem đoạn thẳng nối bất kỳ hai điểm nào trong tập hợp đó có được chứa trong tập hợp hay không.&lt;/p&gt;

&lt;h2 id=&quot;tập-lồi&quot;&gt;Tập Lồi&lt;/h2&gt;

&lt;p&gt;Một tập \(C \subseteq \mathbb{R}^n\) là một &lt;strong&gt;tập lồi&lt;/strong&gt; nếu với bất kỳ hai điểm \(x_1, x_2 \in C\), đoạn thẳng nối chúng cũng nằm trong \(C\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\theta x_1 + (1-\theta)x_2 \in C\) với \(x_1, x_2 \in C\), \(0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Điều này có nghĩa là với bất kỳ hai điểm nào trong \(C\), tất cả các điểm trên đoạn thẳng giữa chúng cũng nằm trong \(C\).&lt;/p&gt;

&lt;p&gt;Hình dưới đây cho thấy các ví dụ về tập lồi. Tam giác bên trái là lồi, nhưng hình có lõm bên phải không lồi vì đoạn thẳng giữa một số điểm ra khỏi tập hợp.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.02_Convex_Set.png&quot; alt=&quot;[Hình1] Tập Lồi [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] Tập Lồi [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;tổ-hợp-lồi&quot;&gt;Tổ hợp Lồi&lt;/h2&gt;

&lt;p&gt;Một tổ hợp tuyến tính của nhiều điểm trong đó các hệ số không âm và tổng bằng 1 được gọi là &lt;strong&gt;tổ hợp lồi&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Một điểm có dạng \(\theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_k x_k\) với \(\theta_1 + \theta_2 + \cdots + \theta_k = 1, \theta_i \ge  0, i = 1,  ..., k\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nếu mọi tổ hợp lồi của các điểm trong tập \(C\) cũng nằm trong \(C\), thì \(C\) là một tập lồi.&lt;/p&gt;

&lt;h2 id=&quot;bao-lồi&quot;&gt;Bao Lồi&lt;/h2&gt;

&lt;p&gt;Tập hợp tất cả các tổ hợp lồi của các điểm trong \(C \subseteq \mathbb{R}^n\) được gọi là &lt;strong&gt;bao lồi&lt;/strong&gt; của \(C\), ký hiệu là &lt;strong&gt;conv&lt;/strong&gt; \(C\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;conv&lt;/strong&gt; \(C = \{ \theta_1 x_1 + \cdots + \theta_k x_k \mid x_i \in C, \theta_i \ge 0, i = 1, ..., k, \theta_1 + \cdots + \theta_k = 1 \}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hình dưới đây cho thấy bao lồi cho một tập hợp 15 điểm và một hình có lõm.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.03_Convex_Hull.png&quot; alt=&quot; Bao Lồi&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;Bao Lồi&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.03_Convex_Hull_2.png&quot; alt=&quot; Bao Lồi&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;Bao Lồi&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>02-01-02 Tập Affine</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_01_02_Affine_set/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_01_02_Affine_set</id>
   <content type="html">&lt;p&gt;Một tập affine là một tập hợp không có biên giới, như một điểm, đường thẳng, mặt phẳng hoặc siêu phẳng. Để xác định xem một tập hợp có phải là affine hay không, hãy kiểm tra xem đường thẳng đi qua bất kỳ hai điểm nào trong tập hợp đó có được chứa trong tập hợp hay không. Việc không có biên giới có nghĩa là nếu bất kỳ không gian nào có biên giới, thì nó không thể là một tập affine. Hãy định nghĩa điều này một cách toán học.&lt;/p&gt;

&lt;h2 id=&quot;tập-affine&quot;&gt;Tập Affine&lt;/h2&gt;

&lt;p&gt;Một tập \(C \subseteq \mathbb{R}^n\) là một &lt;strong&gt;tập affine&lt;/strong&gt; nếu với bất kỳ hai điểm \(x_1, x_2 \in C\), đường thẳng đi qua chúng cũng nằm trong \(C\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\theta x_1 + (1-\theta)x_2 \in C\) với \(\theta \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Điều này có thể được hiểu như một tổ hợp tuyến tính của hai điểm trong \(C\), trong đó tổng các hệ số bằng 1. Nếu kết quả luôn nằm trong \(C\), thì \(C\) là một tập affine.&lt;/p&gt;

&lt;h2 id=&quot;tổ-hợp-affine&quot;&gt;Tổ hợp Affine&lt;/h2&gt;

&lt;p&gt;Một tổ hợp tuyến tính của nhiều điểm trong đó tổng các hệ số bằng 1 được gọi là &lt;strong&gt;tổ hợp affine&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_k x_k \in C\) với \(\theta_1 + \theta_2 + \cdots + \theta_k = 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nếu mọi tổ hợp affine của các điểm trong tập \(C\) cũng nằm trong \(C\), thì \(C\) là một tập affine.&lt;/p&gt;

&lt;h2 id=&quot;bao-affine&quot;&gt;Bao Affine&lt;/h2&gt;

&lt;p&gt;Tập hợp tất cả các tổ hợp affine của các điểm trong \(C \subseteq \mathbb{R}^n\) được gọi là &lt;strong&gt;bao affine&lt;/strong&gt; của \(C\), ký hiệu là &lt;strong&gt;aff&lt;/strong&gt; \(C\):&lt;/p&gt;
&lt;blockquote&gt;
\[\text{aff} (C) = \{ \theta_1 x_1 + \cdots + \theta_k x_k \mid x_1, ..., x_k \in C, \theta_1 + \cdots + \theta_k = 1 \}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;mối-quan-hệ-giữa-tập-affine-và-không-gian-con&quot;&gt;Mối quan hệ giữa tập affine và không gian con&lt;/h2&gt;

&lt;p&gt;Nếu \(C\) là một tập affine và \(x_0 \in C\), thì \(V = C - x_0\) là một không gian con:&lt;/p&gt;
&lt;blockquote&gt;
\[V = C - x_0 =  \{ x - x_0 \mid x \in C \}\]
&lt;/blockquote&gt;

&lt;p&gt;Do đó, “Một tập affine \(C\) là một phép tịnh tiến của không gian con tuyến tính \(V\) bởi \(x_0\),” trong đó \(x_0\) có thể là bất kỳ điểm nào trong \(C\). Chiều của \(C\) giống như chiều của \(V\).&lt;/p&gt;

&lt;h3 id=&quot;tham-khảo-chứng-minh-v-là-một-không-gian-con&quot;&gt;[Tham khảo] Chứng minh \(V\) là một không gian con&lt;/h3&gt;

&lt;p&gt;Để chứng minh \(V\) là một không gian con, cần chỉ ra rằng nó đóng kín dưới phép cộng và nhân vô hướng. Tức là, với \(v_1, v_2 \in V\) và \(\alpha, \beta \in \mathbb{R}\), thì \(\alpha v_1 + \beta v_2 \in V\). Điều này được suy ra từ định nghĩa ở trên.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-01-01 Đường thẳng, đoạn thẳng, tia</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_01_01_Line_line_segment_ray/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_01_01_Line_line_segment_ray</id>
   <content type="html">&lt;p&gt;Để định nghĩa tập affine, tập lồi và hình nón, trước tiên hãy xem xét đường thẳng, đoạn thẳng và tia.&lt;/p&gt;

&lt;p&gt;Đường thẳng là một đường thẳng vô hạn đi qua hai điểm theo cả hai hướng. Ngược lại, đoạn thẳng là một đường thẳng chỉ được xác định giữa hai điểm, và tia bắt đầu từ một điểm và kéo dài vô hạn theo một hướng qua điểm khác. Hình dưới đây cho thấy một đường thẳng và một đoạn thẳng. Tùy thuộc vào phạm vi của tham số \(\theta\), bạn có thể tưởng tượng cách một đường thẳng, đoạn thẳng hoặc tia được định nghĩa.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.01_Line_Segment.png&quot; alt=&quot;Line Segment&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Hình1] } x_1\text{ và } x_2 \text{ định nghĩa Đường thẳng và Đoạn thẳng [1]}$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;[Tham khảo] Khi bạn sử dụng hai điểm được bao gồm trong một tập hợp để tạo ra một đường thẳng, đoạn thẳng hoặc tia, việc liệu những điểm này có được bao gồm trong tập hợp hay không quyết định định nghĩa của tập hợp. (Bạn cũng có thể định nghĩa tập hợp bằng cách sử dụng nhiều điểm và các tổ hợp affine, lồi hoặc nón của chúng. Chi tiết sẽ được giải thích trong các phần tiếp theo.)&lt;/p&gt;

&lt;h2 id=&quot;đường-thẳng&quot;&gt;Đường thẳng&lt;/h2&gt;

&lt;p&gt;Một &lt;strong&gt;Đường thẳng&lt;/strong&gt; đi qua hai điểm \(x_1\) và \(x_2\) được định nghĩa là:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(y = \theta x_1 + (1 - \theta) x_2\) với \(\theta \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;đoạn-thẳng&quot;&gt;Đoạn thẳng&lt;/h2&gt;

&lt;p&gt;Một &lt;strong&gt;Đoạn thẳng&lt;/strong&gt; được định nghĩa bằng cách giới hạn \(\theta\) trong khoảng [0, 1]:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(y = \theta x_1 + (1 - \theta) x_2\) với \(0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hoặc bạn có thể biểu diễn nó như:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(y = x_2 + \theta (x_1 - x_2)\) với \(0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;tia&quot;&gt;Tia&lt;/h2&gt;

&lt;p&gt;Một &lt;strong&gt;Tia&lt;/strong&gt; bắt đầu từ một điểm và kéo dài vô hạn theo một hướng:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(y = x_2 + \theta (x_1 - x_2)\) với \(\theta \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hoặc tương đương:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(y = \theta x_1 + (1 - \theta) x_2\) với \(\theta \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Bây giờ bạn có thể thấy rằng phạm vi của \(\theta\) là \(\theta \in \mathbb{R}\) cho đường thẳng, \(0 \le \theta \le 1\) cho đoạn thẳng, và \(\theta \ge 0\) cho tia. Hơn nữa, bạn sẽ thấy rằng các phạm vi của \(\theta\) giống nhau trong các tập affine, tập lồi và tập nón mà chúng ta sẽ định nghĩa sau này.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>05-06 Conic Programming (CP)</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_06_Conic_Programming_(CP)/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_06_Conic_Programming_(CP)</id>
   <content type="html">&lt;p&gt;If the inequality constraint in a general LP is replaced by a generalized inequality constraint, the problem is called a &lt;em&gt;Conic Program&lt;/em&gt; (CP).&lt;/p&gt;

&lt;h3 id=&quot;conic-program&quot;&gt;Conic Program&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Fx + g \preceq_K 0} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;c, x \in \mathbb{R}^{n}, A \in \mathbb{R}^{p \times n}, \text{and } b \in \mathbb{R}^{p}.
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;\(F: \mathbb{R}^n \rightarrow Y\) is a linear map, \(g \in Y\), for Euclidean space \(Y\).&lt;/li&gt;
  &lt;li&gt;LP is the special case when \(K = \mathbb{R}_{+}^n\), i.e., LP \(\subseteq\) CP.&lt;/li&gt;
  &lt;li&gt;SDP is the special case when \(K = \mathbb{S}_{+}^n\), i.e., SDP \(\subseteq\) CP.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>05-05 Semidefinite Programming (SDP)</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_05_Semidefinite_Programming_(SDP)/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_05_Semidefinite_Programming_(SDP)</id>
   <content type="html">&lt;p&gt;If the inequality constraint in a general LP is replaced by a linear matrix inequality (LMI), the problem is called a &lt;em&gt;Semidefinite Program&lt;/em&gt; (SDP).&lt;/p&gt;

&lt;h3 id=&quot;semidefinite-program&quot;&gt;Semidefinite Program&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{x_1 F_1 + \dotsb + x_n F_n + G \preceq 0} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;G, F_1, \dotsb, F_n \in \mathbb{S}^{k} \text{ and } A \in \mathbb{R}^{p \times n}.
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;If \(G, F_1, \dotsb, F_n\) are all diagonal matrices, the above inequality constraint is equivalent to \(n\) linear inequalities, and the SDP reduces to an LP.&lt;/li&gt;
  &lt;li&gt;Multiple LMIs can be represented as a single LMI using block diagonal matrices:
    &lt;blockquote&gt;
      &lt;p&gt;\(x_1\hat{F_1} + \dotsb + x_n\hat{F_n} + \hat{G} \preceq 0, \quad x_1\tilde{F_1} + \dotsb + x_n\tilde{F_n} + \tilde{G} \preceq 0\)
is equivalent to a single LMI:
\(x_1
\begin{bmatrix}
    \hat{F_1} &amp;amp; 0 \\\\
    0 &amp;amp; \tilde{F_1} \\\\
\end{bmatrix} + 
x_2
\begin{bmatrix}
    \hat{F_2} &amp;amp; 0 \\\\
    0 &amp;amp; \tilde{F_2} \\\\
\end{bmatrix} + 
\dotsb
+
x_n
\begin{bmatrix}
    \hat{F_n} &amp;amp; 0 \\\\
    0 &amp;amp; \tilde{F_n} \\\\
\end{bmatrix} + 
\begin{bmatrix}
    \hat{G} &amp;amp; 0 \\\\
    0 &amp;amp; \tilde{G} \\\\
\end{bmatrix}
\preceq 0\)&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sdp-in-standard-form&quot;&gt;SDP in Standard form&lt;/h2&gt;
&lt;p&gt;When expressed as follows, it is called the standard form of a semidefinite program.&lt;/p&gt;

&lt;h3 id=&quot;standard-form-sdp&quot;&gt;Standard form SDP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{X} &amp;amp;&amp;amp;{\mathrm{tr}(CX)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\mathrm{tr}(A_i X) = b_i, \quad i = 1, \dotsc, m} \\\\
   &amp;amp; &amp;amp;&amp;amp;{X \succeq 0},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;C, A_i \in \mathbb{S}^n, X \in \mathbb{S}^n.
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Recall: \(\mathrm{tr}(CX) = \sum_{i,j=1}^n C_{ij}X_{ij}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All SDPs can be transformed into the standard form SDP through the following process.&lt;/p&gt;

&lt;h3 id=&quot;converting-sdps-to-standard-form&quot;&gt;Converting SDPs to standard form&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Step1.&lt;/strong&gt;  Use a slack variable S to convert the inequality constraint into an equality constraint.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\sum_{l=1}^n F_l x_l+ S = -G} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b}\\\\
   &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step2.&lt;/strong&gt; Transform the equality constraints derived in Step 1 into component-wise equations.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\sum_{l=1}^n (F_l x_l)_{ij} + S_{ij} = -G_{ij}, i,j = 1, \dotsc, k} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b}\\\\
   &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step3.&lt;/strong&gt; Replace x with two nonnegative variables.
\(x = x^{+}  - x^{-}\), where \(x^{+} \text{ and } x^{-} \succeq 0.\)&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T (x^{+}  - x^{-}) + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\sum_{l=1}^n (F_l x^{+} _l)_{ij} - \sum_{l=1}^n (F_l x^{-} _l)_{ij} + S_{ij} = -G_{ij}, i,j = 1, \dotsc, k} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax^{+}  - Ax^{-} = b}\\\\
   &amp;amp; &amp;amp;&amp;amp;{S \succeq 0}\\\\
   &amp;amp; &amp;amp;&amp;amp;{x^{+} \text{, } x^{-} \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step4.&lt;/strong&gt; Define \(X, C, \tilde{A}, \tilde{b}\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;All the blanks are zero.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(X = 
\begin{bmatrix}
diag(x^{+})\\\\
 &amp;amp; diag(x^{-})\\\\
&amp;amp;&amp;amp; s_{11}\\\\
&amp;amp;&amp;amp;&amp;amp; s_{12}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;\dotsc\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;s_{ij}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;\dotsc \\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;s_{kk}\\\\
\end{bmatrix}
,\)
\(C = 
\begin{bmatrix}
diag(c)\\\\
&amp;amp; -diag(c) &amp;amp;\\\\
&amp;amp; &amp;amp; O_{k^2 \text{ x } k^2}\\\\
\end{bmatrix}
,\)
\(P_{ij} = 
\begin{bmatrix}
(F_1)_{ij}\\\\
&amp;amp;(F_2)_{ij}\\\\
&amp;amp;&amp;amp;\dotsc\\\\
&amp;amp;&amp;amp;&amp;amp;(F_n)_{ij}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;-(F_1)_{ij}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;-(F_2)_{ij}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;\dotsc\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;-(F_n)_{ij}\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0&amp;amp;\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;\dotsc\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;1 \phantom{1} (\text{ij th position})\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;\dotsc\\\\
&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0\\\\
\end{bmatrix}
,\)&lt;/p&gt;

  &lt;p&gt;\(Q_{i}= 
\begin{bmatrix}
diag(A_i)\\\\
&amp;amp;-diag(A_i)\\\\
&amp;amp;&amp;amp;O_{k^2 \text{ x } k^2}\\\\
\end{bmatrix}\)
(\(A_i\) is ith row of A),
\(\tilde{A} = 
\begin{bmatrix}
P_{11}\\\\
\dotsc\\\\
P_{kk}\\\\
Q_{1}\\\\
\dotsc\\\\
Q_{p}\\\\
\end{bmatrix}
-G_{ij} = \mathrm{tr}(P_{ij}X)
,\)&lt;/p&gt;

  &lt;p&gt;\(b_i = \mathrm{tr}(Q_iX)\),&lt;/p&gt;

  &lt;p&gt;\(\tilde{b} = 
\begin{bmatrix}
-G_{11}\\\\
\dotsc\\\\
-G_{kk}\\\\
b_{1}\\\\
\dotsc\\\\
b_{p}\\\\
\end{bmatrix}\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step5.&lt;/strong&gt; Substitute the problem from &lt;em&gt;Step3&lt;/em&gt; with \(X, C, \tilde{A}, \tilde{b}\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{X} &amp;amp;&amp;amp;{\mathrm{tr}(CX)} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\mathrm{tr}(\tilde{A}_iX) = \tilde{b}_i, \quad i=1,\dotsc,k^2+p} \\\\
   &amp;amp; &amp;amp;&amp;amp;{X \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;socp-and-equivalent-sdp&quot;&gt;SOCP and equivalent SDP&lt;/h2&gt;
&lt;p&gt;By using the Schur complement[&lt;a href=&quot;https://en.wikipedia.org/wiki/Schur_complement&quot;&gt;8&lt;/a&gt;], the inequality constraint of SOCP can be expressed in such a way that SOCP is transformed into a special case of SDP. That is, there is a relationship of inclusion: SOCP \(\subseteq\) SDP.&lt;/p&gt;

&lt;h3 id=&quot;recall-second-order-cone-program&quot;&gt;Recall: Second-Order Cone Program&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{f^T x} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\| A_i x + b_i \|_2 \leq c_i^T x + d_i, i = 1, \dotsc, m}\\\\
   &amp;amp; &amp;amp;&amp;amp;{Fx = g}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;socp-to-sdp-by-schur-complement&quot;&gt;SOCP to SDP by Schur complement&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{f^T x} \\\\
   &amp;amp;\text{subject to } 
   &amp;amp;&amp;amp;
   \begin{bmatrix}
   (c_i^T x + d)I    &amp;amp; A_i x + b_i \\\\
   (A_i x + b_i)^T &amp;amp; c_i^T x + d \\\\
   \end{bmatrix} \succeq 0, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Fx = g}.
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>05-04 Second-Order Cone Programming (SOCP)</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_04_Second_Order_Cone_Programming_(SOCP)/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_04_Second_Order_Cone_Programming_(SOCP)</id>
   <content type="html">&lt;p&gt;If the inequality constraints in a general LP are replaced with second-order cone constraints (which are affine functions), the problem is called a &lt;em&gt;Second-Order Cone Program&lt;/em&gt; (SOCP).&lt;/p&gt;

&lt;h3 id=&quot;second-order-cone-program&quot;&gt;Second-Order Cone Program&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{f^T x} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\| A_i x + b_i \|_2 \leq c_i^T x + d_i, i = 1, \dotsc, m}\\\\
   &amp;amp; &amp;amp;&amp;amp;{Fx = g},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;x \in \mathbb{R}^n \text{ is the optimization variable, } A_i  \in \mathbb{R}^{n_i \times n}, \text{ and } F \in \mathbb{R}^{p \times n}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;recall-norm-cone&quot;&gt;Recall: Norm cone&lt;/h3&gt;
&lt;p&gt;A &lt;em&gt;norm cone&lt;/em&gt; is a convex cone in \(\mathbb{R}^{n+1}\) defined by all points \((x, t)\) such that \(\| x \| \le t\) for some norm \(\| \cdot \|\).&lt;/p&gt;

&lt;blockquote&gt;
\[\left\{(x, t) : \| x \| \le t \right\} \text{, for a norm } \| \cdot \|\]
&lt;/blockquote&gt;

&lt;p&gt;The figure below shows the norm cone for the \(l_2\) norm \(\| \cdot \|_2\), also called the second-order cone or ice cream cone.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter05/05_04_Norm_Cone.png&quot; alt=&quot;[Fig1] Norm Cone [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Norm Cone [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;qcqp-and-equivalent-socp&quot;&gt;QCQP and equivalent SOCP&lt;/h2&gt;
&lt;p&gt;A QCQP can be reformulated as an SOCP in certain cases, i.e., \(QCQP \subseteq SOCP\).&lt;/p&gt;

&lt;h3 id=&quot;recall-quadratically-constrained-quadratic-program&quot;&gt;Recall: Quadratically Constrained Quadratic Program&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{(1/2)x^T P_0 x + q_0^T x + r_0} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{(1/2)x^T P_i x + q_i^T x + r_i \leq 0}, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;P_i \in \mathbb{S}_{+}^n \text{ for } i = 0, \dotsc, m, \text{ and } A \in \mathbb{R}^{p \times n}
\end{align}\]

  &lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; For convenience, QCQP can be reformulated in different ways to fit SOCP structure.
\(\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{x^T P_0 x + 2q_0^T x + r_0} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{x^T P_i x + 2q_i^T x + r_i \leq 0}, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp; P_i \in \mathbb{S}_{+}^n \text{ for } i = 0, \dotsc, m \text{, and } A \in \mathbb{R}^{\text{p x n}}.
\end{align}\\\)&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; Since \(P_0\) is a positive semidefinite matrix, any \(\tilde{P_0}\) satisfying \(P_0 = \tilde{P_0}\tilde{P_0}\) is also a positive semidefinite matrix. This \(\tilde{P_0}\) can be obtained through eigendecomposition. Using this, the objective function of the QCQP can be transformed as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[P_0 = Q_0 \Lambda_0 \Lambda_0 Q_0^T\]
  &lt;/li&gt;
  &lt;li&gt;
\[I = Q_0 \Lambda_0 \Lambda_0^{-1} Q_0^{-1} = Q_0 \Lambda_0^{-1} \Lambda_0 Q_0^{-1}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\begin{align}
{x^T P_0 x + 2q_0^T x + r_0} &amp;amp;= {x^T P_0 x + q_0^T x + x^T q_0 + q_0^T P_0^{-1} q_0 - q_0^T P_0^{-1} q_0 + r_0}\\\\
&amp;amp;= {x^T Q_0 \Lambda_0 \Lambda_0 Q_0^T x} +
     {q_0^T Q_0 \Lambda_0^{-1} \Lambda_0 Q_0^{-1} x} + {x^T Q_0 \Lambda_0 \Lambda_0^{-1} Q_0^{-1} q_0} +
     {q_0^T Q_0 \Lambda_0^{-1} \Lambda_0^{-1} Q_0^T q_0} - {q_0^T P_0^{-1} q_0 + r_0}\\\\
&amp;amp;=(\Lambda_0 Q_0^T x + \Lambda_0^{-1} Q_0^T q_0)^T(\Lambda_0 Q_0^T x + \Lambda_0^{-1} Q_0^T q_0) - {q_0^T P_0^{-1} q_0 + r_0}\\\\
&amp;amp;=\| \Lambda_0 Q_0^T x + \Lambda_0^{-1} Q_0^T q_0 \|_2^2 - {q_0^T P_0^{-1} q_0 + r_0}\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; The same procedure as in Step 2 is applied to the inequality constraint functions, and then substituted into the QCQP from Step 1.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{\| \Lambda_0 Q_0^T x + \Lambda_0^{-1} Q_0^T q_0 \|_2^2 - {q_0^T P_0^{-1} q_0 + r_0}} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\| \Lambda_i Q_i^T x + \Lambda_i^{-1} Q_i^T q_i \|_2^2 \leq {q_i^T P_i^{-1} q_i + r_i}}, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b}.\\\\
\end{align}\]

&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt; The term \({q_0^T P_0^{-1} q_0 + r_0}\) in the objective function is a constant and can be omitted.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{\| \Lambda_0 Q_0^T x + \Lambda_0^{-1} Q_0^T q_0 \|_2^2} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{\| \Lambda_i Q_i^T x + \Lambda_i^{-1} Q_i^T q_i \|_2^2 \leq {q_i^T P_i^{-1} q_i + r_i} }, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 5.&lt;/strong&gt; Introducing a scalar variable \(t\), the same problem as in Step 4 can be defined.&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x, t} &amp;amp;&amp;amp;{t} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;\lVert{\Lambda_{0} Q_0^T x + \Lambda_0^{-1} Q_0^T q_0} \rVert_2^2 \leq t\\\\
   &amp;amp; &amp;amp;&amp;amp;{\| \Lambda_i Q_i^T x + \Lambda_i^{-1} Q_i^T q_i \|_2^2 \leq {q_i^T P_i^{-1} q_i + r_i} }, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b}.\\\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The above represents a special case of SOCP. Thus, the relationship \(QCQP \subseteq SOCP\) holds.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>05-03 Quadratically Constrained Quadratic Programming (QCQP)</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_03_Quadratically_Constrained_Quadratic_Programming_(QCQP)/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_03_Quadratically_Constrained_Quadratic_Programming_(QCQP)</id>
   <content type="html">&lt;p&gt;If the inequality constraint functions in a quadratic program are replaced with convex quadratic functions, the problem is called a &lt;em&gt;Quadratically Constrained Quadratic Program&lt;/em&gt; (QCQP).&lt;/p&gt;

&lt;h3 id=&quot;quadratically-constrained-quadratic-program&quot;&gt;Quadratically Constrained Quadratic Program&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{(1/2)x^T P_0 x + q_0^T x + r_0} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{(1/2)x^T P_i x + q_i^T x + r_i \leq 0}, i = 1, \dotsc, m\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;P_i \in \mathbb{S}_{+}^n \text{ for } i = 0, \dotsc, m, \text{ and } A \in \mathbb{R}^{p \times n}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;qp-and-equivalent-qcqp&quot;&gt;QP and equivalent QCQP&lt;/h2&gt;
&lt;p&gt;If \(P_i = 0\) for all \(i = 1, \dotsc, m\) in the QCQP constraints, the problem reduces to a QP. Thus, QP is a special case of QCQP, and \(QP \subseteq QCQP\).&lt;/p&gt;

&lt;h3 id=&quot;recall-quadratic-program&quot;&gt;Recall: Quadratic Program&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{(1/2)x^T P x + q^T x + r} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Gx \preceq h} \\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp; \text{where } &amp;amp;&amp;amp;P \in \mathbb{S}_{+}^n, G \in \mathbb{R}^{m \times n}, \text{ and } A \in \mathbb{R}^{p \times n}.
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>05-02 Quadratic Programming (QP)</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_02_Quadratic_Programming_(QP)-copy/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_02_Quadratic_Programming_(QP) copy</id>
   <content type="html">&lt;p&gt;A &lt;strong&gt;Quadratic Program&lt;/strong&gt; (QP) is a convex optimization problem where the objective function is a convex quadratic function and all constraint functions are affine. The general quadratic program is formulated as:&lt;/p&gt;

&lt;h3 id=&quot;general-quadratic-program&quot;&gt;General Quadratic Program&lt;/h3&gt;
&lt;p&gt;\(\begin{align}
    \text{minimize}_{x} \quad &amp;amp;\frac{1}{2}x^T P x + q^T x + r \\
    \text{subject to} \quad &amp;amp;Gx \preceq h \\
    &amp;amp;Ax = b
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;where:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(P \in \mathbb{S}_{+}^n\) (positive semidefinite matrix)&lt;/li&gt;
  &lt;li&gt;\(G \in \mathbb{R}^{m \times n}\) (inequality constraint matrix)&lt;/li&gt;
  &lt;li&gt;\(A \in \mathbb{R}^{p \times n}\) (equality constraint matrix)&lt;/li&gt;
  &lt;li&gt;\(x \in \mathbb{R}^n\) (decision variable)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Key Properties of QP:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The constant \(r\) in the objective function does not affect the optimization process or result and can be omitted.&lt;/li&gt;
  &lt;li&gt;If \(P \in \mathbb{S}_{+}^n\) is not satisfied, the problem is not convex.&lt;/li&gt;
  &lt;li&gt;Even if not explicitly stated, QP assumes \(P \in \mathbb{S}_{+}^n\).&lt;/li&gt;
  &lt;li&gt;The above problem seeks the minimizer \(x^*\) of the convex quadratic function \(\frac{1}{2}x^T P x + q^T x + r\) over a polyhedral feasible set.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;understanding-mathbbs_n-positive-semidefinite-cone&quot;&gt;Understanding \(\mathbb{S}_{+}^n\) (Positive Semidefinite Cone)&lt;/h3&gt;

&lt;p&gt;The notation \(\mathbb{S}_{+}^n\) represents the &lt;strong&gt;positive semidefinite cone&lt;/strong&gt;, which is a fundamental concept in convex optimization:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\mathbb{S}_{+}^n = \{ X \in \mathbb{S}^n : X \succeq 0 \}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;where:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbb{S}^n\) is the set of all \(n \times n\) &lt;strong&gt;symmetric matrices&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;\(X \succeq 0\) means matrix \(X\) is &lt;strong&gt;positive semidefinite&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Key Properties:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Positive semidefinite condition&lt;/strong&gt;: A matrix \(P\) is positive semidefinite if:
    &lt;ul&gt;
      &lt;li&gt;All eigenvalues of \(P\) are non-negative (\(\lambda_i \geq 0\))&lt;/li&gt;
      &lt;li&gt;For any vector \(v\), we have \(v^T P v \geq 0\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Convex cone property&lt;/strong&gt;: \(\mathbb{S}_{+}^n\) is a convex cone because if \(\theta_1, \theta_2 \geq 0\) and \(A, B \in \mathbb{S}_{+}^n\), then \(\theta_1 A + \theta_2 B \in \mathbb{S}_{+}^n\)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Example for \(n=2\):&lt;/strong&gt;
For a \(2 \times 2\) matrix \(P = \begin{bmatrix} a &amp;amp; b \\ b &amp;amp; c \end{bmatrix}\), the condition \(P \in \mathbb{S}_{+}^2\) requires:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(a \geq 0\) (diagonal elements non-negative)&lt;/li&gt;
  &lt;li&gt;\(c \geq 0\) (diagonal elements non-negative)&lt;/li&gt;
  &lt;li&gt;\(ac \geq b^2\) (determinant non-negative)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Why is this important for QP?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The condition \(P \in \mathbb{S}_{+}^n\) ensures that the quadratic function \((1/2)x^T P x + q^T x + r\) is &lt;strong&gt;convex&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Without this condition, the problem may have multiple local minima and would not be a convex optimization problem&lt;/li&gt;
  &lt;li&gt;This guarantees that any local minimum is also a global minimum&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;understanding-gx-preceq-h-component-wise-inequality&quot;&gt;Understanding \(Gx \preceq h\) (Component-wise Inequality)&lt;/h3&gt;

&lt;p&gt;The notation \(Gx \preceq h\) represents &lt;strong&gt;component-wise inequality constraints&lt;/strong&gt;, which is a compact way to write multiple linear inequality constraints:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt;
\(Gx \preceq h \quad \Leftrightarrow \quad (Gx)_i \leq h_i \text{ for all } i = 1, 2, \ldots, m\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;where:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(G \in \mathbb{R}^{m \times n}\) is the constraint matrix&lt;/li&gt;
  &lt;li&gt;\(x \in \mathbb{R}^n\) is the decision variable vector&lt;/li&gt;
  &lt;li&gt;\(h \in \mathbb{R}^m\) is the right-hand side vector&lt;/li&gt;
  &lt;li&gt;\(m\) is the number of inequality constraints&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Expanded Form:&lt;/strong&gt;
The single matrix inequality \(Gx \preceq h\) is equivalent to the system:
\(\begin{align}
g_1^T x &amp;amp;\leq h_1 \\
g_2^T x &amp;amp;\leq h_2 \\
&amp;amp;\vdots \\
g_m^T x &amp;amp;\leq h_m
\end{align}\)&lt;/p&gt;

&lt;p&gt;where \(g_i^T\) is the \(i\)-th row of matrix \(G\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
Consider \(G = \begin{bmatrix} 1 &amp;amp; 2 \\ -1 &amp;amp; 3 \\ 0 &amp;amp; -1 \end{bmatrix}\), \(x = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}\), and \(h = \begin{bmatrix} 5 \\ 2 \\ -1 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;Then \(Gx \preceq h\) means:
\(\begin{align}
x_1 + 2x_2 &amp;amp;\leq 5 \\
-x_1 + 3x_2 &amp;amp;\leq 2 \\
-x_2 &amp;amp;\leq -1 \quad \text{(i.e., } x_2 \geq 1\text{)}
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Geometric Interpretation:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Each inequality \(g_i^T x \leq h_i\) defines a &lt;strong&gt;half-space&lt;/strong&gt; in \(\mathbb{R}^n\)&lt;/li&gt;
  &lt;li&gt;The feasible region is the &lt;strong&gt;intersection&lt;/strong&gt; of all these half-spaces&lt;/li&gt;
  &lt;li&gt;This intersection forms a &lt;strong&gt;polyhedron&lt;/strong&gt; (or polytope if bounded)&lt;/li&gt;
  &lt;li&gt;The constraint \(Gx \preceq h\) defines the &lt;strong&gt;polyhedral feasible set&lt;/strong&gt; for the QP&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter05/05_02_geometric_interpretation_of_QP.png&quot; alt=&quot;[Fig 1] Geometric interpretation of QP [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Geometric interpretation of QP [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;qp-in-standard-form&quot;&gt;QP in Standard Form&lt;/h2&gt;

&lt;p&gt;The standard form of a quadratic program is:&lt;/p&gt;

&lt;h3 id=&quot;standard-form-qp&quot;&gt;Standard Form QP&lt;/h3&gt;
&lt;p&gt;\(\begin{align}
    \text{minimize}_{x} \quad &amp;amp;\frac{1}{2}x^T P x + q^T x + r \\
    \text{subject to} \quad &amp;amp;A x = b \\
    &amp;amp;x \succeq 0
\end{align}\)&lt;/p&gt;

&lt;p&gt;Any general quadratic program can be converted to standard form using the following steps:&lt;/p&gt;

&lt;h3 id=&quot;converting-qps-to-standard-form&quot;&gt;Converting QPs to Standard Form&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; Use slack variables \(s\) to convert inequality constraints into equality constraints:
\(\begin{align}
    \text{minimize}_{x, s} \quad &amp;amp;\frac{1}{2}x^T P x + q^T x + r \\
    \text{subject to} \quad &amp;amp;Gx + s = h \\
    &amp;amp;Ax = b \\
    &amp;amp;s \succeq 0
\end{align}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; Replace \(x\) with two nonnegative variables:
\(x = x^{+} - x^{-}, \quad \text{where } x^{+}, x^{-} \succeq 0\)&lt;/p&gt;

\[\begin{align}
    \text{minimize}_{x^{+}, x^{-}, s} \quad &amp;amp;\frac{1}{2}(x^{+} - x^{-})^T P (x^{+} - x^{-}) + q^T x^{+} - q^T x^{-} + r\\
    \text{subject to} \quad &amp;amp;Gx^{+} - Gx^{-} + s = h \\
    &amp;amp;Ax^{+} - Ax^{-} = b \\
    &amp;amp;s \succeq 0 \\
    &amp;amp;x^{+} \succeq 0, \quad x^{-} \succeq 0
\end{align}\]

&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; Define \(\tilde{x}\), \(\tilde{q}\), \(\tilde{b}\), \(\tilde{A}\), \(\tilde{P}\):&lt;/p&gt;

\[\tilde{x} =
\begin{bmatrix}
x^{+} \\
x^{-} \\
s
\end{bmatrix}, \quad
\tilde{q} =
\begin{bmatrix}
q \\
-q \\
0
\end{bmatrix}, \quad
\tilde{b} =
\begin{bmatrix}
h \\
b
\end{bmatrix}\]

\[\tilde{A} =
\begin{bmatrix}
G &amp;amp; -G &amp;amp; I \\
A &amp;amp; -A &amp;amp; O
\end{bmatrix}, \quad
\tilde{P} =
\begin{bmatrix}
 P &amp;amp; -P &amp;amp; O \\
-P &amp;amp;  P &amp;amp; O \\
 O &amp;amp;  O &amp;amp; O
\end{bmatrix}\]

&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt; Substitute the expressions from Step 3 into the formulation:&lt;/p&gt;

\[\begin{align}
    \text{minimize}_{\tilde{x}} \quad &amp;amp;\frac{1}{2}\tilde{x}^T \tilde{P} \tilde{x} + \tilde{q}^T \tilde{x} + r \\
    \text{subject to} \quad &amp;amp;\tilde{A} \tilde{x} = \tilde{b} \\
    &amp;amp;\tilde{x} \succeq 0
\end{align}\]

&lt;h2 id=&quot;linear-programming-as-a-special-case-of-qp&quot;&gt;Linear Programming as a Special Case of QP&lt;/h2&gt;

&lt;p&gt;If the quadratic term is removed from the objective function of a quadratic program, it takes the form of a linear program. Thus, LP is a special case of QP, denoted as LP \(\subseteq\) QP.&lt;/p&gt;

&lt;h3 id=&quot;recall-general-lp&quot;&gt;Recall: General LP&lt;/h3&gt;
&lt;p&gt;\(\begin{align}
    \text{minimize}_{x} \quad &amp;amp;c^T x + d \\
    \text{subject to} \quad &amp;amp;Gx \preceq h \\
    &amp;amp;Ax = b
\end{align}\)
where \(G \in \mathbb{R}^{m \times n}\) and \(A \in \mathbb{R}^{p \times n}\).&lt;/p&gt;

&lt;h3 id=&quot;example-1-portfolio-optimization&quot;&gt;Example 1: Portfolio Optimization&lt;/h3&gt;

&lt;p&gt;This problem involves appropriately trading off performance and risk in creating a financial portfolio.&lt;/p&gt;

\[\begin{align}
    \text{maximize}_{x} \quad &amp;amp;\mu^T x - \frac{\gamma}{2}x^T P x \\
    \text{subject to} \quad &amp;amp;\mathbf{1}^Tx = 1 \\
    &amp;amp;x \succeq 0
\end{align}\]

&lt;p&gt;&lt;strong&gt;where:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mu\): expected assets’ returns&lt;/li&gt;
  &lt;li&gt;\(P\): covariance matrix of assets’ returns&lt;/li&gt;
  &lt;li&gt;\(\gamma\): risk aversion parameter (hyperparameter)&lt;/li&gt;
  &lt;li&gt;\(x\): portfolio holdings (percentages)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-2-support-vector-machines&quot;&gt;Example 2: Support Vector Machines&lt;/h3&gt;

&lt;p&gt;Support Vector Machines (SVM) are an example of a quadratic program. Below is C-SVM, a variant of SVM. A detailed explanation of SVM is beyond the scope of this chapter and will therefore be omitted.&lt;/p&gt;

\[\begin{align}
    \text{minimize}_{\beta, \beta_0, \xi} \quad &amp;amp;\frac{1}{2} \| \beta \|_2^2 + C \sum_{i=1}^{n} \xi_i \\
    \text{subject to} \quad &amp;amp;\xi_i \geq 0, \quad i = 1, \ldots, n \\
    &amp;amp;y_i (x_i^T \beta + \beta_0) \geq 1 - \xi_i, \quad i = 1, \ldots, n
\end{align}\]

&lt;p&gt;&lt;strong&gt;given:&lt;/strong&gt; \(y \in \{-1, 1\}^n\) and \(X \in \mathbb{R}^{n \times p}\) having rows \(x_1, \ldots, x_n\).&lt;/p&gt;

&lt;h3 id=&quot;example-3-least-squares-in-regression&quot;&gt;Example 3: Least-Squares in Regression&lt;/h3&gt;

&lt;p&gt;The problem of minimizing the following convex quadratic function corresponds to an (unconstrained) QP:
\(\| Ax - b \|_2^2 = x^T A^TA x - 2b^TAx + b^Tb\)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>05-02-03 Linear Regression from Statistical Perspective</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_02_03_Linear_Regression_Statistical_View/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_02_03_Linear_Regression_Statistical_View</id>
   <content type="html">&lt;h2 id=&quot;linear-regression-from-statistical-perspective&quot;&gt;Linear Regression from Statistical Perspective&lt;/h2&gt;

&lt;p&gt;In this lesson, we explore linear regression from a probabilistic and statistical viewpoint, demonstrating why minimizing the sum of squared errors (MSE) is not only intuitive but also theoretically justified through maximum likelihood estimation.&lt;/p&gt;

&lt;h3 id=&quot;1-probabilistic-interpretation-of-linear-regression&quot;&gt;1. Probabilistic Interpretation of Linear Regression&lt;/h3&gt;

&lt;p&gt;From a probabilistic perspective, we can prove that the estimates obtained from linear regression based on minimizing the sum of squared errors from the MSE function are completely natural and reasonable.&lt;/p&gt;

&lt;p&gt;Indeed, we assume that the target variable and input variables are related through the equation:&lt;/p&gt;

\[y_i = \mathbf{w}^\top \mathbf{x}_i + \epsilon_i\]

&lt;p&gt;where $\epsilon_i$ represents the random error that any equation has. These are factors that cannot be explained by the model. Since our estimate is unbiased, this random error is assumed to satisfy the properties according to the Gauss-Markov hypothesis:&lt;/p&gt;

&lt;h4 id=&quot;assumption-1-zero-mean-error&quot;&gt;Assumption 1: Zero Mean Error&lt;/h4&gt;
&lt;p&gt;The errors $\epsilon_i$ are random variables with zero expectation:&lt;/p&gt;

\[\mathbb{E}(\epsilon_i) = 0\]

&lt;h4 id=&quot;assumption-2-uncorrelated-errors&quot;&gt;Assumption 2: Uncorrelated Errors&lt;/h4&gt;
&lt;p&gt;The random errors have no correlation:&lt;/p&gt;

\[\mathbb{E}(\epsilon_i \epsilon_j) = 0, \quad \forall i \neq j\]

&lt;h4 id=&quot;assumption-3-constant-variance-homoscedasticity&quot;&gt;Assumption 3: Constant Variance (Homoscedasticity)&lt;/h4&gt;
&lt;p&gt;The variance of the random error is invariant:&lt;/p&gt;

\[\text{Var}(\epsilon_i) = \sigma^2\]

&lt;h4 id=&quot;assumption-4-independence-of-errors-and-features&quot;&gt;Assumption 4: Independence of Errors and Features&lt;/h4&gt;
&lt;p&gt;The random error $\epsilon_i$ and the input variables $\mathbf{x}_i$ have no correlation:&lt;/p&gt;

\[\text{Cov}(\mathbf{x}_i, \epsilon_i) = 0, \quad \forall i = 1, \dots, p\]

&lt;h3 id=&quot;2-gaussian-distribution-of-errors&quot;&gt;2. Gaussian Distribution of Errors&lt;/h3&gt;

&lt;p&gt;Under these assumptions, the random errors $\epsilon_i$ form a Gaussian (normal) distribution with mean 0 and variance $\sigma^2$, denoted as $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$. The probability density function at each point $\epsilon_i$ is:&lt;/p&gt;

\[p(\epsilon_i) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{\epsilon_i^2}{2\sigma^2} \right)\]

&lt;p&gt;Substituting $\epsilon_i = y_i - \mathbf{w}^\top \mathbf{x}_i$ into the probability density function, we get:&lt;/p&gt;

\[p(y_i \mid \mathbf{x}_i; \mathbf{w}) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{(y_i - \mathbf{w}^\top \mathbf{x}_i)^2}{2\sigma^2} \right)\]

&lt;p&gt;The notation $p(y_i \mid \mathbf{x}_i; \mathbf{w})$ indicates the probability of $y_i$ corresponding to $\mathbf{x}_i$, parameterized by $\mathbf{w}$. Here, $\mathbf{w}$ is known and is not considered as a condition of $y_i$, hence we use ; instead of ,.&lt;/p&gt;

&lt;h3 id=&quot;3-maximum-likelihood-estimation&quot;&gt;3. Maximum Likelihood Estimation&lt;/h3&gt;

&lt;p&gt;From a probabilistic perspective, $p(y_i \mid \mathbf{x}_i; \mathbf{w})$ is a function dependent on the input data $\mathbf{x}_i$ when the weight $\mathbf{w}$ is known. When viewing probability from the perspective of a function with respect to $\mathbf{w}$, we call it the likelihood function:&lt;/p&gt;

\[L(\mathbf{w}) = L(\mathbf{w}; \mathbf{X}, \mathbf{y}) = p(\mathbf{y} \mid \mathbf{X}; \mathbf{w})\]

&lt;p&gt;According to condition 2 of the Gauss-Markov hypothesis, the errors are independent, so the joint probability of the data equals the product of the probability densities of each data point:&lt;/p&gt;

\[\begin{align}
L(\mathbf{w}) &amp;amp;= \prod_{i=1}^{n} p(y_i \mid \mathbf{x}_i; \mathbf{w}) \\
&amp;amp;= \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{\epsilon_i^2}{2\sigma^2} \right)
\end{align}\]

&lt;p&gt;The likelihood function reflects the probabilistic relationship between $\mathbf{y}$ and $\mathbf{X}$. To find $\mathbf{w}$ such that this relationship is most appropriate, according to Maximum Likelihood Estimation, we choose $\mathbf{w}$ such that $L(\mathbf{w})$ is maximized.&lt;/p&gt;

&lt;h3 id=&quot;4-log-likelihood-optimization&quot;&gt;4. Log-Likelihood Optimization&lt;/h3&gt;

&lt;p&gt;Taking the logarithm of both sides to simplify the optimization problem:&lt;/p&gt;

\[\begin{align}
\hat{\mathbf{w}} &amp;amp;= \arg \max \log L(\mathbf{w}) \\
&amp;amp;= \arg \max \log \left[ \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{\epsilon_i^2}{2\sigma^2} \right) \right] \\
&amp;amp;= \arg \max \sum_{i=1}^{n} \log \left[ \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left( -\frac{\epsilon_i^2}{2\sigma^2} \right) \right] \\
&amp;amp;= \arg \max \sum_{i=1}^{n} \left[ -\frac{\epsilon_i^2}{2\sigma^2} - \log \sqrt{2\pi \sigma^2} \right] \\
&amp;amp;= \arg \max \left[ -\frac{1}{2\sigma^2} \sum_{i=1}^{n} \epsilon_i^2 - n \log \sqrt{2\pi \sigma^2} \right]
\end{align}\]

&lt;p&gt;Since $\sigma^2$ and $2\pi$ are constants, optimizing the above function is equivalent to minimizing:&lt;/p&gt;

\[\sum_{i=1}^{n} \epsilon_i^2 = \sum_{i=1}^{n} (y_i - \mathbf{w}^\top \mathbf{x}_i)^2\]

&lt;p&gt;This is equivalent to minimizing the MSE function:&lt;/p&gt;

\[\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2\]

&lt;h3 id=&quot;5-theoretical-justification&quot;&gt;5. Theoretical Justification&lt;/h3&gt;

&lt;p&gt;Thus, from a probabilistic perspective, we have proven that linear regression based on minimizing the sum of squared errors is equivalent to optimizing the likelihood function. When the conditions of the Gauss-Markov hypothesis are satisfied, our estimate is the best linear unbiased estimator (BLUE). Assumptions about confidence intervals for predicted values and evaluation of the significance of weights through P-values can be made based on the normal distribution.&lt;/p&gt;

&lt;div id=&quot;mle-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Maximum Likelihood Estimation Visualization&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;!-- Canvas for visualization --&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;mleCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Visualization:&lt;/strong&gt; Blue dots are data points, red line is the fitted line, and the curves show the Gaussian distributions of errors.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;!-- Controls --&gt;
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Parameters&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;noise-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Noise Level (σ): &lt;span id=&quot;noise-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;noise-slider&quot; min=&quot;0.1&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0.5&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;slope-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;True Slope: &lt;span id=&quot;true-slope-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;slope-slider&quot; min=&quot;-2&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;intercept-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;True Intercept: &lt;span id=&quot;true-intercept-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;intercept-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-data&quot; style=&quot;width: 100%; padding: 10px; background: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 10px;&quot;&gt;Generate New Data&lt;/button&gt;
                
                &lt;div id=&quot;mle-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;MLE Estimates:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Slope: &lt;span id=&quot;mle-slope&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Intercept: &lt;span id=&quot;mle-intercept&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Log-Likelihood: &lt;span id=&quot;log-likelihood&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;6-training-linear-regression-models-with-sklearn&quot;&gt;6. Training Linear Regression Models with sklearn&lt;/h3&gt;

&lt;p&gt;Sklearn is a comprehensive Python library for data science, supporting training of most machine learning models, building pipelines, data normalization, and performing cross-validation.&lt;/p&gt;

&lt;p&gt;In this section, we will learn how to train linear regression models on sklearn. Returning to the previous problem, if we add information about distance to city center:&lt;/p&gt;

\[\mathbf{x}_2 = [20, 18, 17, 16, 15, 14, 12, 10, 8, 7, 5, 2, 1]\]

&lt;p&gt;then the problem becomes multivariate regression. The process of building and training the model includes the steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Data collection&lt;/li&gt;
  &lt;li&gt;Data cleaning&lt;/li&gt;
  &lt;li&gt;Feature selection&lt;/li&gt;
  &lt;li&gt;Data normalization&lt;/li&gt;
  &lt;li&gt;Train/test split&lt;/li&gt;
  &lt;li&gt;Model training and evaluation&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In this problem, we focus on step 6 to understand how to train the model.&lt;/p&gt;

&lt;div id=&quot;sklearn-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Sklearn Linear Regression Example&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;!-- Code example --&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;pre style=&quot;background: #f8f9fa; padding: 15px; border-radius: 5px; overflow-x: auto; font-size: 12px;&quot;&gt;&lt;code id=&quot;sklearn-code&quot;&gt;import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Sample data: house prices
# Features: [area, distance_to_center]
X = np.array([
    [50, 20], [60, 18], [70, 17], [80, 16], [90, 15],
    [100, 14], [110, 12], [120, 10], [130, 8], [140, 7],
    [150, 5], [160, 2], [170, 1]
])

# Target: prices (in thousands)
y = np.array([150, 180, 210, 240, 270, 300, 330, 360, 390, 420, 450, 480, 510])

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# Create and train model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f&quot;Coefficients: {model.coef_}&quot;)
print(f&quot;Intercept: {model.intercept_}&quot;)
print(f&quot;MSE: {mse:.2f}&quot;)
print(f&quot;R²: {r2:.3f}&quot;)
&lt;/code&gt;&lt;/pre&gt;
        &lt;/div&gt;
        
        &lt;!-- Interactive results --&gt;
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Model Results&lt;/h5&gt;
                
                &lt;button id=&quot;run-sklearn&quot; style=&quot;width: 100%; padding: 10px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Run Sklearn Example&lt;/button&gt;
                
                &lt;div id=&quot;sklearn-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Model Parameters:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Area coeff: &lt;span id=&quot;area-coeff&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Distance coeff: &lt;span id=&quot;distance-coeff&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Intercept: &lt;span id=&quot;sklearn-intercept&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;Performance:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;MSE: &lt;span id=&quot;sklearn-mse&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;R²: &lt;span id=&quot;sklearn-r2&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-top: 15px;&quot;&gt;
                    &lt;h6 style=&quot;margin-bottom: 10px; color: #444;&quot;&gt;Prediction Calculator&lt;/h6&gt;
                    &lt;div style=&quot;margin-bottom: 10px;&quot;&gt;
                        &lt;label style=&quot;display: block; margin-bottom: 5px;&quot;&gt;Area (m²):&lt;/label&gt;
                        &lt;input type=&quot;number&quot; id=&quot;pred-area&quot; value=&quot;100&quot; min=&quot;50&quot; max=&quot;200&quot; style=&quot;width: 100%; padding: 5px; border: 1px solid #ddd; border-radius: 3px;&quot; /&gt;
                    &lt;/div&gt;
                    &lt;div style=&quot;margin-bottom: 10px;&quot;&gt;
                        &lt;label style=&quot;display: block; margin-bottom: 5px;&quot;&gt;Distance to center (km):&lt;/label&gt;
                        &lt;input type=&quot;number&quot; id=&quot;pred-distance&quot; value=&quot;10&quot; min=&quot;1&quot; max=&quot;20&quot; style=&quot;width: 100%; padding: 5px; border: 1px solid #ddd; border-radius: 3px;&quot; /&gt;
                    &lt;/div&gt;
                    &lt;button id=&quot;make-prediction&quot; style=&quot;width: 100%; padding: 8px; background: #17a2b8; color: white; border: none; border-radius: 3px; cursor: pointer;&quot;&gt;Predict Price&lt;/button&gt;
                    &lt;div id=&quot;prediction-result&quot; style=&quot;margin-top: 10px; padding: 10px; background: #e9ecef; border-radius: 3px; text-align: center; font-weight: bold;&quot;&gt;
                        Predicted Price: --
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;key-insights&quot;&gt;Key Insights&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Theoretical Foundation&lt;/strong&gt;: Maximum likelihood estimation provides a solid theoretical foundation for why we minimize squared errors in linear regression.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gaussian Assumptions&lt;/strong&gt;: The effectiveness of linear regression relies on the Gauss-Markov assumptions, particularly that errors are normally distributed.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Best Linear Unbiased Estimator&lt;/strong&gt;: Under the right conditions, OLS provides the BLUE - the most efficient unbiased linear estimator.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Practical Implementation&lt;/strong&gt;: Modern tools like sklearn make it easy to implement these theoretical concepts in practice.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Model Evaluation&lt;/strong&gt;: Understanding the statistical foundation helps in proper model evaluation using metrics like R², confidence intervals, and p-values.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;script&gt;
// MLE Visualization
class MLEVisualization {
    constructor() {
        this.canvas = document.getElementById(&apos;mleCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        // Parameters
        this.trueSlope = 1.0;
        this.trueIntercept = 0.0;
        this.noiseLevel = 0.5;
        this.dataPoints = [];
        
        this.setupControls();
        this.generateData();
        this.draw();
    }
    
    setupControls() {
        const noiseSlider = document.getElementById(&apos;noise-slider&apos;);
        const slopeSlider = document.getElementById(&apos;slope-slider&apos;);
        const interceptSlider = document.getElementById(&apos;intercept-slider&apos;);
        const generateBtn = document.getElementById(&apos;generate-data&apos;);
        
        noiseSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.noiseLevel = parseFloat(e.target.value);
            document.getElementById(&apos;noise-value&apos;).textContent = this.noiseLevel.toFixed(1);
            this.generateData();
            this.draw();
        });
        
        slopeSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.trueSlope = parseFloat(e.target.value);
            document.getElementById(&apos;true-slope-value&apos;).textContent = this.trueSlope.toFixed(1);
            this.generateData();
            this.draw();
        });
        
        interceptSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.trueIntercept = parseFloat(e.target.value);
            document.getElementById(&apos;true-intercept-value&apos;).textContent = this.trueIntercept.toFixed(1);
            this.generateData();
            this.draw();
        });
        
        generateBtn.addEventListener(&apos;click&apos;, () =&gt; {
            this.generateData();
            this.draw();
        });
    }
    
    generateData() {
        this.dataPoints = [];
        const n = 20;
        
        for (let i = 0; i &lt; n; i++) {
            const x = (i / (n - 1)) * 4 - 2; // x from -2 to 2
            const trueY = this.trueSlope * x + this.trueIntercept;
            const noise = (Math.random() - 0.5) * 2 * this.noiseLevel;
            const y = trueY + noise;
            
            this.dataPoints.push({ x, y, trueY });
        }
    }
    
    calculateMLE() {
        const n = this.dataPoints.length;
        let sumX = 0, sumY = 0, sumXY = 0, sumX2 = 0;
        
        for (const point of this.dataPoints) {
            sumX += point.x;
            sumY += point.y;
            sumXY += point.x * point.y;
            sumX2 += point.x * point.x;
        }
        
        const slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
        const intercept = (sumY - slope * sumX) / n;
        
        // Calculate log-likelihood
        let logLikelihood = 0;
        for (const point of this.dataPoints) {
            const predicted = slope * point.x + intercept;
            const error = point.y - predicted;
            logLikelihood -= 0.5 * Math.log(2 * Math.PI * this.noiseLevel * this.noiseLevel);
            logLikelihood -= (error * error) / (2 * this.noiseLevel * this.noiseLevel);
        }
        
        return { slope, intercept, logLikelihood };
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const mle = this.calculateMLE();
        
        // Update display
        document.getElementById(&apos;mle-slope&apos;).textContent = mle.slope.toFixed(3);
        document.getElementById(&apos;mle-intercept&apos;).textContent = mle.intercept.toFixed(3);
        document.getElementById(&apos;log-likelihood&apos;).textContent = mle.logLikelihood.toFixed(2);
        
        // Transform coordinates
        const transform = (x, y) =&gt; ({
            x: (x + 2.5) * this.width / 5,
            y: this.height - (y + 2.5) * this.height / 5
        });
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(0, this.height / 2);
        this.ctx.lineTo(this.width, this.height / 2);
        this.ctx.moveTo(this.width / 2, 0);
        this.ctx.lineTo(this.width / 2, this.height);
        this.ctx.stroke();
        
        // Draw fitted line
        this.ctx.strokeStyle = &apos;#ff4444&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        const start = transform(-2, mle.slope * (-2) + mle.intercept);
        const end = transform(2, mle.slope * 2 + mle.intercept);
        this.ctx.moveTo(start.x, start.y);
        this.ctx.lineTo(end.x, end.y);
        this.ctx.stroke();
        
        // Draw data points and error distributions
        for (const point of this.dataPoints) {
            const pos = transform(point.x, point.y);
            
            // Draw Gaussian error distribution
            const predicted = mle.slope * point.x + mle.intercept;
            const errorCenter = transform(point.x, predicted);
            
            this.ctx.strokeStyle = &apos;#cccccc&apos;;
            this.ctx.lineWidth = 1;
            this.ctx.beginPath();
            for (let i = 0; i &lt;= 20; i++) {
                const t = i / 20;
                const gaussY = predicted + (t - 0.5) * 4 * this.noiseLevel;
                const gaussVal = Math.exp(-0.5 * Math.pow((gaussY - predicted) / this.noiseLevel, 2));
                const gaussPos = transform(point.x + gaussVal * 0.3, gaussY);
                
                if (i === 0) {
                    this.ctx.moveTo(gaussPos.x, gaussPos.y);
                } else {
                    this.ctx.lineTo(gaussPos.x, gaussPos.y);
                }
            }
            this.ctx.stroke();
            
            // Draw data point
            this.ctx.fillStyle = &apos;#4444ff&apos;;
            this.ctx.beginPath();
            this.ctx.arc(pos.x, pos.y, 4, 0, 2 * Math.PI);
            this.ctx.fill();
            
            // Draw error line
            this.ctx.strokeStyle = &apos;#888&apos;;
            this.ctx.lineWidth = 1;
            this.ctx.beginPath();
            this.ctx.moveTo(pos.x, pos.y);
            this.ctx.lineTo(errorCenter.x, errorCenter.y);
            this.ctx.stroke();
        }
    }
}

// Sklearn Demo
class SklearnDemo {
    constructor() {
        this.setupControls();
        this.model = null;
        this.data = this.generateSampleData();
    }
    
    generateSampleData() {
        return {
            X: [
                [50, 20], [60, 18], [70, 17], [80, 16], [90, 15],
                [100, 14], [110, 12], [120, 10], [130, 8], [140, 7],
                [150, 5], [160, 2], [170, 1]
            ],
            y: [150, 180, 210, 240, 270, 300, 330, 360, 390, 420, 450, 480, 510]
        };
    }
    
    setupControls() {
        const runBtn = document.getElementById(&apos;run-sklearn&apos;);
        const predBtn = document.getElementById(&apos;make-prediction&apos;);
        
        runBtn.addEventListener(&apos;click&apos;, () =&gt; this.runSklearnExample());
        predBtn.addEventListener(&apos;click&apos;, () =&gt; this.makePrediction());
    }
    
    runSklearnExample() {
        // Simulate sklearn linear regression
        const { X, y } = this.data;
        
        // Calculate means
        const meanX1 = X.reduce((sum, row) =&gt; sum + row[0], 0) / X.length;
        const meanX2 = X.reduce((sum, row) =&gt; sum + row[1], 0) / X.length;
        const meanY = y.reduce((sum, val) =&gt; sum + val, 0) / y.length;
        
        // Calculate coefficients using normal equation
        let sumX1X1 = 0, sumX2X2 = 0, sumX1X2 = 0;
        let sumX1Y = 0, sumX2Y = 0;
        
        for (let i = 0; i &lt; X.length; i++) {
            const x1 = X[i][0] - meanX1;
            const x2 = X[i][1] - meanX2;
            const yVal = y[i] - meanY;
            
            sumX1X1 += x1 * x1;
            sumX2X2 += x2 * x2;
            sumX1X2 += x1 * x2;
            sumX1Y += x1 * yVal;
            sumX2Y += x2 * yVal;
        }
        
        // Solve 2x2 system
        const det = sumX1X1 * sumX2X2 - sumX1X2 * sumX1X2;
        const coeff1 = (sumX2X2 * sumX1Y - sumX1X2 * sumX2Y) / det;
        const coeff2 = (sumX1X1 * sumX2Y - sumX1X2 * sumX1Y) / det;
        const intercept = meanY - coeff1 * meanX1 - coeff2 * meanX2;
        
        // Calculate MSE and R²
        let mse = 0, tss = 0;
        for (let i = 0; i &lt; X.length; i++) {
            const predicted = coeff1 * X[i][0] + coeff2 * X[i][1] + intercept;
            const error = y[i] - predicted;
            mse += error * error;
            tss += (y[i] - meanY) * (y[i] - meanY);
        }
        mse /= X.length;
        const r2 = 1 - (mse * X.length) / tss;
        
        this.model = { coeff1, coeff2, intercept };
        
        // Update display
        document.getElementById(&apos;area-coeff&apos;).textContent = coeff1.toFixed(3);
        document.getElementById(&apos;distance-coeff&apos;).textContent = coeff2.toFixed(3);
        document.getElementById(&apos;sklearn-intercept&apos;).textContent = intercept.toFixed(3);
        document.getElementById(&apos;sklearn-mse&apos;).textContent = mse.toFixed(2);
        document.getElementById(&apos;sklearn-r2&apos;).textContent = r2.toFixed(3);
    }
    
    makePrediction() {
        if (!this.model) {
            alert(&apos;Please run the sklearn example first!&apos;);
            return;
        }
        
        const area = parseFloat(document.getElementById(&apos;pred-area&apos;).value);
        const distance = parseFloat(document.getElementById(&apos;pred-distance&apos;).value);
        
        const prediction = this.model.coeff1 * area + this.model.coeff2 * distance + this.model.intercept;
        
        document.getElementById(&apos;prediction-result&apos;).innerHTML = 
            `Predicted Price: &lt;strong&gt;$${prediction.toFixed(0)}k&lt;/strong&gt;`;
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new MLEVisualization();
    new SklearnDemo();
});
&lt;/script&gt;

&lt;style&gt;
#mle-demo canvas {
    border-radius: 5px;
}

#sklearn-demo pre {
    max-height: 400px;
    overflow-y: auto;
}

.demo-container {
    margin: 20px 0;
}

input[type=&quot;range&quot;] {
    -webkit-appearance: none;
    appearance: none;
    height: 5px;
    background: #ddd;
    outline: none;
    border-radius: 5px;
}

input[type=&quot;range&quot;]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
}

input[type=&quot;range&quot;]::-moz-range-thumb {
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
    border: none;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>05-02-02 Geometric Programming</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_02_02_Geometric_Programming/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_02_02_Geometric_Programming</id>
   <content type="html">&lt;p&gt;In this section, we will see a class of problems that appear non-convex when looking at the objective function and constraint functions, but can be transformed into convex form through several techniques.&lt;/p&gt;

&lt;p&gt;First, we need some definitions:&lt;/p&gt;

&lt;h2 id=&quot;521-monomials-and-posynomials&quot;&gt;5.2.1. Monomials and Posynomials&lt;/h2&gt;

&lt;p&gt;A function \(f: \mathbb{R}^n \to \mathbb{R}\) with domain \(\text{dom } f = \mathbb{R}^n_{++}\) (all elements are positive) has the form:&lt;/p&gt;

\[f(x) = c x_1^{a_1} x_2^{a_2} \ldots x_n^{a_n} \quad \quad (24)\]

&lt;p&gt;where \(c &amp;gt; 0\) and \(a_i \in \mathbb{R}\), is called a &lt;strong&gt;monomial function&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;A sum of monomials:&lt;/p&gt;

\[f(x) = \sum_{k=1}^K c_k x_1^{a_{1k}} x_2^{a_{2k}} \ldots x_n^{a_{nk}} \quad \quad (25)\]

&lt;p&gt;where \(c_k &amp;gt; 0\), is called a &lt;strong&gt;posynomial function&lt;/strong&gt;, or simply a &lt;strong&gt;posynomial&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;522-geometric-programming&quot;&gt;5.2.2. Geometric Programming&lt;/h2&gt;

&lt;p&gt;An optimization problem of the form:&lt;/p&gt;

\[\begin{align}
x &amp;amp;= \arg\min_x f_0(x) \\
\text{subject to: } &amp;amp;f_i(x) \leq 1, \quad i = 1, 2, \ldots, m \quad \quad (26) \\
&amp;amp;h_j(x) = 1, \quad j = 1, 2, \ldots, p
\end{align}\]

&lt;p&gt;where \(f_0, f_1, \ldots, f_m\) are posynomials and \(h_1, \ldots, h_p\) are monomials, is called &lt;strong&gt;Geometric Programming (GP)&lt;/strong&gt;. The condition \(x \succ 0\) is implicit.&lt;/p&gt;

&lt;p&gt;Note that if \(f\) is a posynomial and \(h\) is a monomial, then \(f/h\) is a posynomial.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;

\[\begin{align}
(x, y, z) &amp;amp;= \arg\min_{x,y,z} x/y \\
\text{subject to: } &amp;amp;1 \leq x \leq 2 \\
&amp;amp;x^3 + 2y/z \leq \sqrt{y} \\
&amp;amp;x/y = z
\end{align}\]

&lt;p&gt;This can be rewritten in GP form:&lt;/p&gt;

\[\begin{align}
(x, y, z) &amp;amp;= \arg\min_{x,y,z} xy^{-1} \\
\text{subject to: } &amp;amp;x^{-1} \leq 1 \\
&amp;amp;(1/2)x \leq 1 \\
&amp;amp;x^3 y^{-1/2} + 2y^{1/2}z^{-1} \leq 1 \\
&amp;amp;xy^{-1}z^{-1} = 1
\end{align}\]

&lt;p&gt;This problem is clearly nonconvex since both the objective function and constraint functions are not convex.&lt;/p&gt;

&lt;h2 id=&quot;523-transforming-gp-to-convex-form&quot;&gt;5.2.3. Transforming GP to Convex Form&lt;/h2&gt;

&lt;p&gt;GP can be transformed to convex form as follows:&lt;/p&gt;

&lt;p&gt;Let \(y_i = \log(x_i)\), i.e., \(x_i = \exp(y_i)\). If \(f\) is a monomial function of \(x\), then:&lt;/p&gt;

\[f(x) = c(\exp(y_1))^{a_1} \ldots (\exp(y_n))^{a_n} = \exp(a^T y + b)\]

&lt;p&gt;where \(b = \log(c)\). Now, the function \(g(y) = \exp(a^T y + b)\) is a convex function in \(y\). (The reader can prove by definition that the composition of two convex functions is a convex function. In this case, both the \(\exp\) function and the affine function are convex functions.)&lt;/p&gt;

&lt;p&gt;Similarly, the posynomial in equation (25) can be written as:&lt;/p&gt;

\[f(x) = \sum_{k=1}^K \exp(a_k^T y + b_k)\]

&lt;p&gt;where \(a_k = [a_{1k}, \ldots, a_{nk}]^T\) and \(b_k = \log(c_k)\). Now, the posynomial has been written as a sum of \(\exp\) functions of affine functions (and is therefore a convex function, recall that the sum of convex functions is convex).&lt;/p&gt;

&lt;p&gt;The GP problem (26) is rewritten as:&lt;/p&gt;

\[\begin{align}
y &amp;amp;= \arg\min_y \sum_{k=1}^{K_0} \exp(a_{0k}^T y + b_{0k}) \\
\text{subject to: } &amp;amp;\sum_{k=1}^{K_i} \exp(a_{ik}^T y + b_{ik}) \leq 1, \quad i = 1, \ldots, m \quad \quad (27) \\
&amp;amp;\exp(g_j^T y + h_j) = 1, \quad j = 1, \ldots, p
\end{align}\]

&lt;p&gt;where \(a_{ik} \in \mathbb{R}^n\), \(i = 1, \ldots, p\) and \(g_i \in \mathbb{R}^n\).&lt;/p&gt;

&lt;p&gt;With the observation that the function \(\log \sum_{i=1}^m \exp(g_i(x))\) is a convex function if \(g_i\) are convex functions (we omit the proof), we can rewrite problem (27) in convex form by taking the \(\log\) of the functions as follows:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GP in convex form:&lt;/strong&gt;&lt;/p&gt;

\[\begin{align}
\text{minimize}_y \quad &amp;amp;\tilde{f}_0(y) = \log\left(\sum_{k=1}^{K_0} \exp(a_{0k}^T y + b_{0k})\right) \\
\text{subject to: } &amp;amp;\tilde{f}_i(y) = \log\left(\sum_{k=1}^{K_i} \exp(a_{ik}^T y + b_{ik})\right) \leq 0, \quad i = 1, \ldots, m \quad \quad (28) \\
&amp;amp;\tilde{h}_j(y) = g_j^T y + h_j = 0, \quad j = 1, \ldots, p
\end{align}\]

&lt;p&gt;Now we can say that GP is equivalent to a convex optimization problem because the objective function and inequality constraint functions in (28) are all convex functions, while the equality constraints are in affine form. This form is often called a &lt;strong&gt;geometric program in convex form&lt;/strong&gt; (to distinguish it from the original definition of GP).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>05-02-01 Linear Least-Squares Problems</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_02_01_Least_Square/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_02_01_Least_Square</id>
   <content type="html">&lt;h2 id=&quot;linear-least-squares-problems&quot;&gt;Linear Least-Squares Problems&lt;/h2&gt;

&lt;p&gt;A linear least-squares problem is an optimization problem without constraints where we minimize the sum of squared errors:&lt;/p&gt;

\[\text{minimize}_{x} \quad f_0(x) = \|Ax - b\|_2^2 = \sum_{i=1}^{k} (a_i^T x - b_i)^2\]

&lt;p&gt;&lt;strong&gt;where:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(A \in \mathbb{R}^{k \times n}\) is a matrix with \(k \geq n\)&lt;/li&gt;
  &lt;li&gt;\(a_i^T\) are the rows of \(A\)&lt;/li&gt;
  &lt;li&gt;\(x \in \mathbb{R}^n\) is the variable we want to find&lt;/li&gt;
  &lt;li&gt;\(b \in \mathbb{R}^k\) is the target vector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; Find \(x\) to minimize the sum of squared residuals.&lt;/p&gt;

&lt;h3 id=&quot;example-linear-regression-for-single-variable&quot;&gt;Example: Linear Regression for single variable&lt;/h3&gt;

&lt;p&gt;Finding the best-fit line \(y = mx + c\) through data points. We minimize the sum of squared vertical distances from points to the line.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; Find \(m, c\).&lt;/p&gt;

&lt;div id=&quot;linear-regression-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Interactive Linear Regression Demonstration&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;!-- Canvas for visualization --&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;regressionCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white; cursor: crosshair;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Instructions:&lt;/strong&gt; Click on the canvas to add data points. The red line shows the best-fit line.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;!-- Controls and information --&gt;
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Regression Parameters&lt;/h5&gt;
                &lt;div id=&quot;regression-params&quot; style=&quot;font-family: monospace; font-size: 14px; line-height: 1.6;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Slope (m):&lt;/strong&gt; &lt;span id=&quot;slope-value&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;Intercept (c):&lt;/strong&gt; &lt;span id=&quot;intercept-value&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;R² Score:&lt;/strong&gt; &lt;span id=&quot;r2-value&quot;&gt;N/A&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;MSE:&lt;/strong&gt; &lt;span id=&quot;mse-value&quot;&gt;N/A&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-top: 15px;&quot;&gt;
                    &lt;h5 style=&quot;color: #444;&quot;&gt;Equation&lt;/h5&gt;
                    &lt;div id=&quot;equation&quot; style=&quot;font-family: monospace; font-size: 16px; background: #f0f0f0; padding: 8px; border-radius: 4px;&quot;&gt;
                        y = 0.000x + 0.000
                    &lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-top: 15px;&quot;&gt;
                    &lt;button onclick=&quot;clearPoints()&quot; style=&quot;background: #ff6b6b; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; margin-right: 10px;&quot;&gt;Clear Points&lt;/button&gt;
                    &lt;button onclick=&quot;addRandomPoints()&quot; style=&quot;background: #4ecdc4; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;&quot;&gt;Add Random Points&lt;/button&gt;
                &lt;/div&gt;
            &lt;/div&gt;
            
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-top: 15px;&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Mathematical Formulation&lt;/h5&gt;
                &lt;div style=&quot;font-size: 13px; line-height: 1.5;&quot;&gt;
                    &lt;p&gt;&lt;strong&gt;Objective:&lt;/strong&gt; Minimize sum of squared residuals&lt;/p&gt;
                    &lt;div style=&quot;background: #f8f8f8; padding: 8px; border-radius: 4px; font-family: monospace;&quot;&gt;
                        S(m,c) = Σ(yᵢ - mxᵢ - c)²
                    &lt;/div&gt;
                    &lt;p style=&quot;margin-top: 10px;&quot;&gt;&lt;strong&gt;Solution:&lt;/strong&gt;&lt;/p&gt;
                    &lt;div style=&quot;background: #f8f8f8; padding: 8px; border-radius: 4px; font-family: monospace; font-size: 11px;&quot;&gt;
                        m = Σ(xᵢ-x̄)(yᵢ-ȳ) / Σ(xᵢ-x̄)²&lt;br /&gt;
                        c = ȳ - mx̄
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
// Linear Regression Interactive Demo
class LinearRegressionDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;regressionCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.points = [];
        this.slope = 0;
        this.intercept = 0;
        
        // Set up canvas
        this.canvas.addEventListener(&apos;click&apos;, (e) =&gt; this.addPoint(e));
        
        // Initialize with some sample points
        this.addRandomPoints();
        this.draw();
    }
    
    addPoint(event) {
        const rect = this.canvas.getBoundingClientRect();
        const x = event.clientX - rect.left;
        const y = event.clientY - rect.top;
        
        // Convert canvas coordinates to data coordinates
        const dataX = (x / this.canvas.width) * 10;
        const dataY = ((this.canvas.height - y) / this.canvas.height) * 10;
        
        this.points.push({x: dataX, y: dataY});
        this.calculateRegression();
        this.draw();
        this.updateDisplay();
    }
    
    addRandomPoints() {
        // Add some sample points with a trend
        const baseSlope = 0.8;
        const baseIntercept = 2;
        
        for (let i = 0; i &lt; 8; i++) {
            const x = Math.random() * 8 + 1;
            const y = baseSlope * x + baseIntercept + (Math.random() - 0.5) * 2;
            this.points.push({x: x, y: Math.max(0, Math.min(10, y))});
        }
        
        this.calculateRegression();
        this.draw();
        this.updateDisplay();
    }
    
    clearPoints() {
        this.points = [];
        this.slope = 0;
        this.intercept = 0;
        this.draw();
        this.updateDisplay();
    }
    
    calculateRegression() {
        if (this.points.length &lt; 2) {
            this.slope = 0;
            this.intercept = 0;
            return;
        }
        
        const n = this.points.length;
        const sumX = this.points.reduce((sum, p) =&gt; sum + p.x, 0);
        const sumY = this.points.reduce((sum, p) =&gt; sum + p.y, 0);
        const sumXY = this.points.reduce((sum, p) =&gt; sum + p.x * p.y, 0);
        const sumXX = this.points.reduce((sum, p) =&gt; sum + p.x * p.x, 0);
        
        const meanX = sumX / n;
        const meanY = sumY / n;
        
        const numerator = sumXY - n * meanX * meanY;
        const denominator = sumXX - n * meanX * meanX;
        
        if (Math.abs(denominator) &lt; 1e-10) {
            this.slope = 0;
            this.intercept = meanY;
        } else {
            this.slope = numerator / denominator;
            this.intercept = meanY - this.slope * meanX;
        }
    }
    
    calculateR2() {
        if (this.points.length &lt; 2) return 0;
        
        const meanY = this.points.reduce((sum, p) =&gt; sum + p.y, 0) / this.points.length;
        let ssRes = 0;
        let ssTot = 0;
        
        for (const point of this.points) {
            const predicted = this.slope * point.x + this.intercept;
            ssRes += Math.pow(point.y - predicted, 2);
            ssTot += Math.pow(point.y - meanY, 2);
        }
        
        return ssTot === 0 ? 1 : 1 - (ssRes / ssTot);
    }
    
    calculateMSE() {
        if (this.points.length === 0) return 0;
        
        let mse = 0;
        for (const point of this.points) {
            const predicted = this.slope * point.x + this.intercept;
            mse += Math.pow(point.y - predicted, 2);
        }
        
        return mse / this.points.length;
    }
    
    draw() {
        // Clear canvas
        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
        
        // Draw grid
        this.drawGrid();
        
        // Draw regression line
        if (this.points.length &gt;= 2) {
            this.drawRegressionLine();
        }
        
        // Draw points and residuals
        this.drawPoints();
        
        // Draw axes labels
        this.drawLabels();
    }
    
    drawGrid() {
        this.ctx.strokeStyle = &apos;#f0f0f0&apos;;
        this.ctx.lineWidth = 1;
        
        // Vertical lines
        for (let i = 0; i &lt;= 10; i++) {
            const x = (i / 10) * this.canvas.width;
            this.ctx.beginPath();
            this.ctx.moveTo(x, 0);
            this.ctx.lineTo(x, this.canvas.height);
            this.ctx.stroke();
        }
        
        // Horizontal lines
        for (let i = 0; i &lt;= 10; i++) {
            const y = (i / 10) * this.canvas.height;
            this.ctx.beginPath();
            this.ctx.moveTo(0, y);
            this.ctx.lineTo(this.canvas.width, y);
            this.ctx.stroke();
        }
    }
    
    drawRegressionLine() {
        this.ctx.strokeStyle = &apos;#ff4757&apos;;
        this.ctx.lineWidth = 2;
        
        const x1 = 0;
        const y1 = this.intercept;
        const x2 = 10;
        const y2 = this.slope * x2 + this.intercept;
        
        const canvasX1 = (x1 / 10) * this.canvas.width;
        const canvasY1 = this.canvas.height - (y1 / 10) * this.canvas.height;
        const canvasX2 = (x2 / 10) * this.canvas.width;
        const canvasY2 = this.canvas.height - (y2 / 10) * this.canvas.height;
        
        this.ctx.beginPath();
        this.ctx.moveTo(canvasX1, canvasY1);
        this.ctx.lineTo(canvasX2, canvasY2);
        this.ctx.stroke();
    }
    
    drawPoints() {
        for (const point of this.points) {
            const canvasX = (point.x / 10) * this.canvas.width;
            const canvasY = this.canvas.height - (point.y / 10) * this.canvas.height;
            
            // Draw residual line (vertical distance to regression line)
            if (this.points.length &gt;= 2) {
                const predictedY = this.slope * point.x + this.intercept;
                const predictedCanvasY = this.canvas.height - (predictedY / 10) * this.canvas.height;
                
                this.ctx.strokeStyle = &apos;#ff6b6b&apos;;
                this.ctx.lineWidth = 1;
                this.ctx.setLineDash([2, 2]);
                this.ctx.beginPath();
                this.ctx.moveTo(canvasX, canvasY);
                this.ctx.lineTo(canvasX, predictedCanvasY);
                this.ctx.stroke();
                this.ctx.setLineDash([]);
            }
            
            // Draw point
            this.ctx.fillStyle = &apos;#2f3542&apos;;
            this.ctx.beginPath();
            this.ctx.arc(canvasX, canvasY, 4, 0, 2 * Math.PI);
            this.ctx.fill();
        }
    }
    
    drawLabels() {
        this.ctx.fillStyle = &apos;#666&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        
        // X-axis labels
        for (let i = 0; i &lt;= 10; i += 2) {
            const x = (i / 10) * this.canvas.width;
            this.ctx.fillText(i.toString(), x - 5, this.canvas.height - 5);
        }
        
        // Y-axis labels
        for (let i = 0; i &lt;= 10; i += 2) {
            const y = this.canvas.height - (i / 10) * this.canvas.height;
            this.ctx.fillText(i.toString(), 5, y + 3);
        }
    }
    
    updateDisplay() {
        document.getElementById(&apos;slope-value&apos;).textContent = this.slope.toFixed(3);
        document.getElementById(&apos;intercept-value&apos;).textContent = this.intercept.toFixed(3);
        document.getElementById(&apos;equation&apos;).textContent = `y = ${this.slope.toFixed(3)}x + ${this.intercept.toFixed(3)}`;
        
        if (this.points.length &gt;= 2) {
            document.getElementById(&apos;r2-value&apos;).textContent = this.calculateR2().toFixed(3);
            document.getElementById(&apos;mse-value&apos;).textContent = this.calculateMSE().toFixed(3);
        } else {
            document.getElementById(&apos;r2-value&apos;).textContent = &apos;N/A&apos;;
            document.getElementById(&apos;mse-value&apos;).textContent = &apos;N/A&apos;;
        }
    }
}

// Global functions for buttons
function clearPoints() {
    if (window.regressionDemo) {
        window.regressionDemo.clearPoints();
    }
}

function addRandomPoints() {
    if (window.regressionDemo) {
        window.regressionDemo.clearPoints();
        window.regressionDemo.addRandomPoints();
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    if (document.getElementById(&apos;regressionCanvas&apos;)) {
        window.regressionDemo = new LinearRegressionDemo();
    }
});

// Initialize immediately if DOM is already loaded
if (document.readyState === &apos;loading&apos;) {
    document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
        if (document.getElementById(&apos;regressionCanvas&apos;)) {
            window.regressionDemo = new LinearRegressionDemo();
        }
    });
} else {
    if (document.getElementById(&apos;regressionCanvas&apos;)) {
        window.regressionDemo = new LinearRegressionDemo();
    }
}
&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Given \(n\) data points \((x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)\), find the line \(y = mx + c\) that minimizes the sum of squared vertical distances from the points to the line.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Objective Function:&lt;/strong&gt; We want to minimize
\(S(m,c) = \sum_{i=1}^{n} (y_i - mx_i - c)^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; To find the minimum, we take partial derivatives and set them equal to zero.&lt;/p&gt;

&lt;p&gt;Taking the partial derivative with respect to \(c\):&lt;/p&gt;
&lt;blockquote&gt;
\[\frac{\partial S}{\partial c} = \sum_{i=1}^{n} 2(y_i - mx_i - c)(-1) = -2\sum_{i=1}^{n} (y_i - mx_i - c) = 0\]
&lt;/blockquote&gt;

&lt;p&gt;This gives us:
\(\sum_{i=1}^{n} y_i = m\sum_{i=1}^{n} x_i + nc\)&lt;/p&gt;

&lt;p&gt;Therefore:&lt;/p&gt;

&lt;blockquote&gt;
\[c = \frac{1}{n}\sum_{i=1}^{n} y_i - m\frac{1}{n}\sum_{i=1}^{n} x_i = \bar{y} - m\bar{x}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(\bar{x}\) and \(\bar{y}\) are the means of \(x\) and \(y\) values.&lt;/p&gt;

&lt;p&gt;Taking the partial derivative with respect to \(m\):&lt;/p&gt;

&lt;blockquote&gt;
\[\frac{\partial S}{\partial m} = \sum_{i=1}^{n} 2(y_i - mx_i - c)(-x_i) = -2\sum_{i=1}^{n} x_i(y_i - mx_i - c) = 0\]
&lt;/blockquote&gt;

&lt;p&gt;Substituting \(c = \bar{y} - m\bar{x}\):
\(\sum_{i=1}^{n} x_i(y_i - mx_i - \bar{y} + m\bar{x}) = 0\)&lt;/p&gt;

&lt;p&gt;Rearranging:
\(\sum_{i=1}^{n} x_iy_i - m\sum_{i=1}^{n} x_i^2 - \bar{y}\sum_{i=1}^{n} x_i + m\bar{x}\sum_{i=1}^{n} x_i = 0\)&lt;/p&gt;

&lt;p&gt;Since \(\sum_{i=1}^{n} x_i = n\bar{x}\) and \(\sum_{i=1}^{n} x_iy_i - \bar{y}\sum_{i=1}^{n} x_i = \sum_{i=1}^{n} x_i(y_i - \bar{y})\):&lt;/p&gt;

&lt;blockquote&gt;
\[\sum_{i=1}^{n} x_i(y_i - \bar{y}) = m\left(\sum_{i=1}^{n} x_i^2 - n\bar{x}^2\right)\]
&lt;/blockquote&gt;

&lt;p&gt;Note that \(\sum_{i=1}^{n} x_i^2 - n\bar{x}^2 = \sum_{i=1}^{n} (x_i - \bar{x})^2\)&lt;/p&gt;

&lt;p&gt;Therefore:&lt;/p&gt;

&lt;blockquote&gt;
\[m = \frac{\sum_{i=1}^{n} x_i(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2} = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Final Result:&lt;/strong&gt; The best-fit line has parameters:&lt;/p&gt;

&lt;blockquote&gt;
\[\boxed{m = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2} \quad \text{and} \quad c = \bar{y} - m\bar{x}}\]
&lt;/blockquote&gt;

&lt;p&gt;This is the classical least-squares solution for linear regression, also known as the &lt;strong&gt;Normal Equations&lt;/strong&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-optimal-solution-of-linear-regression-with-multiple-variables&quot;&gt;The Optimal Solution of Linear Regression with multiple variables&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Problem Statement:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In Linear Regression, we aim to find a vector of coefficients \(\mathbf{w}\) that best fits a linear model to a given dataset. We have \(n\) data points, each with \(p\) features.&lt;/p&gt;

&lt;p&gt;Let \(X\) be the design matrix of size \(n \times p\), where each row represents a data point and each column represents a feature.&lt;/p&gt;

&lt;p&gt;Let \(\mathbf{y}\) be the vector of target values of size \(n \times 1\).&lt;/p&gt;

&lt;p&gt;Our linear model predicts the target values \(\hat{\mathbf{y}}\) as:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\hat{\mathbf{y}} = X\mathbf{w}\)
where \(\mathbf{w}\) is the vector of unknown coefficients of size \(p \times 1\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Objective Function (Cost Function):&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The goal is to minimize the sum of squared errors (residuals) between the actual target values \(\mathbf{y}\) and the predicted values \(\hat{\mathbf{y}}\). This is known as the Ordinary Least Squares (OLS) objective function:
\(J(\mathbf{w}) = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \| \mathbf{y} - X\mathbf{w} \|^2\)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; \(J(\mathbf{w})\) is the &lt;strong&gt;cost function&lt;/strong&gt; (also called loss function or objective function) that measures how well our linear model fits the data. It represents the total squared error between our predictions and the actual values. The smaller \(J(\mathbf{w})\), the better our model fits the data. Our goal is to find the optimal weights \(\mathbf{w}\) that minimize this function.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We can express this in matrix form by expanding the squared Euclidean norm:
\(J(\mathbf{w}) = (\mathbf{y} - X\mathbf{w})^{\text{T}}(\mathbf{y} - X\mathbf{w})\)&lt;/p&gt;

&lt;p&gt;Expanding this expression:
\(J(\mathbf{w}) = \mathbf{y}^{\text{T}}\mathbf{y} - \mathbf{y}^{\text{T}}X\mathbf{w} - (X\mathbf{w})^{\text{T}}\mathbf{y} + (X\mathbf{w})^{\text{T}}X\mathbf{w}\)&lt;/p&gt;

&lt;p&gt;Using the property that \((AB)^{\text{T}} = B^{\text{T}}A^{\text{T}}\), we have \((X\mathbf{w})^{\text{T}} = \mathbf{w}^{\text{T}}X^{\text{T}}\).&lt;/p&gt;

&lt;p&gt;Also, since \(\mathbf{y}^{\text{T}}X\mathbf{w}\) is a scalar, its transpose is itself: \((\mathbf{y}^{\text{T}}X\mathbf{w})^{\text{T}} = \mathbf{w}^{\text{T}}X^{\text{T}}\mathbf{y}\).&lt;/p&gt;

&lt;p&gt;Thus, the two middle terms are identical:
\(J(\mathbf{w}) = \mathbf{y}^{\text{T}}\mathbf{y} - 2\mathbf{w}^{\text{T}}X^{\text{T}}\mathbf{y} + \mathbf{w}^{\text{T}}X^{\text{T}}X\mathbf{w}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Minimization \(J(\mathbf{w})\) using Calculus:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To find the optimal \(\mathbf{w}\) that minimizes \(J(\mathbf{w})\), we take the derivative of \(J(\mathbf{w})\) with respect to \(\mathbf{w}\) and set it to zero. We use the following matrix calculus rules:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
\[\frac{\partial (\mathbf{a}^{\text{T}}\mathbf{x})}{\partial \mathbf{x}} = \mathbf{a}\]
  &lt;/li&gt;
  &lt;li&gt;\(\frac{\partial (\mathbf{x}^{\text{T}}A\mathbf{x})}{\partial \mathbf{x}} = (A + A^{\text{T}})\mathbf{x}\) (If \(A\) is symmetric, this simplifies to \(2A\mathbf{x}\))&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Applying these rules to \(J(\mathbf{w})\):
\(\frac{\partial J(\mathbf{w})}{\partial \mathbf{w}} = \frac{\partial (\mathbf{y}^{\text{T}}\mathbf{y})}{\partial \mathbf{w}} - \frac{\partial (2\mathbf{w}^{\text{T}}X^{\text{T}}\mathbf{y})}{\partial \mathbf{w}} + \frac{\partial (\mathbf{w}^{\text{T}}X^{\text{T}}X\mathbf{w})}{\partial \mathbf{w}}\)&lt;/p&gt;

&lt;p&gt;Let’s evaluate each term:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\frac{\partial (\mathbf{y}^{\text{T}}\mathbf{y})}{\partial \mathbf{w}} = 0\) (since \(\mathbf{y}^{\text{T}}\mathbf{y}\) is a scalar constant with respect to \(\mathbf{w}\))&lt;/li&gt;
  &lt;li&gt;\(\frac{\partial (2\mathbf{w}^{\text{T}}X^{\text{T}}\mathbf{y})}{\partial \mathbf{w}} = 2X^{\text{T}}\mathbf{y}\) (using rule 1, with \(\mathbf{a} = X^{\text{T}}\mathbf{y}\))&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For the third term, let \(A = X^{\text{T}}X\). Note that \(A\) is a symmetric matrix because \((X^{\text{T}}X)^{\text{T}} = X^{\text{T}}(X^{\text{T}})^{\text{T}} = X^{\text{T}}X\).&lt;/p&gt;

    &lt;p&gt;So, \(\frac{\partial (\mathbf{w}^{\text{T}}X^{\text{T}}X\mathbf{w})}{\partial \mathbf{w}} = 2X^{\text{T}}X\mathbf{w}\) (using rule 2 for a symmetric matrix \(A\))&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Combining these, the derivative is:&lt;/p&gt;

&lt;blockquote&gt;
\[\frac{\partial J(\mathbf{w})}{\partial \mathbf{w}} = 0 - 2X^{\text{T}}\mathbf{y} + 2X^{\text{T}}X\mathbf{w} = 2X^{\text{T}}X\mathbf{w} - 2X^{\text{T}}\mathbf{y}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Finding the Optimal Solution:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To find the minimum of \(J(\mathbf{w})\), we set the derivative equal to zero:&lt;/p&gt;

\[\frac{\partial J(\mathbf{w})}{\partial \mathbf{w}} = 2X^{\text{T}}X\mathbf{w} - 2X^{\text{T}}\mathbf{y} = 0\]

&lt;p&gt;Dividing by 2 and rearranging:
\(X^{\text{T}}X\mathbf{w} = X^{\text{T}}\mathbf{y}\)&lt;/p&gt;

&lt;p&gt;This is known as the &lt;strong&gt;Normal Equation&lt;/strong&gt;. If \(X^{\text{T}}X\) is invertible (which happens when \(X\) has full column rank), we can solve for \(\mathbf{w}\):&lt;/p&gt;

&lt;blockquote&gt;
\[\boxed{\mathbf{w}^* = (X^{\text{T}}X)^{-1}X^{\text{T}}\mathbf{y}}\]
&lt;/blockquote&gt;

&lt;p&gt;This is the &lt;strong&gt;closed-form solution&lt;/strong&gt; for linear least-squares regression, also known as the &lt;strong&gt;Normal Equation solution&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Performance:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Time complexity: roughly \(n^2k\) operations&lt;/li&gt;
  &lt;li&gt;A standard computer solves problems with hundreds of variables and thousands of terms in seconds&lt;/li&gt;
  &lt;li&gt;Sparse matrices (many zero entries) can be solved much faster&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; A sparse matrix for image processing might have only 5 non-zero entries per row in a 10,000 × 10,000 matrix.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>05-01 Linear Programming (LP)</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_01_Linear_Programming_(LP)/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_01_Linear_Programming_(LP)</id>
   <content type="html">&lt;script src=&quot;https://d3js.org/d3.v7.min.js&quot;&gt;&lt;/script&gt;

&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;

&lt;script id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;Linear Programming (LP) is one of the most fundamental and widely-used optimization techniques in mathematics, economics, and engineering. Imagine you’re a factory manager trying to maximize profit while dealing with limited resources - this is exactly the type of problem LP was designed to solve!&lt;/p&gt;

&lt;h3 id=&quot;what-makes-a-problem-linear&quot;&gt;What makes a problem “Linear”?&lt;/h3&gt;

&lt;p&gt;A problem is linear when:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;objective function&lt;/strong&gt; (what you want to optimize) is a straight line relationship&lt;/li&gt;
  &lt;li&gt;All &lt;strong&gt;constraints&lt;/strong&gt; (limitations) are also straight line relationships&lt;/li&gt;
  &lt;li&gt;No variables are multiplied together (no \(x_1 \cdot x_2\) terms)&lt;/li&gt;
  &lt;li&gt;No variables appear in exponents or under square roots&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;simple-example-the-farmers-problem&quot;&gt;Simple Example: The Farmer’s Problem&lt;/h3&gt;

&lt;p&gt;Let’s start with an intuitive example. A farmer has 100 acres of land and wants to plant corn and wheat to maximize profit:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Corn&lt;/strong&gt;: $300 profit per acre, requires 2 hours of labor per acre&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Wheat&lt;/strong&gt;: $200 profit per acre, requires 1 hour of labor per acre&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Available labor&lt;/strong&gt;: 150 hours total&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: How many acres of each crop should the farmer plant?&lt;/p&gt;

&lt;div id=&quot;farmer-problem-viz&quot; style=&quot;margin: 20px 0;&quot;&gt;&lt;/div&gt;

&lt;div class=&quot;content-box exercise-box&quot;&gt;
&lt;strong&gt;Interactive Exercise:&lt;/strong&gt; Use the sliders below to explore different combinations of corn and wheat. Watch how the profit changes and whether constraints are satisfied!

&lt;div style=&quot;margin: 10px 0;&quot;&gt;
  &lt;label for=&quot;corn-acres&quot;&gt;Corn acres: &lt;span id=&quot;corn-value&quot;&gt;50&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
  &lt;input type=&quot;range&quot; id=&quot;corn-acres&quot; min=&quot;0&quot; max=&quot;100&quot; value=&quot;50&quot; style=&quot;width: 300px;&quot; /&gt;
&lt;/div&gt;

&lt;div style=&quot;margin: 10px 0;&quot;&gt;
  &lt;label for=&quot;wheat-acres&quot;&gt;Wheat acres: &lt;span id=&quot;wheat-value&quot;&gt;50&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
  &lt;input type=&quot;range&quot; id=&quot;wheat-acres&quot; min=&quot;0&quot; max=&quot;100&quot; value=&quot;50&quot; style=&quot;width: 300px;&quot; /&gt;
&lt;/div&gt;

&lt;div id=&quot;farmer-results&quot; style=&quot;margin-top: 15px; font-family: monospace;&quot;&gt;
  &lt;div&gt;Total land used: &lt;span id=&quot;land-used&quot;&gt;100&lt;/span&gt; / 100 acres&lt;/div&gt;
  &lt;div&gt;Total labor used: &lt;span id=&quot;labor-used&quot;&gt;150&lt;/span&gt; / 150 hours&lt;/div&gt;
  &lt;div&gt;Total profit: $&lt;span id=&quot;total-profit&quot;&gt;25000&lt;/span&gt;&lt;/div&gt;
  &lt;div id=&quot;feasibility-status&quot; style=&quot;font-weight: bold; color: green;&quot;&gt;✓ Feasible solution&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Now let’s formalize this intuition. If both the objective function and constraint functions are affine, the optimization problem is called a &lt;em&gt;linear program&lt;/em&gt; (LP). The general linear program is formulated as:&lt;/p&gt;

&lt;h3 id=&quot;general-lp&quot;&gt;General LP&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Gx \preceq h}\\\\
   &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
   &amp;amp;\text{where } &amp;amp;&amp;amp;G \in \mathbb{R}^{m \times n} \text{ and } A \in \mathbb{R}^{p \times n}.
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;The constant \(+d\) in the objective function does not affect the optimization process or result and can be omitted.&lt;/li&gt;
  &lt;li&gt;If you want to maximize \(c^T x + d\) under the same constraints, you can equivalently minimize \(-c^T x - d\).&lt;/li&gt;
  &lt;li&gt;The above problem seeks the minimizer \(x^*\) of the affine function \(c^T x + d\) over a polyhedral feasible set.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

&lt;p&gt;The power of linear programming becomes clear when we visualize it geometrically. Each constraint defines a half-space, and the feasible region is the intersection of all these half-spaces - forming a &lt;strong&gt;polyhedron&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Key Insight:&lt;/strong&gt; The optimal solution of a linear program always occurs at a &lt;strong&gt;vertex&lt;/strong&gt; (corner point) of the feasible region! This is why the simplex method works by moving from vertex to vertex.
&lt;/div&gt;

&lt;div id=&quot;geometric-lp-viz&quot; style=&quot;margin: 20px 0; text-align: center;&quot;&gt;&lt;/div&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter05/05_01_geometric_interpretation_of_LP.png&quot; alt=&quot;[Fig1] Geometric interpretation of LP [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Traditional geometric interpretation of LP [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;lp-in-standard-form&quot;&gt;LP in Standard form&lt;/h2&gt;

&lt;p&gt;Why do we need a standard form? Many LP algorithms (like the simplex method) are designed to work with a specific format. Converting to standard form allows us to use these powerful algorithms consistently.&lt;/p&gt;

&lt;h3 id=&quot;standard-form-lp&quot;&gt;Standard form LP&lt;/h3&gt;
&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x + d} \\\\
   &amp;amp;\text{subject to } &amp;amp;&amp;amp;{A x = b} \\\\
   &amp;amp; &amp;amp;&amp;amp;{x \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Key characteristics of standard form:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Always minimization (maximization problems are converted by negating)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Constraints&lt;/strong&gt;: Only equality constraints (inequalities converted using slack variables)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Variables&lt;/strong&gt;: All variables must be non-negative&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Why Standard Form?&lt;/strong&gt; 
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Algorithmic efficiency:&lt;/strong&gt; Simplex method works directly on standard form&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Theoretical analysis:&lt;/strong&gt; Easier to prove optimality conditions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Software implementation:&lt;/strong&gt; Most LP solvers expect standard form input&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;All general LPs can be converted to standard form using the following steps:&lt;/p&gt;

&lt;h3 id=&quot;converting-lps-to-standard-form&quot;&gt;Converting LPs to standard form&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; Use slack variables \(s\) to convert inequality constraints into equality constraints:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
    &amp;amp;\text{minimize}_{x, s} &amp;amp;&amp;amp;{c^T x + d} \\\\
    &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Gx + s = h} \\\\
    &amp;amp; &amp;amp;&amp;amp;{Ax = b},\\\\
    &amp;amp; &amp;amp;&amp;amp;{s \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; Replace each variable \(x\) with two nonnegative variables:
\(x = x^{+}  - x^{-}\), where \(x^{+} \text{, } x^{-} \succeq 0\).&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
    &amp;amp;\text{minimize}_{x^{+}, x^{-}, s} &amp;amp;&amp;amp;{c^Tx^{+} - c^Tx^{-} + d} \\\\
    &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Gx^{+} - Gx^{-} + s = h} \\\\
    &amp;amp; &amp;amp;&amp;amp;{Ax^{+} - Ax^{-} = b},\\\\
    &amp;amp; &amp;amp;&amp;amp;{s \succeq 0}\\\\
    &amp;amp; &amp;amp;&amp;amp;{x^{+} \succeq 0}, {x^{-} \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; Define \(\tilde{x}\), \(\tilde{c}\), \(\tilde{b}\), and \(\tilde{A}\) as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(\tilde{x} =
\begin{bmatrix}
x^{+} \\\\
x^{-} \\\\
s
\end{bmatrix}, 
\tilde{c} =
\begin{bmatrix}
c \\\\
-c \\\\
0
\end{bmatrix},
\tilde{b} =
\begin{bmatrix}
h \\\\
b
\end{bmatrix}\), 
\(\tilde{A} =
\begin{bmatrix}
G &amp;amp; -G &amp;amp; I\\\\
A &amp;amp; -A &amp;amp; O
\end{bmatrix}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt; Substitute \(\tilde{x}\), \(\tilde{c}\), \(\tilde{b}\), and \(\tilde{A}\) into the problem from Step 2:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
    &amp;amp;\text{minimize}_{\tilde{x}} &amp;amp;&amp;amp;{\tilde{c}^T \tilde{x} + d} \\\\
    &amp;amp;\text{subject to} &amp;amp;&amp;amp;{\tilde{A} \tilde{x} = \tilde{b}} \\\\
    &amp;amp; &amp;amp;&amp;amp;{\tilde{x} \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;example---diet-program&quot;&gt;Example - Diet program&lt;/h3&gt;

&lt;p&gt;The diet problem is a classic application of linear programming, first studied during World War II to find the most economical way to feed soldiers while meeting nutritional requirements.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Problem Setup:&lt;/strong&gt; Find the cheapest combination of foods that meets all nutritional requirements.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
    &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x} \\\\
    &amp;amp;\text{subject to } &amp;amp;&amp;amp;{Dx \succeq d} \\\\
    &amp;amp; &amp;amp;&amp;amp;{x \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Variables and Parameters:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(c_j\): Cost per unit of food item j ($/unit)&lt;/li&gt;
  &lt;li&gt;\(d_i\): Minimum recommended intake for nutrient i (units/day)&lt;/li&gt;
  &lt;li&gt;\(D_{ij}\): Amount of nutrient i in food item j (units of nutrient per unit of food)&lt;/li&gt;
  &lt;li&gt;\(x_j\): Amount of food item j in the diet (units/day)&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;content-box exercise-box&quot;&gt;
&lt;strong&gt;Interactive Diet Optimizer:&lt;/strong&gt; Let&apos;s solve a simplified diet problem with 3 foods and 2 nutrients!

&lt;div style=&quot;display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 15px; margin: 15px 0;&quot;&gt;
  &lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;strong&gt;Bread&lt;/strong&gt;&lt;br /&gt;
    Cost: $2/loaf&lt;br /&gt;
    Protein: 4g/loaf&lt;br /&gt;
    Calories: 200/loaf
  &lt;/div&gt;
  &lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;strong&gt;Milk&lt;/strong&gt;&lt;br /&gt;
    Cost: $3/liter&lt;br /&gt;
    Protein: 8g/liter&lt;br /&gt;
    Calories: 150/liter
  &lt;/div&gt;
  &lt;div style=&quot;text-align: center;&quot;&gt;
    &lt;strong&gt;Meat&lt;/strong&gt;&lt;br /&gt;
    Cost: $8/kg&lt;br /&gt;
    Protein: 20g/kg&lt;br /&gt;
    Calories: 300/kg
  &lt;/div&gt;
&lt;/div&gt;

&lt;div style=&quot;margin: 15px 0;&quot;&gt;
  &lt;strong&gt;Requirements:&lt;/strong&gt;
  &lt;div&gt;Minimum protein: &lt;input type=&quot;number&quot; id=&quot;min-protein&quot; value=&quot;20&quot; min=&quot;10&quot; max=&quot;50&quot; style=&quot;width: 60px;&quot; /&gt; grams/day&lt;/div&gt;
  &lt;div&gt;Minimum calories: &lt;input type=&quot;number&quot; id=&quot;min-calories&quot; value=&quot;800&quot; min=&quot;500&quot; max=&quot;1500&quot; style=&quot;width: 80px;&quot; /&gt; calories/day&lt;/div&gt;
&lt;/div&gt;

&lt;button id=&quot;solve-diet&quot; style=&quot;background-color: #4CAF50; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer;&quot;&gt;Solve Diet Problem&lt;/button&gt;

&lt;div id=&quot;diet-results&quot; style=&quot;margin-top: 15px; font-family: monospace; background-color: #f9f9f9; padding: 10px; border-radius: 4px;&quot;&gt;
  &lt;div&gt;Click &quot;Solve Diet Problem&quot; to see the optimal solution!&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Real-world Applications:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Military logistics:&lt;/strong&gt; Feeding troops cost-effectively&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hospital meal planning:&lt;/strong&gt; Meeting patient dietary requirements&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Animal feed optimization:&lt;/strong&gt; Livestock nutrition at minimum cost&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;School lunch programs:&lt;/strong&gt; Nutritious meals within budget constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;h2 id=&quot;the-simplex-algorithm&quot;&gt;The Simplex Algorithm&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Simplex Algorithm&lt;/strong&gt;, developed by George Dantzig in 1947, is one of the most important algorithms in optimization history. It revolutionized linear programming by providing an efficient method to solve LP problems systematically.&lt;/p&gt;

&lt;h3 id=&quot;why-simplex-works-the-fundamental-theorem&quot;&gt;Why Simplex Works: The Fundamental Theorem&lt;/h3&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Fundamental Theorem of Linear Programming:&lt;/strong&gt; If a linear program has an optimal solution, then there exists an optimal solution that occurs at a vertex (extreme point) of the feasible region.
&lt;/div&gt;

&lt;p&gt;This theorem is the key insight behind the Simplex algorithm. Instead of searching the entire feasible region (which could be infinite), we only need to check the finite number of vertices!&lt;/p&gt;

&lt;h3 id=&quot;how-simplex-works-the-strategy&quot;&gt;How Simplex Works: The Strategy&lt;/h3&gt;

&lt;p&gt;The Simplex algorithm follows this elegant strategy:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Start&lt;/strong&gt; at any vertex of the feasible region&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Check&lt;/strong&gt; if the current vertex is optimal&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Move&lt;/strong&gt; to an adjacent vertex that improves the objective function&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Repeat&lt;/strong&gt; until no improvement is possible (optimal solution found)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;simplex-algorithm-steps&quot;&gt;Simplex Algorithm Steps&lt;/h3&gt;

&lt;p&gt;Let’s walk through the algorithm step by step using our standard form LP:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
    &amp;amp;\text{minimize}_{x} &amp;amp;&amp;amp;{c^T x} \\\\
    &amp;amp;\text{subject to } &amp;amp;&amp;amp;{A x = b} \\\\
    &amp;amp; &amp;amp;&amp;amp;{x \succeq 0}.
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Initial Setup&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Convert the LP to standard form (if not already)&lt;/li&gt;
  &lt;li&gt;Find an initial basic feasible solution (vertex)&lt;/li&gt;
  &lt;li&gt;Set up the simplex tableau&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 2: Optimality Test&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Check if the current solution is optimal&lt;/li&gt;
  &lt;li&gt;If all reduced costs are non-negative, we’re done!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 3: Choose Entering Variable&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Select the variable with the most negative reduced cost&lt;/li&gt;
  &lt;li&gt;This determines the direction to move&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 4: Choose Leaving Variable&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Use the minimum ratio test to avoid infeasibility&lt;/li&gt;
  &lt;li&gt;This determines how far to move&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 5: Pivot Operation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Update the tableau using Gaussian elimination&lt;/li&gt;
  &lt;li&gt;Move to the new vertex&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Step 6: Repeat&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Go back to Step 2 until optimal&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;interactive-simplex-example&quot;&gt;Interactive Simplex Example&lt;/h3&gt;

&lt;p&gt;Let’s solve a simple 2D problem step by step to see how Simplex works in practice:&lt;/p&gt;

&lt;div class=&quot;content-box exercise-box&quot;&gt;
&lt;strong&gt;Interactive Simplex Solver:&lt;/strong&gt; Watch the algorithm move from vertex to vertex!

**Problem:**
$$\begin{align}
\text{maximize } &amp;amp; 3x_1 + 2x_2 \\
\text{subject to } &amp;amp; x_1 + x_2 \leq 4 \\
&amp;amp; 2x_1 + x_2 \leq 6 \\
&amp;amp; x_1, x_2 \geq 0
\end{align}$$

&lt;div id=&quot;simplex-interactive&quot; style=&quot;margin: 20px 0;&quot;&gt;&lt;/div&gt;

&lt;div style=&quot;margin: 15px 0;&quot;&gt;
  &lt;button id=&quot;simplex-step&quot; style=&quot;background-color: #2196F3; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; margin-right: 10px;&quot;&gt;Next Step&lt;/button&gt;
  &lt;button id=&quot;simplex-reset&quot; style=&quot;background-color: #f44336; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer;&quot;&gt;Reset&lt;/button&gt;
&lt;/div&gt;

&lt;div id=&quot;simplex-status&quot; style=&quot;margin-top: 15px; font-family: monospace; background-color: #f9f9f9; padding: 15px; border-radius: 4px;&quot;&gt;
  &lt;div&gt;&lt;strong&gt;Step 0:&lt;/strong&gt; Starting at origin (0, 0)&lt;/div&gt;
  &lt;div&gt;Current objective value: 0&lt;/div&gt;
  &lt;div&gt;Click &quot;Next Step&quot; to begin the Simplex algorithm!&lt;/div&gt;
&lt;/div&gt;

&lt;div id=&quot;simplex-tableau&quot; style=&quot;margin-top: 15px; font-family: monospace; background-color: #f0f8ff; padding: 15px; border-radius: 4px;&quot;&gt;
  &lt;strong&gt;Current Simplex Tableau:&lt;/strong&gt;
  &lt;div id=&quot;tableau-content&quot; style=&quot;margin-top: 10px;&quot;&gt;
    Click &quot;Next Step&quot; to see the tableau!
  &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;why-simplex-is-efficient&quot;&gt;Why Simplex is Efficient&lt;/h3&gt;

&lt;p&gt;Despite having potentially exponential worst-case complexity, Simplex is remarkably efficient in practice:&lt;/p&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Simplex Efficiency:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Average case:&lt;/strong&gt; Typically visits only 2-3 times the number of constraints&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Practical problems:&lt;/strong&gt; Often solves in polynomial time&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Warm starts:&lt;/strong&gt; Can reuse previous solutions when problem changes slightly&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Degeneracy handling:&lt;/strong&gt; Modern implementations handle degenerate cases well&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;h3 id=&quot;simplex-variants-and-modern-developments&quot;&gt;Simplex Variants and Modern Developments&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Revised Simplex Method:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;More numerically stable&lt;/li&gt;
  &lt;li&gt;Better for sparse matrices&lt;/li&gt;
  &lt;li&gt;Used in most commercial solvers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Dual Simplex Method:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Starts with dual feasible solution&lt;/li&gt;
  &lt;li&gt;Useful for sensitivity analysis&lt;/li&gt;
  &lt;li&gt;Better for certain problem types&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Interior Point Methods:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Polynomial-time complexity guarantee&lt;/li&gt;
  &lt;li&gt;Better for very large problems&lt;/li&gt;
  &lt;li&gt;Complement rather than replace Simplex&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;impact-and-applications&quot;&gt;Impact and Applications&lt;/h3&gt;

&lt;p&gt;The Simplex algorithm has transformed numerous industries:&lt;/p&gt;

&lt;div class=&quot;content-box insight-box&quot;&gt;
&lt;strong&gt;Simplex Success Stories:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Airlines:&lt;/strong&gt; Crew scheduling, route optimization, fleet assignment&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Manufacturing:&lt;/strong&gt; Production planning, supply chain optimization&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Finance:&lt;/strong&gt; Portfolio optimization, risk management&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Telecommunications:&lt;/strong&gt; Network flow optimization, bandwidth allocation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Energy:&lt;/strong&gt; Power grid optimization, resource allocation&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;script&gt;
/**
 * Interactive Linear Programming Visualizations
 * Implements farmer problem, geometric interpretation, diet optimizer, and norm comparisons
 */

// Wait for DOM to be fully loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    
    // ==================== FARMER PROBLEM INTERACTIVE ====================
    
    function initializeFarmerProblem() {
        const cornSlider = document.getElementById(&apos;corn-acres&apos;);
        const wheatSlider = document.getElementById(&apos;wheat-acres&apos;);
        
        if (!cornSlider || !wheatSlider) return;
        
        function updateFarmerResults() {
            const corn = parseFloat(cornSlider.value);
            const wheat = parseFloat(wheatSlider.value);
            
            // Update display values
            document.getElementById(&apos;corn-value&apos;).textContent = corn;
            document.getElementById(&apos;wheat-value&apos;).textContent = wheat;
            
            // Calculate metrics
            const landUsed = corn + wheat;
            const laborUsed = corn * 2 + wheat * 1; // 2 hours per corn acre, 1 hour per wheat acre
            const profit = corn * 300 + wheat * 200; // $300 per corn acre, $200 per wheat acre
            
            // Update results
            document.getElementById(&apos;land-used&apos;).textContent = landUsed;
            document.getElementById(&apos;labor-used&apos;).textContent = laborUsed;
            document.getElementById(&apos;total-profit&apos;).textContent = profit;
            
            // Check feasibility
            const feasibilityStatus = document.getElementById(&apos;feasibility-status&apos;);
            if (landUsed &lt;= 100 &amp;&amp; laborUsed &lt;= 150) {
                feasibilityStatus.textContent = &apos;✓ Feasible solution&apos;;
                feasibilityStatus.style.color = &apos;green&apos;;
            } else {
                feasibilityStatus.textContent = &apos;✗ Infeasible solution&apos;;
                feasibilityStatus.style.color = &apos;red&apos;;
            }
        }
        
        cornSlider.addEventListener(&apos;input&apos;, updateFarmerResults);
        wheatSlider.addEventListener(&apos;input&apos;, updateFarmerResults);
        
        // Initialize
        updateFarmerResults();
    }
    
    // ==================== DIET PROBLEM SOLVER ====================
    
    function initializeDietSolver() {
        const solveButton = document.getElementById(&apos;solve-diet&apos;);
        if (!solveButton) return;
        
        solveButton.addEventListener(&apos;click&apos;, function() {
            const minProtein = parseFloat(document.getElementById(&apos;min-protein&apos;).value);
            const minCalories = parseFloat(document.getElementById(&apos;min-calories&apos;).value);
            
            // Simple heuristic solver (in practice, would use simplex method)
            // Food data: [cost, protein, calories]
            const bread = [2, 4, 200];
            const milk = [3, 8, 150];
            const meat = [8, 20, 300];
            
            // Try different combinations and find minimum cost feasible solution
            let bestCost = Infinity;
            let bestSolution = null;
            
            for (let b = 0; b &lt;= 20; b += 0.5) {
                for (let m = 0; m &lt;= 10; m += 0.5) {
                    for (let mt = 0; mt &lt;= 5; mt += 0.5) {
                        const protein = b * bread[1] + m * milk[1] + mt * meat[1];
                        const calories = b * bread[2] + m * milk[2] + mt * meat[2];
                        const cost = b * bread[0] + m * milk[0] + mt * meat[0];
                        
                        if (protein &gt;= minProtein &amp;&amp; calories &gt;= minCalories &amp;&amp; cost &lt; bestCost) {
                            bestCost = cost;
                            bestSolution = [b, m, mt];
                        }
                    }
                }
            }
            
            const resultsDiv = document.getElementById(&apos;diet-results&apos;);
            if (bestSolution) {
                const [bread_amt, milk_amt, meat_amt] = bestSolution;
                const totalProtein = bread_amt * bread[1] + milk_amt * milk[1] + meat_amt * meat[1];
                const totalCalories = bread_amt * bread[2] + milk_amt * milk[2] + meat_amt * meat[2];
                
                resultsDiv.innerHTML = `
                    &lt;div&gt;&lt;strong&gt;Optimal Diet Solution:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Bread: ${bread_amt.toFixed(1)} loaves&lt;/div&gt;
                    &lt;div&gt;Milk: ${milk_amt.toFixed(1)} liters&lt;/div&gt;
                    &lt;div&gt;Meat: ${meat_amt.toFixed(1)} kg&lt;/div&gt;
                    &lt;div&gt;---&lt;/div&gt;
                    &lt;div&gt;Total cost: $${bestCost.toFixed(2)}&lt;/div&gt;
                    &lt;div&gt;Total protein: ${totalProtein.toFixed(1)}g (required: ${minProtein}g)&lt;/div&gt;
                    &lt;div&gt;Total calories: ${totalCalories.toFixed(0)} (required: ${minCalories})&lt;/div&gt;
                `;
            } else {
                resultsDiv.innerHTML = &apos;&lt;div style=&quot;color: red;&quot;&gt;No feasible solution found!&lt;/div&gt;&apos;;
            }
        });
    }
    
    // ==================== SIMPLEX ALGORITHM VISUALIZATION ====================
    
    function initializeSimplexVisualization() {
        const stepButton = document.getElementById(&apos;simplex-step&apos;);
        const resetButton = document.getElementById(&apos;simplex-reset&apos;);
        const statusDiv = document.getElementById(&apos;simplex-status&apos;);
        const tableauDiv = document.getElementById(&apos;tableau-content&apos;);
        const interactiveDiv = document.getElementById(&apos;simplex-interactive&apos;);
        
        if (!stepButton || !resetButton || !statusDiv || !tableauDiv || !interactiveDiv) return;
        
        // Simplex algorithm state
        let currentStep = 0;
        let currentVertex = [0, 0]; // Starting at origin
        let isOptimal = false;
        
        // Problem: maximize 3x1 + 2x2 subject to x1 + x2 &lt;= 4, 2x1 + x2 &lt;= 6, x1,x2 &gt;= 0
        // In standard form: minimize -3x1 - 2x2 subject to x1 + x2 + s1 = 4, 2x1 + x2 + s2 = 6
        
        const vertices = [
            [0, 0, 4, 6], // (x1, x2, s1, s2) - origin
            [0, 4, 0, 2], // (0, 4, 0, 2) - intersection with x1 + x2 = 4
            [2, 2, 0, 0], // (2, 2, 0, 0) - intersection of both constraints
            [3, 0, 1, 0]  // (3, 0, 1, 0) - intersection with 2x1 + x2 = 6
        ];
        
        const objectiveValues = [0, 8, 10, 9]; // 3x1 + 2x2 at each vertex
        const simplexPath = [0, 3, 2]; // Path: origin -&gt; (3,0) -&gt; (2,2) optimal
        
        function createVisualization() {
            const width = 400;
            const height = 300;
            const margin = {top: 20, right: 20, bottom: 40, left: 40};
            
            // Clear previous content
            interactiveDiv.innerHTML = &apos;&apos;;
            
            const svg = d3.select(&apos;#simplex-interactive&apos;)
                .append(&apos;svg&apos;)
                .attr(&apos;width&apos;, width)
                .attr(&apos;height&apos;, height);
            
            // Scales
            const xScale = d3.scaleLinear()
                .domain([0, 4])
                .range([margin.left, width - margin.right]);
            
            const yScale = d3.scaleLinear()
                .domain([0, 6])
                .range([height - margin.bottom, margin.top]);
            
            // Draw feasible region
            const feasibleRegion = [
                [0, 0], [0, 4], [2, 2], [3, 0], [0, 0]
            ];
            
            svg.append(&apos;path&apos;)
                .datum(feasibleRegion)
                .attr(&apos;fill&apos;, &apos;lightblue&apos;)
                .attr(&apos;fill-opacity&apos;, 0.3)
                .attr(&apos;stroke&apos;, &apos;blue&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;d&apos;, d3.line()
                    .x(d =&gt; xScale(d[0]))
                    .y(d =&gt; yScale(d[1]))
                );
            
            // Draw constraint lines
            // x1 + x2 = 4
            svg.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, xScale(0))
                .attr(&apos;y1&apos;, yScale(4))
                .attr(&apos;x2&apos;, xScale(4))
                .attr(&apos;y2&apos;, yScale(0))
                .attr(&apos;stroke&apos;, &apos;red&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;stroke-dasharray&apos;, &apos;5,5&apos;);
            
            // 2x1 + x2 = 6
            svg.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, xScale(0))
                .attr(&apos;y1&apos;, yScale(6))
                .attr(&apos;x2&apos;, xScale(3))
                .attr(&apos;y2&apos;, yScale(0))
                .attr(&apos;stroke&apos;, &apos;green&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;stroke-dasharray&apos;, &apos;5,5&apos;);
            
            // Draw vertices
            const vertexPoints = [[0,0], [0,4], [2,2], [3,0]];
            svg.selectAll(&apos;.vertex&apos;)
                .data(vertexPoints)
                .enter()
                .append(&apos;circle&apos;)
                .attr(&apos;class&apos;, &apos;vertex&apos;)
                .attr(&apos;cx&apos;, d =&gt; xScale(d[0]))
                .attr(&apos;cy&apos;, d =&gt; yScale(d[1]))
                .attr(&apos;r&apos;, 6)
                .attr(&apos;fill&apos;, &apos;orange&apos;)
                .attr(&apos;stroke&apos;, &apos;black&apos;)
                .attr(&apos;stroke-width&apos;, 2);
            
            // Current position indicator
            svg.append(&apos;circle&apos;)
                .attr(&apos;id&apos;, &apos;current-position&apos;)
                .attr(&apos;cx&apos;, xScale(currentVertex[0]))
                .attr(&apos;cy&apos;, yScale(currentVertex[1]))
                .attr(&apos;r&apos;, 8)
                .attr(&apos;fill&apos;, &apos;red&apos;)
                .attr(&apos;stroke&apos;, &apos;darkred&apos;)
                .attr(&apos;stroke-width&apos;, 3);
            
            // Axes
            svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(0,${height - margin.bottom})`)
                .call(d3.axisBottom(xScale));
            
            svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${margin.left},0)`)
                .call(d3.axisLeft(yScale));
            
            // Axis labels
            svg.append(&apos;text&apos;)
                .attr(&apos;x&apos;, width / 2)
                .attr(&apos;y&apos;, height - 5)
                .attr(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;x₁&apos;);
            
            svg.append(&apos;text&apos;)
                .attr(&apos;transform&apos;, &apos;rotate(-90)&apos;)
                .attr(&apos;x&apos;, -height / 2)
                .attr(&apos;y&apos;, 15)
                .attr(&apos;text-anchor&apos;, &apos;middle&apos;)
                .text(&apos;x₂&apos;);
            
            // Legend
            const legend = svg.append(&apos;g&apos;)
                .attr(&apos;transform&apos;, `translate(${width - 150}, 30)`);
            
            legend.append(&apos;text&apos;)
                .attr(&apos;x&apos;, 0)
                .attr(&apos;y&apos;, 0)
                .text(&apos;Constraints:&apos;)
                .attr(&apos;font-weight&apos;, &apos;bold&apos;);
            
            legend.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, 0)
                .attr(&apos;y1&apos;, 15)
                .attr(&apos;x2&apos;, 20)
                .attr(&apos;y2&apos;, 15)
                .attr(&apos;stroke&apos;, &apos;red&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;stroke-dasharray&apos;, &apos;5,5&apos;);
            
            legend.append(&apos;text&apos;)
                .attr(&apos;x&apos;, 25)
                .attr(&apos;y&apos;, 19)
                .text(&apos;x₁ + x₂ ≤ 4&apos;)
                .attr(&apos;font-size&apos;, &apos;12px&apos;);
            
            legend.append(&apos;line&apos;)
                .attr(&apos;x1&apos;, 0)
                .attr(&apos;y1&apos;, 30)
                .attr(&apos;x2&apos;, 20)
                .attr(&apos;y2&apos;, 30)
                .attr(&apos;stroke&apos;, &apos;green&apos;)
                .attr(&apos;stroke-width&apos;, 2)
                .attr(&apos;stroke-dasharray&apos;, &apos;5,5&apos;);
            
            legend.append(&apos;text&apos;)
                .attr(&apos;x&apos;, 25)
                .attr(&apos;y&apos;, 34)
                .text(&apos;2x₁ + x₂ ≤ 6&apos;)
                .attr(&apos;font-size&apos;, &apos;12px&apos;);
        }
        
        function updateTableau(step) {
            let tableauHTML = &apos;&apos;;
            
            switch(step) {
                case 0:
                    tableauHTML = `
                        &lt;table style=&quot;border-collapse: collapse; margin: 10px 0;&quot;&gt;
                            &lt;tr style=&quot;background-color: #e0e0e0;&quot;&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;Basic&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;RHS&lt;/th&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;4&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;2&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;6&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #fff2cc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;z&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; color: red;&quot;&gt;&lt;strong&gt;-3&lt;/strong&gt;&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; color: red;&quot;&gt;-2&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                            &lt;/tr&gt;
                        &lt;/table&gt;
                        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
                            &lt;strong&gt;Analysis:&lt;/strong&gt; Most negative coefficient is -3 (x₁ column). x₁ enters the basis.
                        &lt;/div&gt;
                    `;
                    break;
                case 1:
                    tableauHTML = `
                        &lt;table style=&quot;border-collapse: collapse; margin: 10px 0;&quot;&gt;
                            &lt;tr style=&quot;background-color: #e0e0e0;&quot;&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;Basic&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;RHS&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;Ratio&lt;/th&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; background-color: #ffcccc;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;4&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;4/1 = 4&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #ccffcc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; background-color: #ffcccc;&quot;&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;6&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;&lt;strong&gt;6/2 = 3&lt;/strong&gt;&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #fff2cc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;z&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; background-color: #ffcccc;&quot;&gt;-3&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;-2&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;-&lt;/td&gt;
                            &lt;/tr&gt;
                        &lt;/table&gt;
                        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
                            &lt;strong&gt;Minimum ratio test:&lt;/strong&gt; min{4/1, 6/2} = min{4, 3} = 3. s₂ leaves the basis.
                        &lt;/div&gt;
                    `;
                    break;
                case 2:
                    tableauHTML = `
                        &lt;table style=&quot;border-collapse: collapse; margin: 10px 0;&quot;&gt;
                            &lt;tr style=&quot;background-color: #e0e0e0;&quot;&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;Basic&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;RHS&lt;/th&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; color: red;&quot;&gt;&lt;strong&gt;0.5&lt;/strong&gt;&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;-0.5&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0.5&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0.5&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;3&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #fff2cc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;z&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px; color: red;&quot;&gt;&lt;strong&gt;-0.5&lt;/strong&gt;&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1.5&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;9&lt;/td&gt;
                            &lt;/tr&gt;
                        &lt;/table&gt;
                        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
                            &lt;strong&gt;Current solution:&lt;/strong&gt; x₁ = 3, x₂ = 0, objective = 9&lt;br&gt;
                            &lt;strong&gt;Analysis:&lt;/strong&gt; x₂ has negative coefficient (-0.5), so x₂ enters the basis.
                        &lt;/div&gt;
                    `;
                    break;
                case 3:
                    tableauHTML = `
                        &lt;table style=&quot;border-collapse: collapse; margin: 10px 0;&quot;&gt;
                            &lt;tr style=&quot;background-color: #e0e0e0;&quot;&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;Basic&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₁&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;s₂&lt;/th&gt;
                                &lt;th style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;RHS&lt;/th&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #ccffcc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₂&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;2&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;-1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;2&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;x₁&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;-1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;2&lt;/td&gt;
                            &lt;/tr&gt;
                            &lt;tr style=&quot;background-color: #ccffcc;&quot;&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;z&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;0&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;1&lt;/td&gt;
                                &lt;td style=&quot;border: 1px solid #ccc; padding: 8px;&quot;&gt;10&lt;/td&gt;
                            &lt;/tr&gt;
                        &lt;/table&gt;
                        &lt;div style=&quot;margin-top: 10px;&quot;&gt;
                            &lt;strong&gt;OPTIMAL SOLUTION FOUND!&lt;/strong&gt;&lt;br&gt;
                            x₁ = 2, x₂ = 2, Maximum objective value = 10&lt;br&gt;
                            All coefficients in the objective row are non-negative.
                        &lt;/div&gt;
                    `;
                    break;
            }
            
            tableauDiv.innerHTML = tableauHTML;
        }
        
        function updateStatus(step) {
            let statusHTML = &apos;&apos;;
            
            switch(step) {
                case 0:
                    statusHTML = `
                        &lt;div&gt;&lt;strong&gt;Step 0:&lt;/strong&gt; Initial basic feasible solution&lt;/div&gt;
                        &lt;div&gt;Current vertex: (0, 0)&lt;/div&gt;
                        &lt;div&gt;Current objective value: 0&lt;/div&gt;
                        &lt;div&gt;Basic variables: s₁ = 4, s₂ = 6&lt;/div&gt;
                    `;
                    currentVertex = [0, 0];
                    break;
                case 1:
                    statusHTML = `
                        &lt;div&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Choose entering variable&lt;/div&gt;
                        &lt;div&gt;Most negative coefficient: -3 (x₁ column)&lt;/div&gt;
                        &lt;div&gt;x₁ enters the basis&lt;/div&gt;
                        &lt;div&gt;Performing minimum ratio test...&lt;/div&gt;
                    `;
                    break;
                case 2:
                    statusHTML = `
                        &lt;div&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; First iteration complete&lt;/div&gt;
                        &lt;div&gt;Current vertex: (3, 0)&lt;/div&gt;
                        &lt;div&gt;Current objective value: 9&lt;/div&gt;
                        &lt;div&gt;Basic variables: x₁ = 3, s₁ = 1&lt;/div&gt;
                    `;
                    currentVertex = [3, 0];
                    break;
                case 3:
                    statusHTML = `
                        &lt;div&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; OPTIMAL SOLUTION FOUND!&lt;/div&gt;
                        &lt;div&gt;Current vertex: (2, 2)&lt;/div&gt;
                        &lt;div&gt;Maximum objective value: 10&lt;/div&gt;
                        &lt;div&gt;Basic variables: x₁ = 2, x₂ = 2&lt;/div&gt;
                    `;
                    currentVertex = [2, 2];
                    isOptimal = true;
                    break;
            }
            
            statusDiv.innerHTML = statusHTML;
            
            // Update visualization
            const currentPos = d3.select(&apos;#current-position&apos;);
            if (currentPos.node()) {
                const xScale = d3.scaleLinear().domain([0, 4]).range([40, 360]);
                const yScale = d3.scaleLinear().domain([0, 6]).range([260, 40]);
                
                currentPos
                    .transition()
                    .duration(500)
                    .attr(&apos;cx&apos;, xScale(currentVertex[0]))
                    .attr(&apos;cy&apos;, yScale(currentVertex[1]));
            }
        }
        
        function nextStep() {
            if (currentStep &lt; 3) {
                currentStep++;
                updateStatus(currentStep);
                updateTableau(currentStep);
                
                if (currentStep === 3) {
                    stepButton.textContent = &apos;Algorithm Complete!&apos;;
                    stepButton.disabled = true;
                    stepButton.style.backgroundColor = &apos;#4CAF50&apos;;
                }
            }
        }
        
        function reset() {
            currentStep = 0;
            currentVertex = [0, 0];
            isOptimal = false;
            
            stepButton.textContent = &apos;Next Step&apos;;
            stepButton.disabled = false;
            stepButton.style.backgroundColor = &apos;#2196F3&apos;;
            
            updateStatus(0);
            updateTableau(0);
            createVisualization();
        }
        
        // Event listeners
        stepButton.addEventListener(&apos;click&apos;, nextStep);
        resetButton.addEventListener(&apos;click&apos;, reset);
        
        // Initialize
        createVisualization();
        updateStatus(0);
        updateTableau(0);
    }
    
    // Initialize all interactive elements
    initializeFarmerProblem();
    initializeDietSolver();
    initializeSimplexVisualization();
    
    // Trigger MathJax re-rendering if needed
    if (window.MathJax) {
        MathJax.typesetPromise();
    }
});
&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>05-01-01 Linear Programming - Simplex Algorithm</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_01_01_LP_Simple_Algorithm/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_01_01_LP_Simple_Algorithm</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>05 Canonical Problems</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_00_Canonical_Problems/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter05/05_00_Canonical_Problems</id>
   <content type="html">&lt;h1 id=&quot;canonical-problems&quot;&gt;Canonical Problems&lt;/h1&gt;

&lt;p&gt;In &lt;a href=&quot;/chapter01/2021/01/07/optimization_problems/&quot;&gt;Chapter 1&lt;/a&gt;, we learned that a convex optimization problem is defined as follows:&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter05/05_00_optimization_problem.png&quot; alt=&quot;[Fig1] Convex Optimization Problem in standard form [3]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Convex Optimization Problem in standard form [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;The domain set is convex&lt;/li&gt;
  &lt;li&gt;The objective function \(f\) and the inequality constraint function \(g_i\) are convex&lt;/li&gt;
  &lt;li&gt;The equality constraint function \(h_j\) is affine&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Depending on the type of objective and constraint functions, optimization problems are classified into several categories. In this chapter, we will learn about six major subclasses:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Linear Programming (LP)&lt;/li&gt;
  &lt;li&gt;Quadratic Programming (QP)&lt;/li&gt;
  &lt;li&gt;Quadratically Constrained Quadratic Programming (QCQP)&lt;/li&gt;
  &lt;li&gt;Second-Order Cone Programming (SOCP)&lt;/li&gt;
  &lt;li&gt;Semidefinite Programming (SDP)&lt;/li&gt;
  &lt;li&gt;Conic Programming (CP)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These problems have the following inclusion relationships and become more general as you move down the list:&lt;/p&gt;

&lt;p&gt;\(LP \subseteq QP \subseteq QCQP \subseteq SOCP \subseteq SDP \subseteq CP\)&lt;/p&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter05/05_00_canonical_problems.jpeg&quot; alt=&quot;[Fig2] Canonical Problems&quot; width=&quot;90%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Canonical Problems&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>02-01-05 Hyperplane</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_01_05_Hyperplane/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_01_05_Hyperplane</id>
   <content type="html">&lt;p&gt;A hyperplane is one of the most fundamental geometric objects in convex optimization and linear algebra. It serves as a building block for understanding more complex convex sets and plays a crucial role in optimization algorithms, machine learning, and geometric analysis.&lt;/p&gt;

&lt;h2 id=&quot;definition-of-hyperplane&quot;&gt;Definition of Hyperplane&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;hyperplane&lt;/strong&gt; in \(\mathbb{R}^n\) is a set of the form:&lt;/p&gt;

&lt;blockquote&gt;
\[\mathcal{H} = \{x \in \mathbb{R}^n : a^T x = b\}\]
&lt;/blockquote&gt;

&lt;p&gt;where \(a \in \mathbb{R}^n\) is a nonzero vector (\(a \neq 0\)) and \(b \in \mathbb{R}\) is a scalar.&lt;/p&gt;

&lt;p&gt;The vector \(a\) is called the &lt;strong&gt;normal vector&lt;/strong&gt; to the hyperplane, and it determines the orientation of the hyperplane. The scalar \(b\) determines the position of the hyperplane relative to the origin.&lt;/p&gt;

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;In \(\mathbb{R}^2\): A hyperplane is a &lt;strong&gt;line&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;In \(\mathbb{R}^3\): A hyperplane is a &lt;strong&gt;plane&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;In \(\mathbb{R}^n\) (\(n &amp;gt; 3\)): A hyperplane is an \((n-1)\)-dimensional subspace&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The hyperplane divides the entire space \(\mathbb{R}^n\) into two &lt;strong&gt;halfspaces&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Positive halfspace&lt;/strong&gt;: \(\{x : a^T x \geq b\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Negative halfspace&lt;/strong&gt;: \(\{x : a^T x \leq b\}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;properties-of-hyperplanes&quot;&gt;Properties of Hyperplanes&lt;/h2&gt;

&lt;h3 id=&quot;1-affine-set-property&quot;&gt;1. Affine Set Property&lt;/h3&gt;
&lt;p&gt;Every hyperplane is an &lt;strong&gt;affine set&lt;/strong&gt;. This means that if \(x_1, x_2 \in \mathcal{H}\), then the entire line passing through them is also contained in \(\mathcal{H}\):&lt;/p&gt;

\[\theta x_1 + (1-\theta) x_2 \in \mathcal{H} \quad \forall \theta \in \mathbb{R}\]

&lt;p&gt;&lt;strong&gt;Proof&lt;/strong&gt;: If \(a^T x_1 = b\) and \(a^T x_2 = b\), then:
\(a^T(\theta x_1 + (1-\theta) x_2) = \theta a^T x_1 + (1-\theta) a^T x_2 = \theta b + (1-\theta) b = b\)&lt;/p&gt;

&lt;h3 id=&quot;2-convex-set-property&quot;&gt;2. Convex Set Property&lt;/h3&gt;
&lt;p&gt;Since every affine set is convex, hyperplanes are &lt;strong&gt;convex sets&lt;/strong&gt;. For any \(x_1, x_2 \in \mathcal{H}\) and \(\lambda \in [0,1]\):&lt;/p&gt;

\[\lambda x_1 + (1-\lambda) x_2 \in \mathcal{H}\]

&lt;h3 id=&quot;3-closed-set-property&quot;&gt;3. Closed Set Property&lt;/h3&gt;
&lt;p&gt;Hyperplanes are &lt;strong&gt;closed sets&lt;/strong&gt; because they are the level sets of continuous linear functions.&lt;/p&gt;

&lt;h3 id=&quot;4-dimension&quot;&gt;4. Dimension&lt;/h3&gt;
&lt;p&gt;A hyperplane in \(\mathbb{R}^n\) has dimension \(n-1\).&lt;/p&gt;

&lt;h2 id=&quot;alternative-representations&quot;&gt;Alternative Representations&lt;/h2&gt;

&lt;h3 id=&quot;1-point-normal-form&quot;&gt;1. Point-Normal Form&lt;/h3&gt;
&lt;p&gt;If we know a point \(x_0\) on the hyperplane and the normal vector \(a\), the hyperplane can be written as:&lt;/p&gt;

\[\mathcal{H} = \{x : a^T (x - x_0) = 0\}\]

&lt;p&gt;This is equivalent to \(a^T x = a^T x_0\), so \(b = a^T x_0\).&lt;/p&gt;

&lt;h3 id=&quot;2-matrix-form&quot;&gt;2. Matrix Form&lt;/h3&gt;
&lt;p&gt;A hyperplane can also be represented using matrix notation. If \(A\) is a \(1 \times n\) matrix (row vector), then:&lt;/p&gt;

\[\mathcal{H} = \{x : Ax = b\}\]

&lt;h3 id=&quot;3-parametric-form&quot;&gt;3. Parametric Form&lt;/h3&gt;
&lt;p&gt;A hyperplane can be parameterized using a basis for its null space. If \(\{v_1, v_2, \ldots, v_{n-1}\}\) is an orthonormal basis for the null space of \(a^T\), and \(x_0\) is any point on the hyperplane, then:&lt;/p&gt;

\[\mathcal{H} = \{x_0 + t_1 v_1 + t_2 v_2 + \cdots + t_{n-1} v_{n-1} : t_i \in \mathbb{R}\}\]

&lt;h2 id=&quot;distance-from-point-to-hyperplane&quot;&gt;Distance from Point to Hyperplane&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;distance&lt;/strong&gt; from a point \(x_0\) to the hyperplane \(\{x : a^T x = b\}\) is given by:&lt;/p&gt;

\[d(x_0, \mathcal{H}) = \frac{\lvert a^T x_0 - b \rvert}{\lVert a \rVert_2}\]

&lt;p&gt;This formula comes from projecting the vector from any point on the hyperplane to \(x_0\) onto the normal direction.&lt;/p&gt;

&lt;h3 id=&quot;derivation&quot;&gt;Derivation&lt;/h3&gt;
&lt;p&gt;Let \(x^*\) be the closest point on the hyperplane to \(x_0\). Then \(x^* - x_0\) is parallel to the normal vector \(a\):&lt;/p&gt;

\[x^* - x_0 = t \frac{a}{\lVert a \rVert_2}\]

&lt;p&gt;Since \(x^* \in \mathcal{H}\), we have \(a^T x^* = b\). Substituting:&lt;/p&gt;

\[a^T \left(x_0 + t \frac{a}{\lVert a \rVert_2}\right) = b\]

&lt;p&gt;Solving for \(t\): \(t = \frac{b - a^T x_0}{\lVert a \rVert_2}\)&lt;/p&gt;

&lt;p&gt;The distance is \(\lvert t \rvert = \frac{\lvert a^T x_0 - b \rvert}{\lVert a \rVert_2}\).&lt;/p&gt;

&lt;h2 id=&quot;examples&quot;&gt;Examples&lt;/h2&gt;

&lt;h3 id=&quot;example-1-line-in-mathbbr2&quot;&gt;Example 1: Line in \(\mathbb{R}^2\)&lt;/h3&gt;
&lt;p&gt;The hyperplane \(2x_1 + 3x_2 = 6\) represents a line in the plane.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Normal vector: \(a = (2, 3)\)&lt;/li&gt;
  &lt;li&gt;The line passes through points \((3, 0)\) and \((0, 2)\)&lt;/li&gt;
  &lt;li&gt;Distance from origin: \(\frac{\lvert 2 \cdot 0 + 3 \cdot 0 - 6 \rvert}{\sqrt{2^2 + 3^2}} = \frac{6}{\sqrt{13}}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-2-plane-in-mathbbr3&quot;&gt;Example 2: Plane in \(\mathbb{R}^3\)&lt;/h3&gt;
&lt;p&gt;The hyperplane \(x_1 - 2x_2 + x_3 = 4\) represents a plane in 3D space.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Normal vector: \(a = (1, -2, 1)\)&lt;/li&gt;
  &lt;li&gt;The plane passes through points \((4, 0, 0)\), \((0, -2, 0)\), and \((0, 0, 4)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-3-hyperplane-through-origin&quot;&gt;Example 3: Hyperplane through Origin&lt;/h3&gt;
&lt;p&gt;The hyperplane \(a^T x = 0\) always passes through the origin and is actually a &lt;strong&gt;subspace&lt;/strong&gt; of dimension \(n-1\).&lt;/p&gt;

&lt;h2 id=&quot;interactive-visualization&quot;&gt;Interactive Visualization&lt;/h2&gt;

&lt;div id=&quot;hyperplane-container&quot; style=&quot;width: 100%; max-width: 800px; margin: 20px auto;&quot;&gt;
    &lt;div id=&quot;controls&quot; style=&quot;margin-bottom: 20px; text-align: center;&quot;&gt;
        &lt;label&gt;Normal vector a₁: &lt;input type=&quot;range&quot; id=&quot;a1-slider&quot; min=&quot;-3&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;&lt;/label&gt;
        &lt;span id=&quot;a1-value&quot;&gt;1.0&lt;/span&gt;&lt;br /&gt;
        &lt;label&gt;Normal vector a₂: &lt;input type=&quot;range&quot; id=&quot;a2-slider&quot; min=&quot;-3&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1&quot; /&gt;&lt;/label&gt;
        &lt;span id=&quot;a2-value&quot;&gt;1.0&lt;/span&gt;&lt;br /&gt;
        &lt;label&gt;Offset b: &lt;input type=&quot;range&quot; id=&quot;b-slider&quot; min=&quot;-5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;0&quot; /&gt;&lt;/label&gt;
        &lt;span id=&quot;b-value&quot;&gt;0.0&lt;/span&gt;&lt;br /&gt;
        &lt;button id=&quot;reset-btn&quot;&gt;Reset&lt;/button&gt;
    &lt;/div&gt;
    &lt;canvas id=&quot;hyperplane-canvas&quot; width=&quot;600&quot; height=&quot;400&quot; style=&quot;border: 1px solid #ccc; display: block; margin: 0 auto;&quot;&gt;&lt;/canvas&gt;
    &lt;div id=&quot;info&quot; style=&quot;text-align: center; margin-top: 10px; font-family: monospace;&quot;&gt;
        &lt;p&gt;Hyperplane equation: &lt;span id=&quot;equation&quot;&gt;x₁ + x₂ = 0&lt;/span&gt;&lt;/p&gt;
        &lt;p&gt;Distance from origin: &lt;span id=&quot;distance&quot;&gt;0.0&lt;/span&gt;&lt;/p&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
class HyperplaneVisualizer {
    constructor() {
        this.canvas = document.getElementById(&apos;hyperplane-canvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        // Parameters
        this.a1 = 1;
        this.a2 = 1;
        this.b = 0;
        
        // Scale and offset for coordinate system
        this.scale = 40;
        this.centerX = this.width / 2;
        this.centerY = this.height / 2;
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const a1Slider = document.getElementById(&apos;a1-slider&apos;);
        const a2Slider = document.getElementById(&apos;a2-slider&apos;);
        const bSlider = document.getElementById(&apos;b-slider&apos;);
        const resetBtn = document.getElementById(&apos;reset-btn&apos;);
        
        a1Slider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.a1 = parseFloat(e.target.value);
            document.getElementById(&apos;a1-value&apos;).textContent = this.a1.toFixed(1);
            this.updateDisplay();
        });
        
        a2Slider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.a2 = parseFloat(e.target.value);
            document.getElementById(&apos;a2-value&apos;).textContent = this.a2.toFixed(1);
            this.updateDisplay();
        });
        
        bSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.b = parseFloat(e.target.value);
            document.getElementById(&apos;b-value&apos;).textContent = this.b.toFixed(1);
            this.updateDisplay();
        });
        
        resetBtn.addEventListener(&apos;click&apos;, () =&gt; {
            this.a1 = 1;
            this.a2 = 1;
            this.b = 0;
            a1Slider.value = 1;
            a2Slider.value = 1;
            bSlider.value = 0;
            document.getElementById(&apos;a1-value&apos;).textContent = &apos;1.0&apos;;
            document.getElementById(&apos;a2-value&apos;).textContent = &apos;1.0&apos;;
            document.getElementById(&apos;b-value&apos;).textContent = &apos;0.0&apos;;
            this.updateDisplay();
        });
    }
    
    updateDisplay() {
        this.draw();
        this.updateInfo();
    }
    
    updateInfo() {
        // Update equation
        const eq = `${this.a1.toFixed(1)}x₁ + ${this.a2.toFixed(1)}x₂ = ${this.b.toFixed(1)}`;
        document.getElementById(&apos;equation&apos;).textContent = eq;
        
        // Update distance from origin
        const distance = Math.abs(this.b) / Math.sqrt(this.a1 * this.a1 + this.a2 * this.a2);
        document.getElementById(&apos;distance&apos;).textContent = distance.toFixed(3);
    }
    
    worldToScreen(x, y) {
        return {
            x: this.centerX + x * this.scale,
            y: this.centerY - y * this.scale
        };
    }
    
    draw() {
        // Clear canvas
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        // Draw coordinate system
        this.drawCoordinateSystem();
        
        // Draw hyperplane (line in 2D)
        this.drawHyperplane();
        
        // Draw normal vector
        this.drawNormalVector();
        
        // Draw distance from origin
        this.drawDistanceFromOrigin();
    }
    
    drawCoordinateSystem() {
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        
        // Grid lines
        for (let i = -10; i &lt;= 10; i++) {
            if (i === 0) continue;
            
            // Vertical lines
            const x = this.centerX + i * this.scale;
            this.ctx.beginPath();
            this.ctx.moveTo(x, 0);
            this.ctx.lineTo(x, this.height);
            this.ctx.stroke();
            
            // Horizontal lines
            const y = this.centerY + i * this.scale;
            this.ctx.beginPath();
            this.ctx.moveTo(0, y);
            this.ctx.lineTo(this.width, y);
            this.ctx.stroke();
        }
        
        // Axes
        this.ctx.strokeStyle = &apos;#666&apos;;
        this.ctx.lineWidth = 2;
        
        // X-axis
        this.ctx.beginPath();
        this.ctx.moveTo(0, this.centerY);
        this.ctx.lineTo(this.width, this.centerY);
        this.ctx.stroke();
        
        // Y-axis
        this.ctx.beginPath();
        this.ctx.moveTo(this.centerX, 0);
        this.ctx.lineTo(this.centerX, this.height);
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#666&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.fillText(&apos;x₁&apos;, this.width - 20, this.centerY - 10);
        this.ctx.fillText(&apos;x₂&apos;, this.centerX + 10, 15);
    }
    
    drawHyperplane() {
        if (Math.abs(this.a1) &lt; 1e-10 &amp;&amp; Math.abs(this.a2) &lt; 1e-10) return;
        
        this.ctx.strokeStyle = &apos;#2196F3&apos;;
        this.ctx.lineWidth = 3;
        
        // Find two points on the line a1*x1 + a2*x2 = b
        let x1_start, y1_start, x1_end, y1_end;
        
        if (Math.abs(this.a2) &gt; 1e-10) {
            // Line is not vertical
            x1_start = -10;
            y1_start = (this.b - this.a1 * x1_start) / this.a2;
            x1_end = 10;
            y1_end = (this.b - this.a1 * x1_end) / this.a2;
        } else {
            // Line is vertical
            x1_start = x1_end = this.b / this.a1;
            y1_start = -10;
            y1_end = 10;
        }
        
        const start = this.worldToScreen(x1_start, y1_start);
        const end = this.worldToScreen(x1_end, y1_end);
        
        this.ctx.beginPath();
        this.ctx.moveTo(start.x, start.y);
        this.ctx.lineTo(end.x, end.y);
        this.ctx.stroke();
        
        // Label
        const midX = (start.x + end.x) / 2;
        const midY = (start.y + end.y) / 2;
        this.ctx.fillStyle = &apos;#2196F3&apos;;
        this.ctx.font = &apos;bold 14px Arial&apos;;
        this.ctx.fillText(&apos;Hyperplane&apos;, midX + 10, midY - 10);
    }
    
    drawNormalVector() {
        if (Math.abs(this.a1) &lt; 1e-10 &amp;&amp; Math.abs(this.a2) &lt; 1e-10) return;
        
        // Normalize the normal vector for display
        const norm = Math.sqrt(this.a1 * this.a1 + this.a2 * this.a2);
        const na1 = this.a1 / norm;
        const na2 = this.a2 / norm;
        
        // Find a point on the hyperplane closest to origin
        const t = this.b / (this.a1 * this.a1 + this.a2 * this.a2);
        const px = t * this.a1;
        const py = t * this.a2;
        
        const startPoint = this.worldToScreen(px, py);
        const endPoint = this.worldToScreen(px + na1 * 2, py + na2 * 2);
        
        // Draw normal vector
        this.ctx.strokeStyle = &apos;#FF5722&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.moveTo(startPoint.x, startPoint.y);
        this.ctx.lineTo(endPoint.x, endPoint.y);
        this.ctx.stroke();
        
        // Draw arrowhead
        const angle = Math.atan2(endPoint.y - startPoint.y, endPoint.x - startPoint.x);
        const arrowLength = 10;
        this.ctx.beginPath();
        this.ctx.moveTo(endPoint.x, endPoint.y);
        this.ctx.lineTo(
            endPoint.x - arrowLength * Math.cos(angle - Math.PI / 6),
            endPoint.y - arrowLength * Math.sin(angle - Math.PI / 6)
        );
        this.ctx.moveTo(endPoint.x, endPoint.y);
        this.ctx.lineTo(
            endPoint.x - arrowLength * Math.cos(angle + Math.PI / 6),
            endPoint.y - arrowLength * Math.sin(angle + Math.PI / 6)
        );
        this.ctx.stroke();
        
        // Label
        this.ctx.fillStyle = &apos;#FF5722&apos;;
        this.ctx.font = &apos;bold 12px Arial&apos;;
        this.ctx.fillText(&apos;Normal vector a&apos;, endPoint.x + 5, endPoint.y - 5);
    }
    
    drawDistanceFromOrigin() {
        if (Math.abs(this.a1) &lt; 1e-10 &amp;&amp; Math.abs(this.a2) &lt; 1e-10) return;
        
        // Find closest point on hyperplane to origin
        const t = this.b / (this.a1 * this.a1 + this.a2 * this.a2);
        const px = t * this.a1;
        const py = t * this.a2;
        
        const origin = this.worldToScreen(0, 0);
        const closestPoint = this.worldToScreen(px, py);
        
        // Draw distance line
        this.ctx.strokeStyle = &apos;#4CAF50&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.setLineDash([5, 5]);
        this.ctx.beginPath();
        this.ctx.moveTo(origin.x, origin.y);
        this.ctx.lineTo(closestPoint.x, closestPoint.y);
        this.ctx.stroke();
        this.ctx.setLineDash([]);
        
        // Draw origin point
        this.ctx.fillStyle = &apos;#4CAF50&apos;;
        this.ctx.beginPath();
        this.ctx.arc(origin.x, origin.y, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Draw closest point
        this.ctx.beginPath();
        this.ctx.arc(closestPoint.x, closestPoint.y, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Label
        const midX = (origin.x + closestPoint.x) / 2;
        const midY = (origin.y + closestPoint.y) / 2;
        this.ctx.fillStyle = &apos;#4CAF50&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.fillText(&apos;Distance&apos;, midX + 5, midY + 5);
    }
}

// Initialize visualization when page loads
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new HyperplaneVisualizer();
});
&lt;/script&gt;

&lt;h2 id=&quot;relationship-to-other-concepts&quot;&gt;Relationship to Other Concepts&lt;/h2&gt;

&lt;h3 id=&quot;connection-to-affine-sets&quot;&gt;Connection to Affine Sets&lt;/h3&gt;
&lt;p&gt;Every hyperplane is an affine set, but not every affine set is a hyperplane. Hyperplanes are specifically \((n-1)\)-dimensional affine sets in \(\mathbb{R}^n\).&lt;/p&gt;

&lt;h3 id=&quot;connection-to-linear-algebra&quot;&gt;Connection to Linear Algebra&lt;/h3&gt;
&lt;p&gt;The hyperplane \(\{x : a^T x = b\}\) is the &lt;strong&gt;level set&lt;/strong&gt; of the linear function \(f(x) = a^T x\) at level \(b\). The gradient of this function is constant and equal to \(a\), which explains why \(a\) is perpendicular to the hyperplane.&lt;/p&gt;

&lt;h3 id=&quot;connection-to-optimization&quot;&gt;Connection to Optimization&lt;/h3&gt;
&lt;p&gt;In constrained optimization, equality constraints often define hyperplanes that restrict the feasible region. The method of Lagrange multipliers exploits the fact that at an optimal point, the gradient of the objective function is parallel to the normal vector of the constraint hyperplane.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-01-04 Cone</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_01_04_Convex_cone/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_01_04_Convex_cone</id>
   <content type="html">&lt;p&gt;A cone is a set that extends infinitely in certain directions, like a beam of light from a source, but is not defined in the opposite direction. To determine if a set is a cone, check if the ray starting from the origin and passing through any point in the set is also contained within the set. (Thus, a cone must include the origin.) Because a cone has boundaries, it cannot be an affine set. Let’s define this mathematically.&lt;/p&gt;

&lt;h2 id=&quot;cone&quot;&gt;Cone&lt;/h2&gt;

&lt;p&gt;A set \(C\) is a &lt;strong&gt;cone&lt;/strong&gt; (or &lt;strong&gt;nonnegative homogeneous set&lt;/strong&gt;) if for any point \(x \in C\), the ray \(\theta x\) is also in \(C\) for \(\theta \ge 0\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\theta x \in C\) with \(x \in C\), \(\theta \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;[Reference] Unlike affine or convex sets, when defining a cone, the starting point of the ray is assumed to be the origin, so only one point is used.&lt;/p&gt;

&lt;h2 id=&quot;convex-cone&quot;&gt;Convex Cone&lt;/h2&gt;

&lt;p&gt;A set \(C\) is a &lt;strong&gt;convex cone&lt;/strong&gt; if it is both a cone and convex:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\theta_1 x_1 + \theta_2 x_2 \in C\) with \(x_1, x_2 \in C\), \(\theta_1, \theta_2 \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The figure below shows a pie-shaped convex cone. In the figure, \(x_1\) and \(x_2\) are points in the cone, and \(\theta_1\) and \(\theta_2\) are non-negative scalars.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.04_Convex_Cone.png&quot; alt=&quot;[Fig1] Convex Cone [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Convex Cone [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;conic-combination&quot;&gt;Conic combination&lt;/h2&gt;

&lt;p&gt;A linear combination of several points where all coefficients are non-negative is called a &lt;strong&gt;conic combination&lt;/strong&gt; (or &lt;strong&gt;nonnegative linear combination&lt;/strong&gt;):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;A point of the form \(\theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_k x_k\) with \(\theta_i \ge 0, i = 1,  ..., k\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If every conic combination of points in a set \(C\) is also in \(C\), then \(C\) is a conic set.&lt;/p&gt;

&lt;h2 id=&quot;conic-hull&quot;&gt;Conic hull&lt;/h2&gt;

&lt;p&gt;The set of all conic combinations of points in \(C \subseteq \mathbb{R}^n\) is called the &lt;strong&gt;conic hull&lt;/strong&gt; of \(C\). The conic hull is always the smallest convex cone containing \(C\):&lt;/p&gt;
&lt;blockquote&gt;
\[\{ \theta_1 x_1 + \cdots + \theta_k x_k \mid x_i \in C, \theta_i \ge 0, i = 1, ..., k \}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>02-01-03 Convex set</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_01_03_Convex-set/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_01_03_Convex-set</id>
   <content type="html">&lt;p&gt;Now let’s look at the core concept of this chapter: the convex set. Intuitively, a convex set is a set with no “dents” or “holes” inside. To determine if a set is convex, check if the line segment connecting any two points in the set is also contained within the set.&lt;/p&gt;

&lt;h2 id=&quot;convex-set&quot;&gt;Convex set&lt;/h2&gt;

&lt;p&gt;A set \(C \subseteq \mathbb{R}^n\) is a &lt;strong&gt;convex set&lt;/strong&gt; if for any two points \(x_1, x_2 \in C\), the line segment connecting them is also in \(C\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\theta x_1 + (1-\theta)x_2 \in C\) with \(x_1, x_2 \in C\), \(0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This means that for any two points in \(C\), all points on the line segment between them are also in \(C\).&lt;/p&gt;

&lt;p&gt;The figure below shows examples of convex sets. The triangle on the left is convex, but the shape with a cavity on the right is not convex because the line segment between some points leaves the set.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.02_Convex_Set.png&quot; alt=&quot;[Fig1] Convex Set [1]&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Convex Set [1]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;convex-combination&quot;&gt;Convex combination&lt;/h2&gt;

&lt;p&gt;A linear combination of several points where the coefficients are non-negative and sum to 1 is called a &lt;strong&gt;convex combination&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;A point of the form \(\theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_k x_k\) with \(\theta_1 + \theta_2 + \cdots + \theta_k = 1, \theta_i \ge  0, i = 1,  ..., k\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If every convex combination of points in a set \(C\) is also in \(C\), then \(C\) is a convex set.&lt;/p&gt;

&lt;h2 id=&quot;convex-hull&quot;&gt;Convex hull&lt;/h2&gt;

&lt;p&gt;The set of all convex combinations of points in \(C \subseteq \mathbb{R}^n\) is called the &lt;strong&gt;convex hull&lt;/strong&gt; of \(C\), denoted as &lt;strong&gt;conv&lt;/strong&gt; \(C\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;conv&lt;/strong&gt; \(C = \{ \theta_1 x_1 + \cdots + \theta_k x_k \mid x_i \in C, \theta_i \ge 0, i = 1, ..., k, \theta_1 + \cdots + \theta_k = 1 \}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The figure below shows the convex hull for a set of 15 points and a shape with a cavity.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.03_Convex_Hull.png&quot; alt=&quot; Convex Hull&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;Convex Hull&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.03_Convex_Hull_2.png&quot; alt=&quot; Convex Hull&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;Convex Hull&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>02-01-02 Affine set</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_01_02_Affine_set/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_01_02_Affine_set</id>
   <content type="html">&lt;p&gt;An affine set is a collection with no boundaries, such as a point, line, plane, or hyperplane. To determine if a set is affine, check if the line passing through any two points in the set is also contained within the set. The absence of boundaries means that if any space has a boundary, it cannot be an affine set. Let’s define this mathematically.&lt;/p&gt;

&lt;h2 id=&quot;affine-set&quot;&gt;Affine set&lt;/h2&gt;

&lt;p&gt;A set \(C \subseteq \mathbb{R}^n\) is an &lt;strong&gt;affine set&lt;/strong&gt; if for any two points \(x_1, x_2 \in C\), the line passing through them is also in \(C\):&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\theta x_1 + (1-\theta)x_2 \in C\) with \(\theta \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This can be interpreted as a linear combination of two points in \(C\), where the sum of the coefficients is 1. If the result is always in \(C\), then \(C\) is an affine set.&lt;/p&gt;

&lt;h2 id=&quot;affine-combination&quot;&gt;Affine combination&lt;/h2&gt;

&lt;p&gt;A linear combination of several points where the sum of the coefficients is 1 is called an &lt;strong&gt;affine combination&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_k x_k \in C\) with \(\theta_1 + \theta_2 + \cdots + \theta_k = 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If every affine combination of points in a set \(C\) is also in \(C\), then \(C\) is an affine set.&lt;/p&gt;

&lt;h2 id=&quot;affine-hull&quot;&gt;Affine hull&lt;/h2&gt;

&lt;p&gt;The set of all affine combinations of points in \(C \subseteq \mathbb{R}^n\) is called the &lt;strong&gt;affine hull&lt;/strong&gt; of \(C\), denoted as &lt;strong&gt;aff&lt;/strong&gt; \(C\):&lt;/p&gt;
&lt;blockquote&gt;
\[\text{aff} (C) = \{ \theta_1 x_1 + \cdots + \theta_k x_k \mid x_1, ..., x_k \in C, \theta_1 + \cdots + \theta_k = 1 \}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;relationship-between-affine-set-and-subspace&quot;&gt;Relationship between affine set and subspace&lt;/h2&gt;

&lt;p&gt;If \(C\) is an affine set and \(x_0 \in C\), then \(V = C - x_0\) is a subspace:&lt;/p&gt;
&lt;blockquote&gt;
\[V = C - x_0 =  \{ x - x_0 \mid x \in C \}\]
&lt;/blockquote&gt;

&lt;p&gt;Thus, “An affine set \(C\) is a translation of a linear subspace \(V\) by \(x_0\),” where \(x_0\) can be any point in \(C\). The dimension of \(C\) is the same as that of \(V\).&lt;/p&gt;

&lt;h3 id=&quot;reference-proof-that-v-is-a-subspace&quot;&gt;[Reference] Proof that \(V\) is a subspace&lt;/h3&gt;

&lt;p&gt;To prove \(V\) is a subspace, show that it is closed under addition and scalar multiplication. That is, for \(v_1, v_2 \in V\) and \(\alpha, \beta \in \mathbb{R}\), \(\alpha v_1 + \beta v_2 \in V\). This follows from the definition above.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-01-01 Line, line segment, ray</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_01_01_Line_line_segment_ray/"/>
   <updated>2021-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_01_01_Line_line_segment_ray</id>
   <content type="html">&lt;p&gt;To define affine sets, convex sets, and cones, let’s first look at lines, line segments, and rays.&lt;/p&gt;

&lt;p&gt;A line is an infinitely extending straight path passing through two points in both directions. In contrast, a line segment is a straight path defined only between two points, and a ray starts at one point and extends infinitely in one direction through another point. The figure below shows a line and a line segment. Depending on the range of the parameter \(\theta\), you can imagine how a line, line segment, or ray is defined.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter02/02.01_Line_Segment.png&quot; alt=&quot;Line Segment&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;$$\text{[Fig1] } x_1\text{ and } x_2 \text{ defining a Line and Line Segment [1]}$$&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;[Reference] When you use two points included in a set to create a line, line segment, or ray, whether these are included in the set determines the definition of the set. (You can also define sets using multiple points and their affine, convex, or conic combinations. Details will be explained in the following sections.)&lt;/p&gt;

&lt;h2 id=&quot;line&quot;&gt;Line&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;Line&lt;/strong&gt; passing through two points \(x_1\) and \(x_2\) is defined as:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(y = \theta x_1 + (1 - \theta) x_2\) with \(\theta \in \mathbb{R}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;line-segment&quot;&gt;Line segment&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;Line segment&lt;/strong&gt; is defined by restricting \(\theta\) to the interval [0, 1]:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(y = \theta x_1 + (1 - \theta) x_2\) with \(0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Alternatively, you can express it as:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(y = x_2 + \theta (x_1 - x_2)\) with \(0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;ray&quot;&gt;Ray&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;Ray&lt;/strong&gt; starts at one point and extends infinitely in one direction:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(y = x_2 + \theta (x_1 - x_2)\) with \(\theta \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Or equivalently:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(y = \theta x_1 + (1 - \theta) x_2\) with \(\theta \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now you can see that the range of \(\theta\) is \(\theta \in \mathbb{R}\) for lines, \(0 \le \theta \le 1\) for line segments, and \(\theta \ge 0\) for rays. Furthermore, you will find that the ranges of \(\theta\) are the same in the affine sets, convex sets, and conic sets that we will define later.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>makers</title>
   <link href="http://localhost:4000/home/makers/"/>
   <updated>2021-02-03T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/home/makers</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Conventions</title>
   <link href="http://localhost:4000/contribution/conventions/"/>
   <updated>2021-02-03T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contribution/conventions</id>
   <content type="html">&lt;h2 id=&quot;1-directory-convention&quot;&gt;1. Directory Convention&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;주요 컨텐츠는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;contents/chapter&lt;/code&gt;로 시작하는 디렉토리에 포함되어 있습니다. 또한 컨텐츠에 필요한 이미지는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;image&lt;/code&gt; 디렉토리에 들어 있습니다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;contents/chapter&lt;/code&gt;의 내부 디렉토리는 다음과 같습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;contents
├── chapter01
│   ├── _posts
│   │   ├── 21-01-07-01_00_Introduction.md
│   │   ├── 21-01-07-01_01_optimization_problems.md
│   │   ├── 21-01-28-01_02_convex_optimization_problem.md
│   │   ├── 21-01-28-01_03_goals_and_topics.md
│   │   └── 21-01-28-01_04_brief_history_of_convex_optimization.md
│   ├── index.html
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Jekyll에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_posts&lt;/code&gt; 디렉토리 내에 있는 Markdown 또는 html 파일을 블로그의 Posting으로 인식합니다. 따라서 새로운 포스팅을 작성하고자 한다면 각 디렉토리의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_posts&lt;/code&gt;에 새로 파일을 추가하시면 됩니다.&lt;/li&gt;
  &lt;li&gt;Jekyll의 Posting 파일들은 모두 아래와 같은 Naming Convention을 따라야 합니다.
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yy-mm-dd-new_posting_name.md&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;chapter&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;image&lt;/code&gt; 디렉토리 외의 내용들은 모두 Blog의 설정과 관련된 것들입니다. 안정적인 운영을 위해 설정과 관련된 부분들에 대해서는 직접 편집보다는 이슈로 작성해주시면 처리하겠습니다(관련 내용 수정 시 PR Merge가 어려울 수 있습니다).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-posting-convention&quot;&gt;2. Posting Convention&lt;/h2&gt;

&lt;h3 id=&quot;21-header-field&quot;&gt;2.1. Header Field&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;모든 Posting 파일들은 다음 예시와 같은 Header를 가지고 있어야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---
layout: post
title: Quasi-Newton Methods
chapter: &quot;18&quot;
order: 1
owner: &quot;Kyeongmin Woo&quot;
---
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;layout&lt;/strong&gt;은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;post&lt;/code&gt;여야 합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;title&lt;/strong&gt;은 내용에 맞게 임의의 String으로 설정할 수 있습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;chapter&lt;/strong&gt;는 상위 카테고리의 마지막 두 숫자를 String으로 표기합니다. 다만 한 자리수인 경우 “01”과 같이 0을 붙여줘야 합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;order&lt;/strong&gt;는 해당 chapter 내에서의 정렬 순서를 의미합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;owner&lt;/strong&gt;는 해당 post의 관리자를 의미합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;22-latex&quot;&gt;2.2. Latex&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;수식은 Latex 문법에 따라 표기합니다.&lt;/li&gt;
  &lt;li&gt;$$ 와 같이 double dollar sign을 사용하여 수식임을 나타냅니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$$\theta x_1 + (1-\theta)x_2 \in C$$
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 수식은 다음과 같이 표기됩니다.&lt;/p&gt;

\[\theta x_1 + (1-\theta)x_2 \in C\]

&lt;h3 id=&quot;23-image-convention&quot;&gt;2.3. Image Convention&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Posting 파일에서 이미지를 삽일할 때 아래의 Convention을 따라야합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&amp;gt;
&amp;lt;p align=&quot;center&quot;&amp;gt;
  &amp;lt;img src=&quot;{image_path}&quot; alt=&quot;{description of image}&quot; width=&quot;{scale_ratio}%&quot; height=&quot;{scale_ratio}%&quot;&amp;gt;
  &amp;lt;figcaption style=&quot;text-align: center;&quot;&amp;gt;{figcaption}&amp;lt;/figcaption&amp;gt;
&amp;lt;/p&amp;gt;
&amp;lt;/figure&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;figure class는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;image&lt;/code&gt;여야합니다.&lt;/li&gt;
  &lt;li&gt;{}에 들어갈 내용을 적절히 넣어야합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;24-hyperlink-convention&quot;&gt;2.4 Hyperlink Convention&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Blog 내의 Post에 대한 hyperlink는 jekyll multilang_post_url 사용합니다. 첫 번째 Post인 &lt;a href=&quot;/contents/en/chapter01/01_01_optimization_problems/&quot;&gt;Optimization problems?&lt;/a&gt;의 hyperlink는 아래와 같이 작성합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Optimization problems?](/contents/en/chapter01/01_01_optimization_problems/)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;기타 외부 Url로의 hyperlink는 다음과 같이 작성할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Convex Optimization 위키](&amp;lt;https://bit.ly/2PXv736&amp;gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-github-convnention&quot;&gt;3. GitHub Convnention&lt;/h2&gt;

&lt;p&gt;작성 내용에 질문이 있거나 수정 사항을 발견하신 경우 다음 두 방법 중 하나로 남겨주시면 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;댓글 작성하기&lt;/li&gt;
  &lt;li&gt;Repogitory에 이슈 생성하기&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;새로운 내용을 추가하거나 직접 편집하시고 싶으신 경우에는 새로운 Branch를 생성하여 먼저 수정하신 후 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pull Request&lt;/code&gt;를 생성해주시면 됩니다. 신규 작성 및 기존 내용 수정은 누구나 가능합니다.&lt;/p&gt;

&lt;h3 id=&quot;31-repository-policy&quot;&gt;3.1. Repository Policy&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main&lt;/code&gt; 브랜치로 Merge 되기 위해서는 1명 이상의 Reviewer가 Approve 해야 합니다. CODEOWNERS 시스템이 도입되어 있어 각 Chapter 별 Reviewer가 자동으로 할당됩니다.&lt;/p&gt;

&lt;h3 id=&quot;32-branch-naming-convention&quot;&gt;3.2. Branch Naming Convention&lt;/h3&gt;

&lt;p&gt;브랜치 이름은 다음 컨벤션에 맞춰 생성해주시면 됩니다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[feature|bugfix]/[chapter**|settings]-변경-사항
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Prefix는 feature와 bugfix 두 가지를 사용합니다. 각각의 사용 예시는 다음과 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;feature
    &lt;ul&gt;
      &lt;li&gt;Migration 작업&lt;/li&gt;
      &lt;li&gt;문장/수식/이미지 등이 달라지는 경우&lt;/li&gt;
      &lt;li&gt;새로운 내용이 추가되는 경우&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;bugfix
    &lt;ul&gt;
      &lt;li&gt;오타를 수정하는 경우&lt;/li&gt;
      &lt;li&gt;latex view가 깨져 수정하는 경우&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;구체적인 예시는 아래와 같습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature/chapter01-migration&lt;/code&gt;: chapter01 Migration&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature/chapter01-fix-formula&lt;/code&gt;: chapter01에서 수식 업데이트&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;feature/settings-update-branch-convention&lt;/code&gt;: Convention 업데이트&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bugfix/chapter01-fix-typo&lt;/code&gt;: chapter01에서 오타 수정&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>01-04 Lịch sử ngắn gọn về tối ưu hóa lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter01/01_04_brief_history_of_convex_optimization/"/>
   <updated>2021-01-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter01/01_04_brief_history_of_convex_optimization</id>
   <content type="html">&lt;h1 id=&quot;lịch-sử-phát-triển-của-tối-ưu-hóa-lồi&quot;&gt;Lịch sử phát triển của Tối ưu hóa Lồi&lt;/h1&gt;

&lt;p&gt;Tối ưu hóa lồi có một lịch sử phát triển phong phú, từ những nền tảng lý thuyết đầu tiên đến các ứng dụng hiện đại trong công nghệ và khoa học. Hãy cùng khám phá hành trình này qua các giai đoạn quan trọng.&lt;/p&gt;

&lt;h2 id=&quot;-tổng-quan-timeline&quot;&gt;🎯 Tổng quan Timeline&lt;/h2&gt;

&lt;div class=&quot;timeline-container&quot;&gt;
  &lt;div class=&quot;timeline-item&quot;&gt;
    &lt;div class=&quot;timeline-year&quot;&gt;1900-1970&lt;/div&gt;
    &lt;div class=&quot;timeline-content&quot;&gt;Phát triển nền tảng lý thuyết&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&quot;timeline-item&quot;&gt;
    &lt;div class=&quot;timeline-year&quot;&gt;1947-1990&lt;/div&gt;
    &lt;div class=&quot;timeline-content&quot;&gt;Các thuật toán đột phá&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&quot;timeline-item&quot;&gt;
    &lt;div class=&quot;timeline-year&quot;&gt;1990-nay&lt;/div&gt;
    &lt;div class=&quot;timeline-content&quot;&gt;Bùng nổ ứng dụng&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;-giai-đoạn-1-nền-tảng-lý-thuyết-1900-1970&quot;&gt;📚 Giai đoạn 1: Nền tảng Lý thuyết (1900-1970)&lt;/h2&gt;

&lt;h3 id=&quot;những-người-tiên-phong&quot;&gt;Những người tiên phong&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Hermann Minkowski (1864-1909)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Đặt nền móng cho hình học lồi với khái niệm “tập lồi”&lt;/li&gt;
  &lt;li&gt;Phát triển lý thuyết về các đa diện lồi&lt;/li&gt;
  &lt;li&gt;Ảnh hưởng: Tạo ra ngôn ngữ toán học cơ bản cho tối ưu hóa lồi&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Leonid Kantorovich (1912-1986)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Phát triển lý thuyết lập trình tuyến tính vào những năm 1930&lt;/li&gt;
  &lt;li&gt;Giải quyết bài toán phân bổ tài nguyên tối ưu&lt;/li&gt;
  &lt;li&gt;Đóng góp: Chứng minh tính khả thi của việc tối ưu hóa trong kinh tế&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;John von Neumann (1903-1957)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Phát triển lý thuyết trò chơi và mối liên hệ với tối ưu hóa&lt;/li&gt;
  &lt;li&gt;Đưa ra định lý minimax cơ bản&lt;/li&gt;
  &lt;li&gt;Ảnh hưởng: Kết nối tối ưu hóa với lý thuyết quyết định&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;các-khái-niệm-nền-tảng-được-hình-thành&quot;&gt;Các khái niệm nền tảng được hình thành:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tập lồi và hàm lồi&lt;/strong&gt;: Định nghĩa chính xác và tính chất cơ bản&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Điều kiện tối ưu&lt;/strong&gt;: Phát triển các điều kiện cần và đủ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Duality theory&lt;/strong&gt;: Khái niệm về bài toán đối ngẫu&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;️-giai-đoạn-2-cách-mạng-thuật-toán-1947-1990&quot;&gt;⚙️ Giai đoạn 2: Cách mạng Thuật toán (1947-1990)&lt;/h2&gt;

&lt;h3 id=&quot;1947-thuật-toán-simplex---bước-ngoặt-lịch-sử&quot;&gt;1947: Thuật toán Simplex - Bước ngoặt lịch sử&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;George Dantzig&lt;/strong&gt; đã tạo ra cuộc cách mạng với thuật toán Simplex:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ý tưởng cốt lõi: Di chuyển dọc theo các cạnh của đa diện khả thi
để tìm điểm tối ưu tại một đỉnh.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Tại sao quan trọng?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lần đầu tiên có thuật toán thực tế để giải bài toán lập trình tuyến tính&lt;/li&gt;
  &lt;li&gt;Mở ra khả năng ứng dụng trong logistics, sản xuất, quân sự&lt;/li&gt;
  &lt;li&gt;Hiệu quả cao trong thực tế dù có độ phức tạp tệ nhất là exponential&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1960s-phương-pháp-điểm-trong-đầu-tiên&quot;&gt;1960s: Phương pháp Điểm trong đầu tiên&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Fiacco &amp;amp; McCormick&lt;/strong&gt; phát triển:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Barrier methods cho bài toán có ràng buộc bất đẳng thức&lt;/li&gt;
  &lt;li&gt;Ý tưởng: Thêm hàm penalty để “đẩy” nghiệm vào bên trong miền khả thi&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Dikin&lt;/strong&gt; đóng góp:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Affine scaling method&lt;/li&gt;
  &lt;li&gt;Cải thiện hướng tiếp cận của barrier methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1970s-phương-pháp-ellipsoid-và-subgradient&quot;&gt;1970s: Phương pháp Ellipsoid và Subgradient&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Shor, Nemirovski, Yudin&lt;/strong&gt; phát triển:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ellipsoid method&lt;/strong&gt;: Thuật toán đa thức đầu tiên cho LP&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Subgradient methods&lt;/strong&gt;: Xử lý hàm không khả vi&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ý nghĩa lý thuyết:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Chứng minh LP thuộc lớp P (polynomial time)&lt;/li&gt;
  &lt;li&gt;Mở rộng khả năng giải các bài toán không trơn&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1984-đột-phá-của-karmarkar&quot;&gt;1984: Đột phá của Karmarkar&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Narendra Karmarkar&lt;/strong&gt; tạo ra cuộc cách mạng thứ hai:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Thuật toán interior-point với độ phức tạp \(O(n^{3.5}L)\)&lt;/li&gt;
  &lt;li&gt;Hiệu quả thực tế cao hơn simplex cho bài toán lớn&lt;/li&gt;
  &lt;li&gt;Khởi đầu cho kỷ nguyên interior-point methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;late-1980s-1990s-tổng-quát-hóa&quot;&gt;Late 1980s-1990s: Tổng quát hóa&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Nesterov &amp;amp; Nemirovski (1994)&lt;/strong&gt; mở rộng:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Interior-point methods cho tối ưu lồi phi tuyến&lt;/li&gt;
  &lt;li&gt;Self-concordant functions&lt;/li&gt;
  &lt;li&gt;Polynomial-time algorithms cho broader class&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-giai-đoạn-3-bùng-nổ-ứng-dụng-1990-nay&quot;&gt;🚀 Giai đoạn 3: Bùng nổ Ứng dụng (1990-nay)&lt;/h2&gt;

&lt;h3 id=&quot;trước-1990-giới-hạn-trong-operations-research&quot;&gt;Trước 1990: Giới hạn trong Operations Research&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Các ứng dụng chính:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Transportation problems&lt;/strong&gt;: Tối ưu hóa vận chuyển hàng hóa&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Production planning&lt;/strong&gt;: Lập kế hoạch sản xuất&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Resource allocation&lt;/strong&gt;: Phân bổ tài nguyên trong doanh nghiệp&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Military logistics&lt;/strong&gt;: Ứng dụng trong quân sự (WWII và Cold War)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Tại sao giới hạn?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Máy tính chưa đủ mạnh&lt;/li&gt;
  &lt;li&gt;Thiếu software tools&lt;/li&gt;
  &lt;li&gt;Chưa nhận thức được tiềm năng trong engineering&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;từ-1990-cách-mạng-ứng-dụng&quot;&gt;Từ 1990: Cách mạng Ứng dụng&lt;/h3&gt;

&lt;h4 id=&quot;️-control-systems-hệ-thống-điều-khiển&quot;&gt;🎛️ Control Systems (Hệ thống Điều khiển)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Model Predictive Control (MPC)&lt;/strong&gt;: Điều khiển dự báo&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Robust control&lt;/strong&gt;: Điều khiển bền vững&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ví dụ&lt;/strong&gt;: Điều khiển nhiệt độ trong nhà máy, autopilot máy bay&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;-signal-processing-xử-lý-tín-hiệu&quot;&gt;📡 Signal Processing (Xử lý Tín hiệu)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Compressed sensing&lt;/strong&gt;: Khôi phục tín hiệu từ ít mẫu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Image denoising&lt;/strong&gt;: Khử nhiễu ảnh&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ví dụ&lt;/strong&gt;: MRI imaging, radar processing&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;-communications-truyền-thông&quot;&gt;📱 Communications (Truyền thông)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Beamforming&lt;/strong&gt;: Định hướng sóng trong antenna arrays&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Power allocation&lt;/strong&gt;: Phân bổ công suất trong mạng wireless&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ví dụ&lt;/strong&gt;: 5G networks, satellite communications&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;-circuit-design-thiết-kế-mạch&quot;&gt;💻 Circuit Design (Thiết kế Mạch)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Gate sizing&lt;/strong&gt;: Tối ưu kích thước transistor&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Power optimization&lt;/strong&gt;: Tối ưu tiêu thụ năng lượng&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ví dụ&lt;/strong&gt;: CPU design, mobile chip optimization&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-các-lớp-bài-toán-mới&quot;&gt;🆕 Các lớp bài toán mới&lt;/h3&gt;

&lt;h4 id=&quot;semidefinite-programming-sdp&quot;&gt;Semidefinite Programming (SDP)&lt;/h4&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Tối ưu hóa trên ma trận bán xác định dương
Ứng dụng: Relaxation của bài toán combinatorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;second-order-cone-programming-socp&quot;&gt;Second-Order Cone Programming (SOCP)&lt;/h4&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Tối ưu hóa với ràng buộc hình nón bậc hai
Ứng dụng: Robust optimization, portfolio optimization
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;robust-optimization&quot;&gt;Robust Optimization&lt;/h4&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Tối ưu hóa với uncertainty trong dữ liệu
Ứng dụng: Finance, supply chain management
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;-xu-hướng-hiện-tại-và-tương-lai&quot;&gt;🔮 Xu hướng Hiện tại và Tương lai&lt;/h2&gt;

&lt;h3 id=&quot;machine-learning-integration&quot;&gt;Machine Learning Integration&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Convex relaxations&lt;/strong&gt; của neural networks&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Optimization trong training&lt;/strong&gt;: Adam, RMSprop&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: L1, L2 penalties&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;big-data-applications&quot;&gt;Big Data Applications&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Distributed optimization&lt;/strong&gt;: Xử lý dữ liệu lớn&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Online algorithms&lt;/strong&gt;: Học trực tuyến&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Streaming optimization&lt;/strong&gt;: Tối ưu real-time&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;quantum-computing&quot;&gt;Quantum Computing&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Quantum convex optimization&lt;/strong&gt;: Thuật toán lượng tử&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Variational quantum algorithms&lt;/strong&gt;: QAOA, VQE&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-bài-học-từ-lịch-sử&quot;&gt;💡 Bài học từ Lịch sử&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Lý thuyết dẫn đường cho thực hành&lt;/strong&gt;: Nền tảng toán học vững chắc là cần thiết&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Công nghệ thúc đẩy ứng dụng&lt;/strong&gt;: Máy tính mạnh mở ra khả năng mới&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interdisciplinary collaboration&lt;/strong&gt;: Sự kết hợp giữa các lĩnh vực tạo ra đột phá&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Practical needs drive innovation&lt;/strong&gt;: Nhu cầu thực tế thúc đẩy phát triển thuật toán&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;div class=&quot;info-box&quot;&gt;
&lt;h4&gt;🎯 Takeaway chính&lt;/h4&gt;
&lt;p&gt;Tối ưu hóa lồi đã phát triển từ một lĩnh vực toán học thuần túy thành công cụ không thể thiếu trong công nghệ hiện đại. Sự kết hợp giữa lý thuyết vững chắc và thuật toán hiệu quả đã tạo ra những ứng dụng đột phá trong mọi lĩnh vực của cuộc sống.&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;-khám-phá-tương-tác&quot;&gt;🎮 Khám phá Tương tác&lt;/h2&gt;

&lt;h3 id=&quot;simplex-algorithm-visualization&quot;&gt;Simplex Algorithm Visualization&lt;/h3&gt;

&lt;div id=&quot;simplex-demo&quot;&gt;
  &lt;h4&gt;Minh họa Thuật toán Simplex&lt;/h4&gt;
  &lt;p&gt;Thử nghiệm với bài toán lập trình tuyến tính đơn giản:&lt;/p&gt;
  
  &lt;div class=&quot;problem-setup&quot;&gt;
    &lt;p&gt;&lt;strong&gt;Bài toán:&lt;/strong&gt; Maximize \\(c_1x_1 + c_2x_2\\)&lt;/p&gt;
    &lt;p&gt;&lt;strong&gt;Subject to:&lt;/strong&gt; \\(x_1, x_2 \geq 0\\) và các ràng buộc tuyến tính&lt;/p&gt;
    
    &lt;div class=&quot;controls&quot;&gt;
      &lt;label&gt;c₁: &lt;input type=&quot;range&quot; id=&quot;c1&quot; min=&quot;-5&quot; max=&quot;5&quot; value=&quot;3&quot; step=&quot;0.1&quot; /&gt;&lt;/label&gt;
      &lt;span id=&quot;c1-value&quot;&gt;3&lt;/span&gt;&lt;br /&gt;
      &lt;label&gt;c₂: &lt;input type=&quot;range&quot; id=&quot;c2&quot; min=&quot;-5&quot; max=&quot;5&quot; value=&quot;2&quot; step=&quot;0.1&quot; /&gt;&lt;/label&gt;
      &lt;span id=&quot;c2-value&quot;&gt;2&lt;/span&gt;&lt;br /&gt;
      &lt;button onclick=&quot;runSimplex()&quot;&gt;Chạy Simplex&lt;/button&gt;
      &lt;button onclick=&quot;resetDemo()&quot;&gt;Reset&lt;/button&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  
  &lt;canvas id=&quot;simplex-canvas&quot; width=&quot;400&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;
  &lt;div id=&quot;simplex-steps&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;timeline-explorer&quot;&gt;Timeline Explorer&lt;/h3&gt;

&lt;div id=&quot;timeline-explorer&quot;&gt;
  &lt;h4&gt;Khám phá Timeline Tương tác&lt;/h4&gt;
  &lt;div class=&quot;year-slider&quot;&gt;
    &lt;label&gt;Năm: &lt;input type=&quot;range&quot; id=&quot;year-slider&quot; min=&quot;1900&quot; max=&quot;2024&quot; value=&quot;1947&quot; step=&quot;1&quot; /&gt;&lt;/label&gt;
    &lt;span id=&quot;current-year&quot;&gt;1947&lt;/span&gt;
  &lt;/div&gt;
  
  &lt;div id=&quot;year-info&quot;&gt;
    &lt;h5 id=&quot;event-title&quot;&gt;1947: Thuật toán Simplex&lt;/h5&gt;
    &lt;p id=&quot;event-description&quot;&gt;George Dantzig phát triển thuật toán Simplex, mở đầu kỷ nguyên tối ưu hóa thực tế.&lt;/p&gt;
    &lt;div id=&quot;event-impact&quot;&gt;
      &lt;strong&gt;Tác động:&lt;/strong&gt; &lt;span id=&quot;impact-text&quot;&gt;Cách mạng trong operations research&lt;/span&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;ứng-dụng-hiện-đại&quot;&gt;Ứng dụng Hiện đại&lt;/h3&gt;

&lt;div id=&quot;applications-demo&quot;&gt;
  &lt;h4&gt;Ứng dụng trong Cuộc sống&lt;/h4&gt;
  &lt;div class=&quot;app-selector&quot;&gt;
    &lt;button onclick=&quot;showApplication(&apos;portfolio&apos;)&quot; class=&quot;app-btn&quot;&gt;Portfolio Optimization&lt;/button&gt;
    &lt;button onclick=&quot;showApplication(&apos;supply-chain&apos;)&quot; class=&quot;app-btn&quot;&gt;Supply Chain&lt;/button&gt;
    &lt;button onclick=&quot;showApplication(&apos;machine-learning&apos;)&quot; class=&quot;app-btn&quot;&gt;Machine Learning&lt;/button&gt;
    &lt;button onclick=&quot;showApplication(&apos;signal-processing&apos;)&quot; class=&quot;app-btn&quot;&gt;Signal Processing&lt;/button&gt;
  &lt;/div&gt;
  
  &lt;div id=&quot;app-content&quot;&gt;
    &lt;div class=&quot;app-example&quot; id=&quot;portfolio&quot;&gt;
      &lt;h5&gt;📈 Portfolio Optimization&lt;/h5&gt;
      &lt;p&gt;&lt;strong&gt;Bài toán:&lt;/strong&gt; Phân bổ vốn đầu tư để tối đa hóa lợi nhuận và giảm thiểu rủi ro&lt;/p&gt;
      &lt;p&gt;&lt;strong&gt;Công thức:&lt;/strong&gt; \\(\min \frac{1}{2}w^T\Sigma w - \mu^T w\\)&lt;/p&gt;
      &lt;p&gt;&lt;strong&gt;Ứng dụng:&lt;/strong&gt; Quỹ đầu tư, ngân hàng, bảo hiểm&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
// Simplex Algorithm Demo
function runSimplex() {
  const canvas = document.getElementById(&apos;simplex-canvas&apos;);
  const ctx = canvas.getContext(&apos;2d&apos;);
  const c1 = parseFloat(document.getElementById(&apos;c1&apos;).value);
  const c2 = parseFloat(document.getElementById(&apos;c2&apos;).value);
  
  // Clear canvas
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  
  // Draw feasible region (simple example)
  ctx.fillStyle = &apos;rgba(0, 122, 204, 0.2)&apos;;
  ctx.beginPath();
  ctx.moveTo(50, 250);
  ctx.lineTo(200, 250);
  ctx.lineTo(200, 100);
  ctx.lineTo(100, 50);
  ctx.lineTo(50, 100);
  ctx.closePath();
  ctx.fill();
  
  // Draw objective function direction
  ctx.strokeStyle = &apos;#ff6b35&apos;;
  ctx.lineWidth = 3;
  ctx.beginPath();
  ctx.moveTo(125, 175);
  ctx.lineTo(125 + c1*20, 175 - c2*20);
  ctx.stroke();
  
  // Add labels
  ctx.fillStyle = &apos;#333&apos;;
  ctx.font = &apos;14px Arial&apos;;
  ctx.fillText(&apos;Feasible Region&apos;, 60, 200);
  ctx.fillText(`Objective: ${c1.toFixed(1)}x₁ + ${c2.toFixed(1)}x₂`, 220, 50);
  
  // Show steps
  document.getElementById(&apos;simplex-steps&apos;).innerHTML = `
    &lt;h5&gt;Các bước Simplex:&lt;/h5&gt;
    &lt;ol&gt;
      &lt;li&gt;Bắt đầu tại đỉnh (0,0)&lt;/li&gt;
      &lt;li&gt;Kiểm tra hướng cải thiện: (${c1.toFixed(1)}, ${c2.toFixed(1)})&lt;/li&gt;
      &lt;li&gt;Di chuyển dọc theo cạnh có gradient tốt nhất&lt;/li&gt;
      &lt;li&gt;Dừng khi không thể cải thiện thêm&lt;/li&gt;
    &lt;/ol&gt;
  `;
}

function resetDemo() {
  document.getElementById(&apos;c1&apos;).value = 3;
  document.getElementById(&apos;c2&apos;).value = 2;
  document.getElementById(&apos;c1-value&apos;).textContent = &apos;3&apos;;
  document.getElementById(&apos;c2-value&apos;).textContent = &apos;2&apos;;
  document.getElementById(&apos;simplex-steps&apos;).innerHTML = &apos;&apos;;
  const canvas = document.getElementById(&apos;simplex-canvas&apos;);
  const ctx = canvas.getContext(&apos;2d&apos;);
  ctx.clearRect(0, 0, canvas.width, canvas.height);
}

// Timeline Explorer
const timelineEvents = {
  1900: {title: &quot;1900: Nền tảng Hình học&quot;, desc: &quot;Minkowski phát triển lý thuyết tập lồi&quot;, impact: &quot;Tạo nền tảng toán học&quot;},
  1930: {title: &quot;1930: Kantorovich&quot;, desc: &quot;Lý thuyết lập trình tuyến tính đầu tiên&quot;, impact: &quot;Ứng dụng trong kinh tế&quot;},
  1947: {title: &quot;1947: Thuật toán Simplex&quot;, desc: &quot;Dantzig tạo ra thuật toán thực tế đầu tiên&quot;, impact: &quot;Cách mạng operations research&quot;},
  1960: {title: &quot;1960s: Interior Point&quot;, desc: &quot;Fiacco &amp; McCormick phát triển barrier methods&quot;, impact: &quot;Mở rộng khả năng giải bài toán&quot;},
  1984: {title: &quot;1984: Karmarkar&quot;, desc: &quot;Interior-point polynomial-time algorithm&quot;, impact: &quot;Đột phá về độ phức tạp&quot;},
  1994: {title: &quot;1994: Nesterov &amp; Nemirovski&quot;, desc: &quot;Tổng quát hóa cho convex optimization&quot;, impact: &quot;Nền tảng cho ứng dụng hiện đại&quot;},
  2010: {title: &quot;2010s: Machine Learning&quot;, desc: &quot;Tích hợp với AI và Big Data&quot;, impact: &quot;Ứng dụng rộng rãi trong công nghệ&quot;},
  2024: {title: &quot;2024: Quantum Computing&quot;, desc: &quot;Thuật toán tối ưu lượng tử&quot;, impact: &quot;Tương lai của tính toán&quot;}
};

function updateTimeline() {
  const year = parseInt(document.getElementById(&apos;year-slider&apos;).value);
  document.getElementById(&apos;current-year&apos;).textContent = year;
  
  // Find closest event
  let closestYear = 1900;
  for (let eventYear in timelineEvents) {
    if (parseInt(eventYear) &lt;= year) {
      closestYear = parseInt(eventYear);
    }
  }
  
  const event = timelineEvents[closestYear];
  document.getElementById(&apos;event-title&apos;).textContent = event.title;
  document.getElementById(&apos;event-description&apos;).textContent = event.desc;
  document.getElementById(&apos;impact-text&apos;).textContent = event.impact;
}

// Applications Demo
const applications = {
  portfolio: {
    title: &quot;📈 Portfolio Optimization&quot;,
    problem: &quot;Phân bổ vốn đầu tư để tối đa hóa lợi nhuận và giảm thiểu rủi ro&quot;,
    formula: &quot;\\min \\frac{1}{2}w^T\\Sigma w - \\mu^T w&quot;,
    usage: &quot;Quỹ đầu tư, ngân hàng, bảo hiểm&quot;
  },
  &quot;supply-chain&quot;: {
    title: &quot;🚚 Supply Chain Optimization&quot;,
    problem: &quot;Tối ưu hóa logistics và phân phối hàng hóa&quot;,
    formula: &quot;\\min \\sum_{i,j} c_{ij}x_{ij}&quot;,
    usage: &quot;Amazon, Walmart, FedEx&quot;
  },
  &quot;machine-learning&quot;: {
    title: &quot;🤖 Machine Learning&quot;,
    problem: &quot;Training neural networks và feature selection&quot;,
    formula: &quot;\\min \\frac{1}{2}||Xw - y||^2 + \\lambda||w||_1&quot;,
    usage: &quot;Google, Facebook, Tesla autopilot&quot;
  },
  &quot;signal-processing&quot;: {
    title: &quot;📡 Signal Processing&quot;,
    problem: &quot;Khôi phục tín hiệu từ dữ liệu nhiễu hoặc không đầy đủ&quot;,
    formula: &quot;\\min ||x||_1 \\text{ s.t. } ||Ax - b||_2 \\leq \\epsilon&quot;,
    usage: &quot;MRI imaging, radar, 5G communications&quot;
  }
};

function showApplication(appKey) {
  const app = applications[appKey];
  document.getElementById(&apos;app-content&apos;).innerHTML = `
    &lt;div class=&quot;app-example&quot;&gt;
      &lt;h5&gt;${app.title}&lt;/h5&gt;
      &lt;p&gt;&lt;strong&gt;Bài toán:&lt;/strong&gt; ${app.problem}&lt;/p&gt;
      &lt;p&gt;&lt;strong&gt;Công thức:&lt;/strong&gt; \\(${app.formula}\\)&lt;/p&gt;
      &lt;p&gt;&lt;strong&gt;Ứng dụng:&lt;/strong&gt; ${app.usage}&lt;/p&gt;
    &lt;/div&gt;
  `;
  
  // Re-render MathJax
  if (window.MathJax) {
    MathJax.typesetPromise([document.getElementById(&apos;app-content&apos;)]);
  }
}

// Event listeners
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
  // Slider updates
  document.getElementById(&apos;c1&apos;).addEventListener(&apos;input&apos;, function() {
    document.getElementById(&apos;c1-value&apos;).textContent = this.value;
  });
  
  document.getElementById(&apos;c2&apos;).addEventListener(&apos;input&apos;, function() {
    document.getElementById(&apos;c2-value&apos;).textContent = this.value;
  });
  
  document.getElementById(&apos;year-slider&apos;).addEventListener(&apos;input&apos;, updateTimeline);
  
  // Initialize
  updateTimeline();
  showApplication(&apos;portfolio&apos;);
});
&lt;/script&gt;

&lt;style&gt;
.timeline-container {
  position: relative;
  margin: 20px 0;
}

.timeline-item {
  display: flex;
  margin: 10px 0;
  padding: 10px;
  border-left: 3px solid #007acc;
  background: #f8f9fa;
}

.timeline-year {
  font-weight: bold;
  color: #007acc;
  min-width: 100px;
}

.timeline-content {
  margin-left: 20px;
}

.info-box {
  background: #e3f2fd;
  border: 1px solid #2196f3;
  border-radius: 5px;
  padding: 15px;
  margin: 20px 0;
}

.info-box h4 {
  margin-top: 0;
  color: #1976d2;
}

/* Interactive Demo Styles */
#simplex-demo, #timeline-explorer, #applications-demo {
  background: #f8f9fa;
  border: 1px solid #dee2e6;
  border-radius: 8px;
  padding: 20px;
  margin: 20px 0;
}

.controls {
  margin: 15px 0;
}

.controls label {
  display: inline-block;
  margin: 5px 10px 5px 0;
  min-width: 40px;
}

.controls input[type=&quot;range&quot;] {
  width: 150px;
  margin: 0 10px;
}

.controls button {
  background: #007acc;
  color: white;
  border: none;
  padding: 8px 16px;
  border-radius: 4px;
  cursor: pointer;
  margin: 5px;
}

.controls button:hover {
  background: #005a9e;
}

#simplex-canvas {
  border: 1px solid #ccc;
  margin: 10px 0;
  background: white;
}

.year-slider {
  margin: 15px 0;
}

.year-slider input[type=&quot;range&quot;] {
  width: 300px;
}

#year-info {
  background: white;
  padding: 15px;
  border-radius: 5px;
  border-left: 4px solid #007acc;
}

.app-selector {
  margin: 15px 0;
}

.app-btn {
  background: #28a745;
  color: white;
  border: none;
  padding: 10px 15px;
  border-radius: 5px;
  cursor: pointer;
  margin: 5px;
  font-size: 14px;
}

.app-btn:hover {
  background: #218838;
}

.app-example {
  background: white;
  padding: 15px;
  border-radius: 5px;
  border-left: 4px solid #28a745;
  margin-top: 15px;
}

.problem-setup {
  background: white;
  padding: 15px;
  border-radius: 5px;
  margin: 10px 0;
}

#simplex-steps {
  background: white;
  padding: 15px;
  border-radius: 5px;
  margin-top: 10px;
}

#simplex-steps ol {
  margin: 10px 0;
  padding-left: 20px;
}

#simplex-steps li {
  margin: 5px 0;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>01-03 Mục tiêu và Chủ đề</title>
   <link href="http://localhost:4000/contents/vi/chapter01/01_03_goals_and_topics/"/>
   <updated>2021-01-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter01/01_03_goals_and_topics</id>
   <content type="html">&lt;h2 id=&quot;mục-tiêu&quot;&gt;Mục tiêu&lt;/h2&gt;
&lt;p&gt;Mục tiêu của khóa học này là phát triển các khả năng sau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nhận biết khi nào một bài toán cho trước là bài toán tối ưu hóa lồi&lt;/li&gt;
  &lt;li&gt;Xây dựng một tình huống cho trước thành bài toán tối ưu hóa lồi&lt;/li&gt;
  &lt;li&gt;Lựa chọn thuật toán phù hợp nhất để giải một bài toán tối ưu hóa lồi đã định nghĩa&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;chủ-đề&quot;&gt;Chủ đề&lt;/h2&gt;
&lt;p&gt;Để đạt được những mục tiêu này, các chủ đề sau sẽ được đề cập:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tập lồi, hàm số, bài toán tối ưu hóa&lt;/li&gt;
  &lt;li&gt;Ví dụ và ứng dụng&lt;/li&gt;
  &lt;li&gt;Thuật toán&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Đặc biệt, trọng tâm chính sẽ là thuật toán.&lt;/p&gt;

&lt;h2 id=&quot;thuật-toán&quot;&gt;Thuật toán&lt;/h2&gt;
&lt;p&gt;Có nhiều phương pháp khác nhau để giải bài toán tối ưu hóa. Hiệu suất của mỗi phương pháp phụ thuộc vào tính chất của bài toán được giải. Để chọn thuật toán hiệu quả nhất, cần có hiểu biết sâu sắc về cả bài toán và thuật toán. Hãy xem một ví dụ: khử nhiễu total variation.&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-khử-nhiễu-total-variation&quot;&gt;Ví dụ: Khử nhiễu Total variation&lt;/h3&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/2d_fused_lasso.png&quot; alt=&quot;2D Fused Lasso&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] Khử nhiễu Total Variation [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Giả sử bạn nhận được một hình ảnh nhiễu (giữa), và bạn muốn loại bỏ nhiễu để có được nghiệm (phải) gần với hình ảnh thật (trái). Nếu mỗi giá trị pixel là \(y_i, i = 1, ..., n\), bài toán này có thể được xây dựng thành bài toán tối ưu hóa sau, thường được gọi là bài toán 2D fused lasso hoặc khử nhiễu 2D total variation:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{\theta} \frac{1}{2} \sum_{i=1}^n (y_i - \theta_{i})^2 + \lambda \sum_{(i,j) \in E} \vert \theta_i - \theta_j \vert\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;E: tập hợp các cạnh giữa tất cả các \(\theta\) lân cận&lt;/li&gt;
  &lt;li&gt;\(\frac{1}{2} \sum_{i=1}^n (y_i - \theta_{i})^2\): Mất mát bình phương tối thiểu. Buộc \(\theta\) gần với \(y\)&lt;/li&gt;
  &lt;li&gt;\(\sum_{(i,j) \in E} \vert \theta_i - \theta_j \vert\): Làm mịn total variation. Được sử dụng khi sự thay đổi giữa các pixel lân cận không lớn (từng phần hằng số). Việc chọn phương pháp làm mịn phù hợp đòi hỏi xem xét cẩn thận đặc điểm của bài toán. (Để biết thêm chi tiết về làm mịn total variation, xem Chương 6.1.2 và 6.3 trong Tài liệu tham khảo 1.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bài toán tối ưu hóa lồi ở trên có thể được giải bằng thuật toán &lt;a href=&quot;http://stanford.edu/~boyd/admm.html&quot;&gt;Specialized ADMM&lt;/a&gt;, mang lại nghiệm bên phải sau 20 lần lặp.&lt;/p&gt;

&lt;h3 id=&quot;specialized-admm-20-lần-lặp&quot;&gt;Specialized ADMM, 20 lần lặp&lt;/h3&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/result1.png&quot; alt=&quot;Result1&quot; width=&quot;50%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình2] Kết quả Specialized ADMM [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;proximal-gradient-descent-1000-lần-lặp&quot;&gt;Proximal gradient descent, 1000 lần lặp&lt;/h3&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/result2.png&quot; alt=&quot;Result2&quot; width=&quot;50%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình3] Kết quả Proximal Gradient Descent [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;coordinate-descent-10k-chu-kỳ&quot;&gt;Coordinate descent, 10K chu kỳ&lt;/h3&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/result3.png&quot; alt=&quot;Result3&quot; width=&quot;50%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình4] Kết quả Coordinate Descent [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Như được chỉ ra ở trên, đối với bài toán 2D fused lasso, Specialized ADMM hoạt động tốt nhất trong ba phương pháp. Tuy nhiên, đối với các bài toán khác, hai phương pháp còn lại có thể vượt trội hơn Specialized ADMM. Trong các chương sau, chúng ta sẽ phân tích các thuật toán và bài toán khác nhau để học cách lựa chọn thuật toán phù hợp nhất.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>01-02 Bài toán tối ưu hóa lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter01/01_02_convex_optimization_problem/"/>
   <updated>2021-01-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter01/01_02_convex_optimization_problem</id>
   <content type="html">&lt;p&gt;Bài toán tối ưu hóa lồi là một loại bài toán tối ưu hóa.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align*} 
&amp;amp;\min_{x\in D}\ &amp;amp;&amp;amp;f(x) \\
&amp;amp;\text{với điều kiện} &amp;amp;&amp;amp; g_i(x) \le 0,\ i = 1, ..., m \\
&amp;amp;&amp;amp;&amp;amp; h_j(x) = 0,\ j = 1,\ ..., r
\end{align*}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Bài toán Tối ưu hóa Lồi ở dạng chuẩn [3]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ở đây, hàm mục tiêu \(f\) và các hàm ràng buộc bất đẳng thức \(g_i\) là lồi, và các hàm ràng buộc đẳng thức \(h_j\) là affine. Một hàm affine là một hàm tuyến tính cộng với một hằng số:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(h_j,\ j = 1, ..., r\) là affine: \(h_j(x) = a_{j}^T x + b_{j},\ j=1, ..., r\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Điều gì có nghĩa là một hàm lồi? Để hiểu điều này, trước tiên chúng ta cần hiểu tập lồi.&lt;/p&gt;

&lt;h2 id=&quot;tập-lồi&quot;&gt;Tập lồi&lt;/h2&gt;
&lt;p&gt;Một đoạn thẳng nối hai điểm \(x_1\) và \(x_2\) được định nghĩa là:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x = \theta x_1 + (1 - \theta) x_2\) với \(0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Cho một tập hợp, nếu đoạn thẳng giữa bất kỳ hai điểm \(x_1\) và \(x_2\) nào trong tập cũng được chứa trong tập đó, chúng ta gọi nó là tập lồi. Nói cách khác, một tập \(C\) là lồi nếu:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x_1, x_2 \in C\), \(0 \le \theta \le 1\)  \(\Rightarrow\) \(\theta x_1 + (1-\theta)x_2 \in C\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ví dụ, trong hình dưới đây, chỉ có hình bên trái nhất là tập lồi.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/Convex_set.png&quot; alt=&quot;Convex Set&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình1] trái: tập lồi, giữa &amp;amp; phải: tập không lồi [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;hàm-lồi&quot;&gt;Hàm lồi&lt;/h2&gt;
&lt;p&gt;Một hàm lồi được định nghĩa như sau:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f: \mathbb{R}^n \rightarrow \mathbb{R}\) là lồi nếu \(dom(f)\) là tập lồi và,&lt;/p&gt;

  &lt;p&gt;\(f(\theta x + (1 - \theta)y) \le \theta f(x) + (1-\theta)f(y)\) với mọi \(x, y \in dom(f),\ 0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Về mặt hình học, điều này có nghĩa là với bất kỳ hai điểm \((x, f(x))\) và \((y, f(y))\) nào trên đồ thị của \(f\), đoạn thẳng nối chúng nằm phía trên đồ thị giữa \(x\) và \(y\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/Convex_function.png&quot; alt=&quot;Convex Function&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình2] Hàm Lồi [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;mối-quan-hệ-giữa-tập-lồi-và-hàm-lồi&quot;&gt;Mối quan hệ giữa tập lồi và hàm lồi&lt;/h2&gt;
&lt;p&gt;Có một mối quan hệ chặt chẽ giữa hàm lồi và tập lồi:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Một hàm \(f\) là lồi khi và chỉ khi epigraph của nó là tập lồi.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Epigraph là gì? ‘Epi’ có nghĩa là ‘phía trên’, vì vậy epigraph của \(f\) là tập hợp các điểm phía trên đồ thị của \(f\). Chính thức, epigraph được định nghĩa là:&lt;/p&gt;

&lt;blockquote&gt;
\[\eqalign{
&amp;amp; \text{epigraph của } f: \mathbb{R}^n \rightarrow \mathbb{R}\\
&amp;amp; \text{epi } f = \{(x, t) \in \mathbb{R}^{n+1} \mid x \in \text{ dom } f, f(x) \le t\}
}\]
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/epigraph.png&quot; alt=&quot;Epigraph&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình3] Epigraph [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Nếu \(f\) là hàm lồi, thì \(\text{epi } f\) luôn là tập lồi, và ngược lại. Đây là tính chất quan trọng kết nối định nghĩa của hàm lồi và tập lồi.&lt;/p&gt;

&lt;h2 id=&quot;hàm-lồi-và-hàm-lõm&quot;&gt;Hàm lồi và hàm lõm&lt;/h2&gt;

&lt;p&gt;Một hàm \(f\) là lõm nếu \(-f\) là lồi. Tương đương, \(f\) là lõm nếu:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f(\theta x + (1 - \theta)y) \ge \theta f(x) + (1-\theta)f(y)\) với mọi \(x, y \in dom(f),\ 0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Về mặt hình học, điều này có nghĩa là đoạn thẳng nối bất kỳ hai điểm nào trên đồ thị nằm dưới đồ thị của hàm số. Một hàm lõm “cong xuống” trong khi hàm lồi “cong lên”.&lt;/p&gt;

&lt;p&gt;Còn về hàm lõm thì sao? Tại sao chúng ta nhấn mạnh hàm lồi nhiều đến vậy, và dường như “bỏ qua” hàm lõm?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Chúng ta “không quan tâm” đến hàm lõm riêng biệt vì chúng chỉ là hình ảnh phản chiếu của hàm lồi. Luôn chuyển đổi việc tối đa hóa hàm lõm \(f\) thành tối thiểu hóa hàm lồi \(-f\).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tính-chất-tốt-của-bài-toán-tối-ưu-hóa-lồi&quot;&gt;Tính chất tốt của bài toán tối ưu hóa lồi&lt;/h2&gt;
&lt;p&gt;Một điểm cực tiểu địa phương của hàm lồi luôn là cực tiểu toàn cục. Đối với bài toán tối ưu hóa lồi, nghiệm thường dễ tìm hơn so với bài toán không lồi, vì hàm lồi có tính chất sau:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Nếu \(f\) là lồi và \(x\) là điểm tối ưu địa phương (tức là cực tiểu địa phương), thì \(x\) cũng là điểm tối ưu toàn cục.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hãy chứng minh điều này bằng phản chứng:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Chứng minh bằng phản chứng:&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Giả sử với hàm lồi \(f\), \(x\) là điểm tối ưu địa phương nhưng không phải tối ưu toàn cục. Gọi \(y\) là điểm tối ưu toàn cục khả thi, nên với mọi \(\rho\) dương, \(\|y - x\|_2 &amp;gt; \rho\) và \(f(y) &amp;lt; f(x)\). (Vì \(x\) tối ưu địa phương, nếu \(\|x - y\|_2 \le \rho\) thì \(f(x) \le f(y)\), điều này mâu thuẫn với việc \(y\) tối ưu toàn cục.)
Bây giờ, với \(\theta=\frac{\rho}{2\|y-x\|_2}\), gọi \(z = \theta y + (1 - \theta) x = x + \theta( y - x)\). Khi đó:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;
      &lt;p&gt;\(z\) là tổ hợp lồi của hai điểm khả thi \(x, y\), nên nó cũng khả thi.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;\(\|z - x\|_2 = \theta \|y - x\|_2 = \frac{\rho}{2} &amp;lt; \rho\).&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
\[f(z) \le \theta f(y) + (1 - \theta) f(x) &amp;lt; \theta f(x) + (1 - \theta) f(x) = f(x)\]
    &lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;Điểm 2 và 3 mâu thuẫn với giả thiết rằng \(x\) là điểm tối ưu địa phương, nên bằng phản chứng, bất kỳ điểm tối ưu địa phương \(x\) nào cũng là tối ưu toàn cục.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;tổ-hợp-lồi&quot;&gt;Tổ hợp lồi&lt;/h2&gt;

&lt;p&gt;Tổ hợp lồi của \(x_1, ..., x_k\) được định nghĩa là:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x = \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_k x_k\) với \(\theta_1 + \cdots + \theta_k = 1, \theta_i \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nếu \(D\) là tập lồi và \(x_1, x_2, ..., x_k \in D\), thì \(x \in D\) cũng vậy.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>01-04 Brief history of convex optimization</title>
   <link href="http://localhost:4000/contents/en/chapter01/01_04_brief_history_of_convex_optimization/"/>
   <updated>2021-01-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter01/01_04_brief_history_of_convex_optimization</id>
   <content type="html">&lt;h1 id=&quot;lịch-sử-phát-triển-của-tối-ưu-hóa-lồi&quot;&gt;Lịch sử phát triển của Tối ưu hóa Lồi&lt;/h1&gt;

&lt;p&gt;Tối ưu hóa lồi có một lịch sử phát triển phong phú, từ những nền tảng lý thuyết đầu tiên đến các ứng dụng hiện đại trong công nghệ và khoa học. Hãy cùng khám phá hành trình này qua các giai đoạn quan trọng.&lt;/p&gt;

&lt;h2 id=&quot;-tổng-quan-timeline&quot;&gt;🎯 Tổng quan Timeline&lt;/h2&gt;

&lt;div class=&quot;timeline-container&quot;&gt;
  &lt;div class=&quot;timeline-item&quot;&gt;
    &lt;div class=&quot;timeline-year&quot;&gt;1900-1970&lt;/div&gt;
    &lt;div class=&quot;timeline-content&quot;&gt;Phát triển nền tảng lý thuyết&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&quot;timeline-item&quot;&gt;
    &lt;div class=&quot;timeline-year&quot;&gt;1947-1990&lt;/div&gt;
    &lt;div class=&quot;timeline-content&quot;&gt;Các thuật toán đột phá&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&quot;timeline-item&quot;&gt;
    &lt;div class=&quot;timeline-year&quot;&gt;1990-nay&lt;/div&gt;
    &lt;div class=&quot;timeline-content&quot;&gt;Bùng nổ ứng dụng&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;-giai-đoạn-1-nền-tảng-lý-thuyết-1900-1970&quot;&gt;📚 Giai đoạn 1: Nền tảng Lý thuyết (1900-1970)&lt;/h2&gt;

&lt;h3 id=&quot;những-người-tiên-phong&quot;&gt;Những người tiên phong&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Hermann Minkowski (1864-1909)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Đặt nền móng cho hình học lồi với khái niệm “tập lồi”&lt;/li&gt;
  &lt;li&gt;Phát triển lý thuyết về các đa diện lồi&lt;/li&gt;
  &lt;li&gt;Ảnh hưởng: Tạo ra ngôn ngữ toán học cơ bản cho tối ưu hóa lồi&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Leonid Kantorovich (1912-1986)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Phát triển lý thuyết lập trình tuyến tính vào những năm 1930&lt;/li&gt;
  &lt;li&gt;Giải quyết bài toán phân bổ tài nguyên tối ưu&lt;/li&gt;
  &lt;li&gt;Đóng góp: Chứng minh tính khả thi của việc tối ưu hóa trong kinh tế&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;John von Neumann (1903-1957)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Phát triển lý thuyết trò chơi và mối liên hệ với tối ưu hóa&lt;/li&gt;
  &lt;li&gt;Đưa ra định lý minimax cơ bản&lt;/li&gt;
  &lt;li&gt;Ảnh hưởng: Kết nối tối ưu hóa với lý thuyết quyết định&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;các-khái-niệm-nền-tảng-được-hình-thành&quot;&gt;Các khái niệm nền tảng được hình thành:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tập lồi và hàm lồi&lt;/strong&gt;: Định nghĩa chính xác và tính chất cơ bản&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Điều kiện tối ưu&lt;/strong&gt;: Phát triển các điều kiện cần và đủ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Duality theory&lt;/strong&gt;: Khái niệm về bài toán đối ngẫu&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;️-giai-đoạn-2-cách-mạng-thuật-toán-1947-1990&quot;&gt;⚙️ Giai đoạn 2: Cách mạng Thuật toán (1947-1990)&lt;/h2&gt;

&lt;h3 id=&quot;1947-thuật-toán-simplex---bước-ngoặt-lịch-sử&quot;&gt;1947: Thuật toán Simplex - Bước ngoặt lịch sử&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;George Dantzig&lt;/strong&gt; đã tạo ra cuộc cách mạng với thuật toán Simplex:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ý tưởng cốt lõi: Di chuyển dọc theo các cạnh của đa diện khả thi
để tìm điểm tối ưu tại một đỉnh.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Tại sao quan trọng?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lần đầu tiên có thuật toán thực tế để giải bài toán lập trình tuyến tính&lt;/li&gt;
  &lt;li&gt;Mở ra khả năng ứng dụng trong logistics, sản xuất, quân sự&lt;/li&gt;
  &lt;li&gt;Hiệu quả cao trong thực tế dù có độ phức tạp tệ nhất là exponential&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1960s-phương-pháp-điểm-trong-đầu-tiên&quot;&gt;1960s: Phương pháp Điểm trong đầu tiên&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Fiacco &amp;amp; McCormick&lt;/strong&gt; phát triển:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Barrier methods cho bài toán có ràng buộc bất đẳng thức&lt;/li&gt;
  &lt;li&gt;Ý tưởng: Thêm hàm penalty để “đẩy” nghiệm vào bên trong miền khả thi&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Dikin&lt;/strong&gt; đóng góp:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Affine scaling method&lt;/li&gt;
  &lt;li&gt;Cải thiện hướng tiếp cận của barrier methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1970s-phương-pháp-ellipsoid-và-subgradient&quot;&gt;1970s: Phương pháp Ellipsoid và Subgradient&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Shor, Nemirovski, Yudin&lt;/strong&gt; phát triển:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ellipsoid method&lt;/strong&gt;: Thuật toán đa thức đầu tiên cho LP&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Subgradient methods&lt;/strong&gt;: Xử lý hàm không khả vi&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ý nghĩa lý thuyết:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Chứng minh LP thuộc lớp P (polynomial time)&lt;/li&gt;
  &lt;li&gt;Mở rộng khả năng giải các bài toán không trơn&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1984-đột-phá-của-karmarkar&quot;&gt;1984: Đột phá của Karmarkar&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Narendra Karmarkar&lt;/strong&gt; tạo ra cuộc cách mạng thứ hai:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Thuật toán interior-point với độ phức tạp \(O(n^{3.5}L)\)&lt;/li&gt;
  &lt;li&gt;Hiệu quả thực tế cao hơn simplex cho bài toán lớn&lt;/li&gt;
  &lt;li&gt;Khởi đầu cho kỷ nguyên interior-point methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;late-1980s-1990s-tổng-quát-hóa&quot;&gt;Late 1980s-1990s: Tổng quát hóa&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Nesterov &amp;amp; Nemirovski (1994)&lt;/strong&gt; mở rộng:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Interior-point methods cho tối ưu lồi phi tuyến&lt;/li&gt;
  &lt;li&gt;Self-concordant functions&lt;/li&gt;
  &lt;li&gt;Polynomial-time algorithms cho broader class&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-giai-đoạn-3-bùng-nổ-ứng-dụng-1990-nay&quot;&gt;🚀 Giai đoạn 3: Bùng nổ Ứng dụng (1990-nay)&lt;/h2&gt;

&lt;h3 id=&quot;trước-1990-giới-hạn-trong-operations-research&quot;&gt;Trước 1990: Giới hạn trong Operations Research&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Các ứng dụng chính:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Transportation problems&lt;/strong&gt;: Tối ưu hóa vận chuyển hàng hóa&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Production planning&lt;/strong&gt;: Lập kế hoạch sản xuất&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Resource allocation&lt;/strong&gt;: Phân bổ tài nguyên trong doanh nghiệp&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Military logistics&lt;/strong&gt;: Ứng dụng trong quân sự (WWII và Cold War)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Tại sao giới hạn?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Máy tính chưa đủ mạnh&lt;/li&gt;
  &lt;li&gt;Thiếu software tools&lt;/li&gt;
  &lt;li&gt;Chưa nhận thức được tiềm năng trong engineering&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;từ-1990-cách-mạng-ứng-dụng&quot;&gt;Từ 1990: Cách mạng Ứng dụng&lt;/h3&gt;

&lt;h4 id=&quot;️-control-systems-hệ-thống-điều-khiển&quot;&gt;🎛️ Control Systems (Hệ thống Điều khiển)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Model Predictive Control (MPC)&lt;/strong&gt;: Điều khiển dự báo&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Robust control&lt;/strong&gt;: Điều khiển bền vững&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ví dụ&lt;/strong&gt;: Điều khiển nhiệt độ trong nhà máy, autopilot máy bay&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;-signal-processing-xử-lý-tín-hiệu&quot;&gt;📡 Signal Processing (Xử lý Tín hiệu)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Compressed sensing&lt;/strong&gt;: Khôi phục tín hiệu từ ít mẫu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Image denoising&lt;/strong&gt;: Khử nhiễu ảnh&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ví dụ&lt;/strong&gt;: MRI imaging, radar processing&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;-communications-truyền-thông&quot;&gt;📱 Communications (Truyền thông)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Beamforming&lt;/strong&gt;: Định hướng sóng trong antenna arrays&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Power allocation&lt;/strong&gt;: Phân bổ công suất trong mạng wireless&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ví dụ&lt;/strong&gt;: 5G networks, satellite communications&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;-circuit-design-thiết-kế-mạch&quot;&gt;💻 Circuit Design (Thiết kế Mạch)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Gate sizing&lt;/strong&gt;: Tối ưu kích thước transistor&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Power optimization&lt;/strong&gt;: Tối ưu tiêu thụ năng lượng&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ví dụ&lt;/strong&gt;: CPU design, mobile chip optimization&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-các-lớp-bài-toán-mới&quot;&gt;🆕 Các lớp bài toán mới&lt;/h3&gt;

&lt;h4 id=&quot;semidefinite-programming-sdp&quot;&gt;Semidefinite Programming (SDP)&lt;/h4&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Tối ưu hóa trên ma trận bán xác định dương
Ứng dụng: Relaxation của bài toán combinatorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;second-order-cone-programming-socp&quot;&gt;Second-Order Cone Programming (SOCP)&lt;/h4&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Tối ưu hóa với ràng buộc hình nón bậc hai
Ứng dụng: Robust optimization, portfolio optimization
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;robust-optimization&quot;&gt;Robust Optimization&lt;/h4&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Tối ưu hóa với uncertainty trong dữ liệu
Ứng dụng: Finance, supply chain management
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;-xu-hướng-hiện-tại-và-tương-lai&quot;&gt;🔮 Xu hướng Hiện tại và Tương lai&lt;/h2&gt;

&lt;h3 id=&quot;machine-learning-integration&quot;&gt;Machine Learning Integration&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Convex relaxations&lt;/strong&gt; của neural networks&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Optimization trong training&lt;/strong&gt;: Adam, RMSprop&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: L1, L2 penalties&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;big-data-applications&quot;&gt;Big Data Applications&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Distributed optimization&lt;/strong&gt;: Xử lý dữ liệu lớn&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Online algorithms&lt;/strong&gt;: Học trực tuyến&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Streaming optimization&lt;/strong&gt;: Tối ưu real-time&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;quantum-computing&quot;&gt;Quantum Computing&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Quantum convex optimization&lt;/strong&gt;: Thuật toán lượng tử&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Variational quantum algorithms&lt;/strong&gt;: QAOA, VQE&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-bài-học-từ-lịch-sử&quot;&gt;💡 Bài học từ Lịch sử&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Lý thuyết dẫn đường cho thực hành&lt;/strong&gt;: Nền tảng toán học vững chắc là cần thiết&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Công nghệ thúc đẩy ứng dụng&lt;/strong&gt;: Máy tính mạnh mở ra khả năng mới&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interdisciplinary collaboration&lt;/strong&gt;: Sự kết hợp giữa các lĩnh vực tạo ra đột phá&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Practical needs drive innovation&lt;/strong&gt;: Nhu cầu thực tế thúc đẩy phát triển thuật toán&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;div class=&quot;info-box&quot;&gt;
&lt;h4&gt;🎯 Takeaway chính&lt;/h4&gt;
&lt;p&gt;Tối ưu hóa lồi đã phát triển từ một lĩnh vực toán học thuần túy thành công cụ không thể thiếu trong công nghệ hiện đại. Sự kết hợp giữa lý thuyết vững chắc và thuật toán hiệu quả đã tạo ra những ứng dụng đột phá trong mọi lĩnh vực của cuộc sống.&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;-khám-phá-tương-tác&quot;&gt;🎮 Khám phá Tương tác&lt;/h2&gt;

&lt;h3 id=&quot;simplex-algorithm-visualization&quot;&gt;Simplex Algorithm Visualization&lt;/h3&gt;

&lt;div id=&quot;simplex-demo&quot;&gt;
  &lt;h4&gt;Minh họa Thuật toán Simplex&lt;/h4&gt;
  &lt;p&gt;Thử nghiệm với bài toán lập trình tuyến tính đơn giản:&lt;/p&gt;
  
  &lt;div class=&quot;problem-setup&quot;&gt;
    &lt;p&gt;&lt;strong&gt;Bài toán:&lt;/strong&gt; Maximize \\(c_1x_1 + c_2x_2\\)&lt;/p&gt;
    &lt;p&gt;&lt;strong&gt;Subject to:&lt;/strong&gt; \\(x_1, x_2 \geq 0\\) và các ràng buộc tuyến tính&lt;/p&gt;
    
    &lt;div class=&quot;controls&quot;&gt;
      &lt;label&gt;c₁: &lt;input type=&quot;range&quot; id=&quot;c1&quot; min=&quot;-5&quot; max=&quot;5&quot; value=&quot;3&quot; step=&quot;0.1&quot; /&gt;&lt;/label&gt;
      &lt;span id=&quot;c1-value&quot;&gt;3&lt;/span&gt;&lt;br /&gt;
      &lt;label&gt;c₂: &lt;input type=&quot;range&quot; id=&quot;c2&quot; min=&quot;-5&quot; max=&quot;5&quot; value=&quot;2&quot; step=&quot;0.1&quot; /&gt;&lt;/label&gt;
      &lt;span id=&quot;c2-value&quot;&gt;2&lt;/span&gt;&lt;br /&gt;
      &lt;button onclick=&quot;runSimplex()&quot;&gt;Chạy Simplex&lt;/button&gt;
      &lt;button onclick=&quot;resetDemo()&quot;&gt;Reset&lt;/button&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  
  &lt;canvas id=&quot;simplex-canvas&quot; width=&quot;400&quot; height=&quot;300&quot;&gt;&lt;/canvas&gt;
  &lt;div id=&quot;simplex-steps&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;timeline-explorer&quot;&gt;Timeline Explorer&lt;/h3&gt;

&lt;div id=&quot;timeline-explorer&quot;&gt;
  &lt;h4&gt;Khám phá Timeline Tương tác&lt;/h4&gt;
  &lt;div class=&quot;year-slider&quot;&gt;
    &lt;label&gt;Năm: &lt;input type=&quot;range&quot; id=&quot;year-slider&quot; min=&quot;1900&quot; max=&quot;2024&quot; value=&quot;1947&quot; step=&quot;1&quot; /&gt;&lt;/label&gt;
    &lt;span id=&quot;current-year&quot;&gt;1947&lt;/span&gt;
  &lt;/div&gt;
  
  &lt;div id=&quot;year-info&quot;&gt;
    &lt;h5 id=&quot;event-title&quot;&gt;1947: Thuật toán Simplex&lt;/h5&gt;
    &lt;p id=&quot;event-description&quot;&gt;George Dantzig phát triển thuật toán Simplex, mở đầu kỷ nguyên tối ưu hóa thực tế.&lt;/p&gt;
    &lt;div id=&quot;event-impact&quot;&gt;
      &lt;strong&gt;Tác động:&lt;/strong&gt; &lt;span id=&quot;impact-text&quot;&gt;Cách mạng trong operations research&lt;/span&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;ứng-dụng-hiện-đại&quot;&gt;Ứng dụng Hiện đại&lt;/h3&gt;

&lt;div id=&quot;applications-demo&quot;&gt;
  &lt;h4&gt;Ứng dụng trong Cuộc sống&lt;/h4&gt;
  &lt;div class=&quot;app-selector&quot;&gt;
    &lt;button onclick=&quot;showApplication(&apos;portfolio&apos;)&quot; class=&quot;app-btn&quot;&gt;Portfolio Optimization&lt;/button&gt;
    &lt;button onclick=&quot;showApplication(&apos;supply-chain&apos;)&quot; class=&quot;app-btn&quot;&gt;Supply Chain&lt;/button&gt;
    &lt;button onclick=&quot;showApplication(&apos;machine-learning&apos;)&quot; class=&quot;app-btn&quot;&gt;Machine Learning&lt;/button&gt;
    &lt;button onclick=&quot;showApplication(&apos;signal-processing&apos;)&quot; class=&quot;app-btn&quot;&gt;Signal Processing&lt;/button&gt;
  &lt;/div&gt;
  
  &lt;div id=&quot;app-content&quot;&gt;
    &lt;div class=&quot;app-example&quot; id=&quot;portfolio&quot;&gt;
      &lt;h5&gt;📈 Portfolio Optimization&lt;/h5&gt;
      &lt;p&gt;&lt;strong&gt;Bài toán:&lt;/strong&gt; Phân bổ vốn đầu tư để tối đa hóa lợi nhuận và giảm thiểu rủi ro&lt;/p&gt;
      &lt;p&gt;&lt;strong&gt;Công thức:&lt;/strong&gt; \\(\min \frac{1}{2}w^T\Sigma w - \mu^T w\\)&lt;/p&gt;
      &lt;p&gt;&lt;strong&gt;Ứng dụng:&lt;/strong&gt; Quỹ đầu tư, ngân hàng, bảo hiểm&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
// Simplex Algorithm Demo
function runSimplex() {
  const canvas = document.getElementById(&apos;simplex-canvas&apos;);
  const ctx = canvas.getContext(&apos;2d&apos;);
  const c1 = parseFloat(document.getElementById(&apos;c1&apos;).value);
  const c2 = parseFloat(document.getElementById(&apos;c2&apos;).value);
  
  // Clear canvas
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  
  // Draw feasible region (simple example)
  ctx.fillStyle = &apos;rgba(0, 122, 204, 0.2)&apos;;
  ctx.beginPath();
  ctx.moveTo(50, 250);
  ctx.lineTo(200, 250);
  ctx.lineTo(200, 100);
  ctx.lineTo(100, 50);
  ctx.lineTo(50, 100);
  ctx.closePath();
  ctx.fill();
  
  // Draw objective function direction
  ctx.strokeStyle = &apos;#ff6b35&apos;;
  ctx.lineWidth = 3;
  ctx.beginPath();
  ctx.moveTo(125, 175);
  ctx.lineTo(125 + c1*20, 175 - c2*20);
  ctx.stroke();
  
  // Add labels
  ctx.fillStyle = &apos;#333&apos;;
  ctx.font = &apos;14px Arial&apos;;
  ctx.fillText(&apos;Feasible Region&apos;, 60, 200);
  ctx.fillText(`Objective: ${c1.toFixed(1)}x₁ + ${c2.toFixed(1)}x₂`, 220, 50);
  
  // Show steps
  document.getElementById(&apos;simplex-steps&apos;).innerHTML = `
    &lt;h5&gt;Các bước Simplex:&lt;/h5&gt;
    &lt;ol&gt;
      &lt;li&gt;Bắt đầu tại đỉnh (0,0)&lt;/li&gt;
      &lt;li&gt;Kiểm tra hướng cải thiện: (${c1.toFixed(1)}, ${c2.toFixed(1)})&lt;/li&gt;
      &lt;li&gt;Di chuyển dọc theo cạnh có gradient tốt nhất&lt;/li&gt;
      &lt;li&gt;Dừng khi không thể cải thiện thêm&lt;/li&gt;
    &lt;/ol&gt;
  `;
}

function resetDemo() {
  document.getElementById(&apos;c1&apos;).value = 3;
  document.getElementById(&apos;c2&apos;).value = 2;
  document.getElementById(&apos;c1-value&apos;).textContent = &apos;3&apos;;
  document.getElementById(&apos;c2-value&apos;).textContent = &apos;2&apos;;
  document.getElementById(&apos;simplex-steps&apos;).innerHTML = &apos;&apos;;
  const canvas = document.getElementById(&apos;simplex-canvas&apos;);
  const ctx = canvas.getContext(&apos;2d&apos;);
  ctx.clearRect(0, 0, canvas.width, canvas.height);
}

// Timeline Explorer
const timelineEvents = {
  1900: {title: &quot;1900: Nền tảng Hình học&quot;, desc: &quot;Minkowski phát triển lý thuyết tập lồi&quot;, impact: &quot;Tạo nền tảng toán học&quot;},
  1930: {title: &quot;1930: Kantorovich&quot;, desc: &quot;Lý thuyết lập trình tuyến tính đầu tiên&quot;, impact: &quot;Ứng dụng trong kinh tế&quot;},
  1947: {title: &quot;1947: Thuật toán Simplex&quot;, desc: &quot;Dantzig tạo ra thuật toán thực tế đầu tiên&quot;, impact: &quot;Cách mạng operations research&quot;},
  1960: {title: &quot;1960s: Interior Point&quot;, desc: &quot;Fiacco &amp; McCormick phát triển barrier methods&quot;, impact: &quot;Mở rộng khả năng giải bài toán&quot;},
  1984: {title: &quot;1984: Karmarkar&quot;, desc: &quot;Interior-point polynomial-time algorithm&quot;, impact: &quot;Đột phá về độ phức tạp&quot;},
  1994: {title: &quot;1994: Nesterov &amp; Nemirovski&quot;, desc: &quot;Tổng quát hóa cho convex optimization&quot;, impact: &quot;Nền tảng cho ứng dụng hiện đại&quot;},
  2010: {title: &quot;2010s: Machine Learning&quot;, desc: &quot;Tích hợp với AI và Big Data&quot;, impact: &quot;Ứng dụng rộng rãi trong công nghệ&quot;},
  2024: {title: &quot;2024: Quantum Computing&quot;, desc: &quot;Thuật toán tối ưu lượng tử&quot;, impact: &quot;Tương lai của tính toán&quot;}
};

function updateTimeline() {
  const year = parseInt(document.getElementById(&apos;year-slider&apos;).value);
  document.getElementById(&apos;current-year&apos;).textContent = year;
  
  // Find closest event
  let closestYear = 1900;
  for (let eventYear in timelineEvents) {
    if (parseInt(eventYear) &lt;= year) {
      closestYear = parseInt(eventYear);
    }
  }
  
  const event = timelineEvents[closestYear];
  document.getElementById(&apos;event-title&apos;).textContent = event.title;
  document.getElementById(&apos;event-description&apos;).textContent = event.desc;
  document.getElementById(&apos;impact-text&apos;).textContent = event.impact;
}

// Applications Demo
const applications = {
  portfolio: {
    title: &quot;📈 Portfolio Optimization&quot;,
    problem: &quot;Phân bổ vốn đầu tư để tối đa hóa lợi nhuận và giảm thiểu rủi ro&quot;,
    formula: &quot;\\min \\frac{1}{2}w^T\\Sigma w - \\mu^T w&quot;,
    usage: &quot;Quỹ đầu tư, ngân hàng, bảo hiểm&quot;
  },
  &quot;supply-chain&quot;: {
    title: &quot;🚚 Supply Chain Optimization&quot;,
    problem: &quot;Tối ưu hóa logistics và phân phối hàng hóa&quot;,
    formula: &quot;\\min \\sum_{i,j} c_{ij}x_{ij}&quot;,
    usage: &quot;Amazon, Walmart, FedEx&quot;
  },
  &quot;machine-learning&quot;: {
    title: &quot;🤖 Machine Learning&quot;,
    problem: &quot;Training neural networks và feature selection&quot;,
    formula: &quot;\\min \\frac{1}{2}||Xw - y||^2 + \\lambda||w||_1&quot;,
    usage: &quot;Google, Facebook, Tesla autopilot&quot;
  },
  &quot;signal-processing&quot;: {
    title: &quot;📡 Signal Processing&quot;,
    problem: &quot;Khôi phục tín hiệu từ dữ liệu nhiễu hoặc không đầy đủ&quot;,
    formula: &quot;\\min ||x||_1 \\text{ s.t. } ||Ax - b||_2 \\leq \\epsilon&quot;,
    usage: &quot;MRI imaging, radar, 5G communications&quot;
  }
};

function showApplication(appKey) {
  const app = applications[appKey];
  document.getElementById(&apos;app-content&apos;).innerHTML = `
    &lt;div class=&quot;app-example&quot;&gt;
      &lt;h5&gt;${app.title}&lt;/h5&gt;
      &lt;p&gt;&lt;strong&gt;Bài toán:&lt;/strong&gt; ${app.problem}&lt;/p&gt;
      &lt;p&gt;&lt;strong&gt;Công thức:&lt;/strong&gt; \\(${app.formula}\\)&lt;/p&gt;
      &lt;p&gt;&lt;strong&gt;Ứng dụng:&lt;/strong&gt; ${app.usage}&lt;/p&gt;
    &lt;/div&gt;
  `;
  
  // Re-render MathJax
  if (window.MathJax) {
    MathJax.typesetPromise([document.getElementById(&apos;app-content&apos;)]);
  }
}

// Event listeners
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
  // Slider updates
  document.getElementById(&apos;c1&apos;).addEventListener(&apos;input&apos;, function() {
    document.getElementById(&apos;c1-value&apos;).textContent = this.value;
  });
  
  document.getElementById(&apos;c2&apos;).addEventListener(&apos;input&apos;, function() {
    document.getElementById(&apos;c2-value&apos;).textContent = this.value;
  });
  
  document.getElementById(&apos;year-slider&apos;).addEventListener(&apos;input&apos;, updateTimeline);
  
  // Initialize
  updateTimeline();
  showApplication(&apos;portfolio&apos;);
});
&lt;/script&gt;

&lt;style&gt;
.timeline-container {
  position: relative;
  margin: 20px 0;
}

.timeline-item {
  display: flex;
  margin: 10px 0;
  padding: 10px;
  border-left: 3px solid #007acc;
  background: #f8f9fa;
}

.timeline-year {
  font-weight: bold;
  color: #007acc;
  min-width: 100px;
}

.timeline-content {
  margin-left: 20px;
}

.info-box {
  background: #e3f2fd;
  border: 1px solid #2196f3;
  border-radius: 5px;
  padding: 15px;
  margin: 20px 0;
}

.info-box h4 {
  margin-top: 0;
  color: #1976d2;
}

/* Interactive Demo Styles */
#simplex-demo, #timeline-explorer, #applications-demo {
  background: #f8f9fa;
  border: 1px solid #dee2e6;
  border-radius: 8px;
  padding: 20px;
  margin: 20px 0;
}

.controls {
  margin: 15px 0;
}

.controls label {
  display: inline-block;
  margin: 5px 10px 5px 0;
  min-width: 40px;
}

.controls input[type=&quot;range&quot;] {
  width: 150px;
  margin: 0 10px;
}

.controls button {
  background: #007acc;
  color: white;
  border: none;
  padding: 8px 16px;
  border-radius: 4px;
  cursor: pointer;
  margin: 5px;
}

.controls button:hover {
  background: #005a9e;
}

#simplex-canvas {
  border: 1px solid #ccc;
  margin: 10px 0;
  background: white;
}

.year-slider {
  margin: 15px 0;
}

.year-slider input[type=&quot;range&quot;] {
  width: 300px;
}

#year-info {
  background: white;
  padding: 15px;
  border-radius: 5px;
  border-left: 4px solid #007acc;
}

.app-selector {
  margin: 15px 0;
}

.app-btn {
  background: #28a745;
  color: white;
  border: none;
  padding: 10px 15px;
  border-radius: 5px;
  cursor: pointer;
  margin: 5px;
  font-size: 14px;
}

.app-btn:hover {
  background: #218838;
}

.app-example {
  background: white;
  padding: 15px;
  border-radius: 5px;
  border-left: 4px solid #28a745;
  margin-top: 15px;
}

.problem-setup {
  background: white;
  padding: 15px;
  border-radius: 5px;
  margin: 10px 0;
}

#simplex-steps {
  background: white;
  padding: 15px;
  border-radius: 5px;
  margin-top: 10px;
}

#simplex-steps ol {
  margin: 10px 0;
  padding-left: 20px;
}

#simplex-steps li {
  margin: 5px 0;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>01-03 Goals and Topics</title>
   <link href="http://localhost:4000/contents/en/chapter01/01_03_goals_and_topics/"/>
   <updated>2021-01-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter01/01_03_goals_and_topics</id>
   <content type="html">&lt;h2 id=&quot;goals&quot;&gt;Goals&lt;/h2&gt;
&lt;p&gt;The goal of this course is to develop the following abilities:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Recognize when a given problem is a convex optimization problem&lt;/li&gt;
  &lt;li&gt;Formulate a given situation as a convex optimization problem&lt;/li&gt;
  &lt;li&gt;Select the most appropriate algorithm to solve a defined convex optimization problem&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;topics&quot;&gt;Topics&lt;/h2&gt;
&lt;p&gt;To achieve these goals, the following topics will be covered:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Convex sets, functions, optimization problems&lt;/li&gt;
  &lt;li&gt;Examples and applications&lt;/li&gt;
  &lt;li&gt;Algorithms&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In particular, the main focus will be on algorithms.&lt;/p&gt;

&lt;h2 id=&quot;algorithms&quot;&gt;Algorithms&lt;/h2&gt;
&lt;p&gt;There are many different methods for solving optimization problems. The performance of each method depends on the properties of the problem being solved. To choose the most efficient algorithm, a deep understanding of both the problem and the algorithms is required. Let’s look at an example: total variation denoising.&lt;/p&gt;

&lt;h3 id=&quot;example-total-variation-denoising&quot;&gt;Example: Total variation denoising&lt;/h3&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/2d_fused_lasso.png&quot; alt=&quot;2D Fused Lasso&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Total Variation Denoising [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;Suppose you receive a noisy image (middle), and you want to remove the noise to obtain a solution (right) close to the true image (left). If each pixel value is \(y_i, i = 1, ..., n\), this problem can be formulated as the following optimization problem, commonly called the 2D fused lasso or 2D total variation denoising problem:&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{\theta} \frac{1}{2} \sum_{i=1}^n (y_i - \theta_{i})^2 + \lambda \sum_{(i,j) \in E} \vert \theta_i - \theta_j \vert\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;E: the set of edges between all neighboring \(\theta\)&lt;/li&gt;
  &lt;li&gt;\(\frac{1}{2} \sum_{i=1}^n (y_i - \theta_{i})^2\): Least squares loss. Forces \(\theta\) to be close to \(y\)&lt;/li&gt;
  &lt;li&gt;\(\sum_{(i,j) \in E} \vert \theta_i - \theta_j \vert\): Total variation smoothing. Used when the change between neighboring pixels is not large (piecewise constant). Choosing the right smoothing method requires careful consideration of the problem’s characteristics. (For more details on total variation smoothing, see Chapter 6.1.2 and 6.3 in Reference 1.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The convex optimization problem above can be solved using the &lt;a href=&quot;http://stanford.edu/~boyd/admm.html&quot;&gt;Specialized ADMM&lt;/a&gt; algorithm, which yields the solution on the right after 20 iterations.&lt;/p&gt;

&lt;h3 id=&quot;specialized-admm-20-iterations&quot;&gt;Specialized ADMM, 20 iterations&lt;/h3&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/result1.png&quot; alt=&quot;Result1&quot; width=&quot;50%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Specialized ADMM Result [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;proximal-gradient-descent-1000-iterations&quot;&gt;Proximal gradient descent, 1000 iterations&lt;/h3&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/result2.png&quot; alt=&quot;Result2&quot; width=&quot;50%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig3] Proximal Gradient Descent Result [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;coordinate-descent-10k-cycles&quot;&gt;Coordinate descent, 10K cycles&lt;/h3&gt;
&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/result3.png&quot; alt=&quot;Result3&quot; width=&quot;50%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig4] Coordinate Descent Result [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;As shown above, for the 2D fused lasso problem, Specialized ADMM performs best among the three methods. However, for other problems, the other two methods may outperform Specialized ADMM. In later chapters, we will analyze various algorithms and problems to learn how to select the most appropriate algorithm.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>01-02 Convex optimization problem</title>
   <link href="http://localhost:4000/contents/en/chapter01/01_02_convex_optimization_problem/"/>
   <updated>2021-01-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter01/01_02_convex_optimization_problem</id>
   <content type="html">&lt;p&gt;A convex optimization problem is a type of optimization problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align*} 
&amp;amp;\min_{x\in D}\ &amp;amp;&amp;amp;f(x) \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp; g_i(x) \le 0,\ i = 1, ..., m \\
&amp;amp;&amp;amp;&amp;amp; h_j(x) = 0,\ j = 1,\ ..., r
\end{align*}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Convex Optimization Problem in standard form [3]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Here, the objective function \(f\) and the inequality constraint functions \(g_i\) are convex, and the equality constraint functions \(h_j\) are affine. An affine function is a linear function plus a constant:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(h_j,\ j = 1, ..., r\) are affine: \(h_j(x) = a_{j}^T x + b_{j},\ j=1, ..., r\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What does it mean for a function to be convex? To understand this, we first need to understand convex sets.&lt;/p&gt;

&lt;h2 id=&quot;convex-sets&quot;&gt;Convex sets&lt;/h2&gt;
&lt;p&gt;A line segment connecting two points \(x_1\) and \(x_2\) is defined as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x = \theta x_1 + (1 - \theta) x_2\) with \(0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Given a set, if the line segment between any two points \(x_1\) and \(x_2\) in the set is also contained in the set, we call it a convex set. In other words, a set \(C\) is convex if:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x_1, x_2 \in C\), \(0 \le \theta \le 1\)  \(\Rightarrow\) \(\theta x_1 + (1-\theta)x_2 \in C\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For example, in the figure below, only the leftmost shape is a convex set.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/Convex_set.png&quot; alt=&quot;Convex Set&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] left: a convex set, mid &amp;amp; right: non-convex sets [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;convex-functions&quot;&gt;Convex functions&lt;/h2&gt;
&lt;p&gt;A convex function is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f: \mathbb{R}^n \rightarrow \mathbb{R}\) is convex if \(dom(f)\) is a convex set and,&lt;/p&gt;

  &lt;p&gt;\(f(\theta x + (1 - \theta)y) \le \theta f(x) + (1-\theta)f(y)\) for all \(x, y \in dom(f),\ 0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Geometrically, this means that for any two points \((x, f(x))\) and \((y, f(y))\) on the graph of \(f\), the line segment connecting them lies above the graph between \(x\) and \(y\).&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/Convex_function.png&quot; alt=&quot;Convex Function&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Convex Function [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;relation-between-a-convex-set-and-a-convex-function&quot;&gt;Relation between a convex set and a convex function&lt;/h2&gt;
&lt;p&gt;There is a close relationship between convex functions and convex sets:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;A function \(f\) is convex if and only if its epigraph is a convex set.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What is an epigraph? ‘Epi’ means ‘above’, so the epigraph of \(f\) is the set of points above the graph of \(f\). Formally, the epigraph is defined as:&lt;/p&gt;

&lt;blockquote&gt;
\[\eqalign{
&amp;amp; \text{epigraph of } f: \mathbb{R}^n \rightarrow \mathbb{R}\\
&amp;amp; \text{epi } f = \{(x, t) \in \mathbb{R}^{n+1} \mid x \in \text{ dom } f, f(x) \le t\}
}\]
&lt;/blockquote&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter01/epigraph.png&quot; alt=&quot;Epigraph&quot; width=&quot;70%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig3] Epigraph [2]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;p&gt;If \(f\) is a convex function, then \(\text{epi } f\) is always a convex set, and vice versa. This is a key property connecting the definitions of convex functions and convex sets.&lt;/p&gt;

&lt;h2 id=&quot;convex-and-concave-functions&quot;&gt;Convex and concave functions&lt;/h2&gt;

&lt;p&gt;A function \(f\) is concave if \(-f\) is convex. Equivalently, \(f\) is concave if:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(f(\theta x + (1 - \theta)y) \ge \theta f(x) + (1-\theta)f(y)\) for all \(x, y \in dom(f),\ 0 \le \theta \le 1\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Geometrically, this means that the line segment connecting any two points on the graph lies below the graph of the function. A concave function “curves downward” while a convex function “curves upward”.&lt;/p&gt;

&lt;p&gt;What about concave functions? Why do we emphasize convex functions so much, and seemingly “ignore” concave ones?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We “don’t care” about concave functions separately because they’re just the mirror image of convex ones. Always reformulate maximization of concave \(f\) as minimization of convex \(-f\).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;nice-property-of-convex-optimization-problems&quot;&gt;Nice property of convex optimization problems&lt;/h2&gt;
&lt;p&gt;A local minimum of a convex function is always a global minimum. For convex optimization problems, solutions are generally easier to find than for non-convex problems, because convex functions have the following property:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;If \(f\) is convex and \(x\) is a locally optimal point (i.e., a local minimum), then \(x\) is also a globally optimal point.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let’s prove this by contradiction:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Proof by contradiction:&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Suppose for a convex function \(f\), \(x\) is a locally optimal point but not a globally optimal point. Let \(y\) be a feasible global optimal point, so for any positive \(\rho\), \(\|y - x\|_2 &amp;gt; \rho\) and \(f(y) &amp;lt; f(x)\). (Because \(x\) is locally optimal, if \(\|x - y\|_2 \le \rho\) then \(f(x) \le f(y)\), which contradicts \(y\) being globally optimal.)
Now, for \(\theta=\frac{\rho}{2\|y-x\|_2}\), let \(z = \theta y + (1 - \theta) x = x + \theta( y - x)\). Then:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;
      &lt;p&gt;\(z\) is a convex combination of two feasible points \(x, y\), so it is also feasible.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;\(\|z - x\|_2 = \theta \|y - x\|_2 = \frac{\rho}{2} &amp;lt; \rho\).&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
\[f(z) \le \theta f(y) + (1 - \theta) f(x) &amp;lt; \theta f(x) + (1 - \theta) f(x) = f(x)\]
    &lt;/li&gt;
  &lt;/ol&gt;

  &lt;p&gt;Points 2 and 3 contradict the assumption that \(x\) is a locally optimal point, so by contradiction, any locally optimal point \(x\) is also globally optimal.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;convex-combination&quot;&gt;Convex combination&lt;/h2&gt;

&lt;p&gt;A convex combination of \(x_1, ..., x_k\) is defined as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x = \theta_1 x_1 + \theta_2 x_2 + \cdots + \theta_k x_k\) with \(\theta_1 + \cdots + \theta_k = 1, \theta_i \ge 0\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If \(D\) is a convex set and \(x_1, x_2, ..., x_k \in D\), then \(x \in D\) as well.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>contents</title>
   <link href="http://localhost:4000/home/link_to_how_to_contribute/"/>
   <updated>2021-01-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/home/link_to_how_to_contribute</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Initial Settings</title>
   <link href="http://localhost:4000/contribution/initial_settings/"/>
   <updated>2021-01-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contribution/initial_settings</id>
   <content type="html">&lt;p&gt;The contents of this repository are hosted as a &lt;a href=&quot;https://convex-optimization-for-all.github.io/&quot;&gt;Github Blog&lt;/a&gt; using Jekyll.
Therefore, to edit existing content or create new content, you must follow Jekyll’s directory structure and content writing conventions.
Additionally, you need to verify that changes are properly reflected in your local environment (your current computer) through a web browser.&lt;/p&gt;

&lt;p&gt;We have compiled environment setup instructions for those who are not familiar with GitHub or Jekyll.
If you have difficulties following the guide, please leave an &lt;a href=&quot;https://github.com/convex-optimization-for-all/convex-optimization-for-all.github.io/issues&quot;&gt;issue&lt;/a&gt; in the repository or contact us via the email below for assistance.&lt;/p&gt;

&lt;p&gt;(Kyeongmin Woo, wgm0601@gmail.com)&lt;/p&gt;

&lt;h2 id=&quot;1-git-installation&quot;&gt;1. Git Installation&lt;/h2&gt;

&lt;p&gt;All work management for this blog is performed through Git and GitHub. Please visit the website below to install Git.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://git-scm.com/downloads&quot;&gt;https://git-scm.com/downloads&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-downloading-the-repository&quot;&gt;2. Downloading the Repository&lt;/h2&gt;

&lt;p&gt;To modify the blog, enter the following command in the terminal to download the blog’s source code.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/convex-optimization-for-all/convex-optimization-for-all.github.io.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-local-hosting&quot;&gt;3. Local Hosting&lt;/h2&gt;

&lt;p&gt;Before applying changed or modified content to the blog, you must verify that the work has been performed as intended through local hosting.
If you merge work content that does not follow Jekyll’s required conventions into the repository, the blog hosted on the actual web may not function properly.
For local hosting setup, you can choose between two methods: using a virtual environment (Docker) (Option 1) or directly installing the Jekyll environment locally (Option 2).
After completing the local hosting setup and running the local server, you can check your blog content through the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;127.0.0.1:4000&lt;/code&gt; address in your web browser.&lt;/p&gt;

&lt;h3 id=&quot;3-1-option-1-docker-installation&quot;&gt;3-1. (Option 1) Docker Installation&lt;/h3&gt;

&lt;h3 id=&quot;a-docker-installation&quot;&gt;A. Docker Installation&lt;/h3&gt;

&lt;p&gt;Using Docker enables local hosting without direct environment installation on your local machine.
Please visit the website below to install Docker.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.docker.com/get-docker/&quot;&gt;https://docs.docker.com/get-docker/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;b-local-hosting&quot;&gt;B. Local Hosting&lt;/h3&gt;

&lt;p&gt;Enter the following command in the terminal.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-2-option-2-jekyll-environment-installation&quot;&gt;3-2. (Option 2) Jekyll Environment Installation&lt;/h3&gt;

&lt;h3 id=&quot;a-jekyll-and-ruby-package-installation&quot;&gt;A. Jekyll and Ruby Package Installation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://jekyllrb.com/docs/installation/&quot;&gt;Installing Ruby&lt;/a&gt;: Jekyll is built with Ruby. Therefore, you need to install Ruby to use Jekyll.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jekyllrb.com/docs/&quot;&gt;Installing Jekyll&lt;/a&gt;: Once Ruby is installed, enter the cloned repository and install Jekyll.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jekyllrb.com/docs/&quot;&gt;Installing Bundle Gem&lt;/a&gt;: You need to additionally install Ruby packages required for hosting. Run the following command in the repository’s project directory.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;bundle &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;b-local-hosting-1&quot;&gt;B. Local Hosting&lt;/h3&gt;

&lt;p&gt;Enter the following command in the terminal.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ jekyll serve
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If hosting doesn’t work, you can also try the following command.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bundle exec jekyll serve
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If both commands don’t work, the Jekyll environment has not been properly installed.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>How to Contribute</title>
   <link href="http://localhost:4000/contribution/how_to_contribute/"/>
   <updated>2021-01-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contribution/how_to_contribute</id>
   <content type="html">&lt;hr /&gt;

&lt;h2 id=&quot;1-컨텐츠를-직접-수정하는-방법&quot;&gt;1. 컨텐츠를 직접 수정하는 방법&lt;/h2&gt;

&lt;h3 id=&quot;1-우선-local의-repository-directory로-들어갑니다-local-repository가-없다면-initial-settings를-참고하시기-바랍니다&quot;&gt;(1) 우선 Local의 Repository Directory로 들어갑니다. Local Repository가 없다면 &lt;a href=&quot;https://convex-optimization-for-all.github.io/contribution/2021/01/27/initial_settings/&quot;&gt;Initial Settings&lt;/a&gt;를 참고하시기 바랍니다.&lt;/h3&gt;

&lt;h3 id=&quot;2--remote-저장소와의-정보를-동기화합니다&quot;&gt;(2)  Remote 저장소와의 정보를 동기화합니다.&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git checkout main
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git pull &lt;span class=&quot;nt&quot;&gt;--all&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-수정-내용을-담는-새로운-브랜치를-생성합니다-브랜치-명은-prefix챕터명수정하는_이유로-하시면-됩니다branch-naming-convetion-예시는-아래와-같습니다&quot;&gt;(3) 수정 내용을 담는 새로운 브랜치를 생성합니다. 브랜치 명은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[Prefix]/[챕터명]/[수정하는_이유]&lt;/code&gt;로 하시면 됩니다(&lt;a href=&quot;https://convex-optimization-for-all.github.io/contribution/2021/02/03/conventions/&quot;&gt;Branch Naming Convetion&lt;/a&gt;). 예시는 아래와 같습니다.&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git checkout &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; bugfix/chapter01-fix-typo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4-파일을-편집합니다-생성-또는-수정하고자-하는-컨텐츠는-convention을-지켜-작성해야-합니다&quot;&gt;(4) 파일을 편집합니다. 생성 또는 수정하고자 하는 컨텐츠는 &lt;a href=&quot;https://convex-optimization-for-all.github.io/contribution/2021/02/03/conventions/&quot;&gt;Convention&lt;/a&gt;을 지켜 작성해야 합니다.&lt;/h3&gt;

&lt;h3 id=&quot;5-remote로-push합니다-예시는-아래와-같습니다&quot;&gt;(5) Remote로 Push합니다. 예시는 아래와 같습니다.&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git push origin bugfix/chapter01-fix-typo
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;6-github에서-main-branch로의-pull-request를-생성합니다-pull-request-생성-방법은-아래-github-docs를-참고하시기-바랍니다&quot;&gt;(6) &lt;a href=&quot;https://github.com/convex-optimization-for-all/convex-optimization-for-all.github.io/pulls&quot;&gt;Github&lt;/a&gt;에서 main branch로의 Pull Request를 생성합니다. Pull Request 생성 방법은 아래 GitHub Docs를 참고하시기 바랍니다.&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request&quot;&gt;Creating a pull request&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-컨텐츠-수정을-요청하는-방법&quot;&gt;2. 컨텐츠 수정을 요청하는 방법&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Github Repository에 &lt;a href=&quot;https://github.com/convex-optimization-for-all/convex-optimization-for-all.github.io/issues&quot;&gt;Issue&lt;/a&gt;를 생성하실 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>introduction</title>
   <link href="http://localhost:4000/home/introduction/"/>
   <updated>2021-01-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/home/introduction</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>contents</title>
   <link href="http://localhost:4000/home/contents/"/>
   <updated>2021-01-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/home/contents</id>
   <content type="html">&lt;p&gt;An introduction to convex optimization problems, concepts in convex analysis, convex optimization algorithms, duality theory, optimality conditions, and applications of convex optimization in statistics and machine learning.&lt;/p&gt;

&lt;h1 id=&quot;course-objectives&quot;&gt;Course Objectives&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Provide students with fundamental knowledge of convex optimization to support their study and research in data science.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Enable students to understand optimization algorithms and use existing software to solve optimization problems.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Begin to develop skills in analyzing and solving convex optimization problems in real-world applications, and in applying optimization algorithms to these problems.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;main-textbooks&quot;&gt;Main Textbooks&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Y. Nesterov, Lectures on Convex Optimization, 2018. [FIT_2101685_001]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;S. Boyd &amp;amp; L. Vandenberghe, Convex Optimization, 2004.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;C. C. Aggarwal, Linear Algebra and Optimization for Machine Learning: A Textbook, 2020. [FIT_2101685_101]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;C. Byrne, A First Course in Optimization, CRC Press, 2015.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;S. Sra, S. Nowozin, &amp;amp; S. J. Wright (eds.), Optimization for Machine Learning, MIT Press, 2012.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>02-01 Tập Affine và Tập Lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter02/02_01_Affine_and_Convex_Sets/"/>
   <updated>2021-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/02_01_Affine_and_Convex_Sets</id>
   <content type="html">&lt;p&gt;Trong chương này, chúng ta sẽ khám phá các khái niệm và định nghĩa xoay quanh tập lồi. Chúng tôi giới thiệu ba loại tập hợp: cơ bản nhất là tập affine, và bằng cách áp đặt các ràng buộc bổ sung lên tập affine, chúng ta định nghĩa tập lồi và hình nón.&lt;/p&gt;

&lt;p&gt;Thú vị là, các tập hợp này có thể được coi như các tập hợp của nhiều đường thẳng (line), đoạn thẳng hoặc tia. Một tập affine được hình thành bằng cách tập hợp nhiều đường thẳng, một tập lồi bằng cách tập hợp nhiều đoạn thẳng, và một hình nón bằng cách tập hợp nhiều tia. Góc nhìn này giúp việc hiểu các khái niệm này trở nên dễ dàng hơn. Ngoài ra, một hình nón đôi khi được gọi là tập đồng nhất không âm, có nghĩa là tính chất mở rộng chỉ theo một hướng từ gốc tọa độ, giúp làm rõ cách đặt tên.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02-01 Affine and Convex Sets</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_01_Affine_and_Convex_Sets/"/>
   <updated>2021-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter02/02_01_Affine_and_Convex_Sets</id>
   <content type="html">&lt;p&gt;In this chapter, we will explore the concepts and definitions centered around convex sets. We introduce three types of sets: the most basic is the affine set, and by imposing additional constraints on the affine set, we define the convex set and the cone.&lt;/p&gt;

&lt;p&gt;Interestingly, these sets can be thought of as collections of many lines (line), line segments, or rays. An affine set is formed by gathering many lines, a convex set by gathering many line segments, and a cone by gathering many rays. This perspective makes it easier to understand these concepts. Also, a cone is sometimes called a nonnegative homogeneous set, which refers to the property that it extends only in one direction from the origin, helping to clarify the naming.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>01-01 Bài toán tối ưu hóa?</title>
   <link href="http://localhost:4000/contents/vi/chapter01/01_01_optimization_problems/"/>
   <updated>2021-01-07T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter01/01_01_optimization_problems</id>
   <content type="html">&lt;p&gt;Bài toán tối ưu hóa là bài toán trong đó, trong số nhiều ứng viên có thể, chúng ta tìm kiếm nghiệm tối ưu (giá trị tối ưu) hoặc một giá trị gần với tối ưu.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Trong khoa học dữ liệu và học máy&lt;/strong&gt;, tối ưu hóa có mặt ở khắp mọi nơi:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Huấn luyện mạng nơ-ron&lt;/strong&gt;: Tìm kiếm trọng số để giảm thiểu lỗi dự đoán&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hồi quy tuyến tính&lt;/strong&gt;: Tìm đường thẳng khớp nhất để giảm thiểu bình phương sai số&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phân cụm&lt;/strong&gt;: Tối ưu hóa tâm cụm để giảm thiểu phương sai trong cụm&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lựa chọn đặc trưng&lt;/strong&gt;: Chọn tập con đặc trưng tốt nhất để tối đa hóa hiệu suất mô hình&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Điều chỉnh siêu tham số&lt;/strong&gt;: Tìm tỷ lệ học tối ưu, tham số chính quy, v.v.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Mỗi khi bạn huấn luyện một mô hình học máy, bạn đang giải một bài toán tối ưu hóa!&lt;/p&gt;

&lt;h2 id=&quot;bài-toán-tối-ưu-hóa-toán-học&quot;&gt;Bài toán tối ưu hóa toán học&lt;/h2&gt;
&lt;p&gt;Một bài toán tối ưu hóa toán học có thể được biểu diễn như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align*} 
&amp;amp;\min_{x\in D}\ &amp;amp;&amp;amp; f(x) \\
&amp;amp;\text{với điều kiện} &amp;amp;&amp;amp; g_i(x) \le 0,\ i = 1, ..., m \\
&amp;amp;&amp;amp;&amp;amp; h_j(x) = 0,\ j = 1,\ ..., r
\end{align*}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Bài toán Tối ưu hóa Toán học ở dạng chuẩn&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(x \in \mathbb{R}^n\) là biến tối ưu hóa&lt;/li&gt;
  &lt;li&gt;\(f: \mathbb{R}^n \rightarrow \mathbb{R}\) là hàm mục tiêu hoặc hàm chi phí&lt;/li&gt;
  &lt;li&gt;\(g_i: \mathbb{R}^n \rightarrow \mathbb{R}, i = 1, ..., m\) là các hàm ràng buộc bất đẳng thức&lt;/li&gt;
  &lt;li&gt;\(h_j: \mathbb{R}^n \rightarrow \mathbb{R}, j = 1, ..., r\) là các hàm ràng buộc đẳng thức&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Vector \(x\) mà tối thiểu hóa hàm mục tiêu \(f\) trên miền khả thi (tập hợp tất cả các điểm thỏa mãn các ràng buộc) được ký hiệu là \(x^*\) và được gọi là nghiệm tối ưu.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Các ràng buộc có thể được phân loại thành hai loại:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Ràng buộc tường minh: Các ràng buộc được chỉ định trực tiếp trong bài toán tối ưu hóa. Trong dạng chuẩn ở trên, các ràng buộc được biểu diễn bởi các hàm \(g_i\) và \(h_j\) là tường minh. Nếu không có ràng buộc tường minh, bài toán được gọi là bài toán không ràng buộc.&lt;/li&gt;
  &lt;li&gt;Ràng buộc ngầm: Các ràng buộc không được chỉ định trực tiếp, nhưng phát sinh từ giao của các miền của hàm mục tiêu và các hàm ràng buộc.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;\(D = dom(f) \cap \bigcap_{i=1}^m {\rm dom}(g_i) \cap \bigcap_{j=1}^r dom(h_j)\)&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ghi chú:&lt;/strong&gt; \(dom(f)\) có nghĩa là miền của hàm \(f\).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Ví dụ: ràng buộc ngầm ↔ ràng buộc tường minh&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Giả sử bài toán tối ưu hóa được cho như sau:&lt;/p&gt;

\[\begin{align*} \text{tối thiểu } &amp;amp; &amp;amp; \log(x) \end{align*}\]

  &lt;p&gt;Ở đây, miền của hàm mục tiêu \(\log(x)\) là \(x &amp;gt; 0\), nên \(x &amp;gt; 0\) là một ràng buộc ngầm. Nếu chúng ta viết điều này dưới dạng bài toán tối ưu hóa với ràng buộc tường minh:&lt;/p&gt;

\[\begin{align*} &amp;amp;\text{tối thiểu } &amp;amp;&amp;amp; \log(x) \\ &amp;amp;\text{với điều kiện } &amp;amp;&amp;amp;x &amp;gt; 0 \end{align*}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;💡 Mẹo chuyên nghiệp&lt;/strong&gt;: Bắt đầu với các công thức lồi khi có thể - chúng dễ giải và hiểu hơn. Chỉ chuyển sang các mô hình phi lồi phức tạp khi các phương pháp đơn giản hơn không đáp ứng được yêu cầu của bạn.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>01 Giới thiệu</title>
   <link href="http://localhost:4000/contents/vi/chapter01/01_00_Introduction/"/>
   <updated>2021-01-07T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter01/01_00_Introduction</id>
   <content type="html">&lt;p&gt;Giới thiệu về các Bài toán Tối ưu hóa Toán học—đặc biệt là các Bài toán Tối ưu hóa Lồi.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>01-01 Optimization problems?</title>
   <link href="http://localhost:4000/contents/en/chapter01/01_01_optimization_problems/"/>
   <updated>2021-01-07T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter01/01_01_optimization_problems</id>
   <content type="html">&lt;p&gt;An optimization problem is a problem in which, among many possible candidates, we seek the optimal solution (optimal value) or a value close to the optimal.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In data science and machine learning&lt;/strong&gt;, optimization is everywhere:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Training neural networks&lt;/strong&gt;: Finding weights that minimize prediction error&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Linear regression&lt;/strong&gt;: Finding the best-fit line that minimizes squared errors&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Clustering&lt;/strong&gt;: Optimizing cluster centers to minimize within-cluster variance&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Feature selection&lt;/strong&gt;: Choosing the best subset of features to maximize model performance&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hyperparameter tuning&lt;/strong&gt;: Finding optimal learning rates, regularization parameters, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Every time you train a machine learning model, you’re solving an optimization problem!&lt;/p&gt;

&lt;h2 id=&quot;mathematical-optimization-problems&quot;&gt;Mathematical optimization problems&lt;/h2&gt;
&lt;p&gt;A mathematical optimization problem can be expressed as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align*} 
&amp;amp;\min_{x\in D}\ &amp;amp;&amp;amp; f(x) \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp; g_i(x) \le 0,\ i = 1, ..., m \\
&amp;amp;&amp;amp;&amp;amp; h_j(x) = 0,\ j = 1,\ ..., r
\end{align*}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Mathematical Optimization Problem in standard form&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(x \in \mathbb{R}^n\) is the optimization variable&lt;/li&gt;
  &lt;li&gt;\(f: \mathbb{R}^n \rightarrow \mathbb{R}\) is the objective or cost function&lt;/li&gt;
  &lt;li&gt;\(g_i: \mathbb{R}^n \rightarrow \mathbb{R}, i = 1, ..., m\) are the inequality constraint functions&lt;/li&gt;
  &lt;li&gt;\(h_j: \mathbb{R}^n \rightarrow \mathbb{R}, j = 1, ..., r\) are the equality constraint functions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The vector \(x\) that minimizes the objective function \(f\) over the feasible domain (the set of all points satisfying the constraints) is denoted as \(x^*\) and called the optimal solution.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Constraints can be classified into two types:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Explicit constraints: Constraints that are directly specified in the optimization problem. In the standard form above, the constraints expressed by the functions \(g_i\) and \(h_j\) are explicit. If there are no explicit constraints, the problem is called an unconstrained problem.&lt;/li&gt;
  &lt;li&gt;Implicit constraints: Constraints that are not directly specified, but arise from the intersection of the domains of the objective and constraint functions.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;\(D = dom(f) \cap \bigcap_{i=1}^m {\rm dom}(g_i) \cap \bigcap_{j=1}^r dom(h_j)\)&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; \(dom(f)\) means the domain of the function \(f\).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Example: implicit constraint ↔ explicit constraint&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;Suppose the optimization problem is given as follows:&lt;/p&gt;

\[\begin{align*} \text{minimize } &amp;amp; &amp;amp; \log(x) \end{align*}\]

  &lt;p&gt;Here, the domain of the objective function \(\log(x)\) is \(x &amp;gt; 0\), so \(x &amp;gt; 0\) is an implicit constraint. If we write this as an optimization problem with explicit constraints:&lt;/p&gt;

\[\begin{align*} &amp;amp;\text{minimize } &amp;amp;&amp;amp; \log(x) \\ &amp;amp;\text{subject to } &amp;amp;&amp;amp;x &amp;gt; 0 \end{align*}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;💡 Pro Tip&lt;/strong&gt;: Start with convex formulations when possible - they’re easier to solve and understand. Only move to complex non-convex models when simpler approaches fail to meet your requirements.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>01 Introduction</title>
   <link href="http://localhost:4000/contents/en/chapter01/01_00_Introduction/"/>
   <updated>2021-01-07T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter01/01_00_Introduction</id>
   <content type="html">&lt;p&gt;Introduction to Mathematical Optimization Problems—especially Convex Optimization Problems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00 Giới thiệu</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_Introduction</id>
   <content type="html">&lt;p&gt;Tối ưu hóa là trái tim của khoa học dữ liệu. Dù bạn đang huấn luyện một mạng nơ-ron, tối thiểu hóa lỗi trong các mô hình hồi quy, hay phân bổ tài nguyên hiệu quả trong hệ thống gợi ý, về bản chất bạn đang giải quyết các bài toán tìm kiếm giải pháp “tốt nhất” từ một tập hợp khổng lồ các khả năng. Nhưng để làm điều này một cách hiệu quả, bạn cần nói được ngôn ngữ của toán học. Chúng ta sẽ ôn lại các ý tưởng chính từ đại số tuyến tính, lý thuyết tập hợp và giải tích, đảm bảo bạn được trang bị để xử lý các gradient, ma trận, ràng buộc và sự bất định phát sinh trong các tác vụ tối ưu hóa.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-04 Xác Suất và Thống Kê</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_04_Probability_and_Statistics/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_04_Probability_and_Statistics</id>
   <content type="html">&lt;h2 id=&quot;xác-suất-và-thống-kê-cho-tối-ưu-hóa-lồi&quot;&gt;Xác Suất và Thống Kê cho Tối Ưu Hóa Lồi&lt;/h2&gt;

&lt;p&gt;Xác suất và thống kê tạo nên nền tảng quan trọng để hiểu nhiều bài toán tối ưu hóa, đặc biệt trong học máy và khoa học dữ liệu. Phần này giới thiệu các khái niệm xác suất thiết yếu thường xuất hiện trong tối ưu hóa lồi, từ ước lượng hợp lý tối đa đến tối ưu hóa Bayes.&lt;/p&gt;

&lt;h3 id=&quot;tại-sao-xác-suất-quan-trọng-trong-tối-ưu-hóa&quot;&gt;Tại Sao Xác Suất Quan Trọng trong Tối Ưu Hóa&lt;/h3&gt;

&lt;p&gt;Nhiều bài toán tối ưu hóa phát sinh từ mô hình hóa thống kê:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ước Lượng Hợp Lý Tối Đa (MLE)&lt;/strong&gt;: Tìm tham số để tối đa hóa khả năng của dữ liệu quan sát&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tối Ưu Hóa Bayes&lt;/strong&gt;: Sử dụng mô hình xác suất để hướng dẫn tìm kiếm giải pháp tối ưu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tối Ưu Hóa Ngẫu Nhiên&lt;/strong&gt;: Xử lý sự bất định và ngẫu nhiên trong hàm mục tiêu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: Thêm prior xác suất để ngăn overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tối Thiểu Hóa Rủi Ro&lt;/strong&gt;: Tối ưu hóa kỳ vọng loss trên phân phối xác suất&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;các-chủ-đề-chính&quot;&gt;Các Chủ Đề Chính&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Lý Thuyết Xác Suất Cơ Bản&lt;/strong&gt;: Không gian mẫu, biến cố và tiên đề xác suất&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Các Phân Phối Xác Suất Thông Dụng&lt;/strong&gt;: Phân phối chuẩn, mũ và các phân phối quan trọng khác&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kỳ Vọng và Phương Sai&lt;/strong&gt;: Tính toán và tối ưu hóa giá trị kỳ vọng&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Định Lý Bayes&lt;/strong&gt;: Nền tảng cho tối ưu hóa và suy luận Bayes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ước Lượng Thống Kê&lt;/strong&gt;: Kết nối lý thuyết xác suất với bài toán tối ưu hóa&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;kết-nối-với-tối-ưu-hóa-lồi&quot;&gt;Kết Nối với Tối Ưu Hóa Lồi&lt;/h3&gt;

&lt;p&gt;Hiểu xác suất giúp bạn:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Xây Dựng Bài Toán&lt;/strong&gt;: Chuyển đổi sự bất định thực tế thành bài toán tối ưu hóa toán học&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Chọn Hàm Mục Tiêu&lt;/strong&gt;: Lựa chọn hàm loss phù hợp dựa trên giả thuyết xác suất&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Diễn Giải Kết Quả&lt;/strong&gt;: Hiểu khoảng tin cậy và ý nghĩa thống kê của nghiệm&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Xử Lý Nhiễu&lt;/strong&gt;: Đối phó với lỗi đo lường và quá trình ngẫu nhiên&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Thiết Kế Thuật Toán&lt;/strong&gt;: Phát triển phương pháp tối ưu hóa bền vững hoạt động dưới sự bất định&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nền tảng này sẽ rất quan trọng khi chúng ta khám phá cách các mô hình xác suất dẫn đến bài toán tối ưu hóa lồi trong học máy, thống kê và các ứng dụng kỹ thuật.&lt;/p&gt;

&lt;div style=&quot;background: #e8f4fd; padding: 15px; border-left: 4px solid #2196F3; margin: 20px 0;&quot;&gt;
&lt;strong&gt;💡 Lộ Trình Học:&lt;/strong&gt; Bắt đầu với các khái niệm xác suất cơ bản, sau đó khám phá cách chúng kết nối với tối ưu hóa thông qua ước lượng hợp lý tối đa và phương pháp Bayes. Mỗi bài học xây dựng hướng tới việc hiểu cách sự bất định và ngẫu nhiên tạo ra các bài toán tối ưu hóa.
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>00-04-02 Các Phân Phối Xác Suất Thông Dụng</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_04_02_Common_Probability_Distributions/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_04_02_Common_Probability_Distributions</id>
   <content type="html">&lt;h2 id=&quot;các-phân-phối-xác-suất-thông-dụng&quot;&gt;Các Phân Phối Xác Suất Thông Dụng&lt;/h2&gt;

&lt;p&gt;Hiểu các phân phối xác suất chính là điều thiết yếu cho các bài toán tối ưu hóa trong học máy và thống kê. Các phân phối này thường xuất hiện như giả thuyết trong mô hình, prior trong phương pháp Bayes, và mô hình lỗi trong hồi quy.&lt;/p&gt;

&lt;h3 id=&quot;1-phân-phối-rời-rạc&quot;&gt;1. Phân Phối Rời Rạc&lt;/h3&gt;

&lt;h4 id=&quot;phân-phối-bernoulli&quot;&gt;Phân Phối Bernoulli&lt;/h4&gt;

&lt;p&gt;Mô hình một thí nghiệm đơn với hai kết quả (thành công/thất bại).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham số&lt;/strong&gt;: \(p \in [0,1]\) (xác suất thành công)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = p^k (1-p)^{1-k}\) với \(k \in \{0,1\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kỳ vọng&lt;/strong&gt;: \(\mathbb{E}[X] = p\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phương sai&lt;/strong&gt;: \(\text{Var}(X) = p(1-p)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ứng dụng&lt;/strong&gt;: Phân loại nhị phân, tung đồng xu, kiểm định A/B&lt;/p&gt;

&lt;h4 id=&quot;phân-phối-nhị-thức&quot;&gt;Phân Phối Nhị Thức&lt;/h4&gt;

&lt;p&gt;Mô hình số lần thành công trong $n$ thí nghiệm Bernoulli độc lập.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham số&lt;/strong&gt;: \(n \in \mathbb{N}\) (số thí nghiệm), \(p \in [0,1]\) (xác suất thành công)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\) với \(k = 0,1,\ldots,n\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kỳ vọng&lt;/strong&gt;: \(\mathbb{E}[X] = np\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phương sai&lt;/strong&gt;: \(\text{Var}(X) = np(1-p)\)&lt;/p&gt;

&lt;h4 id=&quot;phân-phối-poisson&quot;&gt;Phân Phối Poisson&lt;/h4&gt;

&lt;p&gt;Mô hình số sự kiện trong một khoảng thời gian cố định khi các sự kiện xảy ra độc lập với tốc độ không đổi.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham số&lt;/strong&gt;: \(\lambda &amp;gt; 0\) (tham số tốc độ)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}\) với \(k = 0,1,2,\ldots\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kỳ vọng&lt;/strong&gt;: \(\mathbb{E}[X] = \lambda\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phương sai&lt;/strong&gt;: \(\text{Var}(X) = \lambda\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ứng dụng&lt;/strong&gt;: Dữ liệu đếm, sự kiện hiếm, lý thuyết hàng đợi&lt;/p&gt;

&lt;div id=&quot;discrete-distributions-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Phân Phối Rời Rạc Tương Tác&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;discreteCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Trực quan hóa:&lt;/strong&gt; Hàm khối xác suất của các phân phối rời rạc.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Loại Phân Phối&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;bernoulli&quot; checked=&quot;&quot; /&gt; Bernoulli
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;binomial&quot; /&gt; Nhị Thức
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;poisson&quot; /&gt; Poisson
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;discrete-params&quot;&gt;
                    &lt;div id=&quot;p-param&quot; style=&quot;margin-bottom: 15px;&quot;&gt;
                        &lt;label for=&quot;p-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;p: &lt;span id=&quot;p-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;p-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.5&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;n-param&quot; style=&quot;margin-bottom: 15px; display: none;&quot;&gt;
                        &lt;label for=&quot;n-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;n: &lt;span id=&quot;n-value&quot;&gt;10&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;n-slider&quot; min=&quot;5&quot; max=&quot;50&quot; step=&quot;1&quot; value=&quot;10&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;lambda-param&quot; style=&quot;margin-bottom: 15px; display: none;&quot;&gt;
                        &lt;label for=&quot;lambda-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;λ: &lt;span id=&quot;lambda-value&quot;&gt;3.0&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;lambda-slider&quot; min=&quot;0.5&quot; max=&quot;10&quot; step=&quot;0.5&quot; value=&quot;3.0&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;discrete-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Thống Kê:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Kỳ vọng: &lt;span id=&quot;discrete-mean&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Phương sai: &lt;span id=&quot;discrete-variance&quot;&gt;0.250&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Mode: &lt;span id=&quot;discrete-mode&quot;&gt;0 hoặc 1&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2-phân-phối-liên-tục&quot;&gt;2. Phân Phối Liên Tục&lt;/h3&gt;

&lt;h4 id=&quot;phân-phối-đều&quot;&gt;Phân Phối Đều&lt;/h4&gt;

&lt;p&gt;Tất cả các giá trị trong một khoảng đều có khả năng xảy ra như nhau.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham số&lt;/strong&gt;: \(a, b \in \mathbb{R}\) với \(a &amp;lt; b\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{1}{b-a}\) với \(x \in [a,b]\), 0 nếu ngược lại&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kỳ vọng&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{a+b}{2}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phương sai&lt;/strong&gt;: \(\text{Var}(X) = \frac{(b-a)^2}{12}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ứng dụng&lt;/strong&gt;: Lấy mẫu ngẫu nhiên, khởi tạo trong thuật toán&lt;/p&gt;

&lt;h4 id=&quot;phân-phối-chuẩn-gaussian&quot;&gt;Phân Phối Chuẩn (Gaussian)&lt;/h4&gt;

&lt;p&gt;Phân phối quan trọng nhất trong thống kê và tối ưu hóa.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham số&lt;/strong&gt;: \(\mu \in \mathbb{R}\) (kỳ vọng), \(\sigma^2 &amp;gt; 0\) (phương sai)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kỳ vọng&lt;/strong&gt;: \(\mathbb{E}[X] = \mu\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phương sai&lt;/strong&gt;: \(\text{Var}(X) = \sigma^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tính chất&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Đối xứng quanh \(\mu\)&lt;/li&gt;
  &lt;li&gt;Quy tắc 68-95-99.7&lt;/li&gt;
  &lt;li&gt;Định lý giới hạn trung tâm&lt;/li&gt;
  &lt;li&gt;Entropy tối đa với kỳ vọng và phương sai cho trước&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;phân-phối-mũ&quot;&gt;Phân Phối Mũ&lt;/h4&gt;

&lt;p&gt;Mô hình thời gian chờ giữa các sự kiện trong quá trình Poisson.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham số&lt;/strong&gt;: \(\lambda &amp;gt; 0\) (tham số tốc độ)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \lambda e^{-\lambda x}\) với \(x \geq 0\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kỳ vọng&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{1}{\lambda}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phương sai&lt;/strong&gt;: \(\text{Var}(X) = \frac{1}{\lambda^2}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tính chất&lt;/strong&gt;: Tính chất không nhớ&lt;/p&gt;

&lt;h4 id=&quot;phân-phối-beta&quot;&gt;Phân Phối Beta&lt;/h4&gt;

&lt;p&gt;Phân phối linh hoạt trên \([0,1]\), thường dùng để mô hình hóa xác suất.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham số&lt;/strong&gt;: \(\alpha, \beta &amp;gt; 0\) (tham số hình dạng)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha-1}(1-x)^{\beta-1}\) với \(x \in [0,1]\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kỳ vọng&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{\alpha}{\alpha+\beta}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phương sai&lt;/strong&gt;: \(\text{Var}(X) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\)&lt;/p&gt;

&lt;div id=&quot;continuous-distributions-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Phân Phối Liên Tục Tương Tác&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;continuousCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Trực quan hóa:&lt;/strong&gt; Hàm mật độ xác suất của các phân phối liên tục.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Loại Phân Phối&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;uniform&quot; checked=&quot;&quot; /&gt; Đều
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;normal&quot; /&gt; Chuẩn
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;exponential&quot; /&gt; Mũ
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;beta&quot; /&gt; Beta
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;continuous-params&quot;&gt;
                    &lt;div id=&quot;uniform-params&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;a-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;a: &lt;span id=&quot;a-value&quot;&gt;0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;a-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;b-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;b: &lt;span id=&quot;b-value&quot;&gt;1&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;b-slider&quot; min=&quot;0.5&quot; max=&quot;4&quot; step=&quot;0.1&quot; value=&quot;1&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;normal-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;mu-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;μ: &lt;span id=&quot;mu-value&quot;&gt;0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;mu-slider&quot; min=&quot;-3&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;sigma-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;σ: &lt;span id=&quot;sigma-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;sigma-slider&quot; min=&quot;0.5&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;exponential-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;exp-lambda-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;λ: &lt;span id=&quot;exp-lambda-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;exp-lambda-slider&quot; min=&quot;0.2&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;beta-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;alpha-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;α: &lt;span id=&quot;alpha-value&quot;&gt;2&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;alpha-slider&quot; min=&quot;0.5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;2&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;beta-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;β: &lt;span id=&quot;beta-value&quot;&gt;2&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;beta-slider&quot; min=&quot;0.5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;2&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;continuous-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Thống Kê:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Kỳ vọng: &lt;span id=&quot;continuous-mean&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Phương sai: &lt;span id=&quot;continuous-variance&quot;&gt;0.083&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Miền xác định: &lt;span id=&quot;continuous-support&quot;&gt;[0, 1]&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;3-phân-phối-đa-biến&quot;&gt;3. Phân Phối Đa Biến&lt;/h3&gt;

&lt;h4 id=&quot;phân-phối-chuẩn-đa-biến&quot;&gt;Phân Phối Chuẩn Đa Biến&lt;/h4&gt;

&lt;p&gt;Mở rộng của phân phối chuẩn cho nhiều chiều.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham số&lt;/strong&gt;: \(\boldsymbol{\mu} \in \mathbb{R}^d\) (vector kỳ vọng), \(\boldsymbol{\Sigma} \in \mathbb{R}^{d \times d}\) (ma trận hiệp phương sai, xác định dương)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;PDF&lt;/strong&gt;: $$f(\mathbf{x}) = \frac{1}{(2\pi)^{d/2}&lt;/td&gt;
      &lt;td&gt;\boldsymbol{\Sigma}&lt;/td&gt;
      &lt;td&gt;^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^T\boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right)$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Tính chất&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Phân phối biên là chuẩn&lt;/li&gt;
  &lt;li&gt;Tổ hợp tuyến tính là chuẩn&lt;/li&gt;
  &lt;li&gt;Phân phối có điều kiện là chuẩn&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;multivariate-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f0f8ff;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Phân Phối Chuẩn Đa Biến&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;multivariateCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Trực Quan 2D:&lt;/strong&gt; Đồ thị đường đồng mức của phân phối chuẩn hai biến. Các mẫu hiển thị dưới dạng chấm.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Tham Số&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;mu1-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;μ₁: &lt;span id=&quot;mu1-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;mu1-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;mu2-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;μ₂: &lt;span id=&quot;mu2-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;mu2-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sigma1-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;σ₁: &lt;span id=&quot;sigma1-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sigma1-slider&quot; min=&quot;0.5&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sigma2-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;σ₂: &lt;span id=&quot;sigma2-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sigma2-slider&quot; min=&quot;0.5&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;rho-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;ρ (tương quan): &lt;span id=&quot;rho-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;rho-slider&quot; min=&quot;-0.9&quot; max=&quot;0.9&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-samples&quot; style=&quot;width: 100%; padding: 10px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Tạo Mẫu&lt;/button&gt;
                
                &lt;div id=&quot;multivariate-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Ma Trận Hiệp Phương Sai:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Σ₁₁: &lt;span id=&quot;cov11&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Σ₁₂: &lt;span id=&quot;cov12&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Σ₂₂: &lt;span id=&quot;cov22&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Det(Σ): &lt;span id=&quot;det-cov&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;4-ứng-dụng-trong-tối-ưu-hóa&quot;&gt;4. Ứng Dụng trong Tối Ưu Hóa&lt;/h3&gt;

&lt;h4 id=&quot;ước-lượng-hợp-lý-tối-đa&quot;&gt;Ước Lượng Hợp Lý Tối Đa&lt;/h4&gt;
&lt;p&gt;Nhiều bài toán tối ưu hóa liên quan đến việc tìm tham số để tối đa hóa likelihood của dữ liệu quan sát dưới một phân phối cụ thể:&lt;/p&gt;

\[\hat{\theta} = \arg\max_\theta \prod_{i=1}^n f(x_i; \theta)\]

&lt;h4 id=&quot;tối-ưu-hóa-bayes&quot;&gt;Tối Ưu Hóa Bayes&lt;/h4&gt;
&lt;p&gt;Phân phối prior mã hóa niềm tin về tham số trước khi thấy dữ liệu:&lt;/p&gt;

\[p(\theta|dữ\ liệu) \propto p(dữ\ liệu|\theta) \cdot p(\theta)\]

&lt;h4 id=&quot;regularization&quot;&gt;Regularization&lt;/h4&gt;
&lt;p&gt;Phân phối có thể được sử dụng như prior để regularize bài toán tối ưu hóa:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;L2 regularization ↔ Prior Gaussian&lt;/li&gt;
  &lt;li&gt;L1 regularization ↔ Prior Laplace&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;tối-ưu-hóa-ngẫu-nhiên&quot;&gt;Tối Ưu Hóa Ngẫu Nhiên&lt;/h4&gt;
&lt;p&gt;Phân phối mô hình nhiễu và sự bất định trong hàm mục tiêu và ràng buộc.&lt;/p&gt;

&lt;h3 id=&quot;những-hiểu-biết-quan-trọng-cho-tối-ưu-hóa&quot;&gt;Những Hiểu Biết Quan Trọng cho Tối Ưu Hóa&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Lựa Chọn Mô Hình&lt;/strong&gt;: Chọn phân phối phù hợp với đặc điểm dữ liệu của bạn&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ước Lượng Tham Số&lt;/strong&gt;: Sử dụng MLE hoặc phương pháp Bayes để ước lượng tham số phân phối&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Định Lượng Sự Bất Định&lt;/strong&gt;: Phân phối cung cấp cách tự nhiên để định lượng sự bất định&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: Phân phối prior có thể ngăn overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hiệu Quả Tính Toán&lt;/strong&gt;: Một số phân phối có nghiệm dạng đóng cho các phép toán thông dụng&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hiểu các phân phối này và tính chất của chúng là quan trọng để xây dựng và giải quyết các bài toán tối ưu hóa trong học máy, thống kê và các ứng dụng kỹ thuật.&lt;/p&gt;

&lt;script&gt;
// Discrete Distributions Demo
class DiscreteDistributionsDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;discreteCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.distType = &apos;bernoulli&apos;;
        this.params = { p: 0.5, n: 10, lambda: 3.0 };
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;discrete-dist&quot;]&apos;);
        const pSlider = document.getElementById(&apos;p-slider&apos;);
        const nSlider = document.getElementById(&apos;n-slider&apos;);
        const lambdaSlider = document.getElementById(&apos;lambda-slider&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.distType = e.target.value;
                this.updateParameterVisibility();
                this.updateStats();
                this.draw();
            });
        });
        
        pSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.p = parseFloat(e.target.value);
            document.getElementById(&apos;p-value&apos;).textContent = this.params.p.toFixed(1);
            this.updateStats();
            this.draw();
        });
        
        nSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.n = parseInt(e.target.value);
            document.getElementById(&apos;n-value&apos;).textContent = this.params.n;
            this.updateStats();
            this.draw();
        });
        
        lambdaSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.lambda = parseFloat(e.target.value);
            document.getElementById(&apos;lambda-value&apos;).textContent = this.params.lambda.toFixed(1);
            this.updateStats();
            this.draw();
        });
        
        this.updateParameterVisibility();
        this.updateStats();
    }
    
    updateParameterVisibility() {
        document.getElementById(&apos;p-param&apos;).style.display = 
            (this.distType === &apos;bernoulli&apos; || this.distType === &apos;binomial&apos;) ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;n-param&apos;).style.display = 
            this.distType === &apos;binomial&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;lambda-param&apos;).style.display = 
            this.distType === &apos;poisson&apos; ? &apos;block&apos; : &apos;none&apos;;
    }
    
    updateStats() {
        let mean, variance, mode;
        
        switch(this.distType) {
            case &apos;bernoulli&apos;:
                mean = this.params.p;
                variance = this.params.p * (1 - this.params.p);
                mode = this.params.p &gt; 0.5 ? &apos;1&apos; : (this.params.p &lt; 0.5 ? &apos;0&apos; : &apos;0 hoặc 1&apos;);
                break;
            case &apos;binomial&apos;:
                mean = this.params.n * this.params.p;
                variance = this.params.n * this.params.p * (1 - this.params.p);
                mode = Math.floor((this.params.n + 1) * this.params.p).toString();
                break;
            case &apos;poisson&apos;:
                mean = this.params.lambda;
                variance = this.params.lambda;
                mode = Math.floor(this.params.lambda).toString();
                break;
        }
        
        document.getElementById(&apos;discrete-mean&apos;).textContent = mean.toFixed(3);
        document.getElementById(&apos;discrete-variance&apos;).textContent = variance.toFixed(3);
        document.getElementById(&apos;discrete-mode&apos;).textContent = mode;
    }
    
    factorial(n) {
        if (n &lt;= 1) return 1;
        return n * this.factorial(n - 1);
    }
    
    binomialCoeff(n, k) {
        if (k &gt; n) return 0;
        return this.factorial(n) / (this.factorial(k) * this.factorial(n - k));
    }
    
    getProbability(k) {
        switch(this.distType) {
            case &apos;bernoulli&apos;:
                return k === 0 ? (1 - this.params.p) : (k === 1 ? this.params.p : 0);
            case &apos;binomial&apos;:
                if (k &lt; 0 || k &gt; this.params.n) return 0;
                return this.binomialCoeff(this.params.n, k) * 
                       Math.pow(this.params.p, k) * 
                       Math.pow(1 - this.params.p, this.params.n - k);
            case &apos;poisson&apos;:
                if (k &lt; 0) return 0;
                return Math.pow(this.params.lambda, k) * Math.exp(-this.params.lambda) / this.factorial(k);
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Determine range
        let maxK;
        switch(this.distType) {
            case &apos;bernoulli&apos;: maxK = 1; break;
            case &apos;binomial&apos;: maxK = this.params.n; break;
            case &apos;poisson&apos;: maxK = Math.min(20, this.params.lambda + 3 * Math.sqrt(this.params.lambda)); break;
        }
        
        // Find max probability for scaling
        let maxProb = 0;
        for (let k = 0; k &lt;= maxK; k++) {
            maxProb = Math.max(maxProb, this.getProbability(k));
        }
        
        // Draw bars
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        const barWidth = plotWidth / (maxK + 2);
        
        for (let k = 0; k &lt;= maxK; k++) {
            const prob = this.getProbability(k);
            const x = marginX + (k + 0.5) * barWidth;
            const height = (prob / maxProb) * plotHeight * 0.8;
            const y = this.height - marginY - height;
            
            this.ctx.fillRect(x - barWidth * 0.3, y, barWidth * 0.6, height);
            
            // Label
            this.ctx.fillStyle = &apos;#000&apos;;
            this.ctx.font = &apos;10px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(k.toString(), x, this.height - marginY + 15);
            this.ctx.fillText(prob.toFixed(3), x, y - 5);
            this.ctx.fillStyle = &apos;#2196f3&apos;;
        }
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;k&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;P(X = k)&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Continuous Distributions Demo
class ContinuousDistributionsDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;continuousCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.distType = &apos;uniform&apos;;
        this.params = { a: 0, b: 1, mu: 0, sigma: 1, lambda: 1, alpha: 2, beta: 2 };
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;continuous-dist&quot;]&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.distType = e.target.value;
                this.updateParameterVisibility();
                this.updateStats();
                this.draw();
            });
        });
        
        // Setup all sliders
        const sliders = [&apos;a&apos;, &apos;b&apos;, &apos;mu&apos;, &apos;sigma&apos;, &apos;exp-lambda&apos;, &apos;alpha&apos;, &apos;beta&apos;];
        sliders.forEach(slider =&gt; {
            const element = document.getElementById(slider + &apos;-slider&apos;);
            if (element) {
                element.addEventListener(&apos;input&apos;, (e) =&gt; {
                    const value = parseFloat(e.target.value);
                    const param = slider === &apos;exp-lambda&apos; ? &apos;lambda&apos; : slider;
                    this.params[param] = value;
                    
                    const valueSpan = document.getElementById(slider + &apos;-value&apos;);
                    if (valueSpan) {
                        valueSpan.textContent = value.toFixed(1);
                    }
                    
                    this.updateStats();
                    this.draw();
                });
            }
        });
        
        this.updateParameterVisibility();
        this.updateStats();
    }
    
    updateParameterVisibility() {
        document.getElementById(&apos;uniform-params&apos;).style.display = 
            this.distType === &apos;uniform&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;normal-params&apos;).style.display = 
            this.distType === &apos;normal&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;exponential-params&apos;).style.display = 
            this.distType === &apos;exponential&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;beta-params&apos;).style.display = 
            this.distType === &apos;beta&apos; ? &apos;block&apos; : &apos;none&apos;;
    }
    
    updateStats() {
        let mean, variance, support;
        
        switch(this.distType) {
            case &apos;uniform&apos;:
                mean = (this.params.a + this.params.b) / 2;
                variance = Math.pow(this.params.b - this.params.a, 2) / 12;
                support = `[${this.params.a}, ${this.params.b}]`;
                break;
            case &apos;normal&apos;:
                mean = this.params.mu;
                variance = this.params.sigma * this.params.sigma;
                support = &apos;(-∞, ∞)&apos;;
                break;
            case &apos;exponential&apos;:
                mean = 1 / this.params.lambda;
                variance = 1 / (this.params.lambda * this.params.lambda);
                support = &apos;[0, ∞)&apos;;
                break;
            case &apos;beta&apos;:
                mean = this.params.alpha / (this.params.alpha + this.params.beta);
                variance = (this.params.alpha * this.params.beta) / 
                          (Math.pow(this.params.alpha + this.params.beta, 2) * 
                           (this.params.alpha + this.params.beta + 1));
                support = &apos;[0, 1]&apos;;
                break;
        }
        
        document.getElementById(&apos;continuous-mean&apos;).textContent = mean.toFixed(3);
        document.getElementById(&apos;continuous-variance&apos;).textContent = variance.toFixed(3);
        document.getElementById(&apos;continuous-support&apos;).textContent = support;
    }
    
    gamma(z) {
        // Stirling&apos;s approximation for gamma function
        if (z &lt; 0.5) return Math.PI / (Math.sin(Math.PI * z) * this.gamma(1 - z));
        z -= 1;
        let x = 0.99999999999980993;
        const p = [676.5203681218851, -1259.1392167224028, 771.32342877765313,
                  -176.61502916214059, 12.507343278686905, -0.13857109526572012,
                  9.9843695780195716e-6, 1.5056327351493116e-7];
        for (let i = 0; i &lt; p.length; i++) {
            x += p[i] / (z + i + 1);
        }
        const t = z + p.length - 0.5;
        return Math.sqrt(2 * Math.PI) * Math.pow(t, z + 0.5) * Math.exp(-t) * x;
    }
    
    getPDF(x) {
        switch(this.distType) {
            case &apos;uniform&apos;:
                return (x &gt;= this.params.a &amp;&amp; x &lt;= this.params.b) ? 
                       1 / (this.params.b - this.params.a) : 0;
            case &apos;normal&apos;:
                return Math.exp(-0.5 * Math.pow((x - this.params.mu) / this.params.sigma, 2)) / 
                       (this.params.sigma * Math.sqrt(2 * Math.PI));
            case &apos;exponential&apos;:
                return x &gt;= 0 ? this.params.lambda * Math.exp(-this.params.lambda * x) : 0;
            case &apos;beta&apos;:
                if (x &lt; 0 || x &gt; 1) return 0;
                const B = this.gamma(this.params.alpha) * this.gamma(this.params.beta) / 
                         this.gamma(this.params.alpha + this.params.beta);
                return Math.pow(x, this.params.alpha - 1) * Math.pow(1 - x, this.params.beta - 1) / B;
        }
    }
    
    getRange() {
        switch(this.distType) {
            case &apos;uniform&apos;: return [this.params.a - 0.5, this.params.b + 0.5];
            case &apos;normal&apos;: return [this.params.mu - 4 * this.params.sigma, this.params.mu + 4 * this.params.sigma];
            case &apos;exponential&apos;: return [0, 5 / this.params.lambda];
            case &apos;beta&apos;: return [0, 1];
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        const [minX, maxX] = this.getRange();
        
        // Find max PDF for scaling
        let maxPDF = 0;
        for (let i = 0; i &lt;= 200; i++) {
            const x = minX + (maxX - minX) * i / 200;
            maxPDF = Math.max(maxPDF, this.getPDF(x));
        }
        
        // Draw PDF curve
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let i = 0; i &lt;= 200; i++) {
            const x = minX + (maxX - minX) * i / 200;
            const pdf = this.getPDF(x);
            const plotX = marginX + (x - minX) / (maxX - minX) * plotWidth;
            const plotY = this.height - marginY - (pdf / maxPDF) * plotHeight * 0.8;
            
            if (i === 0) {
                this.ctx.moveTo(plotX, plotY);
            } else {
                this.ctx.lineTo(plotX, plotY);
            }
        }
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;x&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;f(x)&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Multivariate Normal Demo
class MultivariateDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;multivariateCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.params = { mu1: 0, mu2: 0, sigma1: 1, sigma2: 1, rho: 0 };
        this.samples = [];
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const sliders = [&apos;mu1&apos;, &apos;mu2&apos;, &apos;sigma1&apos;, &apos;sigma2&apos;, &apos;rho&apos;];
        
        sliders.forEach(slider =&gt; {
            const element = document.getElementById(slider + &apos;-slider&apos;);
            element.addEventListener(&apos;input&apos;, (e) =&gt; {
                this.params[slider] = parseFloat(e.target.value);
                document.getElementById(slider + &apos;-value&apos;).textContent = this.params[slider].toFixed(1);
                this.updateStats();
                this.draw();
            });
        });
        
        document.getElementById(&apos;generate-samples&apos;).addEventListener(&apos;click&apos;, () =&gt; {
            this.generateSamples();
            this.draw();
        });
        
        this.updateStats();
    }
    
    updateStats() {
        const cov11 = this.params.sigma1 * this.params.sigma1;
        const cov12 = this.params.rho * this.params.sigma1 * this.params.sigma2;
        const cov22 = this.params.sigma2 * this.params.sigma2;
        const det = cov11 * cov22 - cov12 * cov12;
        
        document.getElementById(&apos;cov11&apos;).textContent = cov11.toFixed(3);
        document.getElementById(&apos;cov12&apos;).textContent = cov12.toFixed(3);
        document.getElementById(&apos;cov22&apos;).textContent = cov22.toFixed(3);
        document.getElementById(&apos;det-cov&apos;).textContent = det.toFixed(3);
    }
    
    generateSamples() {
        this.samples = [];
        const n = 100;
        
        for (let i = 0; i &lt; n; i++) {
            // Box-Muller transform
            const u1 = Math.random();
            const u2 = Math.random();
            const z1 = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
            const z2 = Math.sqrt(-2 * Math.log(u1)) * Math.sin(2 * Math.PI * u2);
            
            // Transform to correlated normal
            const x1 = this.params.mu1 + this.params.sigma1 * z1;
            const x2 = this.params.mu2 + this.params.sigma2 * (this.params.rho * z1 + Math.sqrt(1 - this.params.rho * this.params.rho) * z2);
            
            this.samples.push([x1, x2]);
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Draw contour ellipses
        const levels = [0.5, 1, 1.5, 2];
        const colors = [&apos;#ff9999&apos;, &apos;#ff6666&apos;, &apos;#ff3333&apos;, &apos;#ff0000&apos;];
        
        levels.forEach((level, idx) =&gt; {
            this.ctx.strokeStyle = colors[idx];
            this.ctx.lineWidth = 1;
            this.ctx.beginPath();
            
            const a = level * this.params.sigma1;
            const b = level * this.params.sigma2;
            const angle = 0.5 * Math.atan2(2 * this.params.rho * this.params.sigma1 * this.params.sigma2,
                                          this.params.sigma1 * this.params.sigma1 - this.params.sigma2 * this.params.sigma2);
            
            for (let i = 0; i &lt;= 100; i++) {
                const t = 2 * Math.PI * i / 100;
                const x = a * Math.cos(t) * Math.cos(angle) - b * Math.sin(t) * Math.sin(angle) + this.params.mu1;
                const y = a * Math.cos(t) * Math.sin(angle) + b * Math.sin(t) * Math.cos(angle) + this.params.mu2;
                
                const plotX = marginX + (x + 4) / 8 * plotWidth;
                const plotY = this.height - marginY - (y + 4) / 8 * plotHeight;
                
                if (i === 0) {
                    this.ctx.moveTo(plotX, plotY);
                } else {
                    this.ctx.lineTo(plotX, plotY);
                }
            }
            this.ctx.stroke();
        });
        
        // Draw samples
        if (this.samples.length &gt; 0) {
            this.ctx.fillStyle = &apos;#2196f3&apos;;
            this.samples.forEach(([x1, x2]) =&gt; {
                const plotX = marginX + (x1 + 4) / 8 * plotWidth;
                const plotY = this.height - marginY - (x2 + 4) / 8 * plotHeight;
                
                if (plotX &gt;= marginX &amp;&amp; plotX &lt;= this.width - marginX &amp;&amp;
                    plotY &gt;= marginY &amp;&amp; plotY &lt;= this.height - marginY) {
                    this.ctx.beginPath();
                    this.ctx.arc(plotX, plotY, 2, 0, 2 * Math.PI);
                    this.ctx.fill();
                }
            });
        }
        
        // Draw mean point
        const meanX = marginX + (this.params.mu1 + 4) / 8 * plotWidth;
        const meanY = this.height - marginY - (this.params.mu2 + 4) / 8 * plotHeight;
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.beginPath();
        this.ctx.arc(meanX, meanY, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;X₁&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;X₂&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new DiscreteDistributionsDemo();
    new ContinuousDistributionsDemo();
    new MultivariateDemo();
});
&lt;/script&gt;

&lt;style&gt;
input[type=&quot;range&quot;] {
    -webkit-appearance: none;
    appearance: none;
    height: 5px;
    background: #ddd;
    outline: none;
    border-radius: 5px;
}

input[type=&quot;range&quot;]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
}

input[type=&quot;range&quot;]::-moz-range-thumb {
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
    border: none;
}

canvas {
    border-radius: 5px;
}

.demo-container {
    margin: 20px 0;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>00-04-01 Lý Thuyết Xác Suất Cơ Bản</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_04_01_Basic_Probability_Theory/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_04_01_Basic_Probability_Theory</id>
   <content type="html">&lt;h2 id=&quot;lý-thuyết-xác-suất-cơ-bản&quot;&gt;Lý Thuyết Xác Suất Cơ Bản&lt;/h2&gt;

&lt;p&gt;Lý thuyết xác suất cung cấp khung toán học để lý luận về sự bất định, điều này là nền tảng cho nhiều bài toán tối ưu hóa trong học máy và khoa học dữ liệu.&lt;/p&gt;

&lt;h3 id=&quot;1-không-gian-mẫu-và-biến-cố&quot;&gt;1. Không Gian Mẫu và Biến Cố&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Không Gian Mẫu (Ω)&lt;/strong&gt;: Tập hợp tất cả các kết quả có thể có của một thí nghiệm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Biến Cố (A)&lt;/strong&gt;: Một tập con của không gian mẫu đại diện cho một tập hợp các kết quả.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Tung đồng xu: Ω = {S, N}&lt;/li&gt;
  &lt;li&gt;Tung xúc xắc: Ω = {1, 2, 3, 4, 5, 6}&lt;/li&gt;
  &lt;li&gt;Liên tục: Ω = [0, 1] cho biến ngẫu nhiên đều&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;sample-space-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Trực Quan Hóa Không Gian Mẫu Tương Tác&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;sampleSpaceCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Trực quan hóa:&lt;/strong&gt; Nhấp để tạo mẫu ngẫu nhiên. Các màu khác nhau đại diện cho các biến cố khác nhau.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Loại Thí Nghiệm&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;coin&quot; checked=&quot;&quot; /&gt; Tung Đồng Xu
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;dice&quot; /&gt; Tung Xúc Xắc
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;uniform&quot; /&gt; Đều [0,1]
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-sample&quot; style=&quot;width: 100%; padding: 10px; background: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 10px;&quot;&gt;Tạo Mẫu&lt;/button&gt;
                &lt;button id=&quot;clear-samples&quot; style=&quot;width: 100%; padding: 8px; background: #6c757d; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Xóa&lt;/button&gt;
                
                &lt;div id=&quot;sample-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Thống Kê:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Tổng mẫu: &lt;span id=&quot;total-samples&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Biến cố A: &lt;span id=&quot;event-a-count&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Biến cố B: &lt;span id=&quot;event-b-count&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A) ≈ &lt;span id=&quot;prob-a&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B) ≈ &lt;span id=&quot;prob-b&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2-tiên-đề-xác-suất-tiên-đề-kolmogorov&quot;&gt;2. Tiên Đề Xác Suất (Tiên Đề Kolmogorov)&lt;/h3&gt;

&lt;p&gt;Với bất kỳ độ đo xác suất P nào, các tiên đề sau phải được thỏa mãn:&lt;/p&gt;

&lt;h4 id=&quot;tiên-đề-1-tính-không-âm&quot;&gt;Tiên Đề 1: Tính Không Âm&lt;/h4&gt;
&lt;p&gt;\(P(A) \geq 0 \text{ với mọi biến cố } A\)&lt;/p&gt;

&lt;h4 id=&quot;tiên-đề-2-chuẩn-hóa&quot;&gt;Tiên Đề 2: Chuẩn Hóa&lt;/h4&gt;
&lt;p&gt;\(P(\Omega) = 1\)&lt;/p&gt;

&lt;h4 id=&quot;tiên-đề-3-tính-cộng-đếm-được&quot;&gt;Tiên Đề 3: Tính Cộng Đếm Được&lt;/h4&gt;
&lt;p&gt;Với các biến cố xung khắc \(A_1, A_2, \ldots\):
\(P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)\)&lt;/p&gt;

&lt;h3 id=&quot;3-tính-chất-và-quy-tắc-cơ-bản&quot;&gt;3. Tính Chất và Quy Tắc Cơ Bản&lt;/h3&gt;

&lt;h4 id=&quot;quy-tắc-phần-bù&quot;&gt;Quy Tắc Phần Bù&lt;/h4&gt;
&lt;p&gt;\(P(A^c) = 1 - P(A)\)&lt;/p&gt;

&lt;h4 id=&quot;quy-tắc-cộng&quot;&gt;Quy Tắc Cộng&lt;/h4&gt;
&lt;p&gt;Với hai biến cố A và B bất kỳ:
\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)&lt;/p&gt;

&lt;h4 id=&quot;quy-tắc-nhân&quot;&gt;Quy Tắc Nhân&lt;/h4&gt;
&lt;p&gt;\(P(A \cap B) = P(A|B) \cdot P(B) = P(B|A) \cdot P(A)\)&lt;/p&gt;

&lt;h3 id=&quot;4-xác-suất-có-điều-kiện&quot;&gt;4. Xác Suất Có Điều Kiện&lt;/h3&gt;

&lt;p&gt;Xác suất của biến cố A khi biết rằng biến cố B đã xảy ra:&lt;/p&gt;

\[P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) &amp;gt; 0\]

&lt;p&gt;&lt;strong&gt;Diễn giải&lt;/strong&gt;: Xác suất có điều kiện cập nhật niềm tin của chúng ta về A khi có thông tin về B.&lt;/p&gt;

&lt;div id=&quot;conditional-prob-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Trực Quan Hóa Xác Suất Có Điều Kiện&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;conditionalCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Biểu Đồ Venn:&lt;/strong&gt; Hình tròn xanh là biến cố A, hình tròn đỏ là biến cố B. Giao màu tím thể hiện A ∩ B.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Điều Chỉnh Xác Suất&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;prob-a-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;P(A): &lt;span id=&quot;prob-a-value&quot;&gt;0.4&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;prob-a-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.4&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;prob-b-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;P(B): &lt;span id=&quot;prob-b-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;prob-b-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.5&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;overlap-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Giao: &lt;span id=&quot;overlap-value&quot;&gt;0.2&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;overlap-slider&quot; min=&quot;0&quot; max=&quot;0.4&quot; step=&quot;0.05&quot; value=&quot;0.2&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;conditional-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Xác Suất:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;P(A) = &lt;span id=&quot;display-prob-a&quot;&gt;0.400&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B) = &lt;span id=&quot;display-prob-b&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A ∩ B) = &lt;span id=&quot;display-prob-ab&quot;&gt;0.200&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A ∪ B) = &lt;span id=&quot;display-prob-union&quot;&gt;0.700&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;Có Điều Kiện:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;P(A|B) = &lt;span id=&quot;display-prob-a-given-b&quot;&gt;0.400&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B|A) = &lt;span id=&quot;display-prob-b-given-a&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;5-tính-độc-lập&quot;&gt;5. Tính Độc Lập&lt;/h3&gt;

&lt;p&gt;Hai biến cố A và B &lt;strong&gt;độc lập&lt;/strong&gt; nếu:
\(P(A \cap B) = P(A) \cdot P(B)\)&lt;/p&gt;

&lt;p&gt;Tương đương:
\(P(A|B) = P(A) \quad \text{và} \quad P(B|A) = P(B)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Diễn giải&lt;/strong&gt;: Kiến thức về một biến cố không thay đổi xác suất của biến cố kia.&lt;/p&gt;

&lt;h3 id=&quot;6-biến-ngẫu-nhiên&quot;&gt;6. Biến Ngẫu Nhiên&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Biến ngẫu nhiên&lt;/strong&gt; X là một hàm gán một số thực cho mỗi kết quả trong không gian mẫu:
\(X: \Omega \rightarrow \mathbb{R}\)&lt;/p&gt;

&lt;h4 id=&quot;các-loại-biến-ngẫu-nhiên&quot;&gt;Các Loại Biến Ngẫu Nhiên:&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Rời rạc&lt;/strong&gt;: Nhận các giá trị đếm được (ví dụ: số lần xuất hiện mặt sấp)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hàm Khối Xác Suất (PMF): \(P(X = x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Liên tục&lt;/strong&gt;: Nhận các giá trị không đếm được (ví dụ: chiều cao, cân nặng)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hàm Mật Độ Xác Suất (PDF): \(f_X(x)\)&lt;/li&gt;
  &lt;li&gt;
\[P(a \leq X \leq b) = \int_a^b f_X(x) dx\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;7-kết-nối-với-tối-ưu-hóa&quot;&gt;7. Kết Nối với Tối Ưu Hóa&lt;/h3&gt;

&lt;p&gt;Lý thuyết xác suất kết nối với tối ưu hóa theo nhiều cách:&lt;/p&gt;

&lt;h4 id=&quot;ước-lượng-hợp-lý-tối-đa&quot;&gt;Ước Lượng Hợp Lý Tối Đa&lt;/h4&gt;
&lt;p&gt;Tìm tham số θ để tối đa hóa likelihood:
\(\hat{\theta} = \arg\max_\theta P(\text{dữ liệu}|\theta)\)&lt;/p&gt;

&lt;h4 id=&quot;tối-ưu-hóa-giá-trị-kỳ-vọng&quot;&gt;Tối Ưu Hóa Giá Trị Kỳ Vọng&lt;/h4&gt;
&lt;p&gt;Tối thiểu hóa kỳ vọng loss:
\(\min_\theta \mathbb{E}[L(Y, f(X; \theta))]\)&lt;/p&gt;

&lt;h4 id=&quot;tối-ưu-hóa-bayes&quot;&gt;Tối Ưu Hóa Bayes&lt;/h4&gt;
&lt;p&gt;Sử dụng phân phối xác suất để mô hình hóa sự bất định trong hàm mục tiêu và hướng dẫn tìm kiếm nghiệm tối ưu.&lt;/p&gt;

&lt;div id=&quot;optimization-connection&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f0f8ff;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Ví Dụ Xác Suất trong Tối Ưu Hóa&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;optimizationCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Ví Dụ MLE:&lt;/strong&gt; Tìm tham số μ để tối đa hóa likelihood của dữ liệu quan sát từ Normal(μ, 1).
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Demo MLE&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;true-mu-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;μ Thực: &lt;span id=&quot;true-mu-value&quot;&gt;2.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;true-mu-slider&quot; min=&quot;-2&quot; max=&quot;4&quot; step=&quot;0.1&quot; value=&quot;2.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sample-size-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Kích Thước Mẫu: &lt;span id=&quot;sample-size-value&quot;&gt;20&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sample-size-slider&quot; min=&quot;5&quot; max=&quot;100&quot; step=&quot;5&quot; value=&quot;20&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-mle-data&quot; style=&quot;width: 100%; padding: 10px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Tạo Dữ Liệu &amp;amp; Tìm MLE&lt;/button&gt;
                
                &lt;div id=&quot;mle-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Kết Quả:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;μ Thực: &lt;span id=&quot;display-true-mu&quot;&gt;2.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Trung bình mẫu: &lt;span id=&quot;sample-mean&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Ước lượng MLE: &lt;span id=&quot;mle-estimate&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Sai số: &lt;span id=&quot;mle-error&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;những-điểm-chính&quot;&gt;Những Điểm Chính&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Nền Tảng&lt;/strong&gt;: Tiên đề xác suất cung cấp nền tảng toán học để lý luận về sự bất định&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Xác Suất Có Điều Kiện&lt;/strong&gt;: Thiết yếu để cập nhật niềm tin với thông tin mới&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tính Độc Lập&lt;/strong&gt;: Đơn giản hóa tính toán và giả thuyết mô hình hóa&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Biến Ngẫu Nhiên&lt;/strong&gt;: Cầu nối giữa xác suất trừu tượng và ứng dụng cụ thể&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kết Nối Tối Ưu Hóa&lt;/strong&gt;: Nhiều bài toán tối ưu hóa phát sinh từ mô hình hóa xác suất&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hiểu những khái niệm cơ bản này chuẩn bị cho bạn các chủ đề nâng cao hơn như suy luận Bayes, ước lượng hợp lý tối đa và tối ưu hóa ngẫu nhiên - những yếu tố trung tâm của học máy và khoa học dữ liệu hiện đại.&lt;/p&gt;

&lt;script&gt;
// Sample Space Visualization
class SampleSpaceDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;sampleSpaceCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.samples = [];
        this.experimentType = &apos;coin&apos;;
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;experiment&quot;]&apos;);
        const generateBtn = document.getElementById(&apos;generate-sample&apos;);
        const clearBtn = document.getElementById(&apos;clear-samples&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.experimentType = e.target.value;
                this.samples = [];
                this.updateStats();
                this.draw();
            });
        });
        
        generateBtn.addEventListener(&apos;click&apos;, () =&gt; this.generateSample());
        clearBtn.addEventListener(&apos;click&apos;, () =&gt; {
            this.samples = [];
            this.updateStats();
            this.draw();
        });
        
        this.canvas.addEventListener(&apos;click&apos;, () =&gt; this.generateSample());
    }
    
    generateSample() {
        let sample;
        
        switch(this.experimentType) {
            case &apos;coin&apos;:
                sample = {
                    value: Math.random() &lt; 0.5 ? &apos;S&apos; : &apos;N&apos;,
                    x: Math.random() * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: Math.random() &lt; 0.5, // Biến cố A: Sấp
                    eventB: Math.random() &lt; 0.3  // Biến cố B: May mắn
                };
                break;
            case &apos;dice&apos;:
                const diceValue = Math.floor(Math.random() * 6) + 1;
                sample = {
                    value: diceValue,
                    x: Math.random() * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: diceValue &gt;= 4, // Biến cố A: 4, 5, hoặc 6
                    eventB: diceValue % 2 === 0 // Biến cố B: Chẵn
                };
                break;
            case &apos;uniform&apos;:
                const uniformValue = Math.random();
                sample = {
                    value: uniformValue.toFixed(3),
                    x: uniformValue * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: uniformValue &gt; 0.5, // Biến cố A: &gt; 0.5
                    eventB: uniformValue &lt; 0.7  // Biến cố B: &lt; 0.7
                };
                break;
        }
        
        this.samples.push(sample);
        this.updateStats();
        this.draw();
    }
    
    updateStats() {
        const total = this.samples.length;
        const eventACount = this.samples.filter(s =&gt; s.eventA).length;
        const eventBCount = this.samples.filter(s =&gt; s.eventB).length;
        
        document.getElementById(&apos;total-samples&apos;).textContent = total;
        document.getElementById(&apos;event-a-count&apos;).textContent = eventACount;
        document.getElementById(&apos;event-b-count&apos;).textContent = eventBCount;
        document.getElementById(&apos;prob-a&apos;).textContent = total &gt; 0 ? (eventACount / total).toFixed(3) : &apos;0.000&apos;;
        document.getElementById(&apos;prob-b&apos;).textContent = total &gt; 0 ? (eventBCount / total).toFixed(3) : &apos;0.000&apos;;
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        // Draw background
        this.ctx.fillStyle = &apos;#f8f9fa&apos;;
        this.ctx.fillRect(0, 0, this.width, this.height);
        
        // Draw samples
        this.samples.forEach(sample =&gt; {
            // Determine color based on events
            let color = &apos;#666&apos;;
            if (sample.eventA &amp;&amp; sample.eventB) color = &apos;#9c27b0&apos;; // Cả hai biến cố
            else if (sample.eventA) color = &apos;#2196f3&apos;; // Chỉ biến cố A
            else if (sample.eventB) color = &apos;#f44336&apos;; // Chỉ biến cố B
            
            this.ctx.fillStyle = color;
            this.ctx.beginPath();
            this.ctx.arc(sample.x, sample.y, 5, 0, 2 * Math.PI);
            this.ctx.fill();
            
            // Draw value
            this.ctx.fillStyle = &apos;#000&apos;;
            this.ctx.font = &apos;10px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(sample.value, sample.x, sample.y - 8);
        });
        
        // Draw legend
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;left&apos;;
        this.ctx.fillText(&apos;Chú thích:&apos;, 10, 20);
        
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 35, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Chỉ biến cố A&apos;, 30, 38);
        
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 50, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Chỉ biến cố B&apos;, 30, 53);
        
        this.ctx.fillStyle = &apos;#9c27b0&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 65, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Cả A và B&apos;, 30, 68);
    }
}

// Conditional Probability Visualization
class ConditionalProbDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;conditionalCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.probA = 0.4;
        this.probB = 0.5;
        this.overlap = 0.2;
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const probASlider = document.getElementById(&apos;prob-a-slider&apos;);
        const probBSlider = document.getElementById(&apos;prob-b-slider&apos;);
        const overlapSlider = document.getElementById(&apos;overlap-slider&apos;);
        
        probASlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.probA = parseFloat(e.target.value);
            document.getElementById(&apos;prob-a-value&apos;).textContent = this.probA.toFixed(1);
            this.updateCalculations();
            this.draw();
        });
        
        probBSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.probB = parseFloat(e.target.value);
            document.getElementById(&apos;prob-b-value&apos;).textContent = this.probB.toFixed(1);
            this.updateCalculations();
            this.draw();
        });
        
        overlapSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.overlap = parseFloat(e.target.value);
            document.getElementById(&apos;overlap-value&apos;).textContent = this.overlap.toFixed(1);
            // Ensure overlap doesn&apos;t exceed min(probA, probB)
            const maxOverlap = Math.min(this.probA, this.probB);
            if (this.overlap &gt; maxOverlap) {
                this.overlap = maxOverlap;
                overlapSlider.value = this.overlap;
                document.getElementById(&apos;overlap-value&apos;).textContent = this.overlap.toFixed(1);
            }
            this.updateCalculations();
            this.draw();
        });
        
        this.updateCalculations();
    }
    
    updateCalculations() {
        const probUnion = this.probA + this.probB - this.overlap;
        const probAGivenB = this.probB &gt; 0 ? this.overlap / this.probB : 0;
        const probBGivenA = this.probA &gt; 0 ? this.overlap / this.probA : 0;
        
        document.getElementById(&apos;display-prob-a&apos;).textContent = this.probA.toFixed(3);
        document.getElementById(&apos;display-prob-b&apos;).textContent = this.probB.toFixed(3);
        document.getElementById(&apos;display-prob-ab&apos;).textContent = this.overlap.toFixed(3);
        document.getElementById(&apos;display-prob-union&apos;).textContent = probUnion.toFixed(3);
        document.getElementById(&apos;display-prob-a-given-b&apos;).textContent = probAGivenB.toFixed(3);
        document.getElementById(&apos;display-prob-b-given-a&apos;).textContent = probBGivenA.toFixed(3);
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        // Draw universe rectangle
        this.ctx.strokeStyle = &apos;#000&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.strokeRect(50, 50, 300, 200);
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;14px Arial&apos;;
        this.ctx.fillText(&apos;Ω (Không gian mẫu)&apos;, 55, 45);
        
        // Calculate circle parameters
        const centerAX = 150;
        const centerAY = 150;
        const centerBX = 250;
        const centerBY = 150;
        
        // Calculate radii based on probabilities (area proportional to probability)
        const radiusA = Math.sqrt(this.probA * 10000 / Math.PI);
        const radiusB = Math.sqrt(this.probB * 10000 / Math.PI);
        
        // Draw circle A
        this.ctx.globalAlpha = 0.3;
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerAX, centerAY, radiusA, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Draw circle B
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerBX, centerBY, radiusB, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Draw intersection (approximate)
        if (this.overlap &gt; 0) {
            this.ctx.fillStyle = &apos;#9c27b0&apos;;
            const overlapRadius = Math.sqrt(this.overlap * 5000 / Math.PI);
            this.ctx.beginPath();
            this.ctx.arc((centerAX + centerBX) / 2, (centerAY + centerBY) / 2, overlapRadius, 0, 2 * Math.PI);
            this.ctx.fill();
        }
        
        this.ctx.globalAlpha = 1.0;
        
        // Draw circle outlines
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.arc(centerAX, centerAY, radiusA, 0, 2 * Math.PI);
        this.ctx.stroke();
        
        this.ctx.strokeStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerBX, centerBY, radiusB, 0, 2 * Math.PI);
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;16px Arial&apos;;
        this.ctx.fillText(&apos;A&apos;, centerAX - 40, centerAY);
        this.ctx.fillText(&apos;B&apos;, centerBX + 30, centerBY);
        
        if (this.overlap &gt; 0) {
            this.ctx.fillText(&apos;A∩B&apos;, (centerAX + centerBX) / 2 - 15, (centerAY + centerBY) / 2 + 5);
        }
    }
}

// MLE Optimization Demo
class MLEDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;optimizationCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.trueMu = 2.0;
        this.sampleSize = 20;
        this.data = [];
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const trueMuSlider = document.getElementById(&apos;true-mu-slider&apos;);
        const sampleSizeSlider = document.getElementById(&apos;sample-size-slider&apos;);
        const generateBtn = document.getElementById(&apos;generate-mle-data&apos;);
        
        trueMuSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.trueMu = parseFloat(e.target.value);
            document.getElementById(&apos;true-mu-value&apos;).textContent = this.trueMu.toFixed(1);
            document.getElementById(&apos;display-true-mu&apos;).textContent = this.trueMu.toFixed(3);
        });
        
        sampleSizeSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.sampleSize = parseInt(e.target.value);
            document.getElementById(&apos;sample-size-value&apos;).textContent = this.sampleSize;
        });
        
        generateBtn.addEventListener(&apos;click&apos;, () =&gt; this.generateDataAndFindMLE());
    }
    
    generateDataAndFindMLE() {
        // Generate data from Normal(trueMu, 1)
        this.data = [];
        for (let i = 0; i &lt; this.sampleSize; i++) {
            // Box-Muller transform for normal distribution
            const u1 = Math.random();
            const u2 = Math.random();
            const z = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
            this.data.push(this.trueMu + z); // Normal(trueMu, 1)
        }
        
        // Calculate MLE (sample mean for normal distribution)
        const sampleMean = this.data.reduce((sum, x) =&gt; sum + x, 0) / this.data.length;
        const error = Math.abs(sampleMean - this.trueMu);
        
        // Update display
        document.getElementById(&apos;sample-mean&apos;).textContent = sampleMean.toFixed(3);
        document.getElementById(&apos;mle-estimate&apos;).textContent = sampleMean.toFixed(3);
        document.getElementById(&apos;mle-error&apos;).textContent = error.toFixed(3);
        
        this.draw();
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        if (this.data.length === 0) {
            this.ctx.fillStyle = &apos;#666&apos;;
            this.ctx.font = &apos;16px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(&apos;Nhấp &quot;Tạo Dữ Liệu &amp; Tìm MLE&quot; để bắt đầu&apos;, this.width / 2, this.height / 2);
            return;
        }
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // X-axis
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Y-axis
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Find data range
        const minX = Math.min(...this.data) - 1;
        const maxX = Math.max(...this.data) + 1;
        
        // Draw likelihood function
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let i = 0; i &lt;= 100; i++) {
            const mu = minX + (maxX - minX) * i / 100;
            let logLikelihood = 0;
            
            // Calculate log-likelihood
            for (const x of this.data) {
                logLikelihood -= 0.5 * Math.log(2 * Math.PI);
                logLikelihood -= 0.5 * (x - mu) * (x - mu);
            }
            
            const x = marginX + (mu - minX) / (maxX - minX) * plotWidth;
            const y = this.height - marginY - (logLikelihood - (-this.data.length * 2)) / (this.data.length) * plotHeight * 0.8;
            
            if (i === 0) {
                this.ctx.moveTo(x, y);
            } else {
                this.ctx.lineTo(x, y);
            }
        }
        this.ctx.stroke();
        
        // Mark MLE
        const sampleMean = this.data.reduce((sum, x) =&gt; sum + x, 0) / this.data.length;
        const mleX = marginX + (sampleMean - minX) / (maxX - minX) * plotWidth;
        
        this.ctx.strokeStyle = &apos;#f44336&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.moveTo(mleX, marginY);
        this.ctx.lineTo(mleX, this.height - marginY);
        this.ctx.stroke();
        
        // Mark true value
        const trueX = marginX + (this.trueMu - minX) / (maxX - minX) * plotWidth;
        this.ctx.strokeStyle = &apos;#4caf50&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.setLineDash([5, 5]);
        this.ctx.beginPath();
        this.ctx.moveTo(trueX, marginY);
        this.ctx.lineTo(trueX, this.height - marginY);
        this.ctx.stroke();
        this.ctx.setLineDash([]);
        
        // Draw data points
        this.ctx.fillStyle = &apos;#666&apos;;
        for (const x of this.data) {
            const pointX = marginX + (x - minX) / (maxX - minX) * plotWidth;
            this.ctx.beginPath();
            this.ctx.arc(pointX, this.height - marginY + 10, 2, 0, 2 * Math.PI);
            this.ctx.fill();
        }
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;μ&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;Log-Likelihood&apos;, 0, 0);
        this.ctx.restore();
        
        // Legend
        this.ctx.textAlign = &apos;left&apos;;
        this.ctx.fillText(&apos;— Likelihood&apos;, 10, 20);
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.fillText(&apos;— MLE&apos;, 10, 35);
        this.ctx.fillStyle = &apos;#4caf50&apos;;
        this.ctx.fillText(&apos;--- μ Thực&apos;, 10, 50);
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new SampleSpaceDemo();
    new ConditionalProbDemo();
    new MLEDemo();
});
&lt;/script&gt;

&lt;style&gt;
input[type=&quot;range&quot;] {
    -webkit-appearance: none;
    appearance: none;
    height: 5px;
    background: #ddd;
    outline: none;
    border-radius: 5px;
}

input[type=&quot;range&quot;]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
}

input[type=&quot;range&quot;]::-moz-range-thumb {
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
    border: none;
}

canvas {
    border-radius: 5px;
}

.demo-container {
    margin: 20px 0;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>00-03 Giải tích thực và Lý thuyết tập hợp</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_03_Real_Analysis_and_Set_Theory/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_03_Real_Analysis_and_Set_Theory</id>
   <content type="html">&lt;p&gt;Bài học này bao gồm các khái niệm cần thiết từ giải tích thực và lý thuyết tập hợp cần thiết cho tối ưu hóa, được tổ chức thành hai phần chính để hiểu một cách toàn diện.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-03-02 Tôpô trong Giải tích thực</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_03_02_Topology_in_Real_Analysis/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_03_02_Topology_in_Real_Analysis</id>
   <content type="html">&lt;p&gt;Bài học này bao gồm các khái niệm tôpô cần thiết từ giải tích thực, rất quan trọng để hiểu cấu trúc của các vùng khả thi, tính liên tục và sự tồn tại của nghiệm tối ưu trong các bài toán tối ưu hóa.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;giới-thiệu-về-tôpô&quot;&gt;Giới thiệu về Tôpô&lt;/h2&gt;

&lt;p&gt;Tôpô nghiên cứu các tính chất của không gian được bảo toàn dưới các biến dạng liên tục. Trong tối ưu hóa, các khái niệm tôpô giúp chúng ta hiểu cấu trúc của các vùng khả thi và hành vi của các hàm số, đặc biệt liên quan đến sự tồn tại và đặc trưng của nghiệm tối ưu.&lt;/p&gt;

&lt;h3 id=&quot;không-gian-metric-và-khoảng-cách&quot;&gt;Không gian metric và Khoảng cách&lt;/h3&gt;

&lt;p&gt;Trước khi thảo luận về tôpô, chúng ta cần khái niệm khoảng cách. Trong \(\mathbb{R}^n\), &lt;strong&gt;khoảng cách Euclid&lt;/strong&gt; chuẩn giữa các điểm \(\mathbf{x}\) và \(\mathbf{y}\) là:&lt;/p&gt;

\[d(\mathbf{x}, \mathbf{y}) = \|\mathbf{x} - \mathbf{y}\|_2 = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}\]

&lt;h3 id=&quot;hình-cầu-mở-và-lân-cận&quot;&gt;Hình cầu mở và Lân cận&lt;/h3&gt;

&lt;p&gt;Một &lt;strong&gt;hình cầu mở&lt;/strong&gt; có tâm tại \(\mathbf{x}_0\) với bán kính \(\epsilon &amp;gt; 0\) là:&lt;/p&gt;

\[B(\mathbf{x}_0, \epsilon) = \{\mathbf{y} \in \mathbb{R}^n : d(\mathbf{x}_0, \mathbf{y}) &amp;lt; \epsilon\}\]

&lt;p&gt;This represents all points within distance \(\epsilon\) from \(\mathbf{x}_0\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In \(\mathbb{R}\): \(B(0, 1) = (-1, 1)\) (open interval)&lt;/li&gt;
  &lt;li&gt;In \(\mathbb{R}^2\): \(B(\mathbf{0}, 1) = \{(x, y) : x^2 + y^2 &amp;lt; 1\}\) (open unit disk)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;open-sets&quot;&gt;Open Sets&lt;/h2&gt;

&lt;p&gt;An &lt;strong&gt;open set&lt;/strong&gt; is characterized by the property that it &lt;strong&gt;contains none of its boundary points&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;formal-definition&quot;&gt;Formal Definition&lt;/h3&gt;

&lt;p&gt;A set \(S\) in \(\mathbb{R}^n\) is &lt;strong&gt;open&lt;/strong&gt; if for every point \(\mathbf{x} \in S\), there exists a positive real number \(\epsilon &amp;gt; 0\) such that the open ball \(B(\mathbf{x}, \epsilon)\) is entirely contained within \(S\):&lt;/p&gt;

\[\forall \mathbf{x} \in S, \exists \epsilon &amp;gt; 0 : B(\mathbf{x}, \epsilon) \subseteq S\]

&lt;h3 id=&quot;intuitive-understanding&quot;&gt;Intuitive Understanding&lt;/h3&gt;

&lt;p&gt;An open set has the property that if you’re inside it, you can move a small distance in any direction and still remain inside the set. There’s always some “wiggle room” around every point.&lt;/p&gt;

&lt;h3 id=&quot;examples-of-open-sets&quot;&gt;Examples of Open Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(0, 1) = \{x : 0 &amp;lt; x &amp;lt; 1\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[(-\infty, 5) = \{x : x &amp;lt; 5\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}\) itself&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 &amp;lt; 1\}\) (open unit disk)&lt;/li&gt;
  &lt;li&gt;\(\{(x, y) : x &amp;gt; 0, y &amp;gt; 0\}\) (first quadrant, excluding axes)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^2\) itself&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any open ball \(B(\mathbf{x}_0, r)\)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) itself&lt;/li&gt;
  &lt;li&gt;\(\emptyset\) (empty set - vacuously open)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;properties-of-open-sets&quot;&gt;Properties of Open Sets&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;The union of any collection of open sets is open&lt;/li&gt;
  &lt;li&gt;The intersection of finitely many open sets is open&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) and \(\emptyset\) are both open&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;closed-sets&quot;&gt;Closed Sets&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;closed set&lt;/strong&gt; is defined as a set that contains all of its boundary points. Equivalently, a set \(S\) is closed if its complement \(\mathbb{R}^n \setminus S\) is an &lt;strong&gt;open set&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;formal-definition-1&quot;&gt;Formal Definition&lt;/h3&gt;

&lt;p&gt;A set \(S\) is &lt;strong&gt;closed&lt;/strong&gt; if it contains all its limit points. That is, if a sequence of points \((x_n)\) from \(S\) converges to a point \(\mathbf{x}\), then \(\mathbf{x}\) must also be in \(S\):&lt;/p&gt;

\[\text{If } \mathbf{x}_n \in S \text{ for all } n \text{ and } \lim_{n \to \infty} \mathbf{x}_n = \mathbf{x}, \text{ then } \mathbf{x} \in S\]

&lt;h3 id=&quot;examples-of-closed-sets&quot;&gt;Examples of Closed Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[[0, 1] = \{x : 0 \leq x \leq 1\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[[a, \infty) = \{x : x \geq a\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\{0\}\) (single point)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{Z}\) (integers)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
  &lt;li&gt;\(\{(x, y) : x \geq 0, y \geq 0\}\) (first quadrant, including axes)&lt;/li&gt;
  &lt;li&gt;\(\{(0, 0)\}\) (single point)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any closed ball \(\overline{B}(\mathbf{x}_0, r) = \{\mathbf{x} : d(\mathbf{x}, \mathbf{x}_0) \leq r\}\)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) itself&lt;/li&gt;
  &lt;li&gt;\(\emptyset\) (empty set)&lt;/li&gt;
  &lt;li&gt;Any finite set&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;properties-of-closed-sets&quot;&gt;Properties of Closed Sets&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;The intersection of any collection of closed sets is closed&lt;/li&gt;
  &lt;li&gt;The union of finitely many closed sets is closed&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) and \(\emptyset\) are both closed&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;important-note&quot;&gt;Important Note&lt;/h3&gt;

&lt;p&gt;Sets can be:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Open but not closed:&lt;/strong&gt; \((0, 1)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closed but not open:&lt;/strong&gt; \([0, 1]\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Both open and closed:&lt;/strong&gt; \(\mathbb{R}^n\), \(\emptyset\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Neither open nor closed:&lt;/strong&gt; \([0, 1)\), \((0, 1]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;boundary-interior-and-closure&quot;&gt;Boundary, Interior, and Closure&lt;/h2&gt;

&lt;h3 id=&quot;boundary&quot;&gt;Boundary&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;boundary&lt;/strong&gt; of a set \(S\), denoted \(\partial S\), consists of points that are “on the edge” of the set. A point \(\mathbf{x}\) is a &lt;strong&gt;boundary point&lt;/strong&gt; of \(S\) if every open ball centered at \(\mathbf{x}\) intersects both \(S\) and its complement \(S^c\):&lt;/p&gt;

\[\partial S = \{\mathbf{x} : \forall \epsilon &amp;gt; 0, B(\mathbf{x}, \epsilon) \cap S \neq \emptyset \text{ and } B(\mathbf{x}, \epsilon) \cap S^c \neq \emptyset\}\]

&lt;h3 id=&quot;interior&quot;&gt;Interior&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;interior&lt;/strong&gt; of a set \(S\), denoted \(S^\circ\) or \(\text{int}(S)\), includes all points strictly “inside” the set, excluding the boundary:&lt;/p&gt;

\[S^\circ = \{\mathbf{x} \in S : \exists \epsilon &amp;gt; 0, B(\mathbf{x}, \epsilon) \subseteq S\}\]

&lt;h3 id=&quot;closure&quot;&gt;Closure&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;closure&lt;/strong&gt; of a set \(S\), denoted \(\overline{S}\) or \(\text{cl}(S)\), is the smallest closed set containing \(S\):&lt;/p&gt;

\[\overline{S} = S \cup \partial S\]

&lt;h3 id=&quot;example-analysis&quot;&gt;Example Analysis&lt;/h3&gt;

&lt;p&gt;For the interval \(S = [0, 1)\) in \(\mathbb{R}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Interior:&lt;/strong&gt; \(S^\circ = (0, 1)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Boundary:&lt;/strong&gt; \(\partial S = \{0, 1\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closure:&lt;/strong&gt; \(\overline{S} = [0, 1]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the open disk \(S = \{(x, y) : x^2 + y^2 &amp;lt; 1\}\) in \(\mathbb{R}^2\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Interior:&lt;/strong&gt; \(S^\circ = S\) (the set is already open)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Boundary:&lt;/strong&gt; \(\partial S = \{(x, y) : x^2 + y^2 = 1\}\) (unit circle)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closure:&lt;/strong&gt; \(\overline{S} = \{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;compact-sets&quot;&gt;Compact Sets&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;compact set&lt;/strong&gt; is one of the most important concepts in optimization theory.&lt;/p&gt;

&lt;h3 id=&quot;definition-in-euclidean-spaces&quot;&gt;Definition in Euclidean Spaces&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Heine-Borel Theorem:&lt;/strong&gt; In Euclidean spaces (\(\mathbb{R}^n\)), a set is compact if and only if it is both &lt;strong&gt;closed and bounded&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Bounded:&lt;/strong&gt; A set \(S\) is bounded if it can be contained within some sufficiently large open ball: \(\exists M &amp;gt; 0, \mathbf{x}_0\) such that \(S \subseteq B(\mathbf{x}_0, M)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closed:&lt;/strong&gt; As defined above&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;examples-of-compact-sets&quot;&gt;Examples of Compact Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\([a, b]\) (any closed, bounded interval)&lt;/li&gt;
  &lt;li&gt;\(\{0\}\) (single point)&lt;/li&gt;
  &lt;li&gt;Any finite set&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
  &lt;li&gt;\([0, 1] \times [0, 1]\) (unit square)&lt;/li&gt;
  &lt;li&gt;Any finite set of points&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any closed ball \(\overline{B}(\mathbf{x}_0, r)\)&lt;/li&gt;
  &lt;li&gt;Any closed, bounded rectangle \([a_1, b_1] \times [a_2, b_2] \times \cdots \times [a_n, b_n]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;non-compact-sets&quot;&gt;Non-Compact Sets&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\((0, 1)\) (bounded but not closed)&lt;/li&gt;
  &lt;li&gt;\([0, \infty)\) (closed but not bounded)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) (not bounded)&lt;/li&gt;
  &lt;li&gt;\(\{1, 1/2, 1/3, 1/4, \ldots\}\) (bounded but not closed, since 0 is a limit point not in the set)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;continuity-of-functions&quot;&gt;Continuity of Functions&lt;/h2&gt;

&lt;h3 id=&quot;point-wise-continuity&quot;&gt;Point-wise Continuity&lt;/h3&gt;

&lt;p&gt;A function \(f: A \to \mathbb{R}\) is &lt;strong&gt;continuous at a point&lt;/strong&gt; \(\mathbf{c} \in A\) if for every \(\varepsilon &amp;gt; 0\), there exists \(\delta &amp;gt; 0\) such that for all \(\mathbf{x} \in A\):&lt;/p&gt;

\[\|\mathbf{x} - \mathbf{c}\| &amp;lt; \delta \implies |f(\mathbf{x}) - f(\mathbf{c})| &amp;lt; \varepsilon\]

&lt;p&gt;&lt;strong&gt;Intuitive meaning:&lt;/strong&gt; Small changes in input lead to small changes in output.&lt;/p&gt;

&lt;h3 id=&quot;global-continuity&quot;&gt;Global Continuity&lt;/h3&gt;

&lt;p&gt;\(f\) is &lt;strong&gt;continuous on \(A\)&lt;/strong&gt; if it’s continuous at every point in \(A\).&lt;/p&gt;

&lt;h3 id=&quot;sequential-characterization&quot;&gt;Sequential Characterization&lt;/h3&gt;

&lt;p&gt;\(f\) is continuous at \(\mathbf{c}\) if and only if for every sequence \((\mathbf{x}_n)\) in \(A\) converging to \(\mathbf{c}\):&lt;/p&gt;

\[\lim_{n \to \infty} f(\mathbf{x}_n) = f(\mathbf{c})\]

&lt;hr /&gt;

&lt;h2 id=&quot;important-theorems-for-optimization&quot;&gt;Important Theorems for Optimization&lt;/h2&gt;

&lt;h3 id=&quot;extreme-value-theorem&quot;&gt;Extreme Value Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;If \(f\) is continuous on a compact set \(K\), then \(f\) attains its maximum and minimum on \(K\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is fundamental for optimization: it guarantees that continuous objective functions have optimal solutions on compact feasible regions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof idea:&lt;/strong&gt; Compactness ensures that the supremum and infimum of \(f\) on \(K\) are actually achieved at points in \(K\).&lt;/p&gt;

&lt;h3 id=&quot;intermediate-value-theorem&quot;&gt;Intermediate Value Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;If \(f\) is continuous on \([a, b]\) and \(y\) is between \(f(a)\) and \(f(b)\), then there exists \(c \in [a, b]\) such that \(f(c) = y\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This helps establish the existence of solutions to equations \(f(x) = 0\).&lt;/p&gt;

&lt;h3 id=&quot;bolzano-weierstrass-theorem&quot;&gt;Bolzano-Weierstrass Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Every bounded sequence in \(\mathbb{R}^n\) has a convergent subsequence.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is crucial for proving convergence of optimization algorithms.&lt;/p&gt;

&lt;h3 id=&quot;weierstrass-approximation-theorem&quot;&gt;Weierstrass Approximation Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Every continuous function on a closed interval can be uniformly approximated by polynomials.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This justifies using polynomial approximations in optimization algorithms.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;h3 id=&quot;1-existence-of-solutions&quot;&gt;1. Existence of Solutions&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Compact feasible sets guarantee optimal solutions exist:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If the feasible region \(S\) is compact and the objective function \(f\) is continuous, then the optimization problem \(\min_{\mathbf{x} \in S} f(\mathbf{x})\) has a solution.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-constraint-qualification&quot;&gt;2. Constraint Qualification&lt;/h3&gt;

&lt;p&gt;Understanding topological properties of constraint sets:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Regular points:&lt;/strong&gt; Points where constraint gradients are linearly independent&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interior point methods:&lt;/strong&gt; Require the feasible region to have non-empty interior&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-convergence-analysis&quot;&gt;3. Convergence Analysis&lt;/h3&gt;

&lt;p&gt;Analyzing whether optimization algorithms converge:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Closed sets:&lt;/strong&gt; Ensure limit points of convergent sequences remain feasible&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compactness:&lt;/strong&gt; Guarantees convergent subsequences exist&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-local-vs-global-optima&quot;&gt;4. Local vs Global Optima&lt;/h3&gt;

&lt;p&gt;Using neighborhoods to define optimality:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Local minimum:&lt;/strong&gt; \(f(\mathbf{x}^*) \leq f(\mathbf{x})\) for all \(\mathbf{x}\) in some neighborhood of \(\mathbf{x}^*\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Global minimum:&lt;/strong&gt; \(f(\mathbf{x}^*) \leq f(\mathbf{x})\) for all \(\mathbf{x}\) in the feasible region&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-feasible-region-analysis&quot;&gt;5. Feasible Region Analysis&lt;/h3&gt;

&lt;p&gt;Determining properties of constraint sets:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linear constraints:&lt;/strong&gt; Define closed sets (half-spaces)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nonlinear constraints:&lt;/strong&gt; May create sets that are neither open nor closed&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compact feasible regions:&lt;/strong&gt; Guarantee existence of optimal solutions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-portfolio-optimization&quot;&gt;Example: Portfolio Optimization&lt;/h3&gt;

&lt;p&gt;Consider minimizing portfolio risk subject to constraints:&lt;/p&gt;

\[\begin{align}
\min_{\mathbf{w}} \quad &amp;amp; \mathbf{w}^T \mathbf{\Sigma} \mathbf{w} \\
\text{s.t.} \quad &amp;amp; \mathbf{1}^T \mathbf{w} = 1 \\
&amp;amp; \mathbf{w} \geq \mathbf{0}
\end{align}\]

&lt;p&gt;The feasible region \(S = \{\mathbf{w} : \mathbf{1}^T \mathbf{w} = 1, \mathbf{w} \geq \mathbf{0}\}\) is:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Closed:&lt;/strong&gt; It’s the intersection of closed sets&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bounded:&lt;/strong&gt; The constraint \(\mathbf{1}^T \mathbf{w} = 1\) with \(\mathbf{w} \geq \mathbf{0}\) bounds the feasible region&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compact:&lt;/strong&gt; Being closed and bounded in \(\mathbb{R}^n\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since the objective function \(\mathbf{w}^T \mathbf{\Sigma} \mathbf{w}\) is continuous and \(S\) is compact, the Extreme Value Theorem guarantees that an optimal portfolio exists.&lt;/p&gt;

&lt;p&gt;Understanding topology and real analysis provides the rigorous foundation needed to prove that optimization problems have solutions and that algorithms will find them. These concepts are essential for both theoretical analysis and practical algorithm design.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-03-01 Cơ sở Lý thuyết tập hợp</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_03_01_Set_Theory_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_03_01_Set_Theory_Fundamentals</id>
   <content type="html">&lt;p&gt;Bài học này bao gồm các khái niệm cơ bản từ lý thuyết tập hợp cung cấp nền tảng toán học để hiểu các bài toán tối ưu hóa, ràng buộc và vùng khả thi.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;giới-thiệu-về-lý-thuyết-tập-hợp&quot;&gt;Giới thiệu về Lý thuyết tập hợp&lt;/h2&gt;

&lt;p&gt;Lý thuyết tập hợp cung cấp nền tảng cho toán học hiện đại và rất cần thiết để hiểu các khái niệm tối ưu hóa. Một &lt;strong&gt;tập hợp&lt;/strong&gt; đơn giản là một bộ sưu tập các đối tượng riêng biệt, được gọi là các phần tử hoặc thành viên.&lt;/p&gt;

&lt;h3 id=&quot;ký-hiệu-cơ-bản&quot;&gt;Ký hiệu cơ bản&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ký hiệu tập hợp:&lt;/strong&gt; \(A = \{1, 2, 3, 4\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Quan hệ thành viên:&lt;/strong&gt; \(x \in A\) (x thuộc A) hoặc \(x \notin A\) (x không thuộc A)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tập rỗng:&lt;/strong&gt; \(\emptyset = \{\}\) (tập hợp không có phần tử nào)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ký hiệu xây dựng tập hợp:&lt;/strong&gt; \(A = \{x : P(x)\}\) (tập hợp tất cả x sao cho tính chất P(x) đúng)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ví-dụ&quot;&gt;Ví dụ&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\(A = \{1, 2, 3, 4\}\) (liệt kê tường minh)&lt;/li&gt;
  &lt;li&gt;\(B = \{x \in \mathbb{R} : x^2 &amp;lt; 4\} = (-2, 2)\) (ký hiệu xây dựng tập hợp)&lt;/li&gt;
  &lt;li&gt;\(C = \{x \in \mathbb{Z} : x \text{ là số chẵn}\}\) (tất cả số nguyên chẵn)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;các-phép-toán-tập-hợp-cơ-bản&quot;&gt;Các phép toán tập hợp cơ bản&lt;/h2&gt;

&lt;h3 id=&quot;tập-hợp-và-tập-con&quot;&gt;Tập hợp và Tập con&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tập con:&lt;/strong&gt; \(A \subseteq B\) có nghĩa là mọi phần tử của \(A\) cũng thuộc \(B\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tập con thực sự:&lt;/strong&gt; \(A \subset B\) có nghĩa là \(A \subseteq B\) và \(A \neq B\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bằng nhau giữa các tập hợp:&lt;/strong&gt; \(A = B\) khi và chỉ khi \(A \subseteq B\) và \(B \subseteq A\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\{1, 2\} \subseteq \{1, 2, 3, 4\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[\{1, 2\} \subset \{1, 2, 3, 4\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\emptyset \subseteq A\) với mọi tập hợp \(A\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hợp-và-giao&quot;&gt;Hợp và Giao&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Hợp (\(A \cup B\)):&lt;/strong&gt; Tất cả các phần tử thuộc \(A\) hoặc \(B\) (hoặc cả hai)
\(A \cup B = \{x : x \in A \text{ hoặc } x \in B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Giao (\(A \cap B\)):&lt;/strong&gt; Tất cả các phần tử thuộc cả \(A\) và \(B\)
\(A \cap B = \{x : x \in A \text{ và } x \in B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Nếu \(A = \{1, 2, 3\}\) và \(B = \{3, 4, 5\}\), thì:
    &lt;ul&gt;
      &lt;li&gt;
\[A \cup B = \{1, 2, 3, 4, 5\}\]
      &lt;/li&gt;
      &lt;li&gt;
\[A \cap B = \{3\}\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Tập hợp rời nhau:&lt;/strong&gt; \(A\) và \(B\) rời nhau nếu \(A \cap B = \emptyset\)&lt;/p&gt;

&lt;h3 id=&quot;phần-bù-và-hiệu&quot;&gt;Phần bù và Hiệu&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Phần bù (\(A^c\)):&lt;/strong&gt; Tất cả các phần tử không thuộc \(A\) (trong một tập hợp toàn thể \(U\) nào đó)
\(A^c = \{x \in U : x \notin A\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hiệu tập hợp (\(A \setminus B\)):&lt;/strong&gt; Các phần tử thuộc \(A\) nhưng không thuộc \(B\)
\(A \setminus B = \{x : x \in A \text{ và } x \notin B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hiệu đối xứng:&lt;/strong&gt; \((A \setminus B) \cup (B \setminus A) = (A \cup B) \setminus (A \cap B)\)&lt;/p&gt;

&lt;h3 id=&quot;các-luật-tập-hợp&quot;&gt;Các luật tập hợp&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Luật giao hoán:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[A \cup B = B \cup A\]
  &lt;/li&gt;
  &lt;li&gt;
\[A \cap B = B \cap A\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Luật kết hợp:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(A \cup B) \cup C = A \cup (B \cup C)\]
  &lt;/li&gt;
  &lt;li&gt;
\[(A \cap B) \cap C = A \cap (B \cap C)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Luật phân phối:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\]
  &lt;/li&gt;
  &lt;li&gt;
\[A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Luật De Morgan:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(A \cup B)^c = A^c \cap B^c\]
  &lt;/li&gt;
  &lt;li&gt;
\[(A \cap B)^c = A^c \cup B^c\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;các-tập-số-quan-trọng&quot;&gt;Các tập số quan trọng&lt;/h2&gt;

&lt;p&gt;Hiểu biết về hệ thống phân cấp các tập số là rất quan trọng cho tối ưu hóa:&lt;/p&gt;

&lt;h3 id=&quot;số-tự-nhiên&quot;&gt;Số tự nhiên&lt;/h3&gt;
&lt;p&gt;\(\mathbb{N} = \{1, 2, 3, 4, \ldots\}\)
(Thỉnh thoảng bao gồm 0: \(\mathbb{N}_0 = \{0, 1, 2, 3, \ldots\}\))&lt;/p&gt;

&lt;h3 id=&quot;số-nguyên&quot;&gt;Số nguyên&lt;/h3&gt;
&lt;p&gt;\(\mathbb{Z} = \{\ldots, -2, -1, 0, 1, 2, \ldots\}\)&lt;/p&gt;

&lt;h3 id=&quot;số-hữu-tỉ&quot;&gt;Số hữu tỉ&lt;/h3&gt;
&lt;p&gt;\(\mathbb{Q} = \left\{\frac{p}{q} : p, q \in \mathbb{Z}, q \neq 0\right\}\)&lt;/p&gt;

&lt;p&gt;Tất cả các số có thể biểu diễn dưới dạng phân số.&lt;/p&gt;

&lt;h3 id=&quot;số-thực&quot;&gt;Số thực&lt;/h3&gt;
&lt;p&gt;\(\mathbb{R}\) bao gồm tất cả các số hữu tỉ và vô tỉ (như \(\pi\), \(e\), \(\sqrt{2}\)).&lt;/p&gt;

&lt;h3 id=&quot;số-phức&quot;&gt;Số phức&lt;/h3&gt;
&lt;p&gt;\(\mathbb{C} = \{a + bi : a, b \in \mathbb{R}, i^2 = -1\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phân cấp:&lt;/strong&gt; \(\mathbb{N} \subset \mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R} \subset \mathbb{C}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;hàm-số-miền-xác-định-và-miền-giá-trị&quot;&gt;Hàm số: Miền xác định và Miền giá trị&lt;/h2&gt;

&lt;p&gt;Một &lt;strong&gt;hàm số&lt;/strong&gt; \(f: A \to B\) là một quy tắc gán cho mỗi phần tử trong tập hợp \(A\) đúng một phần tử trong tập hợp \(B\).&lt;/p&gt;

&lt;h3 id=&quot;các-khái-niệm-chính&quot;&gt;Các khái niệm chính&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Miền xác định:&lt;/strong&gt; Tập hợp \(A\) của tất cả các giá trị đầu vào có thể&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Miền đồng biến:&lt;/strong&gt; Tập hợp \(B\) nơi các giá trị đầu ra được lấy từ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Miền giá trị (Ảnh):&lt;/strong&gt; Tập hợp tất cả các giá trị đầu ra thực tế: \(\text{Range}(f) = \{f(x) : x \in A\} \subseteq B\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt; Với \(f(x) = x^2\) và \(f: \mathbb{R} \to \mathbb{R}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Miền xác định: \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;Miền đồng biến: \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;Miền giá trị: \([0, \infty)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;các-loại-hàm-số&quot;&gt;Các loại hàm số&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Đơn ánh (Một-đến-Một):&lt;/strong&gt; Mỗi phần tử trong miền giá trị tương ứng với đúng một phần tử trong miền xác định
\(f(x_1) = f(x_2) \implies x_1 = x_2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Toàn ánh (Lên):&lt;/strong&gt; Mọi phần tử trong miền đồng biến đều nằm trong miền giá trị
Với mọi \(y \in B\), tồn tại \(x \in A\) sao cho \(f(x) = y\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Song ánh:&lt;/strong&gt; Vừa là đơn ánh vừa là toàn ánh
Có một tương ứng hoàn hảo một-đến-một giữa miền xác định và miền đồng biến.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(f(x) = 2x\) trên \(\mathbb{R}\) là song ánh&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) trên \(\mathbb{R}\) không là đơn ánh cũng không là toàn ánh&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) trên \([0, \infty) \to [0, \infty)\) là song ánh&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;bất-đẳng-thức&quot;&gt;Bất đẳng thức&lt;/h2&gt;

&lt;p&gt;Hiểu biết về bất đẳng thức là rất quan trọng cho tối ưu hóa, vì các ràng buộc thường được biểu diễn dưới dạng bất đẳng thức.&lt;/p&gt;

&lt;h3 id=&quot;các-ký-hiệu-bất-đẳng-thức-cơ-bản&quot;&gt;Các ký hiệu bất đẳng thức cơ bản&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\(a &amp;lt; b\): \(a\) nhỏ hơn \(b\) một cách nghiêm ngặt&lt;/li&gt;
  &lt;li&gt;\(a \leq b\): \(a\) nhỏ hơn hoặc bằng \(b\)&lt;/li&gt;
  &lt;li&gt;\(a &amp;gt; b\): \(a\) lớn hơn \(b\) một cách nghiêm ngặt&lt;/li&gt;
  &lt;li&gt;\(a \geq b\): \(a\) lớn hơn hoặc bằng \(b\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tính-chất-của-bất-đẳng-thức&quot;&gt;Tính chất của bất đẳng thức&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tính bắc cầu:&lt;/strong&gt; Nếu \(a \leq b\) và \(b \leq c\), thì \(a \leq c\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Phép cộng:&lt;/strong&gt; Nếu \(a \leq b\), thì \(a + c \leq b + c\) với mọi \(c\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Nhân với số dương:&lt;/strong&gt; Nếu \(a \leq b\) và \(c &amp;gt; 0\), thì \(ac \leq bc\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Nhân với số âm:&lt;/strong&gt; Nếu \(a \leq b\) và \(c &amp;lt; 0\), thì \(ac \geq bc\) (bất đẳng thức đảo chiều!)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;ký-hiệu-khoảng&quot;&gt;Ký hiệu khoảng&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Khoảng mở:&lt;/strong&gt; \((a, b) = \{x \in \mathbb{R} : a &amp;lt; x &amp;lt; b\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Khoảng đóng:&lt;/strong&gt; \([a, b] = \{x \in \mathbb{R} : a \leq x \leq b\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Khoảng nửa mở:&lt;/strong&gt; \([a, b)\), \((a, b]\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Khoảng không bị chặn:&lt;/strong&gt; \((-\infty, a)\), \([a, \infty)\), \((-\infty, \infty) = \mathbb{R}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ứng-dụng-trong-tối-ưu-hóa&quot;&gt;Ứng dụng trong Tối ưu hóa&lt;/h2&gt;

&lt;p&gt;Các khái niệm lý thuyết tập hợp là cơ bản cho tối ưu hóa:&lt;/p&gt;

&lt;h3 id=&quot;1-vùng-khả-thi&quot;&gt;1. Vùng khả thi&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Vùng khả thi&lt;/strong&gt; là tập hợp tất cả các điểm thỏa mãn các ràng buộc:
\(S = \{x \in \mathbb{R}^n : g_i(x) \leq 0, i = 1, \ldots, m; h_j(x) = 0, j = 1, \ldots, p\}\)&lt;/p&gt;

&lt;h3 id=&quot;2-tập-mức&quot;&gt;2. Tập mức&lt;/h3&gt;

&lt;p&gt;Với một hàm số \(f: \mathbb{R}^n \to \mathbb{R}\), &lt;strong&gt;tập mức&lt;/strong&gt; tại mức \(c\) là:
\(L_c = \{x \in \mathbb{R}^n : f(x) = c\}\)&lt;/p&gt;

&lt;h3 id=&quot;3-điều-kiện-ràng-buộc&quot;&gt;3. Điều kiện ràng buộc&lt;/h3&gt;

&lt;p&gt;Hiểu biết khi nào các tập ràng buộc có các tính chất “tốt” (như đóng hoặc có phần trong không rỗng) ảnh hưởng đến sự tồn tại và đặc trưng của các nghiệm tối ưu.&lt;/p&gt;

&lt;h3 id=&quot;4-phân-tích-hội-tụ&quot;&gt;4. Phân tích hội tụ&lt;/h3&gt;

&lt;p&gt;Dãy số và giới hạn là thiết yếu để phân tích liệu các thuật toán tối ưu hóa có hội tụ về nghiệm tối ưu hay không.&lt;/p&gt;

&lt;h3 id=&quot;5-các-phép-toán-tập-hợp-trong-thuật-toán&quot;&gt;5. Các phép toán tập hợp trong thuật toán&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Giao:&lt;/strong&gt; Tìm các điểm thỏa mãn nhiều ràng buộc&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hợp:&lt;/strong&gt; Kết hợp các vùng khả thi từ các kịch bản khác nhau&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phần bù:&lt;/strong&gt; Hiểu biết về các vùng không khả thi&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt; Trong quy hoạch tuyến tính, vùng khả thi là:
\(S = \{x \in \mathbb{R}^n : Ax \leq b, x \geq 0\} = \bigcap_{i=1}^{m} \{x : a_i^T x \leq b_i\} \cap \{x : x \geq 0\}\)&lt;/p&gt;

&lt;p&gt;Đây là giao của các nửa không gian, minh họa cách các phép toán tập hợp xuất hiện tự nhiên trong việc xây dựng bài toán tối ưu hóa.&lt;/p&gt;

&lt;p&gt;Hiểu biết về lý thuyết tập hợp cung cấp nền tảng toán học chặt chẽ cần thiết để xây dựng các bài toán tối ưu hóa một cách chính xác và phân tích các tính chất của chúng một cách hệ thống.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02 Đại số tuyến tính cơ bản</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_02_Basic_Linear_Algebra/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_02_Basic_Linear_Algebra</id>
   <content type="html">&lt;p&gt;Bài học này bao gồm các khái niệm đại số tuyến tính cần thiết cho tối ưu hóa, được tổ chức thành ba phần chính để học tập có hệ thống.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-03 Giá trị riêng và Vector riêng</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_02_03_Eigenvalues_and_Eigenvectors/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_02_03_Eigenvalues_and_Eigenvectors</id>
   <content type="html">&lt;p&gt;Bài học này bao gồm giá trị riêng và vector riêng, rất quan trọng để hiểu hành vi của các phép biến đổi tuyến tính và hàm bậc hai trong tối ưu hóa.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;định-nghĩa-và-trực-giác&quot;&gt;Định nghĩa và Trực giác&lt;/h2&gt;

&lt;p&gt;Khi một ma trận biến đổi một vector, nó thường thay đổi cả hướng và độ dài của vector. Tuy nhiên, &lt;strong&gt;vector riêng&lt;/strong&gt; là những vector đặc biệt mà khi được biến đổi bởi một ma trận cho trước, chỉ bị thay đổi tỉ lệ nhưng không thay đổi hướng.&lt;/p&gt;

&lt;h3 id=&quot;định-nghĩa-toán-học&quot;&gt;Định nghĩa Toán học&lt;/h3&gt;

&lt;p&gt;Với một ma trận vuông \(\mathbf{A}\) và một vector khác không \(\mathbf{v}\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\mathbf{v}\) là một &lt;strong&gt;vector riêng&lt;/strong&gt; của \(\mathbf{A}\)&lt;/li&gt;
  &lt;li&gt;\(\lambda\) là &lt;strong&gt;giá trị riêng&lt;/strong&gt; tương ứng&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;nếu chúng thỏa mãn &lt;strong&gt;phương trình giá trị riêng&lt;/strong&gt;:&lt;/p&gt;

\[\mathbf{A}\mathbf{v} = \lambda\mathbf{v}\]

&lt;h3 id=&quot;giải-thích-hình-học&quot;&gt;Giải thích Hình học&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Vector riêng:&lt;/strong&gt; Các vector khác không duy trì hướng của chúng dưới phép biến đổi \(\mathbf{A}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Giá trị riêng:&lt;/strong&gt; Các hệ số vô hướng mà các vector riêng được nhân với&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Hiểu biết Trực quan:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Nếu \(\lambda &amp;gt; 1\): Vector riêng bị kéo dài&lt;/li&gt;
  &lt;li&gt;Nếu \(0 &amp;lt; \lambda &amp;lt; 1\): Vector riêng bị co lại&lt;/li&gt;
  &lt;li&gt;Nếu \(\lambda &amp;lt; 0\): Vector riêng bị nhân tỉ lệ và đảo ngược&lt;/li&gt;
  &lt;li&gt;Nếu \(\lambda = 0\): Vector riêng được ánh xạ thành vector không&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tìm-giá-trị-riêng-và-vector-riêng&quot;&gt;Tìm Giá trị riêng và Vector riêng&lt;/h2&gt;

&lt;h3 id=&quot;bước-1-tìm-giá-trị-riêng&quot;&gt;Bước 1: Tìm Giá trị riêng&lt;/h3&gt;

&lt;p&gt;Sắp xếp lại phương trình giá trị riêng:
\(\mathbf{A}\mathbf{v} = \lambda\mathbf{v}\)
\(\mathbf{A}\mathbf{v} - \lambda\mathbf{v} = \mathbf{0}\)
\((\mathbf{A} - \lambda\mathbf{I})\mathbf{v} = \mathbf{0}\)&lt;/p&gt;

&lt;p&gt;For a non-trivial solution (\(\mathbf{v} \neq \mathbf{0}\)), the matrix \((\mathbf{A} - \lambda\mathbf{I})\) must be singular, so:&lt;/p&gt;

\[\det(\mathbf{A} - \lambda\mathbf{I}) = 0\]

&lt;p&gt;This is called the &lt;strong&gt;characteristic equation&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;step-2-find-eigenvectors&quot;&gt;Step 2: Find Eigenvectors&lt;/h3&gt;

&lt;p&gt;For each eigenvalue \(\lambda_i\), solve the system:
\((\mathbf{A} - \lambda_i\mathbf{I})\mathbf{v} = \mathbf{0}\)&lt;/p&gt;

&lt;p&gt;The solutions form the &lt;strong&gt;eigenspace&lt;/strong&gt; corresponding to \(\lambda_i\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;detailed-example&quot;&gt;Detailed Example&lt;/h2&gt;

&lt;p&gt;Let’s find the eigenvalues and eigenvectors of \(\mathbf{A} = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\).&lt;/p&gt;

&lt;h3 id=&quot;step-1-find-eigenvalues&quot;&gt;Step 1: Find Eigenvalues&lt;/h3&gt;

\[\mathbf{A} - \lambda\mathbf{I} = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix} - \lambda\begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix} = \begin{pmatrix} 3-\lambda &amp;amp; 1 \\ 0 &amp;amp; 2-\lambda \end{pmatrix}\]

\[\det(\mathbf{A} - \lambda\mathbf{I}) = (3-\lambda)(2-\lambda) - (1)(0) = (3-\lambda)(2-\lambda) = 0\]

&lt;p&gt;This gives us \(\lambda_1 = 3\) and \(\lambda_2 = 2\).&lt;/p&gt;

&lt;h3 id=&quot;step-2-find-eigenvectors-1&quot;&gt;Step 2: Find Eigenvectors&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;For \(\lambda_1 = 3\):&lt;/strong&gt;
\((\mathbf{A} - 3\mathbf{I})\mathbf{v} = \begin{pmatrix} 0 &amp;amp; 1 \\ 0 &amp;amp; -1 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This gives us \(v_2 = 0\) and \(v_1\) can be any non-zero value. So \(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) (or any scalar multiple).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For \(\lambda_2 = 2\):&lt;/strong&gt;
\((\mathbf{A} - 2\mathbf{I})\mathbf{v} = \begin{pmatrix} 1 &amp;amp; 1 \\ 0 &amp;amp; 0 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This gives us \(v_1 + v_2 = 0\), so \(v_2 = -v_1\). Thus \(\mathbf{v}_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}\) (or any scalar multiple).&lt;/p&gt;

&lt;h3 id=&quot;verification&quot;&gt;Verification&lt;/h3&gt;

&lt;p&gt;Let’s verify our results:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{A}\mathbf{v}_1 = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 3 \\ 0 \end{pmatrix} = 3\begin{pmatrix} 1 \\ 0 \end{pmatrix} = 3\mathbf{v}_1\) ✓&lt;/li&gt;
  &lt;li&gt;\(\mathbf{A}\mathbf{v}_2 = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\begin{pmatrix} 1 \\ -1 \end{pmatrix} = \begin{pmatrix} 2 \\ -2 \end{pmatrix} = 2\begin{pmatrix} 1 \\ -1 \end{pmatrix} = 2\mathbf{v}_2\) ✓&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;properties-and-important-theorems&quot;&gt;Properties and Important Theorems&lt;/h2&gt;

&lt;h3 id=&quot;key-properties&quot;&gt;Key Properties&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Sum of eigenvalues = trace of matrix:&lt;/strong&gt;
\(\sum_{i=1}^n \lambda_i = \text{tr}(\mathbf{A}) = \sum_{i=1}^n a_{ii}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Product of eigenvalues = determinant of matrix:&lt;/strong&gt;
\(\prod_{i=1}^n \lambda_i = \det(\mathbf{A})\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Eigenvectors corresponding to different eigenvalues are linearly independent&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;If \(\mathbf{A}\) is symmetric, all eigenvalues are real and eigenvectors are orthogonal&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;eigenvalue-multiplicity&quot;&gt;Eigenvalue Multiplicity&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Algebraic multiplicity:&lt;/strong&gt; How many times \(\lambda\) appears as a root of the characteristic polynomial&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Geometric multiplicity:&lt;/strong&gt; The dimension of the eigenspace (number of linearly independent eigenvectors)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For any eigenvalue: geometric multiplicity ≤ algebraic multiplicity&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;diagonalization&quot;&gt;Diagonalization&lt;/h2&gt;

&lt;p&gt;A matrix \(\mathbf{A}\) is &lt;strong&gt;diagonalizable&lt;/strong&gt; if it can be written as:&lt;/p&gt;

\[\mathbf{A} = \mathbf{P}\mathbf{D}\mathbf{P}^{-1}\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{D}\) is a diagonal matrix of eigenvalues&lt;/li&gt;
  &lt;li&gt;\(\mathbf{P}\) is a matrix whose columns are the corresponding eigenvectors&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;benefits-of-diagonalization&quot;&gt;Benefits of Diagonalization&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Easy computation of powers:&lt;/strong&gt; \(\mathbf{A}^k = \mathbf{P}\mathbf{D}^k\mathbf{P}^{-1}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Understanding behavior:&lt;/strong&gt; The eigenvalues determine the transformation’s behavior along each eigenvector direction&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;p&gt;Eigenvalues and eigenvectors are crucial in optimization for several reasons:&lt;/p&gt;

&lt;h3 id=&quot;1-quadratic-forms-and-definiteness&quot;&gt;1. Quadratic Forms and Definiteness&lt;/h3&gt;

&lt;p&gt;For a quadratic function \(f(\mathbf{x}) = \mathbf{x}^T\mathbf{Q}\mathbf{x}\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Positive definite&lt;/strong&gt; (\(f(\mathbf{x}) &amp;gt; 0\) for \(\mathbf{x} \neq \mathbf{0}\)): All eigenvalues of \(\mathbf{Q}\) are positive&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Positive semidefinite&lt;/strong&gt; (\(f(\mathbf{x}) \geq 0\)): All eigenvalues are non-negative&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Negative definite&lt;/strong&gt; (\(f(\mathbf{x}) &amp;lt; 0\) for \(\mathbf{x} \neq \mathbf{0}\)): All eigenvalues are negative&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Indefinite&lt;/strong&gt; (\(f(\mathbf{x})\) can be positive or negative): Mixed positive and negative eigenvalues&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-second-order-optimality-conditions&quot;&gt;2. Second-Order Optimality Conditions&lt;/h3&gt;

&lt;p&gt;For a function \(f(\mathbf{x})\) at a critical point \(\mathbf{x}^*\) (where \(\nabla f(\mathbf{x}^*) = \mathbf{0}\)):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Local minimum:&lt;/strong&gt; Hessian \(\nabla^2 f(\mathbf{x}^*)\) is positive definite (all eigenvalues &amp;gt; 0)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Local maximum:&lt;/strong&gt; Hessian is negative definite (all eigenvalues &amp;lt; 0)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Saddle point:&lt;/strong&gt; Hessian is indefinite (mixed eigenvalues)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-principal-component-analysis-pca&quot;&gt;3. Principal Component Analysis (PCA)&lt;/h3&gt;

&lt;p&gt;PCA finds the directions of maximum variance in data:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Eigenvectors of the covariance matrix give the principal directions&lt;/li&gt;
  &lt;li&gt;Eigenvalues give the variance along each principal direction&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-convergence-analysis&quot;&gt;4. Convergence Analysis&lt;/h3&gt;

&lt;p&gt;In iterative optimization algorithms:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;condition number&lt;/strong&gt; \(\kappa = \frac{\lambda_{\max}}{\lambda_{\min}}\) affects convergence speed&lt;/li&gt;
  &lt;li&gt;Large condition numbers lead to slow convergence&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-newtons-method&quot;&gt;5. Newton’s Method&lt;/h3&gt;

&lt;p&gt;Newton’s method uses the inverse Hessian:
\(\mathbf{x}_{k+1} = \mathbf{x}_k - [\nabla^2 f(\mathbf{x}_k)]^{-1} \nabla f(\mathbf{x}_k)\)&lt;/p&gt;

&lt;p&gt;The eigenvalues of the Hessian determine the method’s behavior and convergence rate.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;example-optimization-application&quot;&gt;Example: Optimization Application&lt;/h2&gt;

&lt;p&gt;Consider minimizing \(f(x, y) = 2x^2 + 3y^2 + 2xy\).&lt;/p&gt;

&lt;p&gt;The Hessian is: \(\mathbf{H} = \begin{pmatrix} 4 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Finding eigenvalues:&lt;/strong&gt;
\(\det(\mathbf{H} - \lambda\mathbf{I}) = (4-\lambda)(6-\lambda) - 4 = \lambda^2 - 10\lambda + 20 = 0\)&lt;/p&gt;

\[\lambda = \frac{10 \pm \sqrt{100-80}}{2} = \frac{10 \pm 2\sqrt{5}}{2} = 5 \pm \sqrt{5}\]

&lt;p&gt;Since both eigenvalues are positive (\(\lambda_1 = 5 + \sqrt{5} &amp;gt; 0\) and \(\lambda_2 = 5 - \sqrt{5} &amp;gt; 0\)), the Hessian is positive definite, confirming that the origin is a global minimum.&lt;/p&gt;

&lt;p&gt;The condition number is \(\kappa = \frac{5 + \sqrt{5}}{5 - \sqrt{5}} \approx 4.24\), indicating reasonably good conditioning for optimization algorithms.&lt;/p&gt;

&lt;p&gt;Understanding eigenvalues and eigenvectors provides deep insights into the geometric and analytical properties of optimization problems, enabling better algorithm design and convergence analysis.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-02 Ma trận và Phép biến đổi Tuyến tính</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_02_02_Matrices_and_Linear_Transformations/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_02_02_Matrices_and_Linear_Transformations</id>
   <content type="html">&lt;p&gt;Bài học này bao gồm ma trận, các phép toán ma trận, và phép biến đổi tuyến tính, là những công cụ cơ bản để biểu diễn và giải quyết các bài toán tối ưu hóa.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ma-trận-và-các-phép-toán-ma-trận&quot;&gt;Ma trận và Các Phép toán Ma trận&lt;/h2&gt;

&lt;h3 id=&quot;ma-trận-là-gì&quot;&gt;Ma trận là gì?&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;matrix&lt;/strong&gt; is a rectangular grid of numbers arranged in rows and columns. Matrices represent data, transformations, systems of equations, and relationships between variables.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;General Form:&lt;/strong&gt;
\(\mathbf{A} = \begin{pmatrix} 
a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\
a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}
\end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This is an \(m \times n\) matrix (\(m\) rows, \(n\) columns).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}\) is a \(2 \times 3\) matrix.&lt;/p&gt;

&lt;h3 id=&quot;matrix-addition&quot;&gt;Matrix Addition&lt;/h3&gt;

&lt;p&gt;Matrices are added by summing corresponding elements. Both matrices must have the same dimensions.&lt;/p&gt;

\[\mathbf{A} + \mathbf{B} = \begin{pmatrix} a_{11} + b_{11} &amp;amp; a_{12} + b_{12} \\ a_{21} + b_{21} &amp;amp; a_{22} + b_{22} \end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 1 &amp;amp; 2 \\ 3 &amp;amp; 4 \end{pmatrix} + \begin{pmatrix} 5 &amp;amp; 6 \\ 7 &amp;amp; 8 \end{pmatrix} = \begin{pmatrix} 6 &amp;amp; 8 \\ 10 &amp;amp; 12 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;scalar-multiplication&quot;&gt;Scalar Multiplication&lt;/h3&gt;

&lt;p&gt;Multiply every element of the matrix by the scalar:&lt;/p&gt;

\[c\mathbf{A} = \begin{pmatrix} ca_{11} &amp;amp; ca_{12} \\ ca_{21} &amp;amp; ca_{22} \end{pmatrix}\]

&lt;h3 id=&quot;matrix-multiplication&quot;&gt;Matrix Multiplication&lt;/h3&gt;

&lt;p&gt;For matrices \(\mathbf{A}_{m \times n}\) and \(\mathbf{B}_{n \times p}\), the product \(\mathbf{C}_{m \times p}\) is formed by taking the dot product of rows from \(\mathbf{A}\) and columns from \(\mathbf{B}\):&lt;/p&gt;

\[c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 1 &amp;amp; 2 \\ 3 &amp;amp; 4 \end{pmatrix} \begin{pmatrix} 5 &amp;amp; 6 \\ 7 &amp;amp; 8 \end{pmatrix} = \begin{pmatrix} 1 \cdot 5 + 2 \cdot 7 &amp;amp; 1 \cdot 6 + 2 \cdot 8 \\ 3 \cdot 5 + 4 \cdot 7 &amp;amp; 3 \cdot 6 + 4 \cdot 8 \end{pmatrix} = \begin{pmatrix} 19 &amp;amp; 22 \\ 43 &amp;amp; 50 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Matrix multiplication is &lt;strong&gt;not commutative&lt;/strong&gt;: \(\mathbf{AB} \neq \mathbf{BA}\) in general.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;linear-transformations&quot;&gt;Linear Transformations&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;linear transformation&lt;/strong&gt; is a function \(T: \mathbb{R}^n \to \mathbb{R}^m\) that preserves vector addition and scalar multiplication. Every linear transformation can be represented by a matrix.&lt;/p&gt;

&lt;h3 id=&quot;definition&quot;&gt;Definition&lt;/h3&gt;

&lt;p&gt;A transformation \(T(\mathbf{v}) = \mathbf{Av}\) is linear if and only if:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Additivity:&lt;/strong&gt; \(T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Homogeneity:&lt;/strong&gt; \(T(c\mathbf{v}) = cT(\mathbf{v})\)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These can be combined into: \(T(c_1\mathbf{u} + c_2\mathbf{v}) = c_1T(\mathbf{u}) + c_2T(\mathbf{v})\)&lt;/p&gt;

&lt;h3 id=&quot;matrix-vector-multiplication&quot;&gt;Matrix-Vector Multiplication&lt;/h3&gt;

&lt;p&gt;If \(\mathbf{A}\) is an \(m \times n\) matrix and \(\mathbf{v}\) is an \(n \times 1\) column vector, their product \(\mathbf{Av}\) is an \(m \times 1\) column vector:&lt;/p&gt;

\[\mathbf{w} = \mathbf{Av} = \begin{pmatrix} 
a_{11}v_1 + a_{12}v_2 + \cdots + a_{1n}v_n \\
a_{21}v_1 + a_{22}v_2 + \cdots + a_{2n}v_n \\
\vdots \\
a_{m1}v_1 + a_{m2}v_2 + \cdots + a_{mn}v_n
\end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 2 &amp;amp; 1 \\ 0 &amp;amp; 3 \end{pmatrix} \begin{pmatrix} 4 \\ 5 \end{pmatrix} = \begin{pmatrix} 2 \cdot 4 + 1 \cdot 5 \\ 0 \cdot 4 + 3 \cdot 5 \end{pmatrix} = \begin{pmatrix} 13 \\ 15 \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;common-2d-transformations&quot;&gt;Common 2D Transformations&lt;/h2&gt;

&lt;p&gt;Understanding geometric transformations helps visualize how matrices affect vectors.&lt;/p&gt;

&lt;h3 id=&quot;scaling&quot;&gt;Scaling&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Scaling Matrix:&lt;/strong&gt;
\(\mathbf{S} = \begin{pmatrix} s_x &amp;amp; 0 \\ 0 &amp;amp; s_y \end{pmatrix}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scales x-coordinates by \(s_x\) and y-coordinates by \(s_y\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt; \(\begin{pmatrix} 2 &amp;amp; 0 \\ 0 &amp;amp; 3 \end{pmatrix}\) doubles x-values and triples y-values&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rotation&quot;&gt;Rotation&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Rotation Matrix (counter-clockwise by angle \(\theta\)):&lt;/strong&gt;
\(\mathbf{R} = \begin{pmatrix} \cos\theta &amp;amp; -\sin\theta \\ \sin\theta &amp;amp; \cos\theta \end{pmatrix}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt; 90° rotation: \(\begin{pmatrix} 0 &amp;amp; -1 \\ 1 &amp;amp; 0 \end{pmatrix}\)&lt;/li&gt;
  &lt;li&gt;Transforms \((x, y) \mapsto (-y, x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reflection&quot;&gt;Reflection&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Reflection across x-axis:&lt;/strong&gt;
\(\mathbf{F}_x = \begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; -1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reflection across y-axis:&lt;/strong&gt;
\(\mathbf{F}_y = \begin{pmatrix} -1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reflection across line \(y = x\):&lt;/strong&gt;
\(\mathbf{F}_{y=x} = \begin{pmatrix} 0 &amp;amp; 1 \\ 1 &amp;amp; 0 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;shearing&quot;&gt;Shearing&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Horizontal Shear:&lt;/strong&gt;
\(\mathbf{H} = \begin{pmatrix} 1 &amp;amp; k \\ 0 &amp;amp; 1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;Transforms \((x, y) \mapsto (x + ky, y)\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;special-types-of-matrices&quot;&gt;Special Types of Matrices&lt;/h2&gt;

&lt;h3 id=&quot;identity-matrix&quot;&gt;Identity Matrix&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;identity matrix&lt;/strong&gt; \(\mathbf{I}\) acts like the number 1 for matrix multiplication:&lt;/p&gt;

\[\mathbf{I}_n = \begin{pmatrix} 
1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 0 \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 1
\end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Property:&lt;/strong&gt; \(\mathbf{AI} = \mathbf{IA} = \mathbf{A}\) for any compatible matrix \(\mathbf{A}\).&lt;/p&gt;

&lt;h3 id=&quot;transpose&quot;&gt;Transpose&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;transpose&lt;/strong&gt; \(\mathbf{A}^T\) flips a matrix across its main diagonal:&lt;/p&gt;

\[\text{If } \mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}, \text{ then } \mathbf{A}^T = \begin{pmatrix} 1 &amp;amp; 4 \\ 2 &amp;amp; 5 \\ 3 &amp;amp; 6 \end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(\mathbf{A}^T)^T = \mathbf{A}\]
  &lt;/li&gt;
  &lt;li&gt;
\[(\mathbf{A} + \mathbf{B})^T = \mathbf{A}^T + \mathbf{B}^T\]
  &lt;/li&gt;
  &lt;li&gt;
\[(\mathbf{AB})^T = \mathbf{B}^T\mathbf{A}^T\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;symmetric-matrices&quot;&gt;Symmetric Matrices&lt;/h3&gt;

&lt;p&gt;A matrix is &lt;strong&gt;symmetric&lt;/strong&gt; if \(\mathbf{A} = \mathbf{A}^T\):&lt;/p&gt;

\[\mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 2 &amp;amp; 4 &amp;amp; 5 \\ 3 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}\]

&lt;p&gt;Symmetric matrices have special properties important in optimization.&lt;/p&gt;

&lt;h3 id=&quot;inverse-matrix&quot;&gt;Inverse Matrix&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;inverse&lt;/strong&gt; \(\mathbf{A}^{-1}\) of a square matrix \(\mathbf{A}\) satisfies:&lt;/p&gt;

\[\mathbf{A}\mathbf{A}^{-1} = \mathbf{A}^{-1}\mathbf{A} = \mathbf{I}\]

&lt;p&gt;&lt;strong&gt;For 2×2 matrices:&lt;/strong&gt;
\(\mathbf{A}^{-1} = \frac{1}{\det(\mathbf{A})} \begin{pmatrix} d &amp;amp; -b \\ -c &amp;amp; a \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;where \(\mathbf{A} = \begin{pmatrix} a &amp;amp; b \\ c &amp;amp; d \end{pmatrix}\) and \(\det(\mathbf{A}) = ad - bc\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Not all matrices have inverses. A matrix is &lt;strong&gt;invertible&lt;/strong&gt; (non-singular) if and only if its determinant is non-zero.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;p&gt;Matrices and linear transformations are fundamental in optimization for several reasons:&lt;/p&gt;

&lt;h3 id=&quot;1-system-of-linear-equations&quot;&gt;1. System of Linear Equations&lt;/h3&gt;

&lt;p&gt;Many optimization problems involve solving \(\mathbf{Ax} = \mathbf{b}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Unique solution:&lt;/strong&gt; \(\mathbf{x} = \mathbf{A}^{-1}\mathbf{b}\) (when \(\mathbf{A}\) is invertible)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Least squares:&lt;/strong&gt; Minimize \(\|\mathbf{Ax} - \mathbf{b}\|^2\) when no exact solution exists&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-quadratic-forms&quot;&gt;2. Quadratic Forms&lt;/h3&gt;

&lt;p&gt;Quadratic functions appear frequently in optimization:
\(f(\mathbf{x}) = \mathbf{x}^T\mathbf{Q}\mathbf{x} + \mathbf{c}^T\mathbf{x} + d\)&lt;/p&gt;

&lt;p&gt;The matrix \(\mathbf{Q}\) determines the curvature properties of the function.&lt;/p&gt;

&lt;h3 id=&quot;3-linear-programming&quot;&gt;3. Linear Programming&lt;/h3&gt;

&lt;p&gt;Standard form: Minimize \(\mathbf{c}^T\mathbf{x}\) subject to \(\mathbf{Ax} = \mathbf{b}\), \(\mathbf{x} \geq \mathbf{0}\)&lt;/p&gt;

&lt;h3 id=&quot;4-constraint-representation&quot;&gt;4. Constraint Representation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Equality constraints:&lt;/strong&gt; \(\mathbf{Ax} = \mathbf{b}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Inequality constraints:&lt;/strong&gt; \(\mathbf{Ax} \leq \mathbf{b}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-transformations-of-variables&quot;&gt;5. Transformations of Variables&lt;/h3&gt;

&lt;p&gt;Change of variables: \(\mathbf{y} = \mathbf{T}\mathbf{x}\) can simplify optimization problems.&lt;/p&gt;

&lt;h3 id=&quot;example-portfolio-optimization&quot;&gt;Example: Portfolio Optimization&lt;/h3&gt;

&lt;p&gt;In finance, we might minimize portfolio risk:
\(\text{minimize } \mathbf{w}^T\mathbf{\Sigma}\mathbf{w}\)&lt;/p&gt;

&lt;p&gt;where \(\mathbf{w}\) is the vector of portfolio weights and \(\mathbf{\Sigma}\) is the covariance matrix of asset returns.&lt;/p&gt;

&lt;p&gt;Understanding matrices and linear transformations provides the tools to formulate, analyze, and solve a wide variety of optimization problems efficiently.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-01 Vector và Không gian Vector</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_02_01_Vectors_and_Vector_Spaces/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_02_01_Vectors_and_Vector_Spaces</id>
   <content type="html">&lt;p&gt;Bài học này giới thiệu vector, không gian vector, và các khái niệm cơ bản tạo nền tảng để hiểu đại số tuyến tính trong ngữ cảnh tối ưu hóa.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;vector-và-không-gian-vector-mathbbrn&quot;&gt;Vector và Không gian Vector (\(\mathbb{R}^n\))&lt;/h2&gt;

&lt;h3 id=&quot;vector-là-gì&quot;&gt;Vector là gì?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vector:&lt;/strong&gt; Hãy nghĩ về vector như một mũi tên trong không gian, biểu diễn cả hướng và độ lớn (độ dài). Về mặt toán học, nó là một danh sách có thứ tự các số, giống như tọa độ. Ví dụ, một vector trong không gian 2D có thể là \(\mathbf{v} = \begin{pmatrix} 3 \\ 4 \end{pmatrix}\), có nghĩa là 3 đơn vị dọc theo trục x và 4 đơn vị dọc theo trục y.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Góc nhìn Hình học vs Đại số:&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Hình học:&lt;/strong&gt; Vector là mũi tên có hướng và độ lớn&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Đại số:&lt;/strong&gt; Vector là danh sách có thứ tự các số thực&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;không-gian-vector&quot;&gt;Không gian Vector&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Không gian Vector (\(\mathbb{R}^n\)):&lt;/strong&gt; Đây là tập hợp tất cả các vector có thể có \(n\) thành phần (số). Ví dụ, \(\mathbb{R}^2\) bao gồm tất cả vector 2 thành phần, biểu diễn tất cả các điểm hoặc mũi tên trong mặt phẳng 2D.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;\(\mathbb{R}^2 = \left\{\begin{pmatrix} x \\ y \end{pmatrix} : x, y \in \mathbb{R}\right\}\) (mặt phẳng)&lt;/li&gt;
      &lt;li&gt;\(\mathbb{R}^3 = \left\{\begin{pmatrix} x \\ y \\ z \end{pmatrix} : x, y, z \in \mathbb{R}\right\}\) (không gian 3D)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;các-phép-toán-vector&quot;&gt;Các Phép toán Vector&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Phép Cộng Vector:&lt;/strong&gt;
\(\mathbf{u} + \mathbf{v} = \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_n \end{pmatrix} + \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} = \begin{pmatrix} u_1 + v_1 \\ u_2 + v_2 \\ \vdots \\ u_n + v_n \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phép Nhân Vô hướng:&lt;/strong&gt;
\(c\mathbf{v} = c \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} = \begin{pmatrix} cv_1 \\ cv_2 \\ \vdots \\ cv_n \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;độc-lập-tuyến-tính-cơ-sở-và-chiều&quot;&gt;Độc lập Tuyến tính, Cơ sở, và Chiều&lt;/h2&gt;

&lt;h3 id=&quot;độc-lập-tuyến-tính&quot;&gt;Độc lập Tuyến tính&lt;/h3&gt;

&lt;p&gt;Một tập hợp vector \(\{\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_k\}\) là &lt;strong&gt;độc lập tuyến tính&lt;/strong&gt; nếu nghiệm duy nhất của:&lt;/p&gt;

\[c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + \cdots + c_k\mathbf{v}_k = \mathbf{0}\]

&lt;p&gt;là \(c_1 = c_2 = \cdots = c_k = 0\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hiểu biết Trực quan:&lt;/strong&gt; Một tập hợp vector “độc lập tuyến tính” nếu không có vector nào trong tập có thể được tạo ra bằng cách chia tỷ lệ và cộng các vector khác trong tập. Tất cả chúng đều chỉ theo các hướng “đủ khác nhau”.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ trong \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) và \(\mathbf{v}_2 = \begin{pmatrix} 0 \\ 1 \end{pmatrix}\) là độc lập tuyến tính&lt;/li&gt;
  &lt;li&gt;\(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 2 \end{pmatrix}\) và \(\mathbf{v}_2 = \begin{pmatrix} 2 \\ 4 \end{pmatrix}\) là phụ thuộc tuyến tính (vì \(\mathbf{v}_2 = 2\mathbf{v}_1\))&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cơ-sở&quot;&gt;Cơ sở&lt;/h3&gt;

&lt;p&gt;Một &lt;strong&gt;cơ sở&lt;/strong&gt; cho một không gian vector là một tập hợp tối thiểu các vector độc lập tuyến tính có thể được kết hợp (chia tỷ lệ và cộng) để tạo ra &lt;em&gt;bất kỳ&lt;/em&gt; vector nào khác trong không gian đó. Nó giống như một tập hợp các khối xây dựng cơ bản.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tính chất của một Cơ sở:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Các vector độc lập tuyến tính&lt;/li&gt;
  &lt;li&gt;Chúng sinh ra toàn bộ không gian vector&lt;/li&gt;
  &lt;li&gt;Mọi vector trong không gian có thể được viết duy nhất như một tổ hợp tuyến tính của các vector cơ sở&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Cơ sở Chuẩn cho \(\mathbb{R}^n\):&lt;/strong&gt;
\(\mathbf{e}_1 = \begin{pmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{pmatrix}, \mathbf{e}_2 = \begin{pmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{pmatrix}, \ldots, \mathbf{e}_n = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 1 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;chiều&quot;&gt;Chiều&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Chiều&lt;/strong&gt; của một không gian vector đơn giản là số lượng vector trong bất kỳ cơ sở nào của nó. Nó cho bạn biết cần bao nhiêu hướng độc lập để mô tả không gian.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^2) = 2\]
  &lt;/li&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^3) = 3\]
  &lt;/li&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^n) = n\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;chuẩn-của-vector&quot;&gt;Chuẩn của Vector&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Chuẩn&lt;/strong&gt; là một hàm gán “độ dài” hoặc “kích thước” cho một vector. Nó tổng quát hóa khái niệm khoảng cách từ gốc tọa độ.&lt;/p&gt;

&lt;h3 id=&quot;tính-chất-của-chuẩn&quot;&gt;Tính chất của Chuẩn&lt;/h3&gt;

&lt;p&gt;Bất kỳ chuẩn \(\|\cdot\|\) nào cũng phải thỏa mãn ba tính chất:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Không âm:&lt;/strong&gt; \(\|\mathbf{x}\| \geq 0\), và \(\|\mathbf{x}\| = 0\) khi và chỉ khi \(\mathbf{x} = \mathbf{0}\)&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Đồng nhất:&lt;/strong&gt; $$|t\mathbf{x}| =&lt;/td&gt;
          &lt;td&gt;t&lt;/td&gt;
          &lt;td&gt;|\mathbf{x}|\(với bất kỳ vô hướng\)t$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bất đẳng thức Tam giác:&lt;/strong&gt; \(\|\mathbf{x} + \mathbf{y}\| \leq \|\mathbf{x}\| + \|\mathbf{y}\|\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;các-chuẩn-thông-dụng&quot;&gt;Các Chuẩn Thông dụng&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Chuẩn Euclid (Chuẩn L2):&lt;/strong&gt;
\(\|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^n x_i^2} = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}\)&lt;/p&gt;

&lt;p&gt;Đây là khoảng cách “thông thường” mà chúng ta quen thuộc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Chuẩn Manhattan (Chuẩn L1):&lt;/strong&gt;
\(\|\mathbf{x}\|_1 = \sum_{i=1}^n |x_i| = |x_1| + |x_2| + \cdots + |x_n|\)&lt;/p&gt;

&lt;p&gt;Còn được gọi là “chuẩn taxi” - khoảng cách mà một chiếc taxi sẽ đi trong thành phố có bố cục dạng lưới.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Chuẩn Tối đa (Chuẩn L∞):&lt;/strong&gt;
\(\|\mathbf{x}\|_\infty = \max_{i} |x_i|\)&lt;/p&gt;

&lt;p&gt;Thành phần lớn nhất theo giá trị tuyệt đối.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt; Với \(\mathbf{x} = \begin{pmatrix} 3 \\ -4 \\ 1 \end{pmatrix}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_2 = \sqrt{3^2 + (-4)^2 + 1^2} = \sqrt{26} \approx 5.1\]
  &lt;/li&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_1 = |3| + |-4| + |1| = 8\]
  &lt;/li&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_\infty = \max\{|3|, |-4|, |1|\} = 4\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tích-vô-hướng-tích-chấm&quot;&gt;Tích Vô hướng (Tích Chấm)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Tích chấm&lt;/strong&gt; (hoặc tích vô hướng) là cách phổ biến nhất để nhân hai vector, tạo ra kết quả vô hướng.&lt;/p&gt;

&lt;h3 id=&quot;định-nghĩa&quot;&gt;Định nghĩa&lt;/h3&gt;

&lt;p&gt;Với hai vector \(\mathbf{x}\) và \(\mathbf{y}\) trong \(\mathbb{R}^n\):&lt;/p&gt;

\[\mathbf{x}^T \mathbf{y} = \mathbf{x} \cdot \mathbf{y} = \sum_{i=1}^n x_i y_i = x_1 y_1 + x_2 y_2 + \cdots + x_n y_n\]

&lt;h3 id=&quot;diễn-giải-hình-học&quot;&gt;Diễn giải Hình học&lt;/h3&gt;

\[\mathbf{x} \cdot \mathbf{y} = \|\mathbf{x}\| \|\mathbf{y}\| \cos \theta\]

&lt;p&gt;trong đó \(\theta\) là góc giữa các vector.&lt;/p&gt;

&lt;h3 id=&quot;tính-chất&quot;&gt;Tính chất&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Giao hoán:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = \mathbf{y} \cdot \mathbf{x}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phân phối:&lt;/strong&gt; \(\mathbf{x} \cdot (\mathbf{y} + \mathbf{z}) = \mathbf{x} \cdot \mathbf{y} + \mathbf{x} \cdot \mathbf{z}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Đồng nhất:&lt;/strong&gt; \((c\mathbf{x}) \cdot \mathbf{y} = c(\mathbf{x} \cdot \mathbf{y})\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;trường-hợp-đặc-biệt&quot;&gt;Trường hợp Đặc biệt&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Vector trực giao:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = 0\) (vuông góc)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Vector song song:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = \pm \|\mathbf{x}\| \|\mathbf{y}\|\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tích chấm bản thân:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{x} = \|\mathbf{x}\|_2^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ví-dụ&quot;&gt;Ví dụ&lt;/h3&gt;

&lt;p&gt;Với \(\mathbf{x} = \begin{pmatrix} 1 \\ 2 \end{pmatrix}\) và \(\mathbf{y} = \begin{pmatrix} 3 \\ 4 \end{pmatrix}\):&lt;/p&gt;

\[\mathbf{x}^T \mathbf{y} = (1)(3) + (2)(4) = 3 + 8 = 11\]

&lt;hr /&gt;

&lt;h2 id=&quot;ứng-dụng-trong-tối-ưu-hóa&quot;&gt;Ứng dụng trong Tối ưu hóa&lt;/h2&gt;

&lt;p&gt;Hiểu về vector và không gian vector là rất quan trọng cho tối ưu hóa vì:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Biến Quyết định:&lt;/strong&gt; Các bài toán tối ưu hóa thường liên quan đến việc tìm giá trị tốt nhất cho nhiều biến, được biểu diễn tự nhiên như vector.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gradient:&lt;/strong&gt; Gradient của một hàm là một vector chỉ theo hướng tăng dốc nhất.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ràng buộc:&lt;/strong&gt; Ràng buộc tuyến tính trong tối ưu hóa có thể được biểu diễn bằng tích chấm: \(\mathbf{a}^T \mathbf{x} \leq b\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Khoảng cách và Độ tương tự:&lt;/strong&gt; Các chuẩn khác nhau cung cấp các cách khác nhau để đo khoảng cách giữa các nghiệm hoặc kích thước của các thay đổi.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tính trực giao:&lt;/strong&gt; Nhiều khái niệm tối ưu hóa dựa vào tính vuông góc, chẳng hạn như mối quan hệ giữa gradient và đường mức.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tổ hợp Tuyến tính:&lt;/strong&gt; Vùng khả thi thường được định nghĩa như tổ hợp tuyến tính của vector (bao lồi, hình nón, v.v.).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Khung không gian vector cung cấp nền tảng toán học để xây dựng và giải quyết các bài toán tối ưu hóa một cách có hệ thống.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01 Giải tích</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_01_Calculus/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_01_Calculus</id>
   <content type="html">&lt;p&gt;Bài học này bao gồm các khái niệm giải tích cần thiết cho tối ưu hóa, được tổ chức thành bốn phần chính để hiểu rõ hơn.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-04 Chuỗi Taylor</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_01_04_Taylor_Series/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_01_04_Taylor_Series</id>
   <content type="html">&lt;p&gt;Bài học này bao gồm việc khai triển chuỗi Taylor, điều này rất cơ bản để xấp xỉ các hàm và hiểu hành vi cục bộ của các hàm trong các thuật toán tối ưu hóa.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;định-nghĩa-chuỗi-taylor&quot;&gt;Định nghĩa Chuỗi Taylor&lt;/h2&gt;

&lt;p&gt;Chuỗi Taylor là một biểu diễn của một hàm dưới dạng tổng vô hạn các số hạng được tính từ giá trị các đạo hàm của hàm tại một điểm duy nhất. Nó cung cấp một cách để xấp xỉ các hàm phức tạp bằng cách sử dụng đa thức.&lt;/p&gt;

&lt;h3 id=&quot;chuỗi-taylor-một-biến&quot;&gt;Chuỗi Taylor Một Biến&lt;/h3&gt;

&lt;p&gt;Chuỗi Taylor là một khai triển chuỗi của hàm \(f(x)\) tại điểm \(a\):&lt;/p&gt;

\[f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n\]

&lt;p&gt;Dưới dạng khai triển:&lt;/p&gt;

\[f(x) = f(a) + \frac{f&apos;(a)}{1!}(x-a) + \frac{f&apos;&apos;(a)}{2!}(x-a)^2 + \frac{f&apos;&apos;&apos;(a)}{3!}(x-a)^3 + \dots\]

&lt;h3 id=&quot;chuỗi-maclaurin&quot;&gt;Chuỗi Maclaurin&lt;/h3&gt;

&lt;p&gt;Khi khai triển tại \(a = 0\), chuỗi Taylor được gọi là &lt;strong&gt;chuỗi Maclaurin&lt;/strong&gt;:&lt;/p&gt;

\[f(x) = f(0) + f&apos;(0)x + \frac{f&apos;&apos;(0)}{2!}x^2 + \frac{f&apos;&apos;&apos;(0)}{3!}x^3 + \dots\]

&lt;h3 id=&quot;các-chuỗi-maclaurin-thông-dụng&quot;&gt;Các Chuỗi Maclaurin Thông Dụng&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Hàm Mũ:&lt;/strong&gt;
\(e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!} + \dots = \sum_{n=0}^{\infty} \frac{x^n}{n!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hàm Sin:&lt;/strong&gt;
\(\sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \dots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{(2n+1)!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hàm Cosin:&lt;/strong&gt;
\(\cos x = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \dots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{(2n)!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Logarit Tự Nhiên (với \(|x| &amp;lt; 1\)):&lt;/strong&gt;
\(\ln(1 + x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \dots = \sum_{n=1}^{\infty} \frac{(-1)^{n+1} x^n}{n}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;chuỗi-taylor-đa-biến&quot;&gt;Chuỗi Taylor Đa Biến&lt;/h2&gt;

&lt;p&gt;Đối với các hàm nhiều biến, chuỗi Taylor trở nên phức tạp hơn nhưng tuân theo các nguyên lý tương tự. Việc khai triển tại điểm \(\mathbf{x}_0\) liên quan đến các đạo hàm riêng.&lt;/p&gt;

&lt;h3 id=&quot;khai-triển-taylor-bậc-nhất&quot;&gt;Khai triển Taylor Bậc Nhất&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Xấp xỉ tuyến tính&lt;/strong&gt; của \(f(\mathbf{x})\) tại \(\mathbf{x}_0\):&lt;/p&gt;

\[f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0)\]

&lt;p&gt;Đây là phương trình của mặt phẳng tiếp tuyến với hàm tại \(\mathbf{x}_0\).&lt;/p&gt;

&lt;h3 id=&quot;khai-triển-taylor-bậc-hai&quot;&gt;Khai triển Taylor Bậc Hai&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Xấp xỉ bậc hai&lt;/strong&gt; bao gồm thông tin về độ cong:&lt;/p&gt;

\[f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \nabla^2 f(\mathbf{x}_0) (\mathbf{x} - \mathbf{x}_0)\]

&lt;p&gt;trong đó \(\nabla^2 f(\mathbf{x}_0)\) là ma trận Hessian tại \(\mathbf{x}_0\).&lt;/p&gt;

&lt;h3 id=&quot;dạng-tổng-quát&quot;&gt;Dạng Tổng Quát&lt;/h3&gt;

&lt;p&gt;Chuỗi Taylor đa biến hoàn chỉnh liên quan đến các tensor bậc cao:&lt;/p&gt;

\[f(\mathbf{x}) = \sum_{|\alpha|=0}^{\infty} \frac{D^{\alpha} f(\mathbf{x}_0)}{\alpha!} (\mathbf{x} - \mathbf{x}_0)^{\alpha}\]

&lt;p&gt;trong đó \(\alpha = (\alpha_1, \alpha_2, \ldots, \alpha_n)\) là chỉ số đa chiều.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ứng-dụng-trong-tối-ưu-hóa&quot;&gt;Ứng dụng trong Tối ưu hóa&lt;/h2&gt;

&lt;p&gt;Chuỗi Taylor là nền tảng của lý thuyết tối ưu hóa và các thuật toán vì một số lý do:&lt;/p&gt;

&lt;h3 id=&quot;1-xấp-xỉ-hàm-cục-bộ&quot;&gt;1. Xấp xỉ Hàm Cục bộ&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Xấp xỉ Tuyến tính (Phương pháp Bậc Nhất):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Được sử dụng trong các thuật toán gradient descent&lt;/li&gt;
  &lt;li&gt;Giả định hàm xấp xỉ tuyến tính trong một vùng lân cận nhỏ&lt;/li&gt;
  &lt;li&gt;Kích thước bước phải đủ nhỏ để xấp xỉ có hiệu lực&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Xấp xỉ Bậc Hai (Phương pháp Bậc Hai):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Được sử dụng trong phương pháp Newton và quasi-Newton&lt;/li&gt;
  &lt;li&gt;Nắm bắt thông tin độ cong thông qua Hessian&lt;/li&gt;
  &lt;li&gt;Thường cung cấp hội tụ nhanh hơn so với phương pháp bậc nhất&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-điều-kiện-tối-ưu&quot;&gt;2. Điều kiện Tối ưu&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Điều kiện Cần Thiết Bậc Nhất:&lt;/strong&gt;
Tại cực tiểu địa phương \(\mathbf{x}^*\), ta phải có \(\nabla f(\mathbf{x}^*) = \mathbf{0}\).&lt;/p&gt;

&lt;p&gt;Điều này xuất phát từ khai triển Taylor bậc nhất: nếu \(\nabla f(\mathbf{x}^*) \neq \mathbf{0}\), ta có thể di chuyển theo hướng \(-\nabla f(\mathbf{x}^*)\) để giảm giá trị hàm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Điều kiện Đủ Bậc Hai:&lt;/strong&gt;
Nếu \(\nabla f(\mathbf{x}^*) = \mathbf{0}\) và \(\nabla^2 f(\mathbf{x}^*)\) là xác định dương, thì \(\mathbf{x}^*\) là cực tiểu địa phương.&lt;/p&gt;

&lt;p&gt;Điều này xuất phát từ khai triển Taylor bậc hai: số hạng bậc hai chiếm ưu thế gần \(\mathbf{x}^*\).&lt;/p&gt;

&lt;h3 id=&quot;3-thiết-kế-thuật-toán&quot;&gt;3. Thiết kế Thuật toán&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Phương pháp Newton:&lt;/strong&gt;
Sử dụng xấp xỉ Taylor bậc hai để tìm cực tiểu của mô hình bậc hai:&lt;/p&gt;

\[\mathbf{x}_{k+1} = \mathbf{x}_k - [\nabla^2 f(\mathbf{x}_k)]^{-1} \nabla f(\mathbf{x}_k)\]

&lt;p&gt;&lt;strong&gt;Phương pháp Trust Region:&lt;/strong&gt;
Sử dụng xấp xỉ Taylor trong vùng tin cậy nơi xấp xỉ được cho là chính xác.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phương pháp Line Search:&lt;/strong&gt;
Sử dụng khai triển Taylor để xác định kích thước bước phù hợp dọc theo hướng tìm kiếm.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ví-dụ-phân-tích-hàm-bậc-hai&quot;&gt;Ví dụ: Phân tích Hàm Bậc Hai&lt;/h2&gt;

&lt;p&gt;Xét \(f(x, y) = x^2 + 2xy + 3y^2\) tại điểm \((0, 0)\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient:&lt;/strong&gt;
\(\nabla f = \begin{pmatrix} 2x + 2y \\ 2x + 6y \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;Tại \((0, 0)\): \(\nabla f(0, 0) = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hessian:&lt;/strong&gt;
\(\nabla^2 f = \begin{pmatrix} 2 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Khai triển Taylor Bậc Hai tại \((0, 0)\):&lt;/strong&gt;
\(f(x, y) \approx f(0, 0) + 0 + \frac{1}{2} \begin{pmatrix} x &amp;amp; y \end{pmatrix} \begin{pmatrix} 2 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}\)&lt;/p&gt;

\[= 0 + \frac{1}{2}(2x^2 + 4xy + 6y^2) = x^2 + 2xy + 3y^2\]

&lt;p&gt;Trong trường hợp này, hàm là chính xác bậc hai, nên khai triển Taylor bậc hai là chính xác.&lt;/p&gt;

&lt;p&gt;Vì Hessian có các giá trị riêng \(\lambda_1 = 2 + 2\sqrt{2} &amp;gt; 0\) và \(\lambda_2 = 2 - 2\sqrt{2} &amp;lt; 0\), điểm \((0, 0)\) là điểm yên ngựa, không phải cực tiểu.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;các-xem-xét-thực-tế&quot;&gt;Các Xem xét Thực tế&lt;/h2&gt;

&lt;h3 id=&quot;hội-tụ-và-độ-chính-xác&quot;&gt;Hội tụ và Độ chính xác&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Bán kính Hội tụ&lt;/strong&gt;: Chuỗi Taylor chỉ hội tụ trong một bán kính nhất định từ điểm khai triển&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sai số Cắt bỏ&lt;/strong&gt;: Sử dụng số hạng hữu hạn đưa vào sai số xấp xỉ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Chi phí Tính toán&lt;/strong&gt;: Các số hạng bậc cao yêu cầu tính toán nhiều đạo hàm hơn&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;lựa-chọn-thuật-toán-tối-ưu-hóa&quot;&gt;Lựa chọn Thuật toán Tối ưu hóa&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Phương pháp bậc nhất&lt;/strong&gt; (gradient descent): Chỉ sử dụng thông tin gradient, chậm hơn nhưng rẻ hơn mỗi lần lặp&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phương pháp bậc hai&lt;/strong&gt; (Newton): Sử dụng thông tin Hessian, hội tụ nhanh hơn nhưng đắt mỗi lần lặp&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phương pháp quasi-Newton&lt;/strong&gt;: Xấp xỉ Hessian, cân bằng giữa tốc độ và chi phí tính toán&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Khai triển chuỗi Taylor giúp chúng ta xấp xỉ các hàm phức tạp với các hàm đa thức đơn giản hơn xung quanh một điểm cụ thể, điều này rất quan trọng cho các thuật toán tối ưu hóa và hiểu hành vi cục bộ của các hàm.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-03 Gradient và Đạo hàm Hướng</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_01_03_Gradient_and_Directional_Derivatives/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_01_03_Gradient_and_Directional_Derivatives</id>
   <content type="html">&lt;p&gt;Bài học này khám phá vector gradient và đạo hàm hướng, những khái niệm trung tâm trong tối ưu hóa để hiểu cách các hàm số thay đổi theo các hướng khác nhau.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;vector-gradient&quot;&gt;Vector Gradient&lt;/h2&gt;

&lt;p&gt;Gradient \(\nabla f\) là một vector gồm các đạo hàm riêng của hàm số \(f\) theo từng biến của nó. Nó chỉ ra hướng tăng dốc nhất của hàm số tại một điểm cho trước.&lt;/p&gt;

&lt;h3 id=&quot;định-nghĩa-và-tính-toán&quot;&gt;Định nghĩa và Tính toán&lt;/h3&gt;

&lt;p&gt;Với hàm hai biến \(f(x, y)\), gradient của nó là:&lt;/p&gt;

\[\nabla f = \begin{pmatrix} \frac{\partial f}{\partial x} \\ \frac{\partial f}{\partial y} \end{pmatrix}\]

&lt;p&gt;Với hàm \(n\) biến \(f(x_1, x_2, \ldots, x_n)\):&lt;/p&gt;

\[\nabla f = \begin{pmatrix} \frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{pmatrix}\]

&lt;h3 id=&quot;ví-dụ-tính-gradient&quot;&gt;Ví dụ: Tính Gradient&lt;/h3&gt;

&lt;p&gt;Với \(f(x, y) = x^2 + 3xy + y^2\):&lt;/p&gt;

&lt;p&gt;\(\frac{\partial f}{\partial x} = 2x + 3y\)
\(\frac{\partial f}{\partial y} = 3x + 2y\)&lt;/p&gt;

&lt;p&gt;Do đó: \(\nabla f = \begin{pmatrix} 2x + 3y \\ 3x + 2y \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;Tại điểm \((1, 2)\): \(\nabla f(1, 2) = \begin{pmatrix} 2(1) + 3(2) \\ 3(1) + 2(2) \end{pmatrix} = \begin{pmatrix} 8 \\ 7 \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;đạo-hàm-hướng&quot;&gt;Đạo hàm Hướng&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Đạo hàm hướng&lt;/strong&gt; đo tốc độ thay đổi của \(f\) khi chúng ta di chuyển theo bất kỳ hướng nào được chọn \(\mathbf{u}\). Ở đây \(\mathbf{u}\) phải là vector đơn vị (có độ dài bằng 1).&lt;/p&gt;

&lt;h3 id=&quot;định-nghĩa&quot;&gt;Định nghĩa&lt;/h3&gt;

&lt;p&gt;Với hàm số \(f(\mathbf{x})\) và vector đơn vị \(\mathbf{u} = \langle u_1, u_2, \ldots, u_n \rangle\):&lt;/p&gt;

\[D_{\mathbf{u}}f(\mathbf{x}) = \nabla f(\mathbf{x}) \cdot \mathbf{u} = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} u_i\]

&lt;h3 id=&quot;giải-thích-hình-học&quot;&gt;Giải thích Hình học&lt;/h3&gt;

&lt;p&gt;Đạo hàm hướng có thể được viết như:&lt;/p&gt;

\[D_{\mathbf{u}}f = \lvert \nabla f \rvert \cos \theta\]

&lt;p&gt;nơi \(\theta\) là góc giữa \(\nabla f\) và \(\mathbf{u}\), và \(\lvert \nabla f \rvert\) là độ lớn của gradient.&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-tính-đạo-hàm-hướng&quot;&gt;Ví dụ: Tính Đạo hàm Hướng&lt;/h3&gt;

&lt;p&gt;Sử dụng ví dụ trước \(f(x, y) = x^2 + 3xy + y^2\) tại điểm \((1, 2)\) nơi \(\nabla f(1, 2) = \begin{pmatrix} 8 \\ 7 \end{pmatrix}\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hướng 1:&lt;/strong&gt; \(\mathbf{u}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) (hướng x dương)
\(D_{\mathbf{u}_1}f(1, 2) = 8 \cdot 1 + 7 \cdot 0 = 8\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hướng 2:&lt;/strong&gt; \(\mathbf{u}_2 = \begin{pmatrix} 0 \\ 1 \end{pmatrix}\) (hướng y dương)
\(D_{\mathbf{u}_2}f(1, 2) = 8 \cdot 0 + 7 \cdot 1 = 7\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hướng 3:&lt;/strong&gt; \(\mathbf{u}_3 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1 \end{pmatrix}\) (đường chéo 45°)
\(D_{\mathbf{u}_3}f(1, 2) = 8 \cdot \frac{1}{\sqrt{2}} + 7 \cdot \frac{1}{\sqrt{2}} = \frac{15}{\sqrt{2}} \approx 10.61\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tốc-độ-thay-đổi-tối-đa-và-tối-thiểu&quot;&gt;Tốc độ Thay đổi Tối đa và Tối thiểu&lt;/h2&gt;

&lt;h3 id=&quot;các-tính-chất-chính&quot;&gt;Các Tính chất Chính&lt;/h3&gt;

&lt;p&gt;Từ công thức \(D_{\mathbf{u}}f = \lvert \nabla f \rvert \cos \theta\), chúng ta có thể xác định:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Tốc độ Thay đổi Tối đa&lt;/strong&gt;: Xảy ra khi \(\cos \theta = 1\) (tức là \(\theta = 0°\))
    &lt;ul&gt;
      &lt;li&gt;Hướng: \(\mathbf{u} = \frac{\nabla f}{\lvert \nabla f \rvert}\) (cùng hướng với gradient)&lt;/li&gt;
      &lt;li&gt;Tốc độ tối đa: \(D_{\max}f = \lvert \nabla f \rvert\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tốc độ Thay đổi Tối thiểu&lt;/strong&gt;: Xảy ra khi \(\cos \theta = -1\) (tức là \(\theta = 180°\))
    &lt;ul&gt;
      &lt;li&gt;Hướng: \(\mathbf{u} = -\frac{\nabla f}{\lvert \nabla f \rvert}\) (ngược với gradient)&lt;/li&gt;
      &lt;li&gt;Tốc độ tối thiểu: \(D_{\min}f = -\lvert \nabla f \rvert\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tốc độ Thay đổi Bằng Không&lt;/strong&gt;: Xảy ra khi \(\cos \theta = 0\) (tức là \(\theta = 90°\))
    &lt;ul&gt;
      &lt;li&gt;Hướng: Bất kỳ vector nào vuông góc với \(\nabla f\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;tóm-tắt-các-tính-chất-của-gradient&quot;&gt;Tóm tắt Các Tính chất của Gradient&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Gradient \(\nabla f\) chỉ theo hướng &lt;strong&gt;tăng dốc nhất&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Hướng \(-\nabla f\) chỉ theo hướng &lt;strong&gt;giảm dốc nhất&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Độ lớn \(\lvert \nabla f \rvert\) cho &lt;strong&gt;tốc độ thay đổi tối đa&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Khi \(\nabla f = \mathbf{0}\), điểm đó là &lt;strong&gt;điểm tới hạn&lt;/strong&gt; (tối ưu tiềm năng)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;mối-quan-hệ-với-đường-đồng-mức&quot;&gt;Mối quan hệ với Đường đồng mức&lt;/h2&gt;

&lt;p&gt;Tại bất kỳ điểm nào trên đường mức \(f(x, y) = c\), vector gradient \(\nabla f\) &lt;strong&gt;trực giao (vuông góc)&lt;/strong&gt; với đường tiếp tuyến của đường mức tại điểm đó.&lt;/p&gt;

&lt;h3 id=&quot;tại-sao-điều-này-quan-trọng&quot;&gt;Tại sao Điều này Quan trọng&lt;/h3&gt;

&lt;p&gt;Tính chất trực giao này rất cơ bản vì:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Đường mức biểu diễn giá trị hàm hằng số&lt;/strong&gt;: Di chuyển dọc theo đường mức không thay đổi giá trị hàm, nên đạo hàm hướng bằng không.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gradient chỉ hướng tăng dốc nhất&lt;/strong&gt;: Hướng tăng giá trị hàm nhanh nhất phải vuông góc với hướng không thay đổi giá trị chút nào.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Thông đạt tối ưu hóa&lt;/strong&gt;: Để tìm cực trị, chúng ta tìm các điểm nơi gradient bằng không (điểm tới hạn) hoặc nơi gradient vuông góc với biên ràng buộc.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;ứng-dụng-trong-tối-ưu-hóa&quot;&gt;Ứng dụng trong Tối ưu hóa&lt;/h3&gt;

&lt;p&gt;Hiểu gradient và đạo hàm hướng rất quan trọng cho:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Gradient Descent&lt;/strong&gt;: Di chuyển theo hướng \(-\nabla f\) để tối thiểu hóa \(f\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Gradient Ascent&lt;/strong&gt;: Di chuyển theo hướng \(+\nabla f\) để tối đa hóa \(f\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tối ưu hóa có Ràng buộc&lt;/strong&gt;: Sử dụng mối quan hệ giữa gradient và đường mức&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phân tích Hội tụ&lt;/strong&gt;: Hiểu khi nào thuật toán sẽ hội tụ đến nghiệm tối ưu&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lựa chọn Kích thước Bước&lt;/strong&gt;: Xác định di chuyển bao xa theo hướng gradient&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Gradient cung cấp cả hướng di chuyển và thông tin về tốc độ thay đổi của hàm, làm cho nó trở thành nền tảng cho hầu hết các thuật toán tối ưu hóa.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-02 Đạo hàm và Giải tích đa biến</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_01_02_Derivatives_and_Multivariable_Calculus/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_01_02_Derivatives_and_Multivariable_Calculus</id>
   <content type="html">&lt;p&gt;Bài học này bao gồm đạo hàm và các khái niệm giải tích đa biến thiết yếu tạo nền tảng cho lý thuyết và thuật toán tối ưu hóa.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;đạo-hàm-và-tốc-độ-thay-đổi&quot;&gt;Đạo hàm và Tốc độ Thay đổi&lt;/h2&gt;

&lt;p&gt;Đạo hàm của một hàm một biến thể hiện tốc độ thay đổi tức thời của nó, điều này rất cơ bản để hiểu cách các hàm số hoạt động cục bộ.&lt;/p&gt;

&lt;h3 id=&quot;các-khái-niệm-đạo-hàm-cơ-bản&quot;&gt;Các Khái niệm Đạo hàm Cơ bản&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Độ dốc giữa hai điểm:&lt;/strong&gt;&lt;/p&gt;

\[\text{Độ dốc} = \frac{y_2 - y_1}{x_2 - x_1}\]

&lt;p&gt;&lt;strong&gt;Đạo hàm (tốc độ thay đổi tức thời):&lt;/strong&gt;&lt;/p&gt;

\[f&apos;(x_0) = \lim_{x_1 \to x_0} \frac{f(x_1) - f(x_0)}{x_1 - x_0} = \lim_{\Delta x \to 0} \frac{f(x_0 + \Delta x) - f(x_0)}{\Delta x}\]

&lt;p&gt;Đạo hàm cho chúng ta biết hàm số thay đổi nhanh như thế nào tại bất kỳ điểm nào, điều này rất quan trọng để tìm các điểm tối ưu nơi tốc độ thay đổi bằng không.&lt;/p&gt;

&lt;h3 id=&quot;đường-mức-của-hàm-số&quot;&gt;Đường mức của Hàm số&lt;/h3&gt;

&lt;p&gt;Đường mức là một khái niệm cơ bản trong giải tích đa biến được sử dụng để trực quan hóa các hàm hai biến, thường được ký hiệu là \(f(x, y)\). Chúng cung cấp cách biểu diễn một bề mặt 3D trong mặt phẳng 2D.&lt;/p&gt;

&lt;p&gt;Một &lt;strong&gt;đường mức&lt;/strong&gt; của hàm số \(f(x, y)\) là tập hợp tất cả các điểm \((x, y)\) trong miền xác định của \(f\) nơi hàm số nhận giá trị hằng số:&lt;/p&gt;

\[f(x, y) = c\]

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Với \(f(x, y) = x^2 + y^2\), các đường mức là các hình tròn: \(x^2 + y^2 = c\)&lt;/li&gt;
  &lt;li&gt;Với \(f(x, y) = x + y\), các đường mức là các đường thẳng song song: \(x + y = c\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Đường mức giúp chúng ta hiểu:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Địa hình của hàm số&lt;/li&gt;
  &lt;li&gt;Hướng tăng và giảm dốc nhất&lt;/li&gt;
  &lt;li&gt;Vị trí của các điểm tối ưu tiềm năng&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;các-khái-niệm-chính-của-giải-tích-đa-biến&quot;&gt;Các Khái niệm Chính của Giải tích Đa biến&lt;/h2&gt;

&lt;h3 id=&quot;đạo-hàm-riêng&quot;&gt;Đạo hàm Riêng&lt;/h3&gt;

&lt;p&gt;Với một hàm số \(f(x_1, x_2, \ldots, x_n)\), &lt;strong&gt;đạo hàm riêng&lt;/strong&gt; theo \(x_i\) là:&lt;/p&gt;

\[\frac{\partial f}{\partial x_i} = \lim_{h \to 0} \frac{f(x_1, \ldots, x_i + h, \ldots, x_n) - f(x_1, \ldots, x_i, \ldots, x_n)}{h}\]

&lt;p&gt;Điều này đo lường cách \(f\) thay đổi khi chỉ có \(x_i\) biến thiên trong khi tất cả các biến khác giữ cố định.&lt;/p&gt;

&lt;h3 id=&quot;vector-gradient&quot;&gt;Vector Gradient&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Gradient&lt;/strong&gt; là một vector gồm tất cả các đạo hàm riêng:&lt;/p&gt;

\[\nabla f(\mathbf{x}) = \begin{pmatrix} \frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{pmatrix}\]

&lt;p&gt;Gradient chỉ theo hướng tăng dốc nhất của hàm số và vuông góc với các đường mức.&lt;/p&gt;

&lt;h3 id=&quot;ma-trận-hessian&quot;&gt;Ma trận Hessian&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Ma trận Hessian&lt;/strong&gt; chứa tất cả các đạo hàm riêng bậc hai:&lt;/p&gt;

\[\nabla^2 f(\mathbf{x}) = \mathbf{H} = \begin{pmatrix} 
\frac{\partial^2 f}{\partial x_1^2} &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_2^2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_n^2}
\end{pmatrix}\]

&lt;p&gt;Hessian cung cấp thông tin về độ cong của hàm số và rất quan trọng cho:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Xác định bản chất của các điểm tới hạn (cực tiểu, cực đại, hoặc điểm yên ngựa)&lt;/li&gt;
  &lt;li&gt;Các phương pháp tối ưu hóa bậc hai như phương pháp Newton&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;quy-tắc-dây-chuyền-cho-hàm-đa-biến&quot;&gt;Quy tắc Dây chuyền cho Hàm Đa biến&lt;/h2&gt;

&lt;p&gt;Quy tắc dây chuyền là cơ bản để tính đạo hàm của các hàm hợp thành, thường xuất hiện trong các bài toán tối ưu hóa.&lt;/p&gt;

&lt;h3 id=&quot;quy-tắc-dây-chuyền-cơ-bản&quot;&gt;Quy tắc Dây chuyền Cơ bản&lt;/h3&gt;

&lt;p&gt;Với hàm số \(z = f(x, y)\) nơi \(x = g(t)\) và \(y = h(t)\):&lt;/p&gt;

\[\frac{dz}{dt} = \frac{\partial f}{\partial x} \frac{dx}{dt} + \frac{\partial f}{\partial y} \frac{dy}{dt}\]

&lt;h3 id=&quot;quy-tắc-dây-chuyền-tổng-quát&quot;&gt;Quy tắc Dây chuyền Tổng quát&lt;/h3&gt;

&lt;p&gt;Với \(z = f(x_1, x_2, \ldots, x_n)\) nơi mỗi \(x_i = x_i(t_1, t_2, \ldots, t_m)\):&lt;/p&gt;

\[\frac{\partial z}{\partial t_j} = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} \frac{\partial x_i}{\partial t_j}\]

&lt;h3 id=&quot;ứng-dụng-trong-tối-ưu-hóa&quot;&gt;Ứng dụng trong Tối ưu hóa&lt;/h3&gt;

&lt;p&gt;Quy tắc dây chuyền rất thiết yếu cho:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Tính toán Gradient&lt;/strong&gt;: Tính gradient của các hàm mục tiêu hợp thành&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Xử lý Ràng buộc&lt;/strong&gt;: Xử lý các ràng buộc là hàm của các biến khác&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Triển khai Thuật toán&lt;/strong&gt;: Lan truyền ngược trong mạng nơ-ron và vi phân tự động&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phân tích Độ nhạy&lt;/strong&gt;: Hiểu cách thay đổi tham số ảnh hưởng đến các nghiệm tối ưu&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;ví-dụ-tối-ưu-hóa-với-ràng-buộc&quot;&gt;Ví dụ: Tối ưu hóa với Ràng buộc&lt;/h3&gt;

&lt;p&gt;Xem xét việc tối thiểu hóa \(f(x, y) = x^2 + y^2\) với điều kiện \(g(x, y) = x + y - 1 = 0\).&lt;/p&gt;

&lt;p&gt;Sử dụng ràng buộc để loại bỏ một biến: \(y = 1 - x\), vậy chúng ta tối thiểu hóa:
\(h(x) = f(x, 1-x) = x^2 + (1-x)^2\)&lt;/p&gt;

&lt;p&gt;Sử dụng quy tắc dây chuyền:
\(h&apos;(x) = \frac{\partial f}{\partial x} \cdot 1 + \frac{\partial f}{\partial y} \cdot \frac{d(1-x)}{dx} = 2x + 2(1-x)(-1) = 4x - 2\)&lt;/p&gt;

&lt;p&gt;Đặt \(h&apos;(x) = 0\) cho \(x = 1/2\), vậy điểm tối ưu là \((1/2, 1/2)\).&lt;/p&gt;

&lt;p&gt;Điều này minh họa cách các khái niệm giải tích đa biến làm việc cùng nhau để giải quyết các bài toán tối ưu hóa một cách hệ thống.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-01 Tính liên tục và Tính liên tục đều</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_01_01_Continuity_and_Uniform_Continuity/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/00_01_01_Continuity_and_Uniform_Continuity</id>
   <content type="html">&lt;p&gt;Bài học này giới thiệu các khái niệm cơ bản về tính liên tục và tính liên tục đều, những khái niệm quan trọng để hiểu hành vi của các hàm số trong tối ưu hóa.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tính-liên-tục-và-tính-liên-tục-đều&quot;&gt;Tính liên tục và Tính liên tục đều&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Tính liên tục&lt;/strong&gt; và &lt;strong&gt;Tính liên tục đều&lt;/strong&gt; là những khái niệm cơ bản mô tả hành vi của các hàm số, đặc biệt liên quan đến tính “mượt mà” hoặc “có thể dự đoán được” của chúng. Mặc dù có liên quan chặt chẽ, chúng thể hiện các tính chất khác biệt, với tính liên tục đều là điều kiện mạnh hơn so với tính liên tục thông thường.&lt;/p&gt;

&lt;h3 id=&quot;định-nghĩa-tính-liên-tục&quot;&gt;Định nghĩa Tính liên tục&lt;/h3&gt;

&lt;p&gt;Một hàm số \(f: A \to \mathbb{R}\) được gọi là &lt;strong&gt;liên tục tại một điểm&lt;/strong&gt; \(c \in A\) nếu, với mọi số thực dương \(\varepsilon &amp;gt; 0\), tồn tại một số thực dương \(\delta &amp;gt; 0\) sao cho với mọi \(x \in A\), nếu&lt;/p&gt;

\[\lvert x - c \rvert &amp;lt; \delta\]

&lt;p&gt;thì&lt;/p&gt;

\[\lvert f(x) - f(c) \rvert &amp;lt; \varepsilon\]

&lt;p&gt;Một cách trực quan, điều này có nghĩa là với bất kỳ mức độ chính xác mong muốn \(\varepsilon\) nào trong đầu ra \(f(x)\), chúng ta có thể tìm được một khoảng đủ nhỏ xung quanh \(c\) (có độ rộng \(2\delta\)) sao cho tất cả các giá trị \(x\) trong khoảng này ánh xạ tới các giá trị \(f(x)\) nằm trong khoảng \(\varepsilon\) xung quanh \(f(c)\). Khía cạnh quan trọng ở đây là việc chọn \(\delta\) thường phụ thuộc không chỉ vào \(\varepsilon\) mà còn vào điểm cụ thể \(c\).&lt;/p&gt;

&lt;p&gt;Một hàm số &lt;strong&gt;liên tục trên một tập hợp&lt;/strong&gt; \(A\) nếu nó liên tục tại mọi điểm \(c \in A\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ về các hàm liên tục&lt;/strong&gt; bao gồm tất cả đa thức (ví dụ: \(f(x) = x^2 + 3x - 1\)), các hàm lượng giác như \(\sin(x)\) và \(\cos(x)\), và các hàm mũ \(e^x\) trên miền xác định tương ứng của chúng.&lt;/p&gt;

&lt;h3 id=&quot;định-nghĩa-tính-liên-tục-đều&quot;&gt;Định nghĩa Tính liên tục đều&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Tính liên tục đều&lt;/strong&gt;, mặt khác, áp đặt một điều kiện nghiêm ngặt hơn. Một hàm số \(f: A \to \mathbb{R}\) được gọi là &lt;strong&gt;liên tục đều trên một tập hợp&lt;/strong&gt; \(A\) nếu, với mọi số thực dương \(\varepsilon &amp;gt; 0\), tồn tại một số thực dương \(\delta &amp;gt; 0\) sao cho với mọi \(x, y \in A\), nếu&lt;/p&gt;

\[\lvert x - y \rvert &amp;lt; \delta\]

&lt;p&gt;thì&lt;/p&gt;

\[\lvert f(x) - f(y) \rvert &amp;lt; \varepsilon\]

&lt;p&gt;&lt;strong&gt;Sự khác biệt chính&lt;/strong&gt; so với tính liên tục theo điểm nằm ở thứ tự của các lượng từ: đối với tính liên tục &lt;strong&gt;đều&lt;/strong&gt;, \(\delta\) chỉ phụ thuộc vào \(\varepsilon\) và độc lập với các điểm cụ thể \(x\) và \(y\) trong miền xác định.&lt;/p&gt;

&lt;h3 id=&quot;định-nghĩa-tính-liên-tục-lipschitz&quot;&gt;Định nghĩa Tính liên tục Lipschitz&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Tính liên tục Lipschitz&lt;/strong&gt; cung cấp một khái niệm cụ thể và định lượng hơn về tính liên tục. Một hàm số \(f: A \to \mathbb{R}\) được gọi là &lt;strong&gt;liên tục Lipschitz&lt;/strong&gt; (hoặc &lt;strong&gt;L-Lipschitz&lt;/strong&gt;) trên một tập hợp \(A\) nếu tồn tại một hằng số \(L \geq 0\) sao cho với mọi \(x, y \in A\):&lt;/p&gt;

\[\lvert f(x) - f(y) \rvert \leq L \lvert x - y \rvert\]

&lt;p&gt;Hằng số nhỏ nhất \(L\) như vậy được gọi là &lt;strong&gt;hằng số Lipschitz&lt;/strong&gt; hoặc &lt;strong&gt;mô-đun Lipschitz&lt;/strong&gt; của \(f\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Các tính chất chính của Tính liên tục Lipschitz:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tốc độ thay đổi bị chặn&lt;/strong&gt;: Điều kiện Lipschitz đảm bảo rằng hàm số không thể thay đổi nhanh hơn một tốc độ tuyến tính được xác định bởi \(L\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tính liên tục đều&lt;/strong&gt;: Mọi hàm liên tục Lipschitz đều là liên tục đều (chọn \(\delta = \varepsilon/L\) với \(L &amp;gt; 0\)).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Khả vi hầu khắp nơi&lt;/strong&gt;: Các hàm liên tục Lipschitz khả vi hầu khắp nơi, và tại nơi đạo hàm tồn tại, \(\lvert f&apos;(x) \rvert \leq L\).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(f(x) = \lvert x \rvert\) là 1-Lipschitz trên \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;\(f(x) = \sin(x)\) là 1-Lipschitz trên \(\mathbb{R}\) (vì \(\lvert \cos(x) \rvert \leq 1\))&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) không phải Lipschitz trên \(\mathbb{R}\) nhưng là Lipschitz trên bất kỳ khoảng bị chặn nào&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;sự-khác-biệt-chính-và-thứ-bậc&quot;&gt;Sự khác biệt chính và Thứ bậc&lt;/h3&gt;

&lt;p&gt;Ba loại tính liên tục tạo thành một thứ bậc của các điều kiện ngày càng mạnh:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tính liên tục ⊆ Tính liên tục đều ⊆ Tính liên tục Lipschitz&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Theo điểm so với Toàn cục&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Tính liên tục&lt;/strong&gt;: Tính chất cục bộ (kiểm tra tại mỗi điểm)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Tính liên tục đều&lt;/strong&gt;: Tính chất toàn cục của toàn bộ hàm số&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Tính liên tục Lipschitz&lt;/strong&gt;: Tính chất toàn cục với các ràng buộc định lượng&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lựa chọn \(\delta\)&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Tính liên tục&lt;/strong&gt;: \(\delta\) có thể phụ thuộc vào cả \(\varepsilon\) và điểm cụ thể \(c\)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Tính liên tục đều&lt;/strong&gt;: \(\delta\) chỉ phụ thuộc vào \(\varepsilon\), hoạt động cho tất cả các điểm đồng thời&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Tính liên tục Lipschitz&lt;/strong&gt;: \(\delta = \varepsilon/L\) cung cấp mối quan hệ rõ ràng&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kiểm soát Tốc độ Thay đổi&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Tính liên tục&lt;/strong&gt;: Không kiểm soát tốc độ thay đổi&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Tính liên tục đều&lt;/strong&gt;: Đảm bảo biến thiên bị chặn trên các khoảng nhỏ&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Tính liên tục Lipschitz&lt;/strong&gt;: Cung cấp ràng buộc tuyến tính rõ ràng cho tốc độ thay đổi&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mối quan hệ Độ mạnh&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;Mọi hàm liên tục Lipschitz đều là liên tục đều&lt;/li&gt;
      &lt;li&gt;Mọi hàm liên tục đều đều là liên tục&lt;/li&gt;
      &lt;li&gt;Các mệnh đề ngược lại nói chung không đúng&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;ví-dụ-chi-tiết-và-so-sánh&quot;&gt;Ví dụ Chi tiết và So sánh&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ 1: \(f(x) = x^2\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Trên \(\mathbb{R}\)&lt;/strong&gt;: Liên tục nhưng không liên tục đều (tốc độ thay đổi \(\lvert f&apos;(x) \rvert = 2\lvert x \rvert\) không bị chặn)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Trên \([0,1]\)&lt;/strong&gt;: Liên tục, liên tục đều, và Lipschitz với \(L = 2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ 2: \(f(x) = \sin(x)\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Trên \(\mathbb{R}\)&lt;/strong&gt;: Liên tục, liên tục đều, và 1-Lipschitz (vì \(\lvert \cos(x) \rvert \leq 1\))&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ 3: \(f(x) = \lvert x \rvert\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Trên \(\mathbb{R}\)&lt;/strong&gt;: Liên tục, liên tục đều, và 1-Lipschitz&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lưu ý&lt;/strong&gt;: Không khả vi tại \(x = 0\), nhưng vẫn là Lipschitz&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ví dụ 4: \(f(x) = \sqrt{x}\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Trên \([0,1]\)&lt;/strong&gt;: Liên tục và liên tục đều, nhưng không phải Lipschitz (đạo hàm không bị chặn gần \(x = 0\))&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Trên \([a,1]\) với \(a &amp;gt; 0\)&lt;/strong&gt;: Lipschitz với \(L = 1/(2\sqrt{a})\)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>00 Introduction</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_Introduction</id>
   <content type="html">&lt;p&gt;Optimization is at the heart of data science. Whether you’re training a neural network, minimizing errors in regression models, or efficiently allocating resources in recommendation systems, you’re essentially solving problems that involve finding the “best” solution from a vast set of possibilities. But to do this effectively, you need to speak the language of mathematics. We’ll revisit key ideas from linear algebra, set theory, and calculus, ensuring you’re equipped to handle gradients, matrices, constraints, and uncertainties that arise in optimization tasks.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-04 Probability and Statistics</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_04_Probability_and_Statistics/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_04_Probability_and_Statistics</id>
   <content type="html">&lt;h2 id=&quot;probability-and-statistics-for-convex-optimization&quot;&gt;Probability and Statistics for Convex Optimization&lt;/h2&gt;

&lt;p&gt;Probability and statistics form a crucial foundation for understanding many optimization problems, especially in machine learning and data science. This section introduces the essential probabilistic concepts that frequently appear in convex optimization, from maximum likelihood estimation to Bayesian optimization.&lt;/p&gt;

&lt;h3 id=&quot;why-probability-matters-in-optimization&quot;&gt;Why Probability Matters in Optimization&lt;/h3&gt;

&lt;p&gt;Many optimization problems arise from statistical modeling:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Maximum Likelihood Estimation (MLE)&lt;/strong&gt;: Finding parameters that maximize the likelihood of observed data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bayesian Optimization&lt;/strong&gt;: Using probabilistic models to guide the search for optimal solutions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stochastic Optimization&lt;/strong&gt;: Dealing with uncertainty and randomness in objective functions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: Adding probabilistic priors to prevent overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Risk Minimization&lt;/strong&gt;: Optimizing expected loss over probability distributions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;key-topics-covered&quot;&gt;Key Topics Covered&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Basic Probability Theory&lt;/strong&gt;: Sample spaces, events, and probability axioms&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Common Probability Distributions&lt;/strong&gt;: Normal, exponential, and other distributions crucial for optimization&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Expectation and Variance&lt;/strong&gt;: Computing and optimizing expected values&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bayes’ Theorem&lt;/strong&gt;: Foundation for Bayesian optimization and inference&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Statistical Estimation&lt;/strong&gt;: Connecting probability theory to optimization problems&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;connection-to-convex-optimization&quot;&gt;Connection to Convex Optimization&lt;/h3&gt;

&lt;p&gt;Understanding probability helps you:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Formulate Problems&lt;/strong&gt;: Convert real-world uncertainty into mathematical optimization problems&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Choose Objective Functions&lt;/strong&gt;: Select appropriate loss functions based on probabilistic assumptions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interpret Results&lt;/strong&gt;: Understand confidence intervals and statistical significance of solutions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Handle Noise&lt;/strong&gt;: Deal with measurement errors and stochastic processes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Design Algorithms&lt;/strong&gt;: Develop robust optimization methods that work under uncertainty&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This foundation will be essential as we explore how probabilistic models lead to convex optimization problems in machine learning, statistics, and engineering applications.&lt;/p&gt;

&lt;div style=&quot;background: #e8f4fd; padding: 15px; border-left: 4px solid #2196F3; margin: 20px 0;&quot;&gt;
&lt;strong&gt;💡 Learning Path:&lt;/strong&gt; Start with basic probability concepts, then explore how they connect to optimization through maximum likelihood estimation and Bayesian methods. Each lesson builds toward understanding how uncertainty and randomness create optimization problems.
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>00-04-02 Common Probability Distributions</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_04_02_Common_Probability_Distributions/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_04_02_Common_Probability_Distributions</id>
   <content type="html">&lt;h2 id=&quot;common-probability-distributions&quot;&gt;Common Probability Distributions&lt;/h2&gt;

&lt;p&gt;Understanding key probability distributions is essential for optimization problems in machine learning and statistics. These distributions frequently appear as assumptions in models, priors in Bayesian methods, and error models in regression.&lt;/p&gt;

&lt;h3 id=&quot;1-discrete-distributions&quot;&gt;1. Discrete Distributions&lt;/h3&gt;

&lt;h4 id=&quot;bernoulli-distribution&quot;&gt;Bernoulli Distribution&lt;/h4&gt;

&lt;p&gt;Models a single trial with two outcomes (success/failure).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(p \in [0,1]\) (probability of success)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = p^k (1-p)^{1-k}\) for \(k \in \{0,1\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = p\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = p(1-p)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;: Binary classification, coin flips, A/B testing&lt;/p&gt;

&lt;h4 id=&quot;binomial-distribution&quot;&gt;Binomial Distribution&lt;/h4&gt;

&lt;p&gt;Models the number of successes in \(n\) independent Bernoulli trials.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(n \in \mathbb{N}\) (trials), \(p \in [0,1]\) (success probability)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\) for \(k = 0,1,\ldots,n\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = np\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = np(1-p)\)&lt;/p&gt;

&lt;h4 id=&quot;poisson-distribution&quot;&gt;Poisson Distribution&lt;/h4&gt;

&lt;p&gt;Models the number of events in a fixed interval when events occur independently at a constant rate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(\lambda &amp;gt; 0\) (rate parameter)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}\) for \(k = 0,1,2,\ldots\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = \lambda\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = \lambda\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;: Count data, rare events, queueing theory&lt;/p&gt;

&lt;div id=&quot;discrete-distributions-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Interactive Discrete Distributions&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;discreteCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Visualization:&lt;/strong&gt; Probability mass functions of discrete distributions.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Distribution Type&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;bernoulli&quot; checked=&quot;&quot; /&gt; Bernoulli
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;binomial&quot; /&gt; Binomial
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;poisson&quot; /&gt; Poisson
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;discrete-params&quot;&gt;
                    &lt;div id=&quot;p-param&quot; style=&quot;margin-bottom: 15px;&quot;&gt;
                        &lt;label for=&quot;p-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;p: &lt;span id=&quot;p-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;p-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.5&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;n-param&quot; style=&quot;margin-bottom: 15px; display: none;&quot;&gt;
                        &lt;label for=&quot;n-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;n: &lt;span id=&quot;n-value&quot;&gt;10&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;n-slider&quot; min=&quot;5&quot; max=&quot;50&quot; step=&quot;1&quot; value=&quot;10&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;lambda-param&quot; style=&quot;margin-bottom: 15px; display: none;&quot;&gt;
                        &lt;label for=&quot;lambda-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;λ: &lt;span id=&quot;lambda-value&quot;&gt;3.0&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;lambda-slider&quot; min=&quot;0.5&quot; max=&quot;10&quot; step=&quot;0.5&quot; value=&quot;3.0&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;discrete-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Statistics:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Mean: &lt;span id=&quot;discrete-mean&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Variance: &lt;span id=&quot;discrete-variance&quot;&gt;0.250&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Mode: &lt;span id=&quot;discrete-mode&quot;&gt;0 or 1&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2-continuous-distributions&quot;&gt;2. Continuous Distributions&lt;/h3&gt;

&lt;h4 id=&quot;uniform-distribution&quot;&gt;Uniform Distribution&lt;/h4&gt;

&lt;p&gt;All values in an interval are equally likely.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(a, b \in \mathbb{R}\) with \(a &amp;lt; b\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{1}{b-a}\) for \(x \in [a,b]\), 0 otherwise&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{a+b}{2}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = \frac{(b-a)^2}{12}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;: Random sampling, initialization in algorithms&lt;/p&gt;

&lt;h4 id=&quot;normal-gaussian-distribution&quot;&gt;Normal (Gaussian) Distribution&lt;/h4&gt;

&lt;p&gt;The most important distribution in statistics and optimization.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(\mu \in \mathbb{R}\) (mean), \(\sigma^2 &amp;gt; 0\) (variance)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = \mu\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = \sigma^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Symmetric around \(\mu\)&lt;/li&gt;
  &lt;li&gt;68-95-99.7 rule&lt;/li&gt;
  &lt;li&gt;Central Limit Theorem&lt;/li&gt;
  &lt;li&gt;Maximum entropy for given mean and variance&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;exponential-distribution&quot;&gt;Exponential Distribution&lt;/h4&gt;

&lt;p&gt;Models waiting times between events in a Poisson process.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(\lambda &amp;gt; 0\) (rate parameter)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \lambda e^{-\lambda x}\) for \(x \geq 0\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{1}{\lambda}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = \frac{1}{\lambda^2}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties&lt;/strong&gt;: Memoryless property&lt;/p&gt;

&lt;h4 id=&quot;beta-distribution&quot;&gt;Beta Distribution&lt;/h4&gt;

&lt;p&gt;Flexible distribution on \([0,1]\), often used for modeling probabilities.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(\alpha, \beta &amp;gt; 0\) (shape parameters)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha-1}(1-x)^{\beta-1}\) for \(x \in [0,1]\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{\alpha}{\alpha+\beta}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\)&lt;/p&gt;

&lt;div id=&quot;continuous-distributions-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Interactive Continuous Distributions&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;continuousCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Visualization:&lt;/strong&gt; Probability density functions of continuous distributions.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Distribution Type&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;uniform&quot; checked=&quot;&quot; /&gt; Uniform
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;normal&quot; /&gt; Normal
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;exponential&quot; /&gt; Exponential
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;beta&quot; /&gt; Beta
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;continuous-params&quot;&gt;
                    &lt;div id=&quot;uniform-params&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;a-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;a: &lt;span id=&quot;a-value&quot;&gt;0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;a-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;b-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;b: &lt;span id=&quot;b-value&quot;&gt;1&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;b-slider&quot; min=&quot;0.5&quot; max=&quot;4&quot; step=&quot;0.1&quot; value=&quot;1&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;normal-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;mu-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;μ: &lt;span id=&quot;mu-value&quot;&gt;0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;mu-slider&quot; min=&quot;-3&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;sigma-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;σ: &lt;span id=&quot;sigma-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;sigma-slider&quot; min=&quot;0.5&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;exponential-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;exp-lambda-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;λ: &lt;span id=&quot;exp-lambda-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;exp-lambda-slider&quot; min=&quot;0.2&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;beta-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;alpha-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;α: &lt;span id=&quot;alpha-value&quot;&gt;2&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;alpha-slider&quot; min=&quot;0.5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;2&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;beta-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;β: &lt;span id=&quot;beta-value&quot;&gt;2&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;beta-slider&quot; min=&quot;0.5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;2&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;continuous-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Statistics:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Mean: &lt;span id=&quot;continuous-mean&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Variance: &lt;span id=&quot;continuous-variance&quot;&gt;0.083&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Support: &lt;span id=&quot;continuous-support&quot;&gt;[0, 1]&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;3-multivariate-distributions&quot;&gt;3. Multivariate Distributions&lt;/h3&gt;

&lt;h4 id=&quot;multivariate-normal-distribution&quot;&gt;Multivariate Normal Distribution&lt;/h4&gt;

&lt;p&gt;Extension of the normal distribution to multiple dimensions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(\boldsymbol{\mu} \in \mathbb{R}^d\) (mean vector), \(\boldsymbol{\Sigma} \in \mathbb{R}^{d \times d}\) (covariance matrix, positive definite)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;PDF&lt;/strong&gt;: $$f(\mathbf{x}) = \frac{1}{(2\pi)^{d/2}&lt;/td&gt;
      &lt;td&gt;\boldsymbol{\Sigma}&lt;/td&gt;
      &lt;td&gt;^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^T\boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right)$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Properties&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Marginal distributions are normal&lt;/li&gt;
  &lt;li&gt;Linear combinations are normal&lt;/li&gt;
  &lt;li&gt;Conditional distributions are normal&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;multivariate-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f0f8ff;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Multivariate Normal Distribution&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;multivariateCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;2D Visualization:&lt;/strong&gt; Contour plot of bivariate normal distribution. Samples shown as dots.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Parameters&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;mu1-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;μ₁: &lt;span id=&quot;mu1-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;mu1-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;mu2-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;μ₂: &lt;span id=&quot;mu2-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;mu2-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sigma1-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;σ₁: &lt;span id=&quot;sigma1-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sigma1-slider&quot; min=&quot;0.5&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sigma2-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;σ₂: &lt;span id=&quot;sigma2-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sigma2-slider&quot; min=&quot;0.5&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;rho-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;ρ (correlation): &lt;span id=&quot;rho-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;rho-slider&quot; min=&quot;-0.9&quot; max=&quot;0.9&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-samples&quot; style=&quot;width: 100%; padding: 10px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Generate Samples&lt;/button&gt;
                
                &lt;div id=&quot;multivariate-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Covariance Matrix:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Σ₁₁: &lt;span id=&quot;cov11&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Σ₁₂: &lt;span id=&quot;cov12&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Σ₂₂: &lt;span id=&quot;cov22&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Det(Σ): &lt;span id=&quot;det-cov&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;4-applications-in-optimization&quot;&gt;4. Applications in Optimization&lt;/h3&gt;

&lt;h4 id=&quot;maximum-likelihood-estimation&quot;&gt;Maximum Likelihood Estimation&lt;/h4&gt;
&lt;p&gt;Many optimization problems involve finding parameters that maximize the likelihood of observed data under a specific distribution:&lt;/p&gt;

\[\hat{\theta} = \arg\max_\theta \prod_{i=1}^n f(x_i; \theta)\]

&lt;h4 id=&quot;bayesian-optimization&quot;&gt;Bayesian Optimization&lt;/h4&gt;
&lt;p&gt;Prior distributions encode beliefs about parameters before seeing data:&lt;/p&gt;

\[p(\theta|data) \propto p(data|\theta) \cdot p(\theta)\]

&lt;h4 id=&quot;regularization&quot;&gt;Regularization&lt;/h4&gt;
&lt;p&gt;Distributions can be used as priors to regularize optimization problems:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;L2 regularization ↔ Gaussian prior&lt;/li&gt;
  &lt;li&gt;L1 regularization ↔ Laplace prior&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;stochastic-optimization&quot;&gt;Stochastic Optimization&lt;/h4&gt;
&lt;p&gt;Distributions model noise and uncertainty in objective functions and constraints.&lt;/p&gt;

&lt;h3 id=&quot;key-insights-for-optimization&quot;&gt;Key Insights for Optimization&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Model Selection&lt;/strong&gt;: Choose distributions that match your data’s characteristics&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parameter Estimation&lt;/strong&gt;: Use MLE or Bayesian methods to estimate distribution parameters&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Uncertainty Quantification&lt;/strong&gt;: Distributions provide natural ways to quantify uncertainty&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: Prior distributions can prevent overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Computational Efficiency&lt;/strong&gt;: Some distributions have closed-form solutions for common operations&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Understanding these distributions and their properties is crucial for formulating and solving optimization problems in machine learning, statistics, and engineering applications.&lt;/p&gt;

&lt;script&gt;
// Discrete Distributions Demo
class DiscreteDistributionsDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;discreteCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.distType = &apos;bernoulli&apos;;
        this.params = { p: 0.5, n: 10, lambda: 3.0 };
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;discrete-dist&quot;]&apos;);
        const pSlider = document.getElementById(&apos;p-slider&apos;);
        const nSlider = document.getElementById(&apos;n-slider&apos;);
        const lambdaSlider = document.getElementById(&apos;lambda-slider&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.distType = e.target.value;
                this.updateParameterVisibility();
                this.updateStats();
                this.draw();
            });
        });
        
        pSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.p = parseFloat(e.target.value);
            document.getElementById(&apos;p-value&apos;).textContent = this.params.p.toFixed(1);
            this.updateStats();
            this.draw();
        });
        
        nSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.n = parseInt(e.target.value);
            document.getElementById(&apos;n-value&apos;).textContent = this.params.n;
            this.updateStats();
            this.draw();
        });
        
        lambdaSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.lambda = parseFloat(e.target.value);
            document.getElementById(&apos;lambda-value&apos;).textContent = this.params.lambda.toFixed(1);
            this.updateStats();
            this.draw();
        });
        
        this.updateParameterVisibility();
        this.updateStats();
    }
    
    updateParameterVisibility() {
        document.getElementById(&apos;p-param&apos;).style.display = 
            (this.distType === &apos;bernoulli&apos; || this.distType === &apos;binomial&apos;) ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;n-param&apos;).style.display = 
            this.distType === &apos;binomial&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;lambda-param&apos;).style.display = 
            this.distType === &apos;poisson&apos; ? &apos;block&apos; : &apos;none&apos;;
    }
    
    updateStats() {
        let mean, variance, mode;
        
        switch(this.distType) {
            case &apos;bernoulli&apos;:
                mean = this.params.p;
                variance = this.params.p * (1 - this.params.p);
                mode = this.params.p &gt; 0.5 ? &apos;1&apos; : (this.params.p &lt; 0.5 ? &apos;0&apos; : &apos;0 or 1&apos;);
                break;
            case &apos;binomial&apos;:
                mean = this.params.n * this.params.p;
                variance = this.params.n * this.params.p * (1 - this.params.p);
                mode = Math.floor((this.params.n + 1) * this.params.p).toString();
                break;
            case &apos;poisson&apos;:
                mean = this.params.lambda;
                variance = this.params.lambda;
                mode = Math.floor(this.params.lambda).toString();
                break;
        }
        
        document.getElementById(&apos;discrete-mean&apos;).textContent = mean.toFixed(3);
        document.getElementById(&apos;discrete-variance&apos;).textContent = variance.toFixed(3);
        document.getElementById(&apos;discrete-mode&apos;).textContent = mode;
    }
    
    factorial(n) {
        if (n &lt;= 1) return 1;
        return n * this.factorial(n - 1);
    }
    
    binomialCoeff(n, k) {
        if (k &gt; n) return 0;
        return this.factorial(n) / (this.factorial(k) * this.factorial(n - k));
    }
    
    getProbability(k) {
        switch(this.distType) {
            case &apos;bernoulli&apos;:
                return k === 0 ? (1 - this.params.p) : (k === 1 ? this.params.p : 0);
            case &apos;binomial&apos;:
                if (k &lt; 0 || k &gt; this.params.n) return 0;
                return this.binomialCoeff(this.params.n, k) * 
                       Math.pow(this.params.p, k) * 
                       Math.pow(1 - this.params.p, this.params.n - k);
            case &apos;poisson&apos;:
                if (k &lt; 0) return 0;
                return Math.pow(this.params.lambda, k) * Math.exp(-this.params.lambda) / this.factorial(k);
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Determine range
        let maxK;
        switch(this.distType) {
            case &apos;bernoulli&apos;: maxK = 1; break;
            case &apos;binomial&apos;: maxK = this.params.n; break;
            case &apos;poisson&apos;: maxK = Math.min(20, this.params.lambda + 3 * Math.sqrt(this.params.lambda)); break;
        }
        
        // Find max probability for scaling
        let maxProb = 0;
        for (let k = 0; k &lt;= maxK; k++) {
            maxProb = Math.max(maxProb, this.getProbability(k));
        }
        
        // Draw bars
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        const barWidth = plotWidth / (maxK + 2);
        
        for (let k = 0; k &lt;= maxK; k++) {
            const prob = this.getProbability(k);
            const x = marginX + (k + 0.5) * barWidth;
            const height = (prob / maxProb) * plotHeight * 0.8;
            const y = this.height - marginY - height;
            
            this.ctx.fillRect(x - barWidth * 0.3, y, barWidth * 0.6, height);
            
            // Label
            this.ctx.fillStyle = &apos;#000&apos;;
            this.ctx.font = &apos;10px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(k.toString(), x, this.height - marginY + 15);
            this.ctx.fillText(prob.toFixed(3), x, y - 5);
            this.ctx.fillStyle = &apos;#2196f3&apos;;
        }
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;k&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;P(X = k)&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Continuous Distributions Demo
class ContinuousDistributionsDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;continuousCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.distType = &apos;uniform&apos;;
        this.params = { a: 0, b: 1, mu: 0, sigma: 1, lambda: 1, alpha: 2, beta: 2 };
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;continuous-dist&quot;]&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.distType = e.target.value;
                this.updateParameterVisibility();
                this.updateStats();
                this.draw();
            });
        });
        
        // Setup all sliders
        const sliders = [&apos;a&apos;, &apos;b&apos;, &apos;mu&apos;, &apos;sigma&apos;, &apos;exp-lambda&apos;, &apos;alpha&apos;, &apos;beta&apos;];
        sliders.forEach(slider =&gt; {
            const element = document.getElementById(slider + &apos;-slider&apos;);
            if (element) {
                element.addEventListener(&apos;input&apos;, (e) =&gt; {
                    const value = parseFloat(e.target.value);
                    const param = slider === &apos;exp-lambda&apos; ? &apos;lambda&apos; : slider;
                    this.params[param] = value;
                    
                    const valueSpan = document.getElementById(slider + &apos;-value&apos;);
                    if (valueSpan) {
                        valueSpan.textContent = value.toFixed(1);
                    }
                    
                    this.updateStats();
                    this.draw();
                });
            }
        });
        
        this.updateParameterVisibility();
        this.updateStats();
    }
    
    updateParameterVisibility() {
        document.getElementById(&apos;uniform-params&apos;).style.display = 
            this.distType === &apos;uniform&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;normal-params&apos;).style.display = 
            this.distType === &apos;normal&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;exponential-params&apos;).style.display = 
            this.distType === &apos;exponential&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;beta-params&apos;).style.display = 
            this.distType === &apos;beta&apos; ? &apos;block&apos; : &apos;none&apos;;
    }
    
    updateStats() {
        let mean, variance, support;
        
        switch(this.distType) {
            case &apos;uniform&apos;:
                mean = (this.params.a + this.params.b) / 2;
                variance = Math.pow(this.params.b - this.params.a, 2) / 12;
                support = `[${this.params.a}, ${this.params.b}]`;
                break;
            case &apos;normal&apos;:
                mean = this.params.mu;
                variance = this.params.sigma * this.params.sigma;
                support = &apos;(-∞, ∞)&apos;;
                break;
            case &apos;exponential&apos;:
                mean = 1 / this.params.lambda;
                variance = 1 / (this.params.lambda * this.params.lambda);
                support = &apos;[0, ∞)&apos;;
                break;
            case &apos;beta&apos;:
                mean = this.params.alpha / (this.params.alpha + this.params.beta);
                variance = (this.params.alpha * this.params.beta) / 
                          (Math.pow(this.params.alpha + this.params.beta, 2) * 
                           (this.params.alpha + this.params.beta + 1));
                support = &apos;[0, 1]&apos;;
                break;
        }
        
        document.getElementById(&apos;continuous-mean&apos;).textContent = mean.toFixed(3);
        document.getElementById(&apos;continuous-variance&apos;).textContent = variance.toFixed(3);
        document.getElementById(&apos;continuous-support&apos;).textContent = support;
    }
    
    gamma(z) {
        // Stirling&apos;s approximation for gamma function
        if (z &lt; 0.5) return Math.PI / (Math.sin(Math.PI * z) * this.gamma(1 - z));
        z -= 1;
        let x = 0.99999999999980993;
        const p = [676.5203681218851, -1259.1392167224028, 771.32342877765313,
                  -176.61502916214059, 12.507343278686905, -0.13857109526572012,
                  9.9843695780195716e-6, 1.5056327351493116e-7];
        for (let i = 0; i &lt; p.length; i++) {
            x += p[i] / (z + i + 1);
        }
        const t = z + p.length - 0.5;
        return Math.sqrt(2 * Math.PI) * Math.pow(t, z + 0.5) * Math.exp(-t) * x;
    }
    
    getPDF(x) {
        switch(this.distType) {
            case &apos;uniform&apos;:
                return (x &gt;= this.params.a &amp;&amp; x &lt;= this.params.b) ? 
                       1 / (this.params.b - this.params.a) : 0;
            case &apos;normal&apos;:
                return Math.exp(-0.5 * Math.pow((x - this.params.mu) / this.params.sigma, 2)) / 
                       (this.params.sigma * Math.sqrt(2 * Math.PI));
            case &apos;exponential&apos;:
                return x &gt;= 0 ? this.params.lambda * Math.exp(-this.params.lambda * x) : 0;
            case &apos;beta&apos;:
                if (x &lt; 0 || x &gt; 1) return 0;
                const B = this.gamma(this.params.alpha) * this.gamma(this.params.beta) / 
                         this.gamma(this.params.alpha + this.params.beta);
                return Math.pow(x, this.params.alpha - 1) * Math.pow(1 - x, this.params.beta - 1) / B;
        }
    }
    
    getRange() {
        switch(this.distType) {
            case &apos;uniform&apos;: return [this.params.a - 0.5, this.params.b + 0.5];
            case &apos;normal&apos;: return [this.params.mu - 4 * this.params.sigma, this.params.mu + 4 * this.params.sigma];
            case &apos;exponential&apos;: return [0, 5 / this.params.lambda];
            case &apos;beta&apos;: return [0, 1];
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        const [minX, maxX] = this.getRange();
        
        // Find max PDF for scaling
        let maxPDF = 0;
        for (let i = 0; i &lt;= 200; i++) {
            const x = minX + (maxX - minX) * i / 200;
            maxPDF = Math.max(maxPDF, this.getPDF(x));
        }
        
        // Draw PDF curve
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let i = 0; i &lt;= 200; i++) {
            const x = minX + (maxX - minX) * i / 200;
            const pdf = this.getPDF(x);
            const plotX = marginX + (x - minX) / (maxX - minX) * plotWidth;
            const plotY = this.height - marginY - (pdf / maxPDF) * plotHeight * 0.8;
            
            if (i === 0) {
                this.ctx.moveTo(plotX, plotY);
            } else {
                this.ctx.lineTo(plotX, plotY);
            }
        }
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;x&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;f(x)&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Multivariate Normal Demo
class MultivariateDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;multivariateCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.params = { mu1: 0, mu2: 0, sigma1: 1, sigma2: 1, rho: 0 };
        this.samples = [];
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const sliders = [&apos;mu1&apos;, &apos;mu2&apos;, &apos;sigma1&apos;, &apos;sigma2&apos;, &apos;rho&apos;];
        
        sliders.forEach(slider =&gt; {
            const element = document.getElementById(slider + &apos;-slider&apos;);
            element.addEventListener(&apos;input&apos;, (e) =&gt; {
                this.params[slider] = parseFloat(e.target.value);
                document.getElementById(slider + &apos;-value&apos;).textContent = this.params[slider].toFixed(1);
                this.updateStats();
                this.draw();
            });
        });
        
        document.getElementById(&apos;generate-samples&apos;).addEventListener(&apos;click&apos;, () =&gt; {
            this.generateSamples();
            this.draw();
        });
        
        this.updateStats();
    }
    
    updateStats() {
        const cov11 = this.params.sigma1 * this.params.sigma1;
        const cov12 = this.params.rho * this.params.sigma1 * this.params.sigma2;
        const cov22 = this.params.sigma2 * this.params.sigma2;
        const det = cov11 * cov22 - cov12 * cov12;
        
        document.getElementById(&apos;cov11&apos;).textContent = cov11.toFixed(3);
        document.getElementById(&apos;cov12&apos;).textContent = cov12.toFixed(3);
        document.getElementById(&apos;cov22&apos;).textContent = cov22.toFixed(3);
        document.getElementById(&apos;det-cov&apos;).textContent = det.toFixed(3);
    }
    
    generateSamples() {
        this.samples = [];
        const n = 100;
        
        for (let i = 0; i &lt; n; i++) {
            // Box-Muller transform
            const u1 = Math.random();
            const u2 = Math.random();
            const z1 = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
            const z2 = Math.sqrt(-2 * Math.log(u1)) * Math.sin(2 * Math.PI * u2);
            
            // Transform to correlated normal
            const x1 = this.params.mu1 + this.params.sigma1 * z1;
            const x2 = this.params.mu2 + this.params.sigma2 * (this.params.rho * z1 + Math.sqrt(1 - this.params.rho * this.params.rho) * z2);
            
            this.samples.push([x1, x2]);
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Draw contour ellipses
        const levels = [0.5, 1, 1.5, 2];
        const colors = [&apos;#ff9999&apos;, &apos;#ff6666&apos;, &apos;#ff3333&apos;, &apos;#ff0000&apos;];
        
        levels.forEach((level, idx) =&gt; {
            this.ctx.strokeStyle = colors[idx];
            this.ctx.lineWidth = 1;
            this.ctx.beginPath();
            
            const a = level * this.params.sigma1;
            const b = level * this.params.sigma2;
            const angle = 0.5 * Math.atan2(2 * this.params.rho * this.params.sigma1 * this.params.sigma2,
                                          this.params.sigma1 * this.params.sigma1 - this.params.sigma2 * this.params.sigma2);
            
            for (let i = 0; i &lt;= 100; i++) {
                const t = 2 * Math.PI * i / 100;
                const x = a * Math.cos(t) * Math.cos(angle) - b * Math.sin(t) * Math.sin(angle) + this.params.mu1;
                const y = a * Math.cos(t) * Math.sin(angle) + b * Math.sin(t) * Math.cos(angle) + this.params.mu2;
                
                const plotX = marginX + (x + 4) / 8 * plotWidth;
                const plotY = this.height - marginY - (y + 4) / 8 * plotHeight;
                
                if (i === 0) {
                    this.ctx.moveTo(plotX, plotY);
                } else {
                    this.ctx.lineTo(plotX, plotY);
                }
            }
            this.ctx.stroke();
        });
        
        // Draw samples
        if (this.samples.length &gt; 0) {
            this.ctx.fillStyle = &apos;#2196f3&apos;;
            this.samples.forEach(([x1, x2]) =&gt; {
                const plotX = marginX + (x1 + 4) / 8 * plotWidth;
                const plotY = this.height - marginY - (x2 + 4) / 8 * plotHeight;
                
                if (plotX &gt;= marginX &amp;&amp; plotX &lt;= this.width - marginX &amp;&amp;
                    plotY &gt;= marginY &amp;&amp; plotY &lt;= this.height - marginY) {
                    this.ctx.beginPath();
                    this.ctx.arc(plotX, plotY, 2, 0, 2 * Math.PI);
                    this.ctx.fill();
                }
            });
        }
        
        // Draw mean point
        const meanX = marginX + (this.params.mu1 + 4) / 8 * plotWidth;
        const meanY = this.height - marginY - (this.params.mu2 + 4) / 8 * plotHeight;
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.beginPath();
        this.ctx.arc(meanX, meanY, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;X₁&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;X₂&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new DiscreteDistributionsDemo();
    new ContinuousDistributionsDemo();
    new MultivariateDemo();
});
&lt;/script&gt;

&lt;style&gt;
input[type=&quot;range&quot;] {
    -webkit-appearance: none;
    appearance: none;
    height: 5px;
    background: #ddd;
    outline: none;
    border-radius: 5px;
}

input[type=&quot;range&quot;]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
}

input[type=&quot;range&quot;]::-moz-range-thumb {
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
    border: none;
}

canvas {
    border-radius: 5px;
}

.demo-container {
    margin: 20px 0;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>00-04-01 Basic Probability Theory</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_04_01_Basic_Probability_Theory/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_04_01_Basic_Probability_Theory</id>
   <content type="html">&lt;h2 id=&quot;basic-probability-theory&quot;&gt;Basic Probability Theory&lt;/h2&gt;

&lt;p&gt;Probability theory provides the mathematical framework for reasoning about uncertainty, which is fundamental to many optimization problems in machine learning and data science.&lt;/p&gt;

&lt;h3 id=&quot;1-sample-space-and-events&quot;&gt;1. Sample Space and Events&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Sample Space (Ω)&lt;/strong&gt;: The set of all possible outcomes of an experiment.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Event (A)&lt;/strong&gt;: A subset of the sample space representing a collection of outcomes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Coin flip: Ω = {H, T}&lt;/li&gt;
  &lt;li&gt;Die roll: Ω = {1, 2, 3, 4, 5, 6}&lt;/li&gt;
  &lt;li&gt;Continuous: Ω = [0, 1] for uniform random variable&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;sample-space-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Interactive Sample Space Visualization&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;sampleSpaceCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Visualization:&lt;/strong&gt; Click to generate random samples. Different colors represent different events.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Experiment Type&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;coin&quot; checked=&quot;&quot; /&gt; Coin Flip
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;dice&quot; /&gt; Dice Roll
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;uniform&quot; /&gt; Uniform [0,1]
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-sample&quot; style=&quot;width: 100%; padding: 10px; background: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 10px;&quot;&gt;Generate Sample&lt;/button&gt;
                &lt;button id=&quot;clear-samples&quot; style=&quot;width: 100%; padding: 8px; background: #6c757d; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Clear&lt;/button&gt;
                
                &lt;div id=&quot;sample-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Statistics:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Total samples: &lt;span id=&quot;total-samples&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Event A: &lt;span id=&quot;event-a-count&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Event B: &lt;span id=&quot;event-b-count&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A) ≈ &lt;span id=&quot;prob-a&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B) ≈ &lt;span id=&quot;prob-b&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2-probability-axioms-kolmogorov-axioms&quot;&gt;2. Probability Axioms (Kolmogorov Axioms)&lt;/h3&gt;

&lt;p&gt;For any probability measure P, the following axioms must hold:&lt;/p&gt;

&lt;h4 id=&quot;axiom-1-non-negativity&quot;&gt;Axiom 1: Non-negativity&lt;/h4&gt;
&lt;p&gt;\(P(A) \geq 0 \text{ for all events } A\)&lt;/p&gt;

&lt;h4 id=&quot;axiom-2-normalization&quot;&gt;Axiom 2: Normalization&lt;/h4&gt;
&lt;p&gt;\(P(\Omega) = 1\)&lt;/p&gt;

&lt;h4 id=&quot;axiom-3-countable-additivity&quot;&gt;Axiom 3: Countable Additivity&lt;/h4&gt;
&lt;p&gt;For mutually exclusive events \(A_1, A_2, \ldots\):
\(P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)\)&lt;/p&gt;

&lt;h3 id=&quot;3-basic-properties-and-rules&quot;&gt;3. Basic Properties and Rules&lt;/h3&gt;

&lt;h4 id=&quot;complement-rule&quot;&gt;Complement Rule&lt;/h4&gt;
&lt;p&gt;\(P(A^c) = 1 - P(A)\)&lt;/p&gt;

&lt;h4 id=&quot;addition-rule&quot;&gt;Addition Rule&lt;/h4&gt;
&lt;p&gt;For any two events A and B:
\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)&lt;/p&gt;

&lt;h4 id=&quot;multiplication-rule&quot;&gt;Multiplication Rule&lt;/h4&gt;
&lt;p&gt;\(P(A \cap B) = P(A|B) \cdot P(B) = P(B|A) \cdot P(A)\)&lt;/p&gt;

&lt;h3 id=&quot;4-conditional-probability&quot;&gt;4. Conditional Probability&lt;/h3&gt;

&lt;p&gt;The probability of event A given that event B has occurred:&lt;/p&gt;

\[P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) &amp;gt; 0\]

&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: Conditional probability updates our belief about A when we have information about B.&lt;/p&gt;

&lt;div id=&quot;conditional-prob-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Conditional Probability Visualization&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;conditionalCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Venn Diagram:&lt;/strong&gt; Blue circle is event A, red circle is event B. Purple intersection shows A ∩ B.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Adjust Probabilities&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;prob-a-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;P(A): &lt;span id=&quot;prob-a-value&quot;&gt;0.4&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;prob-a-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.4&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;prob-b-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;P(B): &lt;span id=&quot;prob-b-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;prob-b-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.5&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;overlap-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Overlap: &lt;span id=&quot;overlap-value&quot;&gt;0.2&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;overlap-slider&quot; min=&quot;0&quot; max=&quot;0.4&quot; step=&quot;0.05&quot; value=&quot;0.2&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;conditional-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Probabilities:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;P(A) = &lt;span id=&quot;display-prob-a&quot;&gt;0.400&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B) = &lt;span id=&quot;display-prob-b&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A ∩ B) = &lt;span id=&quot;display-prob-ab&quot;&gt;0.200&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A ∪ B) = &lt;span id=&quot;display-prob-union&quot;&gt;0.700&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;Conditional:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;P(A|B) = &lt;span id=&quot;display-prob-a-given-b&quot;&gt;0.400&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B|A) = &lt;span id=&quot;display-prob-b-given-a&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;5-independence&quot;&gt;5. Independence&lt;/h3&gt;

&lt;p&gt;Two events A and B are &lt;strong&gt;independent&lt;/strong&gt; if:
\(P(A \cap B) = P(A) \cdot P(B)\)&lt;/p&gt;

&lt;p&gt;Equivalently:
\(P(A|B) = P(A) \quad \text{and} \quad P(B|A) = P(B)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: Knowledge about one event doesn’t change the probability of the other.&lt;/p&gt;

&lt;h3 id=&quot;6-random-variables&quot;&gt;6. Random Variables&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;random variable&lt;/strong&gt; X is a function that assigns a real number to each outcome in the sample space:
\(X: \Omega \rightarrow \mathbb{R}\)&lt;/p&gt;

&lt;h4 id=&quot;types-of-random-variables&quot;&gt;Types of Random Variables:&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Discrete&lt;/strong&gt;: Takes countable values (e.g., number of heads in coin flips)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Probability Mass Function (PMF): \(P(X = x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Continuous&lt;/strong&gt;: Takes uncountable values (e.g., height, weight)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Probability Density Function (PDF): \(f_X(x)\)&lt;/li&gt;
  &lt;li&gt;
\[P(a \leq X \leq b) = \int_a^b f_X(x) dx\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;7-connection-to-optimization&quot;&gt;7. Connection to Optimization&lt;/h3&gt;

&lt;p&gt;Probability theory connects to optimization in several ways:&lt;/p&gt;

&lt;h4 id=&quot;maximum-likelihood-estimation&quot;&gt;Maximum Likelihood Estimation&lt;/h4&gt;
&lt;p&gt;Find parameters θ that maximize the likelihood:
\(\hat{\theta} = \arg\max_\theta P(\text{data}|\theta)\)&lt;/p&gt;

&lt;h4 id=&quot;expected-value-optimization&quot;&gt;Expected Value Optimization&lt;/h4&gt;
&lt;p&gt;Minimize expected loss:
\(\min_\theta \mathbb{E}[L(Y, f(X; \theta))]\)&lt;/p&gt;

&lt;h4 id=&quot;bayesian-optimization&quot;&gt;Bayesian Optimization&lt;/h4&gt;
&lt;p&gt;Use probability distributions to model uncertainty in objective functions and guide search for optimal solutions.&lt;/p&gt;

&lt;div id=&quot;optimization-connection&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f0f8ff;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Probability in Optimization Example&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;optimizationCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;MLE Example:&lt;/strong&gt; Finding the parameter μ that maximizes likelihood of observed data from Normal(μ, 1).
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;MLE Demo&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;true-mu-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;True μ: &lt;span id=&quot;true-mu-value&quot;&gt;2.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;true-mu-slider&quot; min=&quot;-2&quot; max=&quot;4&quot; step=&quot;0.1&quot; value=&quot;2.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sample-size-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Sample Size: &lt;span id=&quot;sample-size-value&quot;&gt;20&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sample-size-slider&quot; min=&quot;5&quot; max=&quot;100&quot; step=&quot;5&quot; value=&quot;20&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-mle-data&quot; style=&quot;width: 100%; padding: 10px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Generate Data &amp;amp; Find MLE&lt;/button&gt;
                
                &lt;div id=&quot;mle-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Results:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;True μ: &lt;span id=&quot;display-true-mu&quot;&gt;2.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Sample mean: &lt;span id=&quot;sample-mean&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;MLE estimate: &lt;span id=&quot;mle-estimate&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Error: &lt;span id=&quot;mle-error&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Foundation&lt;/strong&gt;: Probability axioms provide the mathematical foundation for reasoning about uncertainty&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Conditional Probability&lt;/strong&gt;: Essential for updating beliefs with new information&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Independence&lt;/strong&gt;: Simplifies calculations and modeling assumptions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Random Variables&lt;/strong&gt;: Bridge between abstract probability and concrete applications&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Optimization Connection&lt;/strong&gt;: Many optimization problems arise from probabilistic modeling&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Understanding these basics prepares you for more advanced topics like Bayesian inference, maximum likelihood estimation, and stochastic optimization that are central to modern machine learning and data science.&lt;/p&gt;

&lt;script&gt;
// Sample Space Visualization
class SampleSpaceDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;sampleSpaceCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.samples = [];
        this.experimentType = &apos;coin&apos;;
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;experiment&quot;]&apos;);
        const generateBtn = document.getElementById(&apos;generate-sample&apos;);
        const clearBtn = document.getElementById(&apos;clear-samples&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.experimentType = e.target.value;
                this.samples = [];
                this.updateStats();
                this.draw();
            });
        });
        
        generateBtn.addEventListener(&apos;click&apos;, () =&gt; this.generateSample());
        clearBtn.addEventListener(&apos;click&apos;, () =&gt; {
            this.samples = [];
            this.updateStats();
            this.draw();
        });
        
        this.canvas.addEventListener(&apos;click&apos;, () =&gt; this.generateSample());
    }
    
    generateSample() {
        let sample;
        
        switch(this.experimentType) {
            case &apos;coin&apos;:
                sample = {
                    value: Math.random() &lt; 0.5 ? &apos;H&apos; : &apos;T&apos;,
                    x: Math.random() * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: Math.random() &lt; 0.5, // Event A: Heads
                    eventB: Math.random() &lt; 0.3  // Event B: Lucky flip
                };
                break;
            case &apos;dice&apos;:
                const diceValue = Math.floor(Math.random() * 6) + 1;
                sample = {
                    value: diceValue,
                    x: Math.random() * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: diceValue &gt;= 4, // Event A: 4, 5, or 6
                    eventB: diceValue % 2 === 0 // Event B: Even
                };
                break;
            case &apos;uniform&apos;:
                const uniformValue = Math.random();
                sample = {
                    value: uniformValue.toFixed(3),
                    x: uniformValue * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: uniformValue &gt; 0.5, // Event A: &gt; 0.5
                    eventB: uniformValue &lt; 0.7  // Event B: &lt; 0.7
                };
                break;
        }
        
        this.samples.push(sample);
        this.updateStats();
        this.draw();
    }
    
    updateStats() {
        const total = this.samples.length;
        const eventACount = this.samples.filter(s =&gt; s.eventA).length;
        const eventBCount = this.samples.filter(s =&gt; s.eventB).length;
        
        document.getElementById(&apos;total-samples&apos;).textContent = total;
        document.getElementById(&apos;event-a-count&apos;).textContent = eventACount;
        document.getElementById(&apos;event-b-count&apos;).textContent = eventBCount;
        document.getElementById(&apos;prob-a&apos;).textContent = total &gt; 0 ? (eventACount / total).toFixed(3) : &apos;0.000&apos;;
        document.getElementById(&apos;prob-b&apos;).textContent = total &gt; 0 ? (eventBCount / total).toFixed(3) : &apos;0.000&apos;;
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        // Draw background
        this.ctx.fillStyle = &apos;#f8f9fa&apos;;
        this.ctx.fillRect(0, 0, this.width, this.height);
        
        // Draw samples
        this.samples.forEach(sample =&gt; {
            // Determine color based on events
            let color = &apos;#666&apos;;
            if (sample.eventA &amp;&amp; sample.eventB) color = &apos;#9c27b0&apos;; // Both events
            else if (sample.eventA) color = &apos;#2196f3&apos;; // Event A only
            else if (sample.eventB) color = &apos;#f44336&apos;; // Event B only
            
            this.ctx.fillStyle = color;
            this.ctx.beginPath();
            this.ctx.arc(sample.x, sample.y, 5, 0, 2 * Math.PI);
            this.ctx.fill();
            
            // Draw value
            this.ctx.fillStyle = &apos;#000&apos;;
            this.ctx.font = &apos;10px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(sample.value, sample.x, sample.y - 8);
        });
        
        // Draw legend
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;left&apos;;
        this.ctx.fillText(&apos;Legend:&apos;, 10, 20);
        
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 35, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Event A only&apos;, 30, 38);
        
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 50, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Event B only&apos;, 30, 53);
        
        this.ctx.fillStyle = &apos;#9c27b0&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 65, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Both A and B&apos;, 30, 68);
    }
}

// Conditional Probability Visualization
class ConditionalProbDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;conditionalCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.probA = 0.4;
        this.probB = 0.5;
        this.overlap = 0.2;
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const probASlider = document.getElementById(&apos;prob-a-slider&apos;);
        const probBSlider = document.getElementById(&apos;prob-b-slider&apos;);
        const overlapSlider = document.getElementById(&apos;overlap-slider&apos;);
        
        probASlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.probA = parseFloat(e.target.value);
            document.getElementById(&apos;prob-a-value&apos;).textContent = this.probA.toFixed(1);
            this.updateCalculations();
            this.draw();
        });
        
        probBSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.probB = parseFloat(e.target.value);
            document.getElementById(&apos;prob-b-value&apos;).textContent = this.probB.toFixed(1);
            this.updateCalculations();
            this.draw();
        });
        
        overlapSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.overlap = parseFloat(e.target.value);
            document.getElementById(&apos;overlap-value&apos;).textContent = this.overlap.toFixed(1);
            // Ensure overlap doesn&apos;t exceed min(probA, probB)
            const maxOverlap = Math.min(this.probA, this.probB);
            if (this.overlap &gt; maxOverlap) {
                this.overlap = maxOverlap;
                overlapSlider.value = this.overlap;
                document.getElementById(&apos;overlap-value&apos;).textContent = this.overlap.toFixed(1);
            }
            this.updateCalculations();
            this.draw();
        });
        
        this.updateCalculations();
    }
    
    updateCalculations() {
        const probUnion = this.probA + this.probB - this.overlap;
        const probAGivenB = this.probB &gt; 0 ? this.overlap / this.probB : 0;
        const probBGivenA = this.probA &gt; 0 ? this.overlap / this.probA : 0;
        
        document.getElementById(&apos;display-prob-a&apos;).textContent = this.probA.toFixed(3);
        document.getElementById(&apos;display-prob-b&apos;).textContent = this.probB.toFixed(3);
        document.getElementById(&apos;display-prob-ab&apos;).textContent = this.overlap.toFixed(3);
        document.getElementById(&apos;display-prob-union&apos;).textContent = probUnion.toFixed(3);
        document.getElementById(&apos;display-prob-a-given-b&apos;).textContent = probAGivenB.toFixed(3);
        document.getElementById(&apos;display-prob-b-given-a&apos;).textContent = probBGivenA.toFixed(3);
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        // Draw universe rectangle
        this.ctx.strokeStyle = &apos;#000&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.strokeRect(50, 50, 300, 200);
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;14px Arial&apos;;
        this.ctx.fillText(&apos;Ω (Sample Space)&apos;, 55, 45);
        
        // Calculate circle parameters
        const centerAX = 150;
        const centerAY = 150;
        const centerBX = 250;
        const centerBY = 150;
        
        // Calculate radii based on probabilities (area proportional to probability)
        const radiusA = Math.sqrt(this.probA * 10000 / Math.PI);
        const radiusB = Math.sqrt(this.probB * 10000 / Math.PI);
        
        // Draw circle A
        this.ctx.globalAlpha = 0.3;
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerAX, centerAY, radiusA, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Draw circle B
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerBX, centerBY, radiusB, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Draw intersection (approximate)
        if (this.overlap &gt; 0) {
            this.ctx.fillStyle = &apos;#9c27b0&apos;;
            const overlapRadius = Math.sqrt(this.overlap * 5000 / Math.PI);
            this.ctx.beginPath();
            this.ctx.arc((centerAX + centerBX) / 2, (centerAY + centerBY) / 2, overlapRadius, 0, 2 * Math.PI);
            this.ctx.fill();
        }
        
        this.ctx.globalAlpha = 1.0;
        
        // Draw circle outlines
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.arc(centerAX, centerAY, radiusA, 0, 2 * Math.PI);
        this.ctx.stroke();
        
        this.ctx.strokeStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerBX, centerBY, radiusB, 0, 2 * Math.PI);
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;16px Arial&apos;;
        this.ctx.fillText(&apos;A&apos;, centerAX - 40, centerAY);
        this.ctx.fillText(&apos;B&apos;, centerBX + 30, centerBY);
        
        if (this.overlap &gt; 0) {
            this.ctx.fillText(&apos;A∩B&apos;, (centerAX + centerBX) / 2 - 15, (centerAY + centerBY) / 2 + 5);
        }
    }
}

// MLE Optimization Demo
class MLEDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;optimizationCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.trueMu = 2.0;
        this.sampleSize = 20;
        this.data = [];
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const trueMuSlider = document.getElementById(&apos;true-mu-slider&apos;);
        const sampleSizeSlider = document.getElementById(&apos;sample-size-slider&apos;);
        const generateBtn = document.getElementById(&apos;generate-mle-data&apos;);
        
        trueMuSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.trueMu = parseFloat(e.target.value);
            document.getElementById(&apos;true-mu-value&apos;).textContent = this.trueMu.toFixed(1);
            document.getElementById(&apos;display-true-mu&apos;).textContent = this.trueMu.toFixed(3);
        });
        
        sampleSizeSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.sampleSize = parseInt(e.target.value);
            document.getElementById(&apos;sample-size-value&apos;).textContent = this.sampleSize;
        });
        
        generateBtn.addEventListener(&apos;click&apos;, () =&gt; this.generateDataAndFindMLE());
    }
    
    generateDataAndFindMLE() {
        // Generate data from Normal(trueMu, 1)
        this.data = [];
        for (let i = 0; i &lt; this.sampleSize; i++) {
            // Box-Muller transform for normal distribution
            const u1 = Math.random();
            const u2 = Math.random();
            const z = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
            this.data.push(this.trueMu + z); // Normal(trueMu, 1)
        }
        
        // Calculate MLE (sample mean for normal distribution)
        const sampleMean = this.data.reduce((sum, x) =&gt; sum + x, 0) / this.data.length;
        const error = Math.abs(sampleMean - this.trueMu);
        
        // Update display
        document.getElementById(&apos;sample-mean&apos;).textContent = sampleMean.toFixed(3);
        document.getElementById(&apos;mle-estimate&apos;).textContent = sampleMean.toFixed(3);
        document.getElementById(&apos;mle-error&apos;).textContent = error.toFixed(3);
        
        this.draw();
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        if (this.data.length === 0) {
            this.ctx.fillStyle = &apos;#666&apos;;
            this.ctx.font = &apos;16px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(&apos;Click &quot;Generate Data &amp; Find MLE&quot; to start&apos;, this.width / 2, this.height / 2);
            return;
        }
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // X-axis
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Y-axis
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Find data range
        const minX = Math.min(...this.data) - 1;
        const maxX = Math.max(...this.data) + 1;
        
        // Draw likelihood function
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let i = 0; i &lt;= 100; i++) {
            const mu = minX + (maxX - minX) * i / 100;
            let logLikelihood = 0;
            
            // Calculate log-likelihood
            for (const x of this.data) {
                logLikelihood -= 0.5 * Math.log(2 * Math.PI);
                logLikelihood -= 0.5 * (x - mu) * (x - mu);
            }
            
            const x = marginX + (mu - minX) / (maxX - minX) * plotWidth;
            const y = this.height - marginY - (logLikelihood - (-this.data.length * 2)) / (this.data.length) * plotHeight * 0.8;
            
            if (i === 0) {
                this.ctx.moveTo(x, y);
            } else {
                this.ctx.lineTo(x, y);
            }
        }
        this.ctx.stroke();
        
        // Mark MLE
        const sampleMean = this.data.reduce((sum, x) =&gt; sum + x, 0) / this.data.length;
        const mleX = marginX + (sampleMean - minX) / (maxX - minX) * plotWidth;
        
        this.ctx.strokeStyle = &apos;#f44336&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.moveTo(mleX, marginY);
        this.ctx.lineTo(mleX, this.height - marginY);
        this.ctx.stroke();
        
        // Mark true value
        const trueX = marginX + (this.trueMu - minX) / (maxX - minX) * plotWidth;
        this.ctx.strokeStyle = &apos;#4caf50&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.setLineDash([5, 5]);
        this.ctx.beginPath();
        this.ctx.moveTo(trueX, marginY);
        this.ctx.lineTo(trueX, this.height - marginY);
        this.ctx.stroke();
        this.ctx.setLineDash([]);
        
        // Draw data points
        this.ctx.fillStyle = &apos;#666&apos;;
        for (const x of this.data) {
            const pointX = marginX + (x - minX) / (maxX - minX) * plotWidth;
            this.ctx.beginPath();
            this.ctx.arc(pointX, this.height - marginY + 10, 2, 0, 2 * Math.PI);
            this.ctx.fill();
        }
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;μ&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;Log-Likelihood&apos;, 0, 0);
        this.ctx.restore();
        
        // Legend
        this.ctx.textAlign = &apos;left&apos;;
        this.ctx.fillText(&apos;— Likelihood&apos;, 10, 20);
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.fillText(&apos;— MLE&apos;, 10, 35);
        this.ctx.fillStyle = &apos;#4caf50&apos;;
        this.ctx.fillText(&apos;--- True μ&apos;, 10, 50);
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new SampleSpaceDemo();
    new ConditionalProbDemo();
    new MLEDemo();
});
&lt;/script&gt;

&lt;style&gt;
input[type=&quot;range&quot;] {
    -webkit-appearance: none;
    appearance: none;
    height: 5px;
    background: #ddd;
    outline: none;
    border-radius: 5px;
}

input[type=&quot;range&quot;]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
}

input[type=&quot;range&quot;]::-moz-range-thumb {
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
    border: none;
}

canvas {
    border-radius: 5px;
}

.demo-container {
    margin: 20px 0;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>00-03 Real Analysis And Set Theory</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_03_Real_Analysis_and_Set_Theory/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_03_Real_Analysis_and_Set_Theory</id>
   <content type="html">&lt;p&gt;This lesson covers essential concepts from real analysis and set theory needed for optimization, organized into two main sections for comprehensive understanding.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-03-02 Topology in Real Analysis</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_03_02_Topology_in_Real_Analysis/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_03_02_Topology_in_Real_Analysis</id>
   <content type="html">&lt;p&gt;This lesson covers essential topological concepts from real analysis that are crucial for understanding the structure of feasible regions, continuity, and the existence of optimal solutions in optimization problems.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;introduction-to-topology&quot;&gt;Introduction to Topology&lt;/h2&gt;

&lt;p&gt;Topology studies the properties of space that are preserved under continuous deformations. In optimization, topological concepts help us understand the structure of feasible regions and the behavior of functions, particularly regarding the existence and characterization of optimal solutions.&lt;/p&gt;

&lt;h3 id=&quot;metric-spaces-and-distance&quot;&gt;Metric Spaces and Distance&lt;/h3&gt;

&lt;p&gt;Before discussing topology, we need the concept of distance. In \(\mathbb{R}^n\), the standard &lt;strong&gt;Euclidean distance&lt;/strong&gt; between points \(\mathbf{x}\) and \(\mathbf{y}\) is:&lt;/p&gt;

\[d(\mathbf{x}, \mathbf{y}) = \|\mathbf{x} - \mathbf{y}\|_2 = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}\]

&lt;h3 id=&quot;open-balls-and-neighborhoods&quot;&gt;Open Balls and Neighborhoods&lt;/h3&gt;

&lt;p&gt;An &lt;strong&gt;open ball&lt;/strong&gt; centered at \(\mathbf{x}_0\) with radius \(\epsilon &amp;gt; 0\) is:&lt;/p&gt;

\[B(\mathbf{x}_0, \epsilon) = \{\mathbf{y} \in \mathbb{R}^n : d(\mathbf{x}_0, \mathbf{y}) &amp;lt; \epsilon\}\]

&lt;p&gt;This represents all points within distance \(\epsilon\) from \(\mathbf{x}_0\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In \(\mathbb{R}\): \(B(0, 1) = (-1, 1)\) (open interval)&lt;/li&gt;
  &lt;li&gt;In \(\mathbb{R}^2\): \(B(\mathbf{0}, 1) = \{(x, y) : x^2 + y^2 &amp;lt; 1\}\) (open unit disk)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;open-sets&quot;&gt;Open Sets&lt;/h2&gt;

&lt;p&gt;An &lt;strong&gt;open set&lt;/strong&gt; is characterized by the property that it &lt;strong&gt;contains none of its boundary points&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;formal-definition&quot;&gt;Formal Definition&lt;/h3&gt;

&lt;p&gt;A set \(S\) in \(\mathbb{R}^n\) is &lt;strong&gt;open&lt;/strong&gt; if for every point \(\mathbf{x} \in S\), there exists a positive real number \(\epsilon &amp;gt; 0\) such that the open ball \(B(\mathbf{x}, \epsilon)\) is entirely contained within \(S\):&lt;/p&gt;

\[\forall \mathbf{x} \in S, \exists \epsilon &amp;gt; 0 : B(\mathbf{x}, \epsilon) \subseteq S\]

&lt;h3 id=&quot;intuitive-understanding&quot;&gt;Intuitive Understanding&lt;/h3&gt;

&lt;p&gt;An open set has the property that if you’re inside it, you can move a small distance in any direction and still remain inside the set. There’s always some “wiggle room” around every point.&lt;/p&gt;

&lt;h3 id=&quot;examples-of-open-sets&quot;&gt;Examples of Open Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(0, 1) = \{x : 0 &amp;lt; x &amp;lt; 1\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[(-\infty, 5) = \{x : x &amp;lt; 5\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}\) itself&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 &amp;lt; 1\}\) (open unit disk)&lt;/li&gt;
  &lt;li&gt;\(\{(x, y) : x &amp;gt; 0, y &amp;gt; 0\}\) (first quadrant, excluding axes)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^2\) itself&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any open ball \(B(\mathbf{x}_0, r)\)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) itself&lt;/li&gt;
  &lt;li&gt;\(\emptyset\) (empty set - vacuously open)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;properties-of-open-sets&quot;&gt;Properties of Open Sets&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;The union of any collection of open sets is open&lt;/li&gt;
  &lt;li&gt;The intersection of finitely many open sets is open&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) and \(\emptyset\) are both open&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;closed-sets&quot;&gt;Closed Sets&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;closed set&lt;/strong&gt; is defined as a set that contains all of its boundary points. Equivalently, a set \(S\) is closed if its complement \(\mathbb{R}^n \setminus S\) is an &lt;strong&gt;open set&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;formal-definition-1&quot;&gt;Formal Definition&lt;/h3&gt;

&lt;p&gt;A set \(S\) is &lt;strong&gt;closed&lt;/strong&gt; if it contains all its limit points. That is, if a sequence of points \((x_n)\) from \(S\) converges to a point \(\mathbf{x}\), then \(\mathbf{x}\) must also be in \(S\):&lt;/p&gt;

\[\text{If } \mathbf{x}_n \in S \text{ for all } n \text{ and } \lim_{n \to \infty} \mathbf{x}_n = \mathbf{x}, \text{ then } \mathbf{x} \in S\]

&lt;h3 id=&quot;examples-of-closed-sets&quot;&gt;Examples of Closed Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[[0, 1] = \{x : 0 \leq x \leq 1\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[[a, \infty) = \{x : x \geq a\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\{0\}\) (single point)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{Z}\) (integers)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
  &lt;li&gt;\(\{(x, y) : x \geq 0, y \geq 0\}\) (first quadrant, including axes)&lt;/li&gt;
  &lt;li&gt;\(\{(0, 0)\}\) (single point)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any closed ball \(\overline{B}(\mathbf{x}_0, r) = \{\mathbf{x} : d(\mathbf{x}, \mathbf{x}_0) \leq r\}\)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) itself&lt;/li&gt;
  &lt;li&gt;\(\emptyset\) (empty set)&lt;/li&gt;
  &lt;li&gt;Any finite set&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;properties-of-closed-sets&quot;&gt;Properties of Closed Sets&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;The intersection of any collection of closed sets is closed&lt;/li&gt;
  &lt;li&gt;The union of finitely many closed sets is closed&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) and \(\emptyset\) are both closed&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;important-note&quot;&gt;Important Note&lt;/h3&gt;

&lt;p&gt;Sets can be:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Open but not closed:&lt;/strong&gt; \((0, 1)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closed but not open:&lt;/strong&gt; \([0, 1]\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Both open and closed:&lt;/strong&gt; \(\mathbb{R}^n\), \(\emptyset\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Neither open nor closed:&lt;/strong&gt; \([0, 1)\), \((0, 1]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;boundary-interior-and-closure&quot;&gt;Boundary, Interior, and Closure&lt;/h2&gt;

&lt;h3 id=&quot;boundary&quot;&gt;Boundary&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;boundary&lt;/strong&gt; of a set \(S\), denoted \(\partial S\), consists of points that are “on the edge” of the set. A point \(\mathbf{x}\) is a &lt;strong&gt;boundary point&lt;/strong&gt; of \(S\) if every open ball centered at \(\mathbf{x}\) intersects both \(S\) and its complement \(S^c\):&lt;/p&gt;

\[\partial S = \{\mathbf{x} : \forall \epsilon &amp;gt; 0, B(\mathbf{x}, \epsilon) \cap S \neq \emptyset \text{ and } B(\mathbf{x}, \epsilon) \cap S^c \neq \emptyset\}\]

&lt;h3 id=&quot;interior&quot;&gt;Interior&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;interior&lt;/strong&gt; of a set \(S\), denoted \(S^\circ\) or \(\text{int}(S)\), includes all points strictly “inside” the set, excluding the boundary:&lt;/p&gt;

\[S^\circ = \{\mathbf{x} \in S : \exists \epsilon &amp;gt; 0, B(\mathbf{x}, \epsilon) \subseteq S\}\]

&lt;h3 id=&quot;closure&quot;&gt;Closure&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;closure&lt;/strong&gt; of a set \(S\), denoted \(\overline{S}\) or \(\text{cl}(S)\), is the smallest closed set containing \(S\):&lt;/p&gt;

\[\overline{S} = S \cup \partial S\]

&lt;h3 id=&quot;example-analysis&quot;&gt;Example Analysis&lt;/h3&gt;

&lt;p&gt;For the interval \(S = [0, 1)\) in \(\mathbb{R}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Interior:&lt;/strong&gt; \(S^\circ = (0, 1)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Boundary:&lt;/strong&gt; \(\partial S = \{0, 1\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closure:&lt;/strong&gt; \(\overline{S} = [0, 1]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the open disk \(S = \{(x, y) : x^2 + y^2 &amp;lt; 1\}\) in \(\mathbb{R}^2\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Interior:&lt;/strong&gt; \(S^\circ = S\) (the set is already open)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Boundary:&lt;/strong&gt; \(\partial S = \{(x, y) : x^2 + y^2 = 1\}\) (unit circle)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closure:&lt;/strong&gt; \(\overline{S} = \{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;compact-sets&quot;&gt;Compact Sets&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;compact set&lt;/strong&gt; is one of the most important concepts in optimization theory.&lt;/p&gt;

&lt;h3 id=&quot;definition-in-euclidean-spaces&quot;&gt;Definition in Euclidean Spaces&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Heine-Borel Theorem:&lt;/strong&gt; In Euclidean spaces (\(\mathbb{R}^n\)), a set is compact if and only if it is both &lt;strong&gt;closed and bounded&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Bounded:&lt;/strong&gt; A set \(S\) is bounded if it can be contained within some sufficiently large open ball: \(\exists M &amp;gt; 0, \mathbf{x}_0\) such that \(S \subseteq B(\mathbf{x}_0, M)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closed:&lt;/strong&gt; As defined above&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;examples-of-compact-sets&quot;&gt;Examples of Compact Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\([a, b]\) (any closed, bounded interval)&lt;/li&gt;
  &lt;li&gt;\(\{0\}\) (single point)&lt;/li&gt;
  &lt;li&gt;Any finite set&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
  &lt;li&gt;\([0, 1] \times [0, 1]\) (unit square)&lt;/li&gt;
  &lt;li&gt;Any finite set of points&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any closed ball \(\overline{B}(\mathbf{x}_0, r)\)&lt;/li&gt;
  &lt;li&gt;Any closed, bounded rectangle \([a_1, b_1] \times [a_2, b_2] \times \cdots \times [a_n, b_n]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;non-compact-sets&quot;&gt;Non-Compact Sets&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\((0, 1)\) (bounded but not closed)&lt;/li&gt;
  &lt;li&gt;\([0, \infty)\) (closed but not bounded)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) (not bounded)&lt;/li&gt;
  &lt;li&gt;\(\{1, 1/2, 1/3, 1/4, \ldots\}\) (bounded but not closed, since 0 is a limit point not in the set)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;continuity-of-functions&quot;&gt;Continuity of Functions&lt;/h2&gt;

&lt;h3 id=&quot;point-wise-continuity&quot;&gt;Point-wise Continuity&lt;/h3&gt;

&lt;p&gt;A function \(f: A \to \mathbb{R}\) is &lt;strong&gt;continuous at a point&lt;/strong&gt; \(\mathbf{c} \in A\) if for every \(\varepsilon &amp;gt; 0\), there exists \(\delta &amp;gt; 0\) such that for all \(\mathbf{x} \in A\):&lt;/p&gt;

\[\|\mathbf{x} - \mathbf{c}\| &amp;lt; \delta \implies |f(\mathbf{x}) - f(\mathbf{c})| &amp;lt; \varepsilon\]

&lt;p&gt;&lt;strong&gt;Intuitive meaning:&lt;/strong&gt; Small changes in input lead to small changes in output.&lt;/p&gt;

&lt;h3 id=&quot;global-continuity&quot;&gt;Global Continuity&lt;/h3&gt;

&lt;p&gt;\(f\) is &lt;strong&gt;continuous on \(A\)&lt;/strong&gt; if it’s continuous at every point in \(A\).&lt;/p&gt;

&lt;h3 id=&quot;sequential-characterization&quot;&gt;Sequential Characterization&lt;/h3&gt;

&lt;p&gt;\(f\) is continuous at \(\mathbf{c}\) if and only if for every sequence \((\mathbf{x}_n)\) in \(A\) converging to \(\mathbf{c}\):&lt;/p&gt;

\[\lim_{n \to \infty} f(\mathbf{x}_n) = f(\mathbf{c})\]

&lt;hr /&gt;

&lt;h2 id=&quot;important-theorems-for-optimization&quot;&gt;Important Theorems for Optimization&lt;/h2&gt;

&lt;h3 id=&quot;extreme-value-theorem&quot;&gt;Extreme Value Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;If \(f\) is continuous on a compact set \(K\), then \(f\) attains its maximum and minimum on \(K\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is fundamental for optimization: it guarantees that continuous objective functions have optimal solutions on compact feasible regions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof idea:&lt;/strong&gt; Compactness ensures that the supremum and infimum of \(f\) on \(K\) are actually achieved at points in \(K\).&lt;/p&gt;

&lt;h3 id=&quot;intermediate-value-theorem&quot;&gt;Intermediate Value Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;If \(f\) is continuous on \([a, b]\) and \(y\) is between \(f(a)\) and \(f(b)\), then there exists \(c \in [a, b]\) such that \(f(c) = y\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This helps establish the existence of solutions to equations \(f(x) = 0\).&lt;/p&gt;

&lt;h3 id=&quot;bolzano-weierstrass-theorem&quot;&gt;Bolzano-Weierstrass Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Every bounded sequence in \(\mathbb{R}^n\) has a convergent subsequence.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is crucial for proving convergence of optimization algorithms.&lt;/p&gt;

&lt;h3 id=&quot;weierstrass-approximation-theorem&quot;&gt;Weierstrass Approximation Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Every continuous function on a closed interval can be uniformly approximated by polynomials.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This justifies using polynomial approximations in optimization algorithms.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;h3 id=&quot;1-existence-of-solutions&quot;&gt;1. Existence of Solutions&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Compact feasible sets guarantee optimal solutions exist:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If the feasible region \(S\) is compact and the objective function \(f\) is continuous, then the optimization problem \(\min_{\mathbf{x} \in S} f(\mathbf{x})\) has a solution.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-constraint-qualification&quot;&gt;2. Constraint Qualification&lt;/h3&gt;

&lt;p&gt;Understanding topological properties of constraint sets:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Regular points:&lt;/strong&gt; Points where constraint gradients are linearly independent&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interior point methods:&lt;/strong&gt; Require the feasible region to have non-empty interior&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-convergence-analysis&quot;&gt;3. Convergence Analysis&lt;/h3&gt;

&lt;p&gt;Analyzing whether optimization algorithms converge:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Closed sets:&lt;/strong&gt; Ensure limit points of convergent sequences remain feasible&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compactness:&lt;/strong&gt; Guarantees convergent subsequences exist&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-local-vs-global-optima&quot;&gt;4. Local vs Global Optima&lt;/h3&gt;

&lt;p&gt;Using neighborhoods to define optimality:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Local minimum:&lt;/strong&gt; \(f(\mathbf{x}^*) \leq f(\mathbf{x})\) for all \(\mathbf{x}\) in some neighborhood of \(\mathbf{x}^*\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Global minimum:&lt;/strong&gt; \(f(\mathbf{x}^*) \leq f(\mathbf{x})\) for all \(\mathbf{x}\) in the feasible region&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-feasible-region-analysis&quot;&gt;5. Feasible Region Analysis&lt;/h3&gt;

&lt;p&gt;Determining properties of constraint sets:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linear constraints:&lt;/strong&gt; Define closed sets (half-spaces)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nonlinear constraints:&lt;/strong&gt; May create sets that are neither open nor closed&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compact feasible regions:&lt;/strong&gt; Guarantee existence of optimal solutions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-portfolio-optimization&quot;&gt;Example: Portfolio Optimization&lt;/h3&gt;

&lt;p&gt;Consider minimizing portfolio risk subject to constraints:&lt;/p&gt;

\[\begin{align}
\min_{\mathbf{w}} \quad &amp;amp; \mathbf{w}^T \mathbf{\Sigma} \mathbf{w} \\
\text{s.t.} \quad &amp;amp; \mathbf{1}^T \mathbf{w} = 1 \\
&amp;amp; \mathbf{w} \geq \mathbf{0}
\end{align}\]

&lt;p&gt;The feasible region \(S = \{\mathbf{w} : \mathbf{1}^T \mathbf{w} = 1, \mathbf{w} \geq \mathbf{0}\}\) is:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Closed:&lt;/strong&gt; It’s the intersection of closed sets&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bounded:&lt;/strong&gt; The constraint \(\mathbf{1}^T \mathbf{w} = 1\) with \(\mathbf{w} \geq \mathbf{0}\) bounds the feasible region&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compact:&lt;/strong&gt; Being closed and bounded in \(\mathbb{R}^n\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since the objective function \(\mathbf{w}^T \mathbf{\Sigma} \mathbf{w}\) is continuous and \(S\) is compact, the Extreme Value Theorem guarantees that an optimal portfolio exists.&lt;/p&gt;

&lt;p&gt;Understanding topology and real analysis provides the rigorous foundation needed to prove that optimization problems have solutions and that algorithms will find them. These concepts are essential for both theoretical analysis and practical algorithm design.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-03-01 Set Theory Fundamentals</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_03_01_Set_Theory_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_03_01_Set_Theory_Fundamentals</id>
   <content type="html">&lt;p&gt;This lesson covers fundamental concepts from set theory that provide the mathematical foundation for understanding optimization problems, constraints, and feasible regions.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;introduction-to-set-theory&quot;&gt;Introduction to Set Theory&lt;/h2&gt;

&lt;p&gt;Set theory provides the foundation for modern mathematics and is essential for understanding optimization concepts. A &lt;strong&gt;set&lt;/strong&gt; is simply a collection of distinct objects, called elements or members.&lt;/p&gt;

&lt;h3 id=&quot;basic-notation&quot;&gt;Basic Notation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Set notation:&lt;/strong&gt; \(A = \{1, 2, 3, 4\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Element membership:&lt;/strong&gt; \(x \in A\) (x is in A) or \(x \notin A\) (x is not in A)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Empty set:&lt;/strong&gt; \(\emptyset = \{\}\) (the set with no elements)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Set builder notation:&lt;/strong&gt; \(A = \{x : P(x)\}\) (the set of all x such that property P(x) holds)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;examples&quot;&gt;Examples&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\(A = \{1, 2, 3, 4\}\) (explicit listing)&lt;/li&gt;
  &lt;li&gt;\(B = \{x \in \mathbb{R} : x^2 &amp;lt; 4\} = (-2, 2)\) (set builder notation)&lt;/li&gt;
  &lt;li&gt;\(C = \{x \in \mathbb{Z} : x \text{ is even}\}\) (all even integers)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;basic-set-operations&quot;&gt;Basic Set Operations&lt;/h2&gt;

&lt;h3 id=&quot;sets-and-subsets&quot;&gt;Sets and Subsets&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Subset:&lt;/strong&gt; \(A \subseteq B\) means every element of \(A\) is also in \(B\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Proper Subset:&lt;/strong&gt; \(A \subset B\) means \(A \subseteq B\) and \(A \neq B\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Set Equality:&lt;/strong&gt; \(A = B\) if and only if \(A \subseteq B\) and \(B \subseteq A\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\{1, 2\} \subseteq \{1, 2, 3, 4\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[\{1, 2\} \subset \{1, 2, 3, 4\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\emptyset \subseteq A\) for any set \(A\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;union-and-intersection&quot;&gt;Union and Intersection&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Union (\(A \cup B\)):&lt;/strong&gt; All elements that are in \(A\) or \(B\) (or both)
\(A \cup B = \{x : x \in A \text{ or } x \in B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Intersection (\(A \cap B\)):&lt;/strong&gt; All elements that are in both \(A\) and \(B\)
\(A \cap B = \{x : x \in A \text{ and } x \in B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If \(A = \{1, 2, 3\}\) and \(B = \{3, 4, 5\}\), then:
    &lt;ul&gt;
      &lt;li&gt;
\[A \cup B = \{1, 2, 3, 4, 5\}\]
      &lt;/li&gt;
      &lt;li&gt;
\[A \cap B = \{3\}\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disjoint Sets:&lt;/strong&gt; \(A\) and \(B\) are disjoint if \(A \cap B = \emptyset\)&lt;/p&gt;

&lt;h3 id=&quot;complement-and-difference&quot;&gt;Complement and Difference&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Complement (\(A^c\)):&lt;/strong&gt; All elements not in \(A\) (within some universal set \(U\))
\(A^c = \{x \in U : x \notin A\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Set Difference (\(A \setminus B\)):&lt;/strong&gt; Elements in \(A\) but not in \(B\)
\(A \setminus B = \{x : x \in A \text{ and } x \notin B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Symmetric Difference:&lt;/strong&gt; \((A \setminus B) \cup (B \setminus A) = (A \cup B) \setminus (A \cap B)\)&lt;/p&gt;

&lt;h3 id=&quot;set-laws&quot;&gt;Set Laws&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Commutative Laws:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[A \cup B = B \cup A\]
  &lt;/li&gt;
  &lt;li&gt;
\[A \cap B = B \cap A\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Associative Laws:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(A \cup B) \cup C = A \cup (B \cup C)\]
  &lt;/li&gt;
  &lt;li&gt;
\[(A \cap B) \cap C = A \cap (B \cap C)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Distributive Laws:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\]
  &lt;/li&gt;
  &lt;li&gt;
\[A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;De Morgan’s Laws:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(A \cup B)^c = A^c \cap B^c\]
  &lt;/li&gt;
  &lt;li&gt;
\[(A \cap B)^c = A^c \cup B^c\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;important-number-sets&quot;&gt;Important Number Sets&lt;/h2&gt;

&lt;p&gt;Understanding the hierarchy of number systems is crucial for optimization:&lt;/p&gt;

&lt;h3 id=&quot;natural-numbers&quot;&gt;Natural Numbers&lt;/h3&gt;
&lt;p&gt;\(\mathbb{N} = \{1, 2, 3, 4, \ldots\}\)
(Sometimes includes 0: \(\mathbb{N}_0 = \{0, 1, 2, 3, \ldots\}\))&lt;/p&gt;

&lt;h3 id=&quot;integers&quot;&gt;Integers&lt;/h3&gt;
&lt;p&gt;\(\mathbb{Z} = \{\ldots, -2, -1, 0, 1, 2, \ldots\}\)&lt;/p&gt;

&lt;h3 id=&quot;rational-numbers&quot;&gt;Rational Numbers&lt;/h3&gt;
&lt;p&gt;\(\mathbb{Q} = \left\{\frac{p}{q} : p, q \in \mathbb{Z}, q \neq 0\right\}\)&lt;/p&gt;

&lt;p&gt;All numbers that can be expressed as fractions.&lt;/p&gt;

&lt;h3 id=&quot;real-numbers&quot;&gt;Real Numbers&lt;/h3&gt;
&lt;p&gt;\(\mathbb{R}\) includes all rational and irrational numbers (like \(\pi\), \(e\), \(\sqrt{2}\)).&lt;/p&gt;

&lt;h3 id=&quot;complex-numbers&quot;&gt;Complex Numbers&lt;/h3&gt;
&lt;p&gt;\(\mathbb{C} = \{a + bi : a, b \in \mathbb{R}, i^2 = -1\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hierarchy:&lt;/strong&gt; \(\mathbb{N} \subset \mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R} \subset \mathbb{C}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;functions-domain-and-range&quot;&gt;Functions: Domain and Range&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;function&lt;/strong&gt; \(f: A \to B\) is a rule that assigns to each element in set \(A\) exactly one element in set \(B\).&lt;/p&gt;

&lt;h3 id=&quot;key-concepts&quot;&gt;Key Concepts&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Domain:&lt;/strong&gt; The set \(A\) of all possible input values&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Codomain:&lt;/strong&gt; The set \(B\) where outputs are taken from&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Range (Image):&lt;/strong&gt; The set of all actual output values: \(\text{Range}(f) = \{f(x) : x \in A\} \subseteq B\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; For \(f(x) = x^2\) with \(f: \mathbb{R} \to \mathbb{R}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Domain: \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;Codomain: \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;Range: \([0, \infty)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;types-of-functions&quot;&gt;Types of Functions&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Injective (One-to-One):&lt;/strong&gt; Each element in the range corresponds to exactly one element in the domain
\(f(x_1) = f(x_2) \implies x_1 = x_2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Surjective (Onto):&lt;/strong&gt; Every element in the codomain is in the range
For every \(y \in B\), there exists \(x \in A\) such that \(f(x) = y\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bijective:&lt;/strong&gt; Both injective and surjective
There’s a perfect one-to-one correspondence between domain and codomain.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(f(x) = 2x\) on \(\mathbb{R}\) is bijective&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) on \(\mathbb{R}\) is neither injective nor surjective&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) on \([0, \infty) \to [0, \infty)\) is bijective&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;inequalities&quot;&gt;Inequalities&lt;/h2&gt;

&lt;p&gt;Understanding inequalities is crucial for optimization, as constraints are often expressed as inequalities.&lt;/p&gt;

&lt;h3 id=&quot;basic-inequality-symbols&quot;&gt;Basic Inequality Symbols&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\(a &amp;lt; b\): \(a\) is strictly less than \(b\)&lt;/li&gt;
  &lt;li&gt;\(a \leq b\): \(a\) is less than or equal to \(b\)&lt;/li&gt;
  &lt;li&gt;\(a &amp;gt; b\): \(a\) is strictly greater than \(b\)&lt;/li&gt;
  &lt;li&gt;\(a \geq b\): \(a\) is greater than or equal to \(b\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;properties-of-inequalities&quot;&gt;Properties of Inequalities&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Transitivity:&lt;/strong&gt; If \(a \leq b\) and \(b \leq c\), then \(a \leq c\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Addition:&lt;/strong&gt; If \(a \leq b\), then \(a + c \leq b + c\) for any \(c\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Multiplication by Positive:&lt;/strong&gt; If \(a \leq b\) and \(c &amp;gt; 0\), then \(ac \leq bc\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Multiplication by Negative:&lt;/strong&gt; If \(a \leq b\) and \(c &amp;lt; 0\), then \(ac \geq bc\) (inequality flips!)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;interval-notation&quot;&gt;Interval Notation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Open interval:&lt;/strong&gt; \((a, b) = \{x \in \mathbb{R} : a &amp;lt; x &amp;lt; b\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closed interval:&lt;/strong&gt; \([a, b] = \{x \in \mathbb{R} : a \leq x \leq b\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Half-open intervals:&lt;/strong&gt; \([a, b)\), \((a, b]\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Unbounded intervals:&lt;/strong&gt; \((-\infty, a)\), \([a, \infty)\), \((-\infty, \infty) = \mathbb{R}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;p&gt;Set theory concepts are fundamental to optimization:&lt;/p&gt;

&lt;h3 id=&quot;1-feasible-regions&quot;&gt;1. Feasible Regions&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;feasible region&lt;/strong&gt; is the set of all points satisfying the constraints:
\(S = \{x \in \mathbb{R}^n : g_i(x) \leq 0, i = 1, \ldots, m; h_j(x) = 0, j = 1, \ldots, p\}\)&lt;/p&gt;

&lt;h3 id=&quot;2-level-sets&quot;&gt;2. Level Sets&lt;/h3&gt;

&lt;p&gt;For a function \(f: \mathbb{R}^n \to \mathbb{R}\), the &lt;strong&gt;level set&lt;/strong&gt; at level \(c\) is:
\(L_c = \{x \in \mathbb{R}^n : f(x) = c\}\)&lt;/p&gt;

&lt;h3 id=&quot;3-constraint-qualification&quot;&gt;3. Constraint Qualification&lt;/h3&gt;

&lt;p&gt;Understanding when constraint sets have “nice” properties (like being closed or having non-empty interior) affects the existence and characterization of optimal solutions.&lt;/p&gt;

&lt;h3 id=&quot;4-convergence-analysis&quot;&gt;4. Convergence Analysis&lt;/h3&gt;

&lt;p&gt;Sequences and limits are essential for analyzing whether optimization algorithms converge to optimal solutions.&lt;/p&gt;

&lt;h3 id=&quot;5-set-operations-in-algorithms&quot;&gt;5. Set Operations in Algorithms&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Intersection:&lt;/strong&gt; Finding points that satisfy multiple constraints&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Union:&lt;/strong&gt; Combining feasible regions from different scenarios&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Complement:&lt;/strong&gt; Understanding infeasible regions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; In linear programming, the feasible region is:
\(S = \{x \in \mathbb{R}^n : Ax \leq b, x \geq 0\} = \bigcap_{i=1}^{m} \{x : a_i^T x \leq b_i\} \cap \{x : x \geq 0\}\)&lt;/p&gt;

&lt;p&gt;This is the intersection of half-spaces, demonstrating how set operations naturally arise in optimization problem formulation.&lt;/p&gt;

&lt;p&gt;Understanding set theory provides the rigorous mathematical foundation needed to formulate optimization problems precisely and analyze their properties systematically.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02 Basic Linear Algebra</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_02_Basic_Linear_Algebra/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_02_Basic_Linear_Algebra</id>
   <content type="html">&lt;p&gt;This lesson covers essential linear algebra concepts needed for optimization, organized into three main sections for systematic learning.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-03 Eigenvalues and Eigenvectors</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_02_03_Eigenvalues_and_Eigenvectors/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_02_03_Eigenvalues_and_Eigenvectors</id>
   <content type="html">&lt;p&gt;This lesson covers eigenvalues and eigenvectors, which are crucial for understanding the behavior of linear transformations and quadratic functions in optimization.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;definition-and-intuition&quot;&gt;Definition and Intuition&lt;/h2&gt;

&lt;p&gt;When a matrix transforms a vector, it usually changes both the vector’s direction and its length. However, &lt;strong&gt;eigenvectors&lt;/strong&gt; are special vectors that, when transformed by a given matrix, only get scaled but do not change their direction.&lt;/p&gt;

&lt;h3 id=&quot;mathematical-definition&quot;&gt;Mathematical Definition&lt;/h3&gt;

&lt;p&gt;For a square matrix \(\mathbf{A}\) and a non-zero vector \(\mathbf{v}\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\mathbf{v}\) is an &lt;strong&gt;eigenvector&lt;/strong&gt; of \(\mathbf{A}\)&lt;/li&gt;
  &lt;li&gt;\(\lambda\) is the corresponding &lt;strong&gt;eigenvalue&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;if they satisfy the &lt;strong&gt;eigenvalue equation&lt;/strong&gt;:&lt;/p&gt;

\[\mathbf{A}\mathbf{v} = \lambda\mathbf{v}\]

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Eigenvectors:&lt;/strong&gt; Non-zero vectors that maintain their direction under the transformation \(\mathbf{A}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Eigenvalues:&lt;/strong&gt; The scalar factors by which the eigenvectors are scaled&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Visual Understanding:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If \(\lambda &amp;gt; 1\): The eigenvector is stretched&lt;/li&gt;
  &lt;li&gt;If \(0 &amp;lt; \lambda &amp;lt; 1\): The eigenvector is shrunk&lt;/li&gt;
  &lt;li&gt;If \(\lambda &amp;lt; 0\): The eigenvector is scaled and flipped&lt;/li&gt;
  &lt;li&gt;If \(\lambda = 0\): The eigenvector is mapped to the zero vector&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;finding-eigenvalues-and-eigenvectors&quot;&gt;Finding Eigenvalues and Eigenvectors&lt;/h2&gt;

&lt;h3 id=&quot;step-1-find-eigenvalues&quot;&gt;Step 1: Find Eigenvalues&lt;/h3&gt;

&lt;p&gt;Rearrange the eigenvalue equation:
\(\mathbf{A}\mathbf{v} = \lambda\mathbf{v}\)
\(\mathbf{A}\mathbf{v} - \lambda\mathbf{v} = \mathbf{0}\)
\((\mathbf{A} - \lambda\mathbf{I})\mathbf{v} = \mathbf{0}\)&lt;/p&gt;

&lt;p&gt;For a non-trivial solution (\(\mathbf{v} \neq \mathbf{0}\)), the matrix \((\mathbf{A} - \lambda\mathbf{I})\) must be singular, so:&lt;/p&gt;

\[\det(\mathbf{A} - \lambda\mathbf{I}) = 0\]

&lt;p&gt;This is called the &lt;strong&gt;characteristic equation&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;step-2-find-eigenvectors&quot;&gt;Step 2: Find Eigenvectors&lt;/h3&gt;

&lt;p&gt;For each eigenvalue \(\lambda_i\), solve the system:
\((\mathbf{A} - \lambda_i\mathbf{I})\mathbf{v} = \mathbf{0}\)&lt;/p&gt;

&lt;p&gt;The solutions form the &lt;strong&gt;eigenspace&lt;/strong&gt; corresponding to \(\lambda_i\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;detailed-example&quot;&gt;Detailed Example&lt;/h2&gt;

&lt;p&gt;Let’s find the eigenvalues and eigenvectors of \(\mathbf{A} = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\).&lt;/p&gt;

&lt;h3 id=&quot;step-1-find-eigenvalues-1&quot;&gt;Step 1: Find Eigenvalues&lt;/h3&gt;

\[\mathbf{A} - \lambda\mathbf{I} = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix} - \lambda\begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix} = \begin{pmatrix} 3-\lambda &amp;amp; 1 \\ 0 &amp;amp; 2-\lambda \end{pmatrix}\]

\[\det(\mathbf{A} - \lambda\mathbf{I}) = (3-\lambda)(2-\lambda) - (1)(0) = (3-\lambda)(2-\lambda) = 0\]

&lt;p&gt;This gives us \(\lambda_1 = 3\) and \(\lambda_2 = 2\).&lt;/p&gt;

&lt;h3 id=&quot;step-2-find-eigenvectors-1&quot;&gt;Step 2: Find Eigenvectors&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;For \(\lambda_1 = 3\):&lt;/strong&gt;
\((\mathbf{A} - 3\mathbf{I})\mathbf{v} = \begin{pmatrix} 0 &amp;amp; 1 \\ 0 &amp;amp; -1 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This gives us \(v_2 = 0\) and \(v_1\) can be any non-zero value. So \(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) (or any scalar multiple).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For \(\lambda_2 = 2\):&lt;/strong&gt;
\((\mathbf{A} - 2\mathbf{I})\mathbf{v} = \begin{pmatrix} 1 &amp;amp; 1 \\ 0 &amp;amp; 0 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This gives us \(v_1 + v_2 = 0\), so \(v_2 = -v_1\). Thus \(\mathbf{v}_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}\) (or any scalar multiple).&lt;/p&gt;

&lt;h3 id=&quot;verification&quot;&gt;Verification&lt;/h3&gt;

&lt;p&gt;Let’s verify our results:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{A}\mathbf{v}_1 = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 3 \\ 0 \end{pmatrix} = 3\begin{pmatrix} 1 \\ 0 \end{pmatrix} = 3\mathbf{v}_1\) ✓&lt;/li&gt;
  &lt;li&gt;\(\mathbf{A}\mathbf{v}_2 = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\begin{pmatrix} 1 \\ -1 \end{pmatrix} = \begin{pmatrix} 2 \\ -2 \end{pmatrix} = 2\begin{pmatrix} 1 \\ -1 \end{pmatrix} = 2\mathbf{v}_2\) ✓&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;properties-and-important-theorems&quot;&gt;Properties and Important Theorems&lt;/h2&gt;

&lt;h3 id=&quot;key-properties&quot;&gt;Key Properties&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Sum of eigenvalues = trace of matrix:&lt;/strong&gt;
\(\sum_{i=1}^n \lambda_i = \text{tr}(\mathbf{A}) = \sum_{i=1}^n a_{ii}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Product of eigenvalues = determinant of matrix:&lt;/strong&gt;
\(\prod_{i=1}^n \lambda_i = \det(\mathbf{A})\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Eigenvectors corresponding to different eigenvalues are linearly independent&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;If \(\mathbf{A}\) is symmetric, all eigenvalues are real and eigenvectors are orthogonal&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;eigenvalue-multiplicity&quot;&gt;Eigenvalue Multiplicity&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Algebraic multiplicity:&lt;/strong&gt; How many times \(\lambda\) appears as a root of the characteristic polynomial&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Geometric multiplicity:&lt;/strong&gt; The dimension of the eigenspace (number of linearly independent eigenvectors)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For any eigenvalue: geometric multiplicity ≤ algebraic multiplicity&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;diagonalization&quot;&gt;Diagonalization&lt;/h2&gt;

&lt;p&gt;A matrix \(\mathbf{A}\) is &lt;strong&gt;diagonalizable&lt;/strong&gt; if it can be written as:&lt;/p&gt;

\[\mathbf{A} = \mathbf{P}\mathbf{D}\mathbf{P}^{-1}\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{D}\) is a diagonal matrix of eigenvalues&lt;/li&gt;
  &lt;li&gt;\(\mathbf{P}\) is a matrix whose columns are the corresponding eigenvectors&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;benefits-of-diagonalization&quot;&gt;Benefits of Diagonalization&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Easy computation of powers:&lt;/strong&gt; \(\mathbf{A}^k = \mathbf{P}\mathbf{D}^k\mathbf{P}^{-1}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Understanding behavior:&lt;/strong&gt; The eigenvalues determine the transformation’s behavior along each eigenvector direction&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;p&gt;Eigenvalues and eigenvectors are crucial in optimization for several reasons:&lt;/p&gt;

&lt;h3 id=&quot;1-quadratic-forms-and-definiteness&quot;&gt;1. Quadratic Forms and Definiteness&lt;/h3&gt;

&lt;p&gt;For a quadratic function \(f(\mathbf{x}) = \mathbf{x}^T\mathbf{Q}\mathbf{x}\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Positive definite&lt;/strong&gt; (\(f(\mathbf{x}) &amp;gt; 0\) for \(\mathbf{x} \neq \mathbf{0}\)): All eigenvalues of \(\mathbf{Q}\) are positive&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Positive semidefinite&lt;/strong&gt; (\(f(\mathbf{x}) \geq 0\)): All eigenvalues are non-negative&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Negative definite&lt;/strong&gt; (\(f(\mathbf{x}) &amp;lt; 0\) for \(\mathbf{x} \neq \mathbf{0}\)): All eigenvalues are negative&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Indefinite&lt;/strong&gt; (\(f(\mathbf{x})\) can be positive or negative): Mixed positive and negative eigenvalues&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-second-order-optimality-conditions&quot;&gt;2. Second-Order Optimality Conditions&lt;/h3&gt;

&lt;p&gt;For a function \(f(\mathbf{x})\) at a critical point \(\mathbf{x}^*\) (where \(\nabla f(\mathbf{x}^*) = \mathbf{0}\)):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Local minimum:&lt;/strong&gt; Hessian \(\nabla^2 f(\mathbf{x}^*)\) is positive definite (all eigenvalues &amp;gt; 0)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Local maximum:&lt;/strong&gt; Hessian is negative definite (all eigenvalues &amp;lt; 0)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Saddle point:&lt;/strong&gt; Hessian is indefinite (mixed eigenvalues)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-principal-component-analysis-pca&quot;&gt;3. Principal Component Analysis (PCA)&lt;/h3&gt;

&lt;p&gt;PCA finds the directions of maximum variance in data:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Eigenvectors of the covariance matrix give the principal directions&lt;/li&gt;
  &lt;li&gt;Eigenvalues give the variance along each principal direction&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-convergence-analysis&quot;&gt;4. Convergence Analysis&lt;/h3&gt;

&lt;p&gt;In iterative optimization algorithms:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;condition number&lt;/strong&gt; \(\kappa = \frac{\lambda_{\max}}{\lambda_{\min}}\) affects convergence speed&lt;/li&gt;
  &lt;li&gt;Large condition numbers lead to slow convergence&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-newtons-method&quot;&gt;5. Newton’s Method&lt;/h3&gt;

&lt;p&gt;Newton’s method uses the inverse Hessian:
\(\mathbf{x}_{k+1} = \mathbf{x}_k - [\nabla^2 f(\mathbf{x}_k)]^{-1} \nabla f(\mathbf{x}_k)\)&lt;/p&gt;

&lt;p&gt;The eigenvalues of the Hessian determine the method’s behavior and convergence rate.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;example-optimization-application&quot;&gt;Example: Optimization Application&lt;/h2&gt;

&lt;p&gt;Consider minimizing \(f(x, y) = 2x^2 + 3y^2 + 2xy\).&lt;/p&gt;

&lt;p&gt;The Hessian is: \(\mathbf{H} = \begin{pmatrix} 4 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Finding eigenvalues:&lt;/strong&gt;
\(\det(\mathbf{H} - \lambda\mathbf{I}) = (4-\lambda)(6-\lambda) - 4 = \lambda^2 - 10\lambda + 20 = 0\)&lt;/p&gt;

\[\lambda = \frac{10 \pm \sqrt{100-80}}{2} = \frac{10 \pm 2\sqrt{5}}{2} = 5 \pm \sqrt{5}\]

&lt;p&gt;Since both eigenvalues are positive (\(\lambda_1 = 5 + \sqrt{5} &amp;gt; 0\) and \(\lambda_2 = 5 - \sqrt{5} &amp;gt; 0\)), the Hessian is positive definite, confirming that the origin is a global minimum.&lt;/p&gt;

&lt;p&gt;The condition number is \(\kappa = \frac{5 + \sqrt{5}}{5 - \sqrt{5}} \approx 4.24\), indicating reasonably good conditioning for optimization algorithms.&lt;/p&gt;

&lt;p&gt;Understanding eigenvalues and eigenvectors provides deep insights into the geometric and analytical properties of optimization problems, enabling better algorithm design and convergence analysis.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-02 Matrices and Linear Transformations</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_02_02_Matrices_and_Linear_Transformations/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_02_02_Matrices_and_Linear_Transformations</id>
   <content type="html">&lt;p&gt;This lesson covers matrices, matrix operations, and linear transformations, which are fundamental tools for representing and solving optimization problems.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;matrices-and-matrix-operations&quot;&gt;Matrices and Matrix Operations&lt;/h2&gt;

&lt;h3 id=&quot;what-is-a-matrix&quot;&gt;What is a Matrix?&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;matrix&lt;/strong&gt; is a rectangular grid of numbers arranged in rows and columns. Matrices represent data, transformations, systems of equations, and relationships between variables.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;General Form:&lt;/strong&gt;
\(\mathbf{A} = \begin{pmatrix} 
a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\
a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}
\end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This is an \(m \times n\) matrix (\(m\) rows, \(n\) columns).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}\) is a \(2 \times 3\) matrix.&lt;/p&gt;

&lt;h3 id=&quot;matrix-addition&quot;&gt;Matrix Addition&lt;/h3&gt;

&lt;p&gt;Matrices are added by summing corresponding elements. Both matrices must have the same dimensions.&lt;/p&gt;

\[\mathbf{A} + \mathbf{B} = \begin{pmatrix} a_{11} + b_{11} &amp;amp; a_{12} + b_{12} \\ a_{21} + b_{21} &amp;amp; a_{22} + b_{22} \end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 1 &amp;amp; 2 \\ 3 &amp;amp; 4 \end{pmatrix} + \begin{pmatrix} 5 &amp;amp; 6 \\ 7 &amp;amp; 8 \end{pmatrix} = \begin{pmatrix} 6 &amp;amp; 8 \\ 10 &amp;amp; 12 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;scalar-multiplication&quot;&gt;Scalar Multiplication&lt;/h3&gt;

&lt;p&gt;Multiply every element of the matrix by the scalar:&lt;/p&gt;

\[c\mathbf{A} = \begin{pmatrix} ca_{11} &amp;amp; ca_{12} \\ ca_{21} &amp;amp; ca_{22} \end{pmatrix}\]

&lt;h3 id=&quot;matrix-multiplication&quot;&gt;Matrix Multiplication&lt;/h3&gt;

&lt;p&gt;For matrices \(\mathbf{A}_{m \times n}\) and \(\mathbf{B}_{n \times p}\), the product \(\mathbf{C}_{m \times p}\) is formed by taking the dot product of rows from \(\mathbf{A}\) and columns from \(\mathbf{B}\):&lt;/p&gt;

\[c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 1 &amp;amp; 2 \\ 3 &amp;amp; 4 \end{pmatrix} \begin{pmatrix} 5 &amp;amp; 6 \\ 7 &amp;amp; 8 \end{pmatrix} = \begin{pmatrix} 1 \cdot 5 + 2 \cdot 7 &amp;amp; 1 \cdot 6 + 2 \cdot 8 \\ 3 \cdot 5 + 4 \cdot 7 &amp;amp; 3 \cdot 6 + 4 \cdot 8 \end{pmatrix} = \begin{pmatrix} 19 &amp;amp; 22 \\ 43 &amp;amp; 50 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Matrix multiplication is &lt;strong&gt;not commutative&lt;/strong&gt;: \(\mathbf{AB} \neq \mathbf{BA}\) in general.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;linear-transformations&quot;&gt;Linear Transformations&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;linear transformation&lt;/strong&gt; is a function \(T: \mathbb{R}^n \to \mathbb{R}^m\) that preserves vector addition and scalar multiplication. Every linear transformation can be represented by a matrix.&lt;/p&gt;

&lt;h3 id=&quot;definition&quot;&gt;Definition&lt;/h3&gt;

&lt;p&gt;A transformation \(T(\mathbf{v}) = \mathbf{Av}\) is linear if and only if:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Additivity:&lt;/strong&gt; \(T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Homogeneity:&lt;/strong&gt; \(T(c\mathbf{v}) = cT(\mathbf{v})\)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These can be combined into: \(T(c_1\mathbf{u} + c_2\mathbf{v}) = c_1T(\mathbf{u}) + c_2T(\mathbf{v})\)&lt;/p&gt;

&lt;h3 id=&quot;matrix-vector-multiplication&quot;&gt;Matrix-Vector Multiplication&lt;/h3&gt;

&lt;p&gt;If \(\mathbf{A}\) is an \(m \times n\) matrix and \(\mathbf{v}\) is an \(n \times 1\) column vector, their product \(\mathbf{Av}\) is an \(m \times 1\) column vector:&lt;/p&gt;

\[\mathbf{w} = \mathbf{Av} = \begin{pmatrix} 
a_{11}v_1 + a_{12}v_2 + \cdots + a_{1n}v_n \\
a_{21}v_1 + a_{22}v_2 + \cdots + a_{2n}v_n \\
\vdots \\
a_{m1}v_1 + a_{m2}v_2 + \cdots + a_{mn}v_n
\end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 2 &amp;amp; 1 \\ 0 &amp;amp; 3 \end{pmatrix} \begin{pmatrix} 4 \\ 5 \end{pmatrix} = \begin{pmatrix} 2 \cdot 4 + 1 \cdot 5 \\ 0 \cdot 4 + 3 \cdot 5 \end{pmatrix} = \begin{pmatrix} 13 \\ 15 \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;common-2d-transformations&quot;&gt;Common 2D Transformations&lt;/h2&gt;

&lt;p&gt;Understanding geometric transformations helps visualize how matrices affect vectors.&lt;/p&gt;

&lt;h3 id=&quot;scaling&quot;&gt;Scaling&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Scaling Matrix:&lt;/strong&gt;
\(\mathbf{S} = \begin{pmatrix} s_x &amp;amp; 0 \\ 0 &amp;amp; s_y \end{pmatrix}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scales x-coordinates by \(s_x\) and y-coordinates by \(s_y\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt; \(\begin{pmatrix} 2 &amp;amp; 0 \\ 0 &amp;amp; 3 \end{pmatrix}\) doubles x-values and triples y-values&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rotation&quot;&gt;Rotation&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Rotation Matrix (counter-clockwise by angle \(\theta\)):&lt;/strong&gt;
\(\mathbf{R} = \begin{pmatrix} \cos\theta &amp;amp; -\sin\theta \\ \sin\theta &amp;amp; \cos\theta \end{pmatrix}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt; 90° rotation: \(\begin{pmatrix} 0 &amp;amp; -1 \\ 1 &amp;amp; 0 \end{pmatrix}\)&lt;/li&gt;
  &lt;li&gt;Transforms \((x, y) \mapsto (-y, x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reflection&quot;&gt;Reflection&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Reflection across x-axis:&lt;/strong&gt;
\(\mathbf{F}_x = \begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; -1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reflection across y-axis:&lt;/strong&gt;
\(\mathbf{F}_y = \begin{pmatrix} -1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reflection across line \(y = x\):&lt;/strong&gt;
\(\mathbf{F}_{y=x} = \begin{pmatrix} 0 &amp;amp; 1 \\ 1 &amp;amp; 0 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;shearing&quot;&gt;Shearing&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Horizontal Shear:&lt;/strong&gt;
\(\mathbf{H} = \begin{pmatrix} 1 &amp;amp; k \\ 0 &amp;amp; 1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;Transforms \((x, y) \mapsto (x + ky, y)\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;special-types-of-matrices&quot;&gt;Special Types of Matrices&lt;/h2&gt;

&lt;h3 id=&quot;identity-matrix&quot;&gt;Identity Matrix&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;identity matrix&lt;/strong&gt; \(\mathbf{I}\) acts like the number 1 for matrix multiplication:&lt;/p&gt;

\[\mathbf{I}_n = \begin{pmatrix} 
1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 0 \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 1
\end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Property:&lt;/strong&gt; \(\mathbf{AI} = \mathbf{IA} = \mathbf{A}\) for any compatible matrix \(\mathbf{A}\).&lt;/p&gt;

&lt;h3 id=&quot;transpose&quot;&gt;Transpose&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;transpose&lt;/strong&gt; \(\mathbf{A}^T\) flips a matrix across its main diagonal:&lt;/p&gt;

\[\text{If } \mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}, \text{ then } \mathbf{A}^T = \begin{pmatrix} 1 &amp;amp; 4 \\ 2 &amp;amp; 5 \\ 3 &amp;amp; 6 \end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(\mathbf{A}^T)^T = \mathbf{A}\]
  &lt;/li&gt;
  &lt;li&gt;
\[(\mathbf{A} + \mathbf{B})^T = \mathbf{A}^T + \mathbf{B}^T\]
  &lt;/li&gt;
  &lt;li&gt;
\[(\mathbf{AB})^T = \mathbf{B}^T\mathbf{A}^T\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;symmetric-matrices&quot;&gt;Symmetric Matrices&lt;/h3&gt;

&lt;p&gt;A matrix is &lt;strong&gt;symmetric&lt;/strong&gt; if \(\mathbf{A} = \mathbf{A}^T\):&lt;/p&gt;

\[\mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 2 &amp;amp; 4 &amp;amp; 5 \\ 3 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}\]

&lt;p&gt;Symmetric matrices have special properties important in optimization.&lt;/p&gt;

&lt;h3 id=&quot;inverse-matrix&quot;&gt;Inverse Matrix&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;inverse&lt;/strong&gt; \(\mathbf{A}^{-1}\) of a square matrix \(\mathbf{A}\) satisfies:&lt;/p&gt;

\[\mathbf{A}\mathbf{A}^{-1} = \mathbf{A}^{-1}\mathbf{A} = \mathbf{I}\]

&lt;p&gt;&lt;strong&gt;For 2×2 matrices:&lt;/strong&gt;
\(\mathbf{A}^{-1} = \frac{1}{\det(\mathbf{A})} \begin{pmatrix} d &amp;amp; -b \\ -c &amp;amp; a \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;where \(\mathbf{A} = \begin{pmatrix} a &amp;amp; b \\ c &amp;amp; d \end{pmatrix}\) and \(\det(\mathbf{A}) = ad - bc\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Not all matrices have inverses. A matrix is &lt;strong&gt;invertible&lt;/strong&gt; (non-singular) if and only if its determinant is non-zero.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;p&gt;Matrices and linear transformations are fundamental in optimization for several reasons:&lt;/p&gt;

&lt;h3 id=&quot;1-system-of-linear-equations&quot;&gt;1. System of Linear Equations&lt;/h3&gt;

&lt;p&gt;Many optimization problems involve solving \(\mathbf{Ax} = \mathbf{b}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Unique solution:&lt;/strong&gt; \(\mathbf{x} = \mathbf{A}^{-1}\mathbf{b}\) (when \(\mathbf{A}\) is invertible)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Least squares:&lt;/strong&gt; Minimize \(\|\mathbf{Ax} - \mathbf{b}\|^2\) when no exact solution exists&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-quadratic-forms&quot;&gt;2. Quadratic Forms&lt;/h3&gt;

&lt;p&gt;Quadratic functions appear frequently in optimization:
\(f(\mathbf{x}) = \mathbf{x}^T\mathbf{Q}\mathbf{x} + \mathbf{c}^T\mathbf{x} + d\)&lt;/p&gt;

&lt;p&gt;The matrix \(\mathbf{Q}\) determines the curvature properties of the function.&lt;/p&gt;

&lt;h3 id=&quot;3-linear-programming&quot;&gt;3. Linear Programming&lt;/h3&gt;

&lt;p&gt;Standard form: Minimize \(\mathbf{c}^T\mathbf{x}\) subject to \(\mathbf{Ax} = \mathbf{b}\), \(\mathbf{x} \geq \mathbf{0}\)&lt;/p&gt;

&lt;h3 id=&quot;4-constraint-representation&quot;&gt;4. Constraint Representation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Equality constraints:&lt;/strong&gt; \(\mathbf{Ax} = \mathbf{b}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Inequality constraints:&lt;/strong&gt; \(\mathbf{Ax} \leq \mathbf{b}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-transformations-of-variables&quot;&gt;5. Transformations of Variables&lt;/h3&gt;

&lt;p&gt;Change of variables: \(\mathbf{y} = \mathbf{T}\mathbf{x}\) can simplify optimization problems.&lt;/p&gt;

&lt;h3 id=&quot;example-portfolio-optimization&quot;&gt;Example: Portfolio Optimization&lt;/h3&gt;

&lt;p&gt;In finance, we might minimize portfolio risk:
\(\text{minimize } \mathbf{w}^T\mathbf{\Sigma}\mathbf{w}\)&lt;/p&gt;

&lt;p&gt;where \(\mathbf{w}\) is the vector of portfolio weights and \(\mathbf{\Sigma}\) is the covariance matrix of asset returns.&lt;/p&gt;

&lt;p&gt;Understanding matrices and linear transformations provides the tools to formulate, analyze, and solve a wide variety of optimization problems efficiently.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-01 Vectors and Vector Spaces</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_02_01_Vectors_and_Vector_Spaces/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_02_01_Vectors_and_Vector_Spaces</id>
   <content type="html">&lt;p&gt;This lesson introduces vectors, vector spaces, and fundamental concepts that form the foundation for understanding linear algebra in optimization contexts.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;vectors-and-vector-spaces-mathbbrn&quot;&gt;Vectors and Vector Spaces (\(\mathbb{R}^n\))&lt;/h2&gt;

&lt;h3 id=&quot;what-is-a-vector&quot;&gt;What is a Vector?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vectors:&lt;/strong&gt; Think of a vector as an arrow in space, representing both a direction and a magnitude (length). Mathematically, it’s an ordered list of numbers, like coordinates. For example, a vector in 2D space could be \(\mathbf{v} = \begin{pmatrix} 3 \\ 4 \end{pmatrix}\), meaning 3 units along the x-axis and 4 units along the y-axis.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Geometric vs Algebraic View:&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Geometric:&lt;/strong&gt; Vectors are arrows with direction and magnitude&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Algebraic:&lt;/strong&gt; Vectors are ordered lists of real numbers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vector-spaces&quot;&gt;Vector Spaces&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vector Space (\(\mathbb{R}^n\)):&lt;/strong&gt; This is the collection of all possible vectors that have \(n\) components (numbers). For instance, \(\mathbb{R}^2\) includes all 2-component vectors, representing all points or arrows in a 2D plane.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;\(\mathbb{R}^2 = \left\{\begin{pmatrix} x \\ y \end{pmatrix} : x, y \in \mathbb{R}\right\}\) (the plane)&lt;/li&gt;
      &lt;li&gt;\(\mathbb{R}^3 = \left\{\begin{pmatrix} x \\ y \\ z \end{pmatrix} : x, y, z \in \mathbb{R}\right\}\) (3D space)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vector-operations&quot;&gt;Vector Operations&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Vector Addition:&lt;/strong&gt;
\(\mathbf{u} + \mathbf{v} = \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_n \end{pmatrix} + \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} = \begin{pmatrix} u_1 + v_1 \\ u_2 + v_2 \\ \vdots \\ u_n + v_n \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Scalar Multiplication:&lt;/strong&gt;
\(c\mathbf{v} = c \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} = \begin{pmatrix} cv_1 \\ cv_2 \\ \vdots \\ cv_n \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;linear-independence-basis-and-dimension&quot;&gt;Linear Independence, Basis, and Dimension&lt;/h2&gt;

&lt;h3 id=&quot;linear-independence&quot;&gt;Linear Independence&lt;/h3&gt;

&lt;p&gt;A set of vectors \(\{\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_k\}\) is &lt;strong&gt;linearly independent&lt;/strong&gt; if the only solution to:&lt;/p&gt;

\[c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + \cdots + c_k\mathbf{v}_k = \mathbf{0}\]

&lt;p&gt;is \(c_1 = c_2 = \cdots = c_k = 0\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Intuitive Understanding:&lt;/strong&gt; A set of vectors is “linearly independent” if no vector in the set can be created by scaling and adding the other vectors in the set. They all point in “different enough” directions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example in \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) and \(\mathbf{v}_2 = \begin{pmatrix} 0 \\ 1 \end{pmatrix}\) are linearly independent&lt;/li&gt;
  &lt;li&gt;\(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 2 \end{pmatrix}\) and \(\mathbf{v}_2 = \begin{pmatrix} 2 \\ 4 \end{pmatrix}\) are linearly dependent (since \(\mathbf{v}_2 = 2\mathbf{v}_1\))&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;basis&quot;&gt;Basis&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;basis&lt;/strong&gt; for a vector space is a minimal set of linearly independent vectors that can be combined (scaled and added) to create &lt;em&gt;any&lt;/em&gt; other vector in that space. It’s like a fundamental set of building blocks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties of a Basis:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The vectors are linearly independent&lt;/li&gt;
  &lt;li&gt;They span the entire vector space&lt;/li&gt;
  &lt;li&gt;Every vector in the space can be written uniquely as a linear combination of basis vectors&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Standard Basis for \(\mathbb{R}^n\):&lt;/strong&gt;
\(\mathbf{e}_1 = \begin{pmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{pmatrix}, \mathbf{e}_2 = \begin{pmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{pmatrix}, \ldots, \mathbf{e}_n = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 1 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;dimension&quot;&gt;Dimension&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;dimension&lt;/strong&gt; of a vector space is simply the number of vectors in any of its bases. It tells you how many independent directions are needed to describe the space.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^2) = 2\]
  &lt;/li&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^3) = 3\]
  &lt;/li&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^n) = n\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;norms-of-vectors&quot;&gt;Norms of Vectors&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;norm&lt;/strong&gt; is a function that assigns a “length” or “size” to a vector. It generalizes the concept of distance from the origin.&lt;/p&gt;

&lt;h3 id=&quot;properties-of-norms&quot;&gt;Properties of Norms&lt;/h3&gt;

&lt;p&gt;Any norm \(\|\cdot\|\) must satisfy three properties:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Non-negativity:&lt;/strong&gt; \(\|\mathbf{x}\| \geq 0\), and \(\|\mathbf{x}\| = 0\) if and only if \(\mathbf{x} = \mathbf{0}\)&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Homogeneity:&lt;/strong&gt; $$|t\mathbf{x}| =&lt;/td&gt;
          &lt;td&gt;t&lt;/td&gt;
          &lt;td&gt;|\mathbf{x}|\(for any scalar\)t$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Triangle Inequality:&lt;/strong&gt; \(\|\mathbf{x} + \mathbf{y}\| \leq \|\mathbf{x}\| + \|\mathbf{y}\|\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;common-norms&quot;&gt;Common Norms&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Euclidean Norm (L2 Norm):&lt;/strong&gt;
\(\|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^n x_i^2} = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}\)&lt;/p&gt;

&lt;p&gt;This is the “ordinary” distance we’re familiar with.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Manhattan Norm (L1 Norm):&lt;/strong&gt;
\(\|\mathbf{x}\|_1 = \sum_{i=1}^n |x_i| = |x_1| + |x_2| + \cdots + |x_n|\)&lt;/p&gt;

&lt;p&gt;Also called “taxicab norm” - the distance a taxi would travel in a city with a grid layout.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Maximum Norm (L∞ Norm):&lt;/strong&gt;
\(\|\mathbf{x}\|_\infty = \max_{i} |x_i|\)&lt;/p&gt;

&lt;p&gt;The largest component in absolute value.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; For \(\mathbf{x} = \begin{pmatrix} 3 \\ -4 \\ 1 \end{pmatrix}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_2 = \sqrt{3^2 + (-4)^2 + 1^2} = \sqrt{26} \approx 5.1\]
  &lt;/li&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_1 = |3| + |-4| + |1| = 8\]
  &lt;/li&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_\infty = \max\{|3|, |-4|, |1|\} = 4\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;inner-products-dot-product&quot;&gt;Inner Products (Dot Product)&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;dot product&lt;/strong&gt; (or inner product) is the most common way to multiply two vectors, producing a scalar result.&lt;/p&gt;

&lt;h3 id=&quot;definition&quot;&gt;Definition&lt;/h3&gt;

&lt;p&gt;For two vectors \(\mathbf{x}\) and \(\mathbf{y}\) in \(\mathbb{R}^n\):&lt;/p&gt;

\[\mathbf{x}^T \mathbf{y} = \mathbf{x} \cdot \mathbf{y} = \sum_{i=1}^n x_i y_i = x_1 y_1 + x_2 y_2 + \cdots + x_n y_n\]

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

\[\mathbf{x} \cdot \mathbf{y} = \|\mathbf{x}\| \|\mathbf{y}\| \cos \theta\]

&lt;p&gt;where \(\theta\) is the angle between the vectors.&lt;/p&gt;

&lt;h3 id=&quot;properties&quot;&gt;Properties&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Commutative:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = \mathbf{y} \cdot \mathbf{x}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Distributive:&lt;/strong&gt; \(\mathbf{x} \cdot (\mathbf{y} + \mathbf{z}) = \mathbf{x} \cdot \mathbf{y} + \mathbf{x} \cdot \mathbf{z}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Homogeneous:&lt;/strong&gt; \((c\mathbf{x}) \cdot \mathbf{y} = c(\mathbf{x} \cdot \mathbf{y})\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;special-cases&quot;&gt;Special Cases&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Orthogonal vectors:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = 0\) (perpendicular)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parallel vectors:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = \pm \|\mathbf{x}\| \|\mathbf{y}\|\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Self dot product:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{x} = \|\mathbf{x}\|_2^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example&quot;&gt;Example&lt;/h3&gt;

&lt;p&gt;For \(\mathbf{x} = \begin{pmatrix} 1 \\ 2 \end{pmatrix}\) and \(\mathbf{y} = \begin{pmatrix} 3 \\ 4 \end{pmatrix}\):&lt;/p&gt;

\[\mathbf{x}^T \mathbf{y} = (1)(3) + (2)(4) = 3 + 8 = 11\]

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;p&gt;Understanding vectors and vector spaces is crucial for optimization because:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Decision Variables:&lt;/strong&gt; Optimization problems often involve finding the best values for multiple variables, naturally represented as vectors.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gradients:&lt;/strong&gt; The gradient of a function is a vector pointing in the direction of steepest increase.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Constraints:&lt;/strong&gt; Linear constraints in optimization can be expressed using dot products: \(\mathbf{a}^T \mathbf{x} \leq b\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Distance and Similarity:&lt;/strong&gt; Different norms provide different ways to measure distances between solutions or the size of changes.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Orthogonality:&lt;/strong&gt; Many optimization concepts rely on perpendicularity, such as the relationship between gradients and level curves.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Linear Combinations:&lt;/strong&gt; Feasible regions are often defined as linear combinations of vectors (convex hulls, cones, etc.).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The vector space framework provides the mathematical foundation for formulating and solving optimization problems systematically.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01 Calculus</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_01_Calculus/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_01_Calculus</id>
   <content type="html">&lt;p&gt;This lesson covers essential calculus concepts needed for optimization, organized into four main sections for better understanding.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-04 Taylor Series</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_01_04_Taylor_Series/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_01_04_Taylor_Series</id>
   <content type="html">&lt;p&gt;This lesson covers Taylor series expansions, which are fundamental for approximating functions and understanding the local behavior of functions in optimization algorithms.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;taylor-series-definition&quot;&gt;Taylor Series Definition&lt;/h2&gt;

&lt;p&gt;The Taylor series is a representation of a function as an infinite sum of terms calculated from the values of the function’s derivatives at a single point. It provides a way to approximate complex functions using polynomials.&lt;/p&gt;

&lt;h3 id=&quot;single-variable-taylor-series&quot;&gt;Single Variable Taylor Series&lt;/h3&gt;

&lt;p&gt;A Taylor series is a series expansion of a function \(f(x)\) about a point \(a\):&lt;/p&gt;

\[f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n\]

&lt;p&gt;In expanded form:&lt;/p&gt;

\[f(x) = f(a) + \frac{f&apos;(a)}{1!}(x-a) + \frac{f&apos;&apos;(a)}{2!}(x-a)^2 + \frac{f&apos;&apos;&apos;(a)}{3!}(x-a)^3 + \dots\]

&lt;h3 id=&quot;maclaurin-series&quot;&gt;Maclaurin Series&lt;/h3&gt;

&lt;p&gt;When the expansion is around \(a = 0\), the Taylor series is called a &lt;strong&gt;Maclaurin series&lt;/strong&gt;:&lt;/p&gt;

\[f(x) = f(0) + f&apos;(0)x + \frac{f&apos;&apos;(0)}{2!}x^2 + \frac{f&apos;&apos;&apos;(0)}{3!}x^3 + \dots\]

&lt;h3 id=&quot;common-maclaurin-series&quot;&gt;Common Maclaurin Series&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Exponential Function:&lt;/strong&gt;
\(e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!} + \dots = \sum_{n=0}^{\infty} \frac{x^n}{n!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sine Function:&lt;/strong&gt;
\(\sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \dots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{(2n+1)!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cosine Function:&lt;/strong&gt;
\(\cos x = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \dots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{(2n)!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Natural Logarithm (for \(|x| &amp;lt; 1\)):&lt;/strong&gt;
\(\ln(1 + x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \dots = \sum_{n=1}^{\infty} \frac{(-1)^{n+1} x^n}{n}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;multivariable-taylor-series&quot;&gt;Multivariable Taylor Series&lt;/h2&gt;

&lt;p&gt;For functions of multiple variables, Taylor series become more complex but follow similar principles. The expansion around a point \(\mathbf{x}_0\) involves partial derivatives.&lt;/p&gt;

&lt;h3 id=&quot;first-order-taylor-expansion&quot;&gt;First-Order Taylor Expansion&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;linear approximation&lt;/strong&gt; of \(f(\mathbf{x})\) around \(\mathbf{x}_0\):&lt;/p&gt;

\[f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0)\]

&lt;p&gt;This is the equation of the tangent plane to the function at \(\mathbf{x}_0\).&lt;/p&gt;

&lt;h3 id=&quot;second-order-taylor-expansion&quot;&gt;Second-Order Taylor Expansion&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;quadratic approximation&lt;/strong&gt; includes curvature information:&lt;/p&gt;

\[f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \nabla^2 f(\mathbf{x}_0) (\mathbf{x} - \mathbf{x}_0)\]

&lt;p&gt;where \(\nabla^2 f(\mathbf{x}_0)\) is the Hessian matrix at \(\mathbf{x}_0\).&lt;/p&gt;

&lt;h3 id=&quot;general-form&quot;&gt;General Form&lt;/h3&gt;

&lt;p&gt;The complete multivariable Taylor series involves higher-order tensors:&lt;/p&gt;

\[f(\mathbf{x}) = \sum_{|\alpha|=0}^{\infty} \frac{D^{\alpha} f(\mathbf{x}_0)}{\alpha!} (\mathbf{x} - \mathbf{x}_0)^{\alpha}\]

&lt;p&gt;where \(\alpha = (\alpha_1, \alpha_2, \ldots, \alpha_n)\) is a multi-index.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h2&gt;

&lt;p&gt;Taylor series are fundamental to optimization theory and algorithms for several reasons:&lt;/p&gt;

&lt;h3 id=&quot;1-local-function-approximation&quot;&gt;1. Local Function Approximation&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Linear Approximation (First-Order Methods):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Used in gradient descent algorithms&lt;/li&gt;
  &lt;li&gt;Assumes the function is approximately linear in a small neighborhood&lt;/li&gt;
  &lt;li&gt;Step size must be small enough for the approximation to be valid&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Quadratic Approximation (Second-Order Methods):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Used in Newton’s method and quasi-Newton methods&lt;/li&gt;
  &lt;li&gt;Captures curvature information through the Hessian&lt;/li&gt;
  &lt;li&gt;Often provides faster convergence than first-order methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-optimality-conditions&quot;&gt;2. Optimality Conditions&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;First-Order Necessary Condition:&lt;/strong&gt;
At a local minimum \(\mathbf{x}^*\), we must have \(\nabla f(\mathbf{x}^*) = \mathbf{0}\).&lt;/p&gt;

&lt;p&gt;This comes from the first-order Taylor expansion: if \(\nabla f(\mathbf{x}^*) \neq \mathbf{0}\), we could move in the direction \(-\nabla f(\mathbf{x}^*)\) to decrease the function value.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Second-Order Sufficient Condition:&lt;/strong&gt;
If \(\nabla f(\mathbf{x}^*) = \mathbf{0}\) and \(\nabla^2 f(\mathbf{x}^*)\) is positive definite, then \(\mathbf{x}^*\) is a local minimum.&lt;/p&gt;

&lt;p&gt;This follows from the second-order Taylor expansion: the quadratic term dominates near \(\mathbf{x}^*\).&lt;/p&gt;

&lt;h3 id=&quot;3-algorithm-design&quot;&gt;3. Algorithm Design&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Newton’s Method:&lt;/strong&gt;
Uses the second-order Taylor approximation to find the minimum of the quadratic model:&lt;/p&gt;

\[\mathbf{x}_{k+1} = \mathbf{x}_k - [\nabla^2 f(\mathbf{x}_k)]^{-1} \nabla f(\mathbf{x}_k)\]

&lt;p&gt;&lt;strong&gt;Trust Region Methods:&lt;/strong&gt;
Use Taylor approximations within a trusted region where the approximation is believed to be accurate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Line Search Methods:&lt;/strong&gt;
Use Taylor expansions to determine appropriate step sizes along search directions.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;example-quadratic-function-analysis&quot;&gt;Example: Quadratic Function Analysis&lt;/h2&gt;

&lt;p&gt;Consider \(f(x, y) = x^2 + 2xy + 3y^2\) around the point \((0, 0)\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient:&lt;/strong&gt;
\(\nabla f = \begin{pmatrix} 2x + 2y \\ 2x + 6y \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;At \((0, 0)\): \(\nabla f(0, 0) = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hessian:&lt;/strong&gt;
\(\nabla^2 f = \begin{pmatrix} 2 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Second-Order Taylor Expansion around \((0, 0)\):&lt;/strong&gt;
\(f(x, y) \approx f(0, 0) + 0 + \frac{1}{2} \begin{pmatrix} x &amp;amp; y \end{pmatrix} \begin{pmatrix} 2 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}\)&lt;/p&gt;

\[= 0 + \frac{1}{2}(2x^2 + 4xy + 6y^2) = x^2 + 2xy + 3y^2\]

&lt;p&gt;In this case, the function is exactly quadratic, so the second-order Taylor expansion is exact.&lt;/p&gt;

&lt;p&gt;Since the Hessian has eigenvalues \(\lambda_1 = 2 + 2\sqrt{2} &amp;gt; 0\) and \(\lambda_2 = 2 - 2\sqrt{2} &amp;lt; 0\), the point \((0, 0)\) is a saddle point, not a minimum.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;practical-considerations&quot;&gt;Practical Considerations&lt;/h2&gt;

&lt;h3 id=&quot;convergence-and-accuracy&quot;&gt;Convergence and Accuracy&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Radius of Convergence&lt;/strong&gt;: Taylor series only converge within a certain radius from the expansion point&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Truncation Error&lt;/strong&gt;: Using finite terms introduces approximation errors&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Computational Cost&lt;/strong&gt;: Higher-order terms require more derivative computations&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;optimization-algorithm-choice&quot;&gt;Optimization Algorithm Choice&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;First-order methods&lt;/strong&gt; (gradient descent): Use only gradient information, slower but cheaper per iteration&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second-order methods&lt;/strong&gt; (Newton): Use Hessian information, faster convergence but expensive per iteration&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Quasi-Newton methods&lt;/strong&gt;: Approximate the Hessian, balancing speed and computational cost&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Taylor series expansion helps us approximate complex functions with simpler polynomial functions around a specific point, which is vital for optimization algorithms and understanding local behavior of functions.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-03 Gradient and Directional Derivatives</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_01_03_Gradient_and_Directional_Derivatives/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_01_03_Gradient_and_Directional_Derivatives</id>
   <content type="html">&lt;p&gt;This lesson explores the gradient vector and directional derivatives, which are central concepts in optimization for understanding how functions change in different directions.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;gradient-vector&quot;&gt;Gradient Vector&lt;/h2&gt;

&lt;p&gt;The gradient \(\nabla f\) is a vector composed of the partial derivatives of the function \(f\) with respect to each of its variables. It indicates the direction of the steepest ascent of the function at a given point.&lt;/p&gt;

&lt;h3 id=&quot;definition-and-computation&quot;&gt;Definition and Computation&lt;/h3&gt;

&lt;p&gt;For a function of two variables, \(f(x, y)\), its gradient is:&lt;/p&gt;

\[\nabla f = \begin{pmatrix} \frac{\partial f}{\partial x} \\ \frac{\partial f}{\partial y} \end{pmatrix}\]

&lt;p&gt;For a function of \(n\) variables, \(f(x_1, x_2, \ldots, x_n)\):&lt;/p&gt;

\[\nabla f = \begin{pmatrix} \frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{pmatrix}\]

&lt;h3 id=&quot;example-computing-a-gradient&quot;&gt;Example: Computing a Gradient&lt;/h3&gt;

&lt;p&gt;For \(f(x, y) = x^2 + 3xy + y^2\):&lt;/p&gt;

&lt;p&gt;\(\frac{\partial f}{\partial x} = 2x + 3y\)
\(\frac{\partial f}{\partial y} = 3x + 2y\)&lt;/p&gt;

&lt;p&gt;Therefore: \(\nabla f = \begin{pmatrix} 2x + 3y \\ 3x + 2y \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;At the point \((1, 2)\): \(\nabla f(1, 2) = \begin{pmatrix} 2(1) + 3(2) \\ 3(1) + 2(2) \end{pmatrix} = \begin{pmatrix} 8 \\ 7 \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;directional-derivatives&quot;&gt;Directional Derivatives&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;directional derivative&lt;/strong&gt; measures the rate of change of \(f\) when we move in any chosen direction \(\mathbf{u}\). Here \(\mathbf{u}\) must be a unit vector (length 1).&lt;/p&gt;

&lt;h3 id=&quot;definition&quot;&gt;Definition&lt;/h3&gt;

&lt;p&gt;For a function \(f(\mathbf{x})\) and unit vector \(\mathbf{u} = \langle u_1, u_2, \ldots, u_n \rangle\):&lt;/p&gt;

\[D_{\mathbf{u}}f(\mathbf{x}) = \nabla f(\mathbf{x}) \cdot \mathbf{u} = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} u_i\]

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

&lt;p&gt;The directional derivative can be written as:&lt;/p&gt;

\[D_{\mathbf{u}}f = \lvert \nabla f \rvert \cos \theta\]

&lt;p&gt;where \(\theta\) is the angle between \(\nabla f\) and \(\mathbf{u}\), and \(\lvert \nabla f \rvert\) is the magnitude of the gradient.&lt;/p&gt;

&lt;h3 id=&quot;example-computing-directional-derivatives&quot;&gt;Example: Computing Directional Derivatives&lt;/h3&gt;

&lt;p&gt;Using our previous example \(f(x, y) = x^2 + 3xy + y^2\) at point \((1, 2)\) where \(\nabla f(1, 2) = \begin{pmatrix} 8 \\ 7 \end{pmatrix}\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Direction 1:&lt;/strong&gt; \(\mathbf{u}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) (positive x-direction)
\(D_{\mathbf{u}_1}f(1, 2) = 8 \cdot 1 + 7 \cdot 0 = 8\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Direction 2:&lt;/strong&gt; \(\mathbf{u}_2 = \begin{pmatrix} 0 \\ 1 \end{pmatrix}\) (positive y-direction)
\(D_{\mathbf{u}_2}f(1, 2) = 8 \cdot 0 + 7 \cdot 1 = 7\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Direction 3:&lt;/strong&gt; \(\mathbf{u}_3 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1 \end{pmatrix}\) (45° diagonal)
\(D_{\mathbf{u}_3}f(1, 2) = 8 \cdot \frac{1}{\sqrt{2}} + 7 \cdot \frac{1}{\sqrt{2}} = \frac{15}{\sqrt{2}} \approx 10.61\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;maximum-and-minimum-rates-of-change&quot;&gt;Maximum and Minimum Rates of Change&lt;/h2&gt;

&lt;h3 id=&quot;key-properties&quot;&gt;Key Properties&lt;/h3&gt;

&lt;p&gt;From the formula \(D_{\mathbf{u}}f = \lvert \nabla f \rvert \cos \theta\), we can determine:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Maximum Rate of Change&lt;/strong&gt;: Occurs when \(\cos \theta = 1\) (i.e., \(\theta = 0°\))
    &lt;ul&gt;
      &lt;li&gt;Direction: \(\mathbf{u} = \frac{\nabla f}{\lvert \nabla f \rvert}\) (same direction as gradient)&lt;/li&gt;
      &lt;li&gt;Maximum rate: \(D_{\max}f = \lvert \nabla f \rvert\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Minimum Rate of Change&lt;/strong&gt;: Occurs when \(\cos \theta = -1\) (i.e., \(\theta = 180°\))
    &lt;ul&gt;
      &lt;li&gt;Direction: \(\mathbf{u} = -\frac{\nabla f}{\lvert \nabla f \rvert}\) (opposite to gradient)&lt;/li&gt;
      &lt;li&gt;Minimum rate: \(D_{\min}f = -\lvert \nabla f \rvert\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zero Rate of Change&lt;/strong&gt;: Occurs when \(\cos \theta = 0\) (i.e., \(\theta = 90°\))
    &lt;ul&gt;
      &lt;li&gt;Direction: Any vector perpendicular to \(\nabla f\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;summary-of-gradient-properties&quot;&gt;Summary of Gradient Properties&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The gradient \(\nabla f\) points in the direction of &lt;strong&gt;steepest increase&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;The direction \(-\nabla f\) points in the direction of &lt;strong&gt;steepest decrease&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;The magnitude \(\lvert \nabla f \rvert\) gives the &lt;strong&gt;maximum rate of change&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;When \(\nabla f = \mathbf{0}\), the point is a &lt;strong&gt;critical point&lt;/strong&gt; (potential optimum)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;relation-to-level-curves&quot;&gt;Relation to Level Curves&lt;/h2&gt;

&lt;p&gt;At any point on a level curve \(f(x, y) = c\), the gradient vector \(\nabla f\) is &lt;strong&gt;orthogonal (perpendicular)&lt;/strong&gt; to the tangent line of the level curve at that point.&lt;/p&gt;

&lt;h3 id=&quot;why-this-matters&quot;&gt;Why This Matters&lt;/h3&gt;

&lt;p&gt;This orthogonality property is fundamental because:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Level curves represent constant function values&lt;/strong&gt;: Moving along a level curve doesn’t change the function value, so the directional derivative is zero.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gradient points to steepest increase&lt;/strong&gt;: The direction that increases the function value most rapidly must be perpendicular to the direction that doesn’t change it at all.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Optimization insight&lt;/strong&gt;: To find extrema, we look for points where the gradient is zero (critical points) or where the gradient is perpendicular to the constraint boundary.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h3&gt;

&lt;p&gt;Understanding gradients and directional derivatives is crucial for:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Gradient Descent&lt;/strong&gt;: Moving in the direction \(-\nabla f\) to minimize \(f\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Gradient Ascent&lt;/strong&gt;: Moving in the direction \(+\nabla f\) to maximize \(f\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Constrained Optimization&lt;/strong&gt;: Using the relationship between gradients and level curves&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Convergence Analysis&lt;/strong&gt;: Understanding when algorithms will converge to optimal solutions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step Size Selection&lt;/strong&gt;: Determining how far to move in the gradient direction&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The gradient provides both the direction to move and information about how quickly the function is changing, making it the foundation for most optimization algorithms.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-02 Derivatives and Multivariable Calculus</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_01_02_Derivatives_and_Multivariable_Calculus/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_01_02_Derivatives_and_Multivariable_Calculus</id>
   <content type="html">&lt;p&gt;This lesson covers derivatives and essential multivariable calculus concepts that form the foundation for optimization theory and algorithms.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;derivatives-and-rate-of-change&quot;&gt;Derivatives and Rate of Change&lt;/h2&gt;

&lt;p&gt;The derivative of a single variable function represents its instantaneous rate of change, which is fundamental to understanding how functions behave locally.&lt;/p&gt;

&lt;h3 id=&quot;basic-derivative-concepts&quot;&gt;Basic Derivative Concepts&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Slope between two points:&lt;/strong&gt;&lt;/p&gt;

\[\text{Slope} = \frac{y_2 - y_1}{x_2 - x_1}\]

&lt;p&gt;&lt;strong&gt;Derivative (instantaneous rate of change):&lt;/strong&gt;&lt;/p&gt;

\[f&apos;(x_0) = \lim_{x_1 \to x_0} \frac{f(x_1) - f(x_0)}{x_1 - x_0} = \lim_{\Delta x \to 0} \frac{f(x_0 + \Delta x) - f(x_0)}{\Delta x}\]

&lt;p&gt;The derivative tells us how quickly the function is changing at any given point, which is essential for finding optimal points where the rate of change is zero.&lt;/p&gt;

&lt;h3 id=&quot;level-curves-of-functions&quot;&gt;Level Curves of Functions&lt;/h3&gt;

&lt;p&gt;Level curves are a fundamental concept in multivariable calculus used to visualize functions of two variables, typically denoted as \(f(x, y)\). They provide a way to represent a 3D surface in a 2D plane.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;level curve&lt;/strong&gt; of a function \(f(x, y)\) is the set of all points \((x, y)\) in the domain of \(f\) where the function takes a constant value:&lt;/p&gt;

\[f(x, y) = c\]

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For \(f(x, y) = x^2 + y^2\), the level curves are circles: \(x^2 + y^2 = c\)&lt;/li&gt;
  &lt;li&gt;For \(f(x, y) = x + y\), the level curves are parallel lines: \(x + y = c\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Level curves help us understand:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The topography of the function&lt;/li&gt;
  &lt;li&gt;Directions of steepest ascent and descent&lt;/li&gt;
  &lt;li&gt;Locations of potential optima&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;multivariable-calculus-key-concepts&quot;&gt;Multivariable Calculus Key Concepts&lt;/h2&gt;

&lt;h3 id=&quot;partial-derivatives&quot;&gt;Partial Derivatives&lt;/h3&gt;

&lt;p&gt;For a function \(f(x_1, x_2, \ldots, x_n)\), the &lt;strong&gt;partial derivative&lt;/strong&gt; with respect to \(x_i\) is:&lt;/p&gt;

\[\frac{\partial f}{\partial x_i} = \lim_{h \to 0} \frac{f(x_1, \ldots, x_i + h, \ldots, x_n) - f(x_1, \ldots, x_i, \ldots, x_n)}{h}\]

&lt;p&gt;This measures how \(f\) changes when only \(x_i\) varies while all other variables remain fixed.&lt;/p&gt;

&lt;h3 id=&quot;gradient-vector&quot;&gt;Gradient Vector&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;gradient&lt;/strong&gt; is a vector composed of all partial derivatives:&lt;/p&gt;

\[\nabla f(\mathbf{x}) = \begin{pmatrix} \frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{pmatrix}\]

&lt;p&gt;The gradient points in the direction of steepest increase of the function and is perpendicular to level curves.&lt;/p&gt;

&lt;h3 id=&quot;hessian-matrix&quot;&gt;Hessian Matrix&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;Hessian matrix&lt;/strong&gt; contains all second-order partial derivatives:&lt;/p&gt;

\[\nabla^2 f(\mathbf{x}) = \mathbf{H} = \begin{pmatrix} 
\frac{\partial^2 f}{\partial x_1^2} &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_2^2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_n^2}
\end{pmatrix}\]

&lt;p&gt;The Hessian provides information about the curvature of the function and is crucial for:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Determining the nature of critical points (minimum, maximum, or saddle point)&lt;/li&gt;
  &lt;li&gt;Second-order optimization methods like Newton’s method&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;chain-rule-for-multivariable-functions&quot;&gt;Chain Rule for Multivariable Functions&lt;/h2&gt;

&lt;p&gt;The chain rule is fundamental for computing derivatives of composite functions, which frequently appear in optimization problems.&lt;/p&gt;

&lt;h3 id=&quot;basic-chain-rule&quot;&gt;Basic Chain Rule&lt;/h3&gt;

&lt;p&gt;For a function \(z = f(x, y)\) where \(x = g(t)\) and \(y = h(t)\):&lt;/p&gt;

\[\frac{dz}{dt} = \frac{\partial f}{\partial x} \frac{dx}{dt} + \frac{\partial f}{\partial y} \frac{dy}{dt}\]

&lt;h3 id=&quot;general-chain-rule&quot;&gt;General Chain Rule&lt;/h3&gt;

&lt;p&gt;For \(z = f(x_1, x_2, \ldots, x_n)\) where each \(x_i = x_i(t_1, t_2, \ldots, t_m)\):&lt;/p&gt;

\[\frac{\partial z}{\partial t_j} = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} \frac{\partial x_i}{\partial t_j}\]

&lt;h3 id=&quot;applications-in-optimization&quot;&gt;Applications in Optimization&lt;/h3&gt;

&lt;p&gt;The chain rule is essential for:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Gradient Computation&lt;/strong&gt;: Computing gradients of composite objective functions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Constraint Handling&lt;/strong&gt;: Dealing with constraints that are functions of other variables&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Algorithm Implementation&lt;/strong&gt;: Backpropagation in neural networks and automatic differentiation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sensitivity Analysis&lt;/strong&gt;: Understanding how changes in parameters affect optimal solutions&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;example-optimization-with-constraints&quot;&gt;Example: Optimization with Constraints&lt;/h3&gt;

&lt;p&gt;Consider minimizing \(f(x, y) = x^2 + y^2\) subject to \(g(x, y) = x + y - 1 = 0\).&lt;/p&gt;

&lt;p&gt;Using the constraint to eliminate one variable: \(y = 1 - x\), so we minimize:
\(h(x) = f(x, 1-x) = x^2 + (1-x)^2\)&lt;/p&gt;

&lt;p&gt;Using the chain rule:
\(h&apos;(x) = \frac{\partial f}{\partial x} \cdot 1 + \frac{\partial f}{\partial y} \cdot \frac{d(1-x)}{dx} = 2x + 2(1-x)(-1) = 4x - 2\)&lt;/p&gt;

&lt;p&gt;Setting \(h&apos;(x) = 0\) gives \(x = 1/2\), so the optimal point is \((1/2, 1/2)\).&lt;/p&gt;

&lt;p&gt;This demonstrates how multivariable calculus concepts work together to solve optimization problems systematically.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-01 Continuity and Uniform Continuity</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_01_01_Continuity_and_Uniform_Continuity/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter00/00_01_01_Continuity_and_Uniform_Continuity</id>
   <content type="html">&lt;p&gt;This lesson introduces the fundamental concepts of continuity and uniform continuity, which are essential for understanding the behavior of functions in optimization.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;continuity-and-uniform-continuity&quot;&gt;Continuity and Uniform Continuity&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Continuity&lt;/strong&gt; and &lt;strong&gt;Uniform Continuity&lt;/strong&gt; are fundamental concepts that describe the behavior of functions, particularly concerning their “smoothness” or “predictability.” While closely related, they capture distinct properties, with uniform continuity being a stronger condition than mere continuity.&lt;/p&gt;

&lt;h3 id=&quot;definition-of-continuity&quot;&gt;Definition of Continuity&lt;/h3&gt;

&lt;p&gt;A function \(f: A \to \mathbb{R}\) is said to be &lt;strong&gt;continuous at a point&lt;/strong&gt; \(c \in A\) if, for every positive real number \(\varepsilon &amp;gt; 0\), there exists a positive real number \(\delta &amp;gt; 0\) such that for all \(x \in A\), if&lt;/p&gt;

\[\lvert x - c \rvert &amp;lt; \delta\]

&lt;p&gt;then&lt;/p&gt;

\[\lvert f(x) - f(c) \rvert &amp;lt; \varepsilon\]

&lt;p&gt;Intuitively, it means that for any desired level of precision \(\varepsilon\) in the output \(f(x)\), we can find a sufficiently small interval around \(c\) (of width \(2\delta\)) such that all \(x\) values within this interval map to \(f(x)\) values within an \(\varepsilon\)-interval around \(f(c)\). The crucial aspect here is that the choice of \(\delta\) generally depends not only on \(\varepsilon\) but also on the specific point \(c\).&lt;/p&gt;

&lt;p&gt;A function is &lt;strong&gt;continuous on a set&lt;/strong&gt; \(A\) if it is continuous at every point \(c \in A\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples of continuous functions&lt;/strong&gt; include all polynomials (e.g., \(f(x) = x^2 + 3x - 1\)), trigonometric functions like \(\sin(x)\) and \(\cos(x)\), and exponential functions \(e^x\) on their respective domains.&lt;/p&gt;

&lt;h3 id=&quot;definition-of-uniform-continuity&quot;&gt;Definition of Uniform Continuity&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Uniform Continuity&lt;/strong&gt;, on the other hand, imposes a more stringent condition. A function \(f: A \to \mathbb{R}\) is said to be &lt;strong&gt;uniformly continuous on a set&lt;/strong&gt; \(A\) if, for every positive real number \(\varepsilon &amp;gt; 0\), there exists a positive real number \(\delta &amp;gt; 0\) such that for all \(x, y \in A\), if&lt;/p&gt;

\[\lvert x - y \rvert &amp;lt; \delta\]

&lt;p&gt;then&lt;/p&gt;

\[\lvert f(x) - f(y) \rvert &amp;lt; \varepsilon\]

&lt;p&gt;The &lt;strong&gt;key distinction&lt;/strong&gt; from point-wise continuity lies in the order of quantifiers: for &lt;strong&gt;uniform&lt;/strong&gt; continuity, the \(\delta\) depends &lt;em&gt;only&lt;/em&gt; on \(\varepsilon\) and is independent of the specific points \(x\) and \(y\) in the domain.&lt;/p&gt;

&lt;h3 id=&quot;definition-of-lipschitz-continuity&quot;&gt;Definition of Lipschitz Continuity&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Lipschitz Continuity&lt;/strong&gt; provides an even more specific and quantitative notion of continuity. A function \(f: A \to \mathbb{R}\) is said to be &lt;strong&gt;Lipschitz continuous&lt;/strong&gt; (or &lt;strong&gt;L-Lipschitz&lt;/strong&gt;) on a set \(A\) if there exists a constant \(L \geq 0\) such that for all \(x, y \in A\):&lt;/p&gt;

\[\lvert f(x) - f(y) \rvert \leq L \lvert x - y \rvert\]

&lt;p&gt;The smallest such constant \(L\) is called the &lt;strong&gt;Lipschitz constant&lt;/strong&gt; or &lt;strong&gt;Lipschitz modulus&lt;/strong&gt; of \(f\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key Properties of Lipschitz Continuity:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Bounded Rate of Change&lt;/strong&gt;: The Lipschitz condition ensures that the function cannot change faster than a linear rate determined by \(L\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Uniform Continuity&lt;/strong&gt;: Every Lipschitz continuous function is uniformly continuous (choose \(\delta = \varepsilon/L\) for \(L &amp;gt; 0\)).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Almost Everywhere Differentiability&lt;/strong&gt;: Lipschitz continuous functions are differentiable almost everywhere, and where the derivative exists, \(\lvert f&apos;(x) \rvert \leq L\).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(f(x) = \lvert x \rvert\) is 1-Lipschitz on \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;\(f(x) = \sin(x)\) is 1-Lipschitz on \(\mathbb{R}\) (since \(\lvert \cos(x) \rvert \leq 1\))&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) is not Lipschitz on \(\mathbb{R}\) but is Lipschitz on any bounded interval&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;key-differences-and-hierarchy&quot;&gt;Key Differences and Hierarchy&lt;/h3&gt;

&lt;p&gt;The three types of continuity form a hierarchy of increasingly strong conditions:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Continuity ⊆ Uniform Continuity ⊆ Lipschitz Continuity&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Point-wise vs Global&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Continuity&lt;/strong&gt;: Local property (checked at each point)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Uniform Continuity&lt;/strong&gt;: Global property of the entire function&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Lipschitz Continuity&lt;/strong&gt;: Global property with quantitative bounds&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Choice of \(\delta\)&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Continuity&lt;/strong&gt;: \(\delta\) can depend on both \(\varepsilon\) and the specific point \(c\)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Uniform Continuity&lt;/strong&gt;: \(\delta\) depends only on \(\varepsilon\), working for all points simultaneously&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Lipschitz Continuity&lt;/strong&gt;: \(\delta = \varepsilon/L\) provides explicit relationship&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rate of Change Control&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Continuity&lt;/strong&gt;: No control over rate of change&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Uniform Continuity&lt;/strong&gt;: Ensures bounded variation over small intervals&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Lipschitz Continuity&lt;/strong&gt;: Provides explicit linear bound on rate of change&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Strength Relationships&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;Every Lipschitz continuous function is uniformly continuous&lt;/li&gt;
      &lt;li&gt;Every uniformly continuous function is continuous&lt;/li&gt;
      &lt;li&gt;The converses are not generally true&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;detailed-examples-and-comparisons&quot;&gt;Detailed Examples and Comparisons&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Example 1: \(f(x) = x^2\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;On \(\mathbb{R}\)&lt;/strong&gt;: Continuous but not uniformly continuous (rate of change \(\lvert f&apos;(x) \rvert = 2\lvert x \rvert\) is unbounded)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;On \([0,1]\)&lt;/strong&gt;: Continuous, uniformly continuous, and Lipschitz with \(L = 2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example 2: \(f(x) = \sin(x)\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;On \(\mathbb{R}\)&lt;/strong&gt;: Continuous, uniformly continuous, and 1-Lipschitz (since \(\lvert \cos(x) \rvert \leq 1\))&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example 3: \(f(x) = \lvert x \rvert\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;On \(\mathbb{R}\)&lt;/strong&gt;: Continuous, uniformly continuous, and 1-Lipschitz&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: Not differentiable at \(x = 0\), but still Lipschitz&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example 4: \(f(x) = \sqrt{x}\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;On \([0,1]\)&lt;/strong&gt;: Continuous and uniformly continuous, but not Lipschitz (derivative unbounded near \(x = 0\))&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;On \([a,1]\) for \(a &amp;gt; 0\)&lt;/strong&gt;: Lipschitz with \(L = 1/(2\sqrt{a})\)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>08-03 Cải tiến Phương pháp Subgradient</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_03_improving_on_the_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_03_improving_on_the_subgradient_method</id>
   <content type="html">&lt;p&gt;Phương pháp subgradient có lợi thế vì có thể được sử dụng cho các hàm lồi không khả vi, làm cho nó tổng quát hơn. Tuy nhiên, tốc độ hội tụ của nó là \(O(1/\epsilon^{2})\), chậm hơn nhiều so với tốc độ hội tụ của gradient descent là \(O(1/\epsilon)\).&lt;/p&gt;

&lt;p&gt;Có cách nào để kết hợp điểm mạnh của gradient descent và phương pháp subgradient không? Trong phần tiếp theo, chúng ta sẽ tìm hiểu về phương pháp proximal gradient descent, kết hợp ưu điểm của cả hai thuật toán.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-02 Phương pháp Subgradient Ngẫu nhiên</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_02_stochastic_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_02_stochastic_subgradient_method</id>
   <content type="html">&lt;p&gt;Phương pháp subgradient ngẫu nhiên tương tự như stochastic gradient descent, nhưng thay thế gradient bằng subgradient.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-02-04 So sánh Phương pháp Batch và Ngẫu nhiên</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_02_04_batch_vs_stochastic_methods/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_02_04_batch_vs_stochastic_methods</id>
   <content type="html">&lt;p&gt;Tính chất hội tụ của phương pháp batch và ngẫu nhiên như sau:&lt;/p&gt;

&lt;p&gt;Nói chung, phương pháp ngẫu nhiên tiếp cận điểm tối ưu nhanh chóng trong giai đoạn đầu, nhưng có thể không hội tụ tốt gần điểm tối ưu. Ngược lại, phương pháp batch hội tụ chậm hơn nhưng tiếp cận điểm tối ưu chính xác hơn.&lt;/p&gt;

&lt;p&gt;Hình dưới đây so sánh sự hội tụ của phương pháp batch và ngẫu nhiên cho &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_regression&quot;&gt;hồi quy logistic&lt;/a&gt; (không có regularization):&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter08/08_02_stochastic_vs_batch.png&quot; alt=&quot;stochastic_vs_batch&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 3] So sánh Batch vs Stochastic Gradient Descent [2]&lt;/figcaption&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>08-02-03 Tốc độ Hội tụ của Phương pháp Ngẫu nhiên</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_02_03_convergence_rate_of_stochastic_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_02_03_convergence_rate_of_stochastic_method</id>
   <content type="html">&lt;p&gt;Có sự khác biệt về tốc độ hội tụ giữa phương pháp tuần hoàn và phương pháp ngẫu nhiên.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/contents/vi/chapter08/08_01_04_convergence_rate/&quot;&gt;Tốc độ hội tụ&lt;/a&gt; của phương pháp subgradient batch là \(O(G_{batch}^{2}/\epsilon^{2})\), trong đó \(G_{batch}\) là hằng số Lipschitz của \(\sum f_i\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Phương pháp tuần hoàn&lt;/strong&gt;: Độ phức tạp lặp của phương pháp tuần hoàn là \(O(m^{3}G^{2}/\epsilon^{2})\). Nếu một chu kỳ của phương pháp subgradient ngẫu nhiên tuần hoàn được coi là tương đương với một phương pháp subgradient batch, thì mỗi chu kỳ cần \(O(m^{2}G^{2}/\epsilon^{2})\) lần lặp. (\(G\) là hằng số Lipschitz của một hàm đơn \(f_i\))&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Phương pháp ngẫu nhiên&lt;/strong&gt;: Độ phức tạp lặp của phương pháp ngẫu nhiên là \(O(m^{2}G^{2}/\epsilon^{2})\). Tức là, phương pháp ngẫu nhiên cần \(O(mG^{2}/\epsilon^2)\) lần lặp, nhanh hơn \(m\) lần so với phương pháp batch và tuần hoàn với \(O(m^2G^2/\epsilon^2)\). Về mặt ký hiệu Big-O, nếu \(m\) lớn, phương pháp ngẫu nhiên có tốc độ hội tụ nhanh hơn.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Mặc dù các cận Big-O cho phương pháp ngẫu nhiên và tuần hoàn khác nhau một hệ số \(m\), lưu ý rằng cận Big-O của phương pháp tuần hoàn là trường hợp xấu nhất, trong khi của phương pháp ngẫu nhiên là trường hợp trung bình. Trong thực tế, sự khác biệt có thể không lớn như ký hiệu Big-O gợi ý.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-02-02 Hội tụ của các Phương pháp Ngẫu nhiên</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_02_02_convergence_of_stochastic_methods/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_02_02_convergence_of_stochastic_methods</id>
   <content type="html">&lt;p&gt;Giả sử mỗi hàm \(f_i, i = 1,...,m\) là lồi và liên tục Lipschitz với hằng số G.&lt;/p&gt;

&lt;p&gt;Đối với phương pháp subgradient ngẫu nhiên, các tính chất sau đây đúng cho kích thước bước cố định và giảm dần:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Kích thước bước cố định&lt;/strong&gt; với \(t_k = t\), \(k = 1, 2, 3, ...\)&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\text{Đối với phương pháp tuần hoàn và ngẫu nhiên với kích thước bước cố định, điều sau đây đúng:} \\
\begin{align}
\lim_{k\to\infty} f(x_{best}^{(k)}) \le f^{*} + 5m^{2}G^{2}t/2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(mG\) là hằng số Lipschitz của \(\sum_{i=1}^{m} f_i\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Kích thước bước giảm dần&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\text{Đối với phương pháp tuần hoàn và ngẫu nhiên với kích thước bước giảm dần, điều sau đây đúng:} \\
\begin{align}
\lim_{k\to\infty} f(x_{best}^{(k)}) = f^{*}
\end{align}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>08-02-01 Phương pháp Subgradient Ngẫu nhiên</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_02_01_stochastic_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_02_01_stochastic_subgradient_method</id>
   <content type="html">&lt;p&gt;Hãy xem xét bài toán tối thiểu hóa tổng các hàm như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{equation}
\min_x \sum_{i=1}^m f_i(x)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;Nếu chúng ta áp dụng phương pháp subgradient cho bài toán này, chúng ta cần tính subgradient cho mỗi hàm \(f_i\) và cộng chúng lại. (Điều này tương tự như phương pháp được giới thiệu trong &lt;a href=&quot;/contents/vi/chapter06/06_05_stochastic_gradient_descent/&quot;&gt;stochastic gradient descent&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Tóm lại, phương pháp subgradient ngẫu nhiên có dạng như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x^{(k)} = x^{(k-1)} - t_k \cdot g_{i_k}^{(k-1)}, \quad k = 1, 2, 3, . . . 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(i_k \in \{1,...,m\}\) là chỉ số được chọn tại lần lặp thứ \(k\). Như sẽ được thảo luận trong phần tiếp theo về tốc độ hội tụ của phương pháp subgradient ngẫu nhiên, việc lựa chọn phương pháp tuần hoàn hoặc ngẫu nhiên ảnh hưởng đến kết quả. \(g_{i}^{(k-1)} \in \partial f_{i}(x^{k-1})\), và hướng cập nhật này khác với &lt;a href=&quot;/contents/vi/chapter08/08_01_subgradient_method/&quot;&gt;phương pháp subgradient&lt;/a&gt; thông thường (còn được gọi là phương pháp subgradient batch hoặc phương pháp subgradient full batch), nơi sử dụng \(\sum_{i=1}^{m} g_i^{(k-1)}\).&lt;/p&gt;

&lt;p&gt;Nếu mỗi \(f_i, i = 1,...,m\) khả vi, thuật toán này trở thành stochastic gradient descent. (Phương pháp subgradient ngẫu nhiên là một dạng tổng quát hơn)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01 Phương pháp Subgradient</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_01_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_01_subgradient_method</id>
   <content type="html">&lt;p&gt;Giả sử miền của hàm số là \({R}^n\) và có một hàm lồi \(f\) có thể không khả vi tại mọi điểm.&lt;/p&gt;

&lt;p&gt;Phương pháp subgradient được định nghĩa bằng cách thay thế gradient trong phương pháp gradient descent bằng một subgradient. (\(\nabla f(x^{(k-1)}) \to g(x^{(k-1)})\))&lt;/p&gt;

&lt;blockquote&gt;
\[x^{(k)} = x^{(k-1)} - t_k \cdot g^{(k-1)}, \quad k = 1, 2, 3, . . .\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(g^{(k-1)} \in \partial f(x^{(k-1)})\), tức là \(g^{(k-1)}\) là một subgradient của \(f\) tại \(x^{(k-1)}\).&lt;/p&gt;

&lt;h2 id=&quot;phương-pháp-subgradient-không-phải-descent-subgradient&quot;&gt;Phương pháp subgradient (không phải “descent” subgradient)&lt;/h2&gt;

&lt;p&gt;Khác với gradient descent, phương pháp subgradient không luôn đảm bảo giảm giá trị hàm số ở mỗi bước (do đó tên gọi không phải là “descent” subgradient). Vì vậy, khi sử dụng phương pháp subgradient, quan trọng là phải theo dõi kết quả tốt nhất tại mỗi lần lặp.&lt;/p&gt;

&lt;blockquote&gt;
\[f(x_{best}^{(k)}) = \min_{i=0,...k} f(x^{(i)})\]
&lt;/blockquote&gt;

&lt;p&gt;\(f(x^{(k)}_{best})\) biểu thị giá trị nhỏ nhất của hàm \(f\) thu được trong \(k\) lần lặp của phương pháp subgradient.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-08 Phương pháp Subgradient có Chiếu</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_01_08_projected_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_01_08_projected_subgradient_method</id>
   <content type="html">&lt;p&gt;Phương pháp được mô tả trong ví dụ trước được gọi là phương pháp subgradient có chiếu. Thuật toán này có thể được sử dụng cho các bài toán lồi có ràng buộc.&lt;/p&gt;

&lt;p&gt;Nếu chúng ta ký hiệu miền thỏa mãn các ràng buộc là tập \(C\), thì bài toán lồi có ràng buộc được định nghĩa như sau:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
\min_x \text{ }f(x) \quad \text{với điều kiện } x \in C
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bằng cách sử dụng phương pháp subgradient có chiếu, các bài toán như vậy có thể được giải tương đối dễ dàng. Phương pháp subgradient có chiếu tương tự như phương pháp subgradient chuẩn, nhưng ở mỗi lần lặp, kết quả được chiếu lên tập \(C\).&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
x^{(k)} = P_c(x^{(k-1)} - t_k \cdot g^{(k-1)}), \quad k = 1,2,3,...
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Nếu phép chiếu có thể thực hiện được, phương pháp này có cùng tính chất hội tụ và tốc độ như phương pháp subgradient.&lt;/p&gt;

&lt;p&gt;Một điều cần lưu ý về phương pháp subgradient có chiếu là ngay cả khi \(C\) là một tập lồi đơn giản, nếu phép toán chiếu \(P_c\) khó thực hiện, thì bài toán tổng thể cũng trở nên khó giải. Thông thường, các tập \(C\) sau đây tương đối dễ chiếu lên:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ảnh affine: {\(Ax=b : x \in \mathbb{R}^{n}\)}&lt;/li&gt;
  &lt;li&gt;Tập nghiệm của hệ tuyến tính: {\(x: Ax=b\)}&lt;/li&gt;
  &lt;li&gt;Trực giao không âm: \(\mathbb{R}_+^{n} =\){\(x: x\ge 0\)}&lt;/li&gt;
  &lt;li&gt;Một số quả cầu chuẩn: {\(x: \lVert x \rVert _p \le 1\)} với \(p=1,2,\infty\)&lt;/li&gt;
  &lt;li&gt;Một số đa diện đơn giản và hình nón đơn giản&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-07 Ví dụ: Giao của các tập hợp</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_01_07_example_intersection_of_sets/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_01_07_example_intersection_of_sets</id>
   <content type="html">&lt;p&gt;Giả sử chúng ta muốn tìm điểm giao của nhiều tập lồi đóng.&lt;/p&gt;

&lt;p&gt;Đầu tiên, hãy định nghĩa \(f_i(x)\) là khoảng cách từ điểm \(x\) đến tập \(C_i\), và \(f(x)\) là khoảng cách tối đa từ \(x\) đến tất cả các tập \(C_i, i=1,...,m\):&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
f_i(x) &amp;amp; = \mathbb{dist}(x, C_i), i=1,...,m \\
f(x) &amp;amp; = \max_{1,...,m}\text{ }f_i(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Sử dụng hai hàm này, bài toán tìm giao của các tập lồi có thể được công thức hóa thành bài toán tối thiểu hóa sau:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
min_{x}\text{ }f(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán tìm điểm giao của các tập lồi tương đương với việc tìm điểm \(x\) tối thiểu hóa khoảng cách tối đa \(f(x)\) đến các tập \(C_i\). Trong trường hợp này, hàm mục tiêu \(f(x)\) là lồi. Nếu tất cả các tập đều có điểm giao chung, thì \(f^* = 0\) và điểm tối ưu là \(x^* \in C_1 \cap C_2 \cap ... \cap C_m\).&lt;/p&gt;

&lt;h2 id=&quot;gradient-của-hàm-khoảng-cách&quot;&gt;Gradient của hàm khoảng cách&lt;/h2&gt;

&lt;p&gt;Trong &lt;a href=&quot;/contents/vi/chapter07/07_03_05_example_distance_to_convex_set/&quot;&gt;phần trước&lt;/a&gt;, chúng ta đã định nghĩa khoảng cách đến một tập lồi là \(dist(x, C_i) = \min_{y \in C} \lVert y-x \rVert _2\), và thấy rằng gradient của hàm này là:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
\partial dist(x,C) = \frac{x-P_C(x)}{ \Vert x-P_C(x) \Vert_2}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(P_C(x)\) là phép chiếu của điểm \(x\) lên tập \(C\).&lt;/p&gt;

&lt;h2 id=&quot;subdifferential-của-maximum-hữu-hạn-theo-điểm&quot;&gt;Subdifferential của maximum hữu hạn theo điểm&lt;/h2&gt;

&lt;p&gt;Subdifferential của hàm finite pointwise maximum \(f(x)=max_{i=1,...,m}\text{ }f_i(x)\) được định nghĩa như sau.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
\partial f(x) = \text{conv}\left(\bigcup_{i:f_i(x)=f(x)} \partial f_i(x)\right)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Tức là, subdifferential của \(x\) được định nghĩa là convex hull của hợp tất cả các subdifferential \(\partial f_i(x), i=1,...,m\) tại điểm đó.&lt;/p&gt;

&lt;p&gt;Nếu \(f_i(x) = f(x)\) và \(g_i \in \partial f_i(x)\) thì \(g_i \in \partial f(x)\).&lt;/p&gt;

&lt;h2 id=&quot;suy-ra-các-bước-cập-nhật-subgradient&quot;&gt;Suy ra các bước cập nhật subgradient&lt;/h2&gt;

&lt;p&gt;Trong &lt;a href=&quot;/contents/vi/chapter07/07_03_05_example_distance_to_convex_set/&quot;&gt;chương trước&lt;/a&gt;, \(dist(x, C_i)\) có subgradient như sau.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(Nhắc lại:\)
\(\begin{align}
g_i = \nabla f_i(x) = \frac{x-P_{C_i}(x)}{ \Vert x-P_{C_i}(x) \Vert_2}
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nếu có điểm giao của các tập lồi thì chúng ta có thể biết ngay rằng \(f^*=0\) nên có thể sử dụng kích thước bước Polyak. Nhìn vào công thức subgradient trên, \(x-P_{c_i}(x)\) ở dạng chuẩn hóa nên \(\Vert g \Vert_2^{2}=1\). Cuối cùng, thay các giá trị đã biết vào kích thước bước Polyak \(t_k = \{\frac{f^{(k-1)}-f^*}{ \Vert g^{(k-1)} \Vert_2^{2}}\}\), chúng ta có thể suy ra công thức phương pháp subgradient như sau.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
x^{(k)} &amp;amp; = x^{(k-1)} - t_{k}⋅g_{k-1} \\
&amp;amp; = x^{(k-1)} - \frac{f^{(k-1)}-f^*}{ \Vert g^{(k-1)} \Vert_2^{2}} \frac{x^{(k-1)}-P_{C_i}(x)}{ \Vert x^{(k-1)}-P_{C_i}(x) \Vert_2}  \\
&amp;amp; = x^{(k-1)} - f(x^{k-1}) \frac{x^{(k-1)}-P_{C_i}(x)}{ \Vert x^{(k-1)}-P_{C_i}(x) \Vert_2}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây kích thước Polyak \(f(x^{(k-1)})\) là \(dist(x_i^{(k-1)}, C_i) =  \Vert x^{(k-1)}-P_{C_i}(x) \Vert_2\) nên phương pháp subgradient được tổng kết như sau.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
x^{(k)} = P_{C_i}(x^{(k-1)})
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Bài toán này khi biểu diễn bằng hình vẽ có dạng lặp lại phép chiếu lên hàm lồi gần nhất ở mỗi bước.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter08/08_01_projection.png&quot; alt=&quot;projection&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] Alternating Projection Algorithm [10]&lt;/figcaption&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-06 Kích thước bước Polyak</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_01_06_polyak_step_sizes/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_01_06_polyak_step_sizes</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Kích thước bước Polyak&lt;/strong&gt; là một cách để thiết lập kích thước bước khi giá trị tối ưu được biết. Nếu \(f^*\) được biết, kích thước bước Polyak có thể được định nghĩa như sau.&lt;/p&gt;

&lt;h2 id=&quot;định-lý-hội-tụ-cho-kích-thước-bước-polyak&quot;&gt;Định lý hội tụ cho kích thước bước Polyak&lt;/h2&gt;
&lt;blockquote&gt;

\[\begin{align}
t_k = \frac{f^{(k-1)}-f^*}{ \Vert g^{(k-1)} \Vert_2^{2}}, \quad k = 1,2,3...
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;chứng-minh-định-lý-hội-tụ-cho-kích-thước-bước-polyak&quot;&gt;Chứng minh định lý hội tụ cho kích thước bước Polyak&lt;/h2&gt;
&lt;p&gt;Chứng minh có thể được suy ra từ &lt;a href=&quot;/contents/vi/chapter08/08_01_02_basic_inequality/&quot;&gt;bất đẳng thức cơ bản&lt;/a&gt; và chuỗi bất đẳng thức được sử dụng ở đó.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
 \Vert x^{(k)}-x^* \Vert_2^{2}  \quad \le \quad  \Vert x^{(k-1)}-x^* \Vert_2^{2}-2t_k (f(x^{(k-1)})-f^*)+t_k^{2} \Vert g^{(k-1)} \Vert_2^{2} \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;By differentiating the right-hand side above with respect to \(t_k\) and setting it to zero, we obtain the Polyak step size that minimizes the right-hand side.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp; \frac{\partial}{\partial t_k}  \Vert x^{(k-1)}-x^* \Vert_2^{2}-2t_k (f(x^{(k-1)})-f^*)+t_k^{2} \Vert g^{(k-1)} \Vert_2^{2} = 0 \\
 \Longleftrightarrow &amp;amp; -2(f(x^{(k-1)})-f^*)+2t_k \Vert g^{(k-1)} \Vert_2^{2} = 0 \\
 \Longleftrightarrow &amp;amp; f(x^{(k-1)})-f^* = t_k \Vert g^{(k-1)} \Vert_2^{2} \\
 \Longleftrightarrow &amp;amp; t_k = \frac{f(x^{(k-1)})-f^*}{ \Vert g^{(k-1)} \Vert_2^{2}} \quad \text{(Polyak step size at k)}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The convergence rate of the Polyak step size can also be derived from the &lt;a href=&quot;/contents/vi/chapter08/08_01_02_basic_inequality/&quot;&gt;basic inequality&lt;/a&gt; and the sequence of inequalities used there.&lt;/p&gt;

&lt;h2 id=&quot;convergence-rate-for-polyak-step-sizes&quot;&gt;Convergence rate for Polyak step-sizes&lt;/h2&gt;

&lt;p&gt;Let’s substitute the Polyak step size \(t_i\) into the basic inequality derived in the &lt;a href=&quot;/contents/vi/chapter08/08_01_02_basic_inequality/&quot;&gt;basic inequality&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp; 2\sum_{i=1}^{k}t_i(f(x^{(i)})-f^*) \le R^2 + \sum_{i=1}^kt_i^2 \Vert g^{(i)} \Vert_2^2 \\
 \Longleftrightarrow \quad &amp;amp; 2\sum_{i=1}^{k}\frac{(f(x^{(i)})-f^*)^2}{ \Vert g^{(i)} \Vert_2^2} \le R^2 + \sum_{i=1}^k\frac{(f(x^{(i)})-f^*)^2}{ \Vert g^{(i)} \Vert_2^2} \\
 \Longleftrightarrow \quad &amp;amp; \sum_{i=1}^{k}\frac{(f(x^{(i)})-f^*)^2}{ \Vert g^{(i)} \Vert_2^2} \le R^2 \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Assuming that the Lipschitz condition \(\Vert g^{(i)} \Vert_2 \le G\) always holds, the above inequality can be rearranged as follows:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp; \sum_{i=1}^{k}(f(x^{(i)})-f^*)^2 \le R^2G^2 \\
 \Longleftrightarrow \quad &amp;amp; k ⋅ (f(x^{(i)})-f^*)^2 \le R^2G^2 \\
 \Longleftrightarrow \quad &amp;amp; \sqrt{k} ⋅ (f(x^{(i)})-f^*) \le RG \\
 \Longleftrightarrow \quad &amp;amp; (f(x^{(i)})-f^*) \le \frac{RG}{\sqrt{k}} \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If we let \(\frac{RG}{\sqrt{k}}=\epsilon\), then \(k=\big(\frac{RG}{\epsilon}\big)^2\), so the number of trials required to reach a suboptimal point with respect to \(\epsilon\) is on the order of \(\big(\frac{RG}{\epsilon}\big)^2\). In other words, the convergence rate is \(O(1/\epsilon^{2})\), which is the same as other subgradient methods.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-05 Ví dụ: Hồi quy Logistic có Regularization</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_01_05_example_regularized_logistic_regression/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_01_05_example_regularized_logistic_regression</id>
   <content type="html">&lt;p&gt;Giả sử \((x_i, y_i) \in \mathbb{R}^p \times \{0, 1\}\) với \(i=1,...,n\). Hàm mất mát hồi quy logistic được định nghĩa như sau:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
f(\beta) = \sum_{i=1}^n\big(-y_ix_i^T\beta + \log(1+\exp(x_i^T\beta))\big)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hàm này là tổng hữu hạn của một hàm tuyến tính và một hàm log-sum-exp, vì vậy nó là một hàm lồi khả vi.&lt;/p&gt;

&lt;p&gt;Bây giờ, bài toán regularization cho \(\beta\) được công thức hóa như sau:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\min_{\beta} \text{ } f(\beta) + \lambda \cdot P(\beta)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(P(\beta)\) có thể được định nghĩa là \(\Vert \beta \Vert _2^2\) (phạt ridge) hoặc \(\Vert \beta \Vert _1\) (phạt lasso).&lt;/p&gt;

&lt;p&gt;Hàm mất mát với phạt ridge vẫn là một hàm lồi khả vi, nhưng hàm mất mát với phạt lasso trở thành một hàm lồi không khả vi. Đối với hai hàm mất mát này, chúng ta có thể áp dụng gradient descent cho ridge và phương pháp subgradient cho lasso, và bằng cách vẽ đồ thị giá trị hàm mục tiêu tại lần lặp \(k\), chúng ta có thể quan sát đặc điểm hội tụ của cả hai phương pháp.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter08/08_01_grad_vs_subgrad.png&quot; alt=&quot;grad_vs_subgrad&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Gradient descent so với phương pháp Subgradient [3]&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Thí nghiệm này cho thấy rằng gradient descent hội tụ nhanh hơn nhiều so với phương pháp subgradient.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-04 Tốc độ hội tụ</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_01_04_convergence_rate/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_01_04_convergence_rate</id>
   <content type="html">&lt;p&gt;Tốc độ hội tụ mô tả cách số lần lặp cần thiết để đạt đến một điểm \(\epsilon\)-dưới tối ưu phụ thuộc vào \(\epsilon\), sử dụng &lt;a href=&quot;https://en.wikipedia.org/wiki/Big_O_notation&quot;&gt;ký hiệu Big-O&lt;/a&gt;. Ví dụ, nếu \(\epsilon = 10^{-2}\) và tốc độ hội tụ là \(O(1/\epsilon)\), thì cần khoảng \(1/10^{-2}=10^2\) lần lặp.&lt;/p&gt;

&lt;p&gt;Hãy sử dụng &lt;a href=&quot;/contents/vi/chapter08/08_01_02_basic_inequality/&quot;&gt;08-01-02 Bất đẳng thức cơ bản&lt;/a&gt; để suy ra tốc độ hội tụ cho phương pháp subgradient với kích thước bước cố định.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(Nhắc lại:\)
\begin{align}
f^{k}_{best} - f^{*} \quad \le \quad \frac{R^{2}}{2kt} + \frac{G^{2}t}{2}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Giả sử \(\epsilon\) thỏa mãn \(\frac{R^{2}}{2kt} \le \frac{\epsilon}{2}\) và \(\frac{G^{2}t}{2} \le \frac{\epsilon}{2}\) (trong đó \(\epsilon\) là khoảng cách dưới tối ưu, \(G\) là hằng số Lipschitz, và \(R\) là khoảng cách giữa điểm khởi đầu và điểm tối ưu). Khi đó \(\frac{R^{2}}{2kt} + \frac{G^{2}t}{2} \le \epsilon\). Nếu \(\frac{G^{2}t}{2} \le \frac{\epsilon}{2}\), thì \(t \le \frac{\epsilon}{G^{2}}\), và \(\frac{R^{2}}{2kt} \le \frac{\epsilon}{2}\) dẫn đến \(\frac{R^2G^2}{\epsilon^2} \le k\). Điều này có nghĩa là số lần lặp cần thiết ít nhất là \(\frac{R^2G^2}{\epsilon^2}\) để đạt được \(f^{k}_{best} - f^{*} \le \epsilon\).&lt;/p&gt;

&lt;p&gt;Tốc độ hội tụ của thuật toán này là \(O(1/\epsilon^2)\), có nghĩa là nó cần nhiều lần lặp hơn đáng kể so với phương pháp gradient descent, có tốc độ \(O(1/\epsilon)\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-03 Phân tích hội tụ</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_01_03_convergence_analysis/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_01_03_convergence_analysis</id>
   <content type="html">&lt;p&gt;Trong gradient descent, ta giả định rằng \(\nabla f\) liên tục Lipschitz, nhưng trong phương pháp subgradient, ta giả định rằng chính \(f\) là liên tục Lipschitz. (Xem định lý hội tụ cho gradient descent &lt;a href=&quot;#post-not-found&quot;&gt;06-03-01&lt;/a&gt; để tham khảo.)&lt;/p&gt;

&lt;p&gt;Giả sử \(f\) là lồi, dom \(f = \mathbb{R}^n\), và \(f\) thỏa mãn điều kiện Lipschitz:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
| f(x) - f(y) | \le G \lVert x - y \rVert_2 \text{ với mọi } x, y
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Dựa trên các giả định này, công thức hội tụ cho kích thước bước cố định và giảm dần như sau:&lt;/p&gt;

&lt;h2 id=&quot;định-lý-hội-tụ-cho-kích-thước-bước-cố-định&quot;&gt;Định lý hội tụ cho kích thước bước cố định&lt;/h2&gt;

&lt;p&gt;Kích thước bước cố định có tính chất hội tụ sau:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\lim_{k\to\infty} f(x^{(k)}_{best}) \le f^* + \frac{G^{2}t}{2}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;định-lý-hội-tụ-cho-kích-thước-bước-giảm-dần&quot;&gt;Định lý hội tụ cho kích thước bước giảm dần&lt;/h2&gt;

&lt;p&gt;Phương pháp kích thước bước giảm dần có tính chất hội tụ sau:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\lim_{k\to\infty}f(x^{(k)}_{best}) = f^*
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;chứng-minh&quot;&gt;Chứng minh&lt;/h2&gt;

&lt;p&gt;Chứng minh cho kích thước bước cố định và giảm dần như sau.&lt;/p&gt;

&lt;h2 id=&quot;chứng-minh-định-lý-hội-tụ-cho-kích-thước-bước-cố-định&quot;&gt;Chứng minh định lý hội tụ cho kích thước bước cố định&lt;/h2&gt;

&lt;p&gt;Phương pháp kích thước bước cố định sử dụng \(\sum_{i=1}^{k}t_{i} = kt\) trong chứng minh.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; f_{best}^{(k)} - f^* \le \frac{R^{2}+G^{2}\sum_{i=1}^{k}t_{i}^{2}}{2\sum_{i=1}^{k}t_{i}} = \frac{R^{2}+G^{2}k t^{2}}{2kt}  = \frac{R^{2}}{2tk} + \frac{G^{2}t}{2} \\
&amp;amp; \lim_{k→\infty}(f^{(k)}_{best} - f^*) \le 0 + \frac{G^{2}t}{2} = \frac{G^{2}t}{2} \\
&amp;amp; \lim_{k→\infty}(f^{(k)}_{best}) \le f^* + \frac{G^{2}t}{2}
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;chứng-minh-định-lý-hội-tụ-cho-kích-thước-bước-giảm-dần&quot;&gt;Chứng minh định lý hội tụ cho kích thước bước giảm dần&lt;/h2&gt;

&lt;p&gt;Chứng minh cho kích thước bước giảm dần sử dụng các tính chất (1) và (2) sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{(1)} \sum_{i=1}^{\infty} t_i = \infty, \quad \text{(2)}  \sum_{i=1}^{\infty} t_i^{2} = \beta &amp;lt; \infty
\end{align}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; f_{best}^{(k)} - f^* \le \frac{R^{2}+G^{2}\sum_{i=1}^{k}t_{i}^{2}}{2\sum_{i=1}^{k}t_{i}} \\
&amp;amp; \lim_{k→\infty}(f^{(k)}_{best} - f^* ) \le \frac{R^{2}+G^{2}\beta}{2\infty} = 0 \\
&amp;amp; \lim_{k→\infty}(f^{(k)}_{best}) =  f^* \\
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-02 Bất đẳng thức cơ bản</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_01_02_basic_inequality/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_01_02_basic_inequality</id>
   <content type="html">&lt;p&gt;Định lý hội tụ và tốc độ hội tụ của phương pháp subgradient có thể được chứng minh bằng cách sử dụng bất đẳng thức cơ bản sau.&lt;/p&gt;

&lt;h2 id=&quot;bất-đẳng-thức-cơ-bản&quot;&gt;Bất đẳng thức cơ bản&lt;/h2&gt;

&lt;blockquote&gt;
\[\begin{align}
f_{best}^{k} - f^* \quad \le \quad \frac{R^{2}+G^{2}\sum_{i=1}^{k}\alpha_{i}^{2}}{2\sum_{i=1}^{k}\alpha_{i}} 
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;chứng-minh&quot;&gt;Chứng minh&lt;/h2&gt;
&lt;p&gt;Nếu \(x^*\) là điểm tối ưu của hàm \(f\), thì phương trình sau đây đúng:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
 \Vert x^{(k+1)}-x^* \Vert _2^{2} &amp;amp; \quad = \quad  \Vert x^{(k)}-\alpha_k g^{(k)}-x^* \Vert _2^{2}  \\
                                   &amp;amp; \quad = \quad  \Vert (x^{(k)}-x^*)-\alpha_k g^{(k)} \Vert _2^{2}  \\
                                   &amp;amp; \quad = \quad  \Vert x^{(k)}-x^* \Vert _2^2 - 2 \alpha_k g^{(k)T}(x^{(k)}-x^*)+\alpha_k^2 \Vert g^{(k)} \Vert _2^2 \\
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Từ định nghĩa của subgradient, bất đẳng thức sau đây đúng:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
f(x^*) \ge f(x^{(k)}) + g^{(k)T}(x^*-x^{(k)}) &amp;amp; \quad \Longleftrightarrow \quad f(x^*)-f(x^{(k)}) \ge  g^{(k)T}(x^*-x^{(k)}) \\
                     &amp;amp; \quad  \Longleftrightarrow \quad f(x^{(k)} - f(x^*)) \le  g^{(k)T}(x^{(k)}-x^*) \\
                     &amp;amp; \quad \Longleftrightarrow \quad -2\alpha_{k}(f(x^{(k)}) - f(x^*)) \ge  -2\alpha_{k}(g^{(k)T}(x^{(k)}-x^*)) \\
                     &amp;amp; \quad \Longleftrightarrow \quad -2\alpha_{k}(g^{(k)T}(x^{(k)}-x^*)) \le -2\alpha_{k}(f(x^{(k)})-f(x^*)) \\
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Sử dụng các phương trình và bất đẳng thức trên, bất đẳng thức sau có thể được suy ra:&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-01 Lựa chọn kích thước bước</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_01_01_step_size_choices/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_01_01_step_size_choices</id>
   <content type="html">&lt;p&gt;Có nhiều cách khác nhau để chọn &lt;strong&gt;kích thước bước&lt;/strong&gt; trong phương pháp subgradient.&lt;/p&gt;

&lt;p&gt;Hãy xem xét kỹ hơn hai phương pháp sau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Kích thước bước cố định&lt;/strong&gt;: \(t_k = t\), với \(k = 1, 2, 3, ...\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kích thước bước giảm dần&lt;/strong&gt;: \(t_k\) thỏa mãn các điều kiện sau:&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\sum_{k=1}^{\infty} t_k = \infty, \quad \sum_{k=1}^{\infty} t_k^{2} &amp;lt; \infty
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;ví-dụ-về-kích-thước-bước-giảm-dần&quot;&gt;Ví dụ về kích thước bước giảm dần&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; t_k = \frac{1}{k}, k = 1,2,3,... 
&amp;amp; \sum_{k=1}^{\infty}t_k = \infty \quad 	ext{(Chuỗi điều hòa)} 
&amp;amp; \sum_{k=1 }^{\infty}t^2_k \approx 1.644934 &amp;lt; \infty \quad 	ext{(Bài toán Basel)} 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Một đặc điểm chính của kích thước bước trong phương pháp subgradient là nó phải được thiết lập trước, khác với gradient descent. Nói cách khác, không giống như tìm kiếm đường thẳng backtracking trong gradient descent, kích thước bước trong phương pháp subgradient không thích ứng với độ cong của hàm số.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08 Phương pháp Subgradient</title>
   <link href="http://localhost:4000/contents/vi/chapter08/08_00_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/08_00_subgradient_method</id>
   <content type="html">&lt;p&gt;Trong phần này, chúng ta sẽ tìm hiểu về phương pháp subgradient, có thể được áp dụng cho các hàm lồi có thể không khả vi, sử dụng khái niệm subgradient. Chúng ta cũng sẽ khám phá các tính chất hội tụ và tốc độ hội tụ của phương pháp subgradient thông qua các ví dụ.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-03 Improving on the Subgradient Method</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_03_improving_on_the_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_03_improving_on_the_subgradient_method</id>
   <content type="html">&lt;p&gt;The subgradient method is advantageous because it can be used for nondifferentiable convex functions, making it more general. However, its convergence rate is \(O(1/\epsilon^{2})\), which is much slower than the convergence rate of gradient descent, \(O(1/\epsilon)\).&lt;/p&gt;

&lt;p&gt;Is there a way to combine the strengths of gradient descent and the subgradient method? In the next section, we will learn about the proximal gradient descent method, which combines the advantages of both algorithms.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-02 Stochastic Subgradient Method</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_02_stochastic_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_02_stochastic_subgradient_method</id>
   <content type="html">&lt;p&gt;The stochastic subgradient method is similar to stochastic gradient descent, but replaces the gradient with a subgradient.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-02-04 Batch vs Stochastic Methods</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_02_04_batch_vs_stochastic_methods/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_02_04_batch_vs_stochastic_methods</id>
   <content type="html">&lt;p&gt;The convergence properties of batch and stochastic methods are as follows:&lt;/p&gt;

&lt;p&gt;Generally, the stochastic method quickly approaches the optimal point in the early stages, but may not converge as well near the optimal point. In contrast, the batch method converges more slowly but approaches the optimal point more accurately.&lt;/p&gt;

&lt;p&gt;The figure below compares the convergence of batch and stochastic methods for &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_regression&quot;&gt;logistic regression&lt;/a&gt; (without regularization):&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter08/08_02_stochastic_vs_batch.png&quot; alt=&quot;stochastic_vs_batch&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 3] Batch vs Stochastic Gradient Descent [2]&lt;/figcaption&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>08-02-03 Convergence Rate of Stochastic Method</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_02_03_convergence_rate_of_stochastic_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_02_03_convergence_rate_of_stochastic_method</id>
   <content type="html">&lt;p&gt;There are differences in the convergence rates between cyclic and randomized methods.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;/contents/en/chapter08/08_01_04_convergence_rate/&quot;&gt;convergence rate&lt;/a&gt; of the batch subgradient method is \(O(G_{batch}^{2}/\epsilon^{2})\), where \(G_{batch}\) is the Lipschitz constant of \(\sum f_i\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cyclic method&lt;/strong&gt;: The iteration complexity of the cyclic method is \(O(m^{3}G^{2}/\epsilon^{2})\). If one cycle of the cyclic stochastic subgradient method is considered equivalent to one batch subgradient method, then each cycle requires \(O(m^{2}G^{2}/\epsilon^{2})\) iterations. (\(G\) is the Lipschitz constant of a single function \(f_i\))&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Randomized method&lt;/strong&gt;: The iteration complexity of the randomized method is \(O(m^{2}G^{2}/\epsilon^{2})\). That is, the randomized method requires \(O(mG^{2}/\epsilon^2)\) iterations, which is \(m\) times faster than the batch and cyclic methods with \(O(m^2G^2/\epsilon^2)\). In terms of Big-O notation, if \(m\) is large, the randomized method has a faster convergence rate.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Although the Big-O bounds for randomized and cyclic methods differ by a factor of \(m\), note that the cyclic method’s Big-O bound is worst-case, while the randomized method’s is average-case. In practice, the difference may not be as large as the Big-O notation suggests.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-02-02 Convergence of Stochastic Methods</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_02_02_convergence_of_stochastic_methods/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_02_02_convergence_of_stochastic_methods</id>
   <content type="html">&lt;p&gt;Assume each function \(f_i, i = 1,...,m\) is convex and Lipschitz continuous with constant G.&lt;/p&gt;

&lt;p&gt;For the stochastic subgradient method, the following properties hold for fixed and diminishing step sizes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Fixed step sizes&lt;/strong&gt; for \(t_k = t\), \(k = 1, 2, 3, ...\)&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\text{For cyclic and randomized methods with fixed step sizes, the following holds:} \\
\begin{align}
\lim_{k\to\infty} f(x_{best}^{(k)}) \le f^{*} + 5m^{2}G^{2}t/2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(mG\) is the Lipschitz constant of \(\sum_{i=1}^{m} f_i\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Diminishing step sizes&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\text{For cyclic and randomized methods with diminishing step sizes, the following holds:} \\
\begin{align}
\lim_{k\to\infty} f(x_{best}^{(k)}) = f^{*}
\end{align}\]
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>08-02-01 Stochastic Subgradient Method</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_02_01_stochastic_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_02_01_stochastic_subgradient_method</id>
   <content type="html">&lt;p&gt;Let’s consider the problem of minimizing the sum of functions as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{equation}
\min_x \sum_{i=1}^m f_i(x)
\end{equation}\]
&lt;/blockquote&gt;

&lt;p&gt;If we apply the subgradient method to this problem, we need to compute the subgradient for each function \(f_i\) and sum them. (This is similar to the method introduced in &lt;a href=&quot;/contents/en/chapter06/06_05_stochastic_gradient_descent/&quot;&gt;stochastic gradient descent&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;In summary, the stochastic subgradient method takes the following form:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
x^{(k)} = x^{(k-1)} - t_k \cdot g_{i_k}^{(k-1)}, \quad k = 1, 2, 3, . . . 
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(i_k \in \{1,...,m\}\) is the index chosen at the \(k\)-th iteration. As will be discussed in the next section on the convergence rate of the stochastic subgradient method, the choice of cyclic or random method affects the result. \(g_{i}^{(k-1)} \in \partial f_{i}(x^{k-1})\), and this update direction is different from the usual &lt;a href=&quot;/contents/en/chapter08/08_01_subgradient_method/&quot;&gt;subgradient method&lt;/a&gt; (also called batch subgradient method or full batch subgradient method), where \(\sum_{i=1}^{m} g_i^{(k-1)}\) is used.&lt;/p&gt;

&lt;p&gt;If each \(f_i, i = 1,...,m\) is differentiable, this algorithm becomes stochastic gradient descent. (The stochastic subgradient method is a more general form)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01 Subgradient Method</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_01_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_01_subgradient_method</id>
   <content type="html">&lt;p&gt;Assume the domain of the function is \({R}^n\) and there is a convex function \(f\) that may not be differentiable everywhere.&lt;/p&gt;

&lt;p&gt;The subgradient method is defined by replacing the gradient in gradient descent with a subgradient. (\(\nabla f(x^{(k-1)}) \to g(x^{(k-1)})\))&lt;/p&gt;

&lt;blockquote&gt;
\[x^{(k)} = x^{(k-1)} - t_k \cdot g^{(k-1)}, \quad k = 1, 2, 3, . . .\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(g^{(k-1)} \in \partial f(x^{(k-1)})\), i.e., \(g^{(k-1)}\) is a subgradient of \(f\) at \(x^{(k-1)}\).&lt;/p&gt;

&lt;h2 id=&quot;subgradient-method-not-subgradient-descent&quot;&gt;Subgradient method (not subgradient “descent”)&lt;/h2&gt;

&lt;p&gt;Unlike gradient descent, the subgradient method does not always guarantee descent at each step (hence the name is not subgradient “descent”). Therefore, when using the subgradient method, it is important to track the best result at each iteration.&lt;/p&gt;

&lt;blockquote&gt;
\[f(x_{best}^{(k)}) = \min_{i=0,...k} f(x^{(i)})\]
&lt;/blockquote&gt;

&lt;p&gt;\(f(x^{(k)}_{best})\) denotes the minimum value of the function \(f\) obtained over \(k\) iterations of the subgradient method.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-08 Projected Subgradient Method</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_01_08_projected_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_01_08_projected_subgradient_method</id>
   <content type="html">&lt;p&gt;The method described in the previous example is called the projected subgradient method. This algorithm can be used for convex problems with constraints.&lt;/p&gt;

&lt;p&gt;If we denote the domain that satisfies the constraints as the set \(C\), then a constrained convex problem is defined as follows:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
\min_x \text{ }f(x) \quad \text{subject to } x \in C
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;By using the projected subgradient method, such problems can be solved relatively easily. The projected subgradient method is similar to the standard subgradient method, but at each iteration, the result is projected onto the set \(C\).&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
x^{(k)} = P_c(x^{(k-1)} - t_k \cdot g^{(k-1)}), \quad k = 1,2,3,...
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If projection is possible, this method has the same convergence properties and rate as the subgradient method.&lt;/p&gt;

&lt;p&gt;One thing to note about the projected subgradient method is that even if \(C\) is a simple convex set, if the projection operation \(P_c\) is difficult, the overall problem also becomes hard to solve. Typically, the following sets \(C\) are relatively easy to project onto:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Affine images: {\(Ax=b : x \in \mathbb{R}^{n}\)}&lt;/li&gt;
  &lt;li&gt;Solution set of linear system: {\(x: Ax=b\)}&lt;/li&gt;
  &lt;li&gt;Nonnegative orthant: \(\mathbb{R}_+^{n} =\){\(x: x\ge 0\)}&lt;/li&gt;
  &lt;li&gt;Some norm balls: {\(x: \lVert x \rVert _p \le 1\)} for \(p=1,2,\infty\)&lt;/li&gt;
  &lt;li&gt;Some simple polyhedra and simple cones&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-07 Example: Intersection of sets</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_01_07_example_intersection_of_sets/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_01_07_example_intersection_of_sets</id>
   <content type="html">&lt;p&gt;Suppose we want to find the intersection point of several closed convex sets.&lt;/p&gt;

&lt;p&gt;First, let’s define \(f_i(x)\) as the distance from a point \(x\) to the set \(C_i\), and \(f(x)\) as the maximum distance from \(x\) to all sets \(C_i, i=1,...,m\):&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
f_i(x) &amp;amp; = \mathbb{dist}(x, C_i), i=1,...,m \\
f(x) &amp;amp; = \max_{1,...,m}\text{ }f_i(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Using these two functions, the problem of finding the intersection of convex sets can be formulated as the following minimization problem:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
min_{x}\text{ }f(x)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The problem of finding the intersection point of convex sets is equivalent to finding the point \(x\) that minimizes the maximum distance \(f(x)\) to the sets \(C_i\). In this case, the objective function \(f(x)\) is convex. If all sets have a common intersection point, then \(f^* = 0\) and the optimal point is \(x^* \in C_1 \cap C_2 \cap ... \cap C_m\).&lt;/p&gt;

&lt;h2 id=&quot;gradient-of-distance-function&quot;&gt;Gradient of distance function&lt;/h2&gt;

&lt;p&gt;In &lt;a href=&quot;/contents/en/chapter07/07_03_05_example_distance_to_convex_set/&quot;&gt;the previous section&lt;/a&gt;, we defined the distance to a convex set as \(dist(x, C_i) = \min_{y \in C} \lVert y-x \rVert _2\), and saw that the gradient of this function is:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
\partial dist(x,C) = \frac{x-P_C(x)}{ \Vert x-P_C(x) \Vert_2}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(P_C(x)\) is the projection of the point \(x\) onto the set \(C\).&lt;/p&gt;

&lt;h2 id=&quot;subdifferential-of-finite-pointwise-maximum&quot;&gt;Subdifferential of finite pointwise maximum&lt;/h2&gt;

&lt;p&gt;Finite pointwise maximum 함수 \(f(x)=max_{i=1,...,m}\text{ }f_i(x)\)에 대한 subdifferential은 다음과 같이 정의 된다.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
\partial f(x) = \text{conv}\left(\bigcup_{i:f_i(x)=f(x)} \partial f_i(x)\right)
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;즉, \(x\)의 subdifferential은 그 지점의 모든 subdifferential \(\partial f_i(x), i=1,...,m\)의 합집합에 대한 convex hull로 정의된다.&lt;/p&gt;

&lt;p&gt;만약 \(f_i(x) = f(x)\) 이고 \(g_i \in \partial f_i(x)\)이라면 \(g_i \in \partial f(x)\)이다.&lt;/p&gt;

&lt;h2 id=&quot;deriving-subgradient-updating-steps&quot;&gt;Deriving subgradient updating steps&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;/contents/en/chapter07/07_03_05_example_distance_to_convex_set/&quot;&gt;이전 장&lt;/a&gt;에서 보았던 \(dist(x, C_i)\)는 다음과 같은 subgradient를 가진다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(Recall:\)
\(\begin{align}
g_i = \nabla f_i(x) = \frac{x-P_{C_i}(x)}{ \Vert x-P_{C_i}(x) \Vert_2}
\end{align}\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;만약 컨벡스 집합의 교차점이 있다면 우리는 \(f^*=0\)임을 바로 알 수 있기에 Polyak step sizes를 사용할 수 있다. 위 subgradient 수식을 보면 \(x-P_{c_i}(x)\)가 정규화된 형태이므로 \(\Vert g \Vert_2^{2}=1\)이다. 결국 Polyak step size \(t_k = \{\frac{f^{(k-1)}-f^*}{ \Vert g^{(k-1)} \Vert_2^{2}}\}\)에 우리가 알고 있는 값을 대입하면 다음과 같은 subgradient method 공식을 도출할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
x^{(k)} &amp;amp; = x^{(k-1)} - t_{k}⋅g_{k-1} \\
&amp;amp; = x^{(k-1)} - \frac{f^{(k-1)}-f^*}{ \Vert g^{(k-1)} \Vert_2^{2}} \frac{x^{(k-1)}-P_{C_i}(x)}{ \Vert x^{(k-1)}-P_{C_i}(x) \Vert_2}  \\
&amp;amp; = x^{(k-1)} - f(x^{k-1}) \frac{x^{(k-1)}-P_{C_i}(x)}{ \Vert x^{(k-1)}-P_{C_i}(x) \Vert_2}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;여기서 Polyak size인 \(f(x^{(k-1)})\)는 \(dist(x_i^{(k-1)}, C_i) =  \Vert x^{(k-1)}-P_{C_i}(x) \Vert_2\) 이므로 subgradient method는 아래와 같이 정리된다.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
x^{(k)} = P_{C_i}(x^{(k-1)})
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;이 문제는 그림으로 표현하면 각 스텝에서 가장 가까운 컨벡스 함수에 projection을 반복하는 형태이다.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter08/08_01_projection.png&quot; alt=&quot;projection&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 2] Alternating Projection Algorithm [10]&lt;/figcaption&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-06 Polyak step sizes</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_01_06_polyak_step_sizes/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_01_06_polyak_step_sizes</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Polyak step sizes&lt;/strong&gt; are a way to set the step size when the optimal value is known. If \(f^*\) is known, Polyak step sizes can be defined as follows.&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem-for-polyak-step-sizes&quot;&gt;Convergence theorem for Polyak step-sizes&lt;/h2&gt;
&lt;blockquote&gt;

\[\begin{align}
t_k = \frac{f^{(k-1)}-f^*}{ \Vert g^{(k-1)} \Vert_2^{2}}, \quad k = 1,2,3...
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof-of-convergence-theorem-for-polyak-step-sizes&quot;&gt;Proof of convergence theorem for Polyak step-sizes&lt;/h2&gt;
&lt;p&gt;The proof can be derived from the &lt;a href=&quot;/contents/en/chapter08/08_01_02_basic_inequality/&quot;&gt;basic inequality&lt;/a&gt; and the sequence of inequalities used there.&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
 \Vert x^{(k)}-x^* \Vert_2^{2}  \quad \le \quad  \Vert x^{(k-1)}-x^* \Vert_2^{2}-2t_k (f(x^{(k-1)})-f^*)+t_k^{2} \Vert g^{(k-1)} \Vert_2^{2} \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;By differentiating the right-hand side above with respect to \(t_k\) and setting it to zero, we obtain the Polyak step size that minimizes the right-hand side.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp; \frac{\partial}{\partial t_k}  \Vert x^{(k-1)}-x^* \Vert_2^{2}-2t_k (f(x^{(k-1)})-f^*)+t_k^{2} \Vert g^{(k-1)} \Vert_2^{2} = 0 \\
 \Longleftrightarrow &amp;amp; -2(f(x^{(k-1)})-f^*)+2t_k \Vert g^{(k-1)} \Vert_2^{2} = 0 \\
 \Longleftrightarrow &amp;amp; f(x^{(k-1)})-f^* = t_k \Vert g^{(k-1)} \Vert_2^{2} \\
 \Longleftrightarrow &amp;amp; t_k = \frac{f(x^{(k-1)})-f^*}{ \Vert g^{(k-1)} \Vert_2^{2}} \quad \text{(Polyak step size at k)}
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The convergence rate of the Polyak step size can also be derived from the &lt;a href=&quot;/contents/en/chapter08/08_01_02_basic_inequality/&quot;&gt;basic inequality&lt;/a&gt; and the sequence of inequalities used there.&lt;/p&gt;

&lt;h2 id=&quot;convergence-rate-for-polyak-step-sizes&quot;&gt;Convergence rate for Polyak step-sizes&lt;/h2&gt;

&lt;p&gt;Let’s substitute the Polyak step size \(t_i\) into the basic inequality derived in the &lt;a href=&quot;/contents/en/chapter08/08_01_02_basic_inequality/&quot;&gt;basic inequality&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp; 2\sum_{i=1}^{k}t_i(f(x^{(i)})-f^*) \le R^2 + \sum_{i=1}^kt_i^2 \Vert g^{(i)} \Vert_2^2 \\
 \Longleftrightarrow \quad &amp;amp; 2\sum_{i=1}^{k}\frac{(f(x^{(i)})-f^*)^2}{ \Vert g^{(i)} \Vert_2^2} \le R^2 + \sum_{i=1}^k\frac{(f(x^{(i)})-f^*)^2}{ \Vert g^{(i)} \Vert_2^2} \\
 \Longleftrightarrow \quad &amp;amp; \sum_{i=1}^{k}\frac{(f(x^{(i)})-f^*)^2}{ \Vert g^{(i)} \Vert_2^2} \le R^2 \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Assuming that the Lipschitz condition \(\Vert g^{(i)} \Vert_2 \le G\) always holds, the above inequality can be rearranged as follows:&lt;/p&gt;
&lt;blockquote&gt;

\[\begin{align}
&amp;amp; \sum_{i=1}^{k}(f(x^{(i)})-f^*)^2 \le R^2G^2 \\
 \Longleftrightarrow \quad &amp;amp; k ⋅ (f(x^{(i)})-f^*)^2 \le R^2G^2 \\
 \Longleftrightarrow \quad &amp;amp; \sqrt{k} ⋅ (f(x^{(i)})-f^*) \le RG \\
 \Longleftrightarrow \quad &amp;amp; (f(x^{(i)})-f^*) \le \frac{RG}{\sqrt{k}} \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;If we let \(\frac{RG}{\sqrt{k}}=\epsilon\), then \(k=\big(\frac{RG}{\epsilon}\big)^2\), so the number of trials required to reach a suboptimal point with respect to \(\epsilon\) is on the order of \(\big(\frac{RG}{\epsilon}\big)^2\). In other words, the convergence rate is \(O(1/\epsilon^{2})\), which is the same as other subgradient methods.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-05 Example: Regularized Logistic Regression</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_01_05_example_regularized_logistic_regression/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_01_05_example_regularized_logistic_regression</id>
   <content type="html">&lt;p&gt;Suppose \((x_i, y_i) \in \mathbb{R}^p \times \{0, 1\}\) for \(i=1,...,n\). The logistic regression loss is defined as:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
f(\beta) = \sum_{i=1}^n\big(-y_ix_i^T\beta + \log(1+\exp(x_i^T\beta))\big)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This function is a finite sum of a linear function and a log-sum-exp function, so it is a differentiable convex function.&lt;/p&gt;

&lt;p&gt;Now, the regularization problem for \(\beta\) is formulated as:&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\min_{\beta} \text{ } f(\beta) + \lambda \cdot P(\beta)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, \(P(\beta)\) can be defined as \(\Vert \beta \Vert _2^2\) (ridge penalty) or \(\Vert \beta \Vert _1\) (lasso penalty).&lt;/p&gt;

&lt;p&gt;The loss function with ridge penalty remains a differentiable convex function, but the loss function with lasso penalty becomes a nondifferentiable convex function. For these two loss functions, we can apply gradient descent for ridge and the subgradient method for lasso, and by plotting the objective function value at iteration \(k\), we can observe the convergence characteristics of both methods.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter08/08_01_grad_vs_subgrad.png&quot; alt=&quot;grad_vs_subgrad&quot; width=&quot;90%&quot; height=&quot;90%&quot; /&gt;
&lt;/p&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Gradient descent vs Subgradient method [3]&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This experiment shows that gradient descent converges much faster than the subgradient method.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-04 Convergence rate</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_01_04_convergence_rate/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_01_04_convergence_rate</id>
   <content type="html">&lt;p&gt;The convergence rate describes how the number of iterations required to reach an \(\epsilon\)-suboptimal point depends on \(\epsilon\), using &lt;a href=&quot;https://en.wikipedia.org/wiki/Big_O_notation&quot;&gt;Big-O notation&lt;/a&gt;. For example, if \(\epsilon = 10^{-2}\) and the convergence rate is \(O(1/\epsilon)\), then about \(1/10^{-2}=10^2\) iterations are needed.&lt;/p&gt;

&lt;p&gt;Let’s use &lt;a href=&quot;/contents/en/chapter08/08_01_02_basic_inequality/&quot;&gt;08-01-02 Basic inequality&lt;/a&gt; to derive the convergence rate for the subgradient method with fixed step sizes.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(Recall:\)
\begin{align}
f^{k}_{best} - f^{*} \quad \le \quad \frac{R^{2}}{2kt} + \frac{G^{2}t}{2}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Suppose \(\epsilon\) satisfies \(\frac{R^{2}}{2kt} \le \frac{\epsilon}{2}\) and \(\frac{G^{2}t}{2} \le \frac{\epsilon}{2}\) (where \(\epsilon\) is the suboptimality gap, \(G\) is the Lipschitz constant, and \(R\) is the distance between the starting point and the optimal point). Then \(\frac{R^{2}}{2kt} + \frac{G^{2}t}{2} \le \epsilon\). If \(\frac{G^{2}t}{2} \le \frac{\epsilon}{2}\), then \(t \le \frac{\epsilon}{G^{2}}\), and \(\frac{R^{2}}{2kt} \le \frac{\epsilon}{2}\) leads to \(\frac{R^2G^2}{\epsilon^2} \le k\). This means the number of iterations required is at least \(\frac{R^2G^2}{\epsilon^2}\) to achieve \(f^{k}_{best} - f^{*} \le \epsilon\).&lt;/p&gt;

&lt;p&gt;The convergence rate of this algorithm is \(O(1/\epsilon^2)\), which means it requires significantly more iterations than the gradient descent method, which has a rate of \(O(1/\epsilon)\).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-03 Convergence analysis</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_01_03_convergence_analysis/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_01_03_convergence_analysis</id>
   <content type="html">&lt;p&gt;In gradient descent, it is assumed that \(\nabla f\) is Lipschitz continuous, but in the subgradient method, we assume that \(f\) itself is Lipschitz continuous. (See the convergence theorem for gradient descent &lt;a href=&quot;#post-not-found&quot;&gt;06-03-01&lt;/a&gt; for reference.)&lt;/p&gt;

&lt;p&gt;Assume \(f\) is convex, dom \(f = \mathbb{R}^n\), and \(f\) satisfies the Lipschitz condition:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
| f(x) - f(y) | \le G \lVert x - y \rVert_2 \text{ for all } x, y
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Given these assumptions, the convergence formulas for fixed and diminishing step sizes are as follows:&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem-for-fixed-step-sizes&quot;&gt;Convergence theorem for fixed step sizes&lt;/h2&gt;

&lt;p&gt;Fixed step sizes have the following convergence property:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\lim_{k\to\infty} f(x^{(k)}_{best}) \le f^* + \frac{G^{2}t}{2}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;convergence-theorem-for-diminishing-step-sizes&quot;&gt;Convergence theorem for diminishing step sizes&lt;/h2&gt;

&lt;p&gt;The diminishing step sizes method has the following convergence property:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\lim_{k\to\infty}f(x^{(k)}_{best}) = f^*
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;proofs&quot;&gt;Proofs&lt;/h2&gt;

&lt;p&gt;The proofs for fixed and diminishing step sizes are as follows.&lt;/p&gt;

&lt;h2 id=&quot;proof-of-convergence-theorem-for-fixed-step-sizes&quot;&gt;Proof of convergence theorem for fixed step sizes&lt;/h2&gt;

&lt;p&gt;The fixed step size method uses \(\sum_{i=1}^{k}t_{i} = kt\) in its proof.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; f_{best}^{(k)} - f^* \le \frac{R^{2}+G^{2}\sum_{i=1}^{k}t_{i}^{2}}{2\sum_{i=1}^{k}t_{i}} = \frac{R^{2}+G^{2}k t^{2}}{2kt}  = \frac{R^{2}}{2tk} + \frac{G^{2}t}{2} \\
&amp;amp; \lim_{k→\infty}(f^{(k)}_{best} - f^*) \le 0 + \frac{G^{2}t}{2} = \frac{G^{2}t}{2} \\
&amp;amp; \lim_{k→\infty}(f^{(k)}_{best}) \le f^* + \frac{G^{2}t}{2}
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof-of-convergence-theorem-for-diminishing-step-sizes&quot;&gt;Proof of convergence theorem for diminishing step sizes&lt;/h2&gt;

&lt;p&gt;The proof for the diminishing step sizes uses the following properties (1) and (2):&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{(1)} \sum_{i=1}^{\infty} t_i = \infty, \quad \text{(2)}  \sum_{i=1}^{\infty} t_i^{2} = \beta &amp;lt; \infty
\end{align}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; f_{best}^{(k)} - f^* \le \frac{R^{2}+G^{2}\sum_{i=1}^{k}t_{i}^{2}}{2\sum_{i=1}^{k}t_{i}} \\
&amp;amp; \lim_{k→\infty}(f^{(k)}_{best} - f^* ) \le \frac{R^{2}+G^{2}\beta}{2\infty} = 0 \\
&amp;amp; \lim_{k→\infty}(f^{(k)}_{best}) =  f^* \\
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-02 Basic Inequality</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_01_02_basic_inequality/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_01_02_basic_inequality</id>
   <content type="html">&lt;p&gt;The convergence theorem and convergence rate of the subgradient method can be proved using the following basic inequality.&lt;/p&gt;

&lt;h2 id=&quot;basic-inequality&quot;&gt;Basic Inequality&lt;/h2&gt;

&lt;blockquote&gt;
\[\begin{align}
f_{best}^{k} - f^* \quad \le \quad \frac{R^{2}+G^{2}\sum_{i=1}^{k}\alpha_{i}^{2}}{2\sum_{i=1}^{k}\alpha_{i}} 
\end{align}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;proof&quot;&gt;Proof&lt;/h2&gt;
&lt;p&gt;If \(x^*\) is the optimal point of the function \(f\), then the following equation holds:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
 \Vert x^{(k+1)}-x^* \Vert _2^{2} &amp;amp; \quad = \quad  \Vert x^{(k)}-\alpha_k g^{(k)}-x^* \Vert _2^{2}  \\
                                   &amp;amp; \quad = \quad  \Vert (x^{(k)}-x^*)-\alpha_k g^{(k)} \Vert _2^{2}  \\
                                   &amp;amp; \quad = \quad  \Vert x^{(k)}-x^* \Vert _2^2 - 2 \alpha_k g^{(k)T}(x^{(k)}-x^*)+\alpha_k^2 \Vert g^{(k)} \Vert _2^2 \\
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;From the definition of subgradient, the following inequality holds:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{alignat}{1}
f(x^*) \ge f(x^{(k)}) + g^{(k)T}(x^*-x^{(k)}) &amp;amp; \quad \Longleftrightarrow \quad f(x^*)-f(x^{(k)}) \ge  g^{(k)T}(x^*-x^{(k)}) \\
                     &amp;amp; \quad  \Longleftrightarrow \quad f(x^{(k)} - f(x^*)) \le  g^{(k)T}(x^{(k)}-x^*) \\
                     &amp;amp; \quad \Longleftrightarrow \quad -2\alpha_{k}(f(x^{(k)}) - f(x^*)) \ge  -2\alpha_{k}(g^{(k)T}(x^{(k)}-x^*)) \\
                     &amp;amp; \quad \Longleftrightarrow \quad -2\alpha_{k}(g^{(k)T}(x^{(k)}-x^*)) \le -2\alpha_{k}(f(x^{(k)})-f(x^*)) \\
\end{alignat}\]
&lt;/blockquote&gt;

&lt;p&gt;Using the above equations and inequalities, the following inequality can be derived:&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08-01-01 Step size choices</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_01_01_step_size_choices/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_01_01_step_size_choices</id>
   <content type="html">&lt;p&gt;There are various ways to choose the &lt;strong&gt;step size&lt;/strong&gt; in the subgradient method.&lt;/p&gt;

&lt;p&gt;Let’s take a closer look at the following two approaches:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Fixed step sizes&lt;/strong&gt;: \(t_k = t\), where \(k = 1, 2, 3, ...\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Diminishing step sizes&lt;/strong&gt;: \(t_k\) that satisfy the following conditions:&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\sum_{k=1}^{\infty} t_k = \infty, \quad \sum_{k=1}^{\infty} t_k^{2} &amp;lt; \infty
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;example-of-diminishing-step-sizes&quot;&gt;Example of Diminishing step sizes&lt;/h3&gt;

&lt;blockquote&gt;
\[\begin{align}
&amp;amp; t_k = \frac{1}{k}, k = 1,2,3,... \\
&amp;amp; \sum_{k=1}^{\infty}t_k = \infty \quad \text{(Harmonic  series)} \\
&amp;amp; \sum_{k=1 }^{\infty}t^2_k \approx 1.644934 &amp;lt; \infty \quad \text{(Basel problem)} \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;A key feature of the step size in the subgradient method is that it must be set in advance, unlike in gradient descent. In other words, unlike the backtracking line search in gradient descent, the step size in the subgradient method does not adapt to the curvature of the function.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08 Subgradient Method</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_00_subgradient_method/"/>
   <updated>2020-03-29T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter08/08_00_subgradient_method</id>
   <content type="html">&lt;p&gt;In this section, we will look at the subgradient method, which can be applied to convex functions that may not be differentiable, using the concept of subgradients. We will also explore the convergence properties and rate of the subgradient method with examples.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>04-08 Làm giản</title>
   <link href="http://localhost:4000/contents/vi/chapter04/04_08_Relaxation/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/04_08_Relaxation</id>
   <content type="html">&lt;p&gt;Phần này thảo luận về các kỹ thuật làm giản, được sử dụng để đơn giản hóa hoặc xấp xỉ các bài toán tối ưu hóa lồi bằng cách làm giản các ràng buộc.&lt;/p&gt;

&lt;p&gt;Xem xét một bài toán có dạng:&lt;/p&gt;
&lt;blockquote&gt;
\[\text{min}_{x} \text{ } f(x) \text{  thỏa mãn  } x \in C\]
&lt;/blockquote&gt;

&lt;p&gt;Quá trình thay đổi tập miền \(C\) thành một siêu tập \(\tilde{C} \supseteq C\) được gọi là &lt;em&gt;Làm giản&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
\[\text{min}_{x} \text{ } f(x) \text{  thỏa mãn  } x \in \tilde{C}\]
&lt;/blockquote&gt;

&lt;p&gt;Vì chúng ta đang tối ưu hóa trên một tập miền lớn hơn \(C\), giá trị tối ưu của bài toán được làm giản luôn nhỏ hơn hoặc bằng giá trị của bài toán gốc.&lt;/p&gt;

&lt;h3 id=&quot;trường-hợp-đặc-biệt-quan-trọng-làm-giản-ràng-buộc-đẳng-thức-phi-affine&quot;&gt;Trường hợp đặc biệt quan trọng: làm giản ràng buộc đẳng thức phi-affine&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(h_{j}(x) = 0, j = 1, \dotsc, r,\) trong đó \(h_{j}, j = 1, \dotsc, r\) là lồi nhưng phi-affine,
được thay thế bằng \(h_{j}(x) \le 0, j = 1, \dotsc, r.\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Bằng cách biến đổi ràng buộc đẳng thức thành ràng buộc bất đẳng thức, kỹ thuật làm giản làm lỏng lọng các ràng buộc và mở rộng miền một cách hiệu quả. Khi các ràng buộc đẳng thức đã cho là lồi và phi-affine, phương pháp này có thể được sử dụng để tái công thức hóa bài toán thành một bài toán tối ưu hóa lồi. (Tuy nhiên, điều này dưới điều kiện rằng cùng một nghiệm vẫn hợp lệ ngay cả sau khi làm giản.)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>04-07 Biến phụ</title>
   <link href="http://localhost:4000/contents/vi/chapter04/04_07_Slack_variables/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/04_07_Slack_variables</id>
   <content type="html">&lt;h1 id=&quot;biến-phụ-trong-tối-ưu-hóa-lồi&quot;&gt;Biến Phụ trong Tối ưu hóa Lồi&lt;/h1&gt;

&lt;h2 id=&quot;giới-thiệu-và-động-lực&quot;&gt;Giới thiệu và Động lực&lt;/h2&gt;

&lt;p&gt;Biến phụ là các biến phụ trợ được giới thiệu để biến đổi ràng buộc bất đẳng thức thành ràng buộc đẳng thức. Biến đổi này là cơ bản trong lý thuyết tối ưu hóa và có ứng dụng thực tế trong quy hoạch tuyến tính, các phương pháp điểm trong, và nhiều thuật toán tối ưu hóa.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tại sao chúng ta cần biến phụ?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Nhiều thuật toán tối ưu hóa được thiết kế để xử lý ràng buộc đẳng thức hiệu quả hơn&lt;/li&gt;
  &lt;li&gt;Chúng cung cấp giải thích hình học về mức độ “chặt” của ràng buộc&lt;/li&gt;
  &lt;li&gt;Chúng thiết yếu trong phương pháp simplex cho quy hoạch tuyến tính&lt;/li&gt;
  &lt;li&gt;Chúng giúp trong lý thuyết đối ngẫu và phân tích độ nhạy&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;công-thức-toán-học&quot;&gt;Công thức Toán học&lt;/h2&gt;

&lt;p&gt;Xem xét bài toán tối ưu hóa lồi tiêu chuẩn:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_x &amp;amp;&amp;amp;f(x) \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;g_{i}(x) \leq 0, \quad i = 1, \ldots, m\\
&amp;amp;&amp;amp;&amp;amp;Ax = b
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;Bằng cách giới thiệu &lt;strong&gt;biến phụ&lt;/strong&gt; \(s_i \geq 0\) cho mỗi ràng buộc bất đẳng thức, chúng ta có thể tái công thức hóa thành:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_{x, s} &amp;amp;&amp;amp;f(x)\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;s_{i} \geq 0, \quad i = 1, \ldots, m\\
&amp;amp;&amp;amp;&amp;amp;g_{i}(x) + s_{i} = 0, \quad i = 1, \ldots, m\\
&amp;amp;&amp;amp;&amp;amp;Ax = b
\end{aligned}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;giải-thích-hình-học&quot;&gt;Giải thích Hình học&lt;/h2&gt;

&lt;p&gt;Biến phụ \(s_i\) biểu diễn “khoảng trống” hoặc “biên độ” trong ràng buộc thứ \(i\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(s_i &amp;gt; 0\)&lt;/strong&gt;: Ràng buộc \(g_i(x) \leq 0\) &lt;strong&gt;không hoạt động&lt;/strong&gt; (không ràng buộc)
    &lt;ul&gt;
      &lt;li&gt;Điểm \(x\) nằm trong phần trong của vùng khả thi được định nghĩa bởi ràng buộc \(i\)&lt;/li&gt;
      &lt;li&gt;Chúng ta có \(g_i(x) = -s_i &amp;lt; 0\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(s_i = 0\)&lt;/strong&gt;: Ràng buộc \(g_i(x) \leq 0\) &lt;strong&gt;hoạt động&lt;/strong&gt; (ràng buộc)
    &lt;ul&gt;
      &lt;li&gt;Điểm \(x\) nằm chính xác trên biên được định nghĩa bởi \(g_i(x) = 0\)&lt;/li&gt;
      &lt;li&gt;Ràng buộc này “chặt” tại nghiệm tối ưu&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ví-dụ-thực-tế-phân-bổ-tài-nguyên&quot;&gt;Ví dụ Thực tế: Phân bổ Tài nguyên&lt;/h2&gt;

&lt;p&gt;Xem xét một bài toán phân bổ tài nguyên đơn giản:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bài toán Gốc:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\max &amp;amp;&amp;amp;3x_1 + 2x_2 \\
&amp;amp;\text{thỏa mãn} &amp;amp;&amp;amp;x_1 + x_2 \leq 4 \quad \text{(giờ lao động)}\\
&amp;amp;&amp;amp;&amp;amp;2x_1 + x_2 \leq 6 \quad \text{(đơn vị nguyên liệu)}\\
&amp;amp;&amp;amp;&amp;amp;x_1, x_2 \geq 0
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Với Biến Phụ:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\max &amp;amp;&amp;amp;3x_1 + 2x_2 \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;x_1 + x_2 + s_1 = 4\\
&amp;amp;&amp;amp;&amp;amp;2x_1 + x_2 + s_2 = 6\\
&amp;amp;&amp;amp;&amp;amp;x_1, x_2, s_1, s_2 \geq 0
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Giải thích:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(s_1\): giờ lao động chưa sử dụng&lt;/li&gt;
  &lt;li&gt;\(s_2\): đơn vị nguyên liệu chưa sử dụng&lt;/li&gt;
  &lt;li&gt;Nếu \(s_1 = 0\) tại tối ưu: tất cả lao động được sử dụng&lt;/li&gt;
  &lt;li&gt;Nếu \(s_2 &amp;gt; 0\) tại tối ưu: một số nguyên liệu vẫn chưa được sử dụng&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;các-tính-chất-và-cân-nhắc-quan-trọng&quot;&gt;Các Tính chất và Cân nhắc Quan trọng&lt;/h2&gt;

&lt;h3 id=&quot;1-tương-đương-của-các-bài-toán&quot;&gt;1. Tương đương của các Bài toán&lt;/h3&gt;
&lt;p&gt;Các công thức gốc và biến phụ là &lt;strong&gt;tương đương về mặt toán học&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Cùng giá trị mục tiêu tối ưu&lt;/li&gt;
  &lt;li&gt;\(x^*\) tối ưu giống nhau trong cả hai công thức&lt;/li&gt;
  &lt;li&gt;Các biến phụ \(s_i^*\) tại tối ưu cho chúng ta biết ràng buộc nào hoạt động&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-bảo-toàn-tính-lồi&quot;&gt;2. Bảo toàn Tính lồi&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Lưu ý Quan trọng:&lt;/strong&gt; Biến đổi bảo toàn tính lồi &lt;strong&gt;chỉ khi&lt;/strong&gt; \(g_i(x)\) là &lt;strong&gt;hàm affine&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Nếu \(g_i(x) = a_i^T x - b_i\) (affine)&lt;/strong&gt;: Bài toán tái công thức vẫn lồi&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nếu \(g_i(x)\) là phi tuyến&lt;/strong&gt;: Ràng buộc đẳng thức \(g_i(x) + s_i = 0\) có thể phá hủy tính lồi&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-tác-động-độ-phức-tạp&quot;&gt;3. Tác động Độ phức tạp&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Bài toán gốc: \(n\) biến&lt;/li&gt;
  &lt;li&gt;Với biến phụ: \(n + m\) biến&lt;/li&gt;
  &lt;li&gt;Đánh đổi: nhiều biến hơn nhưng cấu trúc ràng buộc đơn giản hơn&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ví-dụ-chuyển-đổi-chương-trình-tuyến-tính&quot;&gt;Ví dụ: Chuyển đổi Chương trình Tuyến tính&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Dạng Gốc:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min &amp;amp;&amp;amp;c^T x \\
&amp;amp;\text{thỏa mãn} &amp;amp;&amp;amp;Ax \leq b\\
&amp;amp;&amp;amp;&amp;amp;x \geq 0
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Dạng Tiêu chuẩn với Biến Phụ:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min &amp;amp;&amp;amp;c^T x \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;Ax + s = b\\
&amp;amp;&amp;amp;&amp;amp;x, s \geq 0
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;Trong đó \(s \in \mathbb{R}^m\) là vector của các biến phụ.&lt;/p&gt;

&lt;h2 id=&quot;các-điểm-chính&quot;&gt;Các Điểm Chính&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Công cụ Biến đổi&lt;/strong&gt;: Biến phụ chuyển đổi bất đẳng thức thành đẳng thức&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ý nghĩa Hình học&lt;/strong&gt;: Chúng đo “mức độ chặt” của ràng buộc&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kích hoạt Thuật toán&lt;/strong&gt;: Thiết yếu cho nhiều thuật toán tối ưu hóa&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Điều kiện Lồi&lt;/strong&gt;: Chỉ bảo toàn tính lồi cho ràng buộc affine&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hiểu biết Thực tế&lt;/strong&gt;: Cung cấp giải thích kinh tế trong các bài toán tài nguyên&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hiểu về biến phụ là quan trọng cho:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Triển khai các thuật toán tối ưu hóa&lt;/li&gt;
  &lt;li&gt;Giải thích kết quả tối ưu hóa&lt;/li&gt;
  &lt;li&gt;Phân tích độ nhạy ràng buộc&lt;/li&gt;
  &lt;li&gt;Kết nối lý thuyết với thực hành tính toán&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>04-06 Loại bỏ ràng buộc đẳng thức</title>
   <link href="http://localhost:4000/contents/vi/chapter04/04_06_Eliminating_equality_constraints/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/04_06_Eliminating_equality_constraints</id>
   <content type="html">&lt;p&gt;Phần này giải thích các kỹ thuật loại bỏ ràng buộc đẳng thức trong các bài toán tối ưu hóa lồi để đơn giản hóa tập khả thi hoặc cấu trúc bài toán.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x)\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;g_{i}(x) \leq 0, i = 1, .., m\\
&amp;amp;&amp;amp;&amp;amp;{Ax = b}.\\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;Đối với một nghiệm tùy ý \(x_{0}\) thỏa mãn \(Ax_{0} = b\) và \(\text{col}(M) = \text{null}(A)\), bất kỳ \(x\) nào thỏa mãn ràng buộc đẳng thức có thể được biểu diễn như sau:&lt;/p&gt;
&lt;blockquote&gt;
\[x = My + x_{0}\]
&lt;/blockquote&gt;

&lt;p&gt;Tức là, \(Ax = A(My + x_{0}) = AMy + Ax_{0} = 0 + b = b\). Do đó, bằng cách thay thế \(My+x_{0}\) cho \(x\) trong bài toán đã cho, chúng ta có thể loại bỏ ràng buộc đẳng thức.&lt;/p&gt;

&lt;p&gt;Vậy, bài toán sau tương đương với bài toán gốc:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_y &amp;amp;&amp;amp;f(My+x_0)\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;g_{i}(My+x_{0}) \leq 0, i = 1, .., m.\\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;Tuy nhiên, cần thận trọng khi sử dụng phương pháp này vì các lý do sau:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Việc tính toán \(M\) nói chung rất đắt đỏ.&lt;/li&gt;
  &lt;li&gt;Nếu \(x\) thưa hơn \(y\), chi phí tính toán sử dụng \(y\) có thể cao hơn.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>04-05 Biến đổi và thay đổi biến</title>
   <link href="http://localhost:4000/contents/vi/chapter04/04_05_Transformations_and_change_of_variables/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/04_05_Transformations_and_change_of_variables</id>
   <content type="html">&lt;p&gt;Phần này thảo luận về các biến đổi và thay đổi biến trong các bài toán tối ưu hóa lồi, hữu ích cho việc đơn giản hóa hoặc tái công thức hóa bài toán.&lt;/p&gt;

&lt;p&gt;Hàm mục tiêu hoặc các hàm ràng buộc có thể được sửa đổi trong khi vẫn bảo toàn bài toán tối ưu hóa đã cho, và đôi khi điều này có thể được sử dụng để khám phá “tính lồi ẩn” của bài toán.&lt;/p&gt;

&lt;h3 id=&quot;định-lý-1&quot;&gt;Định lý 1&lt;/h3&gt;
&lt;p&gt;Khi hàm \(h : \mathbb{R} \rightarrow \mathbb{R}\) là một biến đổi đơn điệu tăng, mối quan hệ sau được thỏa mãn:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
  &amp;amp;\text{min}_{x} f(x) \text{ subject to } x \in C \\
  \Longleftrightarrow \quad &amp;amp;\text{min}_{x} h(f(x)) \text{ subject to } x \in C
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;định-lý-2&quot;&gt;Định lý 2&lt;/h3&gt;
&lt;p&gt;Nếu hàm \(\phi: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\) là hàm tương ứng một-một và ảnh của \(\phi\) bao phủ tập khả thi \(C\), thì các biến của bài toán tối ưu hóa có thể được thay đổi như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} f(x) \text{ subject to } x \in C \\\\ 
   \Longleftrightarrow \quad &amp;amp;\min_{y} f(\phi(y)) \text{ subject to } \phi(y) \in C
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;ví-dụ-quy-hoạch-hình-học&quot;&gt;Ví dụ: quy hoạch hình học&lt;/h3&gt;

&lt;p&gt;Một hàm \(f: \mathbb{R}_{++}^n \rightarrow \mathbb{R}\) có dạng sau được gọi là &lt;strong&gt;đơn thức&lt;/strong&gt; (monomial):&lt;/p&gt;
&lt;blockquote&gt;
\[f(x) = \gamma x_{1}^{a_{1}} x_{2}^{a_{2}} \dotsb x_{n}^{a_{n}} \text{ với } \gamma &amp;gt; 0, a_{1}, \dotsc, a_{n} \in \mathbb{R}.\]
&lt;/blockquote&gt;

&lt;p&gt;Ngoài ra, tổng của các đơn thức được gọi là &lt;strong&gt;đa thức dương&lt;/strong&gt; (posynomial):&lt;/p&gt;
&lt;blockquote&gt;
\[g(x) = \sum_{k=1}^{p} \gamma_{k} x_{1}^{a_{k1}} x_{2}^{a_{k2}} \dotsb x_{n}^{a_{kn}} \text{ với } \gamma &amp;gt; 0, a\_1, \dotsc, a_{n} \in \mathbb{R}.\]
&lt;/blockquote&gt;

&lt;p&gt;Một &lt;strong&gt;chương trình hình học&lt;/strong&gt; được định nghĩa dưới dạng sau và là một bài toán không lồi:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;g_{i}(x) \leq 1, i = 1, \dotsc, m\\
&amp;amp;&amp;amp;&amp;amp;h_{j}(x) = 1, j = 1, \dotsc, r,\\\\
\end{align}\\\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;trong đó \(f\), \(g_{i}, i=1, \dotsc, m\) là các đa thức dương và \(h_{j}, j=1, \dotsc, r\) là các đơn thức.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hãy chứng minh rằng một chương trình hình học tương đương với một bài toán lồi nào đó.&lt;/p&gt;

&lt;h3 id=&quot;chứng-minh&quot;&gt;Chứng minh:&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Đối với \(f(x) = \gamma x_{1}^{a_{1}} x_{2}^{a_{2}} \dotsb x_{n}^{a_{n}}\), nếu chúng ta đặt \(y_{i} = \log x_{i}\) và \(b = \log \gamma\), thì \(f\) có thể được biến đổi như sau, và theo &lt;strong&gt;Định lý 2&lt;/strong&gt;, điều này bảo toàn bài toán tối ưu hóa đã cho một cách tương đương:
\(\gamma (e^{y_{1}})^{a_{1}} (e^{y_{2}})^{a_{2}} \dotsb (e^{y_{n}})^{a_{n}} = e^{a^Ty + b}\)&lt;/p&gt;

  &lt;p&gt;Ngoài ra, một đa thức dương có thể được biểu diễn như \(\sum_{k=1}^{p} e^{a_{k}^{Ty} + b_{k}}\).&lt;/p&gt;

  &lt;p&gt;Tại thời điểm này, theo &lt;strong&gt;Định lý 1&lt;/strong&gt;, dạng logarit \(\log \big( \sum_{k=1}^{p} e^{a_{k}^{Ty} + b_{k}} \big)\) cũng có thể bảo toàn bài toán tối ưu hóa một cách tương đương.&lt;/p&gt;

  &lt;p&gt;Tức là, chương trình hình học tương đương với bài toán sau, đây là một bài toán lồi:&lt;/p&gt;

\[\begin{align}
&amp;amp;\min_{x} \quad &amp;amp;&amp;amp;{log \big( \sum_{k=1}^{p_{0}} e^{a_{0k}^{Ty} + b_{0k}} \big)} \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;{
         log \big( \sum_{k=1}^{p_{i}} e^{a_{ik}^{Ty} + b_{ik}} \big)
         \leq 0
         , \quad i = 1, \dotsc, m
}\\
&amp;amp;&amp;amp;&amp;amp;c_{j}^{Ty} + d_{j} = 0, \quad j = 1, \dotsc, r\\\\
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>04-04 Tối ưu hóa từng phần</title>
   <link href="http://localhost:4000/contents/vi/chapter04/04_04_Partial_optimization/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/04_04_Partial_optimization</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;/contents/vi/chapter03/03_02_operations_that_preserve_convexity/&quot;&gt;Nhắc lại: &lt;/a&gt;
Nếu \(C\) là tập lồi và \(f\) lồi theo \((x,y)\), thì \(g(x) = \min_{y \in C} f(x, y)\) lồi theo \(x\).&lt;/p&gt;

&lt;p&gt;Vậy, tối ưu hóa từng phần trong một bài toán lồi được xây dựng với các hàm nhiều biến bảo toàn tính lồi.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter04/partial-optimization.png&quot; alt=&quot;[Fig1] partial optimization of a convex problem [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Tối ưu hóa từng phần của một bài toán lồi [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ví-dụ-dạng-hinge-của-svm&quot;&gt;Ví dụ: Dạng hinge của SVM&lt;/h3&gt;
&lt;p&gt;Đối với tập không tách được, bài toán SVM được định nghĩa như:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_{\beta, \beta_{0}, \xi} &amp;amp;&amp;amp;\frac{1}{2}\|\beta\|_2^2 + C \sum_{i=1}^{n} \xi_{i} \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;{\xi}_{i} \ge 0, \\ 
&amp;amp;&amp;amp;&amp;amp;y_{i}(x_{i}^T \beta + \beta_{0}) \ge 1 - {\xi}_{i}, \\
&amp;amp;&amp;amp;&amp;amp;i = 1, .., n \\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;Các ràng buộc trên có thể được biểu diễn thành một ràng buộc duy nhất:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
{\xi}_{i} \ge \max\{0, 1 - y_{i} (x_{i}^T \beta + \beta_{0})\} \\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;Trong trường hợp này, \(\max\{0, 1 - y_{i} (x_{i}^T \beta + \beta_{0})\}\) là giá trị nhỏ nhất cho \(\xi_{i}\), và chúng ta có thể định nghĩa \(\tilde{f}\) như:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
\frac{1}{2} \|\beta\|_{2}^{2} + C \sum_{i=1}^{n} {\xi}_{i} &amp;amp;\ge \frac{1}{2} \|\beta\|_{2}^{2} + C \sum_{i=1}^{n} \max({0, 1 - y_{i} (x_{i}^T \beta + \beta_{0})})\\
&amp;amp;= \min\{\frac{1}{2} \|\beta\|_{2}^{2} + C \sum_{i=1}^{n} \xi_{i} \quad | \quad \xi_{i} \ge 0, \ y_{i}(x_{i}^T \beta + \beta_{0}) \ge 1 - \xi_{i}, \ i = 1, .., n\} \\
&amp;amp;= \tilde{f}(\beta, \beta_{0}) \\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;Bằng cách sử dụng \(\tilde{f}\) được đơn giản hóa làm hàm mục tiêu, một nghiệm đơn giản hơn có thể được thu được. Trong bài toán đã cho, \(\xi\) đã bị loại bỏ, và nó cũng đã được chuyển đổi từ bài toán có ràng buộc thành bài toán không ràng buộc.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
\min_{\beta, \beta_0} \frac{1}{2} \|\beta\|_2^2 + C \sum_{i=1}^{n} \max\{0, 1 - y_{i} (x_{i}^{T} \beta + \beta_{0}) \}
\end{aligned}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>04-03 Điều kiện tối ưu</title>
   <link href="http://localhost:4000/contents/vi/chapter04/04_03_Optimality_conditions/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/04_03_Optimality_conditions</id>
   <content type="html">&lt;h2 id=&quot;điều-kiện-tối-ưu-bậc-nhất&quot;&gt;Điều kiện tối ưu bậc nhất&lt;/h2&gt;

&lt;p&gt;Để tìm hiểu thêm về hàm lồi, xem &lt;a href=&quot;#post-not-found&quot;&gt;Chương 3: Các Tính chất Chính của Hàm Lồi&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_x &amp;amp;&amp;amp;f(x) \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;x \in C
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;Đối với một bài toán lồi mà hàm mục tiêu \(f\) &lt;strong&gt;khả vi&lt;/strong&gt;, điều kiện sau là cần và đủ cho một điểm tối ưu \(x\):&lt;/p&gt;

&lt;blockquote&gt;
\[\nabla f(x)^{T}(y-x) \geq 0 \\
\text{ với mọi } y \in C\]
&lt;/blockquote&gt;

&lt;p&gt;Đây được gọi là &lt;em&gt;điều kiện bậc nhất cho tính tối ưu&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;\(\nabla f(x)^{T}(y-x) = 0\) định nghĩa một siêu phẳng đi qua \(x\) trong tập \(C\), và \(- \nabla f(x)\) chỉ hướng di chuyển về phía điểm tối ưu \(x\). &lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Nếu điều kiện trên được thỏa mãn, 
tập \(C\) nằm trong nửa không gian đối diện với \(- \nabla f(x)\), 
nên \(x\) là một điểm tối ưu.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter04/first-order-condition.png&quot; alt=&quot;[Fig1] geometric interpretation of first-order condition for optimality [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Giải thích hình học về điều kiện bậc nhất cho tính tối ưu [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;trường-hợp-đặc-biệt-quan-trọng&quot;&gt;Trường hợp đặc biệt quan trọng&lt;/h3&gt;
&lt;p&gt;Khi \(C = \mathbb{R}^n\) (tối ưu hóa không ràng buộc),
điều kiện tối ưu là:&lt;/p&gt;
&lt;blockquote&gt;
\[\nabla f(x) = 0\]
&lt;/blockquote&gt;

&lt;p&gt;Trong trường hợp này, \(-\nabla f(x)\) chỉ về phía điểm tối ưu \(x\), và \(\nabla f(x) = 0\) có nghĩa là không còn hướng nào để di chuyển để giảm \(f\) tại \(x\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;nền-tảng-toán-học&quot;&gt;Nền tảng Toán học&lt;/h2&gt;

&lt;p&gt;Trong khi các điều kiện bậc nhất sờ dụng gradient \(\nabla f(x)\), các điều kiện bậc hai sử dụng &lt;strong&gt;ma trận Hessian&lt;/strong&gt;:&lt;/p&gt;

\[H_f(x) = \nabla^2 f(x) = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_2^2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}\]

&lt;p&gt;Ma trận Hessian nắm bắt &lt;strong&gt;độ cong&lt;/strong&gt; của hàm tại điểm \(x\), cung cấp thông tin về hình dạng cục bộ của hàm mục tiêu.&lt;/p&gt;

&lt;h2 id=&quot;điều-kiện-tối-ưu-bậc-hai&quot;&gt;Điều kiện Tối ưu Bậc Hai&lt;/h2&gt;

&lt;p&gt;Xem xét bài toán tối ưu hóa không ràng buộc:
\(\min_x f(x)\)&lt;/p&gt;

&lt;p&gt;trong đó \(f: \mathbb{R}^n \to \mathbb{R}\) khả vi liên tục bậc hai.&lt;/p&gt;

&lt;h3 id=&quot;điều-kiện-cần-bậc-hai&quot;&gt;Điều kiện Cần (Bậc Hai)&lt;/h3&gt;

&lt;p&gt;Nếu \(x^*\) là cực tiểu địa phương của \(f\), thì:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Điều kiện cần bậc nhất&lt;/strong&gt;: \(\nabla f(x^*) = 0\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Điều kiện cần bậc hai&lt;/strong&gt;: \(\nabla^2 f(x^*) \succeq 0\) (nửa xác định dương)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;điều-kiện-đủ-bậc-hai&quot;&gt;Điều kiện Đủ (Bậc Hai)&lt;/h3&gt;

&lt;p&gt;Nếu tại điểm \(x^*\):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(\nabla f(x^*) = 0\) (điều kiện bậc nhất)&lt;/li&gt;
  &lt;li&gt;\(\nabla^2 f(x^*) \succ 0\) (xác định dương)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thì \(x^*\) là &lt;strong&gt;cực tiểu địa phương chặt&lt;/strong&gt; của \(f\).&lt;/p&gt;

&lt;h2 id=&quot;hiểu-về-tính-xác-định-dương&quot;&gt;Hiểu về Tính Xác Định Dương&lt;/h2&gt;

&lt;p&gt;Một ma trận đối xứng \(A\) là:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Xác định dương&lt;/strong&gt; (\(A \succ 0\)) nếu \(v^T A v &amp;gt; 0\) với mọi \(v \neq 0\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nửa xác định dương&lt;/strong&gt; (\(A \succeq 0\)) nếu \(v^T A v \geq 0\) với mọi \(v\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Các kiểm tra thực tế cho tính xác định dương:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Kiểm tra giá trị riêng&lt;/strong&gt;: Tất cả giá trị riêng đều dương&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Thứ định thức chính&lt;/strong&gt;: Tất cả thứ định thức chính đều dương&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phân tích Cholesky&lt;/strong&gt;: \(A = L L^T\) tồn tại với \(L\) tam giác dưới&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;giải-thích-hình-học&quot;&gt;Giải thích Hình học&lt;/h2&gt;

&lt;p&gt;Các điều kiện bậc hai cung cấp thông tin về &lt;strong&gt;độ cong&lt;/strong&gt; tại điểm tới hạn:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(\nabla^2 f(x^*) \succ 0\)&lt;/strong&gt;: Hàm cong lên trên theo mọi hướng → &lt;strong&gt;cực tiểu địa phương chặt&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\nabla^2 f(x^*) \prec 0\)&lt;/strong&gt;: Hàm cong xuống dưới theo mọi hướng → &lt;strong&gt;cực đại địa phương chặt&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\nabla^2 f(x^*) \succeq 0\)&lt;/strong&gt;: Độ cong không âm → &lt;strong&gt;có thể là cực tiểu&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hessian bất định&lt;/strong&gt;: Độ cong hỗn hợp → &lt;strong&gt;điểm yên ngựa&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter04/second-order-conditions.png&quot; alt=&quot;Second-order optimality conditions visualization&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Giải thích hình học về các điều kiện bậc hai&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;các-ví-dụ-chi-tiết&quot;&gt;Các Ví dụ Chi tiết&lt;/h2&gt;

&lt;h3 id=&quot;ví-dụ-1-hàm-bậc-hai&quot;&gt;Ví dụ 1: Hàm Bậc Hai&lt;/h3&gt;
&lt;p&gt;Xem xét \(f(x_1, x_2) = x_1^2 + 2x_2^2 + x_1 x_2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bước 1: Tìm điểm tới hạn&lt;/strong&gt;
\(\nabla f(x) = \begin{bmatrix} 2x_1 + x_2 \\ 4x_2 + x_1 \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;Giải: \(x^* = (0, 0)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bước 2: Tính Hessian&lt;/strong&gt;
\(\nabla^2 f(x) = \begin{bmatrix} 2 &amp;amp; 1 \\ 1 &amp;amp; 4 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bước 3: Kiểm tra tính xác định dương&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Giá trị riêng: \(\lambda_1 = \frac{6 + \sqrt{12}}{2} &amp;gt; 0\), \(\lambda_2 = \frac{6 - \sqrt{12}}{2} &amp;gt; 0\)&lt;/li&gt;
  &lt;li&gt;Thứ định thức chính: \(2 &amp;gt; 0\), \(\det = 8 - 1 = 7 &amp;gt; 0\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Kết luận&lt;/strong&gt;: \(\nabla^2 f(0,0) \succ 0\) → \((0,0)\) là cực tiểu địa phương chặt.&lt;/p&gt;

&lt;h3 id=&quot;example-2-non-convex-function&quot;&gt;Example 2: Non-Convex Function&lt;/h3&gt;
&lt;p&gt;Consider \(f(x_1, x_2) = x_1^4 + x_2^4 - 2x_1^2 - 2x_2^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Find critical points&lt;/strong&gt;
\(\nabla f(x) = \begin{bmatrix} 4x_1^3 - 4x_1 \\ 4x_2^3 - 4x_2 \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;Critical points: \((0,0)\), \((\pm 1, 0)\), \((0, \pm 1)\), \((\pm 1, \pm 1)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2: Analyze \((0,0)\)&lt;/strong&gt;
\(\nabla^2 f(0,0) = \begin{bmatrix} -4 &amp;amp; 0 \\ 0 &amp;amp; -4 \end{bmatrix} \prec 0\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;: \((0,0)\) is a strict local maximum.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3: Analyze \((1,1)\)&lt;/strong&gt;
\(\nabla^2 f(1,1) = \begin{bmatrix} 8 &amp;amp; 0 \\ 0 &amp;amp; 8 \end{bmatrix} \succ 0\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;: \((1,1)\) is a strict local minimum.&lt;/p&gt;

&lt;h3 id=&quot;example-3-saddle-point&quot;&gt;Example 3: Saddle Point&lt;/h3&gt;
&lt;p&gt;Consider \(f(x_1, x_2) = x_1^2 - x_2^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analysis at \((0,0)\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\nabla f(0,0) = (0,0)\) ✓&lt;/li&gt;
  &lt;li&gt;\(\nabla^2 f(0,0) = \begin{bmatrix} 2 &amp;amp; 0 \\ 0 &amp;amp; -2 \end{bmatrix}\) (indefinite)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;: \((0,0)\) is a saddle point (neither minimum nor maximum).&lt;/p&gt;

&lt;h2 id=&quot;constrained-optimization-second-order-conditions&quot;&gt;Constrained Optimization: Second-Order Conditions&lt;/h2&gt;

&lt;p&gt;For constrained problems:
\(\min_x f(x) \text{ subject to } h_i(x) = 0, \, i = 1,\ldots,m\)&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;bordered Hessian&lt;/strong&gt; of the Lagrangian is used:
\(\mathcal{L}(x,\lambda) = f(x) + \sum_{i=1}^m \lambda_i h_i(x)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Second-order sufficient condition&lt;/strong&gt;: The bordered Hessian has the correct inertia (number of negative eigenvalues equals the number of constraints).&lt;/p&gt;

&lt;h2 id=&quot;comparison-first-vs-second-order-conditions&quot;&gt;Comparison: First vs Second-Order Conditions&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Aspect&lt;/th&gt;
      &lt;th&gt;First-Order&lt;/th&gt;
      &lt;th&gt;Second-Order&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Information&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Gradient (slope)&lt;/td&gt;
      &lt;td&gt;Hessian (curvature)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Necessary condition&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(\nabla f(x^*) = 0\)&lt;/td&gt;
      &lt;td&gt;\(\nabla f(x^*) = 0\) and \(\nabla^2 f(x^*) \succeq 0\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Sufficient condition&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Not available for unconstrained&lt;/td&gt;
      &lt;td&gt;\(\nabla f(x^*) = 0\) and \(\nabla^2 f(x^*) \succ 0\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Strength&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Weaker&lt;/td&gt;
      &lt;td&gt;Stronger&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Computational cost&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(O(n)\)&lt;/td&gt;
      &lt;td&gt;\(O(n^2)\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Distinguishes&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Critical points&lt;/td&gt;
      &lt;td&gt;Minima, maxima, saddle points&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;interactive-visualization&quot;&gt;Interactive Visualization&lt;/h2&gt;

&lt;p&gt;Explore how second-order conditions work in practice:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 20px 0;&quot;&gt;
    &lt;a href=&quot;../second_order_conditions_interactive.html&quot; target=&quot;_blank&quot; style=&quot;display: inline-block; padding: 12px 24px; background-color: #e74c3c; color: white; text-decoration: none; border-radius: 6px; font-weight: bold; box-shadow: 0 2px 4px rgba(0,0,0,0.2);&quot;&gt;
        🎯 Khởi động Công cụ Khám phá Điều kiện Bậc Hai
    &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;Công cụ tương tác minh họa:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Phân tích giá trị riêng Hessian&lt;/strong&gt; cho các loại hàm khác nhau&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phân loại trực quan&lt;/strong&gt; các điểm tới hạn (cực tiểu, cực đại, yên ngựa)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Đồ thị đường đẳng mức&lt;/strong&gt; hiển thị hành vi độ cong cục bộ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tính toán từng bước&lt;/strong&gt; cho các kiểm tra bậc hai&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tóm-tắt-và-các-điểm-chính&quot;&gt;Tóm tắt và Các Điểm Chính&lt;/h2&gt;

&lt;p&gt;Các điều kiện tối ưu bậc hai cung cấp &lt;strong&gt;đặc trưng mạnh hơn&lt;/strong&gt; cho các điểm tối ưu:&lt;/p&gt;

&lt;h3 id=&quot;kết-quả-chính&quot;&gt;&lt;strong&gt;Kết quả Chính:&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Điều kiện cần&lt;/strong&gt;: \(\nabla f(x^*) = 0\) và \(\nabla^2 f(x^*) \succeq 0\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Điều kiện đủ&lt;/strong&gt;: \(\nabla f(x^*) = 0\) và \(\nabla^2 f(x^*) \succ 0\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Khả năng phân loại&lt;/strong&gt;: Có thể phân biệt giữa cực tiểu, cực đại và điểm yên ngựa&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;tầm-quan-trọng-thực-tế&quot;&gt;&lt;strong&gt;Tầm quan trọng Thực tế:&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Thiết kế thuật toán&lt;/strong&gt;: Nền tảng cho các phương pháp kiểu Newton&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Phân tích tính lồi&lt;/strong&gt;: Thiết yếu cho việc xác minh hàm lồi&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tính bền vững&lt;/strong&gt;: Đảm bảo mạnh hơn so với chỉ các điều kiện bậc nhất&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lý thuyết tối ưu hóa&lt;/strong&gt;: Cầu nối giữa tính tối ưu địa phương và toàn cục&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cân-nhắc-tính-toán&quot;&gt;&lt;strong&gt;Cân nhắc Tính toán:&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Chi phí&lt;/strong&gt;: Lưu trữ và tính toán \(O(n^2)\) cho Hessian&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Xấp xỉ&lt;/strong&gt;: Các phương pháp Quasi-Newton giảm gánh nặng tính toán&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ổn định số&lt;/strong&gt;: Tính toán giá trị riêng yêu cầu triển khai cẩn thận&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hiểu về các điều kiện bậc hai là thiết yếu cho lý thuyết tối ưu hóa nâng cao và phát triển các thuật toán số hiệu quả. Chúng cung cấp nền tảng toán học cho nhiều phương pháp tối ưu hóa hiện đại và đưa ra các hiểu biết sâu sắc hơn về cấu trúc của các bài toán tối ưu hóa.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>04-02 Tập nghiệm lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter04/04_02_Convex_solution_sets/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/04_02_Convex_solution_sets</id>
   <content type="html">&lt;p&gt;Hãy cùng tìm hiểu các tính chất của tập nghiệm lồi. &lt;br /&gt;
Gọi \(X_{opt}\) là tập nghiệm của một bài toán lồi:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
X_{opt} =
&amp;amp;\text{arg}\min_x &amp;amp;&amp;amp;f(x) \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;g_{i}(x) \leq 0, i = 1, .., m \\
&amp;amp;&amp;amp;&amp;amp;h_{j}(x) = 0, j = 1, .., r  \\\\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;tính-chất-chính-1&quot;&gt;Tính chất chính 1&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(X_{opt}\) là một tập lồi.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;chứng-minh&quot;&gt;Chứng minh&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;Nếu \(x\) và \(y\) là các nghiệm:&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;Tập miền \(D\) là lồi, nên với \(0 \le t \le 1\), \(tx+ (1-t)y \in D\).&lt;/li&gt;
    &lt;li&gt;\(g_i, i=1,\dotsc,m\) và \(h_j, j=1, \dotsc,r\) là các hàm lồi và affine, nên các điều kiện sau được thỏa mãn:
 \(\begin{aligned}
    g_{i}(tx + (1-t)y) \leq tg_i(x) + (1-t)g_i(y) \leq 0, \\
    h_{j}(tx + (1-t)y) = th_j(x) + (1-t)h_j(y) = 0 \\
 \end{aligned}\)&lt;/li&gt;
    &lt;li&gt;\(f\) là hàm lồi, nên:
      &lt;blockquote&gt;

        &lt;p&gt;\begin{aligned}
 f(tx+(1-t)y) &amp;amp;\leq tf(x) + (1-t)f(y) &lt;br /&gt;
 = tf^{\star} + (1-t) f^{\star} &lt;br /&gt;
 = f^{\star}
\end{aligned}
trong đó \(f^{\star}\) là giá trị nhỏ nhất.
Vậy, \(tx + (1-t)y\) cũng là một nghiệm.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;giải-thích-hình-học&quot;&gt;Giải thích hình học&lt;/h3&gt;
&lt;p&gt;Trong một hàm lồi, bất kỳ cực trị địa phương nào cũng là cực trị toàn cục. &lt;br /&gt;
Nếu tập nghiệm chứa nhiều phần tử, nó phải có dạng như sau:&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter04/multiple-optima.png&quot; alt=&quot;[Fig1] geometric interpretation of convexity of the solution set&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Giải thích hình học về tính lồi của tập nghiệm&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tính-chất-chính-2&quot;&gt;Tính chất chính 2&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;Nếu \(f\) là hàm lồi chặt, thì nghiệm là duy nhất. Tức là, \(X_{opt}\) chỉ chứa một phần tử.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;\(f\) là hàm lồi chặt có nghĩa là \(f\) luôn thỏa mãn tính chất sau:&lt;/p&gt;
&lt;blockquote&gt;
\[f(tx + (1-t)y) &amp;lt; tf(x) + (1-t)f(y),\]

\[\text{trong đó } 0 &amp;lt; t &amp;lt; 1, x \neq y, \text{ và } x, y \in \text{dom } f.\]
&lt;/blockquote&gt;

&lt;p&gt;Tức là, \(f\) là hàm lồi hướng xuống không có đoạn phẳng, và nghiệm của \(f\) là duy nhất.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>04-01 Thuật ngữ cơ bản</title>
   <link href="http://localhost:4000/contents/vi/chapter04/04_01_Basic_terminology/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/04_01_Basic_terminology</id>
   <content type="html">&lt;h2 id=&quot;cơ-bản-về-tối-ưu-hóa-lồi&quot;&gt;Cơ bản về Tối ưu hóa Lồi&lt;/h2&gt;

&lt;p&gt;Hãy cùng ôn tập các thuật ngữ cơ bản được sử dụng trong các bài toán tối ưu hóa lồi. Một bài toán tối ưu hóa lồi được định nghĩa như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\text{minimize}_{x \in D} &amp;amp;&amp;amp;{f(x)} \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;{g_{i}(x) \leq 0, \quad i = 1, \dotsc, m} \\
&amp;amp;&amp;amp;&amp;amp;{h_{j}(x) = 0, \quad j = 1, \dotsc, r},\\\\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;trong đó \(f\) và \(g_{i}\), \(i=1,\dotsc, m\) đều là hàm lồi,
\(h_j, j = 1, \dotsc, r\) đều là hàm affine,
và miền tối ưu hóa là \(D = dom(f) \cap \bigcap_{i=1}^{m} dom(g_{i}) \cap  \bigcap_{j=1}^r dom(h_{j})\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;\(f\) được gọi là &lt;strong&gt;hàm tiêu chí&lt;/strong&gt; hoặc &lt;strong&gt;hàm mục tiêu&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;\(g_{i}(x)\) được gọi là &lt;strong&gt;hàm ràng buộc bất đẳng thức&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;\(h_{j}(x)\) được gọi là &lt;strong&gt;hàm ràng buộc đẳng thức&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Nếu \(x \in D\) và \(g_{i}(x) \leq 0\) với mọi \(i\) và \(h_{j}(x) = 0\) với mọi \(j\), thì \(x\) là một &lt;strong&gt;điểm khả thi&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Với tất cả các điểm khả thi \(x\), giá trị nhỏ nhất của \(f(x)\) được gọi là &lt;strong&gt;giá trị tối ưu&lt;/strong&gt;, ký hiệu là \(f^{\star}\).&lt;/li&gt;
  &lt;li&gt;Nếu \(x\) khả thi và \(f(x) = f^{\star}\), thì \(x\) được gọi là &lt;strong&gt;tối ưu&lt;/strong&gt;, một &lt;strong&gt;nghiệm&lt;/strong&gt;, hoặc một &lt;strong&gt;điểm cực tiểu&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Nếu \(x\) khả thi và \(f(x) \le f^{\star} + \epsilon\), thì \(x\) được gọi là &lt;strong&gt;\(\epsilon\)-dưới tối ưu&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Nếu \(x\) khả thi và \(g_i(x) = 0\), thì \(g_i\) &lt;strong&gt;hoạt động&lt;/strong&gt; tại \(x\).&lt;/li&gt;
  &lt;li&gt;Một bài toán cực tiểu hóa lồi có thể được chuyển đổi thành bài toán cực đại hóa lõm.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\text{maximize}_{x \in D} &amp;amp;&amp;amp;-f(x)\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;g_{i}(x) \leq 0, i = 1, .., m\\
&amp;amp;&amp;amp;&amp;amp;h_{j}(x) = 0, j = 1, \dotsc, r,\\\\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;trong đó \(f\) và \(g_{i}\), \(i=1,\dotsc, m\) đều là hàm lồi,
\(h_j, j = 1, \dotsc, r\) đều là hàm affine,
và miền tối ưu hóa là \(D = dom(f) \cap \bigcap_{i=1}^{m} dom(g_{i}) \cap  \bigcap_{j=1}^r dom(h_{j})\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;tập-khả-thi&quot;&gt;Tập Khả thi&lt;/h3&gt;

&lt;p&gt;Tập khả thi (còn được gọi là miền khả thi hoặc không gian nghiệm) là tập hợp tất cả các điểm khả thi. Nó biểu diễn tất cả các lựa chọn được phép bởi các điều kiện của bài toán.&lt;/p&gt;

&lt;p&gt;Tập khả thi, thường được ký hiệu bởi \(S\) hoặc \(\mathcal{F}\), được định nghĩa như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[S = \{ \mathbf{x} \in X \mid g_i(\mathbf{x}) \le 0 \text{ với mọi } i=1, \dots, m, \text{ và } h_j(\mathbf{x}) = 0 \text{ với mọi } j=1, \dots, r \}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;tính-chất-của-tập-khả-thi&quot;&gt;Tính chất của Tập Khả thi&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Tính lồi:&lt;/strong&gt; Nếu tất cả các hàm ràng buộc bất đẳng thức $g_i(\mathbf{x})$ đều lồi và tất cả các hàm ràng buộc đẳng thức $h_j(\mathbf{x})$ đều affine (tuyến tính), thì tập khả thi $S$ là một &lt;strong&gt;tập lồi&lt;/strong&gt;. Tính chất này rất quan trọng trong tối ưu hóa lồi, vì nó đảm bảo rằng bất kỳ cực trị địa phương nào cũng là cực trị toàn cục.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tính bị chặn:&lt;/strong&gt; Một tập khả thi có thể &lt;strong&gt;bị chặn&lt;/strong&gt; (được bao quanh trong một vùng hữu hạn) hoặc &lt;strong&gt;không bị chặn&lt;/strong&gt; (mở rộng vô hạn theo một hướng nào đó).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tập rỗng:&lt;/strong&gt; Có thể tập khả thi là tập rỗng ($S = \emptyset$). Điều này có nghĩa là không có điểm nào thỏa mãn tất cả các ràng buộc đã cho, và bài toán tối ưu hóa được gọi là &lt;strong&gt;không khả thi&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Đa diện/Đa hình&lt;/strong&gt; (&lt;strong&gt;Polytope/Polyhedron&lt;/strong&gt;): Trong quy hoạch tuyến tính, nếu tập khả thi khác rỗng và bị chặn, nó được gọi là &lt;strong&gt;đa diện&lt;/strong&gt; (polytope). Nếu nó khác rỗng nhưng có thể không bị chặn, nó được gọi là &lt;strong&gt;đa hình&lt;/strong&gt; (polyhedron). Cả hai đều là tập lồi.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Đỉnh (Điểm cực trị):&lt;/strong&gt; Đối với các bài toán quy hoạch tuyến tính, nếu một nghiệm tối ưu tồn tại, nó luôn có thể được tìm thấy tại một trong các đỉnh (còn được gọi là điểm cực trị hoặc điểm góc) của tập khả thi. Đây là cơ sở cho các thuật toán như phương pháp Simplex.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>04 Cơ bản về tối ưu hóa lồi</title>
   <link href="http://localhost:4000/contents/vi/chapter04/04_00_Convex_optimization_basics/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/04_00_Convex_optimization_basics</id>
   <content type="html">&lt;h2 id=&quot;cơ-bản-về-tối-ưu-hóa-lồi&quot;&gt;Cơ bản về Tối ưu hóa Lồi&lt;/h2&gt;

&lt;p&gt;Chương này giới thiệu các tính chất chính của các bài toán lồi và một số kỹ thuật thường được sử dụng để giải chúng.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>04-08 Relaxation</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_08_Relaxation/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter04/04_08_Relaxation</id>
   <content type="html">&lt;p&gt;This section discusses relaxation techniques, which are used to simplify or approximate convex optimization problems by relaxing constraints.&lt;/p&gt;

&lt;p&gt;Consider a problem of the form:&lt;/p&gt;
&lt;blockquote&gt;
\[\text{min}_{x} \text{ } f(x) \text{  subject to  } x \in C\]
&lt;/blockquote&gt;

&lt;p&gt;The process of changing the domain set \(C\) to a superset \(\tilde{C} \supseteq C\) is known as &lt;em&gt;Relaxation&lt;/em&gt;.&lt;/p&gt;
&lt;blockquote&gt;
\[\text{min}_{x} \text{ } f(x) \text{  subject to  } x \in \tilde{C}\]
&lt;/blockquote&gt;

&lt;p&gt;Since we are optimizing over a larger domain set than \(C\), the optimal value of the relaxed problem is always less than or equal to that of the original problem.&lt;/p&gt;

&lt;h3 id=&quot;important-special-case-relaxing-non-affine-equality-constraints&quot;&gt;Important special case: relaxing non-affine equality constraints&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(h_{j}(x) = 0, j = 1, \dotsc, r,\) where \(h_{j}, j = 1, \dotsc, r\) are convex but non-affine,
are replaced with \(h_{j}(x) \le 0, j = 1, \dotsc, r.\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;By transforming equality constraints into inequality constraints, the relaxation technique loosens the constraints and effectively enlarges the domain. When the given equality constraints are convex and non-affine, this method can be used to reformulate the problem as a convex optimization problem. (However, this is under the condition that the same solution is still valid even after the relaxation.)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>04-07 Slack variables</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_07_Slack_variables/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter04/04_07_Slack_variables</id>
   <content type="html">&lt;h1 id=&quot;slack-variables-in-convex-optimization&quot;&gt;Slack Variables in Convex Optimization&lt;/h1&gt;

&lt;h2 id=&quot;introduction-and-motivation&quot;&gt;Introduction and Motivation&lt;/h2&gt;

&lt;p&gt;Slack variables are auxiliary variables introduced to transform inequality constraints into equality constraints. This transformation is fundamental in optimization theory and has practical applications in linear programming, interior-point methods, and many optimization algorithms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why do we need slack variables?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Many optimization algorithms are designed to handle equality constraints more efficiently&lt;/li&gt;
  &lt;li&gt;They provide a geometric interpretation of how “tight” a constraint is&lt;/li&gt;
  &lt;li&gt;They are essential in the simplex method for linear programming&lt;/li&gt;
  &lt;li&gt;They help in duality theory and sensitivity analysis&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mathematical-formulation&quot;&gt;Mathematical Formulation&lt;/h2&gt;

&lt;p&gt;Consider the standard convex optimization problem:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_x &amp;amp;&amp;amp;f(x) \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;g_{i}(x) \leq 0, \quad i = 1, \ldots, m\\
&amp;amp;&amp;amp;&amp;amp;Ax = b
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;By introducing &lt;strong&gt;slack variables&lt;/strong&gt; \(s_i \geq 0\) for each inequality constraint, we can reformulate this as:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_{x, s} &amp;amp;&amp;amp;f(x)\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;s_{i} \geq 0, \quad i = 1, \ldots, m\\
&amp;amp;&amp;amp;&amp;amp;g_{i}(x) + s_{i} = 0, \quad i = 1, \ldots, m\\
&amp;amp;&amp;amp;&amp;amp;Ax = b
\end{aligned}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h2&gt;

&lt;p&gt;The slack variable \(s_i\) represents the “slack” or “margin” in the \(i\)-th constraint:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(s_i &amp;gt; 0\)&lt;/strong&gt;: The constraint \(g_i(x) \leq 0\) is &lt;strong&gt;inactive&lt;/strong&gt; (not binding)
    &lt;ul&gt;
      &lt;li&gt;The point \(x\) is in the interior of the feasible region defined by constraint \(i\)&lt;/li&gt;
      &lt;li&gt;We have \(g_i(x) = -s_i &amp;lt; 0\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(s_i = 0\)&lt;/strong&gt;: The constraint \(g_i(x) \leq 0\) is &lt;strong&gt;active&lt;/strong&gt; (binding)
    &lt;ul&gt;
      &lt;li&gt;The point \(x\) lies exactly on the boundary defined by \(g_i(x) = 0\)&lt;/li&gt;
      &lt;li&gt;This constraint is “tight” at the optimal solution&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;practical-example-resource-allocation&quot;&gt;Practical Example: Resource Allocation&lt;/h2&gt;

&lt;p&gt;Consider a simple resource allocation problem:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Original Problem:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\max &amp;amp;&amp;amp;3x_1 + 2x_2 \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;x_1 + x_2 \leq 4 \quad \text{(labor hours)}\\
&amp;amp;&amp;amp;&amp;amp;2x_1 + x_2 \leq 6 \quad \text{(material units)}\\
&amp;amp;&amp;amp;&amp;amp;x_1, x_2 \geq 0
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;With Slack Variables:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\max &amp;amp;&amp;amp;3x_1 + 2x_2 \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;x_1 + x_2 + s_1 = 4\\
&amp;amp;&amp;amp;&amp;amp;2x_1 + x_2 + s_2 = 6\\
&amp;amp;&amp;amp;&amp;amp;x_1, x_2, s_1, s_2 \geq 0
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Interpretation:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(s_1\): unused labor hours&lt;/li&gt;
  &lt;li&gt;\(s_2\): unused material units&lt;/li&gt;
  &lt;li&gt;If \(s_1 = 0\) at optimum: all labor is utilized&lt;/li&gt;
  &lt;li&gt;If \(s_2 &amp;gt; 0\) at optimum: some material remains unused&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;important-properties-and-considerations&quot;&gt;Important Properties and Considerations&lt;/h2&gt;

&lt;h3 id=&quot;1-equivalence-of-problems&quot;&gt;1. Equivalence of Problems&lt;/h3&gt;
&lt;p&gt;The original and slack variable formulations are &lt;strong&gt;mathematically equivalent&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Same optimal objective value&lt;/li&gt;
  &lt;li&gt;Optimal \(x^*\) is the same in both formulations&lt;/li&gt;
  &lt;li&gt;The slack variables \(s_i^*\) at optimum tell us which constraints are active&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-convexity-preservation&quot;&gt;2. Convexity Preservation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Critical Note:&lt;/strong&gt; The transformation preserves convexity &lt;strong&gt;only when&lt;/strong&gt; \(g_i(x)\) are &lt;strong&gt;affine functions&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;If \(g_i(x) = a_i^T x - b_i\) (affine)&lt;/strong&gt;: The reformulated problem remains convex&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;If \(g_i(x)\) is nonlinear&lt;/strong&gt;: The equality constraint \(g_i(x) + s_i = 0\) may destroy convexity&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-dimensionality-impact&quot;&gt;3. Dimensionality Impact&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Original problem: \(n\) variables&lt;/li&gt;
  &lt;li&gt;With slack variables: \(n + m\) variables&lt;/li&gt;
  &lt;li&gt;Trade-off: more variables but simpler constraint structure&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;example-converting-a-linear-program&quot;&gt;Example: Converting a Linear Program&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Original Form:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min &amp;amp;&amp;amp;c^T x \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;Ax \leq b\\
&amp;amp;&amp;amp;&amp;amp;x \geq 0
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Standard Form with Slack Variables:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min &amp;amp;&amp;amp;c^T x \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;Ax + s = b\\
&amp;amp;&amp;amp;&amp;amp;x, s \geq 0
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;Where \(s \in \mathbb{R}^m\) is the vector of slack variables.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Transformation Tool&lt;/strong&gt;: Slack variables convert inequalities to equalities&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Geometric Meaning&lt;/strong&gt;: They measure constraint “tightness”&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Algorithm Enabler&lt;/strong&gt;: Essential for many optimization algorithms&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Convexity Condition&lt;/strong&gt;: Preserve convexity only for affine constraints&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Practical Insight&lt;/strong&gt;: Provide economic interpretation in resource problems&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Understanding slack variables is crucial for:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Implementing optimization algorithms&lt;/li&gt;
  &lt;li&gt;Interpreting optimization results&lt;/li&gt;
  &lt;li&gt;Analyzing constraint sensitivity&lt;/li&gt;
  &lt;li&gt;Connecting theory with computational practice&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>04-06 Eliminating equality constraints</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_06_Eliminating_equality_constraints/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter04/04_06_Eliminating_equality_constraints</id>
   <content type="html">&lt;p&gt;This section explains techniques for eliminating equality constraints in convex optimization problems to simplify the feasible set or problem structure.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x)\\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;g_{i}(x) \leq 0, i = 1, .., m\\
&amp;amp;&amp;amp;&amp;amp;{Ax = b}.\\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;For an arbitrary solution \(x_{0}\) satisfying \(Ax_{0} = b\) and \(\text{col}(M) = \text{null}(A)\), any \(x\) that satisfies the equality constraint can be expressed as follows:&lt;/p&gt;
&lt;blockquote&gt;
\[x = My + x_{0}\]
&lt;/blockquote&gt;

&lt;p&gt;That is, \(Ax = A(My + x_{0}) = AMy + Ax_{0} = 0 + b = b\). Therefore, by substituting \(My+x_{0}\) for \(x\) in the given problem, we can eliminate the equality constraint.&lt;/p&gt;

&lt;p&gt;Thus, the following problem is equivalent to the original problem:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_y &amp;amp;&amp;amp;f(My+x_0)\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;g_{i}(My+x_{0}) \leq 0, i = 1, .., m.\\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;However, caution is advised when using this method for the following reasons:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The computation of \(M\) is generally very expensive.&lt;/li&gt;
  &lt;li&gt;If \(x\) is sparser than \(y\), the cost of computation using \(y\) may be higher.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>04-05 Transformations and change of variables</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_05_Transformations_and_change_of_variables/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter04/04_05_Transformations_and_change_of_variables</id>
   <content type="html">&lt;p&gt;This section discusses transformations and change of variables in convex optimization problems, which are useful for simplifying or reformulating problems.&lt;/p&gt;

&lt;p&gt;The objective function or constraint functions can be modified while preserving the given optimization problem, and sometimes this can be used to discover the “hidden convexity” of the problem.&lt;/p&gt;

&lt;h3 id=&quot;theorem-1&quot;&gt;Theorem 1&lt;/h3&gt;
&lt;p&gt;When function \(h : \mathbb{R} \rightarrow \mathbb{R}\) is a monotone increasing transformation, the following relationship holds:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
  &amp;amp;\text{min}_{x} f(x) \text{ subject to } x \in C \\
  \Longleftrightarrow \quad &amp;amp;\text{min}_{x} h(f(x)) \text{ subject to } x \in C
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;theorem-2&quot;&gt;Theorem 2&lt;/h3&gt;
&lt;p&gt;If function \(\phi: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\) is a one-to-one correspondence function and the image of \(\phi\) covers the feasible set \(C\), then the variables of the optimization problem can be changed as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
   &amp;amp;\min_{x} f(x) \text{ subject to } x \in C \\\\ 
   \Longleftrightarrow \quad &amp;amp;\min_{y} f(\phi(y)) \text{ subject to } \phi(y) \in C
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;example-geometric-programming&quot;&gt;Example: geometric programming&lt;/h3&gt;

&lt;p&gt;A function \(f: \mathbb{R}_{++}^n \rightarrow \mathbb{R}\) of the following form is called a &lt;strong&gt;monomial&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
\[f(x) = \gamma x_{1}^{a_{1}} x_{2}^{a_{2}} \dotsb x_{n}^{a_{n}} \text{ for } \gamma &amp;gt; 0, a_{1}, \dotsc, a_{n} \in \mathbb{R}.\]
&lt;/blockquote&gt;

&lt;p&gt;Also, the sum of monomials is called a &lt;strong&gt;posynomial&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
\[g(x) = \sum_{k=1}^{p} \gamma_{k} x_{1}^{a_{k1}} x_{2}^{a_{k2}} \dotsb x_{n}^{a_{kn}} \text{ for } \gamma &amp;gt; 0, a\_1, \dotsc, a_{n} \in \mathbb{R}.\]
&lt;/blockquote&gt;

&lt;p&gt;A &lt;strong&gt;geometric program&lt;/strong&gt; is defined in the following form and is a non-convex problem:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
&amp;amp;\min_{x} &amp;amp;&amp;amp;f(x) \\
&amp;amp;\text{subject to } &amp;amp;&amp;amp;g_{i}(x) \leq 1, i = 1, \dotsc, m\\
&amp;amp;&amp;amp;&amp;amp;h_{j}(x) = 1, j = 1, \dotsc, r,\\\\
\end{align}\\\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;where \(f\), \(g_{i}, i=1, \dotsc, m\) are posynomials and \(h_{j}, j=1, \dotsc, r\) are monomials.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let’s prove that a geometric program is equivalent to some convex problem.&lt;/p&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof:&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;For \(f(x) = \gamma x_{1}^{a_{1}} x_{2}^{a_{2}} \dotsb x_{n}^{a_{n}}\), if we let \(y_{i} = \log x_{i}\) and \(b = \log \gamma\), then \(f\) can be transformed as follows, and by &lt;strong&gt;Theorem 2&lt;/strong&gt;, this preserves the given optimization problem equivalently:
\(\gamma (e^{y_{1}})^{a_{1}} (e^{y_{2}})^{a_{2}} \dotsb (e^{y_{n}})^{a_{n}} = e^{a^Ty + b}\)&lt;/p&gt;

  &lt;p&gt;Also, a posynomial can be represented as \(\sum_{k=1}^{p} e^{a_{k}^{Ty} + b_{k}}\).&lt;/p&gt;

  &lt;p&gt;At this point, by &lt;strong&gt;Theorem 1&lt;/strong&gt;, the logarithmic form \(\log \big( \sum_{k=1}^{p} e^{a_{k}^{Ty} + b_{k}} \big)\) can also preserve the optimization problem equivalently.&lt;/p&gt;

  &lt;p&gt;That is, the geometric program is equivalent to the following problem, which is a convex problem:&lt;/p&gt;

\[\begin{align}
&amp;amp;\min_{x} \quad &amp;amp;&amp;amp;{log \big( \sum_{k=1}^{p_{0}} e^{a_{0k}^{Ty} + b_{0k}} \big)} \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;{
         log \big( \sum_{k=1}^{p_{i}} e^{a_{ik}^{Ty} + b_{ik}} \big)
         \leq 0
         , \quad i = 1, \dotsc, m
}\\
&amp;amp;&amp;amp;&amp;amp;c_{j}^{Ty} + d_{j} = 0, \quad j = 1, \dotsc, r\\\\
\end{align}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>04-04 Partial optimization</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_04_Partial_optimization/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter04/04_04_Partial_optimization</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;/contents/en/chapter03/03_02_operations_that_preserve_convexity/&quot;&gt;Reminder: &lt;/a&gt;
If \(C\) is a convex set and \(f\) is convex in \((x,y)\), then \(g(x) = \min_{y \in C} f(x, y)\) is convex in \(x\).&lt;/p&gt;

&lt;p&gt;Thus, partial optimization in a convex problem constructed with multivariate functions preserves convexity.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter04/partial-optimization.png&quot; alt=&quot;[Fig1] partial optimization of a convex problem [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] partial optimization of a convex problem [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;example-hinge-form-of-svms&quot;&gt;Example: hinge form of SVMs&lt;/h3&gt;
&lt;p&gt;For a non-separable set, the SVM problem is defined as:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_{\beta, \beta_{0}, \xi} &amp;amp;&amp;amp;\frac{1}{2}\|\beta\|_2^2 + C \sum_{i=1}^{n} \xi_{i} \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;{\xi}_{i} \ge 0, \\ 
&amp;amp;&amp;amp;&amp;amp;y_{i}(x_{i}^T \beta + \beta_{0}) \ge 1 - {\xi}_{i}, \\
&amp;amp;&amp;amp;&amp;amp;i = 1, .., n \\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;The above constraints can be expressed as a single constraint:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{aligned}
{\xi}_{i} \ge \max\{0, 1 - y_{i} (x_{i}^T \beta + \beta_{0})\} \\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;In this case, \(\max\{0, 1 - y_{i} (x_{i}^T \beta + \beta_{0})\}\) is the minimum value for \(\xi_{i}\), and we can define \(\tilde{f}\) as:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
\frac{1}{2} \|\beta\|_{2}^{2} + C \sum_{i=1}^{n} {\xi}_{i} &amp;amp;\ge \frac{1}{2} \|\beta\|_{2}^{2} + C \sum_{i=1}^{n} \max({0, 1 - y_{i} (x_{i}^T \beta + \beta_{0})})\\
&amp;amp;= \min\{\frac{1}{2} \|\beta\|_{2}^{2} + C \sum_{i=1}^{n} \xi_{i} \quad | \quad \xi_{i} \ge 0, \ y_{i}(x_{i}^T \beta + \beta_{0}) \ge 1 - \xi_{i}, \ i = 1, .., n\} \\
&amp;amp;= \tilde{f}(\beta, \beta_{0}) \\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;By using the simplified \(\tilde{f}\) as the objective function, a more straightforward solution can be obtained. In the given problem, \(\xi\) has been eliminated, and it has also been transformed from a constrained problem to an unconstrained problem.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
\min_{\beta, \beta_0} \frac{1}{2} \|\beta\|_2^2 + C \sum_{i=1}^{n} \max\{0, 1 - y_{i} (x_{i}^{T} \beta + \beta_{0}) \}
\end{aligned}\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>04-03 Optimality conditions</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_03_Optimality_conditions/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter04/04_03_Optimality_conditions</id>
   <content type="html">&lt;h2 id=&quot;first-order-optimality-condition&quot;&gt;First order optimality condition&lt;/h2&gt;

&lt;p&gt;For more background on convex functions, see &lt;a href=&quot;#post-not-found&quot;&gt;Chapter 3: Key Properties of Convex Functions&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\min_x &amp;amp;&amp;amp;f(x) \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;x \in C
\end{aligned}\]
&lt;/blockquote&gt;

&lt;p&gt;For a convex problem where the objective function \(f\) is &lt;strong&gt;differentiable&lt;/strong&gt;, the following condition is necessary and sufficient for an optimal point \(x\):&lt;/p&gt;

&lt;blockquote&gt;
\[\nabla f(x)^{T}(y-x) \geq 0 \\
\text{ for all } y \in C\]
&lt;/blockquote&gt;

&lt;p&gt;This is called the &lt;em&gt;first-order condition for optimality&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;\(\nabla f(x)^{T}(y-x) = 0\) defines a hyperplane passing through \(x\) in set \(C\), and \(- \nabla f(x)\) points in the direction of movement toward the optimal point \(x\). &lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;If the above condition is satisfied, 
set \(C\) is contained in the half-space opposite to \(- \nabla f(x)\), 
so \(x\) is an optimal point.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter04/first-order-condition.png&quot; alt=&quot;[Fig1] geometric interpretation of first-order condition for optimality [3]&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] geometric interpretation of first-order condition for optimality [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;important-special-case&quot;&gt;Important special case&lt;/h3&gt;
&lt;p&gt;When \(C = \mathbb{R}^n\) (unconstrained optimization),
the optimality condition is:&lt;/p&gt;
&lt;blockquote&gt;
\[\nabla f(x) = 0\]
&lt;/blockquote&gt;

&lt;p&gt;In this case, \(-\nabla f(x)\) points toward the optimal point \(x\), and \(\nabla f(x) = 0\) means there is no further direction to move to decrease \(f\) at \(x\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;mathematical-foundation&quot;&gt;Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;While first-order conditions use the gradient \(\nabla f(x)\), second-order conditions utilize the &lt;strong&gt;Hessian matrix&lt;/strong&gt;:&lt;/p&gt;

\[H_f(x) = \nabla^2 f(x) = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_2^2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}\]

&lt;p&gt;The Hessian captures the &lt;strong&gt;curvature&lt;/strong&gt; of the function at point \(x\), providing information about the local shape of the objective function.&lt;/p&gt;

&lt;h2 id=&quot;second-order-optimality-conditions&quot;&gt;Second-Order Optimality Conditions&lt;/h2&gt;

&lt;p&gt;Consider the unconstrained optimization problem:
\(\min_x f(x)\)&lt;/p&gt;

&lt;p&gt;where \(f: \mathbb{R}^n \to \mathbb{R}\) is twice continuously differentiable.&lt;/p&gt;

&lt;h3 id=&quot;necessary-conditions-second-order&quot;&gt;Necessary Conditions (Second-Order)&lt;/h3&gt;

&lt;p&gt;If \(x^*\) is a local minimum of \(f\), then:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;First-order necessary condition&lt;/strong&gt;: \(\nabla f(x^*) = 0\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second-order necessary condition&lt;/strong&gt;: \(\nabla^2 f(x^*) \succeq 0\) (positive semidefinite)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;sufficient-conditions-second-order&quot;&gt;Sufficient Conditions (Second-Order)&lt;/h3&gt;

&lt;p&gt;If at point \(x^*\):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;\(\nabla f(x^*) = 0\) (first-order condition)&lt;/li&gt;
  &lt;li&gt;\(\nabla^2 f(x^*) \succ 0\) (positive definite)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Then \(x^*\) is a &lt;strong&gt;strict local minimum&lt;/strong&gt; of \(f\).&lt;/p&gt;

&lt;h2 id=&quot;understanding-positive-definiteness&quot;&gt;Understanding Positive Definiteness&lt;/h2&gt;

&lt;p&gt;A symmetric matrix \(A\) is:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Positive definite&lt;/strong&gt; (\(A \succ 0\)) if \(v^T A v &amp;gt; 0\) for all \(v \neq 0\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Positive semidefinite&lt;/strong&gt; (\(A \succeq 0\)) if \(v^T A v \geq 0\) for all \(v\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Practical tests for positive definiteness:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Eigenvalue test&lt;/strong&gt;: All eigenvalues are positive&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Leading principal minors&lt;/strong&gt;: All leading principal minors are positive&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cholesky decomposition&lt;/strong&gt;: \(A = L L^T\) exists with \(L\) lower triangular&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h2&gt;

&lt;p&gt;The second-order conditions provide information about the &lt;strong&gt;curvature&lt;/strong&gt; at the critical point:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;\(\nabla^2 f(x^*) \succ 0\)&lt;/strong&gt;: The function curves upward in all directions → &lt;strong&gt;strict local minimum&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\nabla^2 f(x^*) \prec 0\)&lt;/strong&gt;: The function curves downward in all directions → &lt;strong&gt;strict local maximum&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;\(\nabla^2 f(x^*) \succeq 0\)&lt;/strong&gt;: Non-negative curvature → &lt;strong&gt;possible minimum&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Indefinite Hessian&lt;/strong&gt;: Mixed curvature → &lt;strong&gt;saddle point&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter04/second-order-conditions.png&quot; alt=&quot;Second-order optimality conditions visualization&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
 &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Geometric interpretation of second-order conditions&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;detailed-examples&quot;&gt;Detailed Examples&lt;/h2&gt;

&lt;h3 id=&quot;example-1-quadratic-function&quot;&gt;Example 1: Quadratic Function&lt;/h3&gt;
&lt;p&gt;Consider \(f(x_1, x_2) = x_1^2 + 2x_2^2 + x_1 x_2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Find critical points&lt;/strong&gt;
\(\nabla f(x) = \begin{bmatrix} 2x_1 + x_2 \\ 4x_2 + x_1 \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;Solving: \(x^* = (0, 0)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2: Compute Hessian&lt;/strong&gt;
\(\nabla^2 f(x) = \begin{bmatrix} 2 &amp;amp; 1 \\ 1 &amp;amp; 4 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3: Check positive definiteness&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Eigenvalues: \(\lambda_1 = \frac{6 + \sqrt{12}}{2} &amp;gt; 0\), \(\lambda_2 = \frac{6 - \sqrt{12}}{2} &amp;gt; 0\)&lt;/li&gt;
  &lt;li&gt;Leading principal minors: \(2 &amp;gt; 0\), \(\det = 8 - 1 = 7 &amp;gt; 0\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;: \(\nabla^2 f(0,0) \succ 0\) → \((0,0)\) is a strict local minimum.&lt;/p&gt;

&lt;h3 id=&quot;example-2-non-convex-function&quot;&gt;Example 2: Non-Convex Function&lt;/h3&gt;
&lt;p&gt;Consider \(f(x_1, x_2) = x_1^4 + x_2^4 - 2x_1^2 - 2x_2^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Find critical points&lt;/strong&gt;
\(\nabla f(x) = \begin{bmatrix} 4x_1^3 - 4x_1 \\ 4x_2^3 - 4x_2 \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;Critical points: \((0,0)\), \((\pm 1, 0)\), \((0, \pm 1)\), \((\pm 1, \pm 1)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2: Analyze \((0,0)\)&lt;/strong&gt;
\(\nabla^2 f(0,0) = \begin{bmatrix} -4 &amp;amp; 0 \\ 0 &amp;amp; -4 \end{bmatrix} \prec 0\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;: \((0,0)\) is a strict local maximum.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3: Analyze \((1,1)\)&lt;/strong&gt;
\(\nabla^2 f(1,1) = \begin{bmatrix} 8 &amp;amp; 0 \\ 0 &amp;amp; 8 \end{bmatrix} \succ 0\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;: \((1,1)\) is a strict local minimum.&lt;/p&gt;

&lt;h3 id=&quot;example-3-saddle-point&quot;&gt;Example 3: Saddle Point&lt;/h3&gt;
&lt;p&gt;Consider \(f(x_1, x_2) = x_1^2 - x_2^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analysis at \((0,0)\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\nabla f(0,0) = (0,0)\) ✓&lt;/li&gt;
  &lt;li&gt;\(\nabla^2 f(0,0) = \begin{bmatrix} 2 &amp;amp; 0 \\ 0 &amp;amp; -2 \end{bmatrix}\) (indefinite)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;: \((0,0)\) is a saddle point (neither minimum nor maximum).&lt;/p&gt;

&lt;h2 id=&quot;constrained-optimization-second-order-conditions&quot;&gt;Constrained Optimization: Second-Order Conditions&lt;/h2&gt;

&lt;p&gt;For constrained problems:
\(\min_x f(x) \text{ subject to } h_i(x) = 0, \, i = 1,\ldots,m\)&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;bordered Hessian&lt;/strong&gt; of the Lagrangian is used:
\(\mathcal{L}(x,\lambda) = f(x) + \sum_{i=1}^m \lambda_i h_i(x)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Second-order sufficient condition&lt;/strong&gt;: The bordered Hessian has the correct inertia (number of negative eigenvalues equals the number of constraints).&lt;/p&gt;

&lt;h2 id=&quot;comparison-first-vs-second-order-conditions&quot;&gt;Comparison: First vs Second-Order Conditions&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Aspect&lt;/th&gt;
      &lt;th&gt;First-Order&lt;/th&gt;
      &lt;th&gt;Second-Order&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Information&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Gradient (slope)&lt;/td&gt;
      &lt;td&gt;Hessian (curvature)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Necessary condition&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(\nabla f(x^*) = 0\)&lt;/td&gt;
      &lt;td&gt;\(\nabla f(x^*) = 0\) and \(\nabla^2 f(x^*) \succeq 0\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Sufficient condition&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Not available for unconstrained&lt;/td&gt;
      &lt;td&gt;\(\nabla f(x^*) = 0\) and \(\nabla^2 f(x^*) \succ 0\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Strength&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Weaker&lt;/td&gt;
      &lt;td&gt;Stronger&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Computational cost&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;\(O(n)\)&lt;/td&gt;
      &lt;td&gt;\(O(n^2)\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Distinguishes&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Critical points&lt;/td&gt;
      &lt;td&gt;Minima, maxima, saddle points&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;interactive-visualization&quot;&gt;Interactive Visualization&lt;/h2&gt;

&lt;p&gt;Explore how second-order conditions work in practice:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin: 20px 0;&quot;&gt;
    &lt;a href=&quot;../second_order_conditions_interactive.html&quot; target=&quot;_blank&quot; style=&quot;display: inline-block; padding: 12px 24px; background-color: #e74c3c; color: white; text-decoration: none; border-radius: 6px; font-weight: bold; box-shadow: 0 2px 4px rgba(0,0,0,0.2);&quot;&gt;
        🎯 Launch Second-Order Conditions Explorer
    &lt;/a&gt;
&lt;/div&gt;

&lt;p&gt;The interactive tool demonstrates:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Hessian eigenvalue analysis&lt;/strong&gt; for different function types&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Visual classification&lt;/strong&gt; of critical points (minimum, maximum, saddle)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Contour plots&lt;/strong&gt; showing local curvature behavior&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step-by-step calculations&lt;/strong&gt; for second-order tests&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary-and-key-takeaways&quot;&gt;Summary and Key Takeaways&lt;/h2&gt;

&lt;p&gt;Second-order optimality conditions provide &lt;strong&gt;stronger characterization&lt;/strong&gt; of optimal points:&lt;/p&gt;

&lt;h3 id=&quot;key-results&quot;&gt;&lt;strong&gt;Key Results:&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Necessary conditions&lt;/strong&gt;: \(\nabla f(x^*) = 0\) and \(\nabla^2 f(x^*) \succeq 0\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sufficient conditions&lt;/strong&gt;: \(\nabla f(x^*) = 0\) and \(\nabla^2 f(x^*) \succ 0\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Classification power&lt;/strong&gt;: Can distinguish between minima, maxima, and saddle points&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;practical-importance&quot;&gt;&lt;strong&gt;Practical Importance:&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Algorithm design&lt;/strong&gt;: Foundation for Newton-type methods&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Convexity analysis&lt;/strong&gt;: Essential for verifying convex functions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Robustness&lt;/strong&gt;: Stronger guarantees than first-order conditions alone&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Optimization theory&lt;/strong&gt;: Bridge between local and global optimality&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;computational-considerations&quot;&gt;&lt;strong&gt;Computational Considerations:&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Cost&lt;/strong&gt;: \(O(n^2)\) storage and computation for Hessian&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Approximation&lt;/strong&gt;: Quasi-Newton methods reduce computational burden&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Numerical stability&lt;/strong&gt;: Eigenvalue computations require careful implementation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Understanding second-order conditions is essential for advanced optimization theory and the development of efficient numerical algorithms. They provide the mathematical foundation for many modern optimization methods and offer deeper insights into the structure of optimization problems.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>04-02 Convex solution sets</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_02_Convex_solution_sets/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter04/04_02_Convex_solution_sets</id>
   <content type="html">&lt;p&gt;Let’s understand the properties of convex solution sets. &lt;br /&gt;
Let \(X_{opt}\) denote the set of solutions to a convex problem:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
X_{opt} =
&amp;amp;\text{arg}\min_x &amp;amp;&amp;amp;f(x) \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;g_{i}(x) \leq 0, i = 1, .., m \\
&amp;amp;&amp;amp;&amp;amp;h_{j}(x) = 0, j = 1, .., r  \\\\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;h2 id=&quot;key-property-1&quot;&gt;Key property 1&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(X_{opt}\) is a convex set.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;If \(x\) and \(y\) are solutions:&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;The domain set \(D\) is convex, so for \(0 \le t \le 1\), \(tx+ (1-t)y \in D\).&lt;/li&gt;
    &lt;li&gt;\(g_i, i=1,\dotsc,m\) and \(h_j, j=1, \dotsc,r\) are convex and affine functions, so the following conditions hold:
 \(\begin{aligned}
    g_{i}(tx + (1-t)y) \leq tg_i(x) + (1-t)g_i(y) \leq 0, \\
    h_{j}(tx + (1-t)y) = th_j(x) + (1-t)h_j(y) = 0 \\
 \end{aligned}\)&lt;/li&gt;
    &lt;li&gt;\(f\) is a convex function, so:
      &lt;blockquote&gt;

        &lt;p&gt;\begin{aligned}
 f(tx+(1-t)y) &amp;amp;\leq tf(x) + (1-t)f(y) &lt;br /&gt;
 = tf^{\star} + (1-t) f^{\star} &lt;br /&gt;
 = f^{\star}
\end{aligned}
where \(f^{\star} -\) minimum value.
Thus, \(tx + (1-t)y\) is also a solution.&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric interpretation&lt;/h3&gt;
&lt;p&gt;In a convex function, any local optimum is also a global optimum. &lt;br /&gt;
If the solution set contains multiple elements, it must look like the following:&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter04/multiple-optima.png&quot; alt=&quot;[Fig1] geometric interpretation of convexity of the solution set&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] geometric interpretation of convexity of the solution set&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;key-property-2&quot;&gt;Key property 2&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;If \(f\) is strictly convex, then the solution is unique. That is, \(X_{opt}\) contains only one element.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;\(f\) being strictly convex means that \(f\) always satisfies the following property:&lt;/p&gt;
&lt;blockquote&gt;
\[f(tx + (1-t)y) &amp;lt; tf(x) + (1-t)f(y),\]

\[\text{where } 0 &amp;lt; t &amp;lt; 1, x \neq y, \text{ and } x, y \in \text{dom } f.\]
&lt;/blockquote&gt;

&lt;p&gt;That is, \(f\) is downward convex with no flat segments, and the solution of \(f\) is unique.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>04-01 Basic terminology</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_01_Basic_terminology/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter04/04_01_Basic_terminology</id>
   <content type="html">&lt;h2 id=&quot;convex-optimization-basics&quot;&gt;Convex Optimization Basics&lt;/h2&gt;

&lt;p&gt;Let’s review the basic terminology used in convex optimization problems. A convex optimization problem is defined as:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\text{minimize}_{x \in D} &amp;amp;&amp;amp;{f(x)} \\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;{g_{i}(x) \leq 0, \quad i = 1, \dotsc, m} \\
&amp;amp;&amp;amp;&amp;amp;{h_{j}(x) = 0, \quad j = 1, \dotsc, r},\\\\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;where \(f\) and \(g_{i}\), \(i=1,\dotsc, m\) are all convex,
\(h_j, j = 1, \dotsc, r\) are all affine,
and the optimization domain is \(D = dom(f) \cap \bigcap_{i=1}^{m} dom(g_{i}) \cap  \bigcap_{j=1}^r dom(h_{j})\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;\(f\) is called the &lt;strong&gt;criterion&lt;/strong&gt; or &lt;strong&gt;objective function&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;\(g_{i}(x)\) is called the &lt;strong&gt;inequality constraint function&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;\(h_{j}(x)\) is called the &lt;strong&gt;equality constraint function&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;If \(x \in D\) and \(g_{i}(x) \leq 0\) for all \(i\) and \(h_{j}(x) = 0\) for all \(j\), then \(x\) is a &lt;strong&gt;feasible point&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;For all feasible points \(x\), the minimum value of \(f(x)\) is called the &lt;strong&gt;optimal value&lt;/strong&gt;, denoted as \(f^{\star}\).&lt;/li&gt;
  &lt;li&gt;If \(x\) is feasible and \(f(x) = f^{\star}\), then \(x\) is called &lt;strong&gt;optimal&lt;/strong&gt;, a &lt;strong&gt;solution&lt;/strong&gt;, or a &lt;strong&gt;minimizer&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;If \(x\) is feasible and \(f(x) \le f^{\star} + \epsilon\), then \(x\) is called &lt;strong&gt;\(\epsilon\)-suboptimal&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;If \(x\) is feasible and \(g_i(x) = 0\), then \(g_i\) is &lt;strong&gt;active&lt;/strong&gt; at \(x\).&lt;/li&gt;
  &lt;li&gt;A convex minimization problem can be converted to a concave maximization problem.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\begin{aligned}
&amp;amp;\text{maximize}_{x \in D} &amp;amp;&amp;amp;-f(x)\\
&amp;amp;\text{subject to} &amp;amp;&amp;amp;g_{i}(x) \leq 0, i = 1, .., m\\
&amp;amp;&amp;amp;&amp;amp;h_{j}(x) = 0, j = 1, \dotsc, r,\\\\
\end{aligned}\]
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;where \(f\) and \(g_{i}\), \(i=1,\dotsc, m\) are all convex,
\(h_j, j = 1, \dotsc, r\) are all affine,
and the optimization domain is \(D = dom(f) \cap \bigcap_{i=1}^{m} dom(g_{i}) \cap  \bigcap_{j=1}^r dom(h_{j})\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;feasible-set&quot;&gt;Feasible Set&lt;/h3&gt;

&lt;p&gt;A feasible set (also known as a feasible region or solution space) is the set of all feasible points. It represents all the choices that are allowed by the problem’s conditions.&lt;/p&gt;

&lt;p&gt;The feasible set, often denoted by \(S\) or \(\mathcal{F}\), is defined as:&lt;/p&gt;

&lt;blockquote&gt;
\[S = \{ \mathbf{x} \in X \mid g_i(\mathbf{x}) \le 0 \text{ for all } i=1, \dots, m, \text{ and } h_j(\mathbf{x}) = 0 \text{ for all } j=1, \dots, r \}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;properties-of-feasible-sets&quot;&gt;Properties of Feasible Sets&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Convexity:&lt;/strong&gt; If all inequality constraint functions $g_i(\mathbf{x})$ are convex and all equality constraint functions $h_j(\mathbf{x})$ are affine (linear), then the feasible set $S$ is a &lt;strong&gt;convex set&lt;/strong&gt;. This property is crucial in convex optimization, as it guarantees that any local optimum is also a global optimum.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Boundedness:&lt;/strong&gt; A feasible set can be &lt;strong&gt;bounded&lt;/strong&gt; (enclosed within a finite region) or &lt;strong&gt;unbounded&lt;/strong&gt; (extending infinitely in some direction).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Empty Set:&lt;/strong&gt; It is possible for the feasible set to be empty ($S = \emptyset$). This means there are no points that satisfy all the given constraints, and the optimization problem is said to be &lt;strong&gt;infeasible&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Polytope/Polyhedron&lt;/strong&gt; (&lt;strong&gt;Đa hình / Đa diện&lt;/strong&gt;): In linear programming, if the feasible set is non-empty and bounded, it is called a &lt;strong&gt;polytope&lt;/strong&gt;. If it is non-empty but potentially unbounded, it is called a &lt;strong&gt;polyhedron&lt;/strong&gt;. Both are convex sets.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Vertices (Extreme Points):&lt;/strong&gt; For linear programming problems, if an optimal solution exists, it can always be found at one of the vertices (also known as extreme points or corner points) of the feasible set. This is the basis for algorithms like the Simplex method.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>04 Convex optimization basics</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_00_Convex_optimization_basics/"/>
   <updated>2020-02-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter04/04_00_Convex_optimization_basics</id>
   <content type="html">&lt;h2 id=&quot;convex-optimization-basics&quot;&gt;Convex Optimization Basics&lt;/h2&gt;

&lt;p&gt;This chapter introduces the main properties of convex problems and several techniques commonly used in solving them.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Phương pháp gradient gần kề và tăng tốc</title>
   <link href="http://localhost:4000/contents/vi/chapter09/09_proximal_gradient_descent_and_acceleration/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/09_proximal_gradient_descent_and_acceleration</id>
   <content type="html">&lt;h1 id=&quot;phương-pháp-gradient-gần-kề-và-tăng-tốc&quot;&gt;Phương pháp gradient gần kề và tăng tốc&lt;/h1&gt;

&lt;p&gt;Chương này giới thiệu phương pháp gradient gần kề và các kỹ thuật tăng tốc cho các bài toán tối ưu liên quan đến các hàm tổng hợp.&lt;/p&gt;

&lt;h2 id=&quot;tổng-quan&quot;&gt;Tổng quan&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Phương pháp gradient gần kề được sử dụng cho các bài toán trong đó hàm mục tiêu có thể được tách thành một phần khả vi và một phần không khả vi.&lt;/li&gt;
  &lt;li&gt;Các phương pháp tăng tốc, chẳng hạn như tăng tốc của Nesterov và FISTA, có thể cải thiện tốc độ hội tụ.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cấu-trúc&quot;&gt;Cấu trúc&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Phần 1: Phương pháp gradient gần kề&lt;/li&gt;
  &lt;li&gt;Phần 2: Phân tích hội tụ&lt;/li&gt;
  &lt;li&gt;Phần 3: Ví dụ hoàn thiện ma trận&lt;/li&gt;
  &lt;li&gt;Phần 4: Các trường hợp đặc biệt&lt;/li&gt;
  &lt;li&gt;Phần 5: Các phương pháp tăng tốc&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tham khảo từng phần để biết chi tiết và các công thức toán học.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09-05 Tăng tốc</title>
   <link href="http://localhost:4000/contents/vi/chapter09/09_05_acceleration/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/09_05_acceleration</id>
   <content type="html">&lt;h1 id=&quot;tăng-tốc&quot;&gt;Tăng tốc&lt;/h1&gt;

&lt;p&gt;Các kỹ thuật tăng tốc được sử dụng để tăng tốc sự hội tụ của các thuật toán tối ưu. Trong bối cảnh của các phương pháp gradient gần kề, tăng tốc có thể cải thiện đáng kể tốc độ tìm ra giải pháp.&lt;/p&gt;

&lt;h2 id=&quot;tăng-tốc-của-nesterov&quot;&gt;Tăng tốc của Nesterov&lt;/h2&gt;
&lt;p&gt;Tăng tốc của Nesterov là một kỹ thuật phổ biến giới thiệu động lượng vào các bước cập nhật, cho phép thuật toán di chuyển nhanh hơn về phía điểm tối ưu.&lt;/p&gt;

&lt;h2 id=&quot;fista&quot;&gt;FISTA&lt;/h2&gt;
&lt;p&gt;FISTA (Thuật toán Ngưỡng-Co lặp Nhanh) là một phương pháp gradient gần kề tăng tốc đạt được tốc độ hội tụ \(O(1/k^2)\).&lt;/p&gt;

&lt;h2 id=&quot;cân-nhắc-thực-tế&quot;&gt;Cân nhắc thực tế&lt;/h2&gt;
&lt;p&gt;Mặc dù tăng tốc có thể cải thiện hội tụ, nó cũng có thể gây ra mất ổn định hoặc dao động trong một số trường hợp. Quan trọng là giám sát hành vi của thuật toán và điều chỉnh các tham số khi cần thiết.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09-05-04 Tăng tốc có luôn hữu ích không?</title>
   <link href="http://localhost:4000/contents/vi/chapter09/09_05_04_is_acceleration_always_useful/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/09_05_04_is_acceleration_always_useful</id>
   <content type="html">&lt;h1 id=&quot;tăng-tốc-có-luôn-hữu-ích-không&quot;&gt;Tăng tốc có luôn hữu ích không?&lt;/h1&gt;

&lt;p&gt;Các phương pháp tăng tốc như FISTA có thể đạt được tốc độ hội tụ nhanh hơn về mặt lý thuyết, nhưng trong thực tế, tăng tốc không luôn có lợi.&lt;/p&gt;

&lt;h2 id=&quot;khi-nào-tăng-tốc-có-thể-không-giúp-được&quot;&gt;Khi nào tăng tốc có thể không giúp được&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Nếu bài toán có điều kiện xấu, tăng tốc có thể gây dao động hoặc mất ổn định.&lt;/li&gt;
  &lt;li&gt;Đối với một số bài toán không trơn, tăng tốc có thể không cải thiện hội tụ.&lt;/li&gt;
  &lt;li&gt;Hiện tượng “gợn sóng Nesterov” có thể gây ra hành vi không đơn điệu trong giá trị hàm mục tiêu.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lời-khuyên-thực-tế&quot;&gt;Lời khuyên thực tế&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Sử dụng các phương pháp tăng tốc khi bài toán có điều kiện tốt và trơn.&lt;/li&gt;
  &lt;li&gt;Giám sát hội tụ và ổn định khi áp dụng tăng tốc.&lt;/li&gt;
  &lt;li&gt;Nếu xảy ra mất ổn định, hãy xem xét chuyển sang các phương pháp gradient gần kề tiêu chuẩn.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>09-05-03 Ví dụ: FISTA</title>
   <link href="http://localhost:4000/contents/vi/chapter09/09_05_03_example_FISTA/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/09_05_03_example_FISTA</id>
   <content type="html">&lt;h1 id=&quot;ví-dụ-fista&quot;&gt;Ví dụ: FISTA&lt;/h1&gt;

&lt;p&gt;Trong phần này, chúng ta giới thiệu một ví dụ về Thuật toán Ngưỡng-Co lặp Nhanh (FISTA), đây là một phương pháp gradient gần kề tăng tốc.&lt;/p&gt;

&lt;h2 id=&quot;thuật-toán-fista&quot;&gt;Thuật toán FISTA&lt;/h2&gt;
&lt;p&gt;Thuật toán FISTA giải quyết các bài toán có dạng:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\min_x g(x) + h(x)\)
trong đó \(g\) là hàm lồi và khả vi, và \(h\) là hàm lồi.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Các bước cập nhật là:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Khởi tạo \(x^{(0)} = x^{(-1)}\), \(t_0 = 1\).&lt;/li&gt;
  &lt;li&gt;Với \(k = 1, 2, ...\):
    &lt;ul&gt;
      &lt;li&gt;
\[y^{(k)} = x^{(k-1)} + \frac{t_{k-1} - 1}{t_k} (x^{(k-1)} - x^{(k-2)})\]
      &lt;/li&gt;
      &lt;li&gt;
\[x^{(k)} = \text{prox}_{t_k}(y^{(k)} - t_k \nabla g(y^{(k)}))\]
      &lt;/li&gt;
      &lt;li&gt;
\[t_{k+1} = \frac{1 + \sqrt{1 + 4 t_k^2}}{2}\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ứng-dụng-cho-lasso&quot;&gt;Ứng dụng cho Lasso&lt;/h2&gt;
&lt;p&gt;FISTA có thể được áp dụng cho hồi quy Lasso, bao gồm việc tối thiểu hóa hàm mất mát bình phương tối thiểu với số hạng chính quy hóa \(L_1\).&lt;/p&gt;

&lt;p&gt;FISTA đạt được hội tụ nhanh hơn so với các phương pháp gradient gần kề tiêu chuẩn.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09-05-02 Phân tích hội tụ</title>
   <link href="http://localhost:4000/contents/vi/chapter09/09_05_02_convergence_analysis/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/09_05_02_convergence_analysis</id>
   <content type="html">&lt;h1 id=&quot;phân-tích-hội-tụ&quot;&gt;Phân tích hội tụ&lt;/h1&gt;

&lt;p&gt;Trong phần này, chúng ta phân tích sự hội tụ của phương pháp gradient gần kề tăng tốc.&lt;/p&gt;

&lt;h2 id=&quot;định-lý-hội-tụ&quot;&gt;Định lý hội tụ&lt;/h2&gt;
&lt;p&gt;Giả sử \(g\) là hàm lồi và khả vi, \(h\) là hàm lồi, và \(\nabla g\) liên tục Lipschitz với hằng số \(L &amp;gt; 0\). Khi đó, phương pháp gradient gần kề tăng tốc với kích thước bước cố định \(t \le 1/L\) thỏa mãn:&lt;/p&gt;

&lt;blockquote&gt;
\[f(x^{(k)}) - f^* \le \frac{2L \lVert x^{(0)} - x^* \rVert^2_2}{(k+1)^2}\]
&lt;/blockquote&gt;

&lt;p&gt;Điều này có nghĩa là tốc độ hội tụ là \(O(1/k^2)\), nhanh hơn phương pháp gradient gần kề tiêu chuẩn.&lt;/p&gt;

&lt;h2 id=&quot;tìm-kiếm-đường-thẳng-lùi&quot;&gt;Tìm kiếm đường thẳng lùi&lt;/h2&gt;
&lt;p&gt;Tìm kiếm đường thẳng lùi cho phương pháp gradient gần kề tăng tốc tương tự như đối với phương pháp gradient gần kề tiêu chuẩn, nhưng kích thước bước được chọn một cách thích ứng.&lt;/p&gt;

&lt;p&gt;Để biết thêm chi tiết, tham khảo Beck và Teboulle (2009), “A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems” (FISTA).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09-05-01 Phương pháp gradient gần kề tăng tốc</title>
   <link href="http://localhost:4000/contents/vi/chapter09/09_05_01_accelerated_proximal_gradient_method/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/09_05_01_accelerated_proximal_gradient_method</id>
   <content type="html">&lt;h1 id=&quot;phương-pháp-gradient-gần-kề-tăng-tốc&quot;&gt;Phương pháp gradient gần kề tăng tốc&lt;/h1&gt;

&lt;p&gt;Nếu phương pháp gradient gần kề được tăng tốc, nó có thể đạt được tốc độ hội tụ tối ưu \(O(1/\sqrt{\epsilon})\). Nesterov đã đề xuất bốn phương pháp, trong đó ba phương pháp là các phương pháp tăng tốc:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1983: Phương pháp tăng tốc ban đầu cho các hàm trơn&lt;/li&gt;
  &lt;li&gt;1988: Một phương pháp tăng tốc khác cho các hàm trơn&lt;/li&gt;
  &lt;li&gt;2005: Kỹ thuật làm trơn các hàm không trơn cùng với phương pháp tăng tốc ban đầu&lt;/li&gt;
  &lt;li&gt;2007: Phương pháp tăng tốc cho các hàm tổng hợp&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bây giờ, hãy xem xét phương pháp của Beck và Teboulle (2008), mở rộng phương pháp của Nesterov (1983) cho các hàm tổng hợp.&lt;/p&gt;

&lt;h2 id=&quot;phương-pháp-gradient-gần-kề-tăng-tốc-1&quot;&gt;Phương pháp gradient gần kề tăng tốc&lt;/h2&gt;
&lt;p&gt;Như trước, giả sử \(g\) là hàm lồi và khả vi, và \(h\) là hàm lồi. Bài toán được định nghĩa là:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\min_x g(x) + h(x)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Phương pháp gradient gần kề tăng tốc&lt;/strong&gt; xem xét hướng mà \(x\) đang di chuyển để hướng không thay đổi đột ngột khi di chuyển đến vị trí tiếp theo. Nói cách khác, nó tạo động lượng cho hướng tiến triển, tạo quán tính để tiếp tục di chuyển theo cùng hướng như trước.&lt;/p&gt;

&lt;p&gt;Giá trị ban đầu của thuật toán được đặt là \(x^{(0)} = x^{(-1)} \in \mathbb{R}^n\). Sau đó, sau khi tính toán vị trí \(v\) xem xét động lượng, gradient gần kề được thực hiện.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
v &amp;amp; = x^{(k-1)} + \frac{k-2}{k + 1}  (x^{(k-1)} −x^{(k-2)}) \\
x^{(k)} &amp;amp; = \text{prox}_{t_k} (v − t_k \nabla g(v)), k = 1,2,3,...  \\
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Trong bước đầu tiên \(k = 1\), \(x^{(k-1)} −x^{(k-2)}\) bằng không, vì vậy nó giống như cập nhật gradient gần kề.&lt;/li&gt;
  &lt;li&gt;Trong các bước tiếp theo, \(v\) có động lượng theo hướng trước đó \(x^{(k-1)} −x^{(k-2)}\). Khi \(k\) tăng, trọng số động lượng tăng và hội tụ về 1.&lt;/li&gt;
  &lt;li&gt;Khi \(h = 0\), điều này giống như &lt;strong&gt;phương pháp gradient tăng tốc&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hình dưới đây cho thấy cách trọng số động lượng thay đổi khi \(k\) thay đổi.&lt;/p&gt;

&lt;p&gt;Trong hình này, giá trị âm khi k = 0, nhưng vì số hạng động lượng bằng không vào thời điểm đó, nên nó không gây ra vấn đề gì. Khi k tăng, trọng số tiến gần 1, vì vậy giá trị được cập nhật nhiều hơn và giúp hội tụ nhanh hơn.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter09/momentum_weight.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Trọng số động lượng [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;ví-dụ-lasso&quot;&gt;Ví dụ Lasso&lt;/h2&gt;
&lt;p&gt;Nếu chúng ta áp dụng gradient gần kề tăng tốc cho ví dụ Lasso đã thấy trước đó, chúng ta sẽ nhận được kết quả như được hiển thị trong hình dưới đây. Có thể thấy rằng gradient gần kề tăng tốc có hiệu suất nhanh hơn nhiều so với các phương pháp subgradient hoặc gradient gần kề.&lt;/p&gt;

&lt;p&gt;Có một phần ở giữa đồ thị nhảy lên, được gọi là “gợn sóng Nesterov”. Do đó, gradient gần kề tăng tốc không giảm đơn điệu và không phải là phương pháp giảm.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter09/accelerated_proximal_gradient.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 2] Gradient Gần kề Tăng tốc [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>09-04 Các trường hợp đặc biệt</title>
   <link href="http://localhost:4000/contents/vi/chapter09/09_04_special_cases/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/09_04_special_cases</id>
   <content type="html">&lt;h1 id=&quot;các-trường-hợp-đặc-biệt&quot;&gt;Các trường hợp đặc biệt&lt;/h1&gt;

&lt;p&gt;Phương pháp gradient gần kề cũng được gọi là gradient descent tổng hợp hoặc gradient descent tổng quát.&lt;/p&gt;

&lt;p&gt;Tại sao nó được gọi là &lt;strong&gt;“tổng quát”&lt;/strong&gt;? Lý do là phương pháp gradient gần kề bao gồm tất cả các trường hợp đặc biệt sau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(h = 0 \to\) gradient descent&lt;/li&gt;
  &lt;li&gt;\(h = I_C \to\) projected gradient descent&lt;/li&gt;
  &lt;li&gt;\(g = 0 \to\) thuật toán tối ưu gần kề&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Do đó, tất cả các thuật toán này đều có tốc độ hội tụ \(O(1/\epsilon)\).&lt;/p&gt;

&lt;h2 id=&quot;projected-gradient-descent&quot;&gt;Projected gradient descent&lt;/h2&gt;
&lt;p&gt;Khi \(I_C(x)\) là hàm chỉ thị của một tập lồi đóng \(C \in \mathbb{R}^n\), bài toán tối thiểu hóa \(g(x)\) trên tập \(C\) có thể được đổi dạng như sau. (Lưu ý: \(C\) phải là một tập đóng để phép chiếu được định nghĩa rõ ràng.)&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x \in C} g(x) \iff \min_x g(x) + I_C(x)\]

\[I_C(x) = 
\begin{cases}
0, &amp;amp; x \in C \\
\infty, &amp;amp; x \notin C
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;Lúc này, ánh xạ gần kề được định nghĩa như sau.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{prox}_t(x)  
&amp;amp;= \underset{z}{\text{argmin}} \frac{1}{2t} \lVert x−z \rVert_2^2 + I_C(z) \\
&amp;amp; = \underset{z \in C}{\text{argmin}} \lVert x−z \rVert_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Kết quả là, ánh xạ gần kề \(\text{prox}_t(x) = P_C(x)\) là toán tử chiếu lên \(C\).&lt;/p&gt;

&lt;p&gt;Bước cập nhật gradient gần kề là: \(x^+ = P_C (x−t \nabla g(x) )\). Nói cách khác, sau khi thực hiện cập nhật gradient descent, bạn chiếu lên \(C\).&lt;/p&gt;

&lt;p&gt;Trong hình dưới đây, hình chữ nhật màu hồng là tập khả thi \(C\), và vị trí hiện tại là điểm trên của hai điểm dưới hình chữ nhật. Sau khi thực hiện một bước gradient descent, bạn di chuyển ra ngoài \(C\), vì vậy bạn chiếu ngược lại lên \(C\) để trở về bên trong tập khả thi.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter09/projected_gradient_descent.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Projected Gradient Descent [3]]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;thuật-toán-tối-ưu-gần-kề&quot;&gt;Thuật toán tối ưu gần kề&lt;/h2&gt;

&lt;p&gt;Xem xét bài toán tối thiểu hóa một hàm lồi \(h\) như sau. Ở đây, \(h\) không cần khả vi và \(g(x) = 0\).&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\min_x h(x)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ánh xạ gần kề được định nghĩa là:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^{(k)} &amp;amp;= \text{prox}_{t_k} \big(x^{(k-1)} - t_k \nabla g ( x^{(k-1)} ) \big) , \qquad k = 1, 2, 3, ... \\
&amp;amp;= \text{prox}_{t_k} \big(x^{(k-1)} \big) ,  \qquad \qquad \qquad \qquad \; k = 1, 2, 3, ... \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Do đó, bước cập nhật gradient gần kề là:&lt;/p&gt;
&lt;blockquote&gt;
\[x^+ = \underset{z}{\text{argmin}} \frac{1}{2t} \lVert x−z \rVert_2^2 + h(z)\]
&lt;/blockquote&gt;

&lt;p&gt;Phương pháp gradient gần kề này, chỉ được định nghĩa bởi \(h\) với \(g = 0\), được gọi là &lt;strong&gt;thuật toán tối ưu gần kề (PMA)&lt;/strong&gt;. Phương pháp này nhanh hơn các phương pháp subgradient, nhưng nếu ánh xạ gần kề không có dạng đóng, nó không thể được triển khai.&lt;/p&gt;

&lt;h2 id=&quot;điều-gì-xảy-ra-nếu-chúng-ta-không-thể-tính-prox&quot;&gt;Điều gì xảy ra nếu chúng ta không thể tính prox?&lt;/h2&gt;
&lt;p&gt;Về mặt lý thuyết, khi áp dụng gradient gần kề cho \(f = g + h\), giả định rằng hàm prox có thể được tính toán chính xác. Tức là, giả định rằng điểm cực tiểu có thể được tìm thấy chính xác thông qua ánh xạ gần kề.&lt;/p&gt;
&lt;blockquote&gt;
\[\text{prox}_t(x )= \underset{z}{\text{argmin}} \frac{1}{2t} \lVert x−z \rVert_2^2 + h(z)\]
&lt;/blockquote&gt;

&lt;p&gt;Nói chung, không rõ điều gì xảy ra nếu điểm cực tiểu chỉ được xấp xỉ.
Tuy nhiên, nếu lỗi trong việc xấp xỉ toán tử prox có thể được kiểm soát chính xác, đã được chứng minh rằng tốc độ hội tụ ban đầu có thể được duy trì. (Schmidt et al. (2011), Convergence rates of inexact proximal-gradient methods for convex optimization)&lt;/p&gt;

&lt;p&gt;Trong thực tế, nếu prox có thể được tính toán xấp xỉ, nó sẽ được thực hiện với độ chính xác cao.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09-03 Ví dụ: hoàn thiện ma trận</title>
   <link href="http://localhost:4000/contents/vi/chapter09/09_03_example_matrix_completion/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/09_03_example_matrix_completion</id>
   <content type="html">&lt;h1 id=&quot;ví-dụ-hoàn-thiện-ma-trận-matrix-completion&quot;&gt;Ví dụ: hoàn thiện ma trận (Matrix completion)&lt;/h1&gt;

&lt;p&gt;Trong nhiều ứng dụng, dữ liệu đo được thường được biểu diễn dưới dạng ma trận. Trong những trường hợp này, hầu hết các phần tử trong ma trận có thể trống, chỉ có một vài phần tử chứa dữ liệu quan sát được, dẫn đến một ma trận thưa. Thách thức điền vào các phần tử bị thiếu trong ma trận như vậy được gọi là bài toán &lt;strong&gt;hoàn thiện ma trận&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Ví dụ, vấn đề này có thể xảy ra trong các hệ thống gợi ý khi đề xuất sản phẩm hoặc dịch vụ cho khách hàng chưa từng mua hàng.&lt;/p&gt;

&lt;h2 id=&quot;bài-toán-hoàn-thiện-ma-trận&quot;&gt;Bài toán hoàn thiện ma trận&lt;/h2&gt;
&lt;p&gt;Bài toán &lt;strong&gt;hoàn thiện ma trận&lt;/strong&gt; có thể được phát biểu như sau:&lt;/p&gt;

&lt;p&gt;Gọi ma trận \(Y \in \mathbb{R}^{m\times n}\) biểu diễn dữ liệu quan sát được, và \(Y_{ij}, (i,j) \in \Omega\) ký hiệu các phần tử chứa dữ liệu quan sát được. Ma trận \(B\) là ma trận ước lượng được sử dụng để dự đoán các phần tử bị thiếu.&lt;/p&gt;

&lt;blockquote&gt;
\[\min_B \frac{1}{2} \sum_{(i,j)\in\Omega} (Y_{ij} −B_{ij})^2 + \lambda\lVert B \rVert_{tr}\]
&lt;/blockquote&gt;

&lt;p&gt;Số hạng đầu tiên trong hàm mục tiêu nhằm tối thiểu hóa lỗi giữa ma trận \(B\) và dữ liệu quan sát được, trong khi số hạng thứ hai khuyến khích ma trận \(B\) có hạng thấp. (Giả định rằng ma trận B nằm trên một đa tạp chiều thấp.) Do đó, ma trận \(B\) điền vào các phần tử bị thiếu với các giá trị chiều thấp nhất phù hợp với dữ liệu quan sát được.&lt;/p&gt;

&lt;h3 id=&quot;tham-khảo-chuẩn-vết-trace-norm&quot;&gt;[Tham khảo] Chuẩn vết (Trace Norm)&lt;/h3&gt;
&lt;p&gt;Chuẩn vết của một ma trận được định nghĩa là tổng các giá trị kỳ dị của nó.&lt;/p&gt;

&lt;blockquote&gt;
\[\lVert B \rVert_{tr} = \text{trace}(\sqrt{B^* B}) = \sum_{i=1}^r \sigma_i(B), \quad r = rank(B)\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(B^* B\) là nửa xác định dương, và các giá trị kỳ dị được sắp xếp theo thứ tự \(\sigma_1(X) \ge ... \ge \sigma_r(X) \ge 0\).&lt;/p&gt;

&lt;h3 id=&quot;tham-khảo-bộ-chính-quy-hóa-chuẩn-l1-so-với-bộ-chính-quy-hóa-chuẩn-vết&quot;&gt;[Tham khảo] Bộ chính quy hóa chuẩn &lt;strong&gt;L1&lt;/strong&gt; so với Bộ chính quy hóa chuẩn vết&lt;/h3&gt;
&lt;p&gt;Bài toán này có thể được hiểu như ngưỡng mềm ma trận, trong đó vector trong ngưỡng mềm ban đầu được thay thế bằng ma trận. Trong số hạng chính quy hóa, bộ chính quy hóa chuẩn &lt;strong&gt;L1&lt;/strong&gt; cho vector (\(\lVert \cdot \rVert_{1}\)) được thay thế bằng bộ chính quy hóa chuẩn vết (\(\lVert \cdot \rVert_{tr}\)) cho ma trận, và thực sự, chức năng của hai bộ chính quy hóa này là tương tự.&lt;/p&gt;

&lt;p&gt;Bộ chính quy hóa chuẩn &lt;strong&gt;L1&lt;/strong&gt; tạo ra tính thưa trong vector, trong khi bộ chính quy hóa chuẩn vết tương tự tạo ra tính thưa trong vector giá trị kỳ dị của ma trận. Khi ma trận là đường chéo, các phần tử đường chéo có thể được xem như vector giá trị kỳ dị, và bộ chính quy hóa chuẩn vết tối thiểu hóa tổng các giá trị kỳ dị, thúc đẩy tính thưa trong vector giá trị kỳ dị.&lt;/p&gt;

&lt;p&gt;Trong bối cảnh này, chuẩn vết \(\lVert B \rVert_{tr}\) đóng vai trò như một xấp xỉ cho \(\text{Rank}(B)\).&lt;/p&gt;

&lt;h2 id=&quot;phương-pháp-gradient-gần-kề&quot;&gt;Phương pháp gradient gần kề&lt;/h2&gt;
&lt;p&gt;Khi bài toán này được đóng khung bằng toán tử chiếu, phương pháp gradient gần kề có thể được sử dụng hiệu quả.&lt;/p&gt;
&lt;h3 id=&quot;toán-tử-chiếu&quot;&gt;Toán tử chiếu&lt;/h3&gt;
&lt;p&gt;Hãy định nghĩa toán tử chiếu \(P_\Omega\) cho các giá trị quan sát được như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[[ P_\Omega(B) ] _{ij} =
\begin{cases}
B_{ij}, &amp;amp; (i,j) ∈ \Omega \\\
0, &amp;amp; (i,j) \notin \Omega
\end{cases}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;hàm-mục-tiêu&quot;&gt;Hàm mục tiêu&lt;/h3&gt;
&lt;p&gt;Sử dụng toán tử chiếu, hàm mục tiêu được định nghĩa là:&lt;/p&gt;

&lt;blockquote&gt;
\[f(B) = \underbrace{ \frac{1}{2} \lVert P_\Omega(Y) − P_\Omega(B) \rVert_F^2 }_{g(B)} + \underbrace{ \lambda \lVert B \rVert_{tr} }_{h(B)}\]
&lt;/blockquote&gt;

&lt;p&gt;Bây giờ, hàm \(f(B)\) bao gồm một phần khả vi \(g(B)\) và một phần không khả vi \(h(B)\).&lt;/p&gt;

&lt;h3 id=&quot;ánh-xạ-gần-kề&quot;&gt;Ánh xạ gần kề&lt;/h3&gt;
&lt;p&gt;Để áp dụng phương pháp gradient gần kề, chúng ta cần tính gradient của hàm \(g(B)\) và định nghĩa ánh xạ gần kề.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Gradient của \(g(B)\): \(\nabla g(B) = −(P_\Omega(Y )−P_\Omega(B))\)&lt;/li&gt;
  &lt;li&gt;Ánh xạ gần kề:&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{prox}_t (B) = \underset{Z}{\text{argmin}} \frac{1}{2t} \Vert B−Z \Vert_F^2 + \lambda \Vert Z \Vert_{tr}
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;svd-ma-trận--ngưỡng-mềm&quot;&gt;SVD ma trận &amp;amp; Ngưỡng mềm&lt;/h3&gt;
&lt;p&gt;Ánh xạ gần kề tương ứng với ngưỡng mềm ma trận ở mức \(\lambda\): \(\text{prox}_t(B) = S_{\lambda t}(B)\).&lt;/p&gt;

&lt;p&gt;Thông thường, ma trận \(B\) có kích thước lớn, vì vậy Phân tích Giá trị Kỳ dị (SVD) được sử dụng để tối thiểu hóa tải tính toán. Nếu chúng ta thực hiện SVD sao cho \(B = U \Sigma V^T\), thì \(S_\lambda(B)\) có thể được định nghĩa là:&lt;/p&gt;

&lt;blockquote&gt;
\[S_\lambda(B) = U \Sigma_\lambda V^T\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(\Sigma_\lambda\) là một ma trận đường chéo được định nghĩa như sau:&lt;/p&gt;

&lt;blockquote&gt;
\[(\Sigma_\lambda)_{ii} = \max \{ \Sigma_{ii} −\lambda,0 \}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;reference-sigma_lambda_ii--max--sigma_ii-lambda0---inducement&quot;&gt;[Reference] \((\Sigma_\lambda)_{ii} = \max \{ \Sigma_{ii} −\lambda,0 \}\)  inducement&lt;/h3&gt;
&lt;p&gt;How is this expression derived? Assuming \(\text{prox}_t(B) = Z\), we have:
(Differentiating the right-hand side of \(\text{prox}_t(B)\) with respect to Z yields the following result.)&lt;/p&gt;

&lt;blockquote&gt;
\[0 ∈ Z − B + \lambda t \cdot \partial \lVert Z \rVert_{tr}\]
&lt;/blockquote&gt;

&lt;p&gt;Rearranging this expression gives:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
Z &amp;amp; = B - \lambda t \cdot \partial \lVert Z \rVert_{tr} \\
 &amp;amp; = U \Sigma V^T - \lambda t \cdot (UV^T + W) \\
 &amp;amp; = U (\Sigma - \lambda t) V^T - \lambda t  W \\
 &amp;amp; = U (\Sigma - \lambda ) V^T  \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The final expression can be obtained when the Lipschitz constant is \(L=1\) and \(W\) is 0.&lt;/p&gt;

&lt;p&gt;Thus, we have \(\text{prox}_t(B) = S_\lambda(B) = Z\), leading to the derivation of the following expression:&lt;/p&gt;

&lt;blockquote&gt;
\[(\Sigma_\lambda)_{ii} = \max \{ \Sigma_{ii} −\lambda,0 \}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;reference-derivative-of-trace-norm&quot;&gt;[Reference] Derivative of Trace Norm&lt;/h3&gt;
&lt;p&gt;If \(Z = U \Sigma V^T\), the derivative of the trace norm is given by:&lt;/p&gt;
&lt;blockquote&gt;
\[\partial \lVert Z \rVert_{tr} = \{UV^T + W : \lVert W \rVert_{op} ≤ 1, U^TW = 0, WV = 0 \}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(\lVert W \rVert_{op}\) represents the operator norm, with the largest singular value being less than 1. Additionally, \(W\) is orthogonal to both \(U^T\) and \(V\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For proof, refer to &lt;a href=&quot;https://math.stackexchange.com/questions/701062/derivative-of-the-nuclear-norm-with-respect-to-its-argument&quot;&gt;Derivative of the nuclear norm with respect to its argument&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;proximal-gradient-update&quot;&gt;Proximal gradient update&lt;/h3&gt;
&lt;p&gt;Now, let’s define the proximal gradient update equation.&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = S_{\lambda t} ( B + t( P_\Omega(Y) − P_\Omega(B) ) )\]
&lt;/blockquote&gt;

&lt;p&gt;When \(L = 1\), \(\nabla g(B)\) is Lipschitz continuous, allowing us to choose a fixed step size of \(t = 1\).&lt;/p&gt;

&lt;p&gt;Consequently, the update equation simplifies to:&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = S_\lambda (P_\Omega(Y) + P_\Omega^\bot (B) )\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(P_\Omega^\bot\) biểu diễn phép chiếu lên các giá trị không quan sát được, thỏa mãn phương trình \(P_\Omega(B) + P_\Omega^\bot (B) = B\).&lt;/p&gt;

&lt;p&gt;Trong phương trình này, \(P_\Omega(Y)\) biểu thị phần quan sát được, trong khi \(P_\Omega^\bot (B)\) biểu thị phần bị thiếu. Hàm \(S_\lambda\) rất đơn giản để tính toán, vì nó chỉ yêu cầu thực hiện SVD và tính toán \((\Sigma_\lambda)_{ii} = \max \{ \Sigma_{ii} −\lambda,0 \}\).&lt;/p&gt;

&lt;h2 id=&quot;thuật-toán-soft-impute&quot;&gt;Thuật toán Soft-Impute&lt;/h2&gt;
&lt;p&gt;Thuật toán này được biết đến với tên &lt;strong&gt;Soft-Impute&lt;/strong&gt; và cung cấp một giải pháp đơn giản nhưng hiệu quả cho bài toán hoàn thiện ma trận. Khi xử lý các ma trận lớn, chi phí tính toán của SVD có thể cao. Tuy nhiên, do tính thưa của \(P_\Omega(Y)\) và hạng thấp của \(P_\Omega^\bot (B)\) trong thuật toán này, SVD có thể được thực hiện một cách hiệu quả.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Để biết thêm thông tin chi tiết, vui lòng tham khảo bài báo: Mazumder et al. (2011), “Spectral regularization algorithms for learning
large incomplete matrices”&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>09-02 Phân tích hội tụ</title>
   <link href="http://localhost:4000/contents/vi/chapter09/09_02_convergence_analysis/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/09_02_convergence_analysis</id>
   <content type="html">&lt;h1 id=&quot;phân-tích-hội-tụ&quot;&gt;Phân tích hội tụ&lt;/h1&gt;
&lt;p&gt;Trong phần này, chúng ta phân tích sự hội tụ của phương pháp gradient gần kề.&lt;/p&gt;

&lt;h2 id=&quot;phân-tích-hội-tụ-1&quot;&gt;Phân tích hội tụ&lt;/h2&gt;
&lt;p&gt;Đối với hàm mục tiêu \(f(x) = g(x) + h(x)\), chúng ta giả định như sau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(g\) là hàm lồi, khả vi, và &lt;strong&gt;dom&lt;/strong&gt;\((g) = \mathbb{R}^n\), và \(\nabla g\) liên tục Lipschitz (\(L &amp;gt; 0\)).&lt;/li&gt;
  &lt;li&gt;\(h\) là hàm lồi, và \(\text{prox}_{t}(x) = \underset{z} {\text{argmin}} \{ \parallel x - z \parallel_2^2/ (2t) + h(z) \}\) cần được tính toán.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;định-lý-hội-tụ&quot;&gt;Định lý hội tụ&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Phương pháp gradient gần kề&lt;/strong&gt; thỏa mãn phương trình sau với kích thước bước cố định \(t \le 1/L\): 
\begin{align}
f(x^{(k)}) - f^{*} \le  \frac{ \lVert x^{(0)} - x^{*} \rVert^2_2 }{2tk}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Phương pháp gradient gần kề có tốc độ hội tụ \(O(1/k)\) hoặc \(O(1/\epsilon)\), đây là hiệu suất tương tự như gradient descent. Tuy nhiên, hiệu suất này dựa trên số lần lặp, không phải số phép toán. (Số phép toán có thể thay đổi tùy thuộc vào hàm \(h\).)&lt;/p&gt;

&lt;h2 id=&quot;tìm-kiếm-đường-thẳng-lùi-backtracking-line-search&quot;&gt;Tìm kiếm đường thẳng lùi (Backtracking line search)&lt;/h2&gt;
&lt;p&gt;Phương pháp tìm kiếm đường thẳng lùi của gradient gần kề tương tự như gradient descent nhưng chỉ hoạt động trên phần trơn \(g\), không phải hàm \(f\).&lt;/p&gt;

&lt;p&gt;Đầu tiên, đặt tham số \(0 &amp;lt; \beta &amp;lt; 1\) và bắt đầu với \(t=1\). Trong mỗi lần lặp, giảm \(t\) thành \(t = \beta t\) trong khi thỏa mãn điều kiện sau, và cập nhật gradient gần kề nếu điều kiện không được thỏa mãn.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
g(x - tG_t(x)) &amp;gt; g(x) - t \nabla g(x)^T G_t(x) + \frac{t}{2} \parallel G_t(x) \parallel_2 ^2
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Điều kiện lùi này có nghĩa là giá trị của hàm \(g\) tại vị trí bước tiếp theo \(x - tG_t(x)\) lớn hơn giá trị của xấp xỉ Taylor bậc hai của hàm \(g\).&lt;/p&gt;

&lt;p&gt;Nếu \(G_t(x) = \nabla g(x)\) trong phương trình này, chúng ta có thể thấy rằng \(g(x - t \nabla g(x)) &amp;gt; g(x) - \alpha t \lVert \nabla g(x) \rVert_2^2\), điều này trở nên giống hệt với điều kiện lùi của gradient descent.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ghi chú:&lt;/strong&gt; Để biết thêm chi tiết về backtracking của gradient descent, tham khảo &lt;a href=&quot;/contents/vi/chapter06/06_02_02_backtracking_line_search/&quot;&gt;06-02-02 backtracking line search&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;thuật-toán-tìm-kiếm-đường-thẳng-lùi&quot;&gt;Thuật toán tìm kiếm đường thẳng lùi&lt;/h3&gt;
&lt;p&gt;Nếu chúng ta tóm tắt điều này trong một thuật toán, nó như sau. (Tuy nhiên, \(\nabla x = - t G_t(x)\))&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Khởi tạo các tham số. (\(0 \lt \beta \lt 1\), \(0 \lt \alpha \le 1/2\))&lt;/li&gt;
  &lt;li&gt;Trong mỗi lần lặp, khởi tạo \(t = t_{\text{init}}\). (\(t_{\text{init}} = 1\))&lt;/li&gt;
  &lt;li&gt;Nếu điều kiện \(g(x - tG_t(x)) \gt g(x) - t \nabla g(x)^T G_t(x) + \frac{t}{2} \parallel G_t(x) \parallel_2 ^2\) được thỏa mãn, giảm \(t = \beta t\). Lặp lại bước 3 trong khi điều kiện này được thỏa mãn.&lt;/li&gt;
  &lt;li&gt;Thực hiện cập nhật gradient descent \(x^+ = x - t G_t(x) = \text{prox}_t(x - t \nabla g(x))\).&lt;/li&gt;
  &lt;li&gt;Nếu điều kiện dừng không được thỏa mãn, quay lại bước 2.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Khi lùi trong gradient gần kề, vì \(G_t(x)\) được tính toán lặp đi lặp lại, ánh xạ gần kề được bao gồm trong \(G_t(x)\) cũng được tính toán lặp đi lặp lại. Vì ánh xạ gần kề rất tốn kém để tính toán, chi phí tính toán tổng thể của backtracking có thể cao.&lt;/p&gt;

&lt;h3 id=&quot;định-lý-hội-tụ-1&quot;&gt;Định lý hội tụ&lt;/h3&gt;
&lt;p&gt;Dưới các giả định tương tự như trên, phương pháp tìm kiếm đường thẳng lùi cũng thỏa mãn hiệu suất tương tự.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Phương pháp gradient gần kề&lt;/strong&gt; thỏa mãn phương trình sau cho tìm kiếm đường thẳng lùi. Kích thước bước là \(t_{\text{min}} = \text{min} \{1,\beta /L \}\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[f(x^{(k)})−f^{\star} ≤ \frac{\lVert x^{(0)} − x^{\star} \rVert_{2}^{2}}{2 t_{min}k}, \space t_{\text{min}} = \text{min} \{ 1, \beta / L \} \\\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>09-01 Phương pháp gradient gần kề</title>
   <link href="http://localhost:4000/contents/vi/chapter09/09_01_proximal_gradient_descent/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/09_01_proximal_gradient_descent</id>
   <content type="html">&lt;h1 id=&quot;phương-pháp-gradient-gần-kề-proximal-gradient-descent&quot;&gt;Phương pháp gradient gần kề (Proximal gradient descent)&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Phương pháp gradient gần kề&lt;/strong&gt; là một phương pháp tìm điểm tối ưu bằng cách phân tách hàm mục tiêu thành một phần khả vi và một phần không khả vi. Trong phần này, chúng ta sẽ tìm hiểu cách định nghĩa các hàm và tìm điểm tối ưu trong phương pháp gradient gần kề.&lt;/p&gt;

&lt;h2 id=&quot;hàm-có-thể-phân-tách&quot;&gt;Hàm có thể phân tách&lt;/h2&gt;
&lt;p&gt;Giả sử hàm mục tiêu \(f\) có thể được phân tách thành hai hàm \(g\) và \(h\).&lt;/p&gt;

&lt;blockquote&gt;
\[f(x) = g(x) + h(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, hai hàm \(g\) và \(h\) có các tính chất sau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(g\) là hàm lồi và khả vi. (&lt;strong&gt;dom&lt;/strong&gt;\((g) = \mathbb{R}^n\))&lt;/li&gt;
  &lt;li&gt;\(h\) là hàm lồi và không khả vi.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nếu \(f\) khả vi, bạn có thể tìm vị trí tiếp theo bằng phương pháp gradient descent:&lt;/p&gt;

&lt;blockquote&gt;
\[x^+ = x - t \cdot \nabla f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;[Ghi chú]&lt;/strong&gt; Trong gradient descent, hàm \(f\) được xấp xỉ gần \(x\) bằng khai triển Taylor bậc hai, và ma trận Hessian \(\nabla^2 f(x)\) được thay thế bởi \(\frac{1}{2t} I\). Điểm cực tiểu của xấp xỉ này được chọn làm vị trí tiếp theo. (Xem Chi tiết trong Chương 6 Gradient descent)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^+ = \underset{z}{\text{argmin}}  \underbrace{ f(x) + \nabla f(x)^T (z - x) + \frac{1}{2t} \parallel z - x \parallel_2 ^2}_{\tilde{f}_t(z)}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Tuy nhiên, nếu \(f\) không khả vi, bạn không thể sử dụng gradient descent. Nhưng nếu \(f\) được cấu thành như \(f = g + h\), liệu chúng ta có thể xấp xỉ phần khả vi \(g\) bằng một hàm bậc hai không?&lt;/p&gt;

&lt;p&gt;Ý tưởng này dẫn đến &lt;strong&gt;Phương pháp gradient gần kề&lt;/strong&gt;. Trong phương pháp này, bạn điều chỉnh đến vị trí tốt nhất gần với vị trí được dự đoán bởi gradient descent cho \(g\) và cũng làm cho hàm không khả vi \(h\) nhỏ. Quá trình này có thể được biểu diễn như sau:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
x^+ &amp;amp; = \underset{z}{\text{argmin}}   \tilde{g}_t(z) + h(z) \\
&amp;amp; = \underset{z}{\text{argmin}} \ g(x) + \nabla g(x)^T (z - x) + \frac{1}{2t} \parallel z - x \parallel_2 ^2 + h(z) \\
&amp;amp; = \underset{z}{\text{argmin}}  \nabla g(x)^T (z - x) + \frac{1}{2t} \parallel z - x \parallel_2 ^2 + \frac{t}{2} \parallel \nabla g(x) \parallel_2 ^2  + h(z) \\
&amp;amp; = \underset{z}{\text{argmin}}  \frac{1}{2t} \left ( 2t \nabla g(x)^T (z - x) + \parallel z - x \parallel_2 ^2 + t^2 \parallel \nabla g(x) \parallel_2 ^2 \right )  + h(z) \\
&amp;amp; = \underset{z}{\text{argmin}}  \frac{1}{2t} \left ( \parallel z - x \parallel_2 ^2 + 2t \nabla g(x)^T (z - x) + t^2 \parallel \nabla g(x) \parallel_2 ^2 \right ) + h(z) \\
&amp;amp; = \underset{z}{\text{argmin}}   \frac{1}{2t} \parallel z - (x - t \nabla g(x) )\parallel_2 ^2 + h(z) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Khi chuyển từ dòng thứ 2 sang dòng thứ 3, số hạng \(g(x)\) được loại bỏ như một số hạng hằng số đối với z, và số hạng \(\frac{t}{2} \parallel \nabla g(x)^T \parallel_2 ^2\) được thêm vào. Trong phương trình cuối cùng, số hạng đầu tiên \(\frac{1}{2t} \parallel z - (x - t \nabla g(x) )\parallel_2 ^2\) là số hạng đưa nó gần hơn với vị trí cập nhật gradient của \(g\), và số hạng thứ hai \(h(z)\) là số hạng làm giảm \(h\).&lt;/p&gt;

&lt;h2 id=&quot;phương-pháp-gradient-gần-kề&quot;&gt;Phương pháp gradient gần kề&lt;/h2&gt;
&lt;p&gt;Phương pháp gradient gần kề bắt đầu từ một điểm ban đầu \(x^{(0)}\) và lặp lại việc áp dụng cập nhật sau:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x^{(k)} = \text{prox}_{t_k}(x^{(k-1)} - t_k \nabla g(x^{(k-1)}) )\), \(k=1,2,3,...\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(\text{prox}_{t}\) được định nghĩa là ánh xạ gần kề (proximal mapping):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\text{prox}_{t}(x) = \underset{z}{\arg \min}  \frac{1}{2t} \parallel x - z \parallel_2^2 + h(z)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Nếu chúng ta viết lại điều này dưới dạng cập nhật mà chúng ta đã thấy cho đến nay, nó trở thành:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{(k)} = x^{(k-1)} - t_k \cdot G_{t_k}(x^{(k-1)}), \space \space \text{trong đó} \space G_{t}(x) = \frac{x-\text{prox}_{t} (x - t \nabla g(x))}{t} &lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;điều-này-có-lợi-ích-gì&quot;&gt;Điều này có lợi ích gì?&lt;/h2&gt;
&lt;p&gt;Lợi ích của việc làm này là gì? Có phải chỉ là thay đổi bài toán thành một dạng bài toán tối ưu khác không?&lt;/p&gt;

&lt;p&gt;Điểm quan trọng là đối với hầu hết các hàm \(h\) chính, \(\text{prox}_{t}(\cdot)\) có thể được tính toán một cách giải tích. Nói cách khác, nó có thể được tính toán như sau:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hàm ánh xạ \(\text{prox}_{t}(\cdot)\) chỉ phụ thuộc vào \(h\), không phụ thuộc vào \(g\).&lt;/li&gt;
  &lt;li&gt;Hàm \(g\) có thể rất phức tạp, nhưng ở đây chúng ta chỉ cần tính gradient \(\nabla g\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Phân tích hội tụ sẽ được thực hiện liên quan đến số lần lặp của thuật toán. Lưu ý rằng trong mỗi lần lặp, việc tính toán \(\text{prox}_{t}(\cdot)\) có thể khác nhau về chi phí tính toán tùy thuộc vào \(h\).&lt;/p&gt;

&lt;h2 id=&quot;ví-dụ-ista&quot;&gt;Ví dụ: ISTA&lt;/h2&gt;
&lt;p&gt;Hãy xem một ví dụ về phương pháp gradient gần kề. Trong chương trước, tiêu chí lasso được định nghĩa như sau khi \(y \in \mathbb{R}^n\) và \(X \in \mathbb{R}^{n \times p}\):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
f(\beta) = \frac{1}{2} \parallel y - X\beta \parallel_2^2 + \lambda \parallel \beta \parallel_1 &lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ở đây, \(g(\beta) = \frac{1}{2} \parallel y - X\beta \parallel_2^2\) và \(h(\beta) = \lambda \parallel \beta \parallel_1\). Trong trường hợp này, ánh xạ gần kề được định nghĩa là:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
\text{prox}_{t}(\beta) &amp;amp; = \underset{z}{\text{argmin}}  \frac{1}{2t} \parallel \beta - z \parallel_2^2 + \lambda \parallel z \parallel_1 \\
&amp;amp; = S_{\lambda t}(\beta) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(S_{\lambda t}(\beta)\) là toán tử ngưỡng mềm (soft-thresholding operator), được định nghĩa như sau. (Để biết thêm chi tiết, xem Chương 7 Subgradient)&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
[S_{\lambda t}(\beta)]_i =
\begin{cases}
\beta_i - \lambda &amp;amp; \mbox{nếu } \beta_i \gt \lambda \\
0 &amp;amp; \mbox{nếu } -\lambda \le \beta_i \le \lambda, i = 1, ..., n \\
\beta_i + \lambda &amp;amp; \mbox{nếu } \beta_i \lt -\lambda \\
\end{cases}
\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Vì gradient của \(g\) là \(\nabla g(\beta) = -X^{T} (y - X \beta)\), cập nhật gradient gần kề được định nghĩa là:&lt;/p&gt;

&lt;blockquote&gt;
\[\beta^+ = S_{\lambda t}(\beta + tX^{T} (y - X \beta) )\]
&lt;/blockquote&gt;

&lt;p&gt;Thuật toán này là một thuật toán rất đơn giản được gọi là &lt;strong&gt;thuật toán ngưỡng mềm lặp (iterative soft-thresholding algorithm - ISTA)&lt;/strong&gt;. (Beck và Teboulle (2008), “A fast iterative shrinkage-thresholding algorithm for linear inverse problems”)&lt;/p&gt;

&lt;p&gt;Trong hình dưới đây, bạn có thể thấy rõ sự khác biệt về hiệu suất giữa phương pháp subgradient và phương pháp gradient gần kề. Về mặt số lần lặp, hiệu suất của phương pháp gradient gần kề có thể so sánh với gradient descent.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter09/09.01_01_ISTA.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Hình 1] Ví dụ về tốc độ hội tụ của gradient gần kề (ISTA) so với phương pháp subgradient [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>Proximal gradient descent and acceleration</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_proximal_gradient_descent_and_acceleration/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter09/09_proximal_gradient_descent_and_acceleration</id>
   <content type="html">&lt;h1 id=&quot;proximal-gradient-descent-and-acceleration&quot;&gt;Proximal gradient descent and acceleration&lt;/h1&gt;

&lt;p&gt;This chapter introduces proximal gradient descent and acceleration techniques for optimization problems involving composite functions.&lt;/p&gt;

&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Proximal gradient descent is used for problems where the objective can be split into a differentiable part and a non-differentiable part.&lt;/li&gt;
  &lt;li&gt;Acceleration methods, such as Nesterov’s acceleration and FISTA, can improve convergence rates.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;structure&quot;&gt;Structure&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Section 1: Proximal gradient descent&lt;/li&gt;
  &lt;li&gt;Section 2: Convergence analysis&lt;/li&gt;
  &lt;li&gt;Section 3: Matrix completion example&lt;/li&gt;
  &lt;li&gt;Section 4: Special cases&lt;/li&gt;
  &lt;li&gt;Section 5: Acceleration methods&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Refer to each section for details and mathematical formulations.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09-05 Acceleration</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_05_acceleration/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter09/09_05_acceleration</id>
   <content type="html">&lt;h1 id=&quot;acceleration&quot;&gt;Acceleration&lt;/h1&gt;

&lt;p&gt;Acceleration techniques are used to speed up the convergence of optimization algorithms. In the context of proximal gradient methods, acceleration can significantly improve the rate at which solutions are found.&lt;/p&gt;

&lt;h2 id=&quot;nesterovs-acceleration&quot;&gt;Nesterov’s acceleration&lt;/h2&gt;
&lt;p&gt;Nesterov’s acceleration is a popular technique that introduces momentum to the update steps, allowing the algorithm to move faster towards the optimum.&lt;/p&gt;

&lt;h2 id=&quot;fista&quot;&gt;FISTA&lt;/h2&gt;
&lt;p&gt;FISTA (Fast Iterative Shrinkage-Thresholding Algorithm) is an accelerated proximal gradient method that achieves a convergence rate of \(O(1/k^2)\).&lt;/p&gt;

&lt;h2 id=&quot;practical-considerations&quot;&gt;Practical considerations&lt;/h2&gt;
&lt;p&gt;While acceleration can improve convergence, it may also introduce instability or oscillations in some cases. It is important to monitor the behavior of the algorithm and adjust parameters as needed.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09-05-04 Is acceleration always useful?</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_05_04_is_acceleration_always_useful/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter09/09_05_04_is_acceleration_always_useful</id>
   <content type="html">&lt;h1 id=&quot;is-acceleration-always-useful&quot;&gt;Is acceleration always useful?&lt;/h1&gt;

&lt;p&gt;Acceleration methods such as FISTA can achieve faster convergence rates in theory, but in practice, acceleration is not always beneficial.&lt;/p&gt;

&lt;h2 id=&quot;when-acceleration-may-not-help&quot;&gt;When acceleration may not help&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;If the problem is ill-conditioned, acceleration can cause oscillations or instability.&lt;/li&gt;
  &lt;li&gt;For some non-smooth problems, acceleration may not improve convergence.&lt;/li&gt;
  &lt;li&gt;The “Nesterov ripples” phenomenon can cause non-monotonic behavior in the objective value.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;practical-advice&quot;&gt;Practical advice&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Use acceleration methods when the problem is well-conditioned and smooth.&lt;/li&gt;
  &lt;li&gt;Monitor convergence and stability when applying acceleration.&lt;/li&gt;
  &lt;li&gt;If instability occurs, consider switching to standard proximal gradient methods.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>09-05-03 Example: FISTA</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_05_03_example_FISTA/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter09/09_05_03_example_FISTA</id>
   <content type="html">&lt;h1 id=&quot;example-fista&quot;&gt;Example: FISTA&lt;/h1&gt;

&lt;p&gt;In this section, we introduce an example of the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA), which is an accelerated proximal gradient method.&lt;/p&gt;

&lt;h2 id=&quot;fista-algorithm&quot;&gt;FISTA Algorithm&lt;/h2&gt;
&lt;p&gt;The FISTA algorithm solves problems of the form:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\(\min_x g(x) + h(x)\)
where \(g\) is convex and differentiable, and \(h\) is convex.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The update steps are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Initialize \(x^{(0)} = x^{(-1)}\), \(t_0 = 1\).&lt;/li&gt;
  &lt;li&gt;For \(k = 1, 2, ...\):
    &lt;ul&gt;
      &lt;li&gt;
\[y^{(k)} = x^{(k-1)} + \frac{t_{k-1} - 1}{t_k} (x^{(k-1)} - x^{(k-2)})\]
      &lt;/li&gt;
      &lt;li&gt;
\[x^{(k)} = \text{prox}_{t_k}(y^{(k)} - t_k \nabla g(y^{(k)}))\]
      &lt;/li&gt;
      &lt;li&gt;
\[t_{k+1} = \frac{1 + \sqrt{1 + 4 t_k^2}}{2}\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;application-to-lasso&quot;&gt;Application to Lasso&lt;/h2&gt;
&lt;p&gt;FISTA can be applied to Lasso regression, which involves minimizing a least squares loss with an \(L_1\) regularization term.&lt;/p&gt;

&lt;p&gt;FISTA achieves faster convergence compared to standard proximal gradient methods.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09-05-02 Convergence analysis</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_05_02_convergence_analysis/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter09/09_05_02_convergence_analysis</id>
   <content type="html">&lt;h1 id=&quot;convergence-analysis&quot;&gt;Convergence analysis&lt;/h1&gt;

&lt;p&gt;In this section, we analyze the convergence of the accelerated proximal gradient method.&lt;/p&gt;

&lt;h2 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h2&gt;
&lt;p&gt;Suppose \(g\) is convex and differentiable, \(h\) is convex, and \(\nabla g\) is Lipschitz continuous with constant \(L &amp;gt; 0\). Then, the accelerated proximal gradient method with fixed step size \(t \le 1/L\) satisfies the following:&lt;/p&gt;

&lt;blockquote&gt;
\[f(x^{(k)}) - f^* \le \frac{2L \lVert x^{(0)} - x^* \rVert^2_2}{(k+1)^2}\]
&lt;/blockquote&gt;

&lt;p&gt;This means the convergence rate is \(O(1/k^2)\), which is faster than the standard proximal gradient method.&lt;/p&gt;

&lt;h2 id=&quot;backtracking-line-search&quot;&gt;Backtracking line search&lt;/h2&gt;
&lt;p&gt;The backtracking line search for the accelerated proximal gradient method is similar to that for the standard proximal gradient method, but the step size is chosen adaptively.&lt;/p&gt;

&lt;p&gt;For more details, refer to Beck and Teboulle (2009), “A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems” (FISTA).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09-05-01 Accelerated proximal gradient method</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_05_01_accelerated_proximal_gradient_method/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter09/09_05_01_accelerated_proximal_gradient_method</id>
   <content type="html">&lt;h1 id=&quot;accelerated-proximal-gradient-method&quot;&gt;Accelerated proximal gradient method&lt;/h1&gt;

&lt;p&gt;If proximal gradient descent is accelerated, it can achieve the optimal convergence rate of \(O(1/\sqrt{\epsilon})\). Nesterov proposed four methods, three of which are acceleration methods:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1983: Original acceleration method for smooth functions&lt;/li&gt;
  &lt;li&gt;1988: Another acceleration method for smooth functions&lt;/li&gt;
  &lt;li&gt;2005: Technique for smoothing nonsmooth functions along with the original acceleration method&lt;/li&gt;
  &lt;li&gt;2007: Acceleration method for composite functions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, let’s look at the method of Beck and Teboulle (2008), which extends Nesterov’s (1983) method for composite functions.&lt;/p&gt;

&lt;h2 id=&quot;accelerated-proximal-gradient-method-1&quot;&gt;Accelerated proximal gradient method&lt;/h2&gt;
&lt;p&gt;As before, suppose \(g\) is convex and differentiable, and \(h\) is convex. The problem is defined as:&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\min_x g(x) + h(x)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The &lt;strong&gt;Accelerated proximal gradient method&lt;/strong&gt; considers the direction in which \(x\) was moving so that the direction does not change abruptly when moving to the next position. In other words, it gives momentum to the direction of progress, creating inertia to continue moving in the same direction as before.&lt;/p&gt;

&lt;p&gt;The initial value of the algorithm is set to \(x^{(0)} = x^{(-1)} \in \mathbb{R}^n\). Then, after calculating the position \(v\) considering momentum, the proximal gradient is performed.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
v &amp;amp; = x^{(k-1)} + \frac{k-2}{k + 1}  (x^{(k-1)} −x^{(k-2)}) \\
x^{(k)} &amp;amp; = \text{prox}_{t_k} (v − t_k \nabla g(v)), k = 1,2,3,...  \\
\end{align}\]
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;In the first step \(k = 1\), \(x^{(k-1)} −x^{(k-2)}\) is zero, so it is the same as the proximal gradient update.&lt;/li&gt;
  &lt;li&gt;In the next steps, \(v\) has momentum in the previous direction \(x^{(k-1)} −x^{(k-2)}\). As \(k\) increases, the momentum weight increases and converges to 1.&lt;/li&gt;
  &lt;li&gt;When \(h = 0\), this is the same as the &lt;strong&gt;accelerated gradient method&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The figure below shows how the momentum weight changes as \(k\) changes.&lt;/p&gt;

&lt;p&gt;In this figure, the value is negative when k = 0, but since the momentum term is zero at that time, it does not cause any problems. As k increases, the weight approaches 1, so the value is updated further and helps to converge faster.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter09/momentum_weight.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Momentum weights [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;lasso-example&quot;&gt;Lasso example&lt;/h2&gt;
&lt;p&gt;If we apply the accelerated proximal gradient to the Lasso example seen earlier, we get the results shown in the figure below. It can be seen that the accelerated proximal gradient has much faster performance compared to subgradient or proximal gradient methods.&lt;/p&gt;

&lt;p&gt;There is a part in the middle of the graph that jumps, which is called “Nesterov ripples.” Therefore, the accelerated proximal gradient is not monotonic decreasing and is not a descent method.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter09/accelerated_proximal_gradient.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig2] Accelerated Proximal Gradient [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 
 <entry>
   <title>09-04 Special cases</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_04_special_cases/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter09/09_04_special_cases</id>
   <content type="html">&lt;h1 id=&quot;special-cases&quot;&gt;Special cases&lt;/h1&gt;

&lt;p&gt;Proximal gradient descent is also called composite gradient descent or generalized gradient descent.&lt;/p&gt;

&lt;p&gt;Why is it called &lt;strong&gt;“generalized”&lt;/strong&gt;? The reason is that Proximal gradient descent encompasses all of the following special cases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(h = 0 \to\) gradient descent&lt;/li&gt;
  &lt;li&gt;\(h = I_C \to\) projected gradient descent&lt;/li&gt;
  &lt;li&gt;\(g = 0 \to\) proximal minimization algorithm&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Therefore, all these algorithms have a convergence rate of \(O(1/\epsilon)\).&lt;/p&gt;

&lt;h2 id=&quot;projected-gradient-descent&quot;&gt;Projected gradient descent&lt;/h2&gt;
&lt;p&gt;When \(I_C(x)\) is the indicator function of a closed convex set \(C \in \mathbb{R}^n\), the problem of minimizing \(g(x)\) over the set \(C\) can be reformulated as follows. (Note: \(C\) must be a closed set so that the projection is well-defined.)&lt;/p&gt;

&lt;blockquote&gt;
\[\min_{x \in C} g(x) \iff \min_x g(x) + I_C(x)\]

\[I_C(x) = 
\begin{cases}
0, &amp;amp; x \in C \\
\infty, &amp;amp; x \notin C
\end{cases}\]
&lt;/blockquote&gt;

&lt;p&gt;At this time, the proximal mapping is defined as follows.&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{prox}_t(x)  
&amp;amp;= \underset{z}{\text{argmin}} \frac{1}{2t} \lVert x−z \rVert_2^2 + I_C(z) \\
&amp;amp; = \underset{z \in C}{\text{argmin}} \lVert x−z \rVert_2^2
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;As a result, the proximal mapping \(\text{prox}_t(x) = P_C(x)\) is the projection operator onto \(C\).&lt;/p&gt;

&lt;p&gt;The proximal gradient update step is: \(x^+ = P_C (x−t \nabla g(x) )\). In other words, after performing the gradient descent update, you project onto \(C\).&lt;/p&gt;

&lt;p&gt;In the figure below, the pink rectangle is the feasible set \(C\), and the current position is the upper of the two points below the rectangle. After taking a gradient descent step, you move outside \(C\), so you project back onto \(C\) to return inside the feasible set.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter09/projected_gradient_descent.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig1] Projected Gradient Descent [3]]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;proximal-minimization-algorithm&quot;&gt;Proximal minimization algorithm&lt;/h2&gt;

&lt;p&gt;Consider the problem of minimizing a convex function \(h\) as follows. Here, \(h\) does not need to be differentiable and \(g(x) = 0\).&lt;/p&gt;
&lt;blockquote&gt;

  &lt;p&gt;\begin{align}
\min_x h(x)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The proximal mapping is defined as:&lt;/p&gt;
&lt;blockquote&gt;
\[\begin{align}
x^{(k)} &amp;amp;= \text{prox}_{t_k} \big(x^{(k-1)} - t_k \nabla g ( x^{(k-1)} ) \big) , \qquad k = 1, 2, 3, ... \\
&amp;amp;= \text{prox}_{t_k} \big(x^{(k-1)} \big) ,  \qquad \qquad \qquad \qquad \; k = 1, 2, 3, ... \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Therefore, the proximal gradient update step is:&lt;/p&gt;
&lt;blockquote&gt;
\[x^+ = \underset{z}{\text{argmin}} \frac{1}{2t} \lVert x−z \rVert_2^2 + h(z)\]
&lt;/blockquote&gt;

&lt;p&gt;This proximal gradient method, defined only by \(h\) with \(g = 0\), is called the &lt;strong&gt;proximal minimization algorithm (PMA)&lt;/strong&gt;. This method is faster than subgradient methods, but if the proximal mapping does not have a closed form, it cannot be implemented.&lt;/p&gt;

&lt;h2 id=&quot;what-happens-if-we-cant-evaluate-prox&quot;&gt;What happens if we can’t evaluate prox?&lt;/h2&gt;
&lt;p&gt;Theoretically, when applying proximal gradient to \(f = g + h\), it is assumed that the prox function can be computed exactly. That is, it is assumed that the minimum can be found exactly via the proximal mapping.&lt;/p&gt;
&lt;blockquote&gt;
\[\text{prox}_t(x )= \underset{z}{\text{argmin}} \frac{1}{2t} \lVert x−z \rVert_2^2 + h(z)\]
&lt;/blockquote&gt;

&lt;p&gt;In general, it is not clear what happens if the minimum is only approximated.
However, if the error in approximating the prox operator can be precisely controlled, it has been shown that the original convergence rate can be maintained. (Schmidt et al. (2011), Convergence rates of inexact proximal-gradient methods for convex optimization)&lt;/p&gt;

&lt;p&gt;In practice, if prox can be computed approximately, it will be performed with high accuracy.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09-03 Example: matrix completion</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_03_example_matrix_completion/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter09/09_03_example_matrix_completion</id>
   <content type="html">&lt;h1 id=&quot;example-matrix-completion&quot;&gt;Example: matrix completion&lt;/h1&gt;

&lt;p&gt;In various applications, measured data is often represented as a matrix. In these cases, most entries in the matrix may be empty, with only a few entries containing observed data, leading to a sparse matrix. The challenge of filling in the missing entries in such a matrix is referred to as the &lt;strong&gt;Matrix completion&lt;/strong&gt; problem.&lt;/p&gt;

&lt;p&gt;For instance, this issue can occur in recommendation systems when suggesting products or services to customers who have not yet made a purchase.&lt;/p&gt;

&lt;h2 id=&quot;matrix-completion-problem&quot;&gt;Matrix Completion Problem&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;Matrix completion&lt;/strong&gt; problem can be articulated as follows:&lt;/p&gt;

&lt;p&gt;Let the matrix \(Y \in \mathbb{R}^{m\times n}\) represent the observed data, and let \(Y_{ij}, (i,j) \in \Omega\) denote the entries that contain observed data. The matrix \(B\) is the estimated matrix used to predict the missing entries.&lt;/p&gt;

&lt;blockquote&gt;
\[\min_B \frac{1}{2} \sum_{(i,j)\in\Omega} (Y_{ij} −B_{ij})^2 + \lambda\lVert B \rVert_{tr}\]
&lt;/blockquote&gt;

&lt;p&gt;The first term in the objective function aims to minimize the error between matrix \(B\) and the observed data, while the second term encourages matrix \(B\) to be low-rank. (It is assumed that matrix B resides on a low-dimensional manifold.) Consequently, matrix \(B\) fills in the missing entries with the lowest-dimensional values that align with the observed data.&lt;/p&gt;

&lt;h3 id=&quot;reference-trace-norm&quot;&gt;[Reference] Trace Norm&lt;/h3&gt;
&lt;p&gt;The trace norm of a matrix is defined as the sum of its singular values.&lt;/p&gt;

&lt;blockquote&gt;
\[\lVert B \rVert_{tr} = \text{trace}(\sqrt{B^* B}) = \sum_{i=1}^r \sigma_i(B), \quad r = rank(B)\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(B^* B\) is positive semi-definite, and the singular values are ordered as \(\sigma_1(X) \ge ... \ge \sigma_r(X) \ge 0\).&lt;/p&gt;

&lt;h3 id=&quot;reference-l1-norm-regularizer-vs-trace-norm-regularizer&quot;&gt;[Reference] &lt;strong&gt;L1&lt;/strong&gt; Norm Regularizer vs. Trace Norm Regularizer&lt;/h3&gt;
&lt;p&gt;This problem can be interpreted as matrix soft-thresholding, where the vector in the original soft-thresholding is substituted with a matrix. In the regularizer term, the &lt;strong&gt;L1&lt;/strong&gt; norm regularizer for vectors (\(\lVert \cdot \rVert_{1}\)) is replaced by the trace norm regularizer (\(\lVert \cdot \rVert_{tr}\)) for matrices, and indeed, the functions of the two regularizers are analogous.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;L1&lt;/strong&gt; norm regularizer induces sparsity in the vector, while the trace norm regularizer similarly induces sparsity in the singular value vector of the matrix. When the matrix is diagonal, the diagonal elements can be viewed as the singular value vector, and the trace norm regularizer minimizes the sum of the singular values, promoting sparsity in the singular value vector.&lt;/p&gt;

&lt;p&gt;In this context, the trace norm \(\lVert B \rVert_{tr}\) serves as an approximation for \(\text{Rank}(B)\).&lt;/p&gt;

&lt;h2 id=&quot;proximal-gradient-descent&quot;&gt;Proximal gradient descent&lt;/h2&gt;
&lt;p&gt;When this problem is framed using a projection operator, proximal gradient descent can be effectively utilized.&lt;/p&gt;
&lt;h3 id=&quot;projection-operator&quot;&gt;Projection Operator&lt;/h3&gt;
&lt;p&gt;Let’s define the projection operator \(P_\Omega\) for the observed values as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[[ P_\Omega(B) ] _{ij} =
\begin{cases}
B_{ij}, &amp;amp; (i,j) ∈ \Omega \\\
0, &amp;amp; (i,j) \notin \Omega
\end{cases}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;objective-function&quot;&gt;Objective Function&lt;/h3&gt;
&lt;p&gt;Utilizing the projection operator, the objective function is defined as:&lt;/p&gt;

&lt;blockquote&gt;
\[f(B) = \underbrace{ \frac{1}{2} \lVert P_\Omega(Y) − P_\Omega(B) \rVert_F^2 }_{g(B)} + \underbrace{ \lambda \lVert B \rVert_{tr} }_{h(B)}\]
&lt;/blockquote&gt;

&lt;p&gt;Now, the function \(f(B)\) consists of a differentiable part \(g(B)\) and a non-differentiable part \(h(B)\).&lt;/p&gt;

&lt;h3 id=&quot;proximal-mapping&quot;&gt;Proximal Mapping&lt;/h3&gt;
&lt;p&gt;To apply proximal gradient descent, we need to compute the gradient of the function \(g(B)\) and define the proximal mapping.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Gradient of \(g(B)\): \(\nabla g(B) = −(P_\Omega(Y )−P_\Omega(B))\)&lt;/li&gt;
  &lt;li&gt;Proximal mapping:&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
\[\begin{align}
\text{prox}_t (B) = \underset{Z}{\text{argmin}} \frac{1}{2t} \Vert B−Z \Vert_F^2 + \lambda \Vert Z \Vert_{tr}
\end{align}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;matrix-svd--soft-thresholding&quot;&gt;Matrix SVD &amp;amp; Soft-thresholding&lt;/h3&gt;
&lt;p&gt;The proximal mapping corresponds to matrix soft-thresholding at level \(\lambda\): \(\text{prox}_t(B) = S_{\lambda t}(B)\).&lt;/p&gt;

&lt;p&gt;Typically, matrix \(B\) is large, so Singular Vector Decomposition (SVD) is employed to minimize the computational load. If we perform SVD such that \(B = U \Sigma V^T\), then \(S_\lambda(B)\) can be defined as:&lt;/p&gt;

&lt;blockquote&gt;
\[S_\lambda(B) = U \Sigma_\lambda V^T\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(\Sigma_\lambda\) is a diagonal matrix defined as follows:&lt;/p&gt;

&lt;blockquote&gt;
\[(\Sigma_\lambda)_{ii} = \max \{ \Sigma_{ii} −\lambda,0 \}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;reference-sigma_lambda_ii--max--sigma_ii-lambda0---inducement&quot;&gt;[Reference] \((\Sigma_\lambda)_{ii} = \max \{ \Sigma_{ii} −\lambda,0 \}\)  inducement&lt;/h3&gt;
&lt;p&gt;How is this expression derived? Assuming \(\text{prox}_t(B) = Z\), we have:
(Differentiating the right-hand side of \(\text{prox}_t(B)\) with respect to Z yields the following result.)&lt;/p&gt;

&lt;blockquote&gt;
\[0 ∈ Z − B + \lambda t \cdot \partial \lVert Z \rVert_{tr}\]
&lt;/blockquote&gt;

&lt;p&gt;Rearranging this expression gives:&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
Z &amp;amp; = B - \lambda t \cdot \partial \lVert Z \rVert_{tr} \\
 &amp;amp; = U \Sigma V^T - \lambda t \cdot (UV^T + W) \\
 &amp;amp; = U (\Sigma - \lambda t) V^T - \lambda t  W \\
 &amp;amp; = U (\Sigma - \lambda ) V^T  \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;The final expression can be obtained when the Lipschitz constant is \(L=1\) and \(W\) is 0.&lt;/p&gt;

&lt;p&gt;Thus, we have \(\text{prox}_t(B) = S_\lambda(B) = Z\), leading to the derivation of the following expression:&lt;/p&gt;

&lt;blockquote&gt;
\[(\Sigma_\lambda)_{ii} = \max \{ \Sigma_{ii} −\lambda,0 \}\]
&lt;/blockquote&gt;

&lt;h3 id=&quot;reference-derivative-of-trace-norm&quot;&gt;[Reference] Derivative of Trace Norm&lt;/h3&gt;
&lt;p&gt;If \(Z = U \Sigma V^T\), the derivative of the trace norm is given by:&lt;/p&gt;
&lt;blockquote&gt;
\[\partial \lVert Z \rVert_{tr} = \{UV^T + W : \lVert W \rVert_{op} ≤ 1, U^TW = 0, WV = 0 \}\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(\lVert W \rVert_{op}\) represents the operator norm, with the largest singular value being less than 1. Additionally, \(W\) is orthogonal to both \(U^T\) and \(V\).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For proof, refer to &lt;a href=&quot;https://math.stackexchange.com/questions/701062/derivative-of-the-nuclear-norm-with-respect-to-its-argument&quot;&gt;Derivative of the nuclear norm with respect to its argument&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;proximal-gradient-update&quot;&gt;Proximal gradient update&lt;/h3&gt;
&lt;p&gt;Now, let’s define the proximal gradient update equation.&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = S_{\lambda t} ( B + t( P_\Omega(Y) − P_\Omega(B) ) )\]
&lt;/blockquote&gt;

&lt;p&gt;When \(L = 1\), \(\nabla g(B)\) is Lipschitz continuous, allowing us to choose a fixed step size of \(t = 1\).&lt;/p&gt;

&lt;p&gt;Consequently, the update equation simplifies to:&lt;/p&gt;

&lt;blockquote&gt;
\[B^+ = S_\lambda (P_\Omega(Y) + P_\Omega^\bot (B) )\]
&lt;/blockquote&gt;

&lt;p&gt;Here, \(P_\Omega^\bot\) represents the projection onto the unobserved values, satisfying the equation \(P_\Omega(B) + P_\Omega^\bot (B) = B\).&lt;/p&gt;

&lt;p&gt;In this equation, \(P_\Omega(Y)\) denotes the observed part, while \(P_\Omega^\bot (B)\) represents the missing part. The \(S_\lambda\) function is straightforward to compute, as it only requires performing SVD and calculating \((\Sigma_\lambda)_{ii} = \max \{ \Sigma_{ii} −\lambda,0 \}\).&lt;/p&gt;

&lt;h2 id=&quot;soft-impute-algorithm&quot;&gt;Soft-Impute Algorithm&lt;/h2&gt;
&lt;p&gt;This algorithm is known as &lt;strong&gt;Soft-Impute&lt;/strong&gt; and provides a simple yet effective solution for matrix completion. When dealing with large matrices, the computational cost of SVD can be high. However, due to the sparsity of \(P_\Omega(Y)\) and the low rank of \(P_\Omega^\bot (B)\) in this algorithm, SVD can be performed efficiently.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For more detailed information, please refer to the paper: Mazumder et al. (2011), “Spectral regularization algorithms for learning
large incomplete matrices”&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>09-02 Convergence analysis</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_02_convergence_analysis/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter09/09_02_convergence_analysis</id>
   <content type="html">&lt;h1 id=&quot;convergence-analysis&quot;&gt;Convergence analysis&lt;/h1&gt;
&lt;p&gt;In this section, we analyze the convergence of proximal gradient descent.&lt;/p&gt;

&lt;h2 id=&quot;convergence-analysis-1&quot;&gt;Convergence Analysis&lt;/h2&gt;
&lt;p&gt;For the objective function \(f(x) = g(x) + h(x)\), we assume the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(g\) is convex, differentiable, and &lt;strong&gt;dom&lt;/strong&gt;\((g) = \mathbb{R}^n\), and \(\nabla g\) is Lipschitz continuous (\(L &amp;gt; 0\)).&lt;/li&gt;
  &lt;li&gt;\(h\) is convex, and \(\text{prox}_{t}(x) = \underset{z} {\text{argmin}} \{ \parallel x - z \parallel_2^2/ (2t) + h(z) \}\) needs to be computed.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;convergence-theorem&quot;&gt;Convergence Theorem&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt; satisfies the following equation for a fixed step size \(t \le 1/L\): 
\begin{align}
f(x^{(k)}) - f^{*} \le  \frac{ \lVert x^{(0)} - x^{*} \rVert^2_2 }{2tk}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Proximal gradient descent has a convergence rate of \(O(1/k)\) or \(O(1/\epsilon)\), which is the same performance as gradient descent. However, this performance is based on the number of iterations, not the number of operations. (The number of operations can vary depending on the function \(h\).)&lt;/p&gt;

&lt;h2 id=&quot;backtracking-line-search&quot;&gt;Backtracking line search&lt;/h2&gt;
&lt;p&gt;The backtracking line search method of proximal gradient descent is similar to gradient descent but operates only on the smooth part \(g\), not the function \(f\).&lt;/p&gt;

&lt;p&gt;First, set the parameter to \(0 &amp;lt; \beta &amp;lt; 1\) and start with \(t=1\). In each iteration, reduce \(t\) to \(t = \beta t\) while satisfying the following condition, and update proximal gradient descent if the condition is not met.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
g(x - tG_t(x)) &amp;gt; g(x) - t \nabla g(x)^T G_t(x) + \frac{t}{2} \parallel G_t(x) \parallel_2 ^2
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This backtracking condition means that the value of the function \(g\) at the next step location \(x - tG_t(x)\) is greater than the value of the Taylor second-order approximation of the function \(g\).&lt;/p&gt;

&lt;p&gt;If \(G_t(x) = \nabla g(x)\) in this equation, we can see that \(g(x - t \nabla g(x)) &amp;gt; g(x) - \alpha t \lVert \nabla g(x) \rVert_2^2\), which becomes identical to the backtracking condition of gradient descent.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For more details on the backtracking of gradient descent, refer to &lt;a href=&quot;/contents/en/chapter06/06_02_02_backtracking_line_search/&quot;&gt;06-02-02 backtracking line search&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;backtracking-line-search-algorithm&quot;&gt;Backtracking line search algorithm&lt;/h3&gt;
&lt;p&gt;If we summarize this in an algorithm, it is as follows. (However, \(\nabla x = - t G_t(x)\))&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize the parameters. (\(0 \lt \beta \lt 1\), \(0 \lt \alpha \le 1/2\))&lt;/li&gt;
  &lt;li&gt;In each iteration, initialize \(t = t_{\text{init}}\). (\(t_{\text{init}} = 1\))&lt;/li&gt;
  &lt;li&gt;If the condition \(g(x - tG_t(x)) \gt g(x) - t \nabla g(x)^T G_t(x) + \frac{t}{2} \parallel G_t(x) \parallel_2 ^2\) is satisfied, reduce \(t = \beta t\). Repeat step 3 while this condition is met.&lt;/li&gt;
  &lt;li&gt;Perform the gradient descent update \(x^+ = x - t G_t(x) = \text{prox}_t(x - t \nabla g(x))\).&lt;/li&gt;
  &lt;li&gt;If the termination condition is not met, go back to step 2.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;When backtracking in proximal gradient descent, since \(G_t(x)\) is computed repeatedly, the proximal mapping included in \(G_t(x)\) is also computed repeatedly. Since the proximal mapping is very costly to compute, the overall computational cost of backtracking can be high.&lt;/p&gt;

&lt;h3 id=&quot;convergence-theorem-1&quot;&gt;Convergence Theorem&lt;/h3&gt;
&lt;p&gt;Under the same assumptions as above, the backtracking line search method also satisfies the same performance.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt; satisfies the following equation for backtracking line search. The step size is \(t_{\text{min}} = \text{min} \{1,\beta /L \}\).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
\[f(x^{(k)})−f^{\star} ≤ \frac{\lVert x^{(0)} − x^{\star} \rVert_{2}^{2}}{2 t_{min}k}, \space t_{\text{min}} = \text{min} \{ 1, \beta / L \} \\\]
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>09-01 Proximal gradient descent</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_01_proximal_gradient_descent/"/>
   <updated>2020-01-08T00:00:00+07:00</updated>
   <id>http://localhost:4000/optimization-for-data-science-iuh-2025/contents/en/chapter09/09_01_proximal_gradient_descent</id>
   <content type="html">&lt;h1 id=&quot;proximal-gradient-descent&quot;&gt;Proximal gradient descent&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Proximal gradient descent&lt;/strong&gt; is a method for finding the optimum by decomposing the objective function into a differentiable part and a non-differentiable part. In this section, we will look at how to define functions and find the optimum in proximal gradient descent.&lt;/p&gt;

&lt;h2 id=&quot;decomposable-functions&quot;&gt;Decomposable functions&lt;/h2&gt;
&lt;p&gt;Suppose the objective function \(f\) can be decomposed into two functions \(g\) and \(h\).&lt;/p&gt;

&lt;blockquote&gt;
\[f(x) = g(x) + h(x)\]
&lt;/blockquote&gt;

&lt;p&gt;Here, the two functions \(g\) and \(h\) have the following properties:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(g\) is convex and differentiable. (&lt;strong&gt;dom&lt;/strong&gt;\((g) = \mathbb{R}^n\))&lt;/li&gt;
  &lt;li&gt;\(h\) is convex and non-differentiable.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If \(f\) is differentiable, you can find the next position using gradient descent:&lt;/p&gt;

&lt;blockquote&gt;
\[x^+ = x - t \cdot \nabla f(x)\]
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;[Note]&lt;/strong&gt; In gradient descent, the function \(f\) is approximated near \(x\) by a second-order Taylor expansion, and the Hessian \(\nabla^2 f(x)\) is replaced by \(\frac{1}{2t} I\). The minimum of this approximation is chosen as the next position. (See Chapter 6 Gradient descent for details)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^+ = \underset{z}{\text{argmin}}  \underbrace{ f(x) + \nabla f(x)^T (z - x) + \frac{1}{2t} \parallel z - x \parallel_2 ^2}_{\tilde{f}_t(z)}
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;However, if \(f\) is not differentiable, you cannot use gradient descent. But if \(f\) is composed as \(f = g + h\), can’t we approximate the differentiable part \(g\) with a quadratic?&lt;/p&gt;

&lt;p&gt;This idea leads to &lt;strong&gt;Proximal gradient descent&lt;/strong&gt;. In this method, you adjust to the best position that is close to the location predicted by gradient descent for \(g\) and also makes the non-differentiable function \(h\) small. This process can be expressed as follows:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
x^+ &amp;amp; = \underset{z}{\text{argmin}}   \tilde{g}_t(z) + h(z) \\
&amp;amp; = \underset{z}{\text{argmin}} \ g(x) + \nabla g(x)^T (z - x) + \frac{1}{2t} \parallel z - x \parallel_2 ^2 + h(z) \\
&amp;amp; = \underset{z}{\text{argmin}}  \nabla g(x)^T (z - x) + \frac{1}{2t} \parallel z - x \parallel_2 ^2 + \frac{t}{2} \parallel \nabla g(x) \parallel_2 ^2  + h(z) \\
&amp;amp; = \underset{z}{\text{argmin}}  \frac{1}{2t} \left ( 2t \nabla g(x)^T (z - x) + \parallel z - x \parallel_2 ^2 + t^2 \parallel \nabla g(x) \parallel_2 ^2 \right )  + h(z) \\
&amp;amp; = \underset{z}{\text{argmin}}  \frac{1}{2t} \left ( \parallel z - x \parallel_2 ^2 + 2t \nabla g(x)^T (z - x) + t^2 \parallel \nabla g(x) \parallel_2 ^2 \right ) + h(z) \\
&amp;amp; = \underset{z}{\text{argmin}}   \frac{1}{2t} \parallel z - (x - t \nabla g(x) )\parallel_2 ^2 + h(z) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;When moving from the 2nd to the 3rd line, the term \(g(x)\) is removed as a constant term with respect to z, and the term \(\frac{t}{2} \parallel \nabla g(x)^T \parallel_2 ^2\) is added. In the final equation, the first term \(\frac{1}{2t} \parallel z - (x - t \nabla g(x) )\parallel_2 ^2\) is the term that brings it closer to the gradient update position of \(g\), and the second term \(h(z)\) is the term that reduces \(h\).&lt;/p&gt;

&lt;h2 id=&quot;proximal-gradient-descent-1&quot;&gt;Proximal gradient descent&lt;/h2&gt;
&lt;p&gt;Proximal gradient descent starts from an initial point \(x^{(0)}\) and iteratively applies the following update:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\(x^{(k)} = \text{prox}_{t_k}(x^{(k-1)} - t_k \nabla g(x^{(k-1)}) )\), \(k=1,2,3,...\)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, \(\text{prox}_{t}\) is defined as the proximal mapping:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
\text{prox}_{t}(x) = \underset{z}{\arg \min}  \frac{1}{2t} \parallel x - z \parallel_2^2 + h(z)
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we rewrite this in the update form we have seen so far, it becomes:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
x^{(k)} = x^{(k-1)} - t_k \cdot G_{t_k}(x^{(k-1)}), \space \space \text{where} \space G_{t}(x) = \frac{x-\text{prox}_{t} (x - t \nabla g(x))}{t} &lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;what-good-did-this-do&quot;&gt;What good did this do?&lt;/h2&gt;
&lt;p&gt;What is the benefit of doing this? Could it be just changing the problem to another form of minimization problem?&lt;/p&gt;

&lt;p&gt;The key point is that for most of the main \(h\) functions, \(\text{prox}_{t}(\cdot)\) can be computed analytically. In other words, it can be calculated as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The mapping function \(\text{prox}_{t}(\cdot)\) depends only on \(h\), not on \(g\).&lt;/li&gt;
  &lt;li&gt;The function \(g\) can be very complex, but here we only need to compute the gradient \(\nabla g\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The convergence analysis will be done concerning the number of iterations of the algorithm. Note that in each iteration, computing \(\text{prox}_{t}(\cdot)\) may vary in computational cost depending on \(h\).&lt;/p&gt;

&lt;h2 id=&quot;example-ista&quot;&gt;Example: ISTA&lt;/h2&gt;
&lt;p&gt;Let’s look at an example of proximal gradient descent. In the previous chapter, the lasso criterion was defined as follows when \(y \in \mathbb{R}^n\) and \(X \in \mathbb{R}^{n \times p}\):&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;\begin{align}
f(\beta) = \frac{1}{2} \parallel y - X\beta \parallel_2^2 + \lambda \parallel \beta \parallel_1 &lt;br /&gt;
\end{align}&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, \(g(\beta) = \frac{1}{2} \parallel y - X\beta \parallel_2^2\) and \(h(\beta) = \lambda \parallel \beta \parallel_1\). In this case, the proximal mapping is defined as:&lt;/p&gt;

&lt;blockquote&gt;

\[\begin{align}
\text{prox}_{t}(\beta) &amp;amp; = \underset{z}{\text{argmin}}  \frac{1}{2t} \parallel \beta - z \parallel_2^2 + \lambda \parallel z \parallel_1 \\
&amp;amp; = S_{\lambda t}(\beta) \\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;\(S_{\lambda t}(\beta)\) is the soft-thresholding operator, defined as follows. (For more details, see Chapter 7 Subgradient)&lt;/p&gt;

&lt;blockquote&gt;
\[\begin{align}
[S_{\lambda t}(\beta)]_i =
\begin{cases}
\beta_i - \lambda &amp;amp; \mbox{if } \beta_i \gt \lambda \\
0 &amp;amp; \mbox{if } \lambda \le \beta_i \le \lambda, i = 1, ..., n \\
\beta_i + \lambda &amp;amp; \mbox{if } \beta_i \lt -\lambda \\
\end{cases}
\\
\end{align}\]
&lt;/blockquote&gt;

&lt;p&gt;Since the gradient of \(g\) is \(\nabla g(\beta) = -X^{T} (y - X \beta)\), the proximal gradient update is defined as:&lt;/p&gt;

&lt;blockquote&gt;
\[\beta^+ = S_{\lambda t}(\beta + tX^{T} (y - X \beta) )\]
&lt;/blockquote&gt;

&lt;p&gt;This algorithm is a very simple algorithm called the &lt;strong&gt;iterative soft-thresholding algorithm (ISTA)&lt;/strong&gt;. (Beck and Teboulle (2008), “A fast iterative shrinkage-thresholding algorithm for linear inverse problems”)&lt;/p&gt;

&lt;p&gt;In the following figure, you can clearly see the performance difference between the subgradient method and proximal gradient descent. In terms of the number of iterations, the performance of proximal gradient descent is comparable to that of gradient descent.&lt;/p&gt;

&lt;figure class=&quot;image&quot; style=&quot;align: center;&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/optimization-for-data-science-iuh-2025/img/chapter_img/chapter09/09.01_01_ISTA.png&quot; width=&quot;80%&quot; height=&quot;80%&quot; /&gt;
  &lt;figcaption style=&quot;text-align: center;&quot;&gt;[Fig 1] Example of proximal gradient (ISTA) vs. subgradient method convergence rate [3]&lt;/figcaption&gt;
&lt;/p&gt;
&lt;/figure&gt;
</content>
 </entry>
 

</feed>
