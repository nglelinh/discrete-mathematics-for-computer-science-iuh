<!DOCTYPE html>
<html lang="vi">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <style>
    .MathJax {
      padding: 2em 0.3em;
      overflow-x: auto;
      overflow-y: hidden;
    }
  </style>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

  <title>
    
      06-01 Gradient Descent &middot; Optimization in Data Science
    
  </title>

  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/poole.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/syntax.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/lanyon.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/github-markdown.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/multilang.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/search.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/content-boxes.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap">
  
  <!-- Lunr.js for search functionality -->
  <script src="https://unpkg.com/lunr/lunr.js"></script>

  <link rel="apple-touch-icon-precomposed" sizes="122x144" href="http://localhost:4000/optimization-for-data-science-iuh-2025/public/logo.png">
  <link rel="shortcut icon" href="http://localhost:4000/optimization-for-data-science-iuh-2025/public/convex-logo-144x144.png">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="http://localhost:4000/optimization-for-data-science-iuh-2025/atom.xml">

  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', '', 'auto');
    ga('send', 'pageview');
  </script>
  
</head>


  <body class="sidebar-overlay">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>T·ªëi ∆∞u h√≥a trong Khoa h·ªçc D·ªØ li·ªáu</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/">Trang ch·ªß</a>

    

    
    
    
    <!-- Hi·ªÉn th·ªã c√°c ch∆∞∆°ng c√≥ s·∫µn cho ng√¥n ng·ªØ hi·ªán t·∫°i -->
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/">
              00. C√°c Kh√°i Ni·ªám To√°n H·ªçc C∆° B·∫£n
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter01/">
              01. Gi·ªõi thi·ªáu
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/">
              02. T·∫≠p L·ªìi
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/">
              03. H√†m L·ªìi
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/">
              04. C∆° b·∫£n v·ªÅ T·ªëi ∆∞u h√≥a L·ªìi
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/">
              05. C√°c B√†i To√°n Chu·∫©n
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/">
              06. Gradient Descent
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/">
              07. Subgradient
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/">
              08. Subgradient Method
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/">
              09. Proximal Gradient Descent and Acceleration
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter10/">
              10. Duality in Linear Programs
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter11/">
              11. Duality in General Programs
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter12/">
              12. KKT Conditions
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/">
              13. Duality uses and correspondences
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/">
              14. Newton's Method
              
            </a>
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter16/">
              16. Duality Revisited
              
            </a>
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter18/">
              18. Quasi-Newton Methods
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/">
              19. Proximal Netwon Method
              
            </a>
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
        
      
    
    
    <!-- N·∫øu kh√¥ng c√≥ n·ªôi dung cho ng√¥n ng·ªØ hi·ªán t·∫°i, hi·ªÉn th·ªã th√¥ng b√°o -->
    
    
    <!-- Hi·ªÉn th·ªã th√¥ng tin v·ªÅ t√¨nh tr·∫°ng d·ªãch thu·∫≠t -->
    
      <div class="sidebar-nav-item" style="font-size: 0.8em; color: #999; margin-top: 10px;">
        üìù 26 ch∆∞∆°ng ƒë√£ d·ªãch / 26 ch∆∞∆°ng t·ªïng
      </div>
    
    
    <span class="sidebar-nav-item">Currently v0.0.1</span>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2025. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap github-md-body">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/optimization-for-data-science-iuh-2025/" title="Trang ch·ªß">T·ªëi ∆∞u h√≥a trong Khoa h·ªçc D·ªØ li·ªáu</a>
            <small></small>
          </h3>
          <!-- Header Actions: Language Toggle and GitHub Link -->
          <div class="header-actions">
            <div class="language-toggle">
              <a href="/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_01_gradient_descent/" class="language-switch" title="Chuy·ªÉn sang ti·∫øng Anh">Chuy·ªÉn sang ti·∫øng Anh</a>
            </div>
            <a class="github-logo__wrapper" target="_blank" href="https://github.com/nglelinh/optimization-for-data-science-iuh-2025" title="Github">
             <svg class="github-logo" xmlns="http://www.w3.org/2000/svg"  viewBox="0 0 48 48"><linearGradient id="rL2wppHyxHVbobwndsT6Ca" x1="4" x2="44" y1="23.508" y2="23.508" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#4c4c4c"/><stop offset="1" stop-color="#343434"/></linearGradient><path fill="url(#rL2wppHyxHVbobwndsT6Ca)" d="M24,4C12.954,4,4,12.954,4,24c0,8.887,5.801,16.411,13.82,19.016h12.36	C38.199,40.411,44,32.887,44,24C44,12.954,35.046,4,24,4z"/><path d="M30.01,41.996L30,36.198c0-0.939-0.22-1.856-0.642-2.687c5.641-1.133,8.386-4.468,8.386-10.177	c0-2.255-0.665-4.246-1.976-5.92c0.1-0.317,0.174-0.645,0.22-0.981c0.188-1.369-0.023-2.264-0.193-2.984l-0.027-0.116	c-0.186-0.796-0.409-1.364-0.418-1.388l-0.111-0.282l-0.111-0.282l-0.302-0.032l-0.303-0.032c0,0-0.199-0.021-0.501-0.021	c-0.419,0-1.04,0.042-1.627,0.241l-0.196,0.066c-0.74,0.249-1.439,0.485-2.417,1.069c-0.286,0.171-0.599,0.366-0.934,0.584	C27.334,12.881,25.705,12.69,24,12.69c-1.722,0-3.365,0.192-4.889,0.571c-0.339-0.22-0.654-0.417-0.942-0.589	c-0.978-0.584-1.677-0.819-2.417-1.069l-0.196-0.066c-0.585-0.199-1.207-0.241-1.626-0.241c-0.302,0-0.501,0.021-0.501,0.021	l-0.302,0.032l-0.3,0.031l-0.112,0.281l-0.113,0.283c-0.01,0.026-0.233,0.594-0.419,1.391l-0.027,0.115	c-0.17,0.719-0.381,1.615-0.193,2.983c0.048,0.346,0.125,0.685,0.23,1.011c-1.285,1.666-1.936,3.646-1.936,5.89	c0,5.695,2.748,9.028,8.397,10.17c-0.194,0.388-0.345,0.798-0.452,1.224c-0.197,0.067-0.378,0.112-0.538,0.137	c-0.238,0.036-0.487,0.054-0.739,0.054c-0.686,0-1.225-0.134-1.435-0.259c-0.313-0.186-0.872-0.727-1.414-1.518	c-0.463-0.675-1.185-1.558-1.992-1.927c-0.698-0.319-1.437-0.502-2.029-0.502c-0.138,0-0.265,0.01-0.376,0.028	c-0.517,0.082-0.949,0.366-1.184,0.78c-0.203,0.357-0.235,0.773-0.088,1.141c0.219,0.548,0.851,0.985,1.343,1.255	c0.242,0.133,0.765,0.619,1.07,1.109c0.229,0.368,0.335,0.63,0.482,0.992c0.087,0.215,0.183,0.449,0.313,0.732	c0.47,1.022,1.937,1.924,2.103,2.023c0.806,0.483,2.161,0.638,3.157,0.683l0.123,0.003c0,0,0.001,0,0.001,0	c0.24,0,0.57-0.023,1.004-0.071v2.613c0.002,0.529-0.537,0.649-1.25,0.638l0.547,0.184C19.395,43.572,21.645,44,24,44	c2.355,0,4.605-0.428,6.703-1.176l0.703-0.262C30.695,42.538,30.016,42.422,30.01,41.996z" opacity=".05"/><path d="M30.781,42.797c-0.406,0.047-1.281-0.109-1.281-0.795v-5.804c0-1.094-0.328-2.151-0.936-3.052	c5.915-0.957,8.679-4.093,8.679-9.812c0-2.237-0.686-4.194-2.039-5.822c0.137-0.365,0.233-0.75,0.288-1.147	c0.175-1.276-0.016-2.086-0.184-2.801l-0.027-0.116c-0.178-0.761-0.388-1.297-0.397-1.319l-0.111-0.282l-0.303-0.032	c0,0-0.178-0.019-0.449-0.019c-0.381,0-0.944,0.037-1.466,0.215l-0.196,0.066c-0.714,0.241-1.389,0.468-2.321,1.024	c-0.332,0.198-0.702,0.431-1.101,0.694C27.404,13.394,25.745,13.19,24,13.19c-1.762,0-3.435,0.205-4.979,0.61	c-0.403-0.265-0.775-0.499-1.109-0.699c-0.932-0.556-1.607-0.784-2.321-1.024l-0.196-0.066c-0.521-0.177-1.085-0.215-1.466-0.215	c-0.271,0-0.449,0.019-0.449,0.019l-0.302,0.032l-0.113,0.283c-0.009,0.022-0.219,0.558-0.397,1.319l-0.027,0.116	c-0.169,0.715-0.36,1.524-0.184,2.8c0.056,0.407,0.156,0.801,0.298,1.174c-1.327,1.62-1.999,3.567-1.999,5.795	c0,5.703,2.766,8.838,8.686,9.806c-0.395,0.59-0.671,1.255-0.813,1.964c-0.33,0.13-0.629,0.216-0.891,0.256	c-0.263,0.04-0.537,0.06-0.814,0.06c-0.69,0-1.353-0.129-1.69-0.329c-0.44-0.261-1.057-0.914-1.572-1.665	c-0.35-0.51-1.047-1.417-1.788-1.755c-0.635-0.29-1.298-0.457-1.821-0.457c-0.11,0-0.21,0.008-0.298,0.022	c-0.366,0.058-0.668,0.252-0.828,0.534c-0.128,0.224-0.149,0.483-0.059,0.708c0.179,0.448,0.842,0.85,1.119,1.002	c0.335,0.184,0.919,0.744,1.254,1.284c0.251,0.404,0.37,0.697,0.521,1.067c0.085,0.209,0.178,0.437,0.304,0.712	c0.331,0.719,1.353,1.472,1.905,1.803c0.754,0.452,2.154,0.578,2.922,0.612l0.111,0.002c0.299,0,0.8-0.045,1.495-0.135v3.177	c0,0.779-0.991,0.81-1.234,0.81c-0.031,0,0.503,0.184,0.503,0.184C19.731,43.64,21.822,44,24,44c2.178,0,4.269-0.36,6.231-1.003	C30.231,42.997,30.812,42.793,30.781,42.797z" opacity=".07"/><path fill="#fff" d="M36.744,23.334c0-2.31-0.782-4.226-2.117-5.728c0.145-0.325,0.296-0.761,0.371-1.309	c0.172-1.25-0.031-2-0.203-2.734s-0.375-1.25-0.375-1.25s-0.922-0.094-1.703,0.172s-1.453,0.469-2.422,1.047	c-0.453,0.27-0.909,0.566-1.27,0.806C27.482,13.91,25.785,13.69,24,13.69c-1.801,0-3.513,0.221-5.067,0.652	c-0.362-0.241-0.821-0.539-1.277-0.811c-0.969-0.578-1.641-0.781-2.422-1.047s-1.703-0.172-1.703-0.172s-0.203,0.516-0.375,1.25	s-0.375,1.484-0.203,2.734c0.077,0.562,0.233,1.006,0.382,1.333c-1.31,1.493-2.078,3.397-2.078,5.704	c0,5.983,3.232,8.714,9.121,9.435c-0.687,0.726-1.148,1.656-1.303,2.691c-0.387,0.17-0.833,0.33-1.262,0.394	c-1.104,0.167-2.271,0-2.833-0.333s-1.229-1.083-1.729-1.813c-0.422-0.616-1.031-1.331-1.583-1.583	c-0.729-0.333-1.438-0.458-1.833-0.396c-0.396,0.063-0.583,0.354-0.5,0.563c0.083,0.208,0.479,0.521,0.896,0.75	c0.417,0.229,1.063,0.854,1.438,1.458c0.418,0.674,0.5,1.063,0.854,1.833c0.249,0.542,1.101,1.219,1.708,1.583	c0.521,0.313,1.562,0.491,2.688,0.542c0.389,0.018,1.308-0.096,2.083-0.206v3.75c0,0.639-0.585,1.125-1.191,1.013	C19.756,43.668,21.833,44,24,44c2.166,0,4.243-0.332,6.19-0.984C29.585,43.127,29,42.641,29,42.002v-5.804	c0-1.329-0.527-2.53-1.373-3.425C33.473,32.071,36.744,29.405,36.744,23.334z M11.239,32.727c-0.154-0.079-0.237-0.225-0.185-0.328	c0.052-0.103,0.22-0.122,0.374-0.043c0.154,0.079,0.237,0.225,0.185,0.328S11.393,32.806,11.239,32.727z M12.451,33.482	c-0.081,0.088-0.255,0.06-0.389-0.062s-0.177-0.293-0.096-0.381c0.081-0.088,0.255-0.06,0.389,0.062S12.532,33.394,12.451,33.482z M13.205,34.732c-0.102,0.072-0.275,0.005-0.386-0.15s-0.118-0.34-0.016-0.412s0.275-0.005,0.386,0.15	C13.299,34.475,13.307,34.66,13.205,34.732z M14.288,35.673c-0.069,0.112-0.265,0.117-0.437,0.012s-0.256-0.281-0.187-0.393	c0.069-0.112,0.265-0.117,0.437-0.012S14.357,35.561,14.288,35.673z M15.312,36.594c-0.213-0.026-0.371-0.159-0.353-0.297	c0.017-0.138,0.204-0.228,0.416-0.202c0.213,0.026,0.371,0.159,0.353,0.297C15.711,36.529,15.525,36.62,15.312,36.594z M16.963,36.833c-0.227-0.013-0.404-0.143-0.395-0.289c0.009-0.146,0.2-0.255,0.427-0.242c0.227,0.013,0.404,0.143,0.395,0.289	C17.381,36.738,17.19,36.846,16.963,36.833z M18.521,36.677c-0.242,0-0.438-0.126-0.438-0.281s0.196-0.281,0.438-0.281	c0.242,0,0.438,0.126,0.438,0.281S18.762,36.677,18.521,36.677z"/></svg>
            </a>
          </div>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">
    06-01 Gradient Descent
    
      
        <span class="lesson-badge required large">B·∫Øt bu·ªôc</span>
      
    
  </h1>
  <p>Gradient descent l√† thu·∫≠t to√°n ƒë∆°n gi·∫£n nh·∫•t ƒë·ªÉ gi·∫£i quy·∫øt c√°c b√†i to√°n t·ªëi ∆∞u h√≥a l·ªìi v√† kh·∫£ vi kh√¥ng r√†ng bu·ªôc.</p>

<blockquote>
  <p>\(\min_x f(x),\)
trong ƒë√≥ \(f\) kh·∫£ vi v√† \(dom(f) = \mathbb{R}^n\).</p>
</blockquote>

<p>Gi√° tr·ªã t·ªëi ∆∞u l√† \(f^* = \min_x f(x)\), v√† ƒëi·ªÉm t·ªëi ∆∞u l√† \(x^*\).</p>

<h2 id="t·∫°i-sao-gradient-descent-quan-tr·ªçng-trong-khoa-h·ªçc-d·ªØ-li·ªáu">T·∫°i sao Gradient Descent quan tr·ªçng trong Khoa h·ªçc D·ªØ li·ªáu</h2>

<p><strong>Gradient descent l√† c√¥ng c·ª• ch·ªß l·ª±c c·ªßa machine learning!</strong> ƒê√¢y l√† thu·∫≠t to√°n ƒë·∫±ng sau:</p>

<ul>
  <li><strong>Hu·∫•n luy·ªán m·∫°ng n∆°-ron</strong>: Backpropagation s·ª≠ d·ª•ng gradient descent ƒë·ªÉ c·∫≠p nh·∫≠t tr·ªçng s·ªë</li>
  <li><strong>H·ªìi quy tuy·∫øn t√≠nh</strong>: T√¨m c√°c h·ªá s·ªë t·ªëi ∆∞u ƒë·ªÉ gi·∫£m thi·ªÉu MSE</li>
  <li><strong>H·ªìi quy logistic</strong>: T·ªëi ∆∞u h√≥a tham s·ªë cho ph√¢n lo·∫°i</li>
  <li><strong>Deep learning</strong>: Hu·∫•n luy·ªán c√°c m√¥ h√¨nh ph·ª©c t·∫°p v·ªõi h√†ng tri·ªáu tham s·ªë</li>
  <li><strong>H·ªá th·ªëng g·ª£i √Ω</strong>: H·ªçc s·ªü th√≠ch ng∆∞·ªùi d√πng v√† ƒë·∫∑c tr∆∞ng s·∫£n ph·∫©m</li>
</ul>

<p><strong>Hi·ªÉu bi·∫øt quan tr·ªçng</strong>: M·ªói khi b·∫°n th·∫•y ‚Äútraining‚Äù ho·∫∑c ‚Äúlearning‚Äù trong ML, gradient descent (ho·∫∑c c√°c bi·∫øn th·ªÉ c·ªßa n√≥) c√≥ kh·∫£ nƒÉng ƒë∆∞·ª£c s·ª≠ d·ª•ng!</p>

<h2 id="gradient-descent-cho-h√†m-m·ªôt-bi·∫øn">Gradient Descent cho H√†m M·ªôt Bi·∫øn</h2>

<p>ƒê·ªëi v·ªõi h√†m m·ªôt bi·∫øn \(f: \mathbb{R} \to \mathbb{R}\), gradient descent ƒë∆∞·ª£c ƒë∆°n gi·∫£n h√≥a ƒë√°ng k·ªÉ. Gradient tr·ªü th√†nh ƒë·∫°o h√†m, v√† quy t·∫Øc c·∫≠p nh·∫≠t tr·ªü th√†nh:</p>

<blockquote>
\[x^{(k)} = x^{(k-1)} - t f'(x^{(k-1)}), \quad k = 1, 2, 3, ...\]
</blockquote>

<p>trong ƒë√≥ \(f'(x)\) l√† ƒë·∫°o h√†m c·ªßa \(f\) t·∫°i ƒëi·ªÉm \(x\).</p>

<h3 id="gi·∫£i-th√≠ch-h√¨nh-h·ªçc">Gi·∫£i th√≠ch H√¨nh h·ªçc</h3>

<p>Trong tr∆∞·ªùng h·ª£p h√†m m·ªôt bi·∫øn, ƒë·∫°o h√†m \(f'(x)\) bi·ªÉu th·ªã ƒë·ªô d·ªëc c·ªßa ƒë∆∞·ªùng ti·∫øp tuy·∫øn t·∫°i ƒëi·ªÉm \(x\):</p>
<ul>
  <li>N·∫øu \(f'(x) &gt; 0\), h√†m s·ªë ƒëang tƒÉng, v√¨ v·∫≠y ch√∫ng ta di chuy·ªÉn sang tr√°i (tr·ª´ ƒëi m·ªôt gi√° tr·ªã d∆∞∆°ng)</li>
  <li>N·∫øu \(f'(x) &lt; 0\), h√†m s·ªë ƒëang gi·∫£m, v√¨ v·∫≠y ch√∫ng ta di chuy·ªÉn sang ph·∫£i (tr·ª´ ƒëi m·ªôt gi√° tr·ªã √¢m)</li>
  <li>N·∫øu \(f'(x) = 0\), ch√∫ng ta ƒë√£ ƒë·∫°t ƒë·∫øn ƒëi·ªÉm t·ªõi h·∫°n (c·ª±c ti·ªÉu ti·ªÅm nƒÉng)</li>
</ul>

<h3 id="t·ªëc-ƒë·ªô-h·ªçc-t">T·ªëc ƒë·ªô h·ªçc \(t\)</h3>

<p>T·ªëc ƒë·ªô h·ªçc \(t\) (c√≤n g·ªçi l√† k√≠ch th∆∞·ªõc b∆∞·ªõc) l√† m·ªôt si√™u tham s·ªë quan tr·ªçng c√≥ th·ªÉ ƒë∆∞·ª£c thi·∫øt l·∫≠p b·ªüi ng∆∞·ªùi thi·∫øt k·∫ø thu·∫≠t to√°n. N√≥ ki·ªÉm so√°t ch√∫ng ta th·ª±c hi·ªán c√°c b∆∞·ªõc l·ªõn nh∆∞ th·∫ø n√†o theo h∆∞·ªõng c·ªßa gradient √¢m.</p>

<p><strong>T√°c ƒë·ªông c·ªßa T·ªëc ƒë·ªô H·ªçc:</strong></p>

<ul>
  <li>
    <p><strong>Qu√° nh·ªè (\(t \ll 1\))</strong>: Thu·∫≠t to√°n s·∫Ω c·∫≠p nh·∫≠t r·∫•t ch·∫≠m, y√™u c·∫ßu nhi·ªÅu l·∫ßn l·∫∑p ƒë·ªÉ h·ªôi t·ª• ƒë·∫øn nghi·ªám t·ªëi ∆∞u. M·∫∑c d√π ƒëi·ªÅu n√†y ƒë·∫£m b·∫£o t√≠nh ·ªïn ƒë·ªãnh, nh∆∞ng c√≥ th·ªÉ t·ªën k√©m v·ªÅ m·∫∑t t√≠nh to√°n.</p>
  </li>
  <li>
    <p><strong>Qu√° l·ªõn (\(t \gg 1\))</strong>: Thu·∫≠t to√°n c√≥ th·ªÉ v∆∞·ª£t qu√° c·ª±c ti·ªÉu v√† c√≥ kh·∫£ nƒÉng ph√¢n k·ª≥, dao ƒë·ªông xung quanh ƒëi·ªÉm t·ªëi ∆∞u ho·∫∑c th·∫≠m ch√≠ di chuy·ªÉn ra kh·ªèi n√≥.</p>
  </li>
  <li>
    <p><strong>V·ª´a ph·∫£i</strong>: Thu·∫≠t to√°n h·ªôi t·ª• nhanh ch√≥ng v√† m∆∞·ª£t m√† ƒë·∫øn nghi·ªám t·ªëi ∆∞u.</p>
  </li>
</ul>

<p><strong>C√°c chi·∫øn l∆∞·ª£c ph·ªï bi·∫øn ƒë·ªÉ ch·ªçn t·ªëc ƒë·ªô h·ªçc:</strong></p>
<ol>
  <li><strong>K√≠ch th∆∞·ªõc b∆∞·ªõc c·ªë ƒë·ªãnh</strong>: S·ª≠ d·ª•ng m·ªôt gi√° tr·ªã kh√¥ng ƒë·ªïi trong su·ªët qu√° tr√¨nh t·ªëi ∆∞u h√≥a</li>
  <li><strong>T√¨m ki·∫øm ƒë∆∞·ªùng ch√≠nh x√°c</strong>: T·∫°i m·ªói l·∫ßn l·∫∑p, ch·ªçn \(t\) ƒë·ªÉ gi·∫£m thi·ªÉu \(f(x^{(k-1)} - t\nabla f(x^{(k-1)}))\)</li>
  <li><strong>T√¨m ki·∫øm ƒë∆∞·ªùng l√πi</strong>: B·∫Øt ƒë·∫ßu v·ªõi k√≠ch th∆∞·ªõc b∆∞·ªõc l·ªõn v√† gi·∫£m d·∫ßn cho ƒë·∫øn khi ƒë·∫°t ƒë∆∞·ª£c s·ª± gi·∫£m ƒë·ªß</li>
  <li><strong>Ph∆∞∆°ng ph√°p th√≠ch ·ª©ng</strong>: ƒêi·ªÅu ch·ªânh t·ªëc ƒë·ªô h·ªçc d·ª±a tr√™n ti·∫øn ƒë·ªô t·ªëi ∆∞u h√≥a (v√≠ d·ª•: Adam, RMSprop)</li>
</ol>

<h3 id="v√≠-d·ª•-h√†m-b·∫≠c-hai">V√≠ d·ª•: H√†m B·∫≠c Hai</h3>

<p>Xem x√©t h√†m b·∫≠c hai \(f(x) = \frac{1}{2}(x - 2)^2 + 1\) v·ªõi ƒë·∫°o h√†m \(f'(x) = x - 2\).</p>

<p>C·∫≠p nh·∫≠t gradient descent tr·ªü th√†nh:</p>
<blockquote>
\[x^{(k)} = x^{(k-1)} - t(x^{(k-1)} - 2)\]
</blockquote>

<p>B·∫Øt ƒë·∫ßu t·ª´ \(x^{(0)} = 0\) v·ªõi k√≠ch th∆∞·ªõc b∆∞·ªõc \(t = 0.1\):</p>
<blockquote>
  <p>\(x^{(1)} = 0 - 0.1(0 - 2) = 0.2 \\\) 
\(x^{(2)} = 0.2 - 0.1(0.2 - 2) = 0.38\)
\(x^{(3)} = 0.38 - 0.1(0.38 - 2) = 0.542\)
‚Ä¶</p>
</blockquote>

<p>D√£y s·ªë h·ªôi t·ª• v·ªÅ \(x^* = 2\), ƒë√¢y l√† c·ª±c ti·ªÉu to√†n c·ª•c.</p>

<h3 id="l·ª±a-ch·ªçn-k√≠ch-th∆∞·ªõc-b∆∞·ªõc">L·ª±a ch·ªçn K√≠ch th∆∞·ªõc B∆∞·ªõc</h3>

<p>Vi·ªác l·ª±a ch·ªçn k√≠ch th∆∞·ªõc b∆∞·ªõc \(t\) l√† r·∫•t quan tr·ªçng:</p>
<ul>
  <li><strong>Qu√° nh·ªè</strong>: H·ªôi t·ª• r·∫•t ch·∫≠m</li>
  <li><strong>Qu√° l·ªõn</strong>: Thu·∫≠t to√°n c√≥ th·ªÉ v∆∞·ª£t qu√° v√† ph√¢n k·ª≥</li>
  <li><strong>T·ªëi ∆∞u</strong>: ƒê·ªëi v·ªõi h√†m b·∫≠c hai \(f(x) = \frac{1}{2}ax^2 + bx + c\) v·ªõi \(a &gt; 0\), k√≠ch th∆∞·ªõc b∆∞·ªõc t·ªëi ∆∞u l√† \(t = \frac{1}{a}\)</li>
</ul>

<h3 id="tr·ª±c-quan-h√≥a-t∆∞∆°ng-t√°c">Tr·ª±c quan H√≥a T∆∞∆°ng t√°c</h3>

<div id="single-var-gradient-descent" style="margin: 20px 0;">
    <div style="margin-bottom: 15px;">
        <label for="step-size-slider">K√≠ch th∆∞·ªõc B∆∞·ªõc (t): <span id="step-size-value">0.1</span></label><br />
        <input type="range" id="step-size-slider" min="0.01" max="0.5" step="0.01" value="0.1" style="width: 300px;" />
    </div>
    
    <div style="margin-bottom: 15px;">
        <label for="start-point-slider">ƒêi·ªÉm B·∫Øt ƒë·∫ßu: <span id="start-point-value">-3</span></label><br />
        <input type="range" id="start-point-slider" min="-5" max="5" step="0.1" value="-3" style="width: 300px;" />
    </div>
    
    <div style="margin-bottom: 15px;">
        <button id="start-animation">B·∫Øt ƒë·∫ßu Animation</button>
        <button id="reset-animation">Reset</button>
        <button id="step-once">M·ªôt B∆∞·ªõc</button>
    </div>
    
    <canvas id="gradient-canvas" width="600" height="400" style="border: 1px solid #ccc; display: block; margin: 0 auto;"></canvas>
    
    <div id="iteration-info" style="text-align: center; margin-top: 10px; font-family: monospace;">
L·∫ßn l·∫∑p: 0, x = -3.000, f(x) = 13.500, f'(x) = -5.000
    </div>
</div>

<script>
class SingleVarGradientDescent {
    constructor() {
        this.canvas = document.getElementById('gradient-canvas');
        this.ctx = this.canvas.getContext('2d');
        this.stepSizeSlider = document.getElementById('step-size-slider');
        this.startPointSlider = document.getElementById('start-point-slider');
        this.stepSizeValue = document.getElementById('step-size-value');
        this.startPointValue = document.getElementById('start-point-value');
        this.iterationInfo = document.getElementById('iteration-info');
        
        // Animation state
        this.isAnimating = false;
        this.currentX = -3;
        this.iteration = 0;
        this.history = [];
        this.animationId = null;
        
        // Function parameters: f(x) = 0.5 * (x - 2)^2 + 1
        this.a = 0.5;
        this.b = 2;
        this.c = 1;
        
        this.setupEventListeners();
        this.reset();
    }
    
    setupEventListeners() {
        this.stepSizeSlider.addEventListener('input', (e) => {
            this.stepSizeValue.textContent = e.target.value;
        });
        
        this.startPointSlider.addEventListener('input', (e) => {
            this.startPointValue.textContent = e.target.value;
            if (!this.isAnimating) {
                this.reset();
            }
        });
        
        document.getElementById('start-animation').addEventListener('click', () => {
            this.startAnimation();
        });
        
        document.getElementById('reset-animation').addEventListener('click', () => {
            this.reset();
        });
        
        document.getElementById('step-once').addEventListener('click', () => {
            this.singleStep();
        });
    }
    
    // Function: f(x) = 0.5 * (x - 2)^2 + 1
    f(x) {
        return this.a * Math.pow(x - this.b, 2) + this.c;
    }
    
    // Derivative: f'(x) = (x - 2)
    fprime(x) {
        return 2 * this.a * (x - this.b);
    }
    
    // Convert x coordinate to canvas coordinate
    xToCanvas(x) {
        const xMin = -5, xMax = 5;
        return (x - xMin) / (xMax - xMin) * this.canvas.width;
    }
    
    // Convert y coordinate to canvas coordinate
    yToCanvas(y) {
        const yMin = 0, yMax = 15;
        return this.canvas.height - (y - yMin) / (yMax - yMin) * this.canvas.height;
    }
    
    // Convert canvas x to actual x
    canvasToX(canvasX) {
        const xMin = -5, xMax = 5;
        return xMin + (canvasX / this.canvas.width) * (xMax - xMin);
    }
    
    drawFunction() {
        this.ctx.strokeStyle = '#2196F3';
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let canvasX = 0; canvasX <= this.canvas.width; canvasX += 2) {
            const x = this.canvasToX(canvasX);
            const y = this.f(x);
            const canvasY = this.yToCanvas(y);
            
            if (canvasX === 0) {
                this.ctx.moveTo(canvasX, canvasY);
            } else {
                this.ctx.lineTo(canvasX, canvasY);
            }
        }
        this.ctx.stroke();
    }
    
    drawAxes() {
        this.ctx.strokeStyle = '#666';
        this.ctx.lineWidth = 1;
        
        // X-axis
        const yZero = this.yToCanvas(0);
        this.ctx.beginPath();
        this.ctx.moveTo(0, yZero);
        this.ctx.lineTo(this.canvas.width, yZero);
        this.ctx.stroke();
        
        // Y-axis
        const xZero = this.xToCanvas(0);
        this.ctx.beginPath();
        this.ctx.moveTo(xZero, 0);
        this.ctx.lineTo(xZero, this.canvas.height);
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = '#666';
        this.ctx.font = '12px Arial';
        this.ctx.textAlign = 'center';
        
        // X-axis labels
        for (let x = -4; x <= 4; x += 2) {
            const canvasX = this.xToCanvas(x);
            this.ctx.fillText(x.toString(), canvasX, yZero + 15);
        }
        
        // Y-axis labels
        this.ctx.textAlign = 'right';
        for (let y = 2; y <= 14; y += 2) {
            const canvasY = this.yToCanvas(y);
            this.ctx.fillText(y.toString(), xZero - 5, canvasY + 4);
        }
    }
    
    drawCurrentPoint() {
        const canvasX = this.xToCanvas(this.currentX);
        const canvasY = this.yToCanvas(this.f(this.currentX));
        
        // Current point
        this.ctx.fillStyle = '#F44336';
        this.ctx.beginPath();
        this.ctx.arc(canvasX, canvasY, 6, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Tangent line
        const derivative = this.fprime(this.currentX);
        const tangentLength = 1;
        const x1 = this.currentX - tangentLength;
        const x2 = this.currentX + tangentLength;
        const y1 = this.f(this.currentX) + derivative * (x1 - this.currentX);
        const y2 = this.f(this.currentX) + derivative * (x2 - this.currentX);
        
        this.ctx.strokeStyle = '#FF9800';
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.moveTo(this.xToCanvas(x1), this.yToCanvas(y1));
        this.ctx.lineTo(this.xToCanvas(x2), this.yToCanvas(y2));
        this.ctx.stroke();
    }
    
    drawHistory() {
        if (this.history.length < 2) return;
        
        this.ctx.strokeStyle = '#4CAF50';
        this.ctx.lineWidth = 2;
        this.ctx.setLineDash([5, 5]);
        this.ctx.beginPath();
        
        for (let i = 0; i < this.history.length; i++) {
            const x = this.history[i];
            const canvasX = this.xToCanvas(x);
            const canvasY = this.yToCanvas(this.f(x));
            
            if (i === 0) {
                this.ctx.moveTo(canvasX, canvasY);
            } else {
                this.ctx.lineTo(canvasX, canvasY);
            }
        }
        this.ctx.stroke();
        this.ctx.setLineDash([]);
        
        // Draw history points
        this.ctx.fillStyle = '#4CAF50';
        for (let i = 0; i < this.history.length - 1; i++) {
            const x = this.history[i];
            const canvasX = this.xToCanvas(x);
            const canvasY = this.yToCanvas(this.f(x));
            
            this.ctx.beginPath();
            this.ctx.arc(canvasX, canvasY, 3, 0, 2 * Math.PI);
            this.ctx.fill();
        }
    }
    
    draw() {
        // Clear canvas
        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
        
        // Draw components
        this.drawAxes();
        this.drawFunction();
        this.drawHistory();
        this.drawCurrentPoint();
        
        // Update iteration info
        this.iterationInfo.textContent = 
            `L·∫ßn l·∫∑p: ${this.iteration}, x = ${this.currentX.toFixed(3)}, ` +
            `f(x) = ${this.f(this.currentX).toFixed(3)}, f'(x) = ${this.fprime(this.currentX).toFixed(3)}`;
    }
    
    singleStep() {
        if (Math.abs(this.fprime(this.currentX)) < 1e-6) {
            return; // Already at minimum
        }
        
        const stepSize = parseFloat(this.stepSizeSlider.value);
        const newX = this.currentX - stepSize * this.fprime(this.currentX);
        
        this.history.push(this.currentX);
        this.currentX = newX;
        this.iteration++;
        
        this.draw();
    }
    
    startAnimation() {
        if (this.isAnimating) {
            this.stopAnimation();
            return;
        }
        
        this.isAnimating = true;
        document.getElementById('start-animation').textContent = 'D·ª´ng Animation';
        
        const animate = () => {
            if (!this.isAnimating) return;
            
            if (Math.abs(this.fprime(this.currentX)) > 1e-6 && this.iteration < 100) {
                this.singleStep();
                this.animationId = setTimeout(animate, 500);
            } else {
                this.stopAnimation();
            }
        };
        
        animate();
    }
    
    stopAnimation() {
        this.isAnimating = false;
        document.getElementById('start-animation').textContent = 'B·∫Øt ƒë·∫ßu Animation';
        if (this.animationId) {
            clearTimeout(this.animationId);
            this.animationId = null;
        }
    }
    
    reset() {
        this.stopAnimation();
        this.currentX = parseFloat(this.startPointSlider.value);
        this.iteration = 0;
        this.history = [];
        this.draw();
    }
}

// Initialize when DOM is loaded
document.addEventListener('DOMContentLoaded', function() {
    new SingleVarGradientDescent();
});
</script>

<h2 id="ph∆∞∆°ng-ph√°p-gradient-descent-cho-h√†m-nhi·ªÅu-bi·∫øn">Ph∆∞∆°ng ph√°p Gradient Descent cho H√†m Nhi·ªÅu Bi·∫øn</h2>

<p>Gradient descent b·∫Øt ƒë·∫ßu t·ª´ m·ªôt ƒëi·ªÉm ban ƒë·∫ßu \(x^{(0)} \in \mathbb{R}^n\) v√† c·∫≠p nh·∫≠t l·∫∑p ƒëi l·∫∑p l·∫°i nh∆∞ sau cho ƒë·∫øn khi ƒë√°p ·ª©ng ti√™u chu·∫©n d·ª´ng:</p>
<blockquote>
  <p>\(x^{(k)} = x^{(k-1)} - t \nabla f(x^{(k-1)}), \quad k = 1, 2, 3, ...\), \(t &gt; 0\)</p>
</blockquote>

<p>M√£ gi·∫£:</p>
<blockquote>
  <p><strong>Cho ƒëi·ªÉm b·∫Øt ƒë·∫ßu</strong> \(x \in dom(f)\) <br />
<strong>L·∫∑p l·∫°i</strong>  <br /></p>
  <ol>
    <li>X√°c ƒë·ªãnh h∆∞·ªõng gi·∫£m \(\Delta x = -\nabla f(x)\). <br /></li>
    <li>T√¨m ki·∫øm ƒë∆∞·ªùng: ch·ªçn k√≠ch th∆∞·ªõc b∆∞·ªõc \(t &gt; 0\). <br /></li>
    <li>C·∫≠p nh·∫≠t \(x = x + t \Delta x\). <br />
<strong>Cho ƒë·∫øn khi</strong> ti√™u chu·∫©n d·ª´ng ƒë∆∞·ª£c th·ªèa m√£n <br /></li>
  </ol>
</blockquote>

<h3 id="v√≠-d·ª•">V√≠ d·ª•</h3>

<p>H√¨nh d∆∞·ªõi ƒë√¢y cho th·∫•y gradient descent tr√™n m·ªôt h√†m l·ªìi. Trong tr∆∞·ªùng h·ª£p n√†y, c·ª±c ti·ªÉu c·ª•c b·ªô c≈©ng l√† c·ª±c ti·ªÉu to√†n c·ª•c.</p>

<figure class="image" style="align: center;">
<p align="center">
  <img src="/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_01_gradientdescent1.png" alt="gradientdescent1" width="80%" height="80%" />
  <figcaption style="text-align: center;">[H√¨nh 1] Gradient descent trong h√†m l·ªìi[3]</figcaption>
</p>
</figure>

<p>H√¨nh ti·∫øp theo cho th·∫•y gradient descent tr√™n m·ªôt h√†m kh√¥ng l·ªìi. ·ªû ƒë√¢y, ƒëi·ªÉm ban ƒë·∫ßu quy·∫øt ƒë·ªãnh c·ª±c ti·ªÉu c·ª•c b·ªô n√†o ƒë∆∞·ª£c ƒë·∫°t t·ªõi.</p>

<figure class="image" style="align: center;">
<p align="center">
  <img src="/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_01_gradientdescent2.png" alt="gradientdescent2" width="80%" height="80%" />
  <figcaption style="text-align: center;">[H√¨nh 2] Gradient descent trong h√†m kh√¥ng l·ªìi[3]</figcaption>
</p>
</figure>

<h2 id="gi·∫£i-th√≠ch-gradient-descent">Gi·∫£i th√≠ch Gradient Descent</h2>
<p>Gradient descent c√≥ th·ªÉ ƒë∆∞·ª£c gi·∫£i th√≠ch l√† vi·ªác ch·ªçn ƒëi·ªÉm ti·∫øp theo b·∫±ng c√°ch gi·∫£m thi·ªÉu m·ªôt x·∫•p x·ªâ b·∫≠c hai c·ªßa h√†m s·ªë.</p>

<p>ƒê·ªëi v·ªõi h√†m \(f\), khai tri·ªÉn Taylor b·∫≠c hai quanh \(x\) l√†:</p>
<blockquote>
\[f(y) \approx f(x) + \nabla f(x)^T (y - x) +  \frac{1}{2} \nabla^2 f(x)  \|y - x\|_2^2\]
</blockquote>

<p>N·∫øu ch√∫ng ta x·∫•p x·ªâ ma tr·∫≠n Hessian \(\nabla^2 f(x)\) b·∫±ng \(\frac{1}{t}I\), th√¨:</p>
<blockquote>
  <p>\(f(y) \approx f(x) + \nabla f(x)^T (y - x) +  \frac{1}{2t}  \|y - x\|_2^2\)
trong ƒë√≥ \(t\) l√† k√≠ch th∆∞·ªõc b∆∞·ªõc.</p>
</blockquote>

<p>V√¨ v·∫≠y, trong gradient descent, h√†m s·ªë ƒë∆∞·ª£c x·∫•p x·ªâ b·ªüi m·ªôt h√†m b·∫≠c hai c√≥ ma tr·∫≠n Hessian v·ªõi c√°c gi√° tr·ªã ri√™ng b·∫±ng ngh·ªãch ƒë·∫£o c·ªßa k√≠ch th∆∞·ªõc b∆∞·ªõc. S·ªë h·∫°ng \(f(x) + \nabla f(x)^T (y - x)\) bi·ªÉu th·ªã m·ªôt x·∫•p x·ªâ tuy·∫øn t√≠nh c·ªßa \(f\), v√† \(\frac{1}{2t}  \|y - x\|_2^2\) ƒë√≥ng vai tr√≤ l√† s·ªë h·∫£ng g·∫ßn k·ªÅ ch·ªâ ra \(y\) g·∫ßn \(x\) nh∆∞ th·∫ø n√†o.</p>

<p>V·ªã tr√≠ ti·∫øp theo ƒë∆∞·ª£c ch·ªçn l√† c·ª±c ti·ªÉu c·ªßa h√†m b·∫≠c hai x·∫•p x·ªâ n√†y. ƒê·∫∑t gradient c·ªßa \(f(y)\) b·∫±ng kh√¥ng ƒë·ªÉ t√¨m v·ªã tr√≠ ti·∫øp theo \(y = x^+\) d·∫´n ƒë·∫øn:</p>

<blockquote>
\[x^+ = x - t \nabla f(x)\]
</blockquote>

<p>Trong h√¨nh minh h·ªça d∆∞·ªõi ƒë√¢y, ch·∫•m xanh bi·ªÉu th·ªã v·ªã tr√≠ hi·ªán t·∫°i \(x\), v√† ch·∫•m ƒë·ªè bi·ªÉu th·ªã v·ªã tr√≠ ti·∫øp theo \(y\). ƒê∆∞·ªùng cong b√™n d∆∞·ªõi l√† h√†m th·ª±c t·∫ø \(f\), v√† ƒë∆∞·ªùng cong b√™n tr√™n l√† x·∫•p x·ªâ b·∫≠c hai c·ªßa \(f\). V√¨ v·∫≠y, ch·∫•m ƒë·ªè ch·ªâ ra c·ª±c ti·ªÉu c·ªßa x·∫•p x·ªâ b·∫≠c hai.</p>

<figure class="image" style="align: center;">
<p align="center">
  <img src="/optimization-for-data-science-iuh-2025/img/chapter_img/chapter06/06_01_gradientdescent3.png" alt="gradientdescent3" width="80%" height="80%" />
  <figcaption style="text-align: center;">$$ \text{[H√¨nh 3] Thu·∫≠t to√°n Gradient descent : ch·∫•m ƒë·ªè l√† } x^+ \text{ v√† ch·∫•m xanh l√† } x \text{ [3]} $$</figcaption>
</p>
</figure>

<p>ƒê·ªô g·∫ßn k·ªÅ c·ªßa v·ªã tr√≠ ti·∫øp theo \(y\) ƒë·∫øn v·ªã tr√≠ hi·ªán t·∫°i \(x\) b·ªã ·∫£nh h∆∞·ªüng b·ªüi tr·ªçng s·ªë c·ªßa s·ªë h·∫°ng g·∫ßn k·ªÅ \(\frac{1}{2t}\). M·ªôt \(t\) nh·ªè h∆°n d·∫´n ƒë·∫øn tr·ªçng s·ªë l·ªõn h∆°n cho s·ªë h·∫°ng g·∫ßn k·ªÅ, d·∫´n ƒë·∫øn c√°c b∆∞·ªõc nh·ªè h∆°n. Qu√° tr√¨nh n√†y c√≥ th·ªÉ ƒë∆∞·ª£c bi·ªÉu th·ªã nh∆∞:</p>

<blockquote>
  <p>\begin{align}
x^+ = \underset{y}{\arg \min} \ f(x) + \nabla f(x)^T (y - x) + \frac{1}{2t} \parallel y - x \parallel_2^2
\end{align}</p>
</blockquote>

</div>

<!-- Back to Chapter Home Link -->

  
  
  <div style="margin-top: 20px; padding: 10px; background-color: #f8f9fa; border-left: 4px solid #007bff;">
    <a href="/optimization-for-data-science-iuh-2025/contents/vi/chapter06/" style="text-decoration: none; color: #007bff; font-weight: bold;">
      ‚Üê Quay l·∫°i ƒë·∫ßu ch∆∞∆°ng
    </a>
  </div>













<div class="related">
  <ul class="related-posts">
    
      
        <li>
          <h2>Previous Post</h2>
          <h3>
            <a href="/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_00_gradient_descent/">
              06 Gradient Descent
            </a>
          </h3>
        </li>
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
    
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <li>
        <h2>Next Post</h2>
        <h3>
          <a href="/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_02_how_to_choose_step_sizes/">
            06-02 C√°ch ch·ªçn k√≠ch th∆∞·ªõc b∆∞·ªõc
          </a>
        </h3>
      </li>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
  </ul>
</div>



<script src="https://utteranc.es/client.js"
        repo="convex-optimization-for-all/convex-optimization-for-all.github.io"
        issue-term="title"
        label="Comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/optimization-for-data-science-iuh-2025/public/js/script.js'></script>
    <script src='/optimization-for-data-science-iuh-2025/public/js/multilang.js'></script>
    <script src='/optimization-for-data-science-iuh-2025/public/js/search.js'></script>
  </body>
</html>
