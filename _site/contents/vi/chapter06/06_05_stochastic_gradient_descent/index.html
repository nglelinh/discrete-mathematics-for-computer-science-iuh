<!DOCTYPE html>
<html lang="vi">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <style>
    .MathJax {
      padding: 2em 0.3em;
      overflow-x: auto;
      overflow-y: hidden;
    }
  </style>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

  <title>
    
      06-05 Stochastic gradient descent &middot; Optimization in Data Science
    
  </title>

  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/poole.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/syntax.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/lanyon.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/github-markdown.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/multilang.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/search.css">
  <link rel="stylesheet" href="/optimization-for-data-science-iuh-2025/public/css/content-boxes.css">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap">
  
  <!-- Lunr.js for search functionality -->
  <script src="https://unpkg.com/lunr/lunr.js"></script>

  <link rel="apple-touch-icon-precomposed" sizes="122x144" href="http://localhost:4000/optimization-for-data-science-iuh-2025/public/logo.png">
  <link rel="shortcut icon" href="http://localhost:4000/optimization-for-data-science-iuh-2025/public/convex-logo-144x144.png">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="http://localhost:4000/optimization-for-data-science-iuh-2025/atom.xml">

  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', '', 'auto');
    ga('send', 'pageview');
  </script>
  
</head>


  <body class="sidebar-overlay">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>T·ªëi ∆∞u h√≥a trong Khoa h·ªçc D·ªØ li·ªáu</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/">Trang ch·ªß</a>

    

    
    
    
    <!-- Hi·ªÉn th·ªã c√°c ch∆∞∆°ng c√≥ s·∫µn cho ng√¥n ng·ªØ hi·ªán t·∫°i -->
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter00/">
              00. C√°c Kh√°i Ni·ªám To√°n H·ªçc C∆° B·∫£n
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter01/">
              01. Gi·ªõi thi·ªáu
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter02/">
              02. T·∫≠p L·ªìi
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter03/">
              03. H√†m L·ªìi
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter04/">
              04. C∆° b·∫£n v·ªÅ T·ªëi ∆∞u h√≥a L·ªìi
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter05/">
              05. C√°c B√†i To√°n Chu·∫©n
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter06/">
              06. Gradient Descent
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter07/">
              07. Subgradient
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter08/">
              08. Subgradient Method
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter09/">
              09. Proximal Gradient Descent and Acceleration
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter10/">
              10. Duality in Linear Programs
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter11/">
              11. Duality in General Programs
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter12/">
              12. KKT Conditions
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter13/">
              13. Duality uses and correspondences
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter14/">
              14. Newton's Method
              
            </a>
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter16/">
              16. Duality Revisited
              
            </a>
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter18/">
              18. Quasi-Newton Methods
              
            </a>
          
        
      
    
      
        
          
          
            <a class="sidebar-nav-item" href="http://localhost:4000/optimization-for-data-science-iuh-2025/contents/vi/chapter19/">
              19. Proximal Netwon Method
              
            </a>
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
        
      
    
      
        
          
          
        
      
    
    
    <!-- N·∫øu kh√¥ng c√≥ n·ªôi dung cho ng√¥n ng·ªØ hi·ªán t·∫°i, hi·ªÉn th·ªã th√¥ng b√°o -->
    
    
    <!-- Hi·ªÉn th·ªã th√¥ng tin v·ªÅ t√¨nh tr·∫°ng d·ªãch thu·∫≠t -->
    
      <div class="sidebar-nav-item" style="font-size: 0.8em; color: #999; margin-top: 10px;">
        üìù 26 ch∆∞∆°ng ƒë√£ d·ªãch / 26 ch∆∞∆°ng t·ªïng
      </div>
    
    
    <span class="sidebar-nav-item">Currently v0.0.1</span>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2025. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap github-md-body">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/optimization-for-data-science-iuh-2025/" title="Trang ch·ªß">T·ªëi ∆∞u h√≥a trong Khoa h·ªçc D·ªØ li·ªáu</a>
            <small></small>
          </h3>
          <!-- Header Actions: Language Toggle and GitHub Link -->
          <div class="header-actions">
            <div class="language-toggle">
              <a href="/optimization-for-data-science-iuh-2025/contents/en/chapter06/06_05_stochastic_gradient_descent/" class="language-switch" title="Chuy·ªÉn sang ti·∫øng Anh">Chuy·ªÉn sang ti·∫øng Anh</a>
            </div>
            <a class="github-logo__wrapper" target="_blank" href="https://github.com/nglelinh/optimization-for-data-science-iuh-2025" title="Github">
             <svg class="github-logo" xmlns="http://www.w3.org/2000/svg"  viewBox="0 0 48 48"><linearGradient id="rL2wppHyxHVbobwndsT6Ca" x1="4" x2="44" y1="23.508" y2="23.508" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#4c4c4c"/><stop offset="1" stop-color="#343434"/></linearGradient><path fill="url(#rL2wppHyxHVbobwndsT6Ca)" d="M24,4C12.954,4,4,12.954,4,24c0,8.887,5.801,16.411,13.82,19.016h12.36	C38.199,40.411,44,32.887,44,24C44,12.954,35.046,4,24,4z"/><path d="M30.01,41.996L30,36.198c0-0.939-0.22-1.856-0.642-2.687c5.641-1.133,8.386-4.468,8.386-10.177	c0-2.255-0.665-4.246-1.976-5.92c0.1-0.317,0.174-0.645,0.22-0.981c0.188-1.369-0.023-2.264-0.193-2.984l-0.027-0.116	c-0.186-0.796-0.409-1.364-0.418-1.388l-0.111-0.282l-0.111-0.282l-0.302-0.032l-0.303-0.032c0,0-0.199-0.021-0.501-0.021	c-0.419,0-1.04,0.042-1.627,0.241l-0.196,0.066c-0.74,0.249-1.439,0.485-2.417,1.069c-0.286,0.171-0.599,0.366-0.934,0.584	C27.334,12.881,25.705,12.69,24,12.69c-1.722,0-3.365,0.192-4.889,0.571c-0.339-0.22-0.654-0.417-0.942-0.589	c-0.978-0.584-1.677-0.819-2.417-1.069l-0.196-0.066c-0.585-0.199-1.207-0.241-1.626-0.241c-0.302,0-0.501,0.021-0.501,0.021	l-0.302,0.032l-0.3,0.031l-0.112,0.281l-0.113,0.283c-0.01,0.026-0.233,0.594-0.419,1.391l-0.027,0.115	c-0.17,0.719-0.381,1.615-0.193,2.983c0.048,0.346,0.125,0.685,0.23,1.011c-1.285,1.666-1.936,3.646-1.936,5.89	c0,5.695,2.748,9.028,8.397,10.17c-0.194,0.388-0.345,0.798-0.452,1.224c-0.197,0.067-0.378,0.112-0.538,0.137	c-0.238,0.036-0.487,0.054-0.739,0.054c-0.686,0-1.225-0.134-1.435-0.259c-0.313-0.186-0.872-0.727-1.414-1.518	c-0.463-0.675-1.185-1.558-1.992-1.927c-0.698-0.319-1.437-0.502-2.029-0.502c-0.138,0-0.265,0.01-0.376,0.028	c-0.517,0.082-0.949,0.366-1.184,0.78c-0.203,0.357-0.235,0.773-0.088,1.141c0.219,0.548,0.851,0.985,1.343,1.255	c0.242,0.133,0.765,0.619,1.07,1.109c0.229,0.368,0.335,0.63,0.482,0.992c0.087,0.215,0.183,0.449,0.313,0.732	c0.47,1.022,1.937,1.924,2.103,2.023c0.806,0.483,2.161,0.638,3.157,0.683l0.123,0.003c0,0,0.001,0,0.001,0	c0.24,0,0.57-0.023,1.004-0.071v2.613c0.002,0.529-0.537,0.649-1.25,0.638l0.547,0.184C19.395,43.572,21.645,44,24,44	c2.355,0,4.605-0.428,6.703-1.176l0.703-0.262C30.695,42.538,30.016,42.422,30.01,41.996z" opacity=".05"/><path d="M30.781,42.797c-0.406,0.047-1.281-0.109-1.281-0.795v-5.804c0-1.094-0.328-2.151-0.936-3.052	c5.915-0.957,8.679-4.093,8.679-9.812c0-2.237-0.686-4.194-2.039-5.822c0.137-0.365,0.233-0.75,0.288-1.147	c0.175-1.276-0.016-2.086-0.184-2.801l-0.027-0.116c-0.178-0.761-0.388-1.297-0.397-1.319l-0.111-0.282l-0.303-0.032	c0,0-0.178-0.019-0.449-0.019c-0.381,0-0.944,0.037-1.466,0.215l-0.196,0.066c-0.714,0.241-1.389,0.468-2.321,1.024	c-0.332,0.198-0.702,0.431-1.101,0.694C27.404,13.394,25.745,13.19,24,13.19c-1.762,0-3.435,0.205-4.979,0.61	c-0.403-0.265-0.775-0.499-1.109-0.699c-0.932-0.556-1.607-0.784-2.321-1.024l-0.196-0.066c-0.521-0.177-1.085-0.215-1.466-0.215	c-0.271,0-0.449,0.019-0.449,0.019l-0.302,0.032l-0.113,0.283c-0.009,0.022-0.219,0.558-0.397,1.319l-0.027,0.116	c-0.169,0.715-0.36,1.524-0.184,2.8c0.056,0.407,0.156,0.801,0.298,1.174c-1.327,1.62-1.999,3.567-1.999,5.795	c0,5.703,2.766,8.838,8.686,9.806c-0.395,0.59-0.671,1.255-0.813,1.964c-0.33,0.13-0.629,0.216-0.891,0.256	c-0.263,0.04-0.537,0.06-0.814,0.06c-0.69,0-1.353-0.129-1.69-0.329c-0.44-0.261-1.057-0.914-1.572-1.665	c-0.35-0.51-1.047-1.417-1.788-1.755c-0.635-0.29-1.298-0.457-1.821-0.457c-0.11,0-0.21,0.008-0.298,0.022	c-0.366,0.058-0.668,0.252-0.828,0.534c-0.128,0.224-0.149,0.483-0.059,0.708c0.179,0.448,0.842,0.85,1.119,1.002	c0.335,0.184,0.919,0.744,1.254,1.284c0.251,0.404,0.37,0.697,0.521,1.067c0.085,0.209,0.178,0.437,0.304,0.712	c0.331,0.719,1.353,1.472,1.905,1.803c0.754,0.452,2.154,0.578,2.922,0.612l0.111,0.002c0.299,0,0.8-0.045,1.495-0.135v3.177	c0,0.779-0.991,0.81-1.234,0.81c-0.031,0,0.503,0.184,0.503,0.184C19.731,43.64,21.822,44,24,44c2.178,0,4.269-0.36,6.231-1.003	C30.231,42.997,30.812,42.793,30.781,42.797z" opacity=".07"/><path fill="#fff" d="M36.744,23.334c0-2.31-0.782-4.226-2.117-5.728c0.145-0.325,0.296-0.761,0.371-1.309	c0.172-1.25-0.031-2-0.203-2.734s-0.375-1.25-0.375-1.25s-0.922-0.094-1.703,0.172s-1.453,0.469-2.422,1.047	c-0.453,0.27-0.909,0.566-1.27,0.806C27.482,13.91,25.785,13.69,24,13.69c-1.801,0-3.513,0.221-5.067,0.652	c-0.362-0.241-0.821-0.539-1.277-0.811c-0.969-0.578-1.641-0.781-2.422-1.047s-1.703-0.172-1.703-0.172s-0.203,0.516-0.375,1.25	s-0.375,1.484-0.203,2.734c0.077,0.562,0.233,1.006,0.382,1.333c-1.31,1.493-2.078,3.397-2.078,5.704	c0,5.983,3.232,8.714,9.121,9.435c-0.687,0.726-1.148,1.656-1.303,2.691c-0.387,0.17-0.833,0.33-1.262,0.394	c-1.104,0.167-2.271,0-2.833-0.333s-1.229-1.083-1.729-1.813c-0.422-0.616-1.031-1.331-1.583-1.583	c-0.729-0.333-1.438-0.458-1.833-0.396c-0.396,0.063-0.583,0.354-0.5,0.563c0.083,0.208,0.479,0.521,0.896,0.75	c0.417,0.229,1.063,0.854,1.438,1.458c0.418,0.674,0.5,1.063,0.854,1.833c0.249,0.542,1.101,1.219,1.708,1.583	c0.521,0.313,1.562,0.491,2.688,0.542c0.389,0.018,1.308-0.096,2.083-0.206v3.75c0,0.639-0.585,1.125-1.191,1.013	C19.756,43.668,21.833,44,24,44c2.166,0,4.243-0.332,6.19-0.984C29.585,43.127,29,42.641,29,42.002v-5.804	c0-1.329-0.527-2.53-1.373-3.425C33.473,32.071,36.744,29.405,36.744,23.334z M11.239,32.727c-0.154-0.079-0.237-0.225-0.185-0.328	c0.052-0.103,0.22-0.122,0.374-0.043c0.154,0.079,0.237,0.225,0.185,0.328S11.393,32.806,11.239,32.727z M12.451,33.482	c-0.081,0.088-0.255,0.06-0.389-0.062s-0.177-0.293-0.096-0.381c0.081-0.088,0.255-0.06,0.389,0.062S12.532,33.394,12.451,33.482z M13.205,34.732c-0.102,0.072-0.275,0.005-0.386-0.15s-0.118-0.34-0.016-0.412s0.275-0.005,0.386,0.15	C13.299,34.475,13.307,34.66,13.205,34.732z M14.288,35.673c-0.069,0.112-0.265,0.117-0.437,0.012s-0.256-0.281-0.187-0.393	c0.069-0.112,0.265-0.117,0.437-0.012S14.357,35.561,14.288,35.673z M15.312,36.594c-0.213-0.026-0.371-0.159-0.353-0.297	c0.017-0.138,0.204-0.228,0.416-0.202c0.213,0.026,0.371,0.159,0.353,0.297C15.711,36.529,15.525,36.62,15.312,36.594z M16.963,36.833c-0.227-0.013-0.404-0.143-0.395-0.289c0.009-0.146,0.2-0.255,0.427-0.242c0.227,0.013,0.404,0.143,0.395,0.289	C17.381,36.738,17.19,36.846,16.963,36.833z M18.521,36.677c-0.242,0-0.438-0.126-0.438-0.281s0.196-0.281,0.438-0.281	c0.242,0,0.438,0.126,0.438,0.281S18.762,36.677,18.521,36.677z"/></svg>
            </a>
          </div>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">
    06-05 Stochastic gradient descent
    
      
        <span class="lesson-badge required large">B·∫Øt bu·ªôc</span>
      
    
  </h1>
  <script src="../../../public/js/script.js"></script>

<script src="https://d3js.org/d3.v7.min.js"></script>

<h2 id="ƒë·ªông-l·ª±c-th·ª≠-th√°ch-c·ªßa-big-data">ƒê·ªông l·ª±c: Th·ª≠ th√°ch c·ªßa Big Data</h2>

<p>H√£y t∆∞·ªüng t∆∞·ª£ng b·∫°n ƒëang hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh machine learning tr√™n h√†ng tri·ªáu ƒëi·ªÉm d·ªØ li·ªáu. Gradient descent truy·ªÅn th·ªëng y√™u c·∫ßu t√≠nh to√°n gradient cho <strong>t·∫•t c·∫£</strong> c√°c ƒëi·ªÉm d·ªØ li·ªáu tr∆∞·ªõc khi th·ª±c hi·ªán m·ªôt l·∫ßn c·∫≠p nh·∫≠t duy nh·∫•t. ƒêi·ªÅu n√†y tr·ªü n√™n t·ªën k√©m v·ªÅ m·∫∑t t√≠nh to√°n v√† ti√™u t·ªën b·ªô nh·ªõ ƒë·ªëi v·ªõi c√°c t·∫≠p d·ªØ li·ªáu l·ªõn.</p>

<p><strong>C√¢u h·ªèi</strong>: ƒêi·ªÅu g√¨ s·∫Ω x·∫£y ra n·∫øu ch√∫ng ta c√≥ th·ªÉ ti·∫øn b·ªô b·∫±ng c√°ch ch·ªâ xem x√©t m·ªôt ƒëi·ªÉm d·ªØ li·ªáu t·∫°i m·ªôt th·ªùi ƒëi·ªÉm?</p>

<h2 id="n·ªÅn-t·∫£ng-to√°n-h·ªçc">N·ªÅn t·∫£ng To√°n h·ªçc</h2>

<p>Xem x√©t b√†i to√°n t·ªëi ∆∞u h√≥a ƒë·ªÉ t·ªëi thi·ªÉu h√≥a m·ªôt t·ªïng c√°c h√†m:</p>

\[\begin{equation}
\min_x f(x) = \min_x \sum_{i=1}^m f_i(x)
\end{equation}\]

<p><strong>Di·ªÖn gi·∫£i th·ª±c t·∫ø</strong>: Trong machine learning, \(f_i(x)\) th∆∞·ªùng ƒë·∫°i di·ªán cho m·∫•t m√°t tr√™n v√≠ d·ª• hu·∫•n luy·ªán th·ª© \(i\), trong ƒë√≥ \(x\) l√† c√°c tham s·ªë m√¥ h√¨nh.</p>

<h3 id="batch-gradient-descent-ph∆∞∆°ng-ph√°p-truy·ªÅn-th·ªëng">Batch Gradient Descent (Ph∆∞∆°ng ph√°p Truy·ªÅn th·ªëng)</h3>

<p>Gradient c·ªßa t·ªïng b·∫±ng t·ªïng c√°c gradient:
\(\nabla f(x) = \nabla \sum_{i=1}^m f_i(x) = \sum_{i=1}^m \nabla f_i(x)\)</p>

<p>Quy t·∫Øc c·∫≠p nh·∫≠t tr·ªü th√†nh:
\(\begin{equation}
x^{(k)} = x^{(k-1)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k-1)}), \,  k=1,2,3,\dots
\end{equation}\)</p>

<p><strong>Chi ph√≠ t√≠nh to√°n</strong>: \(O(m)\) l·∫ßn ƒë√°nh gi√° gradient m·ªói l·∫ßn l·∫∑p, trong ƒë√≥ \(m\) l√† s·ªë l∆∞·ª£ng h√†m (ho·∫∑c ƒëi·ªÉm d·ªØ li·ªáu).</p>

<h2 id="stochastic-gradient-descent-gi·∫£i-ph√°p-thay-th·∫ø-hi·ªáu-qu·∫£">Stochastic Gradient Descent: Gi·∫£i ph√°p thay th·∫ø hi·ªáu qu·∫£</h2>

<p><strong>√ù t∆∞·ªüng ch√≠nh</strong>: Thay v√¨ t√≠nh to√°n gradient cho t·∫•t c·∫£ \(m\) h√†m, SGD ch·ªâ s·ª≠ d·ª•ng <strong>m·ªôt</strong> h√†m t·∫°i m·ªói l·∫ßn l·∫∑p.</p>

\[\begin{equation}
x^{(k)} = x^{(k-1)} - t_k \cdot \nabla f_{i_k} (x^{(k-1)}), \quad i_k \in \{1,2,\dots,m\}
\end{equation}\]

<p><strong>Chi ph√≠ t√≠nh to√°n</strong>: \(O(1)\) l·∫ßn ƒë√°nh gi√° gradient m·ªói l·∫ßn l·∫∑p - m·ªôt c·∫£i thi·ªán to l·ªõn!</p>

<h3 id="interactive-visualization-gd-vs-sgd-with-step-control">Interactive Visualization: GD vs SGD with Step Control</h3>

<div id="gd-sgd-comparison" style="margin: 20px 0;">
    <!-- Parameter Controls -->
    <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px; margin-bottom: 15px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #f9f9f9;">
        <div>
            <label for="learning-rate">Learning Rate: </label>
            <input type="range" id="learning-rate" min="0.01" max="0.5" step="0.01" value="0.1" />
            <span id="lr-value">0.1</span>
        </div>
        <div>
            <label for="num-functions">Number of Functions (m): </label>
            <input type="range" id="num-functions" min="3" max="10" step="1" value="5" />
            <span id="m-value">5</span>
        </div>
        <div>
            <label for="animation-speed">Animation Speed: </label>
            <input type="range" id="animation-speed" min="1" max="10" step="1" value="5" />
            <span id="speed-value">5</span>
        </div>
    </div>
    
    <!-- Execution Mode Selection -->
    <div style="margin-bottom: 15px; padding: 10px; border: 1px solid #ddd; border-radius: 5px; background-color: #f0f8ff;">
        <h4 style="margin: 0 0 10px 0;">Execution Mode:</h4>
        <div style="display: flex; gap: 15px;">
            <label><input type="radio" name="exec-mode" value="auto" checked="" /> Auto Run</label>
            <label><input type="radio" name="exec-mode" value="manual" /> Manual Step-by-Step</label>
        </div>
    </div>
    
    <!-- Control Buttons -->
    <div style="display: flex; gap: 10px; margin-bottom: 15px; flex-wrap: wrap;">
        <button id="start-gd" style="background-color: #4CAF50; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;">Start Gradient Descent</button>
        <button id="start-sgd" style="background-color: #FF9800; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;">Start SGD</button>
        <button id="pause-resume" style="background-color: #2196F3; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;" disabled="">Pause</button>
        <button id="step-forward" style="background-color: #9C27B0; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;" disabled="">Step Forward</button>
        <button id="reset-demo" style="background-color: #f44336; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;">Reset</button>
    </div>
    
    <!-- Algorithm Status -->
    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 15px;">
        <div style="padding: 10px; border: 1px solid #4CAF50; border-radius: 5px; background-color: #f1f8e9;">
            <h4 style="margin: 0 0 5px 0; color: #4CAF50;">Gradient Descent Status</h4>
            <p id="gd-detailed-info" style="margin: 0; font-size: 14px;">Ready to start</p>
        </div>
        <div style="padding: 10px; border: 1px solid #FF9800; border-radius: 5px; background-color: #fff8e1;">
            <h4 style="margin: 0 0 5px 0; color: #FF9800;">SGD Status</h4>
            <p id="sgd-detailed-info" style="margin: 0; font-size: 14px;">Ready to start</p>
        </div>
    </div>
    
    <!-- Visualization Plots -->
    <div style="display: flex; gap: 20px; justify-content: center;">
        <div style="text-align: center;">
            <h4>Gradient Descent (Batch)</h4>
            <svg id="gd-plot" width="350" height="350" style="border: 1px solid #ddd;"></svg>
            <div style="margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;">
                <p id="gd-info" style="margin: 0; font-weight: bold;">Iterations: 0, Cost: 0</p>
                <p id="gd-gradient-info" style="margin: 5px 0 0 0; font-size: 12px; color: #666;">Gradient: [0, 0]</p>
            </div>
        </div>
        <div style="text-align: center;">
            <h4>Stochastic Gradient Descent</h4>
            <svg id="sgd-plot" width="350" height="350" style="border: 1px solid #ddd;"></svg>
            <div style="margin-top: 10px; padding: 8px; background-color: #f5f5f5; border-radius: 4px;">
                <p id="sgd-info" style="margin: 0; font-weight: bold;">Iterations: 0, Cost: 0</p>
                <p id="sgd-gradient-info" style="margin: 5px 0 0 0; font-size: 12px; color: #666;">Selected Function: -, Gradient: [0, 0]</p>
            </div>
        </div>
    </div>
    
    <!-- Progress Visualization -->
    <div style="margin-top: 20px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; background-color: #fafafa;">
        <h4>Convergence Progress</h4>
        <div style="display: flex; gap: 20px;">
            <div style="flex: 1;">
                <p><strong>GD Progress:</strong></p>
                <div style="width: 100%; background-color: #e0e0e0; border-radius: 10px; height: 20px;">
                    <div id="gd-progress" style="width: 0%; background-color: #4CAF50; height: 100%; border-radius: 10px; transition: width 0.3s;"></div>
                </div>
            </div>
            <div style="flex: 1;">
                <p><strong>SGD Progress:</strong></p>
                <div style="width: 100%; background-color: #e0e0e0; border-radius: 10px; height: 20px;">
                    <div id="sgd-progress" style="width: 0%; background-color: #FF9800; height: 100%; border-radius: 10px; transition: width 0.3s;"></div>
                </div>
            </div>
        </div>
    </div>
</div>

<h3 id="c√°c-chi·∫øn-l∆∞·ª£c-l·ª±a-ch·ªçn-cho-sgd">C√°c chi·∫øn l∆∞·ª£c l·ª±a ch·ªçn cho SGD</h3>

<p>Ch·ªâ s·ªë h√†m \(i_k\) c√≥ th·ªÉ ƒë∆∞·ª£c ch·ªçn b·∫±ng c√°c chi·∫øn l∆∞·ª£c kh√°c nhau:</p>

<h4 id="1-quy-t·∫Øc-v√≤ng-tr√≤n-cyclic-rule">1. Quy t·∫Øc v√≤ng tr√≤n (Cyclic Rule)</h4>
<p><strong>M·∫´u</strong>: \(i_k = 1,2,\dots,m, 1,2,\dots,m, \ldots\)</p>
<ul>
  <li><strong>∆Øu ƒëi·ªÉm</strong>: C√≥ t√≠nh quy·∫øt ƒë·ªãnh, ƒë·∫£m b·∫£o t·∫•t c·∫£ c√°c h√†m ƒë·ªÅu ƒë∆∞·ª£c thƒÉm</li>
  <li><strong>Nh∆∞·ª£c ƒëi·ªÉm</strong>: C√≥ th·ªÉ b·ªã k·∫πt trong c√°c m·∫´u tu·∫ßn ho√†n</li>
</ul>

<h4 id="2-quy-t·∫Øc-ng·∫´u-nhi√™n-randomized-rule">2. Quy t·∫Øc ng·∫´u nhi√™n (Randomized Rule)</h4>
<p><strong>M·∫´u</strong>: \(i_k\) ƒë∆∞·ª£c ch·ªçn ng·∫´u nhi√™n ƒë·ªÅu t·ª´ \(\{1,2,\dots,m\}\)</p>
<ul>
  <li><strong>∆Øu ƒëi·ªÉm</strong>: Tr√°nh c√°c m·∫´u tu·∫ßn ho√†n, ƒë·∫£m b·∫£o l√Ω thuy·∫øt t·ªët h∆°n</li>
  <li><strong>Nh∆∞·ª£c ƒëi·ªÉm</strong>: M·ªôt s·ªë h√†m c√≥ th·ªÉ ƒë∆∞·ª£c thƒÉm th∆∞·ªùng xuy√™n h∆°n nh·ªØng h√†m kh√°c</li>
</ul>

<p><strong>Trong th·ª±c t·∫ø</strong>: L·ª±a ch·ªçn ng·∫´u nhi√™n ƒë∆∞·ª£c ∆∞a chu·ªông h∆°n do c√≥ t√≠nh ch·∫•t h·ªôi t·ª• t·ªët h∆°n v√† kh·∫£ nƒÉng tho√°t kh·ªèi c√°c m·∫´u c·ª•c b·ªô.</p>

<h2 id="ph√¢n-t√≠ch-h·ªôi-t·ª•-l√Ω-thuy·∫øt-so-v·ªõi-th·ª±c-t·∫ø">Ph√¢n t√≠ch h·ªôi t·ª•: L√Ω thuy·∫øt so v·ªõi Th·ª±c t·∫ø</h2>

<h3 id="so-s√°nh-to√°n-h·ªçc">So s√°nh To√°n h·ªçc</h3>

<p><strong>Batch GD (m·ªôt epoch)</strong>: 
\(x^{(k+1)} = x^{(k)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k)})\)</p>

<p><strong>SGD (m·ªôt epoch v·ªõi quy t·∫Øc v√≤ng tr√≤n)</strong>:
\(x^{(k+m)} = x^{(k)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k+i-1)})\)</p>

<h3 id="hi·ªÉu-c√¥ng-th·ª©c-quy-t·∫Øc-v√≤ng-tr√≤n-sgd">Hi·ªÉu c√¥ng th·ª©c quy t·∫Øc v√≤ng tr√≤n SGD</h3>

<p>H√£y ph√¢n t√≠ch c√¥ng th·ª©c n√†y t·ª´ng b∆∞·ªõc ƒë·ªÉ hi·ªÉu ƒëi·ªÅu g√¨ x·∫£y ra trong m·ªôt epoch ho√†n ch·ªânh c·ªßa SGD v·ªõi quy t·∫Øc v√≤ng tr√≤n:</p>

<p><strong>Epoch l√† g√¨?</strong> M·ªôt epoch c√≥ nghƒ©a l√† ch√∫ng ta ƒë√£ x·ª≠ l√Ω t·∫•t c·∫£ \(m\) h√†m ƒë√∫ng m·ªôt l·∫ßn.</p>

<p><strong>Quy tr√¨nh quy t·∫Øc v√≤ng tr√≤n:</strong></p>
<ul>
  <li>B·∫Øt ƒë·∫ßu t·∫°i v·ªã tr√≠ \(x^{(k)}\)</li>
  <li><strong>B∆∞·ªõc 1</strong>: S·ª≠ d·ª•ng h√†m \(f_1\), t√≠nh \(\nabla f_1(x^{(k)})\), c·∫≠p nh·∫≠t th√†nh \(x^{(k+1)}\)</li>
  <li><strong>B∆∞·ªõc 2</strong>: S·ª≠ d·ª•ng h√†m \(f_2\), t√≠nh \(\nabla f_2(x^{(k+1)})\), c·∫≠p nh·∫≠t th√†nh \(x^{(k+2)}\)</li>
  <li><strong>B∆∞·ªõc 3</strong>: S·ª≠ d·ª•ng h√†m \(f_3\), t√≠nh \(\nabla f_3(x^{(k+2)})\), c·∫≠p nh·∫≠t th√†nh \(x^{(k+3)}\)</li>
  <li>‚Ä¶</li>
  <li><strong>B∆∞·ªõc m</strong>: S·ª≠ d·ª•ng h√†m \(f_m\), t√≠nh \(\nabla f_m(x^{(k+m-1)})\), c·∫≠p nh·∫≠t th√†nh \(x^{(k+m)}\)</li>
</ul>

<p><strong>C√°c c·∫≠p nh·∫≠t SGD ri√™ng l·∫ª:</strong>
\(\begin{align}
x^{(k+1)} &amp;= x^{(k)} - t_k \nabla f_1(x^{(k)}) \\
x^{(k+2)} &amp;= x^{(k+1)} - t_k \nabla f_2(x^{(k+1)}) \\
x^{(k+3)} &amp;= x^{(k+2)} - t_k \nabla f_3(x^{(k+2)}) \\
&amp;\vdots \\
x^{(k+m)} &amp;= x^{(k+m-1)} - t_k \nabla f_m(x^{(k+m-1)})
\end{align}\)</p>

<p><strong>Thu g·ªçn c√°c c·∫≠p nh·∫≠t:</strong>
N·∫øu ch√∫ng ta thay th·∫ø ƒë·ªá quy v√† thu th·∫≠p t·∫•t c·∫£ c√°c s·ªë h·∫°ng, ch√∫ng ta ƒë∆∞·ª£c:
\(x^{(k+m)} = x^{(k)} - t_k \left[ \nabla f_1(x^{(k)}) + \nabla f_2(x^{(k+1)}) + \cdots + \nabla f_m(x^{(k+m-1)}) \right]\)</p>

<p>This can be written compactly as:
\(x^{(k+m)} = x^{(k)} - t_k \cdot \sum_{i=1}^{m} \nabla f_i (x^{(k+i-1)})\)</p>

<p><strong>√ù t∆∞·ªüng ch√≠nh:</strong> M·ªói gradient \(\nabla f_i\) ƒë∆∞·ª£c ƒë√°nh gi√° t·∫°i m·ªôt v·ªã tr√≠ <strong>kh√°c nhau</strong> \(x^{(k+i-1)}\), kh√¥ng ph·∫£i t·∫°i c√πng v·ªã tr√≠ b·∫Øt ƒë·∫ßu \(x^{(k)}\).</p>

<p><strong>Key difference in update directions</strong>:
\(\sum_{i=1}^{m}[ \nabla f_i (x^{(k+i-1)}) - \nabla f_i (x^{(k)})]\)</p>

<p>This difference represents how much the SGD path deviates from what batch GD would do. If the functions don‚Äôt change much locally (Lipschitz continuous gradients), this difference is small and SGD behaves similarly to batch GD.</p>

<h3 id="concrete-example-with-m--3-functions">Concrete Example with m = 3 Functions</h3>

<p>Let‚Äôs illustrate with \(m = 3\) functions to make this crystal clear:</p>

<p><strong>Starting position:</strong> \(x^{(k)} = [1, 2]\)</p>

<p><strong>SGD Cyclic Rule Process:</strong></p>
<ol>
  <li>
    <p><strong>Use \(f_1\)</strong>: Compute \(\nabla f_1(x^{(k)}) = \nabla f_1([1,2])\), update:
\(x^{(k+1)} = x^{(k)} - t_k \nabla f_1(x^{(k)}) = [1,2] - t_k \nabla f_1([1,2])\)</p>
  </li>
  <li>
    <p><strong>Use \(f_2\)</strong>: Compute \(\nabla f_2(x^{(k+1)})\) at the <strong>new</strong> position, update:
\(x^{(k+2)} = x^{(k+1)} - t_k \nabla f_2(x^{(k+1)})\)</p>
  </li>
  <li>
    <p><strong>Use \(f_3\)</strong>: Compute \(\nabla f_3(x^{(k+2)})\) at the <strong>newest</strong> position, update:
\(x^{(k+3)} = x^{(k+2)} - t_k \nabla f_3(x^{(k+2)})\)</p>
  </li>
</ol>

<p><strong>Final SGD result after one epoch:</strong>
\(x^{(k+3)} = x^{(k)} - t_k[\nabla f_1(x^{(k)}) + \nabla f_2(x^{(k+1)}) + \nabla f_3(x^{(k+2)})]\)</p>

<p><strong>Compare with Batch GD:</strong>
\(x^{(k+1)} = x^{(k)} - t_k[\nabla f_1(x^{(k)}) + \nabla f_2(x^{(k)}) + \nabla f_3(x^{(k)})]\)</p>

<p><strong>The crucial difference:</strong></p>
<ul>
  <li><strong>Batch GD</strong>: All gradients evaluated at the <strong>same</strong> starting point \(x^{(k)}\)</li>
  <li><strong>SGD</strong>: Each gradient evaluated at a <strong>different</strong> point along the optimization path</li>
</ul>

<p>This is why SGD can make faster initial progress (it‚Äôs already ‚Äúexploring‚Äù the landscape) but can be noisier near the optimum.</p>

<h3 id="convergence-properties">Convergence Properties</h3>

<div id="convergence-analysis" style="margin: 20px 0;">
    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px;">
        <div style="border: 1px solid #ddd; padding: 15px; border-radius: 5px;">
            <h4>Batch Gradient Descent</h4>
            <ul>
                <li><strong>Direction</strong>: Always in steepest descent direction</li>
                <li><strong>Convergence</strong>: Smooth, monotonic decrease</li>
                <li><strong>Speed</strong>: Slower per epoch, but stable</li>
                <li><strong>Memory</strong>: Requires full dataset in memory</li>
            </ul>
        </div>
        <div style="border: 1px solid #ddd; padding: 15px; border-radius: 5px;">
            <h4>Stochastic Gradient Descent</h4>
            <ul>
                <li><strong>Direction</strong>: Noisy, approximate descent direction</li>
                <li><strong>Convergence</strong>: Oscillatory, but faster initial progress</li>
                <li><strong>Speed</strong>: Faster per epoch, especially for large datasets</li>
                <li><strong>Memory</strong>: Processes one sample at a time</li>
            </ul>
        </div>
    </div>
</div>

<h3 id="theoretical-guarantees">Theoretical Guarantees</h3>

<p><strong>Lipschitz Continuity Condition</strong>: If \(\nabla f_i(x)\) is Lipschitz continuous with constant \(L\):
\(\|\nabla f_i(x) - \nabla f_i(y)\| \leq L \|x - y\|\)</p>

<p>Then SGD converges to the same optimal solution as batch GD, provided the learning rate satisfies appropriate conditions.</p>

<p><strong>Practical Observation</strong>:</p>
<ul>
  <li>SGD excels in the <strong>exploration phase</strong> (far from optimum)</li>
  <li>SGD struggles in the <strong>exploitation phase</strong> (near optimum) due to noise</li>
</ul>

<h2 id="mini-batch-gradient-descent-the-best-of-both-worlds">Mini-Batch Gradient Descent: The Best of Both Worlds</h2>

<p>A compromise between batch GD and SGD uses <strong>mini-batches</strong> of size \(b\):</p>

\[x^{(k)} = x^{(k-1)} - t_k \cdot \frac{1}{b} \sum_{i \in \mathcal{B}_k} \nabla f_i (x^{(k-1)})\]

<p>where \(\mathcal{B}_k\) is a mini-batch of \(b\) randomly selected indices.</p>

<div id="minibatch-comparison" style="margin: 20px 0;">
    <h4>Comparison: Batch vs Mini-batch vs SGD</h4>
    <table style="width: 100%; border-collapse: collapse; margin: 15px 0;">
        <thead>
            <tr style="background-color: #f5f5f5;">
                <th style="border: 1px solid #ddd; padding: 10px;">Method</th>
                <th style="border: 1px solid #ddd; padding: 10px;">Batch Size</th>
                <th style="border: 1px solid #ddd; padding: 10px;">Computation/Update</th>
                <th style="border: 1px solid #ddd; padding: 10px;">Convergence</th>
                <th style="border: 1px solid #ddd; padding: 10px;">Memory Usage</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td style="border: 1px solid #ddd; padding: 10px;"><strong>Batch GD</strong></td>
                <td style="border: 1px solid #ddd; padding: 10px;">$$m$$ (full dataset)</td>
                <td style="border: 1px solid #ddd; padding: 10px;">$$O(m)$$</td>
                <td style="border: 1px solid #ddd; padding: 10px;">Smooth, stable</td>
                <td style="border: 1px solid #ddd; padding: 10px;">High</td>
            </tr>
            <tr>
                <td style="border: 1px solid #ddd; padding: 10px;"><strong>Mini-batch GD</strong></td>
                <td style="border: 1px solid #ddd; padding: 10px;">$$b$$ (typically 32-256)</td>
                <td style="border: 1px solid #ddd; padding: 10px;">$$O(b)$$</td>
                <td style="border: 1px solid #ddd; padding: 10px;">Balanced</td>
                <td style="border: 1px solid #ddd; padding: 10px;">Medium</td>
            </tr>
            <tr>
                <td style="border: 1px solid #ddd; padding: 10px;"><strong>SGD</strong></td>
                <td style="border: 1px solid #ddd; padding: 10px;">1</td>
                <td style="border: 1px solid #ddd; padding: 10px;">$$O(1)$$</td>
                <td style="border: 1px solid #ddd; padding: 10px;">Fast but noisy</td>
                <td style="border: 1px solid #ddd; padding: 10px;">Low</td>
            </tr>
        </tbody>
    </table>
</div>

<h2 id="nh·ªØng-ƒëi·ªÉm-ch√≠nh-v√†-hi·ªÉu-bi·∫øt-th·ª±c-t·∫ø">Nh·ªØng ƒëi·ªÉm ch√≠nh v√† Hi·ªÉu bi·∫øt th·ª±c t·∫ø</h2>

<h3 id="khi-n√†o-s·ª≠-d·ª•ng-sgd">Khi n√†o s·ª≠ d·ª•ng SGD</h3>
<ol>
  <li><strong>T·∫≠p d·ªØ li·ªáu l·ªõn</strong> (h√†ng tri·ªáu m·∫´u)</li>
  <li><strong>C√°c t√¨nh hu·ªëng h·ªçc tr·ª±c tuy·∫øn</strong></li>
  <li><strong>M√¥i tr∆∞·ªùng b·ªô nh·ªõ h·∫°n ch·∫ø</strong></li>
  <li><strong>C√°c giai ƒëo·∫°n hu·∫•n luy·ªán ƒë·∫ßu</strong> ƒë·ªÉ ti·∫øn b·ªô nhanh</li>
</ol>

<h3 id="khi-n√†o-s·ª≠-d·ª•ng-batch-gd">Khi n√†o s·ª≠ d·ª•ng Batch GD</h3>
<ol>
  <li><strong>T·∫≠p d·ªØ li·ªáu nh·ªè ƒë·∫øn trung b√¨nh</strong></li>
  <li><strong>Y√™u c·∫ßu ƒë·ªô ch√≠nh x√°c cao</strong></li>
  <li><strong>C·∫ßn h·ªôi t·ª• ·ªïn ƒë·ªãnh</strong></li>
  <li><strong>C√°c giai ƒëo·∫°n tinh ch·ªânh cu·ªëi c√πng</strong></li>
</ol>

<h3 id="th·ª±c-h√†nh-t·ªët-nh·∫•t">Th·ª±c h√†nh t·ªët nh·∫•t</h3>
<ul>
  <li><strong>L·∫≠p l·ªãch t·ªëc ƒë·ªô h·ªçc</strong>: B·∫Øt ƒë·∫ßu cao, gi·∫£m d·∫ßn theo th·ªùi gian</li>
  <li><strong>X√°o tr·ªôn</strong>: Ng·∫´u nhi√™n h√≥a th·ª© t·ª± d·ªØ li·ªáu m·ªói epoch</li>
  <li><strong>Mini-batch</strong>: Th∆∞·ªùng l√† l·ª±a ch·ªçn th·ª±c t·∫ø t·ªët nh·∫•t</li>
  <li><strong>Momentum</strong>: Gi√∫p SGD v∆∞·ª£t qua nhi·ªÖu v√† tƒÉng t·ªëc h·ªôi t·ª•</li>
</ul>

<p><strong>Th·ª±c t·∫ø hi·ªán ƒë·∫°i</strong>: H·∫ßu h·∫øt c√°c framework deep learning s·ª≠ d·ª•ng mini-batch SGD v·ªõi c√°c optimizer tinh vi (Adam, RMSprop) t·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh t·ªëc ƒë·ªô h·ªçc.</p>

<script>
document.addEventListener('DOMContentLoaded', function() {
    // Global variables for demos
    let gdData = [], sgdData = [];
    let gdPosition = [2, 2], sgdPosition = [2, 2];
    let isRunning = false;
    let isPaused = false;
    let isManualMode = false;
    let animationId;
    let currentAlgorithm = null; // 'gd' or 'sgd'
    let algorithmState = {
        gd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0] },
        sgd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0], selectedFunc: -1 }
    };
    
    // Initialize sliders
    const learningRateSlider = document.getElementById('learning-rate');
    const numFunctionsSlider = document.getElementById('num-functions');
    const animationSpeedSlider = document.getElementById('animation-speed');
    const lrValue = document.getElementById('lr-value');
    const mValue = document.getElementById('m-value');
    const speedValue = document.getElementById('speed-value');
    
    if (learningRateSlider) {
        learningRateSlider.addEventListener('input', function() {
            lrValue.textContent = this.value;
        });
    }
    
    if (numFunctionsSlider) {
        numFunctionsSlider.addEventListener('input', function() {
            mValue.textContent = this.value;
        });
    }
    
    if (animationSpeedSlider) {
        animationSpeedSlider.addEventListener('input', function() {
            speedValue.textContent = this.value;
        });
    }
    
    // Execution mode radio buttons
    const execModeRadios = document.querySelectorAll('input[name="exec-mode"]');
    execModeRadios.forEach(radio => {
        radio.addEventListener('change', function() {
            isManualMode = this.value === 'manual';
            updateControlButtons();
        });
    });
    
    // Simple quadratic functions for demonstration
    function createFunctions(m) {
        const functions = [];
        for (let i = 0; i < m; i++) {
            const centerX = (Math.random() - 0.5) * 4;
            const centerY = (Math.random() - 0.5) * 4;
            functions.push({
                center: [centerX, centerY],
                gradient: function(x, y) {
                    return [2 * (x - centerX), 2 * (y - centerY)];
                },
                value: function(x, y) {
                    return (x - centerX) ** 2 + (y - centerY) ** 2;
                }
            });
        }
        return functions;
    }
    
    // Setup SVG plots
    function setupPlot(svgId, width = 300, height = 300) {
        const svg = d3.select(`#${svgId}`);
        if (svg.empty()) return null;
        
        svg.selectAll("*").remove();
        
        const margin = {top: 20, right: 20, bottom: 30, left: 40};
        const plotWidth = width - margin.left - margin.right;
        const plotHeight = height - margin.top - margin.bottom;
        
        const xScale = d3.scaleLinear()
            .domain([-3, 3])
            .range([0, plotWidth]);
            
        const yScale = d3.scaleLinear()
            .domain([-3, 3])
            .range([plotHeight, 0]);
        
        const g = svg.append("g")
            .attr("transform", `translate(${margin.left},${margin.top})`);
        
        // Add axes
        g.append("g")
            .attr("transform", `translate(0,${plotHeight})`)
            .call(d3.axisBottom(xScale));
            
        g.append("g")
            .call(d3.axisLeft(yScale));
        
        // Add contour background
        const contourData = [];
        for (let i = 0; i < 20; i++) {
            for (let j = 0; j < 20; j++) {
                const x = -3 + (i / 19) * 6;
                const y = -3 + (j / 19) * 6;
                contourData.push({x, y, z: x*x + y*y});
            }
        }
        
        return {svg, g, xScale, yScale, plotWidth, plotHeight};
    }
    
    // Control button functions
    function updateControlButtons() {
        const pauseResumeBtn = document.getElementById('pause-resume');
        const stepForwardBtn = document.getElementById('step-forward');
        
        if (pauseResumeBtn) {
            pauseResumeBtn.disabled = !isRunning;
            pauseResumeBtn.textContent = isPaused ? 'Resume' : 'Pause';
        }
        
        if (stepForwardBtn) {
            stepForwardBtn.disabled = !isManualMode && !isPaused;
        }
    }
    
    // GD vs SGD Comparison Demo
    const startGDBtn = document.getElementById('start-gd');
    const startSGDBtn = document.getElementById('start-sgd');
    const pauseResumeBtn = document.getElementById('pause-resume');
    const stepForwardBtn = document.getElementById('step-forward');
    const resetBtn = document.getElementById('reset-demo');
    
    if (startGDBtn) {
        startGDBtn.addEventListener('click', function() {
            if (isRunning && currentAlgorithm === 'gd') return;
            initializeAlgorithm('gd');
            if (!isManualMode) {
                runAlgorithm('gd');
            }
        });
    }
    
    if (startSGDBtn) {
        startSGDBtn.addEventListener('click', function() {
            if (isRunning && currentAlgorithm === 'sgd') return;
            initializeAlgorithm('sgd');
            if (!isManualMode) {
                runAlgorithm('sgd');
            }
        });
    }
    
    if (pauseResumeBtn) {
        pauseResumeBtn.addEventListener('click', function() {
            if (isPaused) {
                isPaused = false;
                if (currentAlgorithm) {
                    runAlgorithm(currentAlgorithm);
                }
            } else {
                isPaused = true;
                if (animationId) {
                    cancelAnimationFrame(animationId);
                }
            }
            updateControlButtons();
        });
    }
    
    if (stepForwardBtn) {
        stepForwardBtn.addEventListener('click', function() {
            if (currentAlgorithm && (isManualMode || isPaused)) {
                performSingleStep(currentAlgorithm);
            }
        });
    }
    
    if (resetBtn) {
        resetBtn.addEventListener('click', function() {
            resetDemo();
        });
    }
    
    // Initialize algorithm state
    function initializeAlgorithm(algorithm) {
        const m = parseInt(numFunctionsSlider.value);
        const functions = createFunctions(m);
        
        algorithmState[algorithm] = {
            iteration: 0,
            position: [2, 2],
            path: [[2, 2]],
            functions: functions,
            totalCost: 0,
            gradient: [0, 0],
            selectedFunc: algorithm === 'sgd' ? -1 : undefined
        };
        
        currentAlgorithm = algorithm;
        isRunning = true;
        isPaused = false;
        
        // Setup plot
        const plotId = algorithm === 'gd' ? 'gd-plot' : 'sgd-plot';
        const plot = setupPlot(plotId, 350, 350);
        
        // Update status
        updateAlgorithmDisplay(algorithm);
        updateControlButtons();
        
        // Update detailed info
        const detailedInfoId = algorithm === 'gd' ? 'gd-detailed-info' : 'sgd-detailed-info';
        document.getElementById(detailedInfoId).textContent = 
            isManualMode ? 'Ready for manual stepping' : 'Running automatically...';
    }
    
    // Run algorithm in auto mode
    function runAlgorithm(algorithm) {
        if (isPaused || isManualMode) return;
        
        const speed = parseInt(animationSpeedSlider.value);
        const delay = 1100 - speed * 100; // Convert speed to delay (higher speed = lower delay)
        
        function step() {
            if (isPaused || !isRunning) return;
            
            const shouldContinue = performSingleStep(algorithm);
            
            if (shouldContinue && !isPaused) {
                setTimeout(() => {
                    animationId = requestAnimationFrame(step);
                }, delay);
            } else {
                isRunning = false;
                updateControlButtons();
                
                const detailedInfoId = algorithm === 'gd' ? 'gd-detailed-info' : 'sgd-detailed-info';
                document.getElementById(detailedInfoId).textContent = 'Converged!';
            }
        }
        
        step();
    }
    
    // Perform a single step of the algorithm
    function performSingleStep(algorithm) {
        const state = algorithmState[algorithm];
        const lr = parseFloat(learningRateSlider.value);
        
        if (algorithm === 'gd') {
            return performGDStep(state, lr);
        } else {
            return performSGDStep(state, lr);
        }
    }
    
    function performGDStep(state, lr) {
        // Compute full gradient (sum of all function gradients)
        let gradX = 0, gradY = 0;
        for (const func of state.functions) {
            const grad = func.gradient(state.position[0], state.position[1]);
            gradX += grad[0];
            gradY += grad[1];
        }
        
        // Average the gradients
        gradX /= state.functions.length;
        gradY /= state.functions.length;
        
        state.gradient = [gradX, gradY];
        
        // Update position
        state.position[0] -= lr * gradX;
        state.position[1] -= lr * gradY;
        state.path.push(state.position.slice());
        
        // Compute total cost
        state.totalCost = 0;
        for (const func of state.functions) {
            state.totalCost += func.value(state.position[0], state.position[1]);
        }
        state.totalCost /= state.functions.length;
        
        state.iteration++;
        
        // Update visualization
        updateAlgorithmDisplay('gd');
        
        // Check convergence
        const gradientMagnitude = Math.sqrt(gradX * gradX + gradY * gradY);
        return state.iteration < 100 && gradientMagnitude > 0.01;
    }
    
    function performSGDStep(state, lr) {
        // Select random function
        const funcIndex = Math.floor(Math.random() * state.functions.length);
        const func = state.functions[funcIndex];
        state.selectedFunc = funcIndex;
        
        // Compute gradient for selected function only
        const grad = func.gradient(state.position[0], state.position[1]);
        state.gradient = grad;
        
        // Update position
        state.position[0] -= lr * grad[0];
        state.position[1] -= lr * grad[1];
        state.path.push(state.position.slice());
        
        // Compute total cost
        state.totalCost = 0;
        for (const func of state.functions) {
            state.totalCost += func.value(state.position[0], state.position[1]);
        }
        state.totalCost /= state.functions.length;
        
        state.iteration++;
        
        // Update visualization
        updateAlgorithmDisplay('sgd');
        
        // Check convergence (SGD needs more iterations)
        return state.iteration < 300 && state.totalCost > 0.01;
    }
    
    function updateAlgorithmDisplay(algorithm) {
        const state = algorithmState[algorithm];
        const plotId = algorithm === 'gd' ? 'gd-plot' : 'sgd-plot';
        const color = algorithm === 'gd' ? 'steelblue' : 'orange';
        
        // Update path visualization
        const plot = {
            svg: d3.select(`#${plotId}`),
            g: d3.select(`#${plotId} g`),
            xScale: d3.scaleLinear().domain([-3, 3]).range([0, 270]),
            yScale: d3.scaleLinear().domain([-3, 3]).range([270, 0])
        };
        
        if (!plot.g.empty()) {
            updatePath(plot, state.path, color);
        }
        
        // Update info displays
        const infoId = algorithm === 'gd' ? 'gd-info' : 'sgd-info';
        const gradientInfoId = algorithm === 'gd' ? 'gd-gradient-info' : 'sgd-gradient-info';
        
        document.getElementById(infoId).textContent = 
            `Iterations: ${state.iteration}, Cost: ${state.totalCost.toFixed(4)}`;
        
        if (algorithm === 'gd') {
            document.getElementById(gradientInfoId).textContent = 
                `Gradient: [${state.gradient[0].toFixed(3)}, ${state.gradient[1].toFixed(3)}]`;
        } else {
            document.getElementById(gradientInfoId).textContent = 
                `Selected Function: f${state.selectedFunc + 1}, Gradient: [${state.gradient[0].toFixed(3)}, ${state.gradient[1].toFixed(3)}]`;
        }
        
        // Update progress bar
        const progressId = algorithm === 'gd' ? 'gd-progress' : 'sgd-progress';
        const maxIterations = algorithm === 'gd' ? 100 : 300;
        const progress = Math.min((state.iteration / maxIterations) * 100, 100);
        document.getElementById(progressId).style.width = `${progress}%`;
        
        // Update detailed status
        const detailedInfoId = algorithm === 'gd' ? 'gd-detailed-info' : 'sgd-detailed-info';
        const gradMagnitude = Math.sqrt(state.gradient[0] ** 2 + state.gradient[1] ** 2);
        document.getElementById(detailedInfoId).textContent = 
            `Step ${state.iteration}: Position [${state.position[0].toFixed(3)}, ${state.position[1].toFixed(3)}], |‚àá| = ${gradMagnitude.toFixed(4)}`;
    }
    
    function updatePath(plot, path, color) {
        const line = d3.line()
            .x(d => plot.xScale(d[0]))
            .y(d => plot.yScale(d[1]));
        
        plot.g.selectAll('.path').remove();
        plot.g.append('path')
            .datum(path)
            .attr('class', 'path')
            .attr('fill', 'none')
            .attr('stroke', color)
            .attr('stroke-width', 2)
            .attr('d', line);
        
        // Add current position
        const current = path[path.length - 1];
        plot.g.selectAll('.current-pos').remove();
        plot.g.append('circle')
            .attr('class', 'current-pos')
            .attr('cx', plot.xScale(current[0]))
            .attr('cy', plot.yScale(current[1]))
            .attr('r', 5)
            .attr('fill', color);
    }
    
    function resetDemo() {
        if (animationId) {
            cancelAnimationFrame(animationId);
        }
        
        isRunning = false;
        isPaused = false;
        currentAlgorithm = null;
        
        // Reset algorithm states
        algorithmState = {
            gd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0] },
            sgd: { iteration: 0, position: [2, 2], path: [], functions: [], totalCost: 0, gradient: [0, 0], selectedFunc: -1 }
        };
        
        // Clear plots
        d3.select('#gd-plot').selectAll("*").remove();
        d3.select('#sgd-plot').selectAll("*").remove();
        
        // Reset info displays
        document.getElementById('gd-info').textContent = 'Iterations: 0, Cost: 0';
        document.getElementById('sgd-info').textContent = 'Iterations: 0, Cost: 0';
        document.getElementById('gd-gradient-info').textContent = 'Gradient: [0, 0]';
        document.getElementById('sgd-gradient-info').textContent = 'Selected Function: -, Gradient: [0, 0]';
        
        // Reset detailed info
        document.getElementById('gd-detailed-info').textContent = 'Ready to start';
        document.getElementById('sgd-detailed-info').textContent = 'Ready to start';
        
        // Reset progress bars
        document.getElementById('gd-progress').style.width = '0%';
        document.getElementById('sgd-progress').style.width = '0%';
        
        // Update control buttons
        updateControlButtons();
    }
    
});
</script>


</div>

<!-- Back to Chapter Home Link -->

  
  
  <div style="margin-top: 20px; padding: 10px; background-color: #f8f9fa; border-left: 4px solid #007bff;">
    <a href="/optimization-for-data-science-iuh-2025/contents/vi/chapter06/" style="text-decoration: none; color: #007bff; font-weight: bold;">
      ‚Üê Quay l·∫°i ƒë·∫ßu ch∆∞∆°ng
    </a>
  </div>













<div class="related">
  <ul class="related-posts">
    
      
    
      
    
      
    
      
    
      
    
      
        <li>
          <h2>Previous Post</h2>
          <h3>
            <a href="/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_04_gradient_boosting/">
              06-04 Gradient boosting
            </a>
          </h3>
        </li>
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
    
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
      <li>
        <h2>Next Post</h2>
        <h3>
          <a href="/optimization-for-data-science-iuh-2025/contents/vi/chapter06/06_07_regularization_and_loss_functions/">
            06-07 Regularization v√† Loss Functions
          </a>
        </h3>
      </li>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
  </ul>
</div>



<script src="https://utteranc.es/client.js"
        repo="convex-optimization-for-all/convex-optimization-for-all.github.io"
        issue-term="title"
        label="Comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/optimization-for-data-science-iuh-2025/public/js/script.js'></script>
    <script src='/optimization-for-data-science-iuh-2025/public/js/multilang.js'></script>
    <script src='/optimization-for-data-science-iuh-2025/public/js/search.js'></script>
  </body>
</html>
