[
  {
    "id": "/contents/vi/chapter00/00_Introduction",
    "title": "00 Giới thiệu",
    "chapter": "00",
    "order": 1,
    "owner": "GitHub Copilot",
    "lesson_type": "",
    "content": "Tối ưu hóa là trái tim của khoa học dữ liệu. Dù bạn đang huấn luyện một mạng nơ-ron, tối thiểu hóa lỗi trong các mô hình hồi quy, hay phân bổ tài nguyên hiệu quả trong hệ thống gợi ý, về bản chất bạn đang giải quyết các bài toán tìm kiếm giải pháp \"tốt nhất\" từ một tập hợp khổng lồ các khả năng. Nhưng để làm điều này một cách hiệu quả, bạn cần nói được ngôn ngữ của toán học. Chúng ta sẽ ôn lại các ý tưởng chính từ đại số tuyến tính, lý thuyết tập hợp và giải tích, đảm bảo bạn được trang bị để xử lý các gradient, ma trận, ràng buộc và sự bất định phát sinh trong các tác vụ tối ưu hóa.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_Introduction/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_01_Calculus",
    "title": "00-01 Giải tích",
    "chapter": "00",
    "order": 2,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này bao gồm các khái niệm giải tích cần thiết cho tối ưu hóa, được tổ chức thành bốn phần chính để hiểu rõ hơn.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_01_Calculus/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_01_01_newton_method_interpretation",
    "title": "14-01-01 Giải thích phương pháp Newton",
    "chapter": "",
    "order": 3,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config ; Trang này xem xét cách bước cập nhật đã thảo luận trước đó được dẫn xuất từ xấp xỉ bậc hai của hàm số gốc MATH . Chúng ta cũng so sánh nó với bước cập nhật gradient descent được đề cập trong Chương 6 % multilang post url contents/chapter06/21-03-20-06 00 gradient descent % . Bước cập nhật phương pháp Newton Xấp xỉ Taylor bậc hai xấp xỉ bậc hai của hàm số MATH như sau: > MATH >\\begin align >f y \\approx f x + \\nabla f x ^ T y-x +\\frac 1 2 y-x ^ T \\nabla^ 2 f x y-x ,\\\\\\\\ >f approx y = f x + \\nabla f x ^ T y-x +\\frac 1 2 y-x ^ T \\nabla^ 2 f x y-x . >\\end align > MATH Ở đây, MATH là giá trị MATH của bước tiếp theo, tức là MATH . Chúng ta cũng định nghĩa xấp xỉ bậc hai là MATH . Chúng ta muốn tìm đầu vào MATH để tối thiểu hóa MATH này, tức là xấp xỉ bậc hai. Vì MATH là lồi, đầu vào MATH làm cho gradient của phương trình trên bằng không sẽ tối thiểu hóa MATH . Kết quả này trở thành công thức cập nhật bước trong phương pháp Newton. Hãy nhớ rằng việc lấy đạo hàm trong phương trình dưới đây là theo y. > MATH >\\begin align >\\nabla f approx y &= \\nabla f x +\\frac 1 2 \\Big \\nabla^ 2 f x ^ T y-x + y-x ^ T \\nabla^ 2 f x \\Big \\\\\\\\ >&=\\nabla f x +\\nabla^ 2 f x y-x \\\\\\\\ >& = 0,\\\\\\\\ >\\Leftrightarrow y &= x- \\nabla^ 2 f x ^ -1 \\nabla f x . >\\end align > MATH Bước cập nhật gradient descent Trong gradient descent, chúng ta sử dụng các số hạng xấp xỉ Taylor bậc hai của hàm số MATH , nhưng đối với số hạng bậc hai, chúng ta giả sử nó là ma trận đơn vị chia cho MATH , thay vì kết quả đạo hàm bậc hai thực tế. > MATH >\\begin align >f y \\approx f x + \\nabla f x ^ T y-x +\\frac 1 2t \\| y-x \\| 2 ^ 2 ,\\\\\\\\ >f approx y = f x + \\nabla f x ^ T y-x +\\frac 1 2t \\| y-x \\| 2 ^ 2 .\\\\\\\\ >\\end align > MATH Tương tự như phương pháp Newton, chúng ta có thể xác định giá trị MATH mà tại đó gradient của xấp xỉ trên bằng không, tức là MATH . > MATH >\\begin align >\\nabla f y &= \\nabla f x + \\frac 1 t y-x , \\\\\\\\ > &= 0,\\\\\\\\ >y &= x-t\\nabla f x . >\\end align > MATH Kết quả này giống hệt với bước cập nhật của gradient descent. Để biết thông tin chi tiết về gradient descent, hãy tham khảo chương gradient descent % multilang post url contents/chapter06/21-03-20-06 00 gradient descent % . Ví dụ Làm ví dụ, đối với hàm số MATH , chúng ta giả sử thực hiện các bước có độ dài gần bằng nhau. Tức là, chúng ta đặt kích thước bước trong gradient descent để khớp với độ lớn cập nhật của phương pháp Newton tại mỗi lần lặp, và so sánh hướng hội tụ của gradient descent màu đen và phương pháp Newton màu xanh theo các bước của chúng. Hình 1 So sánh giữa gradient descent màu đen và phương pháp Newton màu xanh 3 Như có thể thấy trong Hình 1, gradient descent giả sử số hạng đạo hàm bậc hai là một hằng số nhân với ma trận đơn vị khi tính toán gradient, do đó nó hội tụ vuông góc với hướng tiếp tuyến của các đường đồng mức, và cho thấy tốc độ hội tụ chậm hơn so với phương pháp Newton. Các chương còn lại sẽ đề cập đến các tính chất, đặc điểm, sự hội tụ, ví dụ, v.v. của phương pháp Newton.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_01_01_newton_method_interpretation/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_01_01_Continuity_and_Uniform_Continuity",
    "title": "00-01-01 Tính liên tục và Tính liên tục đều",
    "chapter": "00",
    "order": 3,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này giới thiệu các khái niệm cơ bản về tính liên tục và tính liên tục đều, những khái niệm quan trọng để hiểu hành vi của các hàm số trong tối ưu hóa. --- Tính liên tục và Tính liên tục đều Tính liên tục và Tính liên tục đều là những khái niệm cơ bản mô tả hành vi của các hàm số, đặc biệt liên quan đến tính \"mượt mà\" hoặc \"có thể dự đoán được\" của chúng. Mặc dù có liên quan chặt chẽ, chúng thể hiện các tính chất khác biệt, với tính liên tục đều là điều kiện mạnh hơn so với tính liên tục thông thường. Định nghĩa Tính liên tục Một hàm số MATH được gọi là liên tục tại một điểm MATH nếu, với mọi số thực dương MATH , tồn tại một số thực dương MATH sao cho với mọi MATH , nếu MATH , tồn tại một số thực dương MATH sao cho với mọi MATH , nếu MATH . 3. Khả vi hầu khắp nơi : Các hàm liên tục Lipschitz khả vi hầu khắp nơi, và tại nơi đạo hàm tồn tại, MATH . Ví dụ: - MATH là 1-Lipschitz trên MATH - MATH là 1-Lipschitz trên MATH vì MATH - MATH không phải Lipschitz trên MATH nhưng là Lipschitz trên bất kỳ khoảng bị chặn nào Sự khác biệt chính và Thứ bậc Ba loại tính liên tục tạo thành một thứ bậc của các điều kiện ngày càng mạnh: Tính liên tục ⊆ Tính liên tục đều ⊆ Tính liên tục Lipschitz 1. Theo điểm so với Toàn cục : - Tính liên tục : Tính chất cục bộ kiểm tra tại mỗi điểm - Tính liên tục đều : Tính chất toàn cục của toàn bộ hàm số - Tính liên tục Lipschitz : Tính chất toàn cục với các ràng buộc định lượng 2. Lựa chọn MATH : - Tính liên tục : MATH có thể phụ thuộc vào cả MATH và điểm cụ thể MATH - Tính liên tục đều : MATH chỉ phụ thuộc vào MATH , hoạt động cho tất cả các điểm đồng thời - Tính liên tục Lipschitz : MATH cung cấp mối quan hệ rõ ràng 3. Kiểm soát Tốc độ Thay đổi : - Tính liên tục : Không kiểm soát tốc độ thay đổi - Tính liên tục đều : Đảm bảo biến thiên bị chặn trên các khoảng nhỏ - Tính liên tục Lipschitz : Cung cấp ràng buộc tuyến tính rõ ràng cho tốc độ thay đổi 4. Mối quan hệ Độ mạnh : - Mọi hàm liên tục Lipschitz đều là liên tục đều - Mọi hàm liên tục đều đều là liên tục - Các mệnh đề ngược lại nói chung không đúng Ví dụ Chi tiết và So sánh Ví dụ 1: MATH - Trên MATH : Liên tục nhưng không liên tục đều tốc độ thay đổi MATH không bị chặn - Trên MATH : Liên tục, liên tục đều, và Lipschitz với MATH Ví dụ 2: MATH - Trên MATH : Liên tục, liên tục đều, và 1-Lipschitz vì MATH Ví dụ 3: MATH - Trên MATH : Liên tục, liên tục đều, và 1-Lipschitz - Lưu ý : Không khả vi tại MATH , nhưng vẫn là Lipschitz Ví dụ 4: MATH - Trên MATH : Liên tục và liên tục đều, nhưng không phải Lipschitz đạo hàm không bị chặn gần MATH - Trên MATH với MATH : Lipschitz với MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_01_01_Continuity_and_Uniform_Continuity/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_01_02_Derivatives_and_Multivariable_Calculus",
    "title": "00-01-02 Đạo hàm và Giải tích đa biến",
    "chapter": "00",
    "order": 4,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này bao gồm đạo hàm và các khái niệm giải tích đa biến thiết yếu tạo nền tảng cho lý thuyết và thuật toán tối ưu hóa. --- Đạo hàm và Tốc độ Thay đổi Đạo hàm của một hàm một biến thể hiện tốc độ thay đổi tức thời của nó, điều này rất cơ bản để hiểu cách các hàm số hoạt động cục bộ. Các Khái niệm Đạo hàm Cơ bản Độ dốc giữa hai điểm: MATH Đạo hàm tốc độ thay đổi tức thời : MATH Đạo hàm cho chúng ta biết hàm số thay đổi nhanh như thế nào tại bất kỳ điểm nào, điều này rất quan trọng để tìm các điểm tối ưu nơi tốc độ thay đổi bằng không. Đường mức của Hàm số Đường mức là một khái niệm cơ bản trong giải tích đa biến được sử dụng để trực quan hóa các hàm hai biến, thường được ký hiệu là MATH . Chúng cung cấp cách biểu diễn một bề mặt 3D trong mặt phẳng 2D. Một đường mức của hàm số MATH là tập hợp tất cả các điểm MATH trong miền xác định của MATH nơi hàm số nhận giá trị hằng số: MATH Ví dụ: - Với MATH , các đường mức là các hình tròn: MATH - Với MATH , các đường mức là các đường thẳng song song: MATH Đường mức giúp chúng ta hiểu: 1. Địa hình của hàm số 2. Hướng tăng và giảm dốc nhất 3. Vị trí của các điểm tối ưu tiềm năng --- Các Khái niệm Chính của Giải tích Đa biến Đạo hàm Riêng Với một hàm số MATH , đạo hàm riêng theo MATH là: MATH Điều này đo lường cách MATH thay đổi khi chỉ có MATH biến thiên trong khi tất cả các biến khác giữ cố định. Vector Gradient Gradient là một vector gồm tất cả các đạo hàm riêng: MATH Gradient chỉ theo hướng tăng dốc nhất của hàm số và vuông góc với các đường mức. Ma trận Hessian Ma trận Hessian chứa tất cả các đạo hàm riêng bậc hai: MATH \\nabla^2 f \\mathbf x = \\mathbf H = \\begin pmatrix \\frac \\partial^2 f \\partial x 1^2 & \\frac \\partial^2 f \\partial x 1 \\partial x 2 & \\cdots & \\frac \\partial^2 f \\partial x 1 \\partial x n \\\\ \\frac \\partial^2 f \\partial x 2 \\partial x 1 & \\frac \\partial^2 f \\partial x 2^2 & \\cdots & \\frac \\partial^2 f \\partial x 2 \\partial x n \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac \\partial^2 f \\partial x n \\partial x 1 & \\frac \\partial^2 f \\partial x n \\partial x 2 & \\cdots & \\frac \\partial^2 f \\partial x n^2 \\end pmatrix MATH Hessian cung cấp thông tin về độ cong của hàm số và rất quan trọng cho: - Xác định bản chất của các điểm tới hạn cực tiểu, cực đại, hoặc điểm yên ngựa - Các phương pháp tối ưu hóa bậc hai như phương pháp Newton --- Quy tắc Dây chuyền cho Hàm Đa biến Quy tắc dây chuyền là cơ bản để tính đạo hàm của các hàm hợp thành, thường xuất hiện trong các bài toán tối ưu hóa. Quy tắc Dây chuyền Cơ bản Với hàm số MATH nơi MATH và MATH : MATH Quy tắc Dây chuyền Tổng quát Với MATH nơi mỗi MATH : MATH Ứng dụng trong Tối ưu hóa Quy tắc dây chuyền rất thiết yếu cho: 1. Tính toán Gradient : Tính gradient của các hàm mục tiêu hợp thành 2. Xử lý Ràng buộc : Xử lý các ràng buộc là hàm của các biến khác 3. Triển khai Thuật toán : Lan truyền ngược trong mạng nơ-ron và vi phân tự động 4. Phân tích Độ nhạy : Hiểu cách thay đổi tham số ảnh hưởng đến các nghiệm tối ưu Ví dụ: Tối ưu hóa với Ràng buộc Xem xét việc tối thiểu hóa MATH với điều kiện MATH . Sử dụng ràng buộc để loại bỏ một biến: MATH , vậy chúng ta tối thiểu hóa: MATH Sử dụng quy tắc dây chuyền: MATH Đặt MATH cho MATH , vậy điểm tối ưu là MATH . Điều này minh họa cách các khái niệm giải tích đa biến làm việc cùng nhau để giải quyết các bài toán tối ưu hóa một cách hệ thống.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_01_02_Derivatives_and_Multivariable_Calculus/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_01_03_Gradient_and_Directional_Derivatives",
    "title": "00-01-03 Gradient và Đạo hàm Hướng",
    "chapter": "00",
    "order": 5,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này khám phá vector gradient và đạo hàm hướng, những khái niệm trung tâm trong tối ưu hóa để hiểu cách các hàm số thay đổi theo các hướng khác nhau. --- Vector Gradient Gradient MATH là một vector gồm các đạo hàm riêng của hàm số MATH theo từng biến của nó. Nó chỉ ra hướng tăng dốc nhất của hàm số tại một điểm cho trước. Định nghĩa và Tính toán Với hàm hai biến MATH , gradient của nó là: MATH Với hàm MATH biến MATH : MATH Ví dụ: Tính Gradient Với MATH : MATH MATH Do đó: MATH Tại điểm MATH : MATH --- Đạo hàm Hướng Đạo hàm hướng đo tốc độ thay đổi của MATH khi chúng ta di chuyển theo bất kỳ hướng nào được chọn MATH . Ở đây MATH phải là vector đơn vị có độ dài bằng 1 . Định nghĩa Với hàm số MATH và vector đơn vị MATH : MATH Giải thích Hình học Đạo hàm hướng có thể được viết như: MATH nơi MATH là góc giữa MATH và MATH , và MATH là độ lớn của gradient. Ví dụ: Tính Đạo hàm Hướng Sử dụng ví dụ trước MATH tại điểm MATH nơi MATH : Hướng 1: MATH hướng x dương MATH Hướng 2: MATH hướng y dương MATH Hướng 3: MATH đường chéo 45° MATH --- Tốc độ Thay đổi Tối đa và Tối thiểu Các Tính chất Chính Từ công thức MATH , chúng ta có thể xác định: 1. Tốc độ Thay đổi Tối đa : Xảy ra khi MATH tức là MATH - Hướng: MATH cùng hướng với gradient - Tốc độ tối đa: MATH 2. Tốc độ Thay đổi Tối thiểu : Xảy ra khi MATH tức là MATH - Hướng: MATH ngược với gradient - Tốc độ tối thiểu: MATH 3. Tốc độ Thay đổi Bằng Không : Xảy ra khi MATH tức là MATH - Hướng: Bất kỳ vector nào vuông góc với MATH Tóm tắt Các Tính chất của Gradient - Gradient MATH chỉ theo hướng tăng dốc nhất - Hướng MATH chỉ theo hướng giảm dốc nhất - Độ lớn MATH cho tốc độ thay đổi tối đa - Khi MATH , điểm đó là điểm tới hạn tối ưu tiềm năng --- Mối quan hệ với Đường đồng mức Tại bất kỳ điểm nào trên đường mức MATH , vector gradient MATH trực giao vuông góc với đường tiếp tuyến của đường mức tại điểm đó. Tại sao Điều này Quan trọng Tính chất trực giao này rất cơ bản vì: 1. Đường mức biểu diễn giá trị hàm hằng số : Di chuyển dọc theo đường mức không thay đổi giá trị hàm, nên đạo hàm hướng bằng không. 2. Gradient chỉ hướng tăng dốc nhất : Hướng tăng giá trị hàm nhanh nhất phải vuông góc với hướng không thay đổi giá trị chút nào. 3. Thông đạt tối ưu hóa : Để tìm cực trị, chúng ta tìm các điểm nơi gradient bằng không điểm tới hạn hoặc nơi gradient vuông góc với biên ràng buộc. Ứng dụng trong Tối ưu hóa Hiểu gradient và đạo hàm hướng rất quan trọng cho: 1. Gradient Descent : Di chuyển theo hướng MATH để tối thiểu hóa MATH 2. Gradient Ascent : Di chuyển theo hướng MATH để tối đa hóa MATH 3. Tối ưu hóa có Ràng buộc : Sử dụng mối quan hệ giữa gradient và đường mức 4. Phân tích Hội tụ : Hiểu khi nào thuật toán sẽ hội tụ đến nghiệm tối ưu 5. Lựa chọn Kích thước Bước : Xác định di chuyển bao xa theo hướng gradient Gradient cung cấp cả hướng di chuyển và thông tin về tốc độ thay đổi của hàm, làm cho nó trở thành nền tảng cho hầu hết các thuật toán tối ưu hóa.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_01_03_Gradient_and_Directional_Derivatives/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_01_04_Taylor_Series",
    "title": "00-01-04 Chuỗi Taylor",
    "chapter": "00",
    "order": 6,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này bao gồm việc khai triển chuỗi Taylor, điều này rất cơ bản để xấp xỉ các hàm và hiểu hành vi cục bộ của các hàm trong các thuật toán tối ưu hóa. --- Định nghĩa Chuỗi Taylor Chuỗi Taylor là một biểu diễn của một hàm dưới dạng tổng vô hạn các số hạng được tính từ giá trị các đạo hàm của hàm tại một điểm duy nhất. Nó cung cấp một cách để xấp xỉ các hàm phức tạp bằng cách sử dụng đa thức. Chuỗi Taylor Một Biến Chuỗi Taylor là một khai triển chuỗi của hàm MATH tại điểm MATH : MATH Dưới dạng khai triển: MATH Chuỗi Maclaurin Khi khai triển tại MATH , chuỗi Taylor được gọi là chuỗi Maclaurin : MATH Các Chuỗi Maclaurin Thông Dụng Hàm Mũ: MATH Hàm Sin: MATH Hàm Cosin: MATH Logarit Tự Nhiên với MATH và MATH , điểm MATH là điểm yên ngựa, không phải cực tiểu. --- Các Xem xét Thực tế Hội tụ và Độ chính xác 1. Bán kính Hội tụ : Chuỗi Taylor chỉ hội tụ trong một bán kính nhất định từ điểm khai triển 2. Sai số Cắt bỏ : Sử dụng số hạng hữu hạn đưa vào sai số xấp xỉ 3. Chi phí Tính toán : Các số hạng bậc cao yêu cầu tính toán nhiều đạo hàm hơn Lựa chọn Thuật toán Tối ưu hóa - Phương pháp bậc nhất gradient descent : Chỉ sử dụng thông tin gradient, chậm hơn nhưng rẻ hơn mỗi lần lặp - Phương pháp bậc hai Newton : Sử dụng thông tin Hessian, hội tụ nhanh hơn nhưng đắt mỗi lần lặp - Phương pháp quasi-Newton : Xấp xỉ Hessian, cân bằng giữa tốc độ và chi phí tính toán Khai triển chuỗi Taylor giúp chúng ta xấp xỉ các hàm phức tạp với các hàm đa thức đơn giản hơn xung quanh một điểm cụ thể, điều này rất quan trọng cho các thuật toán tối ưu hóa và hiểu hành vi cục bộ của các hàm.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_01_04_Taylor_Series/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_02_Basic_Linear_Algebra",
    "title": "00-02 Đại số tuyến tính cơ bản",
    "chapter": "00",
    "order": 7,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này bao gồm các khái niệm đại số tuyến tính cần thiết cho tối ưu hóa, được tổ chức thành ba phần chính để học tập có hệ thống.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_02_Basic_Linear_Algebra/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_02_03_local_convergence_analysis",
    "title": "14-02-03 Phân tích hội tụ cục bộ",
    "chapter": "",
    "order": 7,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config ; Tính chất quan trọng thứ hai của phương pháp Newton là sự hội tụ được đảm bảo gần nghiệm khi các điều kiện nhất định được thỏa mãn. Điều này được gọi là hội tụ cục bộ. Vì phương pháp Newton thuần túy mà chúng ta đã thảo luận từ 14-01 % multilang post url contents/chapter14/2021-03-26-14 01 newton method % không đảm bảo hội tụ, sau này chúng ta sẽ thiết kế phương pháp Newton có giảm chấn để đảm bảo hội tụ bằng cách điều chỉnh kích thước bước sử dụng cùng phương pháp tìm kiếm đường backtracking được đề cập trong Chương 6 % multilang post url contents/chapter06/21-03-20-06 00 gradient descent % , và phân tích sự hội tụ của nó. >Định lý: Cho MATH liên tục khả vi, và cho MATH là một nghiệm của hàm MATH , tức là MATH . >Nếu MATH không suy biến, thì các điều kiện a và b sau được thỏa mãn: \\\\ > a Nếu tồn tại một MATH dương >0 sao cho MATH \\| x^ 0 -x^ \\star \\| \\begin align >\\lim k \\rightarrow \\infty \\frac \\|\\| x^ k+1 -x^ \\star \\|\\| \\|\\| x^ k -x^ \\star \\|\\| =0. >\\end align \\\\ > b Nếu MATH liên tục Lipschitz gần MATH , thì tồn tại một K dương >0 sao cho phương trình sau hội tụ bậc hai được thỏa mãn: >\\begin align >\\|\\|x^ k+1 - x^ \\star \\|\\| \\leq K \\|\\| x^ k -x^ \\star \\|\\|^ 2 . >\\end align Chứng minh a >Chúng ta sắp xếp MATH đến bậc 1 sử dụng khai triển Taylor. Vì các số hạng bậc 2 và cao hơn được giới hạn bởi một bội số hằng của chuẩn của số hạng bậc 1, chúng ta có thể biểu diễn nó bằng ký hiệu little-o như sau: >\\begin align >0=F x^ \\star = F x^ k +\\nabla F x^ k x^ \\star -x^ k +o \\|\\|x^ k -x^ \\star \\|\\| .\\\\ >\\end align >Nhân cả hai vế với MATH và sắp xếp. Vì little-o được xử lý như một số hạng hằng số, nó có thể được bỏ qua. >\\begin align >x^ k -x^ \\star -\\nabla F x^ k ^ -1 F x^ k = o \\|\\|x^ k -x^ \\star \\|\\| . >\\end align >Sử dụng phương pháp Newton MATH , chúng ta có thể thu được kết quả sau: >\\begin align >x^ k+1 -x^ \\star =o \\|\\|x^ k -x^ \\star \\|\\| , >\\end align >Do đó, khi MATH , chúng ta có thể chứng minh a bằng định nghĩa giới hạn của little-o wikipedia https://en.wikipedia.org/wiki/Big O notation . >\\begin align >\\lim k\\rightarrow \\infty \\frac \\|\\|x^ k+1 -x^ \\star \\|\\| \\|\\|x^ k -x^ \\star \\|\\| = \\lim k\\rightarrow \\infty \\frac o \\|\\|x^ k -x^ \\star \\|\\| \\|\\|x^ k -x^ \\star \\|\\| . >\\end align Chứng minh b Quá trình này giống hệt với việc chứng minh rằng tốc độ hội tụ trong giai đoạn Damped của 14-05 % multilang post url contents/chapter14/2021-03-26-14 05 convergence analysis % là bậc hai. Do đó, nó được bỏ qua. Ví dụ : trường hợp phân kỳ Chúng ta xem xét ngắn gọn một ví dụ mà sự hội tụ không được đảm bảo với phương pháp Newton thuần túy. Hình 1 phương pháp Newton thuần túy áp dụng cho tìm nghiệm : trường hợp phân kỳ image-link https://slideplayer.com/slide/4998677/ Như được hiển thị trong hình, tùy thuộc vào điểm khởi tạo MATH , nghiệm có thể phân kỳ.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_02_03_local_convergence_analysis/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_02_01_Vectors_and_Vector_Spaces",
    "title": "00-02-01 Vector và Không gian Vector",
    "chapter": "00",
    "order": 8,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này giới thiệu vector, không gian vector, và các khái niệm cơ bản tạo nền tảng để hiểu đại số tuyến tính trong ngữ cảnh tối ưu hóa. --- Vector và Không gian Vector MATH Vector là gì? - Vector: Hãy nghĩ về vector như một mũi tên trong không gian, biểu diễn cả hướng và độ lớn độ dài . Về mặt toán học, nó là một danh sách có thứ tự các số, giống như tọa độ. Ví dụ, một vector trong không gian 2D có thể là MATH , có nghĩa là 3 đơn vị dọc theo trục x và 4 đơn vị dọc theo trục y. - Góc nhìn Hình học vs Đại số: - Hình học: Vector là mũi tên có hướng và độ lớn - Đại số: Vector là danh sách có thứ tự các số thực Không gian Vector - Không gian Vector MATH : Đây là tập hợp tất cả các vector có thể có MATH thành phần số . Ví dụ, MATH bao gồm tất cả vector 2 thành phần, biểu diễn tất cả các điểm hoặc mũi tên trong mặt phẳng 2D. - Ví dụ: - MATH mặt phẳng - MATH không gian 3D Các Phép toán Vector Phép Cộng Vector: MATH Phép Nhân Vô hướng: MATH --- Độc lập Tuyến tính, Cơ sở, và Chiều Độc lập Tuyến tính Một tập hợp vector MATH là độc lập tuyến tính nếu nghiệm duy nhất của: MATH là MATH . Hiểu biết Trực quan: Một tập hợp vector \"độc lập tuyến tính\" nếu không có vector nào trong tập có thể được tạo ra bằng cách chia tỷ lệ và cộng các vector khác trong tập. Tất cả chúng đều chỉ theo các hướng \"đủ khác nhau\". Ví dụ trong MATH : - MATH và MATH là độc lập tuyến tính - MATH và MATH là phụ thuộc tuyến tính vì MATH Cơ sở Một cơ sở cho một không gian vector là một tập hợp tối thiểu các vector độc lập tuyến tính có thể được kết hợp chia tỷ lệ và cộng để tạo ra bất kỳ vector nào khác trong không gian đó. Nó giống như một tập hợp các khối xây dựng cơ bản. Tính chất của một Cơ sở: 1. Các vector độc lập tuyến tính 2. Chúng sinh ra toàn bộ không gian vector 3. Mọi vector trong không gian có thể được viết duy nhất như một tổ hợp tuyến tính của các vector cơ sở Cơ sở Chuẩn cho MATH : MATH Chiều Chiều của một không gian vector đơn giản là số lượng vector trong bất kỳ cơ sở nào của nó. Nó cho bạn biết cần bao nhiêu hướng độc lập để mô tả không gian. - MATH - MATH - MATH --- Chuẩn của Vector Chuẩn là một hàm gán \"độ dài\" hoặc \"kích thước\" cho một vector. Nó tổng quát hóa khái niệm khoảng cách từ gốc tọa độ. Tính chất của Chuẩn Bất kỳ chuẩn MATH nào cũng phải thỏa mãn ba tính chất: 1. Không âm: MATH , và MATH khi và chỉ khi MATH 2. Đồng nhất: MATH với bất kỳ vô hướng MATH 3. Bất đẳng thức Tam giác: MATH Các Chuẩn Thông dụng Chuẩn Euclid Chuẩn L2 : MATH Đây là khoảng cách \"thông thường\" mà chúng ta quen thuộc. Chuẩn Manhattan Chuẩn L1 : MATH Còn được gọi là \"chuẩn taxi\" - khoảng cách mà một chiếc taxi sẽ đi trong thành phố có bố cục dạng lưới. Chuẩn Tối đa Chuẩn L∞ : MATH Thành phần lớn nhất theo giá trị tuyệt đối. Ví dụ: Với MATH : - MATH - MATH - MATH --- Tích Vô hướng Tích Chấm Tích chấm hoặc tích vô hướng là cách phổ biến nhất để nhân hai vector, tạo ra kết quả vô hướng. Định nghĩa Với hai vector MATH và MATH trong MATH : MATH Diễn giải Hình học MATH trong đó MATH là góc giữa các vector. Tính chất 1. Giao hoán: MATH 2. Phân phối: MATH 3. Đồng nhất: MATH Trường hợp Đặc biệt - Vector trực giao: MATH vuông góc - Vector song song: MATH - Tích chấm bản thân: MATH Ví dụ Với MATH và MATH : MATH --- Ứng dụng trong Tối ưu hóa Hiểu về vector và không gian vector là rất quan trọng cho tối ưu hóa vì: 1. Biến Quyết định: Các bài toán tối ưu hóa thường liên quan đến việc tìm giá trị tốt nhất cho nhiều biến, được biểu diễn tự nhiên như vector. 2. Gradient: Gradient của một hàm là một vector chỉ theo hướng tăng dốc nhất. 3. Ràng buộc: Ràng buộc tuyến tính trong tối ưu hóa có thể được biểu diễn bằng tích chấm: MATH . 4. Khoảng cách và Độ tương tự: Các chuẩn khác nhau cung cấp các cách khác nhau để đo khoảng cách giữa các nghiệm hoặc kích thước của các thay đổi. 5. Tính trực giao: Nhiều khái niệm tối ưu hóa dựa vào tính vuông góc, chẳng hạn như mối quan hệ giữa gradient và đường mức. 6. Tổ hợp Tuyến tính: Vùng khả thi thường được định nghĩa như tổ hợp tuyến tính của vector bao lồi, hình nón, v.v. . Khung không gian vector cung cấp nền tảng toán học để xây dựng và giải quyết các bài toán tối ưu hóa một cách có hệ thống.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_02_01_Vectors_and_Vector_Spaces/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_02_02_Matrices_and_Linear_Transformations",
    "title": "00-02-02 Ma trận và Phép biến đổi Tuyến tính",
    "chapter": "00",
    "order": 9,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này bao gồm ma trận, các phép toán ma trận, và phép biến đổi tuyến tính, là những công cụ cơ bản để biểu diễn và giải quyết các bài toán tối ưu hóa. --- Ma trận và Các Phép toán Ma trận Ma trận là gì? A matrix is a rectangular grid of numbers arranged in rows and columns. Matrices represent data, transformations, systems of equations, and relationships between variables. General Form: MATH \\mathbf A = \\begin pmatrix a 11 & a 12 & \\cdots & a 1n \\\\ a 21 & a 22 & \\cdots & a 2n \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a m1 & a m2 & \\cdots & a mn \\end pmatrix MATH This is an MATH matrix MATH rows, MATH columns . Example: MATH is a MATH matrix. Matrix Addition Matrices are added by summing corresponding elements. Both matrices must have the same dimensions. MATH Example: MATH Scalar Multiplication Multiply every element of the matrix by the scalar: MATH Matrix Multiplication For matrices MATH and MATH , the product MATH is formed by taking the dot product of rows from MATH and columns from MATH : MATH Example: MATH Important: Matrix multiplication is not commutative : MATH in general. --- Linear Transformations A linear transformation is a function MATH that preserves vector addition and scalar multiplication. Every linear transformation can be represented by a matrix. Definition A transformation MATH is linear if and only if: 1. Additivity: MATH 2. Homogeneity: MATH These can be combined into: MATH Matrix-Vector Multiplication If MATH is an MATH matrix and MATH is an MATH column vector, their product MATH is an MATH column vector: MATH \\mathbf w = \\mathbf Av = \\begin pmatrix a 11 v 1 + a 12 v 2 + \\cdots + a 1n v n \\\\ a 21 v 1 + a 22 v 2 + \\cdots + a 2n v n \\\\ \\vdots \\\\ a m1 v 1 + a m2 v 2 + \\cdots + a mn v n \\end pmatrix MATH Example: MATH --- Common 2D Transformations Understanding geometric transformations helps visualize how matrices affect vectors. Scaling Scaling Matrix: MATH - Scales x-coordinates by MATH and y-coordinates by MATH - Example: MATH doubles x-values and triples y-values Rotation Rotation Matrix counter-clockwise by angle MATH : MATH - Example: 90° rotation: MATH - Transforms MATH Reflection Reflection across x-axis: MATH Reflection across y-axis: MATH Reflection across line MATH : MATH Shearing Horizontal Shear: MATH Transforms MATH --- Special Types of Matrices Identity Matrix The identity matrix MATH acts like the number 1 for matrix multiplication: MATH \\mathbf I n = \\begin pmatrix 1 & 0 & \\cdots & 0 \\\\ 0 & 1 & \\cdots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & 1 \\end pmatrix MATH Property: MATH for any compatible matrix MATH . Transpose The transpose MATH flips a matrix across its main diagonal: MATH Properties: - MATH - MATH - MATH Symmetric Matrices A matrix is symmetric if MATH : MATH Symmetric matrices have special properties important in optimization. Inverse Matrix The inverse MATH of a square matrix MATH satisfies: MATH For 2×2 matrices: MATH where MATH and MATH . Note: Not all matrices have inverses. A matrix is invertible non-singular if and only if its determinant is non-zero. --- Applications in Optimization Matrices and linear transformations are fundamental in optimization for several reasons: 1. System of Linear Equations Many optimization problems involve solving MATH : - Unique solution: MATH when MATH is invertible - Least squares: Minimize MATH when no exact solution exists 2. Quadratic Forms Quadratic functions appear frequently in optimization: MATH The matrix MATH determines the curvature properties of the function. 3. Linear Programming Standard form: Minimize MATH subject to MATH , MATH 4. Constraint Representation - Equality constraints: MATH - Inequality constraints: MATH 5. Transformations of Variables Change of variables: MATH can simplify optimization problems. Example: Portfolio Optimization In finance, we might minimize portfolio risk: MATH where MATH is the vector of portfolio weights and MATH is the covariance matrix of asset returns. Understanding matrices and linear transformations provides the tools to formulate, analyze, and solve a wide variety of optimization problems efficiently.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_02_02_Matrices_and_Linear_Transformations/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter15/15_03_02_suboptimality_gap",
    "title": "15-03-02 Suboptimality gap",
    "chapter": "",
    "order": 9,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "앞 절에서 구한 barrier problem과 original problem의 solution인 MATH 와 MATH 의 suboptimality gap은 어떻게 될까? What is the suboptimality gap between MATH , the solution to the barrier problem, and MATH , the solution to the original problem, as derived in the previous section? 따라서, 다음의 식을 구할 수 있다. > MATH \\begin align If convexity is guaranteed, the function is always greater than its tangent, so MATH holds. The tangent is the first-order Taylor approximation Therefore, we can derive the following equation: 비슷하게 MATH 가 성립하므로 다음의 식을 구할 수 있다. Similarly, since MATH holds, we can derive the following equation: h i x^ t - h i x^ \\le \\nabla h i x^ t ^T x^ t - x^ , \\quad i = i, \\cdots , m \\end align MATH Derivation of suboptimality gap 이 두 식에서 suboptimality gap을 유도해 보도록 하겠다. 오른쪽 항은 위의 두 convexity 조건에 의해 도출된다. Let's use these two equations to derive the suboptimality gap. The right-hand side is derived from the two convexity conditions above. f x^ t - f x^ + \\sum i=1 ^ m u i t h i x^ t - h i x^ & \\le \\left\\langle \\nabla f x^ t + \\sum i=1 ^ m u i t \\nabla h i x^ t , \\quad x^ t - x^ \\right\\rangle \\\\\\ & = \\left\\langle -tA^Tv, \\quad x^ t - x^ \\right\\rangle \\\\\\ \\end align MATH 이 식에서 오른쪽 항을 내적해 보면 MATH 이고 MATH 이므로 전체가 0이 된다. 따라서, 첫번째 식의 세번째 항을 오른쪽으로 넘겨서 정리해 보면 다음과 같은 결과를 얻을 수 있다. If we look at the right-hand side of this equation as an inner product, since MATH and MATH , the whole term becomes zero. Therefore, moving the third term of the first equation to the right and simplifying, we get the following result: f x^ t - f x^ & \\le - \\sum i=1 ^ m u i t h i x^ t - h i x^ \\\\\\ & = \\frac m t + \\sum i=1 ^ m u i t h i x^ \\\\\\ & \\le \\frac m t \\end align MATH 두번째 라인의 첫번째 항은 KKT condition에서 MATH 를 만족하므로 MATH 가 된다. 두번째 항도 KKT condition에서 MATH 이므로 제거할 수 있다. 결과적으로 다음과 같은 suboptimality gap을 구할 수 있으며 이는 유용한 stopping criterion이 된다. 참고로, 이 결과는 다음 장에서 duality gap으로도 유도할 수 있다. > MATH \\begin align f x^ t - f x^ \\le \\frac m t \\end align MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter15/15_03_02_suboptimality_gap/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_02_03_Eigenvalues_and_Eigenvectors",
    "title": "00-02-03 Giá trị riêng và Vector riêng",
    "chapter": "00",
    "order": 10,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này bao gồm giá trị riêng và vector riêng, rất quan trọng để hiểu hành vi của các phép biến đổi tuyến tính và hàm bậc hai trong tối ưu hóa. --- Định nghĩa và Trực giác Khi một ma trận biến đổi một vector, nó thường thay đổi cả hướng và độ dài của vector. Tuy nhiên, vector riêng là những vector đặc biệt mà khi được biến đổi bởi một ma trận cho trước, chỉ bị thay đổi tỉ lệ nhưng không thay đổi hướng. Định nghĩa Toán học Với một ma trận vuông MATH và một vector khác không MATH : - MATH là một vector riêng của MATH - MATH là giá trị riêng tương ứng nếu chúng thỏa mãn phương trình giá trị riêng : MATH Giải thích Hình học - Vector riêng: Các vector khác không duy trì hướng của chúng dưới phép biến đổi MATH - Giá trị riêng: Các hệ số vô hướng mà các vector riêng được nhân với Hiểu biết Trực quan: - Nếu MATH : Vector riêng bị kéo dài - Nếu MATH for MATH : All eigenvalues of MATH are positive - Positive semidefinite MATH : All eigenvalues are non-negative - Negative definite MATH f \\mathbf x 0 - Local maximum: Hessian is negative definite all eigenvalues 0 MATH \\lambda 2 = 5 - \\sqrt 5 > 0 MATH , the Hessian is positive definite, confirming that the origin is a global minimum. The condition number is MATH , indicating reasonably good conditioning for optimization algorithms. Understanding eigenvalues and eigenvectors provides deep insights into the geometric and analytical properties of optimization problems, enabling better algorithm design and convergence analysis.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_02_03_Eigenvalues_and_Eigenvectors/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_03_Real_Analysis_and_Set_Theory",
    "title": "00-03 Giải tích thực và Lý thuyết tập hợp",
    "chapter": "00",
    "order": 11,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này bao gồm các khái niệm cần thiết từ giải tích thực và lý thuyết tập hợp cần thiết cho tối ưu hóa, được tổ chức thành hai phần chính để hiểu một cách toàn diện.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_03_Real_Analysis_and_Set_Theory/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_03_01_Set_Theory_Fundamentals",
    "title": "00-03-01 Cơ sở Lý thuyết tập hợp",
    "chapter": "00",
    "order": 12,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này bao gồm các khái niệm cơ bản từ lý thuyết tập hợp cung cấp nền tảng toán học để hiểu các bài toán tối ưu hóa, ràng buộc và vùng khả thi. --- Giới thiệu về Lý thuyết tập hợp Lý thuyết tập hợp cung cấp nền tảng cho toán học hiện đại và rất cần thiết để hiểu các khái niệm tối ưu hóa. Một tập hợp đơn giản là một bộ sưu tập các đối tượng riêng biệt, được gọi là các phần tử hoặc thành viên. Ký hiệu cơ bản - Ký hiệu tập hợp: MATH - Quan hệ thành viên: MATH x thuộc A hoặc MATH x không thuộc A - Tập rỗng: MATH tập hợp không có phần tử nào - Ký hiệu xây dựng tập hợp: MATH tập hợp tất cả x sao cho tính chất P x đúng Ví dụ - MATH liệt kê tường minh - MATH : MATH lớn hơn MATH một cách nghiêm ngặt - MATH : MATH lớn hơn hoặc bằng MATH Tính chất của bất đẳng thức 1. Tính bắc cầu: Nếu MATH và MATH , thì MATH 2. Phép cộng: Nếu MATH , thì MATH với mọi MATH 3. Nhân với số dương: Nếu MATH và MATH , thì MATH 4. Nhân với số âm: Nếu MATH và MATH , thì MATH bất đẳng thức đảo chiều! Ký hiệu khoảng - Khoảng mở: MATH - Khoảng đóng: MATH - Khoảng nửa mở: MATH , MATH - Khoảng không bị chặn: MATH , MATH , MATH --- Ứng dụng trong Tối ưu hóa Các khái niệm lý thuyết tập hợp là cơ bản cho tối ưu hóa: 1. Vùng khả thi Vùng khả thi là tập hợp tất cả các điểm thỏa mãn các ràng buộc: MATH 2. Tập mức Với một hàm số MATH , tập mức tại mức MATH là: MATH 3. Điều kiện ràng buộc Hiểu biết khi nào các tập ràng buộc có các tính chất \"tốt\" như đóng hoặc có phần trong không rỗng ảnh hưởng đến sự tồn tại và đặc trưng của các nghiệm tối ưu. 4. Phân tích hội tụ Dãy số và giới hạn là thiết yếu để phân tích liệu các thuật toán tối ưu hóa có hội tụ về nghiệm tối ưu hay không. 5. Các phép toán tập hợp trong thuật toán - Giao: Tìm các điểm thỏa mãn nhiều ràng buộc - Hợp: Kết hợp các vùng khả thi từ các kịch bản khác nhau - Phần bù: Hiểu biết về các vùng không khả thi Ví dụ: Trong quy hoạch tuyến tính, vùng khả thi là: MATH Đây là giao của các nửa không gian, minh họa cách các phép toán tập hợp xuất hiện tự nhiên trong việc xây dựng bài toán tối ưu hóa. Hiểu biết về lý thuyết tập hợp cung cấp nền tảng toán học chặt chẽ cần thiết để xây dựng các bài toán tối ưu hóa một cách chính xác và phân tích các tính chất của chúng một cách hệ thống.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_03_01_Set_Theory_Fundamentals/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter15/15_06_barrier_method_v2",
    "title": "15-06 Barrier method v.2",
    "chapter": "",
    "order": 12,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "이전 알고리즘에서는 central path에 있는 solution을 생성했는데, 실제 central path는 optimal로 가는 과정 \"means to an end\" 일 뿐이다. 따라서, 문제를 정확히 풀 필요는 없다. In the previous algorithm, we generated solutions along the central path, but in reality, the central path is just a means to reach the optimal solution. Therefore, it is not necessary to solve the problem exactly. Algorithm For this reason, Barrier method v.2 solves the barrier problem approximately. 단, 단계 2의 MATH 와 단계 3-2의 MATH 부분이 approximation으로 바뀌었다. The steps of the algorithm are the same as those in Barrier method v.1. 1. MATH 이고 MATH 을 선택한다. However, in step 2, MATH and in step 3-2, MATH are now approximations. 3. While MATH 1. Choose MATH and set MATH . 2. At MATH , solve the barrier problem to obtain MATH . 3. While MATH 3-1. Choose MATH . 3-2. Initialize Newton's method with MATH . warm start At MATH , solve the barrier problem to obtain MATH . end while Barrier method v.2에서는 다음 두 가지 사항이 매우 중요하다. 얼마나 근사를 잘 할 수 있는가? How close should each approximation be? In Barrier method v.2, the following two issues are very important: How close should each approximation be? How many Newton steps are needed at each centering step? In the following figure, you can see that when the barrier method is applied to a problem with MATH constraints, linear convergence occurs even as MATH becomes large. That is, it has a log scale with respect to MATH . Fig 1 m에 대해 newton iteration과 suboptimality gap 분석 1 다르게 보면 MATH 인 초기 suboptimal gap duality gap 을 줄이기 위해 필요한 newton step은 MATH 에 대해 천천히 증가한다. 아래 그림을 보면 MATH 이 크게 증하하더라도 각 centering step 별로 20~30 newton step 정도만 필요하다. 단, 한 newton step은 문제의 크기에 따라 크게 달라진다. Fig 2 m의 증가와 newton iteration 수 분석 1",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter15/15_06_barrier_method_v2/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_03_02_Topology_in_Real_Analysis",
    "title": "00-03-02 Tôpô trong Giải tích thực",
    "chapter": "00",
    "order": 13,
    "owner": "GitHub Copilot",
    "lesson_type": "required",
    "content": "Bài học này bao gồm các khái niệm tôpô cần thiết từ giải tích thực, rất quan trọng để hiểu cấu trúc của các vùng khả thi, tính liên tục và sự tồn tại của nghiệm tối ưu trong các bài toán tối ưu hóa. --- Giới thiệu về Tôpô Tôpô nghiên cứu các tính chất của không gian được bảo toàn dưới các biến dạng liên tục. Trong tối ưu hóa, các khái niệm tôpô giúp chúng ta hiểu cấu trúc của các vùng khả thi và hành vi của các hàm số, đặc biệt liên quan đến sự tồn tại và đặc trưng của nghiệm tối ưu. Không gian metric và Khoảng cách Trước khi thảo luận về tôpô, chúng ta cần khái niệm khoảng cách. Trong MATH , khoảng cách Euclid chuẩn giữa các điểm MATH và MATH là: MATH Hình cầu mở và Lân cận Một hình cầu mở có tâm tại MATH với bán kính MATH là: MATH such that the open ball MATH is entirely contained within MATH : MATH Intuitive Understanding An open set has the property that if you're inside it, you can move a small distance in any direction and still remain inside the set. There's always some \"wiggle room\" around every point. Examples of Open Sets In MATH : - MATH first quadrant, excluding axes - MATH itself In MATH : - Any open ball MATH - MATH itself - MATH empty set - vacuously open Properties of Open Sets 1. The union of any collection of open sets is open 2. The intersection of finitely many open sets is open 3. MATH and MATH are both open --- Closed Sets A closed set is defined as a set that contains all of its boundary points. Equivalently, a set MATH is closed if its complement MATH is an open set . Formal Definition A set MATH is closed if it contains all its limit points. That is, if a sequence of points MATH from MATH converges to a point MATH , then MATH must also be in MATH : MATH Examples of Closed Sets In MATH : - MATH - MATH - MATH single point - MATH integers In MATH : - MATH closed unit disk - MATH first quadrant, including axes - MATH single point In MATH : - Any closed ball MATH - MATH itself - MATH empty set - Any finite set Properties of Closed Sets 1. The intersection of any collection of closed sets is closed 2. The union of finitely many closed sets is closed 3. MATH and MATH are both closed Important Note Sets can be: - Open but not closed: MATH - Closed but not open: MATH - Both open and closed: MATH , MATH - Neither open nor closed: MATH , MATH --- Boundary, Interior, and Closure Boundary The boundary of a set MATH , denoted MATH , consists of points that are \"on the edge\" of the set. A point MATH is a boundary point of MATH if every open ball centered at MATH intersects both MATH and its complement MATH : MATH Interior The interior of a set MATH , denoted MATH or MATH , includes all points strictly \"inside\" the set, excluding the boundary: MATH Closure The closure of a set MATH , denoted MATH or MATH , is the smallest closed set containing MATH : MATH Example Analysis For the interval MATH in MATH : - Interior: MATH - Boundary: MATH - Closure: MATH For the open disk MATH such that MATH - Closed: As defined above Examples of Compact Sets In MATH : - MATH any closed, bounded interval - MATH single point - Any finite set In MATH : - MATH closed unit disk - MATH unit square - Any finite set of points In MATH : - Any closed ball MATH - Any closed, bounded rectangle MATH Non-Compact Sets - MATH bounded but not closed - MATH closed but not bounded - MATH not bounded - MATH bounded but not closed, since 0 is a limit point not in the set --- Continuity of Functions Point-wise Continuity A function MATH is continuous at a point MATH if for every MATH , there exists MATH such that for all MATH : MATH Intuitive meaning: Small changes in input lead to small changes in output. Global Continuity MATH is continuous on MATH if it's continuous at every point in MATH . Sequential Characterization MATH is continuous at MATH if and only if for every sequence MATH in MATH converging to MATH : MATH --- Important Theorems for Optimization Extreme Value Theorem If MATH is continuous on a compact set MATH , then MATH attains its maximum and minimum on MATH . This is fundamental for optimization: it guarantees that continuous objective functions have optimal solutions on compact feasible regions. Proof idea: Compactness ensures that the supremum and infimum of MATH on MATH are actually achieved at points in MATH . Intermediate Value Theorem If MATH is continuous on MATH and MATH is between MATH and MATH , then there exists MATH such that MATH . This helps establish the existence of solutions to equations MATH . Bolzano-Weierstrass Theorem Every bounded sequence in MATH has a convergent subsequence. This is crucial for proving convergence of optimization algorithms. Weierstrass Approximation Theorem Every continuous function on a closed interval can be uniformly approximated by polynomials. This justifies using polynomial approximations in optimization algorithms. --- Applications in Optimization 1. Existence of Solutions Compact feasible sets guarantee optimal solutions exist: - If the feasible region MATH is compact and the objective function MATH is continuous, then the optimization problem MATH has a solution. 2. Constraint Qualification Understanding topological properties of constraint sets: - Regular points: Points where constraint gradients are linearly independent - Interior point methods: Require the feasible region to have non-empty interior 3. Convergence Analysis Analyzing whether optimization algorithms converge: - Closed sets: Ensure limit points of convergent sequences remain feasible - Compactness: Guarantees convergent subsequences exist 4. Local vs Global Optima Using neighborhoods to define optimality: - Local minimum: MATH for all MATH in some neighborhood of MATH - Global minimum: MATH for all MATH in the feasible region 5. Feasible Region Analysis Determining properties of constraint sets: - Linear constraints: Define closed sets half-spaces - Nonlinear constraints: May create sets that are neither open nor closed - Compact feasible regions: Guarantee existence of optimal solutions Example: Portfolio Optimization Consider minimizing portfolio risk subject to constraints: MATH \\begin align \\min \\mathbf w \\quad & \\mathbf w ^T \\mathbf \\Sigma \\mathbf w \\\\ \\text s.t. \\quad & \\mathbf 1 ^T \\mathbf w = 1 \\\\ & \\mathbf w \\geq \\mathbf 0 \\end align MATH The feasible region MATH is: - Closed: It's the intersection of closed sets - Bounded: The constraint MATH with MATH bounds the feasible region - Compact: Being closed and bounded in MATH Since the objective function MATH is continuous and MATH is compact, the Extreme Value Theorem guarantees that an optimal portfolio exists. Understanding topology and real analysis provides the rigorous foundation needed to prove that optimization problems have solutions and that algorithms will find them. These concepts are essential for both theoretical analysis and practical algorithm design.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_03_02_Topology_in_Real_Analysis/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_04_Probability_and_Statistics",
    "title": "00-04 Xác Suất và Thống Kê",
    "chapter": "00",
    "order": 13,
    "owner": "AI Assistant",
    "lesson_type": "required",
    "content": "Xác Suất và Thống Kê cho Tối Ưu Hóa Lồi Xác suất và thống kê tạo nên nền tảng quan trọng để hiểu nhiều bài toán tối ưu hóa, đặc biệt trong học máy và khoa học dữ liệu. Phần này giới thiệu các khái niệm xác suất thiết yếu thường xuất hiện trong tối ưu hóa lồi, từ ước lượng hợp lý tối đa đến tối ưu hóa Bayes. Tại Sao Xác Suất Quan Trọng trong Tối Ưu Hóa Nhiều bài toán tối ưu hóa phát sinh từ mô hình hóa thống kê: - Ước Lượng Hợp Lý Tối Đa MLE : Tìm tham số để tối đa hóa khả năng của dữ liệu quan sát - Tối Ưu Hóa Bayes : Sử dụng mô hình xác suất để hướng dẫn tìm kiếm giải pháp tối ưu - Tối Ưu Hóa Ngẫu Nhiên : Xử lý sự bất định và ngẫu nhiên trong hàm mục tiêu - Regularization : Thêm prior xác suất để ngăn overfitting - Tối Thiểu Hóa Rủi Ro : Tối ưu hóa kỳ vọng loss trên phân phối xác suất Các Chủ Đề Chính 1. Lý Thuyết Xác Suất Cơ Bản : Không gian mẫu, biến cố và tiên đề xác suất 2. Các Phân Phối Xác Suất Thông Dụng : Phân phối chuẩn, mũ và các phân phối quan trọng khác 3. Kỳ Vọng và Phương Sai : Tính toán và tối ưu hóa giá trị kỳ vọng 4. Định Lý Bayes : Nền tảng cho tối ưu hóa và suy luận Bayes 5. Ước Lượng Thống Kê : Kết nối lý thuyết xác suất với bài toán tối ưu hóa Kết Nối với Tối Ưu Hóa Lồi Hiểu xác suất giúp bạn: - Xây Dựng Bài Toán : Chuyển đổi sự bất định thực tế thành bài toán tối ưu hóa toán học - Chọn Hàm Mục Tiêu : Lựa chọn hàm loss phù hợp dựa trên giả thuyết xác suất - Diễn Giải Kết Quả : Hiểu khoảng tin cậy và ý nghĩa thống kê của nghiệm - Xử Lý Nhiễu : Đối phó với lỗi đo lường và quá trình ngẫu nhiên - Thiết Kế Thuật Toán : Phát triển phương pháp tối ưu hóa bền vững hoạt động dưới sự bất định Nền tảng này sẽ rất quan trọng khi chúng ta khám phá cách các mô hình xác suất dẫn đến bài toán tối ưu hóa lồi trong học máy, thống kê và các ứng dụng kỹ thuật. 💡 Lộ Trình Học: Bắt đầu với các khái niệm xác suất cơ bản, sau đó khám phá cách chúng kết nối với tối ưu hóa thông qua ước lượng hợp lý tối đa và phương pháp Bayes. Mỗi bài học xây dựng hướng tới việc hiểu cách sự bất định và ngẫu nhiên tạo ra các bài toán tối ưu hóa.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_04_Probability_and_Statistics/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_04_01_Basic_Probability_Theory",
    "title": "00-04-01 Lý Thuyết Xác Suất Cơ Bản",
    "chapter": "00",
    "order": 14,
    "owner": "AI Assistant",
    "lesson_type": "required",
    "content": "Lý Thuyết Xác Suất Cơ Bản Lý thuyết xác suất cung cấp khung toán học để lý luận về sự bất định, điều này là nền tảng cho nhiều bài toán tối ưu hóa trong học máy và khoa học dữ liệu. 1. Không Gian Mẫu và Biến Cố Không Gian Mẫu Ω : Tập hợp tất cả các kết quả có thể có của một thí nghiệm. Biến Cố A : Một tập con của không gian mẫu đại diện cho một tập hợp các kết quả. Ví dụ: - Tung đồng xu: Ω = S, N - Tung xúc xắc: Ω = 1, 2, 3, 4, 5, 6 - Liên tục: Ω = 0, 1 cho biến ngẫu nhiên đều Trực Quan Hóa Không Gian Mẫu Tương Tác Trực quan hóa: Nhấp để tạo mẫu ngẫu nhiên. Các màu khác nhau đại diện cho các biến cố khác nhau. Loại Thí Nghiệm Tung Đồng Xu Tung Xúc Xắc Đều 0,1 Tạo Mẫu Xóa Thống Kê: Tổng mẫu: 0 Biến cố A: 0 Biến cố B: 0 P A ≈ 0.000 P B ≈ 0.000 2. Tiên Đề Xác Suất Tiên Đề Kolmogorov Với bất kỳ độ đo xác suất P nào, các tiên đề sau phải được thỏa mãn: Tiên Đề 1: Tính Không Âm MATH Tiên Đề 2: Chuẩn Hóa MATH Tiên Đề 3: Tính Cộng Đếm Được Với các biến cố xung khắc MATH : MATH 3. Tính Chất và Quy Tắc Cơ Bản Quy Tắc Phần Bù MATH Quy Tắc Cộng Với hai biến cố A và B bất kỳ: MATH Quy Tắc Nhân MATH 4. Xác Suất Có Điều Kiện Xác suất của biến cố A khi biết rằng biến cố B đã xảy ra: MATH Diễn giải : Xác suất có điều kiện cập nhật niềm tin của chúng ta về A khi có thông tin về B. Trực Quan Hóa Xác Suất Có Điều Kiện Biểu Đồ Venn: Hình tròn xanh là biến cố A, hình tròn đỏ là biến cố B. Giao màu tím thể hiện A ∩ B. Điều Chỉnh Xác Suất P A : 0.4 P B : 0.5 Giao: 0.2 Xác Suất: P A = 0.400 P B = 0.500 P A ∩ B = 0.200 P A ∪ B = 0.700 Có Điều Kiện: P A|B = 0.400 P B|A = 0.500 5. Tính Độc Lập Hai biến cố A và B độc lập nếu: MATH Tương đương: MATH Diễn giải : Kiến thức về một biến cố không thay đổi xác suất của biến cố kia. 6. Biến Ngẫu Nhiên Biến ngẫu nhiên X là một hàm gán một số thực cho mỗi kết quả trong không gian mẫu: MATH Các Loại Biến Ngẫu Nhiên: Rời rạc : Nhận các giá trị đếm được ví dụ: số lần xuất hiện mặt sấp - Hàm Khối Xác Suất PMF : MATH Liên tục : Nhận các giá trị không đếm được ví dụ: chiều cao, cân nặng - Hàm Mật Độ Xác Suất PDF : MATH - MATH 7. Kết Nối với Tối Ưu Hóa Lý thuyết xác suất kết nối với tối ưu hóa theo nhiều cách: Ước Lượng Hợp Lý Tối Đa Tìm tham số θ để tối đa hóa likelihood: MATH Tối Ưu Hóa Giá Trị Kỳ Vọng Tối thiểu hóa kỳ vọng loss: MATH Tối Ưu Hóa Bayes Sử dụng phân phối xác suất để mô hình hóa sự bất định trong hàm mục tiêu và hướng dẫn tìm kiếm nghiệm tối ưu. Ví Dụ Xác Suất trong Tối Ưu Hóa Ví Dụ MLE: Tìm tham số μ để tối đa hóa likelihood của dữ liệu quan sát từ Normal μ, 1 . Demo MLE μ Thực: 2.0 Kích Thước Mẫu: 20 Tạo Dữ Liệu & Tìm MLE Kết Quả: μ Thực: 2.000 Trung bình mẫu: -- Ước lượng MLE: -- Sai số: -- Những Điểm Chính 1. Nền Tảng : Tiên đề xác suất cung cấp nền tảng toán học để lý luận về sự bất định 2. Xác Suất Có Điều Kiện : Thiết yếu để cập nhật niềm tin với thông tin mới 3. Tính Độc Lập : Đơn giản hóa tính toán và giả thuyết mô hình hóa 4. Biến Ngẫu Nhiên : Cầu nối giữa xác suất trừu tượng và ứng dụng cụ thể 5. Kết Nối Tối Ưu Hóa : Nhiều bài toán tối ưu hóa phát sinh từ mô hình hóa xác suất Hiểu những khái niệm cơ bản này chuẩn bị cho bạn các chủ đề nâng cao hơn như suy luận Bayes, ước lượng hợp lý tối đa và tối ưu hóa ngẫu nhiên - những yếu tố trung tâm của học máy và khoa học dữ liệu hiện đại. // Sample Space Visualization class SampleSpaceDemo constructor this.canvas = document.getElementById 'sampleSpaceCanvas' ; this.ctx = this.canvas.getContext '2d' ; this.width = this.canvas.width; this.height = this.canvas.height; this.samples = ; this.experimentType = 'coin'; this.setupControls ; this.draw ; setupControls const radios = document.querySelectorAll 'input name=\"experiment\" ' ; const generateBtn = document.getElementById 'generate-sample' ; const clearBtn = document.getElementById 'clear-samples' ; radios.forEach radio => radio.addEventListener 'change', e => this.experimentType = e.target.value; this.samples = ; this.updateStats ; this.draw ; ; ; generateBtn.addEventListener 'click', => this.generateSample ; clearBtn.addEventListener 'click', => this.samples = ; this.updateStats ; this.draw ; ; this.canvas.addEventListener 'click', => this.generateSample ; generateSample let sample; switch this.experimentType case 'coin': sample = value: Math.random = 4, // Biến cố A: 4, 5, hoặc 6 eventB: diceValue % 2 === 0 // Biến cố B: Chẵn ; break; case 'uniform': const uniformValue = Math.random ; sample = value: uniformValue.toFixed 3 , x: uniformValue this.width - 40 + 20, y: Math.random this.height - 40 + 20, eventA: uniformValue > 0.5, // Biến cố A: > 0.5 eventB: uniformValue s.eventA .length; const eventBCount = this.samples.filter s => s.eventB .length; document.getElementById 'total-samples' .textContent = total; document.getElementById 'event-a-count' .textContent = eventACount; document.getElementById 'event-b-count' .textContent = eventBCount; document.getElementById 'prob-a' .textContent = total > 0 ? eventACount / total .toFixed 3 : '0.000'; document.getElementById 'prob-b' .textContent = total > 0 ? eventBCount / total .toFixed 3 : '0.000'; draw this.ctx.clearRect 0, 0, this.width, this.height ; // Draw background this.ctx.fillStyle = ' f8f9fa'; this.ctx.fillRect 0, 0, this.width, this.height ; // Draw samples this.samples.forEach sample => // Determine color based on events let color = ' 666'; if sample.eventA && sample.eventB color = ' 9c27b0'; // Cả hai biến cố else if sample.eventA color = ' 2196f3'; // Chỉ biến cố A else if sample.eventB color = ' f44336'; // Chỉ biến cố B this.ctx.fillStyle = color; this.ctx.beginPath ; this.ctx.arc sample.x, sample.y, 5, 0, 2 Math.PI ; this.ctx.fill ; // Draw value this.ctx.fillStyle = ' 000'; this.ctx.font = '10px Arial'; this.ctx.textAlign = 'center'; this.ctx.fillText sample.value, sample.x, sample.y - 8 ; ; // Draw legend this.ctx.fillStyle = ' 000'; this.ctx.font = '12px Arial'; this.ctx.textAlign = 'left'; this.ctx.fillText 'Chú thích:', 10, 20 ; this.ctx.fillStyle = ' 2196f3'; this.ctx.beginPath ; this.ctx.arc 20, 35, 4, 0, 2 Math.PI ; this.ctx.fill ; this.ctx.fillStyle = ' 000'; this.ctx.fillText 'Chỉ biến cố A', 30, 38 ; this.ctx.fillStyle = ' f44336'; this.ctx.beginPath ; this.ctx.arc 20, 50, 4, 0, 2 Math.PI ; this.ctx.fill ; this.ctx.fillStyle = ' 000'; this.ctx.fillText 'Chỉ biến cố B', 30, 53 ; this.ctx.fillStyle = ' 9c27b0'; this.ctx.beginPath ; this.ctx.arc 20, 65, 4, 0, 2 Math.PI ; this.ctx.fill ; this.ctx.fillStyle = ' 000'; this.ctx.fillText 'Cả A và B', 30, 68 ; // Conditional Probability Visualization class ConditionalProbDemo constructor this.canvas = document.getElementById 'conditionalCanvas' ; this.ctx = this.canvas.getContext '2d' ; this.width = this.canvas.width; this.height = this.canvas.height; this.probA = 0.4; this.probB = 0.5; this.overlap = 0.2; this.setupControls ; this.draw ; setupControls const probASlider = document.getElementById 'prob-a-slider' ; const probBSlider = document.getElementById 'prob-b-slider' ; const overlapSlider = document.getElementById 'overlap-slider' ; probASlider.addEventListener 'input', e => this.probA = parseFloat e.target.value ; document.getElementById 'prob-a-value' .textContent = this.probA.toFixed 1 ; this.updateCalculations ; this.draw ; ; probBSlider.addEventListener 'input', e => this.probB = parseFloat e.target.value ; document.getElementById 'prob-b-value' .textContent = this.probB.toFixed 1 ; this.updateCalculations ; this.draw ; ; overlapSlider.addEventListener 'input', e => this.overlap = parseFloat e.target.value ; document.getElementById 'overlap-value' .textContent = this.overlap.toFixed 1 ; // Ensure overlap doesn't exceed min probA, probB const maxOverlap = Math.min this.probA, this.probB ; if this.overlap > maxOverlap this.overlap = maxOverlap; overlapSlider.value = this.overlap; document.getElementById 'overlap-value' .textContent = this.overlap.toFixed 1 ; this.updateCalculations ; this.draw ; ; this.updateCalculations ; updateCalculations const probUnion = this.probA + this.probB - this.overlap; const probAGivenB = this.probB > 0 ? this.overlap / this.probB : 0; const probBGivenA = this.probA > 0 ? this.overlap / this.probA : 0; document.getElementById 'display-prob-a' .textContent = this.probA.toFixed 3 ; document.getElementById 'display-prob-b' .textContent = this.probB.toFixed 3 ; document.getElementById 'display-prob-ab' .textContent = this.overlap.toFixed 3 ; document.getElementById 'display-prob-union' .textContent = probUnion.toFixed 3 ; document.getElementById 'display-prob-a-given-b' .textContent = probAGivenB.toFixed 3 ; document.getElementById 'display-prob-b-given-a' .textContent = probBGivenA.toFixed 3 ; draw this.ctx.clearRect 0, 0, this.width, this.height ; // Draw universe rectangle this.ctx.strokeStyle = ' 000'; this.ctx.lineWidth = 2; this.ctx.strokeRect 50, 50, 300, 200 ; this.ctx.fillStyle = ' 000'; this.ctx.font = '14px Arial'; this.ctx.fillText 'Ω Không gian mẫu ', 55, 45 ; // Calculate circle parameters const centerAX = 150; const centerAY = 150; const centerBX = 250; const centerBY = 150; // Calculate radii based on probabilities area proportional to probability const radiusA = Math.sqrt this.probA 10000 / Math.PI ; const radiusB = Math.sqrt this.probB 10000 / Math.PI ; // Draw circle A this.ctx.globalAlpha = 0.3; this.ctx.fillStyle = ' 2196f3'; this.ctx.beginPath ; this.ctx.arc centerAX, centerAY, radiusA, 0, 2 Math.PI ; this.ctx.fill ; // Draw circle B this.ctx.fillStyle = ' f44336'; this.ctx.beginPath ; this.ctx.arc centerBX, centerBY, radiusB, 0, 2 Math.PI ; this.ctx.fill ; // Draw intersection approximate if this.overlap > 0 this.ctx.fillStyle = ' 9c27b0'; const overlapRadius = Math.sqrt this.overlap 5000 / Math.PI ; this.ctx.beginPath ; this.ctx.arc centerAX + centerBX / 2, centerAY + centerBY / 2, overlapRadius, 0, 2 Math.PI ; this.ctx.fill ; this.ctx.globalAlpha = 1.0; // Draw circle outlines this.ctx.strokeStyle = ' 2196f3'; this.ctx.lineWidth = 2; this.ctx.beginPath ; this.ctx.arc centerAX, centerAY, radiusA, 0, 2 Math.PI ; this.ctx.stroke ; this.ctx.strokeStyle = ' f44336'; this.ctx.beginPath ; this.ctx.arc centerBX, centerBY, radiusB, 0, 2 Math.PI ; this.ctx.stroke ; // Labels this.ctx.fillStyle = ' 000'; this.ctx.font = '16px Arial'; this.ctx.fillText 'A', centerAX - 40, centerAY ; this.ctx.fillText 'B', centerBX + 30, centerBY ; if this.overlap > 0 this.ctx.fillText 'A∩B', centerAX + centerBX / 2 - 15, centerAY + centerBY / 2 + 5 ; // MLE Optimization Demo class MLEDemo constructor this.canvas = document.getElementById 'optimizationCanvas' ; this.ctx = this.canvas.getContext '2d' ; this.width = this.canvas.width; this.height = this.canvas.height; this.trueMu = 2.0; this.sampleSize = 20; this.data = ; this.setupControls ; this.draw ; setupControls const trueMuSlider = document.getElementById 'true-mu-slider' ; const sampleSizeSlider = document.getElementById 'sample-size-slider' ; const generateBtn = document.getElementById 'generate-mle-data' ; trueMuSlider.addEventListener 'input', e => this.trueMu = parseFloat e.target.value ; document.getElementById 'true-mu-value' .textContent = this.trueMu.toFixed 1 ; document.getElementById 'display-true-mu' .textContent = this.trueMu.toFixed 3 ; ; sampleSizeSlider.addEventListener 'input', e => this.sampleSize = parseInt e.target.value ; document.getElementById 'sample-size-value' .textContent = this.sampleSize; ; generateBtn.addEventListener 'click', => this.generateDataAndFindMLE ; generateDataAndFindMLE // Generate data from Normal trueMu, 1 this.data = ; for let i = 0; i sum + x, 0 / this.data.length; const error = Math.abs sampleMean - this.trueMu ; // Update display document.getElementById 'sample-mean' .textContent = sampleMean.toFixed 3 ; document.getElementById 'mle-estimate' .textContent = sampleMean.toFixed 3 ; document.getElementById 'mle-error' .textContent = error.toFixed 3 ; this.draw ; draw this.ctx.clearRect 0, 0, this.width, this.height ; if this.data.length === 0 this.ctx.fillStyle = ' 666'; this.ctx.font = '16px Arial'; this.ctx.textAlign = 'center'; this.ctx.fillText 'Nhấp \"Tạo Dữ Liệu & Tìm MLE\" để bắt đầu', this.width / 2, this.height / 2 ; return; // Draw axes this.ctx.strokeStyle = ' ddd'; this.ctx.lineWidth = 1; const marginX = 50; const marginY = 50; const plotWidth = this.width - 2 marginX; const plotHeight = this.height - 2 marginY; // X-axis this.ctx.beginPath ; this.ctx.moveTo marginX, this.height - marginY ; this.ctx.lineTo this.width - marginX, this.height - marginY ; this.ctx.stroke ; // Y-axis this.ctx.beginPath ; this.ctx.moveTo marginX, marginY ; this.ctx.lineTo marginX, this.height - marginY ; this.ctx.stroke ; // Find data range const minX = Math.min ...this.data - 1; const maxX = Math.max ...this.data + 1; // Draw likelihood function this.ctx.strokeStyle = ' 2196f3'; this.ctx.lineWidth = 2; this.ctx.beginPath ; for let i = 0; i sum + x, 0 / this.data.length; const mleX = marginX + sampleMean - minX / maxX - minX plotWidth; this.ctx.strokeStyle = ' f44336'; this.ctx.lineWidth = 2; this.ctx.beginPath ; this.ctx.moveTo mleX, marginY ; this.ctx.lineTo mleX, this.height - marginY ; this.ctx.stroke ; // Mark true value const trueX = marginX + this.trueMu - minX / maxX - minX plotWidth; this.ctx.strokeStyle = ' 4caf50'; this.ctx.lineWidth = 2; this.ctx.setLineDash 5, 5 ; this.ctx.beginPath ; this.ctx.moveTo trueX, marginY ; this.ctx.lineTo trueX, this.height - marginY ; this.ctx.stroke ; this.ctx.setLineDash ; // Draw data points this.ctx.fillStyle = ' 666'; for const x of this.data const pointX = marginX + x - minX / maxX - minX plotWidth; this.ctx.beginPath ; this.ctx.arc pointX, this.height - marginY + 10, 2, 0, 2 Math.PI ; this.ctx.fill ; // Labels this.ctx.fillStyle = ' 000'; this.ctx.font = '12px Arial'; this.ctx.textAlign = 'center'; this.ctx.fillText 'μ', this.width / 2, this.height - 10 ; this.ctx.save ; this.ctx.translate 15, this.height / 2 ; this.ctx.rotate -Math.PI / 2 ; this.ctx.fillText 'Log-Likelihood', 0, 0 ; this.ctx.restore ; // Legend this.ctx.textAlign = 'left'; this.ctx.fillText '— Likelihood', 10, 20 ; this.ctx.fillStyle = ' f44336'; this.ctx.fillText '— MLE', 10, 35 ; this.ctx.fillStyle = ' 4caf50'; this.ctx.fillText '--- μ Thực', 10, 50 ; // Initialize when DOM is loaded document.addEventListener 'DOMContentLoaded', function new SampleSpaceDemo ; new ConditionalProbDemo ; new MLEDemo ; ; input type=\"range\" -webkit-appearance: none; appearance: none; height: 5px; background: ddd; outline: none; border-radius: 5px; input type=\"range\" ::-webkit-slider-thumb -webkit-appearance: none; appearance: none; width: 15px; height: 15px; background: 007bff; cursor: pointer; border-radius: 50%; input type=\"range\" ::-moz-range-thumb width: 15px; height: 15px; background: 007bff; cursor: pointer; border-radius: 50%; border: none; canvas border-radius: 5px; .demo-container margin: 20px 0;",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_04_01_Basic_Probability_Theory/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter00/00_04_02_Common_Probability_Distributions",
    "title": "00-04-02 Các Phân Phối Xác Suất Thông Dụng",
    "chapter": "00",
    "order": 15,
    "owner": "AI Assistant",
    "lesson_type": "required",
    "content": "Các Phân Phối Xác Suất Thông Dụng Hiểu các phân phối xác suất chính là điều thiết yếu cho các bài toán tối ưu hóa trong học máy và thống kê. Các phân phối này thường xuất hiện như giả thuyết trong mô hình, prior trong phương pháp Bayes, và mô hình lỗi trong hồi quy. 1. Phân Phối Rời Rạc Phân Phối Bernoulli Mô hình một thí nghiệm đơn với hai kết quả thành công/thất bại . Tham số : MATH xác suất thành công PMF : MATH với MATH Kỳ vọng : MATH Phương sai : MATH Ứng dụng : Phân loại nhị phân, tung đồng xu, kiểm định A/B Phân Phối Nhị Thức Mô hình số lần thành công trong MATH thí nghiệm Bernoulli độc lập. Tham số : MATH số thí nghiệm , MATH xác suất thành công PMF : MATH với MATH Kỳ vọng : MATH Phương sai : MATH Phân Phối Poisson Mô hình số sự kiện trong một khoảng thời gian cố định khi các sự kiện xảy ra độc lập với tốc độ không đổi. Tham số : MATH tham số tốc độ PMF : MATH với MATH Kỳ vọng : MATH Phương sai : MATH Ứng dụng : Dữ liệu đếm, sự kiện hiếm, lý thuyết hàng đợi Phân Phối Rời Rạc Tương Tác Trực quan hóa: Hàm khối xác suất của các phân phối rời rạc. Loại Phân Phối Bernoulli Nhị Thức Poisson p: 0.5 n: 10 λ: 3.0 Thống Kê: Kỳ vọng: 0.500 Phương sai: 0.250 Mode: 0 hoặc 1 2. Phân Phối Liên Tục Phân Phối Đều Tất cả các giá trị trong một khoảng đều có khả năng xảy ra như nhau. Tham số : MATH với MATH phương sai PDF : MATH Kỳ vọng : MATH Phương sai : MATH Tính chất : - Đối xứng quanh MATH - Quy tắc 68-95-99.7 - Định lý giới hạn trung tâm - Entropy tối đa với kỳ vọng và phương sai cho trước Phân Phối Mũ Mô hình thời gian chờ giữa các sự kiện trong quá trình Poisson. Tham số : MATH tham số tốc độ PDF : MATH với MATH Kỳ vọng : MATH Phương sai : MATH Tính chất : Tính chất không nhớ Phân Phối Beta Phân phối linh hoạt trên MATH , thường dùng để mô hình hóa xác suất. Tham số : MATH tham số hình dạng PDF : MATH với MATH Kỳ vọng : MATH Phương sai : MATH Phân Phối Liên Tục Tương Tác Trực quan hóa: Hàm mật độ xác suất của các phân phối liên tục. Loại Phân Phối Đều Chuẩn Mũ Beta a: 0 b: 1 μ: 0 σ: 1.0 λ: 1.0 α: 2 β: 2 Thống Kê: Kỳ vọng: 0.500 Phương sai: 0.083 Miền xác định: 0, 1 3. Phân Phối Đa Biến Phân Phối Chuẩn Đa Biến Mở rộng của phân phối chuẩn cho nhiều chiều. Tham số : MATH vector kỳ vọng , MATH ma trận hiệp phương sai, xác định dương PDF : MATH Tính chất : - Phân phối biên là chuẩn - Tổ hợp tuyến tính là chuẩn - Phân phối có điều kiện là chuẩn Phân Phối Chuẩn Đa Biến Trực Quan 2D: Đồ thị đường đồng mức của phân phối chuẩn hai biến. Các mẫu hiển thị dưới dạng chấm. Tham Số μ₁: 0.0 μ₂: 0.0 σ₁: 1.0 σ₂: 1.0 ρ tương quan : 0.0 Tạo Mẫu Ma Trận Hiệp Phương Sai: Σ₁₁: 1.000 Σ₁₂: 0.000 Σ₂₂: 1.000 Det Σ : 1.000 4. Ứng Dụng trong Tối Ưu Hóa Ước Lượng Hợp Lý Tối Đa Nhiều bài toán tối ưu hóa liên quan đến việc tìm tham số để tối đa hóa likelihood của dữ liệu quan sát dưới một phân phối cụ thể: MATH Tối Ưu Hóa Bayes Phân phối prior mã hóa niềm tin về tham số trước khi thấy dữ liệu: MATH Regularization Phân phối có thể được sử dụng như prior để regularize bài toán tối ưu hóa: - L2 regularization ↔ Prior Gaussian - L1 regularization ↔ Prior Laplace Tối Ưu Hóa Ngẫu Nhiên Phân phối mô hình nhiễu và sự bất định trong hàm mục tiêu và ràng buộc. Những Hiểu Biết Quan Trọng cho Tối Ưu Hóa 1. Lựa Chọn Mô Hình : Chọn phân phối phù hợp với đặc điểm dữ liệu của bạn 2. Ước Lượng Tham Số : Sử dụng MLE hoặc phương pháp Bayes để ước lượng tham số phân phối 3. Định Lượng Sự Bất Định : Phân phối cung cấp cách tự nhiên để định lượng sự bất định 4. Regularization : Phân phối prior có thể ngăn overfitting 5. Hiệu Quả Tính Toán : Một số phân phối có nghiệm dạng đóng cho các phép toán thông dụng Hiểu các phân phối này và tính chất của chúng là quan trọng để xây dựng và giải quyết các bài toán tối ưu hóa trong học máy, thống kê và các ứng dụng kỹ thuật. // Discrete Distributions Demo class DiscreteDistributionsDemo constructor this.canvas = document.getElementById 'discreteCanvas' ; this.ctx = this.canvas.getContext '2d' ; this.width = this.canvas.width; this.height = this.canvas.height; this.distType = 'bernoulli'; this.params = p: 0.5, n: 10, lambda: 3.0 ; this.setupControls ; this.draw ; setupControls const radios = document.querySelectorAll 'input name=\"discrete-dist\" ' ; const pSlider = document.getElementById 'p-slider' ; const nSlider = document.getElementById 'n-slider' ; const lambdaSlider = document.getElementById 'lambda-slider' ; radios.forEach radio => radio.addEventListener 'change', e => this.distType = e.target.value; this.updateParameterVisibility ; this.updateStats ; this.draw ; ; ; pSlider.addEventListener 'input', e => this.params.p = parseFloat e.target.value ; document.getElementById 'p-value' .textContent = this.params.p.toFixed 1 ; this.updateStats ; this.draw ; ; nSlider.addEventListener 'input', e => this.params.n = parseInt e.target.value ; document.getElementById 'n-value' .textContent = this.params.n; this.updateStats ; this.draw ; ; lambdaSlider.addEventListener 'input', e => this.params.lambda = parseFloat e.target.value ; document.getElementById 'lambda-value' .textContent = this.params.lambda.toFixed 1 ; this.updateStats ; this.draw ; ; this.updateParameterVisibility ; this.updateStats ; updateParameterVisibility document.getElementById 'p-param' .style.display = this.distType === 'bernoulli' || this.distType === 'binomial' ? 'block' : 'none'; document.getElementById 'n-param' .style.display = this.distType === 'binomial' ? 'block' : 'none'; document.getElementById 'lambda-param' .style.display = this.distType === 'poisson' ? 'block' : 'none'; updateStats let mean, variance, mode; switch this.distType case 'bernoulli': mean = this.params.p; variance = this.params.p 1 - this.params.p ; mode = this.params.p > 0.5 ? '1' : this.params.p n return 0; return this.factorial n / this.factorial k this.factorial n - k ; getProbability k switch this.distType case 'bernoulli': return k === 0 ? 1 - this.params.p : k === 1 ? this.params.p : 0 ; case 'binomial': if k this.params.n return 0; return this.binomialCoeff this.params.n, k Math.pow this.params.p, k Math.pow 1 - this.params.p, this.params.n - k ; case 'poisson': if k radio.addEventListener 'change', e => this.distType = e.target.value; this.updateParameterVisibility ; this.updateStats ; this.draw ; ; ; // Setup all sliders const sliders = 'a', 'b', 'mu', 'sigma', 'exp-lambda', 'alpha', 'beta' ; sliders.forEach slider => const element = document.getElementById slider + '-slider' ; if element element.addEventListener 'input', e => const value = parseFloat e.target.value ; const param = slider === 'exp-lambda' ? 'lambda' : slider; this.params param = value; const valueSpan = document.getElementById slider + '-value' ; if valueSpan valueSpan.textContent = value.toFixed 1 ; this.updateStats ; this.draw ; ; ; this.updateParameterVisibility ; this.updateStats ; updateParameterVisibility document.getElementById 'uniform-params' .style.display = this.distType === 'uniform' ? 'block' : 'none'; document.getElementById 'normal-params' .style.display = this.distType === 'normal' ? 'block' : 'none'; document.getElementById 'exponential-params' .style.display = this.distType === 'exponential' ? 'block' : 'none'; document.getElementById 'beta-params' .style.display = this.distType === 'beta' ? 'block' : 'none'; updateStats let mean, variance, support; switch this.distType case 'uniform': mean = this.params.a + this.params.b / 2; variance = Math.pow this.params.b - this.params.a, 2 / 12; support = MATH this.params.b ; break; case 'normal': mean = this.params.mu; variance = this.params.sigma this.params.sigma; support = ' -∞, ∞ '; break; case 'exponential': mean = 1 / this.params.lambda; variance = 1 / this.params.lambda this.params.lambda ; support = ' 0, ∞ '; break; case 'beta': mean = this.params.alpha / this.params.alpha + this.params.beta ; variance = this.params.alpha this.params.beta / Math.pow this.params.alpha + this.params.beta, 2 this.params.alpha + this.params.beta + 1 ; support = ' 0, 1 '; break; document.getElementById 'continuous-mean' .textContent = mean.toFixed 3 ; document.getElementById 'continuous-variance' .textContent = variance.toFixed 3 ; document.getElementById 'continuous-support' .textContent = support; gamma z // Stirling's approximation for gamma function if z = this.params.a && x = 0 ? this.params.lambda Math.exp -this.params.lambda x : 0; case 'beta': if x 1 return 0; const B = this.gamma this.params.alpha this.gamma this.params.beta / this.gamma this.params.alpha + this.params.beta ; return Math.pow x, this.params.alpha - 1 Math.pow 1 - x, this.params.beta - 1 / B; getRange switch this.distType case 'uniform': return this.params.a - 0.5, this.params.b + 0.5 ; case 'normal': return this.params.mu - 4 this.params.sigma, this.params.mu + 4 this.params.sigma ; case 'exponential': return 0, 5 / this.params.lambda ; case 'beta': return 0, 1 ; draw this.ctx.clearRect 0, 0, this.width, this.height ; const marginX = 50; const marginY = 50; const plotWidth = this.width - 2 marginX; const plotHeight = this.height - 2 marginY; // Draw axes this.ctx.strokeStyle = ' ddd'; this.ctx.lineWidth = 1; this.ctx.beginPath ; this.ctx.moveTo marginX, this.height - marginY ; this.ctx.lineTo this.width - marginX, this.height - marginY ; this.ctx.moveTo marginX, marginY ; this.ctx.lineTo marginX, this.height - marginY ; this.ctx.stroke ; const minX, maxX = this.getRange ; // Find max PDF for scaling let maxPDF = 0; for let i = 0; i const element = document.getElementById slider + '-slider' ; element.addEventListener 'input', e => this.params slider = parseFloat e.target.value ; document.getElementById slider + '-value' .textContent = this.params slider .toFixed 1 ; this.updateStats ; this.draw ; ; ; document.getElementById 'generate-samples' .addEventListener 'click', => this.generateSamples ; this.draw ; ; this.updateStats ; updateStats const cov11 = this.params.sigma1 this.params.sigma1; const cov12 = this.params.rho this.params.sigma1 this.params.sigma2; const cov22 = this.params.sigma2 this.params.sigma2; const det = cov11 cov22 - cov12 cov12; document.getElementById 'cov11' .textContent = cov11.toFixed 3 ; document.getElementById 'cov12' .textContent = cov12.toFixed 3 ; document.getElementById 'cov22' .textContent = cov22.toFixed 3 ; document.getElementById 'det-cov' .textContent = det.toFixed 3 ; generateSamples this.samples = ; const n = 100; for let i = 0; i this.ctx.strokeStyle = colors idx ; this.ctx.lineWidth = 1; this.ctx.beginPath ; const a = level this.params.sigma1; const b = level this.params.sigma2; const angle = 0.5 Math.atan2 2 this.params.rho this.params.sigma1 this.params.sigma2, this.params.sigma1 this.params.sigma1 - this.params.sigma2 this.params.sigma2 ; for let i = 0; i 0 this.ctx.fillStyle = ' 2196f3'; this.samples.forEach x1, x2 => const plotX = marginX + x1 + 4 / 8 plotWidth; const plotY = this.height - marginY - x2 + 4 / 8 plotHeight; if plotX >= marginX && plotX = marginY && plotY input type=\"range\" -webkit-appearance: none; appearance: none; height: 5px; background: ddd; outline: none; border-radius: 5px; input type=\"range\" ::-webkit-slider-thumb -webkit-appearance: none; appearance: none; width: 15px; height: 15px; background: 007bff; cursor: pointer; border-radius: 50%; input type=\"range\" ::-moz-range-thumb width: 15px; height: 15px; background: 007bff; cursor: pointer; border-radius: 50%; border: none; canvas border-radius: 5px; .demo-container margin: 20px 0;",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter00/00_04_02_Common_Probability_Distributions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter01/01_00_Introduction",
    "title": "01 Giới thiệu",
    "chapter": "01",
    "order": 1,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Giới thiệu về các Bài toán Tối ưu hóa Toán học—đặc biệt là các Bài toán Tối ưu hóa Lồi.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter01/01_00_Introduction/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter01/01_01_optimization_problems",
    "title": "01-01 Bài toán tối ưu hóa?",
    "chapter": "01",
    "order": 2,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Bài toán tối ưu hóa là bài toán trong đó, trong số nhiều ứng viên có thể, chúng ta tìm kiếm nghiệm tối ưu giá trị tối ưu hoặc một giá trị gần với tối ưu. Trong khoa học dữ liệu và học máy , tối ưu hóa có mặt ở khắp mọi nơi: - Huấn luyện mạng nơ-ron : Tìm kiếm trọng số để giảm thiểu lỗi dự đoán - Hồi quy tuyến tính : Tìm đường thẳng khớp nhất để giảm thiểu bình phương sai số - Phân cụm : Tối ưu hóa tâm cụm để giảm thiểu phương sai trong cụm - Lựa chọn đặc trưng : Chọn tập con đặc trưng tốt nhất để tối đa hóa hiệu suất mô hình - Điều chỉnh siêu tham số : Tìm tỷ lệ học tối ưu, tham số chính quy, v.v. Mỗi khi bạn huấn luyện một mô hình học máy, bạn đang giải một bài toán tối ưu hóa! Bài toán tối ưu hóa toán học Một bài toán tối ưu hóa toán học có thể được biểu diễn như sau: > MATH \\begin align >&\\min x\\in D \\ && f x \\\\ >&\\text với điều kiện && g i x \\le 0,\\ i = 1, ..., m \\\\ >&&& h j x = 0,\\ j = 1,\\ ..., r >\\end align MATH Bài toán Tối ưu hóa Toán học ở dạng chuẩn MATH là biến tối ưu hóa MATH là hàm mục tiêu hoặc hàm chi phí MATH là các hàm ràng buộc bất đẳng thức MATH là các hàm ràng buộc đẳng thức Vector MATH mà tối thiểu hóa hàm mục tiêu MATH trên miền khả thi tập hợp tất cả các điểm thỏa mãn các ràng buộc được ký hiệu là MATH và được gọi là nghiệm tối ưu. Các ràng buộc có thể được phân loại thành hai loại: 1. Ràng buộc tường minh: Các ràng buộc được chỉ định trực tiếp trong bài toán tối ưu hóa. Trong dạng chuẩn ở trên, các ràng buộc được biểu diễn bởi các hàm MATH và MATH là tường minh. Nếu không có ràng buộc tường minh, bài toán được gọi là bài toán không ràng buộc. 2. Ràng buộc ngầm: Các ràng buộc không được chỉ định trực tiếp, nhưng phát sinh từ giao của các miền của hàm mục tiêu và các hàm ràng buộc. MATH Ghi chú: MATH có nghĩa là miền của hàm MATH . > Ví dụ: ràng buộc ngầm ↔ ràng buộc tường minh > >Giả sử bài toán tối ưu hóa được cho như sau: > > MATH > >Ở đây, miền của hàm mục tiêu MATH là MATH , nên MATH là một ràng buộc ngầm. Nếu chúng ta viết điều này dưới dạng bài toán tối ưu hóa với ràng buộc tường minh: > > MATH > 💡 Mẹo chuyên nghiệp : Bắt đầu với các công thức lồi khi có thể - chúng dễ giải và hiểu hơn. Chỉ chuyển sang các mô hình phi lồi phức tạp khi các phương pháp đơn giản hơn không đáp ứng được yêu cầu của bạn.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter01/01_01_optimization_problems/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter01/01_02_convex_optimization_problem",
    "title": "01-02 Bài toán tối ưu hóa lồi",
    "chapter": "01",
    "order": 3,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Bài toán tối ưu hóa lồi là một loại bài toán tối ưu hóa. > MATH \\begin align >&\\min x\\in D \\ &&f x \\\\ >&\\text với điều kiện && g i x \\le 0,\\ i = 1, ..., m \\\\ >&&& h j x = 0,\\ j = 1,\\ ..., r >\\end align MATH Bài toán Tối ưu hóa Lồi ở dạng chuẩn 3 Ở đây, hàm mục tiêu MATH và các hàm ràng buộc bất đẳng thức MATH là lồi, và các hàm ràng buộc đẳng thức MATH là affine. Một hàm affine là một hàm tuyến tính cộng với một hằng số: > MATH là affine: MATH Điều gì có nghĩa là một hàm lồi? Để hiểu điều này, trước tiên chúng ta cần hiểu tập lồi. Tập lồi Một đoạn thẳng nối hai điểm MATH và MATH được định nghĩa là: > MATH với MATH Cho một tập hợp, nếu đoạn thẳng giữa bất kỳ hai điểm MATH và MATH nào trong tập cũng được chứa trong tập đó, chúng ta gọi nó là tập lồi. Nói cách khác, một tập MATH là lồi nếu: > MATH , MATH MATH MATH Ví dụ, trong hình dưới đây, chỉ có hình bên trái nhất là tập lồi. Hình1 trái: tập lồi, giữa & phải: tập không lồi 2 Hàm lồi Một hàm lồi được định nghĩa như sau: > MATH là lồi nếu MATH là tập lồi và, > > MATH với mọi MATH Về mặt hình học, điều này có nghĩa là với bất kỳ hai điểm MATH và MATH nào trên đồ thị của MATH , đoạn thẳng nối chúng nằm phía trên đồ thị giữa MATH và MATH . Hình2 Hàm Lồi 2 Mối quan hệ giữa tập lồi và hàm lồi Có một mối quan hệ chặt chẽ giữa hàm lồi và tập lồi: > Một hàm MATH là lồi khi và chỉ khi epigraph của nó là tập lồi. Epigraph là gì? 'Epi' có nghĩa là 'phía trên', vì vậy epigraph của MATH là tập hợp các điểm phía trên đồ thị của MATH . Chính thức, epigraph được định nghĩa là: > MATH \\eqalign & \\text epigraph của f: \\mathbb R ^n \\rightarrow \\mathbb R \\\\ & \\text epi f = \\ x, t \\in \\mathbb R ^ n+1 \\mid x \\in \\text dom f, f x \\le t\\ MATH Hình3 Epigraph 2 Nếu MATH là hàm lồi, thì MATH luôn là tập lồi, và ngược lại. Đây là tính chất quan trọng kết nối định nghĩa của hàm lồi và tập lồi. Hàm lồi và hàm lõm Một hàm MATH là lõm nếu MATH là lồi. Tương đương, MATH là lõm nếu: > MATH với mọi MATH Về mặt hình học, điều này có nghĩa là đoạn thẳng nối bất kỳ hai điểm nào trên đồ thị nằm dưới đồ thị của hàm số. Một hàm lõm \"cong xuống\" trong khi hàm lồi \"cong lên\". Còn về hàm lõm thì sao? Tại sao chúng ta nhấn mạnh hàm lồi nhiều đến vậy, và dường như \"bỏ qua\" hàm lõm? - Chúng ta \"không quan tâm\" đến hàm lõm riêng biệt vì chúng chỉ là hình ảnh phản chiếu của hàm lồi. Luôn chuyển đổi việc tối đa hóa hàm lõm MATH thành tối thiểu hóa hàm lồi MATH . Tính chất tốt của bài toán tối ưu hóa lồi Một điểm cực tiểu địa phương của hàm lồi luôn là cực tiểu toàn cục. Đối với bài toán tối ưu hóa lồi, nghiệm thường dễ tìm hơn so với bài toán không lồi, vì hàm lồi có tính chất sau: > Nếu MATH là lồi và MATH là điểm tối ưu địa phương tức là cực tiểu địa phương , thì MATH cũng là điểm tối ưu toàn cục. Hãy chứng minh điều này bằng phản chứng: > Chứng minh bằng phản chứng: > >Giả sử với hàm lồi MATH , MATH là điểm tối ưu địa phương nhưng không phải tối ưu toàn cục. Gọi MATH là điểm tối ưu toàn cục khả thi, nên với mọi MATH dương, MATH và MATH \\theta=\\frac \\rho 2\\|y-x\\| 2 MATH z = \\theta y + 1 - \\theta x = x + \\theta y - x MATH . Khi đó: > >1. MATH là tổ hợp lồi của hai điểm khả thi MATH , nên nó cũng khả thi. > >2. MATH \\|z - x\\| 2 = \\theta \\|y - x\\| 2 = \\frac \\rho 2 >3. MATH f z \\le \\theta f y + 1 - \\theta f x >Điểm 2 và 3 mâu thuẫn với giả thiết rằng MATH là điểm tối ưu địa phương, nên bằng phản chứng, bất kỳ điểm tối ưu địa phương MATH nào cũng là tối ưu toàn cục. Tổ hợp lồi Tổ hợp lồi của MATH được định nghĩa là: > MATH với MATH Nếu MATH là tập lồi và MATH , thì MATH cũng vậy.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter01/01_02_convex_optimization_problem/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter01/01_03_goals_and_topics",
    "title": "01-03 Mục tiêu và Chủ đề",
    "chapter": "01",
    "order": 4,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Mục tiêu Mục tiêu của khóa học này là phát triển các khả năng sau: Nhận biết khi nào một bài toán cho trước là bài toán tối ưu hóa lồi Xây dựng một tình huống cho trước thành bài toán tối ưu hóa lồi Lựa chọn thuật toán phù hợp nhất để giải một bài toán tối ưu hóa lồi đã định nghĩa Chủ đề Để đạt được những mục tiêu này, các chủ đề sau sẽ được đề cập: Tập lồi, hàm số, bài toán tối ưu hóa Ví dụ và ứng dụng Thuật toán Đặc biệt, trọng tâm chính sẽ là thuật toán. Thuật toán Có nhiều phương pháp khác nhau để giải bài toán tối ưu hóa. Hiệu suất của mỗi phương pháp phụ thuộc vào tính chất của bài toán được giải. Để chọn thuật toán hiệu quả nhất, cần có hiểu biết sâu sắc về cả bài toán và thuật toán. Hãy xem một ví dụ: khử nhiễu total variation. Ví dụ: Khử nhiễu Total variation Hình1 Khử nhiễu Total Variation 3 Giả sử bạn nhận được một hình ảnh nhiễu giữa , và bạn muốn loại bỏ nhiễu để có được nghiệm phải gần với hình ảnh thật trái . Nếu mỗi giá trị pixel là MATH , bài toán này có thể được xây dựng thành bài toán tối ưu hóa sau, thường được gọi là bài toán 2D fused lasso hoặc khử nhiễu 2D total variation: > MATH E: tập hợp các cạnh giữa tất cả các MATH lân cận MATH : Mất mát bình phương tối thiểu. Buộc MATH gần với MATH MATH : Làm mịn total variation. Được sử dụng khi sự thay đổi giữa các pixel lân cận không lớn từng phần hằng số . Việc chọn phương pháp làm mịn phù hợp đòi hỏi xem xét cẩn thận đặc điểm của bài toán. Để biết thêm chi tiết về làm mịn total variation, xem Chương 6.1.2 và 6.3 trong Tài liệu tham khảo 1. Bài toán tối ưu hóa lồi ở trên có thể được giải bằng thuật toán Specialized ADMM http://stanford.edu/~boyd/admm.html , mang lại nghiệm bên phải sau 20 lần lặp. Specialized ADMM, 20 lần lặp Hình2 Kết quả Specialized ADMM 3 Proximal gradient descent, 1000 lần lặp Hình3 Kết quả Proximal Gradient Descent 3 Coordinate descent, 10K chu kỳ Hình4 Kết quả Coordinate Descent 3 Như được chỉ ra ở trên, đối với bài toán 2D fused lasso, Specialized ADMM hoạt động tốt nhất trong ba phương pháp. Tuy nhiên, đối với các bài toán khác, hai phương pháp còn lại có thể vượt trội hơn Specialized ADMM. Trong các chương sau, chúng ta sẽ phân tích các thuật toán và bài toán khác nhau để học cách lựa chọn thuật toán phù hợp nhất.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter01/01_03_goals_and_topics/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter01/01_04_brief_history_of_convex_optimization",
    "title": "01-04 Lịch sử ngắn gọn về tối ưu hóa lồi",
    "chapter": "01",
    "order": 5,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Lịch sử phát triển của Tối ưu hóa Lồi Tối ưu hóa lồi có một lịch sử phát triển phong phú, từ những nền tảng lý thuyết đầu tiên đến các ứng dụng hiện đại trong công nghệ và khoa học. Hãy cùng khám phá hành trình này qua các giai đoạn quan trọng. 🎯 Tổng quan Timeline 1900-1970 Phát triển nền tảng lý thuyết 1947-1990 Các thuật toán đột phá 1990-nay Bùng nổ ứng dụng 📚 Giai đoạn 1: Nền tảng Lý thuyết 1900-1970 Những người tiên phong Hermann Minkowski 1864-1909 - Đặt nền móng cho hình học lồi với khái niệm \"tập lồi\" - Phát triển lý thuyết về các đa diện lồi - Ảnh hưởng: Tạo ra ngôn ngữ toán học cơ bản cho tối ưu hóa lồi Leonid Kantorovich 1912-1986 - Phát triển lý thuyết lập trình tuyến tính vào những năm 1930 - Giải quyết bài toán phân bổ tài nguyên tối ưu - Đóng góp: Chứng minh tính khả thi của việc tối ưu hóa trong kinh tế John von Neumann 1903-1957 - Phát triển lý thuyết trò chơi và mối liên hệ với tối ưu hóa - Đưa ra định lý minimax cơ bản - Ảnh hưởng: Kết nối tối ưu hóa với lý thuyết quyết định Các khái niệm nền tảng được hình thành: - Tập lồi và hàm lồi : Định nghĩa chính xác và tính chất cơ bản - Điều kiện tối ưu : Phát triển các điều kiện cần và đủ - Duality theory : Khái niệm về bài toán đối ngẫu ⚙️ Giai đoạn 2: Cách mạng Thuật toán 1947-1990 1947: Thuật toán Simplex - Bước ngoặt lịch sử George Dantzig đã tạo ra cuộc cách mạng với thuật toán Simplex: Ý tưởng cốt lõi: Di chuyển dọc theo các cạnh của đa diện khả thi để tìm điểm tối ưu tại một đỉnh. Tại sao quan trọng? - Lần đầu tiên có thuật toán thực tế để giải bài toán lập trình tuyến tính - Mở ra khả năng ứng dụng trong logistics, sản xuất, quân sự - Hiệu quả cao trong thực tế dù có độ phức tạp tệ nhất là exponential 1960s: Phương pháp Điểm trong đầu tiên Fiacco & McCormick phát triển: - Barrier methods cho bài toán có ràng buộc bất đẳng thức - Ý tưởng: Thêm hàm penalty để \"đẩy\" nghiệm vào bên trong miền khả thi Dikin đóng góp: - Affine scaling method - Cải thiện hướng tiếp cận của barrier methods 1970s: Phương pháp Ellipsoid và Subgradient Shor, Nemirovski, Yudin phát triển: - Ellipsoid method : Thuật toán đa thức đầu tiên cho LP - Subgradient methods : Xử lý hàm không khả vi Ý nghĩa lý thuyết: - Chứng minh LP thuộc lớp P polynomial time - Mở rộng khả năng giải các bài toán không trơn 1984: Đột phá của Karmarkar Narendra Karmarkar tạo ra cuộc cách mạng thứ hai: - Thuật toán interior-point với độ phức tạp \\\\ O n^ 3.5 L \\\\ - Hiệu quả thực tế cao hơn simplex cho bài toán lớn - Khởi đầu cho kỷ nguyên interior-point methods Late 1980s-1990s: Tổng quát hóa Nesterov & Nemirovski 1994 mở rộng: - Interior-point methods cho tối ưu lồi phi tuyến - Self-concordant functions - Polynomial-time algorithms cho broader class 🚀 Giai đoạn 3: Bùng nổ Ứng dụng 1990-nay Trước 1990: Giới hạn trong Operations Research Các ứng dụng chính: - Transportation problems : Tối ưu hóa vận chuyển hàng hóa - Production planning : Lập kế hoạch sản xuất - Resource allocation : Phân bổ tài nguyên trong doanh nghiệp - Military logistics : Ứng dụng trong quân sự WWII và Cold War Tại sao giới hạn? - Máy tính chưa đủ mạnh - Thiếu software tools - Chưa nhận thức được tiềm năng trong engineering Từ 1990: Cách mạng Ứng dụng 🎛️ Control Systems Hệ thống Điều khiển - Model Predictive Control MPC : Điều khiển dự báo - Robust control : Điều khiển bền vững - Ví dụ : Điều khiển nhiệt độ trong nhà máy, autopilot máy bay 📡 Signal Processing Xử lý Tín hiệu - Compressed sensing : Khôi phục tín hiệu từ ít mẫu - Image denoising : Khử nhiễu ảnh - Ví dụ : MRI imaging, radar processing 📱 Communications Truyền thông - Beamforming : Định hướng sóng trong antenna arrays - Power allocation : Phân bổ công suất trong mạng wireless - Ví dụ : 5G networks, satellite communications 💻 Circuit Design Thiết kế Mạch - Gate sizing : Tối ưu kích thước transistor - Power optimization : Tối ưu tiêu thụ năng lượng - Ví dụ : CPU design, mobile chip optimization 🆕 Các lớp bài toán mới Semidefinite Programming SDP Tối ưu hóa trên ma trận bán xác định dương Ứng dụng: Relaxation của bài toán combinatorial Second-Order Cone Programming SOCP Tối ưu hóa với ràng buộc hình nón bậc hai Ứng dụng: Robust optimization, portfolio optimization Robust Optimization Tối ưu hóa với uncertainty trong dữ liệu Ứng dụng: Finance, supply chain management 🔮 Xu hướng Hiện tại và Tương lai Machine Learning Integration - Convex relaxations của neural networks - Optimization trong training : Adam, RMSprop - Regularization : L1, L2 penalties Big Data Applications - Distributed optimization : Xử lý dữ liệu lớn - Online algorithms : Học trực tuyến - Streaming optimization : Tối ưu real-time Quantum Computing - Quantum convex optimization : Thuật toán lượng tử - Variational quantum algorithms : QAOA, VQE 💡 Bài học từ Lịch sử 1. Lý thuyết dẫn đường cho thực hành : Nền tảng toán học vững chắc là cần thiết 2. Công nghệ thúc đẩy ứng dụng : Máy tính mạnh mở ra khả năng mới 3. Interdisciplinary collaboration : Sự kết hợp giữa các lĩnh vực tạo ra đột phá 4. Practical needs drive innovation : Nhu cầu thực tế thúc đẩy phát triển thuật toán --- 🎯 Takeaway chính Tối ưu hóa lồi đã phát triển từ một lĩnh vực toán học thuần túy thành công cụ không thể thiếu trong công nghệ hiện đại. Sự kết hợp giữa lý thuyết vững chắc và thuật toán hiệu quả đã tạo ra những ứng dụng đột phá trong mọi lĩnh vực của cuộc sống. 🎮 Khám phá Tương tác Simplex Algorithm Visualization Minh họa Thuật toán Simplex Thử nghiệm với bài toán lập trình tuyến tính đơn giản: Bài toán: Maximize \\\\ c 1x 1 + c 2x 2\\\\ Subject to: \\\\ x 1, x 2 \\geq 0\\\\ và các ràng buộc tuyến tính c₁: 3 c₂: 2 Chạy Simplex Reset Timeline Explorer Khám phá Timeline Tương tác Năm: 1947 1947: Thuật toán Simplex George Dantzig phát triển thuật toán Simplex, mở đầu kỷ nguyên tối ưu hóa thực tế. Tác động: Cách mạng trong operations research Ứng dụng Hiện đại Ứng dụng trong Cuộc sống Portfolio Optimization Supply Chain Machine Learning Signal Processing 📈 Portfolio Optimization Bài toán: Phân bổ vốn đầu tư để tối đa hóa lợi nhuận và giảm thiểu rủi ro Công thức: \\\\ \\min \\frac 1 2 w^T\\Sigma w - \\mu^T w\\\\ Ứng dụng: Quỹ đầu tư, ngân hàng, bảo hiểm // Simplex Algorithm Demo function runSimplex const canvas = document.getElementById 'simplex-canvas' ; const ctx = canvas.getContext '2d' ; const c1 = parseFloat document.getElementById 'c1' .value ; const c2 = parseFloat document.getElementById 'c2' .value ; // Clear canvas ctx.clearRect 0, 0, canvas.width, canvas.height ; // Draw feasible region simple example ctx.fillStyle = 'rgba 0, 122, 204, 0.2 '; ctx.beginPath ; ctx.moveTo 50, 250 ; ctx.lineTo 200, 250 ; ctx.lineTo 200, 100 ; ctx.lineTo 100, 50 ; ctx.lineTo 50, 100 ; ctx.closePath ; ctx.fill ; // Draw objective function direction ctx.strokeStyle = ' ff6b35'; ctx.lineWidth = 3; ctx.beginPath ; ctx.moveTo 125, 175 ; ctx.lineTo 125 + c1 20, 175 - c2 20 ; ctx.stroke ; // Add labels ctx.fillStyle = ' 333'; ctx.font = '14px Arial'; ctx.fillText 'Feasible Region', 60, 200 ; ctx.fillText Objective: MATH c2.toFixed 1 x₂ , 220, 50 ; // Show steps document.getElementById 'simplex-steps' .innerHTML = Các bước Simplex: Bắt đầu tại đỉnh 0,0 Kiểm tra hướng cải thiện: MATH c2.toFixed 1 Di chuyển dọc theo cạnh có gradient tốt nhất Dừng khi không thể cải thiện thêm ; function resetDemo document.getElementById 'c1' .value = 3; document.getElementById 'c2' .value = 2; document.getElementById 'c1-value' .textContent = '3'; document.getElementById 'c2-value' .textContent = '2'; document.getElementById 'simplex-steps' .innerHTML = ''; const canvas = document.getElementById 'simplex-canvas' ; const ctx = canvas.getContext '2d' ; ctx.clearRect 0, 0, canvas.width, canvas.height ; // Timeline Explorer const timelineEvents = 1900: title: \"1900: Nền tảng Hình học\", desc: \"Minkowski phát triển lý thuyết tập lồi\", impact: \"Tạo nền tảng toán học\" , 1930: title: \"1930: Kantorovich\", desc: \"Lý thuyết lập trình tuyến tính đầu tiên\", impact: \"Ứng dụng trong kinh tế\" , 1947: title: \"1947: Thuật toán Simplex\", desc: \"Dantzig tạo ra thuật toán thực tế đầu tiên\", impact: \"Cách mạng operations research\" , 1960: title: \"1960s: Interior Point\", desc: \"Fiacco & McCormick phát triển barrier methods\", impact: \"Mở rộng khả năng giải bài toán\" , 1984: title: \"1984: Karmarkar\", desc: \"Interior-point polynomial-time algorithm\", impact: \"Đột phá về độ phức tạp\" , 1994: title: \"1994: Nesterov & Nemirovski\", desc: \"Tổng quát hóa cho convex optimization\", impact: \"Nền tảng cho ứng dụng hiện đại\" , 2010: title: \"2010s: Machine Learning\", desc: \"Tích hợp với AI và Big Data\", impact: \"Ứng dụng rộng rãi trong công nghệ\" , 2024: title: \"2024: Quantum Computing\", desc: \"Thuật toán tối ưu lượng tử\", impact: \"Tương lai của tính toán\" ; function updateTimeline const year = parseInt document.getElementById 'year-slider' .value ; document.getElementById 'current-year' .textContent = year; // Find closest event let closestYear = 1900; for let eventYear in timelineEvents if parseInt eventYear $ app.title Bài toán: $ app.problem Công thức: \\\\ $ app.formula \\\\ Ứng dụng: $ app.usage ; // Re-render MathJax if window.MathJax MathJax.typesetPromise document.getElementById 'app-content' ; // Event listeners document.addEventListener 'DOMContentLoaded', function // Slider updates document.getElementById 'c1' .addEventListener 'input', function document.getElementById 'c1-value' .textContent = this.value; ; document.getElementById 'c2' .addEventListener 'input', function document.getElementById 'c2-value' .textContent = this.value; ; document.getElementById 'year-slider' .addEventListener 'input', updateTimeline ; // Initialize updateTimeline ; showApplication 'portfolio' ; ; .timeline-container position: relative; margin: 20px 0; .timeline-item display: flex; margin: 10px 0; padding: 10px; border-left: 3px solid 007acc; background: f8f9fa; .timeline-year font-weight: bold; color: 007acc; min-width: 100px; .timeline-content margin-left: 20px; .info-box background: e3f2fd; border: 1px solid 2196f3; border-radius: 5px; padding: 15px; margin: 20px 0; .info-box h4 margin-top: 0; color: 1976d2; / Interactive Demo Styles / simplex-demo, timeline-explorer, applications-demo background: f8f9fa; border: 1px solid dee2e6; border-radius: 8px; padding: 20px; margin: 20px 0; .controls margin: 15px 0; .controls label display: inline-block; margin: 5px 10px 5px 0; min-width: 40px; .controls input type=\"range\" width: 150px; margin: 0 10px; .controls button background: 007acc; color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; margin: 5px; .controls button:hover background: 005a9e; simplex-canvas border: 1px solid ccc; margin: 10px 0; background: white; .year-slider margin: 15px 0; .year-slider input type=\"range\" width: 300px; year-info background: white; padding: 15px; border-radius: 5px; border-left: 4px solid 007acc; .app-selector margin: 15px 0; .app-btn background: 28a745; color: white; border: none; padding: 10px 15px; border-radius: 5px; cursor: pointer; margin: 5px; font-size: 14px; .app-btn:hover background: 218838; .app-example background: white; padding: 15px; border-radius: 5px; border-left: 4px solid 28a745; margin-top: 15px; .problem-setup background: white; padding: 15px; border-radius: 5px; margin: 10px 0; simplex-steps background: white; padding: 15px; border-radius: 5px; margin-top: 10px; simplex-steps ol margin: 10px 0; padding-left: 20px; simplex-steps li margin: 5px 0;",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter01/01_04_brief_history_of_convex_optimization/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_Convex_sets",
    "title": "02 Tập Lồi",
    "chapter": "02",
    "order": 0,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Trong chương này, chúng ta sẽ nghiên cứu khái niệm về tập lồi, tạo nền tảng cho tối ưu hóa lồi. Bối cảnh Tối ưu hóa lồi đề cập đến các kỹ thuật tìm cực đại hoặc cực tiểu bằng cách định nghĩa các bài toán sử dụng hàm lồi. Tập lồi có liên quan chặt chẽ với hàm lồi theo hai cách chính: Hàm lồi được định nghĩa trên tập lồi. Miền xác định và miền giá trị của một hàm được định nghĩa như các tập lồi, và các tính chất chính của hàm lồi được xác định bởi những tập hợp này. Nếu bạn có thể biến đổi một bài toán tối ưu hóa thành bài toán liên quan đến hàm lồi, nó sẽ trở nên dễ giải hơn. Đôi khi, khó xác định liệu một bài toán có được định nghĩa bởi hàm lồi hay không. Trong những trường hợp như vậy, bạn có thể kiểm tra xem epigraph của hàm có phải là tập lồi hay không để xác định hàm có lồi không. Nội dung Trong chương này, chúng ta sẽ đề cập đến định nghĩa và ví dụ về tập lồi, các tính chất chính của chúng, và các phép toán bảo toàn tính lồi.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_Convex_sets/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_01_Affine_and_Convex_Sets",
    "title": "02-01 Tập Affine và Tập Lồi",
    "chapter": "02",
    "order": 1,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "Trong chương này, chúng ta sẽ khám phá các khái niệm và định nghĩa xoay quanh tập lồi. Chúng tôi giới thiệu ba loại tập hợp: cơ bản nhất là tập affine, và bằng cách áp đặt các ràng buộc bổ sung lên tập affine, chúng ta định nghĩa tập lồi và hình nón. Thú vị là, các tập hợp này có thể được coi như các tập hợp của nhiều đường thẳng line , đoạn thẳng hoặc tia. Một tập affine được hình thành bằng cách tập hợp nhiều đường thẳng, một tập lồi bằng cách tập hợp nhiều đoạn thẳng, và một hình nón bằng cách tập hợp nhiều tia. Góc nhìn này giúp việc hiểu các khái niệm này trở nên dễ dàng hơn. Ngoài ra, một hình nón đôi khi được gọi là tập đồng nhất không âm, có nghĩa là tính chất mở rộng chỉ theo một hướng từ gốc tọa độ, giúp làm rõ cách đặt tên.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_01_Affine_and_Convex_Sets/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_01_01_Line_line_segment_ray",
    "title": "02-01-01 Đường thẳng, đoạn thẳng, tia",
    "chapter": "02",
    "order": 2,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Để định nghĩa tập affine, tập lồi và hình nón, trước tiên hãy xem xét đường thẳng, đoạn thẳng và tia. Đường thẳng là một đường thẳng vô hạn đi qua hai điểm theo cả hai hướng. Ngược lại, đoạn thẳng là một đường thẳng chỉ được xác định giữa hai điểm, và tia bắt đầu từ một điểm và kéo dài vô hạn theo một hướng qua điểm khác. Hình dưới đây cho thấy một đường thẳng và một đoạn thẳng. Tùy thuộc vào phạm vi của tham số MATH , bạn có thể tưởng tượng cách một đường thẳng, đoạn thẳng hoặc tia được định nghĩa. MATH Tham khảo Khi bạn sử dụng hai điểm được bao gồm trong một tập hợp để tạo ra một đường thẳng, đoạn thẳng hoặc tia, việc liệu những điểm này có được bao gồm trong tập hợp hay không quyết định định nghĩa của tập hợp. Bạn cũng có thể định nghĩa tập hợp bằng cách sử dụng nhiều điểm và các tổ hợp affine, lồi hoặc nón của chúng. Chi tiết sẽ được giải thích trong các phần tiếp theo. Đường thẳng Một Đường thẳng đi qua hai điểm MATH và MATH được định nghĩa là: > MATH với MATH Đoạn thẳng Một Đoạn thẳng được định nghĩa bằng cách giới hạn MATH trong khoảng 0, 1 : > MATH với MATH Hoặc bạn có thể biểu diễn nó như: > MATH với MATH Tia Một Tia bắt đầu từ một điểm và kéo dài vô hạn theo một hướng: > MATH với MATH Hoặc tương đương: > MATH với MATH Bây giờ bạn có thể thấy rằng phạm vi của MATH là MATH cho đường thẳng, MATH cho đoạn thẳng, và MATH cho tia. Hơn nữa, bạn sẽ thấy rằng các phạm vi của MATH giống nhau trong các tập affine, tập lồi và tập nón mà chúng ta sẽ định nghĩa sau này.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_01_01_Line_line_segment_ray/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_01_02_Affine_set",
    "title": "02-01-02 Tập Affine",
    "chapter": "02",
    "order": 3,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Một tập affine là một tập hợp không có biên giới, như một điểm, đường thẳng, mặt phẳng hoặc siêu phẳng. Để xác định xem một tập hợp có phải là affine hay không, hãy kiểm tra xem đường thẳng đi qua bất kỳ hai điểm nào trong tập hợp đó có được chứa trong tập hợp hay không. Việc không có biên giới có nghĩa là nếu bất kỳ không gian nào có biên giới, thì nó không thể là một tập affine. Hãy định nghĩa điều này một cách toán học. Tập Affine Một tập MATH là một tập affine nếu với bất kỳ hai điểm MATH , đường thẳng đi qua chúng cũng nằm trong MATH : > MATH với MATH Điều này có thể được hiểu như một tổ hợp tuyến tính của hai điểm trong MATH , trong đó tổng các hệ số bằng 1. Nếu kết quả luôn nằm trong MATH , thì MATH là một tập affine. Tổ hợp Affine Một tổ hợp tuyến tính của nhiều điểm trong đó tổng các hệ số bằng 1 được gọi là tổ hợp affine : > MATH với MATH Nếu mọi tổ hợp affine của các điểm trong tập MATH cũng nằm trong MATH , thì MATH là một tập affine. Bao Affine Tập hợp tất cả các tổ hợp affine của các điểm trong MATH được gọi là bao affine của MATH , ký hiệu là aff MATH : > MATH Mối quan hệ giữa tập affine và không gian con Nếu MATH là một tập affine và MATH , thì MATH là một không gian con: > MATH Do đó, \"Một tập affine MATH là một phép tịnh tiến của không gian con tuyến tính MATH bởi MATH ,\" trong đó MATH có thể là bất kỳ điểm nào trong MATH . Chiều của MATH giống như chiều của MATH . Tham khảo Chứng minh MATH là một không gian con Để chứng minh MATH là một không gian con, cần chỉ ra rằng nó đóng kín dưới phép cộng và nhân vô hướng. Tức là, với MATH và MATH , thì MATH . Điều này được suy ra từ định nghĩa ở trên.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_01_02_Affine_set/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_01_05_Hyperplane",
    "title": "02-01-05 Siêu phẳng",
    "chapter": "02",
    "order": 4.5,
    "owner": "AI Assistant",
    "lesson_type": "",
    "content": "Siêu phẳng là một trong những đối tượng hình học cơ bản nhất trong tối ưu hóa lồi và đại số tuyến tính. Nó đóng vai trò như một khối xây dựng để hiểu các tập lồi phức tạp hơn và đóng vai trò quan trọng trong các thuật toán tối ưu hóa, machine learning và phân tích hình học. Định nghĩa Siêu phẳng Một siêu phẳng trong MATH là một tập hợp có dạng: > MATH trong đó MATH là một vector khác không MATH và MATH là một số vô hướng. Vector MATH được gọi là vector pháp tuyến của siêu phẳng, và nó xác định hướng của siêu phẳng. Số vô hướng MATH xác định vị trí của siêu phẳng so với gốc tọa độ. Giải thích Hình học - Trong MATH : Một siêu phẳng là một đường thẳng - Trong MATH : Một siêu phẳng là một mặt phẳng - Trong MATH MATH : Một siêu phẳng là một không gian con MATH chiều Siêu phẳng chia toàn bộ không gian MATH thành hai nửa không gian : - Nửa không gian dương : MATH - Nửa không gian âm : MATH Tính chất của Siêu phẳng 1. Tính chất Tập Affine Mọi siêu phẳng đều là tập affine . Điều này có nghĩa là nếu MATH , thì toàn bộ đường thẳng đi qua chúng cũng được chứa trong MATH : MATH Chứng minh : Nếu MATH và MATH , thì: MATH 2. Tính chất Tập Lồi Vì mọi tập affine đều là lồi, siêu phẳng là tập lồi . Với bất kỳ MATH và MATH : MATH 3. Tính chất Tập Đóng Siêu phẳng là tập đóng vì chúng là tập mức của các hàm tuyến tính liên tục. 4. Chiều Một siêu phẳng trong MATH có chiều MATH . Các cách biểu diễn khác 1. Dạng Điểm-Pháp tuyến Nếu chúng ta biết một điểm MATH trên siêu phẳng và vector pháp tuyến MATH , siêu phẳng có thể được viết như: MATH Điều này tương đương với MATH , vậy MATH . 2. Dạng Ma trận Một siêu phẳng cũng có thể được biểu diễn bằng ký hiệu ma trận. Nếu MATH là ma trận MATH vector hàng , thì: MATH 3. Dạng Tham số Một siêu phẳng có thể được tham số hóa bằng cách sử dụng một cơ sở cho không gian null của nó. Nếu MATH là một cơ sở trực chuẩn cho không gian null của MATH , và MATH là bất kỳ điểm nào trên siêu phẳng, thì: MATH Khoảng cách từ Điểm đến Siêu phẳng Khoảng cách từ một điểm MATH đến siêu phẳng MATH được cho bởi: MATH Công thức này xuất phát từ việc chiếu vector từ bất kỳ điểm nào trên siêu phẳng đến MATH lên hướng pháp tuyến. Suy dẫn Gọi MATH là điểm gần nhất trên siêu phẳng với MATH . Thì MATH song song với vector pháp tuyến MATH : MATH Vì MATH , ta có MATH . Thay thế: MATH Giải tìm MATH : MATH Khoảng cách là MATH . Ví dụ Ví dụ 1: Đường thẳng trong MATH Siêu phẳng MATH biểu diễn một đường thẳng trong mặt phẳng. - Vector pháp tuyến: MATH - Đường thẳng đi qua các điểm MATH và MATH - Khoảng cách từ gốc tọa độ: MATH Ví dụ 2: Mặt phẳng trong MATH Siêu phẳng MATH biểu diễn một mặt phẳng trong không gian 3D. - Vector pháp tuyến: MATH - Mặt phẳng đi qua các điểm MATH , MATH , và MATH Ví dụ 3: Siêu phẳng đi qua Gốc tọa độ Siêu phẳng MATH luôn đi qua gốc tọa độ và thực sự là một không gian con có chiều MATH . Trực quan hóa Tương tác Ghi chú: Phần này chứa mã JavaScript để tạo trực quan hóa tương tác về siêu phẳng. Phần này sẽ được dịch riêng do tính phức tạp của mã. Mối quan hệ với các Khái niệm khác Kết nối với Tập Affine Mọi siêu phẳng đều là tập affine, nhưng không phải mọi tập affine đều là siêu phẳng. Siêu phẳng là các tập affine có chiều MATH cụ thể trong MATH . Kết nối với Đại số Tuyến tính Siêu phẳng MATH là tập mức của hàm tuyến tính MATH tại mức MATH . Gradient của hàm này là hằng số và bằng MATH , điều này giải thích tại sao MATH vuông góc với siêu phẳng. Kết nối với Tối ưu hóa Trong tối ưu hóa có ràng buộc, các ràng buộc đẳng thức thường định nghĩa các siêu phẳng hạn chế miền khả thi. Phương pháp nhân tử Lagrange khai thác thực tế rằng tại điểm tối ưu, gradient của hàm mục tiêu song song với vector pháp tuyến của siêu phẳng ràng buộc. Interactive Visualization Normal vector a₁: 1.0 Normal vector a₂: 1.0 Offset b: 0.0 Reset Hyperplane equation: x₁ + x₂ = 0 Distance from origin: 0.0 class HyperplaneVisualizer constructor this.canvas = document.getElementById 'hyperplane-canvas' ; this.ctx = this.canvas.getContext '2d' ; this.width = this.canvas.width; this.height = this.canvas.height; // Parameters this.a1 = 1; this.a2 = 1; this.b = 0; // Scale and offset for coordinate system this.scale = 40; this.centerX = this.width / 2; this.centerY = this.height / 2; this.setupControls ; this.draw ; setupControls const a1Slider = document.getElementById 'a1-slider' ; const a2Slider = document.getElementById 'a2-slider' ; const bSlider = document.getElementById 'b-slider' ; const resetBtn = document.getElementById 'reset-btn' ; a1Slider.addEventListener 'input', e => this.a1 = parseFloat e.target.value ; document.getElementById 'a1-value' .textContent = this.a1.toFixed 1 ; this.updateDisplay ; ; a2Slider.addEventListener 'input', e => this.a2 = parseFloat e.target.value ; document.getElementById 'a2-value' .textContent = this.a2.toFixed 1 ; this.updateDisplay ; ; bSlider.addEventListener 'input', e => this.b = parseFloat e.target.value ; document.getElementById 'b-value' .textContent = this.b.toFixed 1 ; this.updateDisplay ; ; resetBtn.addEventListener 'click', => this.a1 = 1; this.a2 = 1; this.b = 0; a1Slider.value = 1; a2Slider.value = 1; bSlider.value = 0; document.getElementById 'a1-value' .textContent = '1.0'; document.getElementById 'a2-value' .textContent = '1.0'; document.getElementById 'b-value' .textContent = '0.0'; this.updateDisplay ; ; updateDisplay this.draw ; this.updateInfo ; updateInfo // Update equation const eq = MATH this.a2.toFixed 1 x₂ = $ this.b.toFixed 1 ; document.getElementById 'equation' .textContent = eq; // Update distance from origin const distance = Math.abs this.b / Math.sqrt this.a1 this.a1 + this.a2 this.a2 ; document.getElementById 'distance' .textContent = distance.toFixed 3 ; worldToScreen x, y return x: this.centerX + x this.scale, y: this.centerY - y this.scale ; draw // Clear canvas this.ctx.clearRect 0, 0, this.width, this.height ; // Draw coordinate system this.drawCoordinateSystem ; // Draw hyperplane line in 2D this.drawHyperplane ; // Draw normal vector this.drawNormalVector ; // Draw distance from origin this.drawDistanceFromOrigin ; drawCoordinateSystem this.ctx.strokeStyle = ' ddd'; this.ctx.lineWidth = 1; // Grid lines for let i = -10; i 1e-10 // Line is not vertical x1 start = -10; y1 start = this.b - this.a1 x1 start / this.a2; x1 end = 10; y1 end = this.b - this.a1 x1 end / this.a2; else // Line is vertical x1 start = x1 end = this.b / this.a1; y1 start = -10; y1 end = 10; const start = this.worldToScreen x1 start, y1 start ; const end = this.worldToScreen x1 end, y1 end ; this.ctx.beginPath ; this.ctx.moveTo start.x, start.y ; this.ctx.lineTo end.x, end.y ; this.ctx.stroke ; // Label const midX = start.x + end.x / 2; const midY = start.y + end.y / 2; this.ctx.fillStyle = ' 2196F3'; this.ctx.font = 'bold 14px Arial'; this.ctx.fillText 'Hyperplane', midX + 10, midY - 10 ; drawNormalVector if Math.abs this.a1 Relationship to Other Concepts Connection to Affine Sets Every hyperplane is an affine set, but not every affine set is a hyperplane. Hyperplanes are specifically MATH -dimensional affine sets in MATH . Connection to Linear Algebra The hyperplane MATH is the level set of the linear function MATH at level MATH . The gradient of this function is constant and equal to MATH , which explains why MATH is perpendicular to the hyperplane. Connection to Optimization In constrained optimization, equality constraints often define hyperplanes that restrict the feasible region. The method of Lagrange multipliers exploits the fact that at an optimal point, the gradient of the objective function is parallel to the normal vector of the constraint hyperplane.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_01_05_Hyperplane/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_01_03_Convex-set",
    "title": "02-01-03 Tập Lồi",
    "chapter": "02",
    "order": 4,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Bây giờ hãy xem xét khái niệm cốt lõi của chương này: tập lồi. Một cách trực quan, tập lồi là một tập hợp không có \"vết lõm\" hoặc \"lỗ hổng\" bên trong. Để xác định xem một tập hợp có lồi hay không, hãy kiểm tra xem đoạn thẳng nối bất kỳ hai điểm nào trong tập hợp đó có được chứa trong tập hợp hay không. Tập Lồi Một tập MATH là một tập lồi nếu với bất kỳ hai điểm MATH , đoạn thẳng nối chúng cũng nằm trong MATH : > MATH với MATH , MATH Điều này có nghĩa là với bất kỳ hai điểm nào trong MATH , tất cả các điểm trên đoạn thẳng giữa chúng cũng nằm trong MATH . Hình dưới đây cho thấy các ví dụ về tập lồi. Tam giác bên trái là lồi, nhưng hình có lõm bên phải không lồi vì đoạn thẳng giữa một số điểm ra khỏi tập hợp. Hình1 Tập Lồi 1 Tổ hợp Lồi Một tổ hợp tuyến tính của nhiều điểm trong đó các hệ số không âm và tổng bằng 1 được gọi là tổ hợp lồi : > Một điểm có dạng MATH với MATH Nếu mọi tổ hợp lồi của các điểm trong tập MATH cũng nằm trong MATH , thì MATH là một tập lồi. Bao Lồi Tập hợp tất cả các tổ hợp lồi của các điểm trong MATH được gọi là bao lồi của MATH , ký hiệu là conv MATH : > conv MATH Hình dưới đây cho thấy bao lồi cho một tập hợp 15 điểm và một hình có lõm. Bao Lồi Bao Lồi",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_01_03_Convex-set/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_01_04_Convex_cone",
    "title": "02-01-04 Hình Nón",
    "chapter": "02",
    "order": 5,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Hình nón là một tập hợp kéo dài vô hạn theo những hướng nhất định, giống như một chùm ánh sáng từ một nguồn, nhưng không được định nghĩa theo hướng ngược lại. Để xác định xem một tập hợp có phải là hình nón hay không, hãy kiểm tra xem tia bắt đầu từ gốc tọa độ và đi qua bất kỳ điểm nào trong tập hợp đó có được chứa trong tập hợp hay không. Do đó, một hình nón phải bao gồm gốc tọa độ. Vì hình nón có biên giới, nó không thể là một tập affine. Hãy định nghĩa điều này một cách toán học. Hình Nón Một tập MATH là một hình nón hoặc tập đồng nhất không âm nếu với bất kỳ điểm MATH , tia MATH cũng nằm trong MATH với MATH : > MATH với MATH , MATH Tham khảo Khác với tập affine hoặc tập lồi, khi định nghĩa hình nón, điểm bắt đầu của tia được giả định là gốc tọa độ, vì vậy chỉ sử dụng một điểm. Hình Nón Lồi Một tập MATH là một hình nón lồi nếu nó vừa là hình nón vừa là tập lồi: > MATH với MATH , MATH Hình dưới đây cho thấy một hình nón lồi có dạng hình quạt. Trong hình, MATH và MATH là các điểm trong hình nón, và MATH và MATH là các vô hướng không âm. Hình1 Hình Nón Lồi 1 Tổ hợp Nón Một tổ hợp tuyến tính của nhiều điểm trong đó tất cả các hệ số đều không âm được gọi là tổ hợp nón hoặc tổ hợp tuyến tính không âm : > Một điểm có dạng MATH với MATH Nếu mọi tổ hợp nón của các điểm trong tập MATH cũng nằm trong MATH , thì MATH là một tập nón. Bao Nón Tập hợp tất cả các tổ hợp nón của các điểm trong MATH được gọi là bao nón của MATH . Bao nón luôn là hình nón lồi nhỏ nhất chứa MATH : > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_01_04_Convex_cone/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_02_Some_important_examples",
    "title": "02-02 Một số ví dụ quan trọng",
    "chapter": "02",
    "order": 6,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "Phần này xem xét các ví dụ chính về tập lồi. Các tập hợp tầm thường: tập rỗng, điểm, đường thẳng, đoạn thẳng, tia Siêu phẳng: MATH , với MATH cho trước, MATH Nửa không gian: MATH với MATH Không gian Affine: MATH , với MATH cho trước Hình cầu Euclidean và ellipsoid Hình cầu chuẩn: MATH , với chuẩn MATH và bán kính MATH cho trước Hình nón lồi: nón chuẩn, nón pháp tuyến, nón nửa xác định dương",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_02_Some_important_examples/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_02_01_Convex_sets_examples",
    "title": "02-02-01 Ví dụ về tập lồi",
    "chapter": "02",
    "order": 7,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Tập lồi bao gồm nhiều dạng khác nhau, từ những dạng tầm thường như điểm và đường thẳng đến siêu phẳng, nửa không gian, hình cầu, ellipsoid, đa diện và hình nón. Siêu phẳng Siêu phẳng là một tập con MATH chiều chia không gian MATH chiều thành hai phần, được định nghĩa như sau. Ở đây, MATH là vector pháp tuyến và MATH là độ lệch từ gốc tọa độ. Siêu phẳng vừa là tập lồi vừa là tập affine. > MATH với MATH Trong hình dưới đây, bất kỳ MATH nào trên siêu phẳng đều thỏa mãn MATH vuông góc với MATH . Do đó, MATH , vậy nếu MATH , thì MATH . Hình1 Siêu phẳng 1 Nửa không gian Nửa không gian là một phía của không gian được chia bởi siêu phẳng. Do đó, một siêu phẳng MATH định nghĩa hai nửa không gian. Nửa không gian là tập lồi nhưng không phải tập affine. > MATH hoặc MATH với MATH Đối với siêu phẳng MATH , nửa không gian MATH nằm theo hướng của vector pháp tuyến MATH , trong khi MATH nằm theo hướng của MATH . Hình2 Nửa không gian 1 Lưu ý: Phần trong của MATH , tức là MATH , được gọi là nửa không gian mở. Tính chất quan trọng: Nửa không gian là Lồi Lấy hai điểm bất kỳ MATH và MATH trong nửa không gian: - Cả hai đều thỏa mãn: MATH và MATH Với bất kỳ tổ hợp lồi nào: MATH với MATH Kiểm tra xem điểm này có nằm trong nửa không gian hay không: MATH Vì MATH thỏa mãn bất đẳng thức, tất cả các điểm giữa MATH và MATH đều nằm trong nửa không gian → nửa không gian là lồi. Hình cầu Euclidean Hình cầu Euclidean là một tập lồi khác, được định nghĩa như sau. MATH là chuẩn Euclidean, MATH . MATH là tâm và MATH là bán kính. Do đó, MATH chứa tất cả các điểm trong bán kính MATH từ tâm MATH . > MATH Hoặc, hình cầu Euclidean có thể được biểu diễn như: > MATH Ellipsoid Ellipsoid là một tập lồi liên quan đến hình cầu Euclidean, được định nghĩa như: > MATH Ở đây, MATH có nghĩa là MATH đối xứng và xác định dương. Vector MATH là tâm của ellipsoid, và ma trận MATH xác định ellipsoid kéo dài bao xa theo mỗi hướng từ tâm. Các trục của ellipsoid là MATH , trong đó MATH là các giá trị riêng của MATH . Do đó, hình cầu là trường hợp đặc biệt của ellipsoid với MATH . Hình dưới đây cho thấy một ellipsoid. Tâm MATH là một điểm, và các trục chính và phụ được vẽ như các đoạn thẳng. Hình3 Ellipsoid 1 Ellipsoid cũng có thể được biểu diễn như: > MATH Ở đây, MATH là ma trận vuông không suy biến. Nếu MATH , biểu thức khớp với biểu thức trước đó, và MATH đối xứng và xác định dương. Nếu MATH đối xứng nửa xác định dương và suy biến, nó được gọi là ellipsoid suy biến, và chiều affine của nó bằng hạng của MATH . Ellipsoid suy biến vẫn là lồi. Hình cầu chuẩn Hình cầu chuẩn là tập hợp các điểm trong bán kính MATH từ tâm MATH , được định nghĩa sử dụng một chuẩn tùy ý. Trong khi hình cầu Euclidean sử dụng chuẩn Euclidean, hình cầu chuẩn có thể sử dụng bất kỳ chuẩn nào. Nếu MATH là bất kỳ chuẩn nào trên MATH , hình cầu chuẩn được định nghĩa như: > MATH Khi p-chuẩn được định nghĩa như: > MATH Hình dạng của hình cầu chuẩn phụ thuộc vào giá trị của MATH . Hình dưới đây cho thấy hình dạng của hình cầu chuẩn trong 3D với các giá trị khác nhau của MATH . Hình cầu chuẩn là lồi nếu MATH . Hình4 Hình cầu chuẩn 1 Hình tiếp theo cho thấy hình dạng của hình cầu chuẩn trong 2D với các giá trị khác nhau của MATH . Hình4 Hình cầu chuẩn 2 Đa diện Đa diện được định nghĩa như giao của các bất đẳng thức và đẳng thức tuyến tính. Tập affine không gian con, siêu phẳng, đường thẳng , tia, đoạn thẳng và nửa không gian đều là đa diện. Đa diện là tập lồi, và một đa diện bị chặn được gọi là polytope. > MATH Một đẳng thức đơn MATH có thể được biểu diễn bằng hai bất đẳng thức MATH và MATH . Do đó, đa diện có thể được định nghĩa chỉ sử dụng các bất đẳng thức. Hình dưới đây cho thấy một đa diện ngũ giác được hình thành bởi giao của năm nửa không gian, với các vector pháp tuyến hướng ra ngoài MATH . Hình5 Đa diện 1 Dưới dạng ma trận, một đa diện có thể được định nghĩa như: > MATH trong đó MATH A = \\begin bmatrix a^T 1 \\\\ \\vdots \\\\ a^T m \\end bmatrix , MATH MATH C = \\begin bmatrix c^T 1 \\\\ \\vdots \\\\ c^T p \\end bmatrix MATH Đơn hình Đơn hình là đa giác đơn giản nhất có thể được hình thành trong không gian MATH chiều, được xây dựng từ MATH điểm. Nếu có MATH điểm MATH độc lập affine, đơn hình được định nghĩa như bao lồi của những MATH điểm này. Độc lập affine có nghĩa là MATH độc lập tuyến tính. > MATH Hình dưới đây cho thấy các đơn hình từ 0 đến 3 chiều: một điểm trong 0D, một đoạn thẳng trong 1D, một tam giác trong 2D, và một tứ diện trong 3D. Hình6 Đơn hình nguồn - wikipedia Một ví dụ phổ biến của đơn hình là đơn hình xác suất: > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_02_01_Convex_sets_examples/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_02_02_Convex_cone_examples",
    "title": "02-02-02 Ví dụ về hình nón lồi",
    "chapter": "02",
    "order": 8,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Các ví dụ về hình nón lồi bao gồm hình nón chuẩn, hình nón pháp tuyến và hình nón nửa xác định dương. Hình nón chuẩn Hình nón chuẩn là một hình nón được định nghĩa bởi tất cả các điểm MATH sao cho MATH trong MATH , trong đó chuẩn có thể là bất kỳ chuẩn nào. > MATH , với chuẩn MATH Hình dưới đây cho thấy hình nón chuẩn cho chuẩn MATH MATH , còn được gọi là hình nón bậc hai hoặc hình nón kem. Hình1 Hình Nón Chuẩn 1 Hình nón pháp tuyến Với một tập MATH và một điểm MATH , hình nón pháp tuyến được định nghĩa như sau: > MATH Hình nón pháp tuyến bao gồm tất cả các vector MATH sao cho tích vô hướng với MATH luôn nhỏ hơn hoặc bằng không với mọi MATH . Điều này có nghĩa là góc giữa MATH và MATH nằm trong khoảng từ 90 đến 270 độ tức là MATH \\cos\\theta Hình2 Hình Nón Pháp Tuyến 3 Hình nón nửa xác định dương Hình nón nửa xác định dương MATH được định nghĩa như sau, trong đó MATH biểu diễn các ma trận đối xứng MATH : > MATH MATH là một hình nón lồi vì với MATH và MATH , ta có MATH . Đây được gọi là hình nón nửa xác định dương . Hình dưới đây cho thấy biên của hình nón nửa xác định dương trong MATH được vẽ trong MATH . Vì ma trận MATH là nửa xác định dương, định thức của nó phải không âm. MATH X = \\begin bmatrix x, y \\\\ y, z \\end bmatrix \\in \\mathbb S ^2 + \\iff x \\ge 0, z \\ge 0, xz \\ge y^2 MATH Hình3 Hình nón nửa xác định dương 1",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_02_02_Convex_cone_examples/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_03_Operations_that_preserve_convexity",
    "title": "02-03 Các phép toán bảo toàn tính lồi của tập lồi",
    "chapter": "02",
    "order": 9,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Phần này thảo luận về các phép toán bảo toàn tính lồi của tập lồi. Những phép toán này hữu ích để xác định tính lồi hoặc xây dựng các tập lồi mong muốn từ những tập đơn giản như siêu phẳng, nửa không gian và hình cầu chuẩn. Các phép toán bảo toàn tính lồi bao gồm: Giao Hàm affine Hàm phối cảnh Hàm tuyến tính-phân thức Giao Giao của các tập lồi là lồi. Tức là, nếu MATH và MATH là lồi, thì MATH là lồi. Tính chất này đúng ngay cả với vô số tập hợp. Không gian con, tập affine và hình nón lồi cũng đóng kín dưới phép giao. Tính lồi có thể được biểu diễn như giao của vô số nửa không gian, và điều ngược lại cũng đúng. Tức là, một tập lồi đóng MATH có thể được định nghĩa như giao của tất cả các nửa không gian chứa MATH : > MATH Hàm affine Cho MATH và MATH . Hàm MATH được định nghĩa bởi MATH được gọi là hàm affine. Nếu MATH là lồi và MATH là lồi, thì: Ảnh affine MATH là lồi. Nghịch ảnh affine MATH là lồi. Áp dụng các hàm affine như co giãn và tịnh tiến, phép chiếu, tổng của hai tập hợp, và tổng từng phần lên các tập lồi sẽ cho kết quả là các tập lồi. Tập nghiệm của một bất đẳng thức ma trận tuyến tính MATH với MATH cũng là lồi. Một hình nón hyperbolic MATH với MATH , MATH cũng là lồi. Hàm phối cảnh Hàm phối cảnh mô hình hóa cách các vật thể xuất hiện nhỏ hơn khi ở xa và lớn hơn khi ở gần, tương tự như cách máy ảnh chiếu hình ảnh. Vật thể nằm trong MATH và ảnh của nó nằm trong MATH . Hàm phối cảnh được định nghĩa là MATH với dom MATH và MATH , trong đó MATH . Hàm này chuẩn hóa tọa độ cuối cùng về 1 và bỏ qua nó, giảm chiều từ MATH xuống MATH . Nếu MATH dom MATH là lồi, thì ảnh MATH cũng là lồi. Hàm phối cảnh hoạt động như một máy ảnh lỗ kim: các vật thể xa hơn từ lỗ kim được chiếu nhỏ hơn. Hình dưới đây minh họa nguyên lý này, cho thấy rằng các vật thể trong cùng một tia bị bắt sẽ được chiếu giống hệt nhau.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_03_Operations_that_preserve_convexity/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_04_Generalized_inequalities",
    "title": "02-04 Bất đẳng thức tổng quát",
    "chapter": "02",
    "order": 10,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Trong không gian thực một chiều MATH , cho hai số 1 và 2, chúng ta có thể nói 2 lớn hơn 1. Nhưng trong không gian thực MATH chiều MATH , cho hai điểm MATH và MATH , liệu chúng ta có thể nói điểm nào lớn hơn? Điều này không đơn giản. Phần này giới thiệu bất đẳng thức tổng quát để so sánh thứ tự giữa hai điểm trong MATH , và cũng thảo luận về các khái niệm phần tử cực tiểu và tối tiểu của một tập hợp. Hình nón thích hợp Một hình nón lồi MATH được gọi là hình nón thích hợp nếu nó thỏa mãn: K là đóng bao gồm biên của nó . K là rắn phần trong của nó không rỗng . K là nhọn không chứa bất kỳ đường thẳng nào tức là MATH . Nếu một hình nón lồi nhọn & đóng được định nghĩa trong một không gian con có chiều MATH hoặc ít hơn, phần trong của nó sẽ rỗng, vì nó không thể chứa một hình cầu mở trong MATH chiều. Do đó, nó không rắn và không thể là hình nón thích hợp. Ví dụ, một hình nón lồi nhọn & đóng hình quạt 2D trong MATH không phải là hình nón thích hợp. Xem Wikipedia: Interior topology https://en.wikipedia.org/wiki/Interior topology để biết định nghĩa về phần trong. Bất đẳng thức tổng quát Sử dụng một hình nón thích hợp, chúng ta có thể định nghĩa một thứ tự từng phần trong MATH được gọi là bất đẳng thức tổng quát . Nó có các tính chất tương tự như thứ tự tiêu chuẩn trong MATH : > MATH Tương tự, thứ tự từng phần nghiêm ngặt được định nghĩa như: > MATH int MATH Nếu MATH , thì MATH là MATH thông thường trong MATH . Tính chất của bất đẳng thức tổng quát Bất đẳng thức tổng quát MATH thỏa mãn: Bảo toàn dưới phép cộng : nếu MATH và MATH , thì MATH . Bắc cầu : nếu MATH và MATH thì MATH . Bảo toàn dưới co giãn không âm : nếu MATH và MATH thì MATH . Phản xạ : MATH . Phản đối xứng : nếu MATH và MATH , thì MATH . Bảo toàn dưới giới hạn : nếu MATH với MATH và MATH khi MATH , thì MATH . Bất đẳng thức tổng quát nghiêm ngặt có các tính chất tương ứng. Phần tử tối tiểu và cực tiểu Sự khác biệt quan trọng nhất giữa thứ tự trong MATH và thứ tự tổng quát trong MATH là thứ tự tuyến tính . Trong MATH , chúng ta có thể so sánh bất kỳ hai điểm nào với MATH hoặc MATH , nhưng bất đẳng thức tổng quát không thể luôn làm điều này. Do đó, việc định nghĩa các khái niệm cực đại và cực tiểu trong bối cảnh bất đẳng thức tổng quát được dự kiến sẽ phức tạp hơn nhiều. Phần tử tối tiểu Nếu MATH thỏa mãn MATH với mọi MATH , thì MATH là phần tử tối tiểu của tập MATH . Tương tự, tối đại có thể được định nghĩa theo cách tương tự. Nếu một tối tiểu tồn tại trong một tập hợp, nó là duy nhất. Tức là, chỉ tồn tại một tối tiểu. Nếu một điểm MATH là tối tiểu của MATH , thì MATH . Ở đây, MATH có nghĩa là theo MATH tất cả các điểm đều có thể so sánh với MATH và lớn hơn hoặc bằng MATH . Phần tử cực tiểu Một khái niệm tương tự là cực tiểu . Nếu MATH và với mọi MATH , điều kiện MATH chỉ đúng khi MATH , thì MATH là phần tử cực tiểu của tập MATH . Tương tự, cực đại có thể được định nghĩa theo cách tương tự. Một tập hợp có thể có nhiều phần tử cực tiểu. Nếu một điểm MATH là cực tiểu trong MATH , thì MATH . Ở đây, MATH có nghĩa là theo MATH tất cả các điểm đều có thể so sánh với MATH và nhỏ hơn hoặc bằng MATH . Trong trường hợp MATH , cực tiểu và tối tiểu là giống nhau và tương ứng với định nghĩa chung của tối tiểu. Tối tiểu và cực tiểu trong hình nón MATH Xét hình nón MATH MATH . Bất đẳng thức MATH có nghĩa là MATH nằm ở phía trên bên phải của MATH . Khi MATH , nói rằng MATH là tối tiểu có nghĩa là tất cả các điểm trong MATH đều nằm ở phía trên bên phải của MATH . Nói rằng MATH là cực tiểu có nghĩa là không có điểm nào trong MATH nằm ở phía dưới bên trái của MATH . Trong hình dưới đây, MATH có một tối tiểu MATH . Tập MATH được hiển thị bằng màu xám nhạt, và vì MATH , MATH là tối tiểu. MATH có một phần tử cực tiểu MATH . Tập MATH được hiển thị bằng màu xám nhạt, và vì MATH , MATH là cực tiểu. Hình1 Phần tử tối tiểu và cực tiểu 1",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_04_Generalized_inequalities/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_05_Separating_and_supporting_hyperplanes",
    "title": "02-05 Siêu phẳng phân tách và hỗ trợ",
    "chapter": "02",
    "order": 11,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "Phần này giới thiệu hai định lý đặc trưng cho tập lồi: định lý siêu phẳng phân tách và định lý siêu phẳng hỗ trợ . Định lý siêu phẳng phân tách Giả sử có một số tập lồi rời rạc không có giao điểm. Làm thế nào chúng ta có thể phân tách chúng? Cách đơn giản nhất là vẽ một đường thẳng giữa các tập hợp. Phương pháp này được sử dụng rộng rãi trong phân loại và được hỗ trợ bởi định lý siêu phẳng phân tách . Nếu có hai tập lồi rời rạc MATH và MATH , thì với MATH , MATH và với MATH , MATH với một số MATH và MATH . Nói cách khác, hàm affine MATH không dương trên MATH và không âm trên MATH . Siêu phẳng MATH được gọi là siêu phẳng phân tách cho MATH và MATH . Hình dưới đây cho thấy một siêu phẳng phân tách chia hai tập lồi rời rạc MATH và MATH . Hình1 Định lý siêu phẳng phân tách 1 Điều ngược lại của định lý siêu phẳng phân tách không đúng. Tức là, sự tồn tại của một siêu phẳng phân tách không đảm bảo rằng các tập hợp là rời rạc. Ví dụ, nếu MATH , thì MATH phân tách MATH và MATH . Phân tách nghiêm ngặt Nếu siêu phẳng phân tách thỏa mãn điều kiện mạnh hơn MATH suy ra MATH , điều này được gọi là phân tách nghiêm ngặt . Các tập lồi đóng rời rạc không phải lúc nào cũng yêu cầu phân tách nghiêm ngặt, nhưng trong nhiều trường hợp, điều kiện này được thỏa mãn. Định lý siêu phẳng hỗ trợ Định lý siêu phẳng hỗ trợ phát biểu rằng với bất kỳ tập lồi không rỗng MATH và bất kỳ điểm MATH nào trên biên bd MATH , tồn tại một siêu phẳng hỗ trợ tại MATH . Siêu phẳng hỗ trợ là gì? Giả sử MATH là một điểm biên của MATH . Nếu với mọi MATH , MATH MATH , thì siêu phẳng MATH là siêu phẳng hỗ trợ cho MATH tại MATH . Lưu ý Biên được định nghĩa là MATH bd MATH cl MATH MATH int MATH , tức là bao đóng trừ đi phần trong. Về mặt hình học, siêu phẳng hỗ trợ MATH tiếp xúc với MATH tại MATH và nửa không gian MATH chứa MATH . Hình 2 Siêu phẳng hỗ trợ 1",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_05_Separating_and_supporting_hyperplanes/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_06_Dual_cones_and_generalized_inequalities",
    "title": "02-06 Hình nón đối ngẫu và bất đẳng thức tổng quát",
    "chapter": "02",
    "order": 12,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Phần này thảo luận về hình nón đối ngẫu được ghép đôi với hình nón, và bất đẳng thức tổng quát đối ngẫu. Sử dụng bất đẳng thức tổng quát đối ngẫu cho phép so sánh bằng cách sử dụng tích vô hướng, làm cho việc so sánh trở nên dễ dàng hơn nhiều.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_06_Dual_cones_and_generalized_inequalities/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_06_01_Dual_cones",
    "title": "02-06-01 Hình nón đối ngẫu",
    "chapter": "02",
    "order": 13,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Hình nón đối ngẫu Hình nón đối ngẫu được định nghĩa như một cặp với một hình nón, ký hiệu là MATH cho hình nón và MATH cho hình nón đối ngẫu. Hình nón đối ngẫu luôn lồi, bất kể MATH có lồi hay không. Hình nón đối ngẫu được định nghĩa là tập hợp các điểm MATH sao cho tích vô hướng với bất kỳ MATH nào trong MATH đều không âm: > MATH Với MATH và MATH , tích vô hướng không âm có nghĩa là góc giữa các vector nằm trong phạm vi mà MATH , tức là MATH và MATH . Do đó, biên của hình nón đối ngẫu được hình thành theo hướng của vector pháp tuyến âm của siêu phẳng hỗ trợ của hình nón. Hình dưới đây cho thấy vùng mà hình nón đối ngẫu được định nghĩa. Tóm lại, vùng của hình nón đối ngẫu là tập hợp tất cả các hướng của vector pháp tuyến âm của các siêu phẳng hỗ trợ của hình nón tại gốc tọa độ. Hình1 Vùng định nghĩa hình nón đối ngẫu Về mặt hình học, nếu MATH , thì MATH là pháp tuyến của siêu phẳng hỗ trợ của MATH tại gốc tọa độ. Hình tiếp theo cho thấy ở bên trái, nửa không gian với pháp tuyến hướng vào trong MATH chứa hình nón MATH , vậy MATH . Ở bên phải, nửa không gian với pháp tuyến hướng vào trong MATH không chứa MATH , vậy MATH . Hình2 Hình nón đối ngẫu và pháp tuyến siêu phẳng hỗ trợ 1 Ví dụ về hình nón đối ngẫu Dưới đây là một số ví dụ về hình nón và đối ngẫu của chúng. Ba ví dụ đầu tiên là tự đối ngẫu , có nghĩa là hình nón và đối ngẫu của nó giống nhau. Ví dụ cuối cùng cho thấy rằng đối ngẫu của hình nón MATH là hình nón MATH , và ngược lại. MATH MATH MATH MATH Hình nón MATH là tự đối ngẫu Hình dưới đây cho thấy rằng hình nón MATH là tự đối ngẫu. Tức là, với MATH trên biên, pháp tuyến MATH của siêu phẳng hỗ trợ tại MATH khớp với biên của MATH , và MATH là biên của hình nón đối ngẫu MATH , vậy MATH và MATH trùng nhau. MATH Hình nón đối ngẫu của hình nón MATH là hình nón MATH Hình dưới đây cho thấy rằng hình nón đối ngẫu của hình nón MATH là hình nón MATH . Tức là, khi MATH là một điểm biên, pháp tuyến MATH của siêu phẳng hỗ trợ tại MATH đi vào phần trong của MATH và trùng với biên của hình nón MATH . MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_06_01_Dual_cones/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter02/02_06_02_Dual_generalized_inequalities",
    "title": "02-06-02 Bất đẳng thức tổng quát đối ngẫu",
    "chapter": "02",
    "order": 14,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Nếu chúng ta có thể định nghĩa một bất đẳng thức tổng quát sử dụng một hình nón thích hợp, chúng ta cũng có thể định nghĩa một bất đẳng thức tổng quát đối ngẫu sử dụng hình nón đối ngẫu, với điều kiện hình nón đối ngẫu là thích hợp. Phần này định nghĩa bất đẳng thức tổng quát đối ngẫu sử dụng một hình nón đối ngẫu thích hợp và định nghĩa lại các phần tử tối tiểu và cực tiểu sử dụng bất đẳng thức đối ngẫu. Bất đẳng thức tổng quát đối ngẫu Cho một hình nón đối ngẫu thích hợp, bất đẳng thức tổng quát được định nghĩa như sau. Với một điểm MATH , nếu tích vô hướng với mọi MATH trong MATH đều không âm, thì MATH là không âm trong hình nón đối ngẫu MATH . Ở đây, MATH được gọi là đối ngẫu của MATH , tức là bất đẳng thức tổng quát đối ngẫu . > MATH với mọi MATH Tính chất chính của bất đẳng thức tổng quát và đối ngẫu MATH khi và chỉ khi MATH với mọi MATH . MATH khi và chỉ khi MATH \\lambda^T x Hình1 Phần tử tối tiểu 1 Phần tử cực tiểu Các điều kiện cần và đủ cho phần tử cực tiểu hơi khác một chút. Với MATH và MATH , nếu MATH là bộ tối ưu hóa của MATH , thì MATH là cực tiểu. Nói cách khác, nếu MATH là cực tiểu, thì MATH không có bộ tối ưu hóa duy nhất. Do đó, với cùng một MATH , có thể có nhiều phần tử cực tiểu, và có thể có nhiều phần tử cực tiểu cho các MATH khác nhau. Hình dưới đây minh họa sự tồn tại của nhiều phần tử cực tiểu. Vùng có đường màu đen dày ở phía dưới bên trái chỉ ra khu vực mà các phần tử cực tiểu tồn tại. Ở đây, MATH là bộ tối ưu hóa của MATH và vì MATH , nó là cực tiểu. Một bộ tối ưu hóa khác, MATH , cũng tồn tại. Hình2 Phần tử cực tiểu 1 Tuy nhiên, điều ngược lại không đúng. Ngay cả khi một điểm MATH là cực tiểu trong một tập MATH , nó có thể không phải là bộ tối ưu hóa của MATH với một số MATH và MATH . Hình dưới đây cho thấy một ví dụ về phần tử cực tiểu không phải là bộ tối ưu hóa. Ở đây, tính lồi của tập hợp dường như đóng vai trò quan trọng trong việc điều ngược lại này không đúng. Hình3 Một ví dụ về phần tử cực tiểu không phải là bộ tối ưu hóa 1 Định lý ngược lại này không được tăng cường với MATH . Trong hình bên trái dưới đây, MATH là cực tiểu, nhưng không phải là bộ tối ưu hóa của MATH . Hình bên phải cho thấy MATH không phải là cực tiểu, nhưng là bộ tối ưu hóa của MATH . MATH Biên sản xuất tối ưu Xét một sản phẩm cần được sản xuất sử dụng n tài nguyên lao động, điện, khí tự nhiên, nước, v.v. . Sản phẩm này có thể được sản xuất theo nhiều cách. Với mỗi phương pháp sản xuất, có một vector tài nguyên MATH , trong đó MATH biểu thị lượng tài nguyên MATH được tiêu thụ. Giả định rằng tiêu thụ tài nguyên MATH không âm, và các tài nguyên có giá trị cao. Tập sản xuất MATH được định nghĩa là tập hợp tất cả các vector tài nguyên MATH . Một phương pháp sản xuất với vector tài nguyên cực tiểu được gọi là tối ưu Pareto hoặc hiệu quả . Tập hợp các phần tử cực tiểu của MATH được gọi là biên sản xuất hiệu quả . Hãy xem xét ngắn gọn về tính tối ưu Pareto. Giả sử có hai phương pháp sản xuất, một với vector tài nguyên MATH MATH và một với vector tài nguyên MATH MATH . Nếu với mọi MATH , MATH , và với một số MATH , MATH , thì chúng ta có thể nói rằng MATH tốt hơn MATH . Nói cách khác, một phương pháp không sử dụng nhiều tài nguyên hơn phương pháp khác, hoặc sử dụng ít nhất một tài nguyên ít hơn, được coi là tốt hơn. Tức là, điều này tương ứng với trường hợp MATH và MATH . Nếu không có phương pháp nào tốt hơn MATH , thì MATH được gọi là tối ưu Pareto. Bằng cách tối thiểu hóa biểu thức sau, chúng ta có thể tìm phương pháp sản xuất tối ưu Pareto. Ở đây, MATH có thể được coi như giá của tài nguyên MATH . Tối thiểu hóa MATH đối với MATH cho ra phương pháp sản xuất rẻ nhất. Vì các giá cả đều dương, kết quả của việc tối thiểu hóa luôn là tối ưu Pareto. > MATH MATH Hình dưới đây minh họa tình huống này một cách rõ ràng. Trong hình, MATH là tối ưu Pareto, trong khi MATH thì không. Hình5 Biên sản xuất tối ưu 1",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter02/02_06_02_Dual_generalized_inequalities/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_00_Convex_functions",
    "title": "03 Hàm lồi",
    "chapter": "03",
    "order": 1,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Trong chương này, chúng ta sẽ nghiên cứu định nghĩa, các ví dụ, tính chất chính của hàm lồi, và các phép toán bảo toàn tính lồi.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_00_Convex_functions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_01_00_Basic_properties_and_examples",
    "title": "03-01 Tính chất cơ bản và ví dụ",
    "chapter": "03",
    "order": 2,
    "owner": "Minjoo Lee",
    "lesson_type": "required",
    "content": "Phần này bao gồm định nghĩa của hàm lồi, các loại hàm lồi tiêu biểu, và các tính chất chính của chúng.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_01_00_Basic_properties_and_examples/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_01_01_convex_functions_definition",
    "title": "03-01-01 Định nghĩa",
    "chapter": "03",
    "order": 3,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Hàm lồi Một hàm MATH được gọi là lồi nếu miền xác định của nó là một tập lồi và với bất kỳ hai điểm MATH , hàm thỏa mãn: > MATH , > > với MATH , cho mọi MATH Điều này có nghĩa là với bất kỳ hai điểm MATH , giá trị của MATH tại tổ hợp lồi của chúng nhỏ hơn hoặc bằng tổ hợp lồi của các giá trị hàm tương ứng. Về mặt hình học, đồ thị của MATH nằm dưới đoạn thẳng nối MATH và MATH . Hình 1 Hàm Lồi 2 Hàm lồi chặt Một hàm MATH được gọi là lồi chặt nếu với bất kỳ hai điểm phân biệt MATH và MATH f \\theta x+ 1-\\theta y > với MATH , là hàm lồi. Lưu ý lồi mạnh ⇒ lồi chặt ⇒ lồi Hàm lõm Một hàm MATH được gọi là lõm nếu MATH là hàm lồi. Tất cả các hàm affine MATH đều thỏa mãn: > MATH \\begin aligned f \\theta x+ 1-\\theta y &= a^T \\theta x+ 1-\\theta y +b \\\\ &= \\theta a^T x + 1-\\theta a^T y + \\theta b + 1-\\theta b \\\\ &= \\theta f x + 1-\\theta f y \\\\ \\end aligned MATH > MATH Tức là, các hàm affine luôn vừa lồi vừa lõm.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_01_01_convex_functions_definition/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_01_02_examples_of_convex_function",
    "title": "03-01-02 Ví dụ về hàm lồi",
    "chapter": "03",
    "order": 4,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Phần này xem xét các ví dỡ điển hình của hàm lồi, bao gồm: Hàm mũ Hàm lũy thừa Hàm affine Hàm bậc hai Hàm mất mát bình phương nhỏ nhất Chuẩn Hàm chỉ thị Hàm hỗ trợ Hàm max Hàm một biến Hàm mũ: Với bất kỳ số thực MATH , MATH là hàm lồi. > MATH là hàm lồi với mọi MATH Hàm lũy thừa: Với MATH , tùy thuộc vào khoảng giá trị của MATH , MATH có thể là hàm lồi hoặc lõm. > MATH là hàm lồi trên MATH với mọi MATH hoặc MATH > MATH là hàm lõm trên MATH với mọi MATH Hàm affine Như đã đề cập trong 03-01-01 % multilang post url contents/chapter03/21-02-12-03 01 01 convex functions definition % , tất cả các hàm affine đều vừa lồi vừa lõm. Trên MATH và MATH : > MATH vừa lồi vừa lõm Trên MATH : > MATH vừa lồi vừa lõm Hàm bậc hai Xem xét hàm bậc hai MATH , trong đó MATH và MATH . Nếu MATH là ma trận nửa xác định dương, thì MATH là hàm lồi. Với MATH : > MATH là hàm lồi với MATH H: Tại sao MATH lồi nếu MATH là ma trận nửa xác định dương? Đáp: Trong hàm bậc hai, đạo hàm bậc hai là ma trận Hessian. Ma trận Hessian xác định độ cong của hàm, và nếu nó là nửa xác định dương, hàm sẽ cong lên trên. Tức là, độ cong theo hướng của các vector riêng của Hessian là không âm. Do đó, nếu đạo hàm bậc hai là nửa xác định dương, hàm sẽ lồi. Hàm mất mát bình phương nhỏ nhất Với bất kỳ ma trận MATH , MATH luôn là ma trận nửa xác định dương, có nghĩa là MATH luôn là hàm lồi. > MATH là hàm lồi với mọi MATH Chuẩn Tất cả các chuẩn trên MATH đều là hàm lồi. Gọi MATH là một chuẩn. Theo định nghĩa, > MATH \\begin aligned f \\theta x+ 1−\\theta y \\le \\theta f x + 1−\\theta f y , \\text với 0 \\le \\theta \\le 1, \\text cho mọi x,y \\in \\text dom f, \\end aligned MATH > MATH \\begin aligned \\|x\\| p = \\left \\sum i=1 ^ n x i^p\\right ^ 1/p \\text với p \\geq 1, \\|x\\| = \\max i=1,.., n |x i|\\\\ \\end aligned MATH Hàm chỉ thị Với một tập MATH cho trước, nếu hàm chỉ thị được định nghĩa là vô cực MATH cho các phần tử không thuộc MATH và bằng không cho các phần tử thuộc MATH , thì hàm chỉ thị là hàm lồi. Nói cách khác, bằng cách định nghĩa hàm có giá trị vô cực bên ngoài tập MATH và bằng không bên trong nó, tính chất lồi được bảo toàn. > MATH I C x = \\begin cases 0, & x \\in C\\\\ \\infty, & x \\notin C\\\\ \\end cases MATH Hàm hỗ trợ Xem xét một tập MATH . Bất kể MATH có lồi hay không, hàm hỗ trợ của MATH đều là hàm lồi. > MATH = MATH là hàm lồi Để tìm hiểu thêm về định nghĩa hàm hỗ trợ, tham khảo định nghĩa trên Wikipedia https://en.wikipedia.org/wiki/Support function . Hàm max Hàm max của một tập hữu hạn các hàm lồi là hàm lồi. Nói cách khác, đường bao trên được hình thành bằng cách nối các giá trị lớn nhất của một tập các hàm lồi là hàm lồi. > MATH là hàm lồi",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_01_02_examples_of_convex_function/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_01_03_key_properties_of_convex_functions",
    "title": "03-01-03 Các tính chất chính của hàm lồi",
    "chapter": "03",
    "order": 5,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Đặc trưng epigraph Như đã thảo luận trong Mục 1.2, MATH lồi khi và chỉ khi epigraph của nó là một tập lồi, và ngược lại. > MATH lồi MATH là một tập lồi Tập mức dưới lồi Nếu một hàm MATH lồi, các tập mức dưới của nó cũng lồi. > MATH , với mọi MATH Lưu ý Tập mức dưới Với một hàm MATH , MATH được gọi là tập mức dưới MATH . Đặc trưng bậc nhất Nếu một hàm MATH khả vi , điều sau đây đúng: Nếu miền MATH lồi và với mọi MATH , MATH , thì MATH lồi, và ngược lại. > MATH lồi MATH lồi, và MATH với mọi MATH Hình dưới đây minh họa điều kiện bậc nhất cho một hàm lồi khả vi MATH . Hình 1 Hàm Lồi 1 Điều kiện này được gọi là điều kiện đường tiếp tuyến hoặc điều kiện siêu phẳng tiếp tuyến trong không gian nhiều chiều . Nó cơ bản nói rằng một hàm lồi luôn nằm trên hoặc trên tất cả các đường tiếp tuyến hoặc siêu phẳng của nó. Bất kể bạn vẽ đường tiếp tuyến ở đâu trên hàm lồi, giá trị thực tế của hàm sẽ không bao giờ xuống dưới đường tiếp tuyến đó. Ví dụ Xem xét hàm lồi đơn giản MATH . Đạo hàm của nó là gradient trong 1D là MATH . Hãy chọn một điểm tùy ý MATH . Phương trình của đường tiếp tuyến với MATH tại MATH được cho bởi: MATH Thế MATH và MATH : MATH Điều kiện lồi yêu cầu rằng với mọi MATH : MATH MATH Hãy rút gọn vế phải: MATH MATH Bây giờ, chuyển tất cả các số hạng sang một bên: MATH Biểu thức này là một bình phương hoàn hảo: MATH Bất đẳng thức này luôn đúng với bất kỳ số thực MATH và MATH , vì bình phương của bất kỳ số thực nào luôn không âm. Điều này xác nhận rằng MATH thỏa mãn điều kiện đường tiếp tuyến và thực sự là một hàm lồi. Đặc trưng bậc hai Nếu một hàm MATH khả vi hai lần, nó có tính chất sau: - Nếu đạo hàm bậc hai MATH là nửa xác định dương với mọi MATH và MATH lồi, thì MATH lồi, và ngược lại. > MATH lồi MATH với mọi MATH : lồi - Nếu đạo hàm bậc hai MATH là xác định dương với mọi MATH , thì MATH lồi chặt. > nếu MATH với mọi MATH , thì MATH lồi chặt - Nói cách khác, độ cong luôn không âm. Bất đẳng thức Jensen Gọi MATH là một hàm lồi và MATH là các trọng số dương sao cho MATH . Khi đó, bất đẳng thức sau đây đúng: MATH Nếu một hàm MATH lồi, nó thỏa mãn bất đẳng thức sau: > MATH > Mở rộng : > MATH là một biến ngẫu nhiên được hỗ trợ trên MATH , thì MATH Hình 2 Bất đẳng thức Jensen 2 Bất đẳng thức Jensen có phải chính xác là định nghĩa của hàm lồi không? Câu trả lời là không—Bất đẳng thức Jensen là một hệ quả và sự tổng quát hóa của định nghĩa tính lồi, chứ không phải là định nghĩa. - Điều này mở rộng trường hợp hai điểm MATH trong định nghĩa thành bất kỳ số hữu hạn điểm và có thể được tổng quát hóa thêm thành tích phân cho các đo lường xác suất . - Tại sao đây là một sự tổng quát hóa: Định nghĩa cơ bản là cho hai điểm tổ hợp lồi nhị phân . Jensen áp dụng nó một cách lặp đi lặp lại cho nhiều điểm hơn. Ví dụ: - Với MATH , Jensen rút gọn chính xác thành định nghĩa. - Với MATH , bạn có thể áp dụng định nghĩa một cách đệ quy: Trước tiên kết hợp hai điểm, sau đó với điểm thứ ba. --- Ví dụ ngắn Hãy sử dụng hàm lồi MATH . Xem xét hai số: MATH và MATH . Chúng ta muốn so sánh MATH với MATH . 1. Tính hàm của giá trị trung bình: Giá trị trung bình của MATH và MATH là MATH . Áp dụng hàm: MATH . 2. Tính giá trị trung bình của các giá trị hàm: MATH . MATH . Giá trị trung bình của các giá trị hàm này là MATH . So sánh hai kết quả: MATH . Điều này minh họa bất đẳng thức Jensen: MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_01_03_key_properties_of_convex_functions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_02_operations_that_preserve_convexity",
    "title": "03-02 Các phép toán bảo toàn tính lồi",
    "chapter": "03",
    "order": 6,
    "owner": "Minjoo Lee",
    "lesson_type": "required",
    "content": "Phần này thảo luận các phép toán bảo toàn tính lồi của các hàm lồi. - Tổng trọng số không âm - Hợp thành với hàm affine - Maximum theo điểm - Hàm phối cảnh - Hàm tuyến tính-phân thức Tổng trọng số không âm Các hàm lồi có các tính chất sau đối với phép nhân vô hướng và phép cộng: • Khi một hàm lồi MATH tồn tại, nhân nó với bất kỳ số không âm nào vẫn cho ra một hàm lồi MATH . > MATH lồi MATH lồi với MATH • Khi hai hàm lồi MATH tồn tại, tổng của chúng cũng lồi. > MATH lồi MATH lồi • Tổng trọng số không âm của các hàm lồi MATH là hàm lồi. > MATH lồi MATH lồi, MATH Hợp thành 1. Hợp thành affine Nếu hàm MATH lồi, thì MATH cũng lồi. > MATH lồi MATH lồi 2. Hợp thành tổng quát Giả sử chúng ta có hàm MATH ánh xạ từ không gian MATH chiều sang không gian 1 chiều và hàm MATH ánh xạ từ không gian 1 chiều sang không gian 1 chiều. Hàm hợp thành MATH lồi hoặc lõm trong các trường hợp sau: > hợp thành của MATH và MATH : > MATH • Nếu MATH lồi, MATH lồi, và MATH không giảm, thì MATH lồi. • Nếu MATH lõm, MATH lồi, và MATH không tăng, thì MATH lồi. • Nếu MATH lõm, MATH lõm, và MATH không giảm, thì MATH lõm. • Nếu MATH lồi, MATH lõm, và MATH không tăng, thì MATH lõm. Lưu ý Tính đơn điệu của phần mở rộng giá trị mở rộng MATH phải được bảo toàn. Ví dụ • Nếu MATH lồi, thì MATH lồi. • Nếu MATH lõm và dương, thì MATH lồi. 3. Hợp thành vector Giả sử chúng ta có hàm MATH ánh xạ từ không gian MATH chiều sang không gian MATH chiều và hàm MATH ánh xạ từ không gian MATH chiều sang không gian 1 chiều. Khi đó hàm hợp thành MATH lồi hoặc lõm trong các trường hợp sau: >hợp thành của MATH và MATH : > MATH • Nếu MATH lồi và MATH lồi, và MATH không giảm theo từng đối số, thì MATH lồi. • Nếu MATH lồi và MATH lõm, và MATH không tăng theo từng đối số, thì MATH lõm. Ví dụ • Nếu MATH lõm và dương, thì MATH lõm. • Nếu MATH lồi, thì MATH lồi. Maximum theo điểm Maximum theo điểm của các hàm được định nghĩa như sau và là hàm lồi: 1. Maximum theo điểm > MATH là các hàm lồi MATH , MATH là hàm lồi 2. Supremum theo điểm Nếu MATH lồi theo MATH với mọi MATH , thì MATH lồi. > MATH lồi theo MATH với mọi MATH > MATH với MATH Nếu hàm MATH lồi, thì MATH cũng lồi. Ví dụ • Khi MATH dương, nếu MATH lồi, thì MATH lồi. • Logarithm âm Khi entropy tương đối MATH lồi trên MATH , thì MATH lồi. • Nếu MATH lồi, thì MATH lồi dưới điều kiện sau: > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_02_operations_that_preserve_convexity/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_03_the_conjugate_function",
    "title": "03-03 Hàm liên hợp",
    "chapter": "03",
    "order": 7,
    "owner": "Minjoo Lee",
    "lesson_type": "required",
    "content": "Phần này giới thiệu hàm liên hợp còn gọi là liên hợp lồi hoặc liên hợp Fenchel , một khái niệm cơ bản trong giải tích lồi và lý thuyết đối ngẫu, cung cấp một công cụ mạnh mẽ để biến đổi các bài toán tối ưu. Định nghĩa và Nền tảng Toán học Với một hàm MATH , hàm liên hợp MATH được định nghĩa là: MATH trong đó MATH biểu thị supremum cận trên nhỏ nhất trên tất cả MATH trong miền xác định của MATH . Giải thích Hình học Hàm liên hợp có một giải thích hình học đẹp: - MATH biểu thị khoảng cách tối đa giữa hàm tuyến tính MATH và hàm gốc MATH - Về mặt hình học, nó đo lường mức độ siêu phẳng với độ dốc MATH có thể được \"nâng lên trên\" đồ thị của MATH - Liên hợp biến đổi hàm từ \"không gian nguyên thủy\" sang \"không gian đối ngẫu\" của các độ dốc Tại sao nó quan trọng? Hàm liên hợp được sử dụng để: 1. Biến đổi các bài toán tối ưu thành các bài toán đối ngẫu tương ứng 2. Cung cấp các công cụ phân tích cho lý thuyết đối ngẫu được đề cập trong Chương 11 3. Cho phép thế trực tiếp trong Đối ngẫu Lagrange mà không cần lấy đạo hàm rõ ràng 4. Thiết lập kết nối giữa các nghiệm tối ưu nguyên thủy và đối ngẫu Hình 1 Hàm liên hợp 2 Các Tính chất Cơ bản Hàm liên hợp có nhiều tính chất đáng chú ý khiến nó trở thành một công cụ phân tích mạnh mẽ: 1. Tính chất Lồi - MATH luôn lồi , bất kể MATH có lồi hay không - Điều này là do MATH là supremum theo điểm của các hàm affine MATH - Supremum của bất kỳ tập hợp nào các hàm lồi affine đều lồi 2. Bất đẳng thức Fenchel Với bất kỳ MATH và MATH : MATH Bất đẳng thức cơ bản này thiết lập mối quan hệ cận dưới giữa một hàm và liên hợp của nó. 3. Liên hợp của Liên hợp Liên hợp kép - Nói chung: MATH liên hợp kép là một cận dưới - Nếu MATH đóng và lồi : MATH phục hồi hoàn hảo - Tính chất này rất quan trọng cho lý thuyết đối ngẫu 4. Mối quan hệ Dưới vi phân Nếu MATH đóng và lồi, thì với bất kỳ MATH : MATH Điều này thiết lập một sự đối xứng đẹp giữa không gian nguyên thủy và đối ngẫu. Các Ví dụ Chi tiết Ví dụ 1: Logarithm Âm Xem xét MATH với MATH . Tính toán từng bước: MATH Để tìm supremum, chúng ta lấy đạo hàm theo MATH : MATH Điều này cho ta MATH chỉ hợp lệ khi MATH : Supremum là MATH Kết quả: MATH f^ y = \\begin cases 0, & \\text nếu \\lvert y \\rvert \\leq 1 \\\\ +\\infty, & \\text nếu \\lvert y \\rvert > 1 \\end cases MATH Đây là hàm chỉ thị của khoảng MATH . Ví dụ 4: Hàm Mũ Xem xét MATH với MATH . MATH Đặt đạo hàm bằng không: MATH , vậy MATH hợp lệ với MATH . Kết quả: MATH f^ y = \\begin cases y \\log y - y, & \\text nếu y > 0 \\\\ 0, & \\text nếu y = 0 \\\\ +\\infty, & \\text nếu y 🎯 Khởi động Công cụ Khám phá Hàm Liên hợp Tương tác Công cụ tương tác cho phép bạn: - Trực quan hóa các loại hàm khác nhau và liên hợp của chúng cạnh nhau - Điều chỉnh tham số để xem chúng ảnh hưởng đến liên hợp như thế nào - Khám phá các đường tiếp tuyến để hiểu giải thích hình học - So sánh nhiều ví dụ với giải thích toán học chi tiết Tóm tắt và Những Điểm Chính Hàm liên hợp là một công cụ toán học mạnh mẽ: 1. Biến đổi hàm từ không gian nguyên thủy sang không gian đối ngẫu thông qua phép toán MATH 2. Luôn tạo ra các hàm lồi , bất kể tính lồi của hàm gốc 3. Thiết lập các bất đẳng thức cơ bản như bất đẳng thức Fenchel: MATH 4. Kích hoạt lý thuyết đối ngẫu bằng cách kết nối các bài toán tối ưu nguyên thủy và đối ngẫu 5. Cung cấp các công cụ phân tích để giải các bài toán tối ưu phức tạp Hiểu biết về hàm liên hợp là thiết yếu cho: - Lý thuyết tối ưu lồi và phát triển thuật toán - Đối ngẫu Lagrange và xây dựng bài toán đối ngẫu - Các phương pháp tối ưu hiện đại như thuật toán gần kề - Phân tích biến phân và kinh tế toán học Trực giác hình học về \"khoảng cách tối đa giữa hàm tuyến tính và phi tuyến\" cung cấp sự hiểu biết trực quan bổ sung cho định nghĩa phân tích, làm cho khái niệm trừu tượng này dễ tiếp cận hơn cho người học.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_03_the_conjugate_function/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_04_00_Quasiconvex_functions",
    "title": "03-04 Hàm giả lồi",
    "chapter": "03",
    "order": 8,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Phần này giới thiệu các hàm giả lồi, định nghĩa, ví dụ và các tính chất cơ bản của chúng.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_04_00_Quasiconvex_functions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_04_01_quasiconvex_functions_definition_and_examples",
    "title": "03-04-01 Hàm giả lồi: định nghĩa và ví dụ",
    "chapter": "03",
    "order": 9,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Một hàm MATH là giả lồi nếu tất cả các tập mức dưới MATH đều lồi với mọi MATH . Các hàm giả lồi tổng quát hóa các hàm lồi và xuất hiện thường xuyên trong các bài toán tối ưu. Định nghĩa Một hàm MATH được gọi là giả lồi hoặc đơn môđ nếu miền xác định MATH và tất cả các tập mức dưới MATH xem 03-01-03 % multilang post url contents/chapter03/21-02-12-03 01 03 key properties of convex functions % đều lồi. > MATH là giả lồi nếu MATH và > MATH với MATH đều lồi. Nếu hàm MATH là giả lồi, thì MATH được gọi là giả lõm . > MATH là giả lõm nếu MATH và > MATH với MATH đều lồi. Khi MATH vừa giả lồi vừa giả lõm, nó được gọi là giả tuyến tính , và miền xác định của hàm và tất cả các tập mức MATH đều lồi. Hình dưới đây cho thấy một ví dụ về hàm giả lồi. Hình 1 hàm giả lồi trên R 1 Với MATH , tập mức dưới MATH là MATH lồi, cụ thể là khoảng MATH . Tập mức dưới MATH là MATH là khoảng MATH . Các hàm lồi có các tập mức dưới lồi và là giả lồi, nhưng điều ngược lại không đúng. > MATH : lồi MATH MATH : giả lồi Ví dụ Hãy xem xét các ví dụ khác nhau về hàm giả lồi. Logarithm MATH trên MATH là giả lồi. Nó cũng là giả lõm, nên nó có tính chất giả tuyến tính. > MATH trên MATH Hàm lấy phần nguyên trên Hàm lấy phần nguyên trên là giả lồi và cũng là giả lõm . > MATH Độ dài của vector Nếu chúng ta định nghĩa độ dài của MATH là chỉ số lớn nhất của các thành phần khác không, > MATH Điều này thỏa mãn > MATH với MATH trên MATH điều này định nghĩa một không gian con, nên nó là giả lồi. Lưu ý: Một không gian con đóng dưới phép cộng và nhân vô hướng. Bất kỳ không gian con nào của MATH cũng là một tập lồi. Hàm tuyến tính-phân thức Dưới các điều kiện sau, hàm MATH vừa giả lồi vừa giả lõm, tức là giả tuyến tính. > MATH với MATH Hàm tỉ lệ khoảng cách Với MATH , khi hàm MATH được định nghĩa như sau, biểu thị tỉ lệ của khoảng cách Euclidean từ MATH đến MATH và từ MATH đến MATH , MATH là giả lồi trên nửa không gian MATH . > MATH Dưới điều kiện MATH , điều này trở thành một tập lồi dưới dạng một quả cầu Euclidean, nên MATH là giả lồi.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_04_01_quasiconvex_functions_definition_and_examples/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_04_02_basic_properties_of_quasiconvex_functions",
    "title": "03-04-02 Các tính chất cơ bản của hàm giả lồi",
    "chapter": "03",
    "order": 10,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Phần này đề cập các tính chất cơ bản của hàm giả lồi, bao gồm mối quan hệ của chúng với hàm lồi và hành vi của chúng dưới các phép toán khác nhau. Bất đẳng thức Jensen biến đổi Các hàm giả lồi có thể được định nghĩa thông qua bất đẳng thức Jensen như sau: > MATH với mọi MATH Hình dưới đây cho thấy rằng nếu hàm MATH là giả lồi, thì giá trị của MATH dọc theo đoạn thẳng giữa hai điểm không vượt quá giá trị lớn nhất của MATH tại các điểm cuối. Fig1 hàm giả lồi trên MATH . Các giá trị của MATH giữa MATH và MATH nhỏ hơn MATH . Hàm giả lồi trên MATH Một hàm liên tục MATH là giả lồi khi và chỉ khi nó thỏa mãn ít nhất một trong các điều kiện sau: • MATH không giảm • MATH không tăng • Tồn tại một điểm MATH sao cho MATH không tăng trên MATH và không giảm trên MATH . Fig2 hàm giả lồi trên MATH . Nó không tăng với MATH trong đó MATH , và không giảm với MATH trong đó MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_04_02_basic_properties_of_quasiconvex_functions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_04_03_differentiable_quasiconvex_functions",
    "title": "03-04-03 Hàm giả lồi khả vi",
    "chapter": "03",
    "order": 11,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Phần này thảo luận các tính chất và đặc trưng của các hàm giả lồi khả vi. Điều kiện bậc nhất Gọi MATH là một hàm khả vi. Nếu MATH lồi và điều kiện sau được thỏa mãn, thì MATH là giả lồi. > MATH là giả lồi MATH MATH với mọi MATH Fig1 Ba đường mức của một hàm giả lồi MATH . MATH là vector pháp tuyến định nghĩa siêu phẳng hỗ trợ của tập mức dưới MATH tại MATH . Điều kiện bậc nhất cho tính giả lồi có vẻ tương tự như đặc trưng bậc nhất của tính lồi xem 03-01-03 % multilang post url contents/chapter03/21-02-12-03 01 03 key properties of convex functions % , nhưng có những khác biệt quan trọng. Ví dụ, nếu MATH lồi và MATH , thì MATH là điểm cực tiểu toàn cục của MATH , nhưng điều này không luôn đúng cho các hàm giả lồi. Điều kiện bậc hai Khi MATH khả vi hai lần, các điều kiện bậc hai được áp dụng. Nếu MATH là giả lồi, thì với mọi MATH và mọi MATH , điều sau đây đúng: > MATH là giả lồi, MATH với mọi MATH , mọi MATH Với các hàm giả lồi trên MATH : > MATH là giả lồi, MATH Tức là, nếu tồn tại bất kỳ điểm nào có độ dốc bằng không, giá trị đạo hàm bậc hai là không âm. Quay lại với MATH , điều kiện bậc hai cũng thỏa mãn các tính chất sau: 1 Khi MATH , chúng ta phải luôn có MATH . 2 Nếu MATH , thì MATH , trong đó MATH hoạt động như ma trận Hessian và là nửa xác định dương trên không gian con MATH chiều MATH . Không gian con MATH chiều MATH có nghĩa là không gian con MATH chiều vuông góc với MATH . Nó có MATH chiều vì MATH là gradient của hàm MATH chiều MATH , làm giảm chiều đi một.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_04_03_differentiable_quasiconvex_functions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_04_04_operations_that_preserve_quasiconvexity",
    "title": "03-04-04 Các phép toán bảo toàn tính giả lồi",
    "chapter": "03",
    "order": 12,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Phần này thảo luận các phép toán bảo toàn tính giả lồi của các hàm. Maximum trọng số không âm Khi MATH là một hàm giả lồi, maximum trọng số không âm MATH là giả lồi. > MATH với MATH là giả lồi Khái niệm này có thể được mở rộng như sau: > MATH với MATH , >trong đó MATH là giả lồi theo MATH với mọi MATH . Hợp thành Nếu MATH là giả lồi và MATH không giảm, thì hợp thành MATH thỏa mãn tính giả lồi. > MATH là giả lồi nếu MATH không giảm và MATH là giả lồi. Hợp thành một hàm giả lồi với các biến đổi affine hoặc tuyến tính-phân thức cho ra một hàm giả lồi. Nếu MATH là giả lồi, thì MATH cũng là giả lồi, và MATH cũng là giả lồi trên tập MATH . Cực tiểu hóa Nếu MATH thỏa mãn tính giả lồi và MATH là một tập lồi, thì điều kiện sau đây đúng: > MATH là giả lồi nếu MATH là giả lồi theo MATH và MATH là một tập lồi. Biểu diễn thông qua họ các hàm lồi Các tập mức dưới của một hàm giả lồi MATH có thể được biểu diễn bằng các bất đẳng thức của các hàm lồi. Một họ các hàm lồi là MATH với MATH , được định nghĩa như sau: > MATH Tức là, tập mức dưới MATH của hàm giả lồi MATH trở thành tập mức dưới 0 của hàm lồi MATH . Ở đây, MATH biểu thị chỉ số của hàm lồi MATH . Với mọi MATH , điều sau được thỏa mãn: > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_04_04_operations_that_preserve_quasiconvexity/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_05_log_concave_and_log_convex_functions",
    "title": "03-05 Hàm log-lõm và log-lồi",
    "chapter": "03",
    "order": 13,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Phần này giới thiệu các hàm log-lõm và log-lồi, quan trọng trong xác suất, thống kê và tối ưu hóa. Định nghĩa Các định nghĩa của hàm log-lõm và log-lồi như sau. MATH là Lõm logarithm hoặc log-lõm Nếu MATH với mọi MATH và MATH là lõm, thì MATH được gọi là lõm logarithm hoặc log-lõm. > MATH là log-lõm với MATH cho mọi MATH : > MATH với MATH . MATH là Lồi logarithm hoặc log-lồi Nếu MATH với mọi MATH và MATH là lồi, thì MATH được gọi là lồi logarithm hoặc log-lồi. Do đó, nếu MATH là log-lồi, thì MATH là log-lõm. > MATH là log-lồi với MATH cho mọi MATH MATH là log-lõm. Đôi khi tiện lợi khi cho phép giá trị MATH bằng 0, trong trường hợp này MATH . Trong các trường hợp như vậy, nếu hàm giá trị mở rộng MATH là lõm, thì MATH có thể được gọi là log-lõm. Các hàm log-lồi và log-lõm lần lượt là giả lồi và giả lõm, vì logarithm là hàm đơn điệu tăng. Ví dụ Hàm affine Nếu MATH được định nghĩa như sau, thì nó là log-lõm. > MATH trên MATH Lũy thừa MATH trên MATH là log-lồi khi MATH và log-lõm khi MATH . Hàm mũ MATH vừa là log-lồi vừa là log-lõm. Hàm phân phối tích lũy của mật độ Gauss MATH là log-lõm. Hàm Gamma MATH là log-lồi với MATH . Định thức MATH là log-lõm trên MATH . Định thức chia vết MATH là log-lõm trên MATH . Tính chất Các hàm log-lồi / lõm khả vi hai lần Nếu MATH khả vi hai lần và MATH lồi, thì phương trình sau đây đúng: > MATH MATH là log-lồi MATH MATH với mọi MATH , và MATH là log-lõm MATH MATH với mọi MATH . Nhân Tính log-lồi và log-lõm đóng dưới phép nhân và nhân với số dương. Nếu MATH và MATH là log-lõm, thì tích theo điểm MATH cũng là log-lõm. Điều này là vì MATH , và cả MATH và MATH đều là các hàm lõm. Cộng và Tích phân Nói chung, tổng của các hàm log-lõm không phải là log-lõm. Tuy nhiên, tính log-lồi được bảo toàn dưới phép cộng. Ví dụ, gọi MATH và MATH là các hàm log-lồi, tức là MATH và MATH là lồi. Bằng các quy tắc hợp thành cho hàm lồi, điều sau đây đúng: > MATH Điều này là lồi. Vế trái là lồi vì: 1. các hàm log-lồi là lồi, 2. áp dụng hàm mũ cho hàm lồi bảo toàn tính lồi, 3. tổng của các hàm lồi là lồi, và 4. logarithm của hàm lồi là lồi. Do đó, toàn bộ kết quả là lồi. Kết luận, tổng của hai hàm log-lồi là log-lồi. Tổng quát hóa điều này, nếu MATH là log-lồi với mọi MATH , thì MATH là log-lồi. > MATH Tích phân của các hàm log-lõm Trong một số trường hợp, tính log-lõm cũng được bảo toàn dưới phép tích phân. Nếu MATH là log-lõm, thì MATH là một hàm log-lõm với MATH . > MATH là log-lõm MATH MATH là log-lõm , MATH với mọi MATH . Dựa trên điều này, chúng ta có thể xác nhận rằng phân phối biên của một mật độ xác suất log-lõm là log-lõm. Tính log-lõm cũng đóng dưới các phép toán tích chập. Nếu MATH và MATH là log-lõm trên MATH , thì tích chập của chúng cũng là log-lõm. > MATH , MATH là log-lõm trên MATH là log-lõm.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_05_log_concave_and_log_convex_functions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_06_convexity_with_respect_to_generalized_inequalities",
    "title": "03-06 Tính lồi đối với bất đẳng thức tổng quát",
    "chapter": "03",
    "order": 14,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Phần này thảo luận tính lồi đối với bất đẳng thức tổng quát, mở rộng khái niệm tính lồi vượt ra ngoài các hàm giá trị thực chuẩn. Trong các không gian khác với MATH , chúng ta sử dụng định nghĩa của nón cho các biểu thức bất đẳng thức tổng quát mở rộng khái niệm thứ tự thường được sử dụng trong không gian MATH xem 02-01-04 % multilang post url contents/chapter02/21-02-08-02 01 04 Convex cone % . Trong phần này, chúng ta xem xét các khái niệm về tính đơn điệu và tính lồi mở rộng ra ngoài không gian MATH sử dụng khái niệm nón. Tính đơn điệu đối với bất đẳng thức tổng quát Giả sử MATH là một nón thích hợp được biểu thị bởi MATH . Một nón lồi MATH là một nón thích hợp nếu nó thỏa mãn các điều kiện sau: • MATH đóng chứa biên của nó • MATH rắn có nội tâm khác rỗng • MATH nhọn không chứa đường thẳng Chúng ta định nghĩa không giảm theo MATH như sau: > MATH là không giảm theo MATH nếu MATH Cũng vậy, khi điều kiện sau được thỏa mãn, chúng ta nói nó là tăng theo MATH : > MATH là tăng theo MATH nếu MATH với mọi MATH , thì nó là tăng. Tương tự, tính đơn điệu có thể được biểu thị như một khái niệm mở rộng trong bất đẳng thức tổng quát. Khi miền là lồi, một hàm khả vi MATH không giảm theo MATH có nghĩa là thỏa mãn phương trình sau. Lưu ý rằng khác với vô hướng đơn giản, gradient MATH phải không âm trong bất đẳng thức đối ngẫu. > Một hàm khả vi MATH không giảm theo MATH MATH MATH với mọi MATH Nếu điều kiện sau được thỏa mãn, MATH được gọi là tăng theo MATH . Như với vô hướng, điều ngược lại không đúng. > MATH với mọi MATH MATH MATH tăng theo MATH . Tính lồi đối với bất đẳng thức tổng quát Gọi MATH là một nón thích hợp liên kết với bất đẳng thức tổng quát MATH . Khi đó, nếu MATH được gọi là lồi theo MATH với mọi MATH và MATH , bất đẳng thức sau đây đúng: > MATH là lồi theo MATH MATH MATH với MATH f \\theta x + 1 - \\theta y \\prec K \\theta f x + 1 - \\theta f y MATH x \\neq y MATH 0 Các hàm lồi theo MATH khả vi Nếu một hàm khả vi MATH là lồi theo MATH và miền hàm là lồi, thì phương trình sau đây đúng: > MATH với mọi MATH Ở đây, MATH là đạo hàm hoặc ma trận Jacobian của MATH tại điểm MATH . Nếu MATH là lồi chặt theo MATH và miền hàm là lồi, thì phương trình sau đây đúng: > MATH với mọi MATH , MATH Định lý hợp thành Nhiều kết quả từ hợp thành có thể được tổng quát hóa cho tính lồi theo MATH . Ví dụ, nếu MATH là lồi theo MATH , MATH là lồi, và phần mở rộng giá trị mở rộng MATH của MATH là không giảm theo MATH , thì MATH là lồi. Điều này tổng quát hóa sự thật rằng hợp thành của một hàm lồi với một hàm lồi không giảm là lồi. Điều kiện MATH không giảm theo MATH có nghĩa là MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_06_convexity_with_respect_to_generalized_inequalities/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter03/03_07_euclidean_norm_convexity_proof",
    "title": "03-01-04 Chuẩn Euclidean - L2 - là Lồi",
    "chapter": "03",
    "order": 15,
    "owner": "AI Assistant",
    "lesson_type": "",
    "content": "Chuẩn Euclidean còn gọi là chuẩn MATH của một vector MATH được định nghĩa là: MATH Chúng ta sẽ chứng minh rằng hàm này là lồi sử dụng ba phương pháp khác nhau: 1. Chứng minh dựa trên định nghĩa sử dụng bất đẳng thức Jensen 2. Kiểm tra đạo hàm bậc hai phân tích Hessian 3. Phương pháp bất đẳng thức tam giác Phương pháp 1: Chứng minh Dựa trên Định nghĩa Định lý : Chuẩn Euclidean MATH là lồi trên MATH . Chứng minh : Để chứng minh tính lồi, chúng ta cần chỉ ra rằng với bất kỳ MATH và MATH : MATH Let MATH . Then: MATH \\begin align \\|z\\| 2^2 &= \\|\\theta x + 1-\\theta y\\| 2^2 \\\\ &= \\theta x + 1-\\theta y ^T \\theta x + 1-\\theta y \\\\ &= \\theta^2 x^T x + 2\\theta 1-\\theta x^T y + 1-\\theta ^2 y^T y \\\\ &= \\theta^2 \\|x\\| 2^2 + 2\\theta 1-\\theta x^T y + 1-\\theta ^2 \\|y\\| 2^2 \\end align MATH By the Cauchy-Schwarz inequality : MATH Therefore: MATH The right-hand side can be factored as: MATH Taking square roots of both sides: MATH This proves that the Euclidean norm is convex. MATH Method 2: Second Derivative Test Hessian Analysis For twice-differentiable functions, we can use the second derivative test : a function is convex if its Hessian matrix is positive semidefinite. Analysis : The Euclidean norm MATH is not differentiable at MATH . However, for MATH , we can compute: MATH MATH The Hessian matrix is: MATH Verification of positive semidefiniteness : For any vector MATH : MATH By Cauchy-Schwarz inequality: MATH Therefore: MATH This shows MATH , confirming convexity for MATH . Method 3: Triangle Inequality Approach Alternative Proof using Minkowski Inequality : The Euclidean norm satisfies the triangle inequality : MATH For convexity, let MATH and MATH where MATH : MATH This directly establishes the convexity condition. Key Properties and Applications Properties of Euclidean Norm Convexity 1. Strict Convexity : The Euclidean norm is actually strictly convex on any line not passing through the origin. 2. Homogeneity : MATH for any scalar MATH . 3. Subadditivity : MATH Triangle inequality . Applications in Optimization The convexity of the Euclidean norm has important implications: 1. Least Squares Problems : The objective function MATH is convex. 2. Regularization : MATH -regularization terms like MATH preserve convexity. 3. Constrained Optimization : Norm constraints MATH define convex feasible sets. Conclusion We have proven that the Euclidean norm is convex using three different approaches: 1. Direct definition : Using Jensen's inequality and Cauchy-Schwarz 2. Second derivative test : Showing the Hessian is positive semidefinite 3. Triangle inequality : Leveraging the fundamental norm property This convexity property is fundamental in optimization theory and has wide-ranging applications in machine learning, signal processing, and numerical analysis. The interactive visualization above demonstrates how the convexity condition MATH holds for any choice of points and convex combination parameter MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter03/03_07_euclidean_norm_convexity_proof/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter04/04_00_Convex_optimization_basics",
    "title": "04 Cơ bản về tối ưu hóa lồi",
    "chapter": "04",
    "order": 1,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Cơ bản về Tối ưu hóa Lồi Chương này giới thiệu các tính chất chính của các bài toán lồi và một số kỹ thuật thường được sử dụng để giải chúng.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter04/04_00_Convex_optimization_basics/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter04/04_01_Basic_terminology",
    "title": "04-01 Thuật ngữ cơ bản",
    "chapter": "04",
    "order": 2,
    "owner": "YoungJae Choung",
    "lesson_type": "required",
    "content": "Cơ bản về Tối ưu hóa Lồi Hãy cùng ôn tập các thuật ngữ cơ bản được sử dụng trong các bài toán tối ưu hóa lồi. Một bài toán tối ưu hóa lồi được định nghĩa như sau: > MATH \\begin aligned &\\text minimize x \\in D && f x \\\\ &\\text subject to && g i x \\leq 0, \\quad i = 1, \\dotsc, m \\\\ &&& h j x = 0, \\quad j = 1, \\dotsc, r ,\\\\\\\\ \\end aligned MATH >trong đó MATH và MATH , MATH đều là hàm lồi, > MATH đều là hàm affine, >và miền tối ưu hóa là MATH . MATH được gọi là hàm tiêu chí hoặc hàm mục tiêu . MATH được gọi là hàm ràng buộc bất đẳng thức . MATH được gọi là hàm ràng buộc đẳng thức . Nếu MATH và MATH với mọi MATH và MATH với mọi MATH , thì MATH là một điểm khả thi . Với tất cả các điểm khả thi MATH , giá trị nhỏ nhất của MATH được gọi là giá trị tối ưu , ký hiệu là MATH . Nếu MATH khả thi và MATH , thì MATH được gọi là tối ưu , một nghiệm , hoặc một điểm cực tiểu . Nếu MATH khả thi và MATH , thì MATH được gọi là MATH -dưới tối ưu . Nếu MATH khả thi và MATH , thì MATH hoạt động tại MATH . Một bài toán cực tiểu hóa lồi có thể được chuyển đổi thành bài toán cực đại hóa lõm. > MATH \\begin aligned &\\text maximize x \\in D &&-f x \\\\ &\\text subject to &&g i x \\leq 0, i = 1, .., m\\\\ &&&h j x = 0, j = 1, \\dotsc, r,\\\\\\\\ \\end aligned MATH >trong đó MATH và MATH , MATH đều là hàm lồi, > MATH đều là hàm affine, >và miền tối ưu hóa là MATH . Tập Khả thi Tập khả thi còn được gọi là miền khả thi hoặc không gian nghiệm là tập hợp tất cả các điểm khả thi. Nó biểu diễn tất cả các lựa chọn được phép bởi các điều kiện của bài toán. Tập khả thi, thường được ký hiệu bởi MATH hoặc MATH , được định nghĩa như sau: > MATH Tính chất của Tập Khả thi 1. Tính lồi: Nếu tất cả các hàm ràng buộc bất đẳng thức MATH đều lồi và tất cả các hàm ràng buộc đẳng thức MATH đều affine tuyến tính , thì tập khả thi MATH là một tập lồi . Tính chất này rất quan trọng trong tối ưu hóa lồi, vì nó đảm bảo rằng bất kỳ cực trị địa phương nào cũng là cực trị toàn cục. 2. Tính bị chặn: Một tập khả thi có thể bị chặn được bao quanh trong một vùng hữu hạn hoặc không bị chặn mở rộng vô hạn theo một hướng nào đó . 3. Tập rỗng: Có thể tập khả thi là tập rỗng MATH . Điều này có nghĩa là không có điểm nào thỏa mãn tất cả các ràng buộc đã cho, và bài toán tối ưu hóa được gọi là không khả thi . 4. Đa diện/Đa hình Polytope/Polyhedron : Trong quy hoạch tuyến tính, nếu tập khả thi khác rỗng và bị chặn, nó được gọi là đa diện polytope . Nếu nó khác rỗng nhưng có thể không bị chặn, nó được gọi là đa hình polyhedron . Cả hai đều là tập lồi. 5. Đỉnh Điểm cực trị : Đối với các bài toán quy hoạch tuyến tính, nếu một nghiệm tối ưu tồn tại, nó luôn có thể được tìm thấy tại một trong các đỉnh còn được gọi là điểm cực trị hoặc điểm góc của tập khả thi. Đây là cơ sở cho các thuật toán như phương pháp Simplex.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter04/04_01_Basic_terminology/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter04/04_02_Convex_solution_sets",
    "title": "04-02 Tập nghiệm lồi",
    "chapter": "04",
    "order": 3,
    "owner": "YoungJae Choung",
    "lesson_type": "required",
    "content": "Hãy cùng tìm hiểu các tính chất của tập nghiệm lồi. Gọi MATH là tập nghiệm của một bài toán lồi: > MATH \\begin aligned X opt = &\\text arg \\min x &&f x \\\\ &\\text subject to &&g i x \\leq 0, i = 1, .., m \\\\ &&&h j x = 0, j = 1, .., r \\\\\\\\ \\end aligned MATH Tính chất chính 1 > MATH là một tập lồi. Chứng minh > Nếu MATH và MATH là các nghiệm: > 1. Tập miền MATH là lồi, nên với MATH , MATH . > 2. MATH và MATH là các hàm lồi và affine, nên các điều kiện sau được thỏa mãn: MATH \\begin aligned g i tx + 1-t y \\leq tg i x + 1-t g i y \\leq 0, \\\\ h j tx + 1-t y = th j x + 1-t h j y = 0 \\\\ \\end aligned MATH > 3. MATH là hàm lồi, nên: > >\\begin aligned > f tx+ 1-t y &\\leq tf x + 1-t f y \\\\ > = tf^ \\star + 1-t f^ \\star \\\\ > = f^ \\star >\\end aligned >trong đó MATH là giá trị nhỏ nhất. >Vậy, MATH cũng là một nghiệm. Giải thích hình học Trong một hàm lồi, bất kỳ cực trị địa phương nào cũng là cực trị toàn cục. Nếu tập nghiệm chứa nhiều phần tử, nó phải có dạng như sau: Hình 1 Giải thích hình học về tính lồi của tập nghiệm Tính chất chính 2 >Nếu MATH là hàm lồi chặt, thì nghiệm là duy nhất. Tức là, MATH chỉ chứa một phần tử. MATH là hàm lồi chặt có nghĩa là MATH luôn thỏa mãn tính chất sau: > MATH f tx + 1-t y > MATH Tức là, MATH là hàm lồi hướng xuống không có đoạn phẳng, và nghiệm của MATH là duy nhất.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter04/04_02_Convex_solution_sets/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter04/04_03_Optimality_conditions",
    "title": "04-03 Điều kiện tối ưu",
    "chapter": "04",
    "order": 4,
    "owner": "YoungJae Choung",
    "lesson_type": "required",
    "content": "Điều kiện tối ưu bậc nhất Để tìm hiểu thêm về hàm lồi, xem Chương 3: Các Tính chất Chính của Hàm Lồi % multilang post url contents/chapter03/20-02-08-03 01 key properties of convex functions % . > MATH \\begin aligned &\\min x &&f x \\\\ &\\text subject to &&x \\in C \\end aligned MATH Đối với một bài toán lồi mà hàm mục tiêu MATH khả vi , điều kiện sau là cần và đủ cho một điểm tối ưu MATH : > MATH \\nabla f x ^ T y-x \\geq 0 \\\\ > \\text với mọi y \\in C MATH Đây được gọi là điều kiện bậc nhất cho tính tối ưu . MATH định nghĩa một siêu phẳng đi qua MATH trong tập MATH , và MATH chỉ hướng di chuyển về phía điểm tối ưu MATH . Nếu điều kiện trên được thỏa mãn, tập MATH nằm trong nửa không gian đối diện với MATH , nên MATH là một điểm tối ưu. Hình 1 Giải thích hình học về điều kiện bậc nhất cho tính tối ưu 3 Trường hợp đặc biệt quan trọng Khi MATH tối ưu hóa không ràng buộc , điều kiện tối ưu là: > MATH Trong trường hợp này, MATH chỉ về phía điểm tối ưu MATH , và MATH có nghĩa là không còn hướng nào để di chuyển để giảm MATH tại MATH . --- Nền tảng Toán học Trong khi các điều kiện bậc nhất sờ dụng gradient MATH , các điều kiện bậc hai sử dụng ma trận Hessian : MATH H f x = \\nabla^2 f x = \\begin bmatrix \\frac \\partial^2 f \\partial x 1^2 & \\frac \\partial^2 f \\partial x 1 \\partial x 2 & \\cdots & \\frac \\partial^2 f \\partial x 1 \\partial x n \\\\ \\frac \\partial^2 f \\partial x 2 \\partial x 1 & \\frac \\partial^2 f \\partial x 2^2 & \\cdots & \\frac \\partial^2 f \\partial x 2 \\partial x n \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac \\partial^2 f \\partial x n \\partial x 1 & \\frac \\partial^2 f \\partial x n \\partial x 2 & \\cdots & \\frac \\partial^2 f \\partial x n^2 \\end bmatrix MATH Ma trận Hessian nắm bắt độ cong của hàm tại điểm MATH , cung cấp thông tin về hình dạng cục bộ của hàm mục tiêu. Điều kiện Tối ưu Bậc Hai Xem xét bài toán tối ưu hóa không ràng buộc: MATH trong đó MATH khả vi liên tục bậc hai. Điều kiện Cần Bậc Hai Nếu MATH là cực tiểu địa phương của MATH , thì: 1. Điều kiện cần bậc nhất : MATH 2. Điều kiện cần bậc hai : MATH nửa xác định dương Điều kiện Đủ Bậc Hai Nếu tại điểm MATH : 1. MATH điều kiện bậc nhất 2. MATH xác định dương Thì MATH là cực tiểu địa phương chặt của MATH . Hiểu về Tính Xác Định Dương Một ma trận đối xứng MATH là: - Xác định dương MATH nếu MATH với mọi MATH - Nửa xác định dương MATH nếu MATH với mọi MATH Các kiểm tra thực tế cho tính xác định dương: 1. Kiểm tra giá trị riêng : Tất cả giá trị riêng đều dương 2. Thứ định thức chính : Tất cả thứ định thức chính đều dương 3. Phân tích Cholesky : MATH tồn tại với MATH tam giác dưới Giải thích Hình học Các điều kiện bậc hai cung cấp thông tin về độ cong tại điểm tới hạn: - MATH : Hàm cong lên trên theo mọi hướng → cực tiểu địa phương chặt - MATH : Hàm cong xuống dưới theo mọi hướng → cực đại địa phương chặt - MATH : Độ cong không âm → có thể là cực tiểu - Hessian bất định : Độ cong hỗn hợp → điểm yên ngựa Hình 1 Giải thích hình học về các điều kiện bậc hai Các Ví dụ Chi tiết Ví dụ 1: Hàm Bậc Hai Xem xét MATH Bước 1: Tìm điểm tới hạn MATH Giải: MATH Bước 2: Tính Hessian MATH Bước 3: Kiểm tra tính xác định dương - Giá trị riêng: MATH , MATH - Thứ định thức chính: MATH , MATH Kết luận : MATH → MATH là cực tiểu địa phương chặt. Example 2: Non-Convex Function Consider MATH Step 1: Find critical points MATH Critical points: MATH , MATH , MATH , MATH Step 2: Analyze MATH MATH Conclusion : MATH is a strict local maximum. Step 3: Analyze MATH MATH Conclusion : MATH is a strict local minimum. Example 3: Saddle Point Consider MATH Analysis at MATH : - MATH ✓ - MATH indefinite Conclusion : MATH is a saddle point neither minimum nor maximum . Constrained Optimization: Second-Order Conditions For constrained problems: MATH The bordered Hessian of the Lagrangian is used: MATH Second-order sufficient condition : The bordered Hessian has the correct inertia number of negative eigenvalues equals the number of constraints . Comparison: First vs Second-Order Conditions | Aspect | First-Order | Second-Order | |--------|-------------|--------------| | Information | Gradient slope | Hessian curvature | | Necessary condition | MATH | MATH and MATH | | Sufficient condition | Not available for unconstrained | MATH and MATH | | Strength | Weaker | Stronger | | Computational cost | MATH | MATH | | Distinguishes | Critical points | Minima, maxima, saddle points | Interactive Visualization Explore how second-order conditions work in practice: 🎯 Khởi động Công cụ Khám phá Điều kiện Bậc Hai Công cụ tương tác minh họa: - Phân tích giá trị riêng Hessian cho các loại hàm khác nhau - Phân loại trực quan các điểm tới hạn cực tiểu, cực đại, yên ngựa - Đồ thị đường đẳng mức hiển thị hành vi độ cong cục bộ - Tính toán từng bước cho các kiểm tra bậc hai Tóm tắt và Các Điểm Chính Các điều kiện tối ưu bậc hai cung cấp đặc trưng mạnh hơn cho các điểm tối ưu: Kết quả Chính: 1. Điều kiện cần : MATH và MATH 2. Điều kiện đủ : MATH và MATH 3. Khả năng phân loại : Có thể phân biệt giữa cực tiểu, cực đại và điểm yên ngựa Tầm quan trọng Thực tế: - Thiết kế thuật toán : Nền tảng cho các phương pháp kiểu Newton - Phân tích tính lồi : Thiết yếu cho việc xác minh hàm lồi - Tính bền vững : Đảm bảo mạnh hơn so với chỉ các điều kiện bậc nhất - Lý thuyết tối ưu hóa : Cầu nối giữa tính tối ưu địa phương và toàn cục Cân nhắc Tính toán: - Chi phí : Lưu trữ và tính toán MATH cho Hessian - Xấp xỉ : Các phương pháp Quasi-Newton giảm gánh nặng tính toán - Ổn định số : Tính toán giá trị riêng yêu cầu triển khai cẩn thận Hiểu về các điều kiện bậc hai là thiết yếu cho lý thuyết tối ưu hóa nâng cao và phát triển các thuật toán số hiệu quả. Chúng cung cấp nền tảng toán học cho nhiều phương pháp tối ưu hóa hiện đại và đưa ra các hiểu biết sâu sắc hơn về cấu trúc của các bài toán tối ưu hóa.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter04/04_03_Optimality_conditions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter04/04_04_Partial_optimization",
    "title": "04-04 Tối ưu hóa từng phần",
    "chapter": "04",
    "order": 5,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Nhắc lại: % multilang post url contents/chapter03/21-02-12-03 02 operations that preserve convexity % Nếu MATH là tập lồi và MATH lồi theo MATH , thì MATH lồi theo MATH . Vậy, tối ưu hóa từng phần trong một bài toán lồi được xây dựng với các hàm nhiều biến bảo toàn tính lồi. Hình 1 Tối ưu hóa từng phần của một bài toán lồi 3 Ví dụ: Dạng hinge của SVM Đối với tập không tách được, bài toán SVM được định nghĩa như: > MATH \\begin aligned &\\min \\beta, \\beta 0 , \\xi &&\\frac 1 2 \\|\\beta\\| 2^2 + C \\sum i=1 ^ n \\xi i \\\\ &\\text subject to && \\xi i \\ge 0, \\\\ &&&y i x i ^T \\beta + \\beta 0 \\ge 1 - \\xi i , \\\\ &&&i = 1, .., n \\\\ \\end aligned MATH Các ràng buộc trên có thể được biểu diễn thành một ràng buộc duy nhất: > MATH \\begin aligned \\xi i \\ge \\max\\ 0, 1 - y i x i ^T \\beta + \\beta 0 \\ \\\\ \\end aligned MATH Trong trường hợp này, MATH là giá trị nhỏ nhất cho MATH , và chúng ta có thể định nghĩa MATH như: > MATH \\begin aligned \\frac 1 2 \\|\\beta\\| 2 ^ 2 + C \\sum i=1 ^ n \\xi i &\\ge \\frac 1 2 \\|\\beta\\| 2 ^ 2 + C \\sum i=1 ^ n \\max 0, 1 - y i x i ^T \\beta + \\beta 0 \\\\ &= \\min\\ \\frac 1 2 \\|\\beta\\| 2 ^ 2 + C \\sum i=1 ^ n \\xi i \\quad | \\quad \\xi i \\ge 0, \\ y i x i ^T \\beta + \\beta 0 \\ge 1 - \\xi i , \\ i = 1, .., n\\ \\\\ &= \\tilde f \\beta, \\beta 0 \\\\ \\end aligned MATH Bằng cách sử dụng MATH được đơn giản hóa làm hàm mục tiêu, một nghiệm đơn giản hơn có thể được thu được. Trong bài toán đã cho, MATH đã bị loại bỏ, và nó cũng đã được chuyển đổi từ bài toán có ràng buộc thành bài toán không ràng buộc. > MATH \\begin aligned \\min \\beta, \\beta 0 \\frac 1 2 \\|\\beta\\| 2^2 + C \\sum i=1 ^ n \\max\\ 0, 1 - y i x i ^ T \\beta + \\beta 0 \\ \\end aligned MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter04/04_04_Partial_optimization/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter04/04_05_Transformations_and_change_of_variables",
    "title": "04-05 Biến đổi và thay đổi biến",
    "chapter": "04",
    "order": 6,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Phần này thảo luận về các biến đổi và thay đổi biến trong các bài toán tối ưu hóa lồi, hữu ích cho việc đơn giản hóa hoặc tái công thức hóa bài toán. Hàm mục tiêu hoặc các hàm ràng buộc có thể được sửa đổi trong khi vẫn bảo toàn bài toán tối ưu hóa đã cho, và đôi khi điều này có thể được sử dụng để khám phá \"tính lồi ẩn\" của bài toán. Định lý 1 Khi hàm MATH là một biến đổi đơn điệu tăng, mối quan hệ sau được thỏa mãn: > MATH >\\begin align > &\\text min x f x \\text subject to x \\in C \\\\ > \\Longleftrightarrow \\quad &\\text min x h f x \\text subject to x \\in C >\\end align > MATH Định lý 2 Nếu hàm MATH là hàm tương ứng một-một và ảnh của MATH bao phủ tập khả thi MATH , thì các biến của bài toán tối ưu hóa có thể được thay đổi như sau: > MATH >\\begin align > &\\min x f x \\text subject to x \\in C \\\\\\\\ > \\Longleftrightarrow \\quad &\\min y f \\phi y \\text subject to \\phi y \\in C >\\end align > MATH Ví dụ: quy hoạch hình học Một hàm MATH có dạng sau được gọi là đơn thức monomial : > MATH Ngoài ra, tổng của các đơn thức được gọi là đa thức dương posynomial : > MATH Một chương trình hình học được định nghĩa dưới dạng sau và là một bài toán không lồi: > MATH \\begin align &\\min x &&f x \\\\ &\\text subject to &&g i x \\leq 1, i = 1, \\dotsc, m\\\\ &&&h j x = 1, j = 1, \\dotsc, r,\\\\\\\\ \\end align \\\\ MATH >trong đó MATH , MATH là các đa thức dương và MATH là các đơn thức. Hãy chứng minh rằng một chương trình hình học tương đương với một bài toán lồi nào đó. Chứng minh: >Đối với MATH , nếu chúng ta đặt MATH và MATH , thì MATH có thể được biến đổi như sau, và theo Định lý 2 , điều này bảo toàn bài toán tối ưu hóa đã cho một cách tương đương: > MATH > >Ngoài ra, một đa thức dương có thể được biểu diễn như MATH . > >Tại thời điểm này, theo Định lý 1 , dạng logarit MATH cũng có thể bảo toàn bài toán tối ưu hóa một cách tương đương. > >Tức là, chương trình hình học tương đương với bài toán sau, đây là một bài toán lồi: > > MATH >\\begin align &\\min x \\quad && log \\big \\sum k=1 ^ p 0 e^ a 0k ^ Ty + b 0k \\big \\\\ &\\text subject to && log \\big \\sum k=1 ^ p i e^ a ik ^ Ty + b ik \\big \\leq 0 , \\quad i = 1, \\dotsc, m \\\\ &&&c j ^ Ty + d j = 0, \\quad j = 1, \\dotsc, r\\\\\\\\ \\end align MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter04/04_05_Transformations_and_change_of_variables/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter04/04_06_Eliminating_equality_constraints",
    "title": "04-06 Loại bỏ ràng buộc đẳng thức",
    "chapter": "04",
    "order": 7,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Phần này giải thích các kỹ thuật loại bỏ ràng buộc đẳng thức trong các bài toán tối ưu hóa lồi để đơn giản hóa tập khả thi hoặc cấu trúc bài toán. > MATH \\begin aligned &\\min x &&f x \\\\ &\\text subject to &&g i x \\leq 0, i = 1, .., m\\\\ &&& Ax = b .\\\\ \\end aligned MATH Đối với một nghiệm tùy ý MATH thỏa mãn MATH và MATH , bất kỳ MATH nào thỏa mãn ràng buộc đẳng thức có thể được biểu diễn như sau: > MATH Tức là, MATH . Do đó, bằng cách thay thế MATH cho MATH trong bài toán đã cho, chúng ta có thể loại bỏ ràng buộc đẳng thức. Vậy, bài toán sau tương đương với bài toán gốc: > MATH \\begin aligned &\\min y &&f My+x 0 \\\\ &\\text subject to &&g i My+x 0 \\leq 0, i = 1, .., m.\\\\ \\end aligned MATH Tuy nhiên, cần thận trọng khi sử dụng phương pháp này vì các lý do sau: 1. Việc tính toán MATH nói chung rất đắt đỏ. 2. Nếu MATH thưa hơn MATH , chi phí tính toán sử dụng MATH có thể cao hơn.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter04/04_06_Eliminating_equality_constraints/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter04/04_07_Slack_variables",
    "title": "04-07 Biến phụ",
    "chapter": "04",
    "order": 8,
    "owner": "YoungJae Choung",
    "lesson_type": "required",
    "content": "Biến Phụ trong Tối ưu hóa Lồi Giới thiệu và Động lực Biến phụ là các biến phụ trợ được giới thiệu để biến đổi ràng buộc bất đẳng thức thành ràng buộc đẳng thức. Biến đổi này là cơ bản trong lý thuyết tối ưu hóa và có ứng dụng thực tế trong quy hoạch tuyến tính, các phương pháp điểm trong, và nhiều thuật toán tối ưu hóa. Tại sao chúng ta cần biến phụ? - Nhiều thuật toán tối ưu hóa được thiết kế để xử lý ràng buộc đẳng thức hiệu quả hơn - Chúng cung cấp giải thích hình học về mức độ \"chặt\" của ràng buộc - Chúng thiết yếu trong phương pháp simplex cho quy hoạch tuyến tính - Chúng giúp trong lý thuyết đối ngẫu và phân tích độ nhạy Công thức Toán học Xem xét bài toán tối ưu hóa lồi tiêu chuẩn: > MATH \\begin aligned &\\min x &&f x \\\\ &\\text subject to &&g i x \\leq 0, \\quad i = 1, \\ldots, m\\\\ &&&Ax = b \\end aligned > MATH Bằng cách giới thiệu biến phụ MATH cho mỗi ràng buộc bất đẳng thức, chúng ta có thể tái công thức hóa thành: > MATH \\begin aligned &\\min x, s &&f x \\\\ &\\text subject to &&s i \\geq 0, \\quad i = 1, \\ldots, m\\\\ &&&g i x + s i = 0, \\quad i = 1, \\ldots, m\\\\ &&&Ax = b \\end aligned MATH Giải thích Hình học Biến phụ MATH biểu diễn \"khoảng trống\" hoặc \"biên độ\" trong ràng buộc thứ MATH : - MATH : Ràng buộc MATH không hoạt động không ràng buộc - Điểm MATH nằm trong phần trong của vùng khả thi được định nghĩa bởi ràng buộc MATH - Chúng ta có MATH \\begin aligned &\\max &&3x 1 + 2x 2 \\\\ &\\text thỏa mãn &&x 1 + x 2 \\leq 4 \\quad \\text giờ lao động \\\\ &&&2x 1 + x 2 \\leq 6 \\quad \\text đơn vị nguyên liệu \\\\ &&&x 1, x 2 \\geq 0 \\end aligned > MATH Với Biến Phụ: > MATH \\begin aligned &\\max &&3x 1 + 2x 2 \\\\ &\\text subject to &&x 1 + x 2 + s 1 = 4\\\\ &&&2x 1 + x 2 + s 2 = 6\\\\ &&&x 1, x 2, s 1, s 2 \\geq 0 \\end aligned > MATH Giải thích: - MATH : giờ lao động chưa sử dụng - MATH : đơn vị nguyên liệu chưa sử dụng - Nếu MATH tại tối ưu: tất cả lao động được sử dụng - Nếu MATH tại tối ưu: một số nguyên liệu vẫn chưa được sử dụng Các Tính chất và Cân nhắc Quan trọng 1. Tương đương của các Bài toán Các công thức gốc và biến phụ là tương đương về mặt toán học : - Cùng giá trị mục tiêu tối ưu - MATH tối ưu giống nhau trong cả hai công thức - Các biến phụ MATH tại tối ưu cho chúng ta biết ràng buộc nào hoạt động 2. Bảo toàn Tính lồi Lưu ý Quan trọng: Biến đổi bảo toàn tính lồi chỉ khi MATH là hàm affine . - Nếu MATH affine : Bài toán tái công thức vẫn lồi - Nếu MATH là phi tuyến : Ràng buộc đẳng thức MATH có thể phá hủy tính lồi 3. Tác động Độ phức tạp - Bài toán gốc: MATH biến - Với biến phụ: MATH biến - Đánh đổi: nhiều biến hơn nhưng cấu trúc ràng buộc đơn giản hơn Ví dụ: Chuyển đổi Chương trình Tuyến tính Dạng Gốc: > MATH \\begin aligned &\\min &&c^T x \\\\ &\\text thỏa mãn &&Ax \\leq b\\\\ &&&x \\geq 0 \\end aligned > MATH Dạng Tiêu chuẩn với Biến Phụ: > MATH \\begin aligned &\\min &&c^T x \\\\ &\\text subject to &&Ax + s = b\\\\ &&&x, s \\geq 0 \\end aligned > MATH Trong đó MATH là vector của các biến phụ. Các Điểm Chính 1. Công cụ Biến đổi : Biến phụ chuyển đổi bất đẳng thức thành đẳng thức 2. Ý nghĩa Hình học : Chúng đo \"mức độ chặt\" của ràng buộc 3. Kích hoạt Thuật toán : Thiết yếu cho nhiều thuật toán tối ưu hóa 4. Điều kiện Lồi : Chỉ bảo toàn tính lồi cho ràng buộc affine 5. Hiểu biết Thực tế : Cung cấp giải thích kinh tế trong các bài toán tài nguyên Hiểu về biến phụ là quan trọng cho: - Triển khai các thuật toán tối ưu hóa - Giải thích kết quả tối ưu hóa - Phân tích độ nhạy ràng buộc - Kết nối lý thuyết với thực hành tính toán",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter04/04_07_Slack_variables/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter04/04_08_Relaxation",
    "title": "04-08 Làm giản",
    "chapter": "04",
    "order": 9,
    "owner": "YoungJae Choung",
    "lesson_type": "required",
    "content": "Phần này thảo luận về các kỹ thuật làm giản, được sử dụng để đơn giản hóa hoặc xấp xỉ các bài toán tối ưu hóa lồi bằng cách làm giản các ràng buộc. Xem xét một bài toán có dạng: > MATH Quá trình thay đổi tập miền MATH thành một siêu tập MATH được gọi là Làm giản . > MATH Vì chúng ta đang tối ưu hóa trên một tập miền lớn hơn MATH , giá trị tối ưu của bài toán được làm giản luôn nhỏ hơn hoặc bằng giá trị của bài toán gốc. Trường hợp đặc biệt quan trọng: làm giản ràng buộc đẳng thức phi-affine > MATH trong đó MATH là lồi nhưng phi-affine, >được thay thế bằng MATH Bằng cách biến đổi ràng buộc đẳng thức thành ràng buộc bất đẳng thức, kỹ thuật làm giản làm lỏng lọng các ràng buộc và mở rộng miền một cách hiệu quả. Khi các ràng buộc đẳng thức đã cho là lồi và phi-affine, phương pháp này có thể được sử dụng để tái công thức hóa bài toán thành một bài toán tối ưu hóa lồi. Tuy nhiên, điều này dưới điều kiện rằng cùng một nghiệm vẫn hợp lệ ngay cả sau khi làm giản.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter04/04_08_Relaxation/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_00_Canonical_Problems",
    "title": "05 Các Bài Toán Chuẩn",
    "chapter": "05",
    "order": 1,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Các Bài Toán Chuẩn Trong Chương 1 /chapter01/2021/01/07/optimization problems/ , chúng ta đã học rằng một bài toán tối ưu lồi được định nghĩa như sau: Fig1 Bài toán tối ưu lồi ở dạng chuẩn 3 Tập miền xác định là lồi Hàm mục tiêu MATH và hàm ràng buộc bất đẳng thức MATH là lồi Hàm ràng buộc đẳng thức MATH là affine Tùy thuộc vào loại hàm mục tiêu và hàm ràng buộc, các bài toán tối ưu được phân loại thành nhiều danh mục khác nhau. Trong chương này, chúng ta sẽ tìm hiểu về sáu lớp con chính: - Quy hoạch tuyến tính Linear Programming - LP - Quy hoạch bậc hai Quadratic Programming - QP - Quy hoạch bậc hai với ràng buộc bậc hai Quadratically Constrained Quadratic Programming - QCQP - Quy hoạch nón bậc hai Second-Order Cone Programming - SOCP - Quy hoạch bán xác định Semidefinite Programming - SDP - Quy hoạch nón Conic Programming - CP Các bài toán này có mối quan hệ bao hàm như sau và trở nên tổng quát hơn khi di chuyển xuống dưới trong danh sách: MATH Fig2 Các Bài Toán Chuẩn",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_00_Canonical_Problems/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_01_Linear_Programming_(LP)",
    "title": "05-01 Quy Hoạch Tuyến Tính (LP)",
    "chapter": "05",
    "order": 2,
    "owner": "Hooncheol Shin",
    "lesson_type": "required",
    "content": "Quy hoạch tuyến tính LP là một trong những kỹ thuật tối ưu hóa cơ bản và được sử dụng rộng rãi nhất trong toán học, kinh tế học và kỹ thuật. Hãy tưởng tượng bạn là một quản lý nhà máy đang cố gắng tối đa hóa lợi nhuận trong khi phải đối phó với các tài nguyên hạn chế - đây chính xác là loại bài toán mà LP được thiết kế để giải quyết! Điều gì làm cho một bài toán \"Tuyến tính\"? Một bài toán là tuyến tính khi: - Hàm mục tiêu thứ bạn muốn tối ưu hóa có mối quan hệ đường thẳng - Tất cả ràng buộc giới hạn cũng có mối quan hệ đường thẳng - Không có biến nào được nhân với nhau không có các số hạng MATH - Không có biến nào xuất hiện trong số mũ hoặc dưới căn bậc hai Ví dụ Đơn giản: Bài toán của Nông dân Hãy bắt đầu với một ví dụ trực quan. Một nông dân có 100 mẫu đất và muốn trồng ngô và lúa mì để tối đa hóa lợi nhuận: - Ngô : Lợi nhuận $300 mỗi mẫu, cần 2 giờ lao động mỗi mẫu - Lúa mì : Lợi nhuận $200 mỗi mẫu, cần 1 giờ lao động mỗi mẫu - Lao động có sẵn : Tổng cộng 150 giờ Câu hỏi : Nông dân nên trồng bao nhiêu mẫu mỗi loại cây trồng? Bài tập Tương tác: Sử dụng các thanh trượt bên dưới để khám phá các tổ hợp khác nhau của ngô và lúa mì. Quan sát cách lợi nhuận thay đổi và liệu các ràng buộc có được thỏa mãn hay không! Số mẫu ngô: 50 Số mẫu lúa mì: 50 Tổng diện tích sử dụng: 100 / 100 mẫu Tổng lao động sử dụng: 150 / 150 giờ Tổng lợi nhuận: $ 25000 ✓ Nghiệm khả thi Bây giờ hãy chính thức hóa trực giác này. Nếu cả hàm mục tiêu và các hàm ràng buộc đều là affine, bài toán tối ưu được gọi là chương trình tuyến tính LP . Chương trình tuyến tính tổng quát được phát biểu như sau: LP Tổng quát > MATH \\begin align > &\\text minimize x && c^T x + d \\\\\\\\ > &\\text subject to && Gx \\preceq h \\\\\\\\ > & && Ax = b ,\\\\\\\\ > &\\text where &&G \\in \\mathbb R ^ m \\times n \\text and A \\in \\mathbb R ^ p \\times n . >\\end align MATH Hằng số MATH trong hàm mục tiêu không ảnh hưởng đến quá trình tối ưu hóa hoặc kết quả và có thể bỏ qua. Nếu bạn muốn tối đa hóa MATH dưới cùng các ràng buộc, bạn có thể tương đương tối thiểu hóa MATH . Bài toán trên tìm nghiệm tối ưu MATH của hàm affine MATH trên một tập khả thi đa diện. Giải thích Hình học Sức mạnh của quy hoạch tuyến tính trở nên rõ ràng khi chúng ta trực quan hóa nó theo hình học. Mỗi ràng buộc định nghĩa một nửa không gian, và vùng khả thi là giao của tất cả các nửa không gian này - tạo thành một đa diện . Thông tin quan trọng: Nghiệm tối ưu của một chương trình tuyến tính luôn xuất hiện tại một đỉnh góc của vùng khả thi! Đây là lý do tại sao phương pháp simplex hoạt động bằng cách di chuyển từ đỉnh này sang đỉnh khác. Fig1 Giải thích hình học truyền thống của LP 1 LP ở Dạng chuẩn Tại sao chúng ta cần một dạng chuẩn? Nhiều thuật toán LP như phương pháp simplex được thiết kế để làm việc với một định dạng cụ thể. Việc chuyển đổi về dạng chuẩn cho phép chúng ta sử dụng các thuật toán mạnh mẽ này một cách nhất quán. LP dạng chuẩn > MATH \\begin align > &\\text minimize x && c^T x + d \\\\\\\\ > &\\text subject to && A x = b \\\\\\\\ > & && x \\succeq 0 . >\\end align MATH Đặc điểm chính của dạng chuẩn: - Mục tiêu : Luôn là tối thiểu hóa các bài toán tối đa hóa được chuyển đổi bằng cách lấy âm - Ràng buộc : Chỉ có ràng buộc đẳng thức bất đẳng thức được chuyển đổi sử dụng biến slack - Biến : Tất cả các biến phải không âm Tại sao Dạng chuẩn? Hiệu quả thuật toán: Phương pháp Simplex làm việc trực tiếp trên dạng chuẩn Phân tích lý thuyết: Dễ dàng hơn để chứng minh các điều kiện tối ưu Triển khai phần mềm: Hầu hết các bộ giải LP mong đợi đầu vào dạng chuẩn Tất cả các LP tổng quát đều có thể được chuyển đổi về dạng chuẩn sử dụng các bước sau: Chuyển đổi LP về dạng chuẩn Bước 1. Sử dụng biến slack MATH để chuyển đổi ràng buộc bất đẳng thức thành ràng buộc đẳng thức: > MATH \\begin align > &\\text minimize x, s && c^T x + d \\\\\\\\ > &\\text subject to && Gx + s = h \\\\\\\\ > & && Ax = b ,\\\\\\\\ > & && s \\succeq 0 . > \\end align MATH Bước 2. Thay thế mỗi biến MATH bằng hai biến không âm: MATH , trong đó MATH . > MATH \\begin align > &\\text minimize x^ + , x^ - , s && c^Tx^ + - c^Tx^ - + d \\\\\\\\ > &\\text subject to && Gx^ + - Gx^ - + s = h \\\\\\\\ > & && Ax^ + - Ax^ - = b ,\\\\\\\\ > & && s \\succeq 0 \\\\\\\\ > & && x^ + \\succeq 0 , x^ - \\succeq 0 . > \\end align MATH Bước 3. Định nghĩa MATH , MATH , MATH , và MATH như sau: > MATH \\tilde x = > \\begin bmatrix > x^ + \\\\\\\\ > x^ - \\\\\\\\ > s > \\end bmatrix , > \\tilde c = > \\begin bmatrix > c \\\\\\\\ > -c \\\\\\\\ > 0 > \\end bmatrix , > \\tilde b = > \\begin bmatrix > h \\\\\\\\ > b > \\end bmatrix > MATH , > MATH > \\tilde A = > \\begin bmatrix > G & -G & I\\\\\\\\ > A & -A & O > \\end bmatrix > MATH Bước 4. Thế MATH , MATH , MATH , và MATH vào bài toán từ Bước 2: > MATH \\begin align > &\\text minimize \\tilde x && \\tilde c ^T \\tilde x + d \\\\\\\\ > &\\text subject to && \\tilde A \\tilde x = \\tilde b \\\\\\\\ > & && \\tilde x \\succeq 0 . > \\end align MATH Ví dụ - Chương trình chế độ ăn uống Bài toán chế độ ăn uống là một ứng dụng kinh điển của quy hoạch tuyến tính, lần đầu tiên được nghiên cứu trong Thế chiến thứ hai để tìm cách nuôi dưỡng binh sĩ một cách kinh tế nhất trong khi vẫn đáp ứng các yêu cầu dinh dưỡng. Thiết lập bài toán: Tìm sự kết hợp thức ăn rẻ nhất đáp ứng tất cả các yêu cầu dinh dưỡng. > MATH \\begin align > &\\text minimize x && c^T x \\\\\\\\ > &\\text subject to && Dx \\succeq d \\\\\\\\ > & && x \\succeq 0 . > \\end align MATH Biến và Tham số: MATH : Chi phí trên mỗi đơn vị thức phẩm j $/đơn vị MATH : Lượng tiêu thụ tối thiểu khuyến nghị cho chất dinh dưỡng i đơn vị/ngày MATH : Lượng chất dinh dưỡng i trong thức phẩm j đơn vị chất dinh dưỡng trên đơn vị thức phẩm MATH : Lượng thức phẩm j trong chế độ ăn uống đơn vị/ngày Bộ Tối ưu hóa Chế độ ăn uống Tương tác: Hãy giải một bài toán chế độ ăn uống đơn giản với 3 loại thức phẩm và 2 chất dinh dưỡng! Bánh mì Chi phí: $2/ổ Protein: 4g/ổ Calories: 200/ổ Sữa Chi phí: $3/lít Protein: 8g/lít Calories: 150/lít Thịt Chi phí: $8/kg Protein: 20g/kg Calories: 300/kg Yêu cầu: Protein tối thiểu: gram/ngày Calories tối thiểu: calories/ngày Giải Bài toán Chế độ ăn uống Nhấp \"Giải Bài toán Chế độ ăn uống\" để xem nghiệm tối ưu! Ứng dụng thực tế: Hậu cần quân sự: Nuôi quân đội một cách hiệu quả về chi phí Lập kế hoạch bữa ăn bệnh viện: Đáp ứng yêu cầu chế độ ăn uống của bệnh nhân Tối ưu hóa thức ăn gia súc: Dinh dưỡng gia súc với chi phí tối thiểu Chương trình bữa trưa học đường: Bữa ăn bổ dưỡng trong phạm vi ngân sách Thuật toán Simplex Thuật toán Simplex , được phát triển bởi George Dantzig năm 1947, là một trong những thuật toán quan trọng nhất trong lịch sử tối ưu hóa. Nó đã cách mạng hóa quy hoạch tuyến tính bằng cách cung cấp một phương pháp hiệu quả để giải các bài toán LP một cách hệ thống. Tại sao Simplex hoạt động: Định lý Cơ bản Định lý Cơ bản của Quy hoạch Tuyến tính: Nếu một chương trình tuyến tính có nghiệm tối ưu, thì tồn tại một nghiệm tối ưu xuất hiện tại một đỉnh cực điểm của vùng khả thi. Định lý này là thông tin quan trọng đằng sau thuật toán Simplex. Thay vì tìm kiếm toàn bộ vùng khả thi có thể vô hạn , chúng ta chỉ cần kiểm tra số hữu hạn các đỉnh! How Simplex Works: The Strategy The Simplex algorithm follows this elegant strategy: 1. Start at any vertex of the feasible region 2. Check if the current vertex is optimal 3. Move to an adjacent vertex that improves the objective function 4. Repeat until no improvement is possible optimal solution found Simplex Algorithm Steps Let's walk through the algorithm step by step using our standard form LP: > MATH \\begin align > &\\text minimize x && c^T x \\\\\\\\ > &\\text subject to && A x = b \\\\\\\\ > & && x \\succeq 0 . > \\end align MATH Step 1: Initial Setup - Convert the LP to standard form if not already - Find an initial basic feasible solution vertex - Set up the simplex tableau Step 2: Optimality Test - Check if the current solution is optimal - If all reduced costs are non-negative, we're done! Step 3: Choose Entering Variable - Select the variable with the most negative reduced cost - This determines the direction to move Step 4: Choose Leaving Variable - Use the minimum ratio test to avoid infeasibility - This determines how far to move Step 5: Pivot Operation - Update the tableau using Gaussian elimination - Move to the new vertex Step 6: Repeat - Go back to Step 2 until optimal Interactive Simplex Example Let's solve a simple 2D problem step by step to see how Simplex works in practice: Interactive Simplex Solver: Watch the algorithm move from vertex to vertex! Problem: MATH \\begin align \\text maximize & 3x 1 + 2x 2 \\\\ \\text subject to & x 1 + x 2 \\leq 4 \\\\ & 2x 1 + x 2 \\leq 6 \\\\ & x 1, x 2 \\geq 0 \\end align MATH Next Step Reset Step 0: Starting at origin 0, 0 Current objective value: 0 Click \"Next Step\" to begin the Simplex algorithm! Current Simplex Tableau: Click \"Next Step\" to see the tableau! Why Simplex is Efficient Despite having potentially exponential worst-case complexity, Simplex is remarkably efficient in practice: Simplex Efficiency: Average case: Typically visits only 2-3 times the number of constraints Practical problems: Often solves in polynomial time Warm starts: Can reuse previous solutions when problem changes slightly Degeneracy handling: Modern implementations handle degenerate cases well Simplex Variants and Modern Developments Revised Simplex Method: - More numerically stable - Better for sparse matrices - Used in most commercial solvers Dual Simplex Method: - Starts with dual feasible solution - Useful for sensitivity analysis - Better for certain problem types Interior Point Methods: - Polynomial-time complexity guarantee - Better for very large problems - Complement rather than replace Simplex Impact and Applications The Simplex algorithm has transformed numerous industries: Simplex Success Stories: Airlines: Crew scheduling, route optimization, fleet assignment Manufacturing: Production planning, supply chain optimization Finance: Portfolio optimization, risk management Telecommunications: Network flow optimization, bandwidth allocation Energy: Power grid optimization, resource allocation / Interactive Linear Programming Visualizations Implements farmer problem, geometric interpretation, diet optimizer, and norm comparisons / // Wait for DOM to be fully loaded document.addEventListener 'DOMContentLoaded', function // ==================== FARMER PROBLEM INTERACTIVE ==================== function initializeFarmerProblem const cornSlider = document.getElementById 'corn-acres' ; const wheatSlider = document.getElementById 'wheat-acres' ; if !cornSlider || !wheatSlider return; function updateFarmerResults const corn = parseFloat cornSlider.value ; const wheat = parseFloat wheatSlider.value ; // Update display values document.getElementById 'corn-value' .textContent = corn; document.getElementById 'wheat-value' .textContent = wheat; // Calculate metrics const landUsed = corn + wheat; const laborUsed = corn 2 + wheat 1; // 2 hours per corn acre, 1 hour per wheat acre const profit = corn 300 + wheat 200; // MATH 200 per wheat acre // Update results document.getElementById 'land-used' .textContent = landUsed; document.getElementById 'labor-used' .textContent = laborUsed; document.getElementById 'total-profit' .textContent = profit; // Check feasibility const feasibilityStatus = document.getElementById 'feasibility-status' ; if landUsed = minProtein && calories >= minCalories && cost Optimal Diet Solution: Bread: $ bread amt.toFixed 1 loaves Milk: $ milk amt.toFixed 1 liters Meat: $ meat amt.toFixed 1 kg --- Total cost: MATH bestCost.toFixed 2 Total protein: MATH minProtein g Total calories: MATH minCalories ; else resultsDiv.innerHTML = ' No feasible solution found! '; ; // ==================== SIMPLEX ALGORITHM VISUALIZATION ==================== function initializeSimplexVisualization const stepButton = document.getElementById 'simplex-step' ; const resetButton = document.getElementById 'simplex-reset' ; const statusDiv = document.getElementById 'simplex-status' ; const tableauDiv = document.getElementById 'tableau-content' ; const interactiveDiv = document.getElementById 'simplex-interactive' ; if !stepButton || !resetButton || !statusDiv || !tableauDiv || !interactiveDiv return; // Simplex algorithm state let currentStep = 0; let currentVertex = 0, 0 ; // Starting at origin let isOptimal = false; // Problem: maximize 3x1 + 2x2 subject to x1 + x2 = 0 // In standard form: minimize -3x1 - 2x2 subject to x1 + x2 + s1 = 4, 2x1 + x2 + s2 = 6 const vertices = 0, 0, 4, 6 , // x1, x2, s1, s2 - origin 0, 4, 0, 2 , // 0, 4, 0, 2 - intersection with x1 + x2 = 4 2, 2, 0, 0 , // 2, 2, 0, 0 - intersection of both constraints 3, 0, 1, 0 // 3, 0, 1, 0 - intersection with 2x1 + x2 = 6 ; const objectiveValues = 0, 8, 10, 9 ; // 3x1 + 2x2 at each vertex const simplexPath = 0, 3, 2 ; // Path: origin -> 3,0 -> 2,2 optimal function createVisualization const width = 400; const height = 300; const margin = top: 20, right: 20, bottom: 40, left: 40 ; // Clear previous content interactiveDiv.innerHTML = ''; const svg = d3.select ' simplex-interactive' .append 'svg' .attr 'width', width .attr 'height', height ; // Scales const xScale = d3.scaleLinear .domain 0, 4 .range margin.left, width - margin.right ; const yScale = d3.scaleLinear .domain 0, 6 .range height - margin.bottom, margin.top ; // Draw feasible region const feasibleRegion = 0, 0 , 0, 4 , 2, 2 , 3, 0 , 0, 0 ; svg.append 'path' .datum feasibleRegion .attr 'fill', 'lightblue' .attr 'fill-opacity', 0.3 .attr 'stroke', 'blue' .attr 'stroke-width', 2 .attr 'd', d3.line .x d => xScale d 0 .y d => yScale d 1 ; // Draw constraint lines // x1 + x2 = 4 svg.append 'line' .attr 'x1', xScale 0 .attr 'y1', yScale 4 .attr 'x2', xScale 4 .attr 'y2', yScale 0 .attr 'stroke', 'red' .attr 'stroke-width', 2 .attr 'stroke-dasharray', '5,5' ; // 2x1 + x2 = 6 svg.append 'line' .attr 'x1', xScale 0 .attr 'y1', yScale 6 .attr 'x2', xScale 3 .attr 'y2', yScale 0 .attr 'stroke', 'green' .attr 'stroke-width', 2 .attr 'stroke-dasharray', '5,5' ; // Draw vertices const vertexPoints = 0,0 , 0,4 , 2,2 , 3,0 ; svg.selectAll '.vertex' .data vertexPoints .enter .append 'circle' .attr 'class', 'vertex' .attr 'cx', d => xScale d 0 .attr 'cy', d => yScale d 1 .attr 'r', 6 .attr 'fill', 'orange' .attr 'stroke', 'black' .attr 'stroke-width', 2 ; // Current position indicator svg.append 'circle' .attr 'id', 'current-position' .attr 'cx', xScale currentVertex 0 .attr 'cy', yScale currentVertex 1 .attr 'r', 8 .attr 'fill', 'red' .attr 'stroke', 'darkred' .attr 'stroke-width', 3 ; // Axes svg.append 'g' .attr 'transform', translate 0,$ height - margin.bottom .call d3.axisBottom xScale ; svg.append 'g' .attr 'transform', translate $ margin.left ,0 .call d3.axisLeft yScale ; // Axis labels svg.append 'text' .attr 'x', width / 2 .attr 'y', height - 5 .attr 'text-anchor', 'middle' .text 'x₁' ; svg.append 'text' .attr 'transform', 'rotate -90 ' .attr 'x', -height / 2 .attr 'y', 15 .attr 'text-anchor', 'middle' .text 'x₂' ; // Legend const legend = svg.append 'g' .attr 'transform', translate $ width - 150 , 30 ; legend.append 'text' .attr 'x', 0 .attr 'y', 0 .text 'Constraints:' .attr 'font-weight', 'bold' ; legend.append 'line' .attr 'x1', 0 .attr 'y1', 15 .attr 'x2', 20 .attr 'y2', 15 .attr 'stroke', 'red' .attr 'stroke-width', 2 .attr 'stroke-dasharray', '5,5' ; legend.append 'text' .attr 'x', 25 .attr 'y', 19 .text 'x₁ + x₂ ≤ 4' .attr 'font-size', '12px' ; legend.append 'line' .attr 'x1', 0 .attr 'y1', 30 .attr 'x2', 20 .attr 'y2', 30 .attr 'stroke', 'green' .attr 'stroke-width', 2 .attr 'stroke-dasharray', '5,5' ; legend.append 'text' .attr 'x', 25 .attr 'y', 34 .text '2x₁ + x₂ ≤ 6' .attr 'font-size', '12px' ; function updateTableau step let tableauHTML = ''; switch step case 0: tableauHTML = Basic x₁ x₂ s₁ s₂ RHS s₁ 1 1 1 0 4 s₂ 2 1 0 1 6 z -3 -2 0 0 0 Analysis: Most negative coefficient is -3 x₁ column . x₁ enters the basis. ; break; case 1: tableauHTML = Basic x₁ x₂ s₁ s₂ RHS Ratio s₁ 1 1 1 0 4 4/1 = 4 s₂ 2 1 0 1 6 6/2 = 3 z -3 -2 0 0 0 - Minimum ratio test: min 4/1, 6/2 = min 4, 3 = 3. s₂ leaves the basis. ; break; case 2: tableauHTML = Basic x₁ x₂ s₁ s₂ RHS s₁ 0 0.5 1 -0.5 1 x₁ 1 0.5 0 0.5 3 z 0 -0.5 0 1.5 9 Current solution: x₁ = 3, x₂ = 0, objective = 9 Analysis: x₂ has negative coefficient -0.5 , so x₂ enters the basis. ; break; case 3: tableauHTML = Basic x₁ x₂ s₁ s₂ RHS x₂ 0 1 2 -1 2 x₁ 1 0 -1 1 2 z 0 0 1 1 10 OPTIMAL SOLUTION FOUND! x₁ = 2, x₂ = 2, Maximum objective value = 10 All coefficients in the objective row are non-negative. ; break; tableauDiv.innerHTML = tableauHTML; function updateStatus step let statusHTML = ''; switch step case 0: statusHTML = Step 0: Initial basic feasible solution Current vertex: 0, 0 Current objective value: 0 Basic variables: s₁ = 4, s₂ = 6 ; currentVertex = 0, 0 ; break; case 1: statusHTML = Step 1: Choose entering variable Most negative coefficient: -3 x₁ column x₁ enters the basis Performing minimum ratio test... ; break; case 2: statusHTML = Step 2: First iteration complete Current vertex: 3, 0 Current objective value: 9 Basic variables: x₁ = 3, s₁ = 1 ; currentVertex = 3, 0 ; break; case 3: statusHTML = Step 3: OPTIMAL SOLUTION FOUND! Current vertex: 2, 2 Maximum objective value: 10 Basic variables: x₁ = 2, x₂ = 2 ; currentVertex = 2, 2 ; isOptimal = true; break; statusDiv.innerHTML = statusHTML; // Update visualization const currentPos = d3.select ' current-position' ; if currentPos.node const xScale = d3.scaleLinear .domain 0, 4 .range 40, 360 ; const yScale = d3.scaleLinear .domain 0, 6 .range 260, 40 ; currentPos .transition .duration 500 .attr 'cx', xScale currentVertex 0 .attr 'cy', yScale currentVertex 1 ; function nextStep if currentStep",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_01_Linear_Programming_(LP)/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_02_Quadratic_Programming_(QP) copy",
    "title": "05-02 Quy Hoạch Bậc Hai (QP)",
    "chapter": "05",
    "order": 3,
    "owner": "Hooncheol Shin",
    "lesson_type": "required",
    "content": "Một Chương trình Bậc hai QP là một bài toán tối ưu lồi trong đó hàm mục tiêu là một hàm bậc hai lồi và tất cả các hàm ràng buộc đều là affine. Chương trình bậc hai tổng quát được phát biểu như: Chương trình Bậc hai Tổng quát MATH \\begin align \\text minimize x \\quad &\\frac 1 2 x^T P x + q^T x + r \\\\ \\text subject to \\quad &Gx \\preceq h \\\\ &Ax = b \\end align MATH trong đó: - MATH ma trận bán xác định dương - MATH ma trận ràng buộc bất đẳng thức - MATH ma trận ràng buộc đẳng thức - MATH biến quyết định Tính chất Chính của QP: - Hằng số MATH trong hàm mục tiêu không ảnh hưởng đến quá trình tối ưu hóa hoặc kết quả và có thể bỏ qua. - Nếu MATH không được thỏa mãn, bài toán không lồi. - Ngay cả khi không được nêu rõ, QP giả định MATH . - Bài toán trên tìm nghiệm tối ưu MATH của hàm bậc hai lồi MATH trên một tập khả thi đa diện. Hiểu về MATH Nón Bán xác định Dương Ký hiệu MATH đại diện cho nón bán xác định dương , đây là một khái niệm cơ bản trong tối ưu lồi: Định nghĩa: > MATH trong đó: - MATH là tập tất cả các ma trận đối xứng MATH - MATH có nghĩa là ma trận MATH là bán xác định dương Tính chất Chính: 1. Điều kiện bán xác định dương : Một ma trận MATH là bán xác định dương nếu: - Tất cả các giá trị riêng của MATH đều không âm MATH - Với mọi vector MATH , chúng ta có MATH 2. Tính chất nón lồi : MATH là một nón lồi vì nếu MATH và MATH , thì MATH Ví dụ cho MATH : Với ma trận MATH MATH , điều kiện MATH yêu cầu: - MATH các phần tử đường chéo không âm - MATH các phần tử đường chéo không âm - MATH định thức không âm Tại sao điều này quan trọng đối với QP? - Điều kiện MATH đảm bảo rằng hàm bậc hai MATH là lồi - Không có điều kiện này, bài toán có thể có nhiều cực tiểu địa phương và sẽ không là một bài toán tối ưu lồi - Điều này đảm bảo rằng bất kỳ cực tiểu địa phương nào cũng là cực tiểu toàn cục Hiểu về MATH Bất đẳng thức Theo thành phần Ký hiệu MATH đại diện cho ràng buộc bất đẳng thức theo thành phần , đây là cách gọn gàng để viết nhiều ràng buộc bất đẳng thức tuyến tính: Định nghĩa: MATH where: - MATH is the constraint matrix - MATH is the decision variable vector - MATH is the right-hand side vector - MATH is the number of inequality constraints Expanded Form: The single matrix inequality MATH is equivalent to the system: MATH \\begin align g 1^T x &\\leq h 1 \\\\ g 2^T x &\\leq h 2 \\\\ &\\vdots \\\\ g m^T x &\\leq h m \\end align MATH where MATH is the MATH -th row of matrix MATH . Example: Consider MATH , MATH , and MATH Then MATH means: MATH \\begin align x 1 + 2x 2 &\\leq 5 \\\\ -x 1 + 3x 2 &\\leq 2 \\\\ -x 2 &\\leq -1 \\quad \\text i.e., x 2 \\geq 1\\text \\end align MATH Geometric Interpretation: - Each inequality MATH defines a half-space in MATH - The feasible region is the intersection of all these half-spaces - This intersection forms a polyhedron or polytope if bounded - The constraint MATH defines the polyhedral feasible set for the QP Fig 1 Geometric interpretation of QP 1 QP in Standard Form The standard form of a quadratic program is: Standard Form QP MATH \\begin align \\text minimize x \\quad &\\frac 1 2 x^T P x + q^T x + r \\\\ \\text subject to \\quad &A x = b \\\\ &x \\succeq 0 \\end align MATH Any general quadratic program can be converted to standard form using the following steps: Converting QPs to Standard Form Step 1. Use slack variables MATH to convert inequality constraints into equality constraints: MATH \\begin align \\text minimize x, s \\quad &\\frac 1 2 x^T P x + q^T x + r \\\\ \\text subject to \\quad &Gx + s = h \\\\ &Ax = b \\\\ &s \\succeq 0 \\end align MATH Step 2. Replace MATH with two nonnegative variables: MATH MATH \\begin align \\text minimize x^ + , x^ - , s \\quad &\\frac 1 2 x^ + - x^ - ^T P x^ + - x^ - + q^T x^ + - q^T x^ - + r\\\\ \\text subject to \\quad &Gx^ + - Gx^ - + s = h \\\\ &Ax^ + - Ax^ - = b \\\\ &s \\succeq 0 \\\\ &x^ + \\succeq 0, \\quad x^ - \\succeq 0 \\end align MATH Step 3. Define MATH , MATH , MATH , MATH , MATH : MATH \\tilde x = \\begin bmatrix x^ + \\\\ x^ - \\\\ s \\end bmatrix , \\quad \\tilde q = \\begin bmatrix q \\\\ -q \\\\ 0 \\end bmatrix , \\quad \\tilde b = \\begin bmatrix h \\\\ b \\end bmatrix MATH MATH \\tilde A = \\begin bmatrix G & -G & I \\\\ A & -A & O \\end bmatrix , \\quad \\tilde P = \\begin bmatrix P & -P & O \\\\ -P & P & O \\\\ O & O & O \\end bmatrix MATH Step 4. Substitute the expressions from Step 3 into the formulation: MATH \\begin align \\text minimize \\tilde x \\quad &\\frac 1 2 \\tilde x ^T \\tilde P \\tilde x + \\tilde q ^T \\tilde x + r \\\\ \\text subject to \\quad &\\tilde A \\tilde x = \\tilde b \\\\ &\\tilde x \\succeq 0 \\end align MATH Linear Programming as a Special Case of QP If the quadratic term is removed from the objective function of a quadratic program, it takes the form of a linear program. Thus, LP is a special case of QP, denoted as LP MATH QP. Recall: General LP MATH \\begin align \\text minimize x \\quad &c^T x + d \\\\ \\text subject to \\quad &Gx \\preceq h \\\\ &Ax = b \\end align MATH where MATH and MATH . Ví dụ 1: Tối ưu hóa Danh mục Đầu tư Bài toán này bao gồm việc cân bằng hợp lý giữa hiệu suất và rủi ro khi tạo một danh mục tài chính. MATH \\begin align \\text maximize x \\quad &\\mu^T x - \\frac \\gamma 2 x^T P x \\\\ \\text subject to \\quad &\\mathbf 1 ^Tx = 1 \\\\ &x \\succeq 0 \\end align MATH trong đó: - MATH : lợi nhuận kỳ vọng của các tài sản - MATH : ma trận hiệp phương sai của lợi nhuận tài sản - MATH : tham số tránh rủi ro siêu tham số - MATH : nắm giữ danh mục phần trăm Ví dụ 2: Máy Vector Hỗ trợ Máy Vector Hỗ trợ SVM là một ví dụ của chương trình bậc hai. Dưới đây là C-SVM, một biến thể của SVM. Giải thích chi tiết về SVM nằm ngoài phạm vi của chương này và do đó sẽ được bỏ qua. MATH \\begin align \\text minimize \\beta, \\beta 0, \\xi \\quad &\\frac 1 2 \\| \\beta \\| 2^2 + C \\sum i=1 ^ n \\xi i \\\\ \\text subject to \\quad &\\xi i \\geq 0, \\quad i = 1, \\ldots, n \\\\ &y i x i^T \\beta + \\beta 0 \\geq 1 - \\xi i, \\quad i = 1, \\ldots, n \\end align MATH cho trước: MATH và MATH có các hàng MATH . Ví dụ 3: Bình phương Tối thiểu trong Hồi quy Bài toán tối thiểu hóa hàm bậc hai lồi sau tương ứng với một QP không ràng buộc : MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_02_Quadratic_Programming_(QP)-copy/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_03_Quadratically_Constrained_Quadratic_Programming_(QCQP)",
    "title": "05-03 Quy Hoạch Bậc Hai với Ràng buộc Bậc Hai (QCQP)",
    "chapter": "05",
    "order": 4,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Nếu các hàm ràng buộc bất đẳng thức trong một chương trình bậc hai được thay thế bằng các hàm bậc hai lồi, bài toán được gọi là Chương trình Bậc hai với Ràng buộc Bậc hai QCQP . Chương trình Bậc hai với Ràng buộc Bậc hai > MATH >\\begin align > &\\text minimize x && 1/2 x^T P 0 x + q 0^T x + r 0 \\\\\\\\ > &\\text subject to && 1/2 x^T P i x + q i^T x + r i \\leq 0 , i = 1, \\dotsc, m\\\\\\\\ > & && Ax = b ,\\\\\\\\ > & \\text where &&P i \\in \\mathbb S + ^n \\text với i = 0, \\dotsc, m, \\text và A \\in \\mathbb R ^ p \\times n . >\\end align MATH QP và QCQP tương đương Nếu MATH với mọi MATH trong các ràng buộc QCQP, bài toán rút gọn thành một QP. Do đó, QP là một trường hợp đặc biệt của QCQP, và MATH . Nhắc lại: Chương trình Bậc hai > MATH >\\begin align > &\\text minimize x && 1/2 x^T P x + q^T x + r \\\\\\\\ > &\\text subject to && Gx \\preceq h \\\\\\\\ > & && Ax = b ,\\\\\\\\ > & \\text where &&P \\in \\mathbb S + ^n, G \\in \\mathbb R ^ m \\times n , \\text và A \\in \\mathbb R ^ p \\times n . >\\end align MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_03_Quadratically_Constrained_Quadratic_Programming_(QCQP)/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_04_Second_Order_Cone_Programming_(SOCP)",
    "title": "05-04 Quy Hoạch Nón Bậc Hai (SOCP)",
    "chapter": "05",
    "order": 5,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Nếu các ràng buộc bất đẳng thức trong một LP tổng quát được thay thế bằng các ràng buộc nón bậc hai là các hàm affine , bài toán được gọi là Chương trình Nón Bậc hai SOCP . Chương trình Nón Bậc hai > MATH >\\begin align > &\\text minimize x && f^T x \\\\\\\\ > &\\text subject to && \\| A i x + b i \\| 2 \\leq c i^T x + d i, i = 1, \\dotsc, m \\\\\\\\ > & && Fx = g ,\\\\\\\\ > & \\text where &&x \\in \\mathbb R ^n \\text là biến tối ưu, A i \\in \\mathbb R ^ n i \\times n , \\text và F \\in \\mathbb R ^ p \\times n . >\\end align MATH Nhắc lại: Nón chuẩn Một nón chuẩn là một nón lồi trong MATH được định nghĩa bởi tất cả các điểm MATH sao cho MATH với một chuẩn nào đó MATH . > MATH Hình dưới đây cho thấy nón chuẩn cho chuẩn MATH MATH , cũng được gọi là nón bậc hai hoặc nón kem. Fig1 Nón Chuẩn 1 QCQP và SOCP tương đương Một QCQP có thể được tái công thức thành một SOCP trong một số trường hợp, tức là, MATH . Nhắc lại: Chương trình Bậc hai với Ràng buộc Bậc hai > MATH >\\begin align > &\\text minimize x && 1/2 x^T P 0 x + q 0^T x + r 0 \\\\\\\\ > &\\text subject to && 1/2 x^T P i x + q i^T x + r i \\leq 0 , i = 1, \\dotsc, m\\\\\\\\ > & && Ax = b ,\\\\\\\\ > & \\text where &&P i \\in \\mathbb S + ^n \\text với i = 0, \\dotsc, m, \\text và A \\in \\mathbb R ^ p \\times n >\\end align MATH > Step 1. For convenience, QCQP can be reformulated in different ways to fit SOCP structure. > MATH >\\begin align > &\\text minimize x && x^T P 0 x + 2q 0^T x + r 0 \\\\\\\\ > &\\text subject to && x^T P i x + 2q i^T x + r i \\leq 0 , i = 1, \\dotsc, m\\\\\\\\ > & && Ax = b ,\\\\\\\\ > & \\text where && P i \\in \\mathbb S + ^n \\text for i = 0, \\dotsc, m \\text , and A \\in \\mathbb R ^ \\text p x n . >\\end align \\\\ > MATH > Step 2. Since MATH is a positive semidefinite matrix, any MATH satisfying MATH is also a positive semidefinite matrix. This MATH can be obtained through eigendecomposition. Using this, the objective function of the QCQP can be transformed as follows: MATH MATH > MATH > \\begin align > x^T P 0 x + 2q 0^T x + r 0 &= x^T P 0 x + q 0^T x + x^T q 0 + q 0^T P 0^ -1 q 0 - q 0^T P 0^ -1 q 0 + r 0 \\\\\\\\ > &= x^T Q 0 \\Lambda 0 \\Lambda 0 Q 0^T x + > q 0^T Q 0 \\Lambda 0^ -1 \\Lambda 0 Q 0^ -1 x + x^T Q 0 \\Lambda 0 \\Lambda 0^ -1 Q 0^ -1 q 0 + > q 0^T Q 0 \\Lambda 0^ -1 \\Lambda 0^ -1 Q 0^T q 0 - q 0^T P 0^ -1 q 0 + r 0 \\\\\\\\ > &= \\Lambda 0 Q 0^T x + \\Lambda 0^ -1 Q 0^T q 0 ^T \\Lambda 0 Q 0^T x + \\Lambda 0^ -1 Q 0^T q 0 - q 0^T P 0^ -1 q 0 + r 0 \\\\\\\\ > &=\\| \\Lambda 0 Q 0^T x + \\Lambda 0^ -1 Q 0^T q 0 \\| 2^2 - q 0^T P 0^ -1 q 0 + r 0 \\\\\\\\ > \\end align > MATH Step 3. The same procedure as in Step 2 is applied to the inequality constraint functions, and then substituted into the QCQP from Step 1. > MATH >\\begin align > &\\text minimize x && \\| \\Lambda 0 Q 0^T x + \\Lambda 0^ -1 Q 0^T q 0 \\| 2^2 - q 0^T P 0^ -1 q 0 + r 0 \\\\\\\\ > &\\text subject to && \\| \\Lambda i Q i^T x + \\Lambda i^ -1 Q i^T q i \\| 2^2 \\leq q i^T P i^ -1 q i + r i , i = 1, \\dotsc, m\\\\\\\\ > & && Ax = b .\\\\\\\\ >\\end align > MATH > Step 4. The term MATH in the objective function is a constant and can be omitted. > MATH >\\begin align > &\\text minimize x && \\| \\Lambda 0 Q 0^T x + \\Lambda 0^ -1 Q 0^T q 0 \\| 2^2 \\\\\\\\ > &\\text subject to && \\| \\Lambda i Q i^T x + \\Lambda i^ -1 Q i^T q i \\| 2^2 \\leq q i^T P i^ -1 q i + r i , i = 1, \\dotsc, m\\\\\\\\ > & && Ax = b .\\\\\\\\ >\\end align > MATH Step 5. Introducing a scalar variable MATH , the same problem as in Step 4 can be defined. > MATH >\\begin align > &\\text minimize x, t && t \\\\\\\\ > &\\text subject to &&\\lVert \\Lambda 0 Q 0^T x + \\Lambda 0^ -1 Q 0^T q 0 \\rVert 2^2 \\leq t\\\\\\\\ > & && \\| \\Lambda i Q i^T x + \\Lambda i^ -1 Q i^T q i \\| 2^2 \\leq q i^T P i^ -1 q i + r i , i = 1, \\dotsc, m\\\\\\\\ > & && Ax = b .\\\\\\\\ >\\end align > MATH Phần trên đại diện cho một trường hợp đặc biệt của SOCP. Do đó, mối quan hệ MATH được thỏa mãn.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_04_Second_Order_Cone_Programming_(SOCP)/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_05_Semidefinite_Programming_(SDP)",
    "title": "05-05 Quy Hoạch Bán Xác Định (SDP)",
    "chapter": "05",
    "order": 6,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Nếu ràng buộc bất đẳng thức trong một LP tổng quát được thay thế bằng một bất đẳng thức ma trận tuyến tính LMI , bài toán được gọi là Chương trình Bán xác định SDP . Chương trình Bán xác định > MATH >\\begin align > &\\text minimize x && c^T x + d \\\\\\\\ > &\\text subject to && x 1 F 1 + \\dotsb + x n F n + G \\preceq 0 \\\\\\\\ > & && Ax = b ,\\\\\\\\ > & \\text where &&G, F 1, \\dotsb, F n \\in \\mathbb S ^ k \\text và A \\in \\mathbb R ^ p \\times n . >\\end align MATH Nếu MATH đều là các ma trận đường chéo, ràng buộc bất đẳng thức trên tương đương với MATH bất đẳng thức tuyến tính, và SDP rút gọn thành một LP. Nhiều LMI có thể được biểu diễn thành một LMI duy nhất sử dụng các ma trận đường chéo khối: > MATH > x 1\\hat F 1 + \\dotsb + x n\\hat F n + \\hat G \\preceq 0, \\quad x 1\\tilde F 1 + \\dotsb + x n\\tilde F n + \\tilde G \\preceq 0 > MATH > is equivalent to a single LMI: > MATH > x 1 > \\begin bmatrix > \\hat F 1 & 0 \\\\\\\\ > 0 & \\tilde F 1 \\\\\\\\ > \\end bmatrix + > x 2 > \\begin bmatrix > \\hat F 2 & 0 \\\\\\\\ > 0 & \\tilde F 2 \\\\\\\\ > \\end bmatrix + > \\dotsb > + > x n > \\begin bmatrix > \\hat F n & 0 \\\\\\\\ > 0 & \\tilde F n \\\\\\\\ > \\end bmatrix + > \\begin bmatrix > \\hat G & 0 \\\\\\\\ > 0 & \\tilde G \\\\\\\\ > \\end bmatrix > \\preceq 0 > MATH SDP ở Dạng chuẩn Khi được biểu diễn như sau, nó được gọi là dạng chuẩn của một chương trình bán xác định. SDP dạng chuẩn > MATH >\\begin align > &\\text minimize X && \\mathrm tr CX \\\\\\\\ > &\\text subject to && \\mathrm tr A i X = b i, \\quad i = 1, \\dotsc, m \\\\\\\\ > & && X \\succeq 0 ,\\\\\\\\ > & \\text where &&C, A i \\in \\mathbb S ^n, X \\in \\mathbb S ^n. >\\end align MATH Nhắc lại: MATH Tất cả các SDP đều có thể được biến đổi thành SDP dạng chuẩn thông qua quá trình sau. Chuyển đổi SDP về dạng chuẩn Step1. Use a slack variable S to convert the inequality constraint into an equality constraint. > MATH >\\begin align > &\\text minimize x && c^T x + d \\\\\\\\ > &\\text subject to && \\sum l=1 ^n F l x l+ S = -G \\\\\\\\ > & && Ax = b \\\\\\\\ > & && S \\succeq 0 >\\end align > MATH Step2. Transform the equality constraints derived in Step 1 into component-wise equations. > MATH >\\begin align > &\\text minimize x && c^T x + d \\\\\\\\ > &\\text subject to && \\sum l=1 ^n F l x l ij + S ij = -G ij , i,j = 1, \\dotsc, k \\\\\\\\ > & && Ax = b \\\\\\\\ > & && S \\succeq 0 >\\end align > MATH Step3. Replace x with two nonnegative variables. MATH , where MATH > MATH >\\begin align > &\\text minimize x && c^T x^ + - x^ - + d \\\\\\\\ > &\\text subject to && \\sum l=1 ^n F l x^ + l ij - \\sum l=1 ^n F l x^ - l ij + S ij = -G ij , i,j = 1, \\dotsc, k \\\\\\\\ > & && Ax^ + - Ax^ - = b \\\\\\\\ > & && S \\succeq 0 \\\\\\\\ > & && x^ + \\text , x^ - \\succeq 0 . >\\end align > MATH Step4. Define MATH . All the blanks are zero. > MATH > X = > \\begin bmatrix > diag x^ + \\\\\\\\ > & diag x^ - \\\\\\\\ > && s 11 \\\\\\\\ > &&& s 12 \\\\\\\\ > &&&&\\dotsc\\\\\\ > &&&&&s ij \\\\\\\\ > &&&&&&\\dotsc \\\\\\ > &&&&&&&s kk \\\\\\\\ > \\end bmatrix > , MATH > MATH > C = > \\begin bmatrix > diag c \\\\\\\\ > & -diag c &\\\\\\\\ > & & O k^2 \\text x k^2 \\\\\\\\ > \\end bmatrix > , MATH > MATH > P ij = > \\begin bmatrix > F 1 ij \\\\\\\\ > & F 2 ij \\\\\\\\ > &&\\dotsc\\\\\\\\ > &&& F n ij \\\\\\\\ > &&&&- F 1 ij \\\\\\\\ > &&&&&- F 2 ij \\\\\\\\ > &&&&&&\\dotsc\\\\\\\\ > &&&&&&&- F n ij \\\\\\\\ > &&&&&&&&0&\\\\\\\\ > &&&&&&&&&\\dotsc\\\\\\\\ > &&&&&&&&&&1 \\phantom 1 \\text ij th position \\\\\\\\ > &&&&&&&&&&&\\dotsc\\\\\\\\ > &&&&&&&&&&&&0\\\\\\\\ > \\end bmatrix > , MATH > > MATH > Q i = > \\begin bmatrix > diag A i \\\\\\\\ > &-diag A i \\\\\\\\ > &&O k^2 \\text x k^2 \\\\\\\\ > \\end bmatrix > MATH > MATH is ith row of A , > MATH > \\tilde A = > \\begin bmatrix > P 11 \\\\\\\\ > \\dotsc\\\\\\\\ > P kk \\\\\\\\ > Q 1 \\\\\\\\ > \\dotsc\\\\\\\\ > Q p \\\\\\\\ > \\end bmatrix > -G ij = \\mathrm tr P ij X > , MATH > > MATH > b i = \\mathrm tr Q iX > MATH , > > MATH > \\tilde b = > \\begin bmatrix > -G 11 \\\\\\\\ > \\dotsc\\\\\\\\ > -G kk \\\\\\\\ > b 1 \\\\\\\\ > \\dotsc\\\\\\\\ > b p \\\\\\\\ > \\end bmatrix > MATH . Step5. Substitute the problem from Step3 with MATH . > MATH >\\begin align > &\\text minimize X && \\mathrm tr CX \\\\\\\\ > &\\text subject to && \\mathrm tr \\tilde A iX = \\tilde b i, \\quad i=1,\\dotsc,k^2+p \\\\\\\\ > & && X \\succeq 0 . >\\end align > MATH SOCP và SDP tương đương Bằng cách sử dụng bù Schur 8 https://en.wikipedia.org/wiki/Schur complement , ràng buộc bất đẳng thức của SOCP có thể được biểu diễn theo cách mà SOCP được biến đổi thành một trường hợp đặc biệt của SDP. Tức là, có một mối quan hệ bao hàm: SOCP MATH SDP. Nhắc lại: Chương trình Nón Bậc hai > MATH >\\begin align > &\\text minimize x && f^T x \\\\\\\\ > &\\text subject to && \\| A i x + b i \\| 2 \\leq c i^T x + d i, i = 1, \\dotsc, m \\\\\\\\ > & && Fx = g . >\\end align > MATH SOCP thành SDP bằng bù Schur > MATH >\\begin align > &\\text minimize x && f^T x \\\\\\\\ > &\\text subject to > && > \\begin bmatrix > c i^T x + d I & A i x + b i \\\\\\\\ > A i x + b i ^T & c i^T x + d \\\\\\\\ > \\end bmatrix \\succeq 0, i = 1, \\dotsc, m\\\\\\\\ > & && Fx = g . >\\end align > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_05_Semidefinite_Programming_(SDP)/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_06_Conic_Programming_(CP)",
    "title": "05-06 Quy Hoạch Nón (CP)",
    "chapter": "05",
    "order": 7,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Nếu ràng buộc bất đẳng thức trong một LP tổng quát được thay thế bằng một ràng buộc bất đẳng thức tổng quát, bài toán được gọi là Chương trình Nón CP . Chương trình Nón > MATH >\\begin align > &\\text minimize x && c^T x + d \\\\\\\\ > &\\text subject to && Fx + g \\preceq K 0 \\\\\\\\ > & && Ax = b ,\\\\\\\\ > & \\text where &&c, x \\in \\mathbb R ^ n , A \\in \\mathbb R ^ p \\times n , \\text và b \\in \\mathbb R ^ p . >\\end align MATH MATH là một ánh xạ tuyến tính, MATH , với không gian Euclidean MATH . LP là trường hợp đặc biệt khi MATH , tức là, LP MATH CP. SDP là trường hợp đặc biệt khi MATH , tức là, SDP MATH CP.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_06_Conic_Programming_(CP)/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_02_01_Least_Square",
    "title": "05-02-01 Bài Toán Bình Phương Tối Thiểu Tuyến Tính",
    "chapter": "05",
    "order": 8,
    "owner": "Hooncheol Shin",
    "lesson_type": "required",
    "content": "Bài Toán Bình Phương Tối Thiểu Tuyến Tính Bài toán bình phương tối thiểu tuyến tính là một bài toán tối ưu không có ràng buộc, trong đó chúng ta tối thiểu hóa tổng các sai số bình phương: MATH trong đó: - MATH là một ma trận với MATH - MATH là các hàng của MATH - MATH là biến chúng ta muốn tìm - MATH là vector mục tiêu Mục tiêu: Tìm MATH để tối thiểu hóa tổng các phần dư bình phương. Ví dụ: Hồi quy Tuyến tính với hàm một biến Tìm đường thẳng khớp nhất MATH đi qua các điểm dữ liệu. Chúng ta tối thiểu hóa tổng các khoảng cách thẳng đứng bình phương từ các điểm đến đường thẳng. Mục tiêu: Tìm MATH . Minh họa Hồi quy Tuyến tính Tương tác Hướng dẫn: Nhấp vào canvas để thêm các điểm dữ liệu. Đường thẳng đỏ hiển thị đường khớp nhất. Tham số Hồi quy Hệ số góc m : 0.000 Tung độ gốc c : 0.000 Điểm R²: N/A MSE: N/A Phương trình y = 0.000x + 0.000 Xóa Điểm Thêm Điểm Ngẫu nhiên Công thức Toán học Mục tiêu: Tối thiểu hóa tổng các phần dư bình phương S m,c = Σ yᵢ - mxᵢ - c ² Nghiệm: m = Σ xᵢ-x̄ yᵢ-ȳ / Σ xᵢ-x̄ ² c = ȳ - mx̄ // Linear Regression Interactive Demo class LinearRegressionDemo constructor this.canvas = document.getElementById 'regressionCanvas' ; this.ctx = this.canvas.getContext '2d' ; this.points = ; this.slope = 0; this.intercept = 0; // Set up canvas this.canvas.addEventListener 'click', e => this.addPoint e ; // Initialize with some sample points this.addRandomPoints ; this.draw ; addPoint event const rect = this.canvas.getBoundingClientRect ; const x = event.clientX - rect.left; const y = event.clientY - rect.top; // Convert canvas coordinates to data coordinates const dataX = x / this.canvas.width 10; const dataY = this.canvas.height - y / this.canvas.height 10; this.points.push x: dataX, y: dataY ; this.calculateRegression ; this.draw ; this.updateDisplay ; addRandomPoints // Add some sample points with a trend const baseSlope = 0.8; const baseIntercept = 2; for let i = 0; i sum + p.x, 0 ; const sumY = this.points.reduce sum, p => sum + p.y, 0 ; const sumXY = this.points.reduce sum, p => sum + p.x p.y, 0 ; const sumXX = this.points.reduce sum, p => sum + p.x p.x, 0 ; const meanX = sumX / n; const meanY = sumY / n; const numerator = sumXY - n meanX meanY; const denominator = sumXX - n meanX meanX; if Math.abs denominator sum + p.y, 0 / this.points.length; let ssRes = 0; let ssTot = 0; for const point of this.points const predicted = this.slope point.x + this.intercept; ssRes += Math.pow point.y - predicted, 2 ; ssTot += Math.pow point.y - meanY, 2 ; return ssTot === 0 ? 1 : 1 - ssRes / ssTot ; calculateMSE if this.points.length === 0 return 0; let mse = 0; for const point of this.points const predicted = this.slope point.x + this.intercept; mse += Math.pow point.y - predicted, 2 ; return mse / this.points.length; draw // Clear canvas this.ctx.clearRect 0, 0, this.canvas.width, this.canvas.height ; // Draw grid this.drawGrid ; // Draw regression line if this.points.length >= 2 this.drawRegressionLine ; // Draw points and residuals this.drawPoints ; // Draw axes labels this.drawLabels ; drawGrid this.ctx.strokeStyle = ' f0f0f0'; this.ctx.lineWidth = 1; // Vertical lines for let i = 0; i = 2 const predictedY = this.slope point.x + this.intercept; const predictedCanvasY = this.canvas.height - predictedY / 10 this.canvas.height; this.ctx.strokeStyle = ' ff6b6b'; this.ctx.lineWidth = 1; this.ctx.setLineDash 2, 2 ; this.ctx.beginPath ; this.ctx.moveTo canvasX, canvasY ; this.ctx.lineTo canvasX, predictedCanvasY ; this.ctx.stroke ; this.ctx.setLineDash ; // Draw point this.ctx.fillStyle = ' 2f3542'; this.ctx.beginPath ; this.ctx.arc canvasX, canvasY, 4, 0, 2 Math.PI ; this.ctx.fill ; drawLabels this.ctx.fillStyle = ' 666'; this.ctx.font = '12px Arial'; // X-axis labels for let i = 0; i = 2 document.getElementById 'r2-value' .textContent = this.calculateR2 .toFixed 3 ; document.getElementById 'mse-value' .textContent = this.calculateMSE .toFixed 3 ; else document.getElementById 'r2-value' .textContent = 'N/A'; document.getElementById 'mse-value' .textContent = 'N/A'; // Global functions for buttons function clearPoints if window.regressionDemo window.regressionDemo.clearPoints ; function addRandomPoints if window.regressionDemo window.regressionDemo.clearPoints ; window.regressionDemo.addRandomPoints ; // Initialize when DOM is loaded document.addEventListener 'DOMContentLoaded', function if document.getElementById 'regressionCanvas' window.regressionDemo = new LinearRegressionDemo ; ; // Initialize immediately if DOM is already loaded if document.readyState === 'loading' document.addEventListener 'DOMContentLoaded', function if document.getElementById 'regressionCanvas' window.regressionDemo = new LinearRegressionDemo ; ; else if document.getElementById 'regressionCanvas' window.regressionDemo = new LinearRegressionDemo ; Bài toán: Cho MATH điểm dữ liệu MATH , tìm đường thẳng MATH tối thiểu hóa tổng các khoảng cách thẳng đứng bình phương từ các điểm đến đường thẳng. Hàm Mục tiêu: Chúng ta muốn tối thiểu hóa MATH Nghiệm: Để tìm cực tiểu, chúng ta lấy đạo hàm riêng và cho bằng không. Lấy đạo hàm riêng theo MATH : > MATH Điều này cho ta: MATH Do đó: > MATH trong đó MATH và MATH là giá trị trung bình của các giá trị MATH và MATH . Lấy đạo hàm riêng theo MATH : > MATH Thay thế MATH : MATH Sắp xếp lại: MATH Vì MATH và MATH : > MATH Lưu ý rằng MATH Do đó: > MATH Kết quả Cuối cùng: Đường thẳng khớp nhất có các tham số: > MATH Đây là nghiệm bình phương tối thiểu kinh điển cho hồi quy tuyến tính, cũng được biết đến với tên gọi Phương trình Chuẩn . --- Nghiệm Tối ưu của Hồi quy Tuyến tính với hàm nhiều biến Phát biểu Bài toán: Trong Hồi quy Tuyến tính, chúng ta muốn tìm một vector các hệ số MATH khớp nhất với một mô hình tuyến tính cho một tập dữ liệu cho trước. Chúng ta có MATH điểm dữ liệu, mỗi điểm có MATH đặc trưng. Gọi MATH là ma trận thiết kế kích thước MATH , trong đó mỗi hàng đại diện cho một điểm dữ liệu và mỗi cột đại diện cho một đặc trưng. Gọi MATH là vector các giá trị mục tiêu kích thước MATH . Mô hình tuyến tính của chúng ta dự đoán các giá trị mục tiêu MATH như: MATH trong đó MATH là vector các hệ số chưa biết kích thước MATH . Hàm Mục tiêu Hàm Chi phí : Mục tiêu là tối thiểu hóa tổng các sai số bình phương phần dư giữa các giá trị mục tiêu thực tế MATH và các giá trị dự đoán MATH . Điều này được biết đến với tên gọi hàm mục tiêu Bình phương Tối thiểu Thông thường OLS : MATH Chúng ta có thể biểu diễn điều này dưới dạng ma trận bằng cách khai triển chuẩn Euclidean bình phương: MATH Khai triển biểu thức này: MATH Sử dụng tính chất MATH , chúng ta có MATH . Ngoài ra, vì MATH là một số vô hướng, chuyển vị của nó chính là nó: MATH . Do đó, hai số hạng ở giữa là giống nhau: MATH Tối thiểu hóa sử dụng Giải tích: Để tìm MATH tối ưu tối thiểu hóa MATH , chúng ta lấy đạo hàm của MATH theo MATH và cho bằng không. Chúng ta sử dụng các quy tắc giải tích ma trận sau: 1. MATH 2. MATH Nếu MATH đối xứng, điều này được rút gọn thành MATH Áp dụng các quy tắc này cho MATH : MATH Hãy tính từng số hạng: - MATH vì MATH là một hằng số vô hướng đối với MATH - MATH sử dụng quy tắc 1, với MATH - Đối với số hạng thứ ba, đặt MATH . Lưu ý rằng MATH là ma trận đối xứng vì MATH . Vậy, MATH sử dụng quy tắc 2 cho ma trận đối xứng MATH Kết hợp các thành phần này, đạo hàm là: > MATH Tìm Nghiệm Tối ưu: Để tìm cực tiểu của MATH , chúng ta cho đạo hàm bằng không: MATH Chia cho 2 và sắp xếp lại: MATH Đây được gọi là Phương trình Chuẩn . Nếu MATH khả nghịch điều này xảy ra khi MATH có hạng cột đầy đủ , chúng ta có thể giải để tìm MATH : > MATH Đây là nghiệm dạng đóng cho hồi quy bình phương tối thiểu tuyến tính, còn được gọi là nghiệm Phương trình Chuẩn . Tính chất Quan trọng: 1. Tính duy nhất: Nếu MATH khả nghịch, nghiệm là duy nhất. 2. Ý nghĩa Hình học: Nghiệm MATH làm cho vector phần dư MATH vuông góc với không gian cột của MATH . 3. Độ phức tạp Tính toán: MATH trong đó MATH là số mẫu và MATH là số đặc trưng. Khi MATH không khả nghịch: - Điều này xảy ra khi MATH không có hạng cột đầy đủ tức là một số đặc trưng phụ thuộc tuyến tính - Trong trường hợp này, chúng ta có thể sử dụng nghịch đảo giả Moore-Penrose : MATH - Hoặc thêm điều chuẩn hóa Ridge regression : MATH Hiệu suất: - Độ phức tạp thời gian: khoảng MATH phép toán - Một máy tính tiêu chuẩn giải quyết các bài toán với hàng trăm biến và hàng nghìn số hạng trong vài giây - Ma trận thưa nhiều phần tử bằng không có thể được giải nhanh hơn nhiều Ví dụ: Một ma trận thưa để xử lý ảnh có thể chỉ có 5 phần tử khác không trên mỗi hàng trong ma trận 10,000 × 10,000.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_02_01_Least_Square/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_02_02_Geometric_Programming",
    "title": "05-02-02 Quy Hoạch Hình Học",
    "chapter": "05",
    "order": 9,
    "owner": "Copilot",
    "lesson_type": "",
    "content": "Trong phần này, chúng ta sẽ thấy một lớp các bài toán có vẻ không lồi khi nhìn vào hàm mục tiêu và các hàm ràng buộc, nhưng có thể được biến đổi thành dạng lồi thông qua nhiều kỹ thuật. Trước tiên, chúng ta cần một số định nghĩa: 5.2.1. Đơn thức và Đa thức dương Một hàm MATH với miền MATH tất cả các phần tử đều dương có dạng: MATH trong đó MATH và MATH , được gọi là hàm đơn thức . Một tổng các đơn thức: MATH trong đó MATH , được gọi là hàm đa thức dương , hoặc đơn giản là đa thức dương . 5.2.2. Quy hoạch Hình học Một bài toán tối ưu có dạng: MATH \\begin align x &= \\arg\\min x f 0 x \\\\ \\text subject to: &f i x \\leq 1, \\quad i = 1, 2, \\ldots, m \\quad \\quad 26 \\\\ &h j x = 1, \\quad j = 1, 2, \\ldots, p \\end align MATH trong đó MATH là các đa thức dương và MATH là các đơn thức, được gọi là Quy hoạch Hình học GP . Điều kiện MATH là ngầm định. Lưu ý rằng nếu MATH là một đa thức dương và MATH là một đơn thức, thì MATH là một đa thức dương. Ví dụ: MATH \\begin align x, y, z &= \\arg\\min x,y,z x/y \\\\ \\text subject to: &1 \\leq x \\leq 2 \\\\ &x^3 + 2y/z \\leq \\sqrt y \\\\ &x/y = z \\end align MATH Điều này có thể được viết lại dưới dạng GP: MATH \\begin align x, y, z &= \\arg\\min x,y,z xy^ -1 \\\\ \\text subject to: &x^ -1 \\leq 1 \\\\ & 1/2 x \\leq 1 \\\\ &x^3 y^ -1/2 + 2y^ 1/2 z^ -1 \\leq 1 \\\\ &xy^ -1 z^ -1 = 1 \\end align MATH Bài toán này rõ ràng là không lồi vì cả hàm mục tiêu và các hàm ràng buộc đều không lồi. 5.2.3. Biến đổi GP về Dạng Lồi GP có thể được biến đổi về dạng lồi như sau: Gọi MATH , tức là, MATH . Nếu MATH là một hàm đơn thức của MATH , thì: MATH trong đó MATH . Bây giờ, hàm MATH là một hàm lồi theo MATH . Người đọc có thể chứng minh bằng định nghĩa rằng hợp thành của hai hàm lồi là một hàm lồi. Trong trường hợp này, cả hàm MATH và hàm affine đều là các hàm lồi. Tương tự, đa thức dương trong phương trình 25 có thể được viết như: MATH trong đó MATH và MATH . Bây giờ, đa thức dương đã được viết dưới dạng tổng các hàm MATH của các hàm affine và do đó là một hàm lồi, nhớ lại rằng tổng các hàm lồi là lồi . The GP problem 26 is rewritten as: MATH \\begin align y &= \\arg\\min y \\sum k=1 ^ K 0 \\exp a 0k ^T y + b 0k \\\\ \\text subject to: &\\sum k=1 ^ K i \\exp a ik ^T y + b ik \\leq 1, \\quad i = 1, \\ldots, m \\quad \\quad 27 \\\\ &\\exp g j^T y + h j = 1, \\quad j = 1, \\ldots, p \\end align MATH where MATH , MATH and MATH . Với nhận xét rằng hàm MATH là một hàm lồi nếu MATH là các hàm lồi chúng ta bỏ qua chứng minh , chúng ta có thể viết lại bài toán 27 dưới dạng lồi bằng cách lấy MATH của các hàm như sau: GP ở dạng lồi: MATH \\begin align \\text minimize y \\quad &\\tilde f 0 y = \\log\\left \\sum k=1 ^ K 0 \\exp a 0k ^T y + b 0k \\right \\\\ \\text subject to: &\\tilde f i y = \\log\\left \\sum k=1 ^ K i \\exp a ik ^T y + b ik \\right \\leq 0, \\quad i = 1, \\ldots, m \\quad \\quad 28 \\\\ &\\tilde h j y = g j^T y + h j = 0, \\quad j = 1, \\ldots, p \\end align MATH Bây giờ chúng ta có thể nói rằng GP tương đương với một bài toán tối ưu lồi vì hàm mục tiêu và các hàm ràng buộc bất đẳng thức trong 28 đều là các hàm lồi, trong khi các ràng buộc đẳng thức ở dạng affine. Dạng này thường được gọi là chương trình hình học ở dạng lồi để phân biệt với định nghĩa gốc của GP .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_02_02_Geometric_Programming/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_01_01_LP_Simple_Algorithm",
    "title": "05-01-01 Quy Hoạch Tuyến Tính - Thuật Toán Simplex",
    "chapter": "05",
    "order": 9,
    "owner": "Hooncheol Shin",
    "lesson_type": "required",
    "content": "",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_01_01_LP_Simple_Algorithm/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter05/05_02_03_Linear_Regression_Statistical_View",
    "title": "05-02-03 Hồi Quy Tuyến Tính từ Góc Nhìn Thống Kê",
    "chapter": "05",
    "order": 10,
    "owner": "AI Assistant",
    "lesson_type": "required",
    "content": "Hồi Quy Tuyến Tính từ Góc Nhìn Thống Kê Trong bài học này, chúng ta khám phá hồi quy tuyến tính từ góc nhìn xác suất và thống kê, chứng minh tại sao việc tối thiểu hóa tổng bình phương sai số MSE không chỉ trực quan mà còn được chứng minh lý thuyết thông qua ước lượng hợp lý tối đa. 1. Diễn Giải Xác Suất của Hồi Quy Tuyến Tính Dưới góc nhìn xác suất, chúng ta có thể chứng minh rằng các ước lượng đạt được từ hồi quy tuyến tính dựa trên việc tối thiểu hóa tổng bình phương sai số từ hàm MSE là hoàn toàn tự nhiên và hợp lý. Thật vậy, chúng ta giả định biến mục tiêu và biến đầu vào liên hệ với nhau qua phương trình: MATH trong đó MATH đại diện cho sai số ngẫu nhiên mà bất kỳ phương trình nào cũng có. Đây là những yếu tố không thể giải thích bởi mô hình. Do ước lượng của chúng ta là không chệch, sai số ngẫu nhiên này được giả định thỏa mãn các tính chất theo giả thuyết của Gauss-Markov: Giả Thuyết 1: Sai Số Có Kỳ Vọng Bằng Không Các sai số MATH là đại lượng ngẫu nhiên có kỳ vọng bằng 0: MATH Giả Thuyết 2: Các Sai Số Không Tương Quan Các sai số ngẫu nhiên không có sự tương quan: MATH Giả Thuyết 3: Phương Sai Đồng Nhất Homoscedasticity Phương sai của sai số ngẫu nhiên là bất biến: MATH Giả Thuyết 4: Độc Lập Giữa Sai Số và Đặc Trưng Sai số ngẫu nhiên MATH và các biến đầu vào MATH không có sự tương quan: MATH 2. Phân Phối Gaussian của Sai Số Dưới các giả thuyết này, các sai số ngẫu nhiên MATH tạo thành một phân phối Gaussian phân phối chuẩn với trung bình bằng 0 và phương sai MATH , ký hiệu là MATH . Hàm mật độ xác suất tại mỗi điểm MATH là: MATH Thay MATH vào hàm mật độ xác suất, ta được: MATH Ký hiệu MATH cho biết xác suất của MATH tương ứng với MATH , được tham số hóa bởi MATH . Ở đây, MATH là đã biết và không được xem như điều kiện của MATH , do đó sử dụng dấu ; thay vì ,. 3. Ước Lượng Hợp Lý Tối Đa Dưới góc độ xác suất, MATH là hàm phụ thuộc vào dữ liệu đầu vào MATH khi đã biết trọng số MATH . Khi xem xác suất dưới góc nhìn của một hàm theo MATH , ta gọi đó là hàm hợp lý likelihood : MATH Theo điều kiện 2 của giả thuyết Gauss-Markov, các sai số là độc lập, nên xác suất đồng thời của dữ liệu bằng tích các mật độ xác suất của từng điểm dữ liệu: MATH \\begin align L \\mathbf w &= \\prod i=1 ^ n p y i \\mid \\mathbf x i; \\mathbf w \\\\ &= \\prod i=1 ^ n \\frac 1 \\sqrt 2\\pi \\sigma^2 \\exp \\left -\\frac \\epsilon i^2 2\\sigma^2 \\right \\end align MATH Hàm hợp lý phản ánh mối quan hệ xác suất giữa MATH và MATH . Để tìm MATH sao cho mối quan hệ này phù hợp nhất, theo ước lượng hợp lý tối đa Maximum Likelihood Estimation , ta chọn MATH sao cho MATH lớn nhất. 4. Tối Ưu Hóa Log-Likelihood Lấy logarit hai vế để đơn giản hóa bài toán tối ưu: MATH \\begin align \\hat \\mathbf w &= \\arg \\max \\log L \\mathbf w \\\\ &= \\arg \\max \\log \\left \\prod i=1 ^ n \\frac 1 \\sqrt 2\\pi \\sigma^2 \\exp \\left -\\frac \\epsilon i^2 2\\sigma^2 \\right \\right \\\\ &= \\arg \\max \\sum i=1 ^ n \\log \\left \\frac 1 \\sqrt 2\\pi \\sigma^2 \\exp \\left -\\frac \\epsilon i^2 2\\sigma^2 \\right \\right \\\\ &= \\arg \\max \\sum i=1 ^ n \\left -\\frac \\epsilon i^2 2\\sigma^2 - \\log \\sqrt 2\\pi \\sigma^2 \\right \\\\ &= \\arg \\max \\left -\\frac 1 2\\sigma^2 \\sum i=1 ^ n \\epsilon i^2 - n \\log \\sqrt 2\\pi \\sigma^2 \\right \\end align MATH Vì MATH và MATH là hằng số, tối ưu hóa hàm trên tương đương với tối thiểu hóa: MATH Điều này tương đương với việc tối thiểu hóa hàm MSE: MATH 5. Chứng Minh Lý Thuyết Như vậy, dưới góc nhìn xác suất, ta đã chứng minh rằng hồi quy tuyến tính dựa trên tối thiểu hóa tổng bình phương sai số tương đương với tối ưu hóa hàm hợp lý. Khi các điều kiện của giả thuyết Gauss-Markov được thỏa mãn, ước lượng của chúng ta là ước lượng không chệch tốt nhất best linear unbiased estimator - BLUE . Các giả thuyết về khoảng tin cậy của giá trị dự báo và đánh giá ý nghĩa của các trọng số thông qua P-value có thể được thực hiện dựa trên phân phối chuẩn. Trực Quan Hóa Ước Lượng Hợp Lý Tối Đa Trực quan hóa: Các chấm xanh là điểm dữ liệu, đường đỏ là đường khớp, và các đường cong thể hiện phân phối Gaussian của sai số. Tham Số Mức Nhiễu σ : 0.5 Hệ Số Góc Thực: 1.0 Hệ Số Chặn Thực: 0.0 Tạo Dữ Liệu Mới Ước Lượng MLE: Hệ số góc: 0.000 Hệ số chặn: 0.000 Log-Likelihood: 0.000 6. Huấn Luyện Mô Hình Hồi Quy Tuyến Tính trên Sklearn Sklearn là một thư viện toàn diện của Python về khoa học dữ liệu, hỗ trợ huấn luyện hầu hết các mô hình học máy, xây dựng pipeline, chuẩn hóa dữ liệu, và thực hiện kiểm định chéo cross-validation . Trong phần này, chúng ta sẽ tìm hiểu cách huấn luyện mô hình hồi quy tuyến tính trên sklearn. Quay lại bài toán trước, nếu thêm thông tin về khoảng cách tới trung tâm: MATH khi đó bài toán trở thành hồi quy đa biến. Quy trình xây dựng và huấn luyện mô hình gồm các bước: 1. Thu thập dữ liệu 2. Làm sạch dữ liệu 3. Lựa chọn dữ liệu đầu vào 4. Chuẩn hóa dữ liệu 5. Phân chia tập huấn luyện/kiểm tra train/test 6. Huấn luyện và đánh giá mô hình Ở bài toán này, chúng ta tập trung vào bước 6 để hiểu cách huấn luyện mô hình. Ví Dụ Sklearn Hồi Quy Tuyến Tính import numpy as np from sklearn.linear model import LinearRegression from sklearn.model selection import train test split from sklearn.metrics import mean squared error, r2 score import matplotlib.pyplot as plt Dữ liệu mẫu: giá nhà Đặc trưng: diện tích, khoảng cách tới trung tâm X = np.array 50, 20 , 60, 18 , 70, 17 , 80, 16 , 90, 15 , 100, 14 , 110, 12 , 120, 10 , 130, 8 , 140, 7 , 150, 5 , 160, 2 , 170, 1 Mục tiêu: giá nghìn đô la y = np.array 150, 180, 210, 240, 270, 300, 330, 360, 390, 420, 450, 480, 510 Chia dữ liệu X train, X test, y train, y test = train test split X, y, test size=0.3, random state=42 Tạo và huấn luyện mô hình model = LinearRegression model.fit X train, y train Dự đoán y pred = model.predict X test Đánh giá mô hình mse = mean squared error y test, y pred r2 = r2 score y test, y pred print f\"Hệ số: model.coef \" print f\"Hệ số chặn: model.intercept \" print f\"MSE: mse:.2f \" print f\"R²: r2:.3f \" Kết Quả Mô Hình Chạy Ví Dụ Sklearn Tham Số Mô Hình: Hệ số diện tích: -- Hệ số khoảng cách: -- Hệ số chặn: -- Hiệu Suất: MSE: -- R²: -- Máy Tính Dự Đoán Diện tích m² : Khoảng cách tới trung tâm km : Dự Đoán Giá Giá Dự Đoán: -- Những Hiểu Biết Quan Trọng 1. Nền Tảng Lý Thuyết : Ước lượng hợp lý tối đa cung cấp nền tảng lý thuyết vững chắc cho việc tại sao chúng ta tối thiểu hóa sai số bình phương trong hồi quy tuyến tính. 2. Giả Thuyết Gaussian : Hiệu quả của hồi quy tuyến tính dựa trên các giả thuyết Gauss-Markov, đặc biệt là sai số được phân phối chuẩn. 3. Ước Lượng Không Chệch Tốt Nhất : Dưới điều kiện phù hợp, OLS cung cấp BLUE - ước lượng tuyến tính không chệch hiệu quả nhất. 4. Triển Khai Thực Tế : Các công cụ hiện đại như sklearn giúp dễ dàng triển khai các khái niệm lý thuyết này trong thực tế. 5. Đánh Giá Mô Hình : Hiểu nền tảng thống kê giúp đánh giá mô hình đúng cách sử dụng các chỉ số như R², khoảng tin cậy và p-values. // MLE Visualization class MLEVisualization constructor this.canvas = document.getElementById 'mleCanvas' ; this.ctx = this.canvas.getContext '2d' ; this.width = this.canvas.width; this.height = this.canvas.height; // Parameters this.trueSlope = 1.0; this.trueIntercept = 0.0; this.noiseLevel = 0.5; this.dataPoints = ; this.setupControls ; this.generateData ; this.draw ; setupControls const noiseSlider = document.getElementById 'noise-slider' ; const slopeSlider = document.getElementById 'slope-slider' ; const interceptSlider = document.getElementById 'intercept-slider' ; const generateBtn = document.getElementById 'generate-data' ; noiseSlider.addEventListener 'input', e => this.noiseLevel = parseFloat e.target.value ; document.getElementById 'noise-value' .textContent = this.noiseLevel.toFixed 1 ; this.generateData ; this.draw ; ; slopeSlider.addEventListener 'input', e => this.trueSlope = parseFloat e.target.value ; document.getElementById 'true-slope-value' .textContent = this.trueSlope.toFixed 1 ; this.generateData ; this.draw ; ; interceptSlider.addEventListener 'input', e => this.trueIntercept = parseFloat e.target.value ; document.getElementById 'true-intercept-value' .textContent = this.trueIntercept.toFixed 1 ; this.generateData ; this.draw ; ; generateBtn.addEventListener 'click', => this.generateData ; this.draw ; ; generateData this.dataPoints = ; const n = 20; for let i = 0; i x: x + 2.5 this.width / 5, y: this.height - y + 2.5 this.height / 5 ; // Draw axes this.ctx.strokeStyle = ' ddd'; this.ctx.lineWidth = 1; this.ctx.beginPath ; this.ctx.moveTo 0, this.height / 2 ; this.ctx.lineTo this.width, this.height / 2 ; this.ctx.moveTo this.width / 2, 0 ; this.ctx.lineTo this.width / 2, this.height ; this.ctx.stroke ; // Draw fitted line this.ctx.strokeStyle = ' ff4444'; this.ctx.lineWidth = 2; this.ctx.beginPath ; const start = transform -2, mle.slope -2 + mle.intercept ; const end = transform 2, mle.slope 2 + mle.intercept ; this.ctx.moveTo start.x, start.y ; this.ctx.lineTo end.x, end.y ; this.ctx.stroke ; // Draw data points and error distributions for const point of this.dataPoints const pos = transform point.x, point.y ; // Draw Gaussian error distribution const predicted = mle.slope point.x + mle.intercept; const errorCenter = transform point.x, predicted ; this.ctx.strokeStyle = ' cccccc'; this.ctx.lineWidth = 1; this.ctx.beginPath ; for let i = 0; i this.runSklearnExample ; predBtn.addEventListener 'click', => this.makePrediction ; runSklearnExample // Simulate sklearn linear regression const X, y = this.data; // Calculate means const meanX1 = X.reduce sum, row => sum + row 0 , 0 / X.length; const meanX2 = X.reduce sum, row => sum + row 1 , 0 / X.length; const meanY = y.reduce sum, val => sum + val, 0 / y.length; // Calculate coefficients using normal equation let sumX1X1 = 0, sumX2X2 = 0, sumX1X2 = 0; let sumX1Y = 0, sumX2Y = 0; for let i = 0; i MATH prediction.toFixed 0 k ; // Initialize when DOM is loaded document.addEventListener 'DOMContentLoaded', function new MLEVisualization ; new SklearnDemo ; ; mle-demo canvas border-radius: 5px; sklearn-demo pre max-height: 400px; overflow-y: auto; .demo-container margin: 20px 0; input type=\"range\" -webkit-appearance: none; appearance: none; height: 5px; background: ddd; outline: none; border-radius: 5px; input type=\"range\" ::-webkit-slider-thumb -webkit-appearance: none; appearance: none; width: 15px; height: 15px; background: 007bff; cursor: pointer; border-radius: 50%; input type=\"range\" ::-moz-range-thumb width: 15px; height: 15px; background: 007bff; cursor: pointer; border-radius: 50%; border: none;",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter05/05_02_03_Linear_Regression_Statistical_View/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_00_gradient_descent",
    "title": "06 Gradient Descent",
    "chapter": "06",
    "order": 1,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Trong chương này, chúng ta sẽ khám phá Gradient Descent Thuật toán Gradient , một trong những phương pháp cơ bản và quan trọng nhất trong tối ưu hóa. Trong các thuật toán tối ưu hóa, việc lựa chọn hướng tìm kiếm và kích thước bước là rất quan trọng đối với tốc độ hội tụ và sự thành công. Gradient descent di chuyển theo hướng của gradient âm. Kích thước bước có thể được cố định hoặc được chọn một cách thích ứng, và chúng ta sẽ thảo luận cả hai cách tiếp cận trong chương này. Để gradient descent hội tụ, một số điều kiện tiên quyết phải được đáp ứng. Nếu những điều kiện này được thỏa mãn, chúng ta có thể phân tích gradient descent hội tụ nhanh như thế nào. Nếu tính lồi mạnh được thỏa mãn, sự hội tụ thậm chí còn nhanh hơn, và chúng ta sẽ xem xét tốc độ hội tụ trong những trường hợp như vậy. Chúng ta cũng sẽ xem xét các ứng dụng của gradient descent, bao gồm gradient boosting và stochastic gradient descent.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_00_gradient_descent/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_01_gradient_descent",
    "title": "06-01 Gradient Descent",
    "chapter": "06",
    "order": 2,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Gradient descent là thuật toán đơn giản nhất để giải quyết các bài toán tối ưu hóa lồi và khả vi không ràng buộc. > MATH > trong đó MATH khả vi và MATH . Giá trị tối ưu là MATH , và điểm tối ưu là MATH . Tại sao Gradient Descent quan trọng trong Khoa học Dữ liệu Gradient descent là công cụ chủ lực của machine learning! Đây là thuật toán đằng sau: - Huấn luyện mạng nơ-ron : Backpropagation sử dụng gradient descent để cập nhật trọng số - Hồi quy tuyến tính : Tìm các hệ số tối ưu để giảm thiểu MSE - Hồi quy logistic : Tối ưu hóa tham số cho phân loại - Deep learning : Huấn luyện các mô hình phức tạp với hàng triệu tham số - Hệ thống gợi ý : Học sở thích người dùng và đặc trưng sản phẩm Hiểu biết quan trọng : Mỗi khi bạn thấy \"training\" hoặc \"learning\" trong ML, gradient descent hoặc các biến thể của nó có khả năng được sử dụng! Gradient Descent cho Hàm Một Biến Đối với hàm một biến MATH , gradient descent được đơn giản hóa đáng kể. Gradient trở thành đạo hàm, và quy tắc cập nhật trở thành: > MATH trong đó MATH là đạo hàm của MATH tại điểm MATH . Giải thích Hình học Trong trường hợp hàm một biến, đạo hàm MATH biểu thị độ dốc của đường tiếp tuyến tại điểm MATH : - Nếu MATH , hàm số đang tăng, vì vậy chúng ta di chuyển sang trái trừ đi một giá trị dương - Nếu MATH x^ k = x^ k-1 - t x^ k-1 - 2 MATH Bắt đầu từ MATH với kích thước bước MATH : > MATH > MATH > MATH > ... Dãy số hội tụ về MATH , đây là cực tiểu toàn cục. Lựa chọn Kích thước Bước Việc lựa chọn kích thước bước MATH là rất quan trọng: - Quá nhỏ : Hội tụ rất chậm - Quá lớn : Thuật toán có thể vượt quá và phân kỳ - Tối ưu : Đối với hàm bậc hai MATH với MATH , kích thước bước tối ưu là MATH Trực quan Hóa Tương tác Kích thước Bước t : 0.1 Điểm Bắt đầu: -3 Bắt đầu Animation Reset Một Bước Lần lặp: 0, x = -3.000, f x = 13.500, f' x = -5.000 class SingleVarGradientDescent constructor this.canvas = document.getElementById 'gradient-canvas' ; this.ctx = this.canvas.getContext '2d' ; this.stepSizeSlider = document.getElementById 'step-size-slider' ; this.startPointSlider = document.getElementById 'start-point-slider' ; this.stepSizeValue = document.getElementById 'step-size-value' ; this.startPointValue = document.getElementById 'start-point-value' ; this.iterationInfo = document.getElementById 'iteration-info' ; // Animation state this.isAnimating = false; this.currentX = -3; this.iteration = 0; this.history = ; this.animationId = null; // Function parameters: f x = 0.5 x - 2 ^2 + 1 this.a = 0.5; this.b = 2; this.c = 1; this.setupEventListeners ; this.reset ; setupEventListeners this.stepSizeSlider.addEventListener 'input', e => this.stepSizeValue.textContent = e.target.value; ; this.startPointSlider.addEventListener 'input', e => this.startPointValue.textContent = e.target.value; if !this.isAnimating this.reset ; ; document.getElementById 'start-animation' .addEventListener 'click', => this.startAnimation ; ; document.getElementById 'reset-animation' .addEventListener 'click', => this.reset ; ; document.getElementById 'step-once' .addEventListener 'click', => this.singleStep ; ; // Function: f x = 0.5 x - 2 ^2 + 1 f x return this.a Math.pow x - this.b, 2 + this.c; // Derivative: f' x = x - 2 fprime x return 2 this.a x - this.b ; // Convert x coordinate to canvas coordinate xToCanvas x const xMin = -5, xMax = 5; return x - xMin / xMax - xMin this.canvas.width; // Convert y coordinate to canvas coordinate yToCanvas y const yMin = 0, yMax = 15; return this.canvas.height - y - yMin / yMax - yMin this.canvas.height; // Convert canvas x to actual x canvasToX canvasX const xMin = -5, xMax = 5; return xMin + canvasX / this.canvas.width xMax - xMin ; drawFunction this.ctx.strokeStyle = ' 2196F3'; this.ctx.lineWidth = 2; this.ctx.beginPath ; for let canvasX = 0; canvasX if !this.isAnimating return; if Math.abs this.fprime this.currentX > 1e-6 && this.iteration Phương pháp Gradient Descent cho Hàm Nhiều Biến Gradient descent bắt đầu từ một điểm ban đầu MATH và cập nhật lặp đi lặp lại như sau cho đến khi đáp ứng tiêu chuẩn dừng: > MATH , MATH Mã giả: > Cho điểm bắt đầu MATH > Lặp lại > 1. Xác định hướng giảm MATH . > 2. Tìm kiếm đường: chọn kích thước bước MATH . > 3. Cập nhật MATH . > Cho đến khi tiêu chuẩn dừng được thỏa mãn Ví dụ Hình dưới đây cho thấy gradient descent trên một hàm lồi. Trong trường hợp này, cực tiểu cục bộ cũng là cực tiểu toàn cục. Hình 1 Gradient descent trong hàm lồi 3 Hình tiếp theo cho thấy gradient descent trên một hàm không lồi. Ở đây, điểm ban đầu quyết định cực tiểu cục bộ nào được đạt tới. Hình 2 Gradient descent trong hàm không lồi 3 Giải thích Gradient Descent Gradient descent có thể được giải thích là việc chọn điểm tiếp theo bằng cách giảm thiểu một xấp xỉ bậc hai của hàm số. Đối với hàm MATH , khai triển Taylor bậc hai quanh MATH là: > MATH Nếu chúng ta xấp xỉ ma trận Hessian MATH bằng MATH , thì: > MATH trong đó MATH là kích thước bước. Vì vậy, trong gradient descent, hàm số được xấp xỉ bởi một hàm bậc hai có ma trận Hessian với các giá trị riêng bằng nghịch đảo của kích thước bước. Số hạng MATH biểu thị một xấp xỉ tuyến tính của MATH , và MATH đóng vai trò là số hảng gần kề chỉ ra MATH gần MATH như thế nào. Vị trí tiếp theo được chọn là cực tiểu của hàm bậc hai xấp xỉ này. Đặt gradient của MATH bằng không để tìm vị trí tiếp theo MATH dẫn đến: > MATH Trong hình minh họa dưới đây, chấm xanh biểu thị vị trí hiện tại MATH , và chấm đỏ biểu thị vị trí tiếp theo MATH . Đường cong bên dưới là hàm thực tế MATH , và đường cong bên trên là xấp xỉ bậc hai của MATH . Vì vậy, chấm đỏ chỉ ra cực tiểu của xấp xỉ bậc hai. MATH Độ gần kề của vị trí tiếp theo MATH đến vị trí hiện tại MATH bị ảnh hưởng bởi trọng số của số hạng gần kề MATH . Một MATH nhỏ hơn dẫn đến trọng số lớn hơn cho số hạng gần kề, dẫn đến các bước nhỏ hơn. Quá trình này có thể được biểu thị như: > \\begin align x^+ = \\underset y \\arg \\min \\ f x + \\nabla f x ^T y - x + \\frac 1 2t \\parallel y - x \\parallel 2^2 \\end align",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_01_gradient_descent/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_02_how_to_choose_step_sizes",
    "title": "06-02 Cách chọn kích thước bước",
    "chapter": "06",
    "order": 3,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Khi thực hiện gradient descent, kích thước bước quyết định cách biến MATH được cập nhật và ảnh hưởng đến tốc độ và sự thành công trong việc tìm giá trị tối ưu. Phần này giới thiệu ba phương pháp chính để chọn kích thước bước nhằm giúp gradient descent tìm được tối ưu nhanh hơn: - Kích thước bước cố định - Tìm kiếm đường lùi - Tìm kiếm đường chính xác",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_02_how_to_choose_step_sizes/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_02_01_fixed_step_size",
    "title": "06-02-01 Kích thước bước cố định",
    "chapter": "06",
    "order": 4,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Cách đơn giản nhất để chọn kích thước bước trong gradient descent là sử dụng một giá trị cố định cho tất cả các lần lặp: MATH với MATH . Tuy nhiên, sự hội tụ và hành vi phụ thuộc rất nhiều vào việc lựa chọn MATH . Ví dụ, trong hình dưới đây, gradient descent được áp dụng cho MATH với các kích thước bước khác nhau: Hình 1 Các kịch bản kích thước bước 3 Trong trường hợp A, kích thước bước MATH quá lớn, gây ra phân kỳ sau 8 bước. Không thể đạt được cực tiểu. Trong trường hợp B, kích thước bước MATH quá nhỏ, vì vậy sự hội tụ rất chậm và cực tiểu không được đạt được ngay cả sau 100 bước. Trong trường hợp C, kích thước bước là \"phù hợp\", và sự hội tụ đạt được trong khoảng 40 bước. Cách tìm giá trị \"phù hợp\" này được thảo luận sau trong chương này.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_02_01_fixed_step_size/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_02_02_backtracking_line_search",
    "title": "06-02-02 Tìm kiếm đường lùi",
    "chapter": "06",
    "order": 5,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Quy tắc cập nhật cơ bản là: MATH trong đó MATH là vector tham số tại lần lặp MATH , MATH là gradient, và MATH là kích thước bước tốc độ học . Nếu sử dụng kích thước bước cố định trong gradient descent, tốc độ hội tụ luôn giống nhau, điều này có thể gây vấn đề trong các vùng điều kiện xấu nơi cực tiểu bị bỏ lỡ hoặc tiến độ chậm . Để giải quyết điều này, kích thước bước có thể được chọn một cách thích ứng để phù hợp với độ cong của hàm. Một phương pháp như vậy là tìm kiếm đường lùi . Tìm kiếm Đường lùi là gì? Phương pháp này thử một bước từ vị trí hiện tại, và nếu bước quá lớn, nó sẽ lùi lại. Hình dưới đây cho thấy cách tìm kiếm đường lùi xác định kích thước bước. Hình1 Tìm kiếm Đường lùi 3 Các phương pháp tìm kiếm đường động chọn MATH để đảm bảo tiến độ đủ, thường bằng cách giảm thiểu MATH dọc theo hướng tìm kiếm MATH gradient âm cho giảm . Tìm kiếm đường chính xác tìm MATH , nhưng điều này tốn kém về tính toán cho MATH không phải bậc hai. Tìm kiếm đường không chính xác xấp xỉ điều này một cách hiệu quả, và tìm kiếm đường lùi là một phương pháp không chính xác phổ biến do tính đơn giản và đảm bảo của nó. Trong hàm lồi MATH , vùng tìm kiếm bị giới hạn trong một đường thẳng. Đường thẳng dưới là một bước từ vị trí hiện tại MATH theo hướng giảm. Nếu MATH luôn ở trên đường thẳng, rất khó để đánh giá liệu bước có quá lớn hay phù hợp. Trong tìm kiếm đường lùi, đường thẳng trên được sử dụng, đây là một bước theo hướng giảm được tỉ lệ bởi MATH . Nếu MATH ở trên đường thẳng, bước quá lớn; nếu ở dưới, bước phù hợp. Nếu bước quá lớn, MATH được giảm cho đến khi MATH rơi xuống dưới đường thẳng. MATH cuối cùng nằm trong khoảng MATH . Thuật toán Tìm kiếm Đường lùi Tóm tắt như sau với MATH : 1. Khởi tạo tham số MATH , đặt MATH . 4. Cập nhật MATH . 5. Nếu tiêu chuẩn dừng chưa được đáp ứng, lặp lại từ bước 2. Tìm kiếm đường lùi đơn giản và hiệu quả. Tham số MATH xác định hướng, và MATH xác định mức độ lùi lại. Thường MATH và MATH được chọn gần 1. Ví dụ Tìm kiếm Đường lùi Với kích thước bước thích ứng, sự hội tụ nhanh hơn nhiều so với kích thước bước cố định ví dụ: 12 bước so với 100 bước cho cùng một bài toán . Bao gồm các bước lùi, tổng sự hội tụ đạt được trong khoảng 40 bước. Hình2 Hội tụ 3 Trực giác về Tìm kiếm Đường lùi Một xấp xỉ bậc hai cho MATH là: > MATH Đối với MATH : > MATH > \\begin align > f x - t \\nabla f x &\\approx f x - t \\|\\nabla f x \\| 2^2 + \\frac 1 2 t \\|\\nabla f x \\| 2^2 > \\end align > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_02_02_backtracking_line_search/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_02_03_exact_line_search",
    "title": "06-02-03 Tìm kiếm đường chính xác",
    "chapter": "06",
    "order": 6,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Một cách khác để thích ứng kích thước bước trong gradient descent là tìm kiếm đường chính xác . Tìm kiếm Đường chính xác là gì? Trong tìm kiếm đường chính xác, chúng ta di chuyển theo hướng của gradient âm và chọn kích thước bước tốt nhất có thể. Đối với biểu thức sau, nếu MATH , bước tiếp theo MATH di chuyển ra khỏi vị trí hiện tại. Bằng cách thay đổi MATH , chúng ta tìm kích thước bước MATH làm giảm thiểu MATH : > MATH Tìm kiếm đường chính xác hiệu quả cho các bài toán tối ưu hóa một biến, nhưng đối với các bài toán nhiều biến, việc tìm kiếm toàn diện kích thước bước tối ưu thường không thực tế. Trong thực tế, tìm kiếm lùi hiệu quả hơn và được sử dụng phổ biến hơn.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_02_03_exact_line_search/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_01_05_hessian_approximation",
    "title": "06-01-05 Tại sao Kích thước Bước lại Quan trọng?",
    "chapter": "06",
    "order": 6,
    "owner": "AI Assistant",
    "lesson_type": "supplementary",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Trong gradient descent, chọn đúng kích thước bước MATH rất quan trọng. Nhưng tại sao? Câu trả lời nằm ở việc hiểu gradient descent thực sự đang làm gì: nó đang đưa ra một giả định đơn giản về độ cong của hàm số . Ý tưởng Cốt lõi Khi chúng ta thực hiện gradient descent: > MATH Thực ra chúng ta đang giải bài toán này: > MATH Điều này có nghĩa là gì? - Số hạng đầu: \"Đi theo hướng dốc nhất\" - Số hạng thứ hai: \"Nhưng đừng đi quá xa khỏi vị trí hiện tại\" - Tham số MATH điều khiển sự cân bằng này Kích thước Bước = Tin tưởng vào Độ phẳng Hãy nghĩ về kích thước bước theo cách này: > MATH - MATH lớn : \"Tôi nghĩ hàm số khá phẳng ở đây\" → thực hiện bước lớn - MATH nhỏ : \"Tôi nghĩ hàm số rất cong ở đây\" → thực hiện bước nhỏ, cẩn thận Ví dụ Đơn giản Xét hai hàm: 1. Hàm phẳng : MATH 2. Hàm dốc : MATH Với hàm phẳng, bạn có thể dùng MATH bước lớn . Với hàm dốc, bạn cần MATH bước nhỏ để tránh vượt quá mục tiêu. Tại sao Điều này Hoạt động Hãy xem tại sao điều này cho chúng ta công thức gradient descent. Chúng ta muốn tối thiểu hóa: > MATH Lấy đạo hàm theo MATH và đặt bằng không: > MATH Giải theo MATH : > MATH Đó chính xác là cập nhật gradient descent! Số hạng MATH hoạt động như một \"lò xo\" kéo bạn về phía MATH , ngăn bạn thực hiện những bước quá lớn. Khi nào Hoạt động Tốt? Trường hợp tốt: - Hàm có độ \"dốc\" gần như nhau theo mọi hướng - Hàm hình bát như MATH Trường hợp xấu: - Hàm rất dốc theo một hướng nhưng phẳng theo hướng khác - Hàm hình \"thung lũng\" như MATH Cách Chọn Kích thước Bước Quy tắc thực tế : Bắt đầu với MATH và điều chỉnh: - Nếu gradient descent dao động mạnh → làm MATH nhỏ hơn - Nếu gradient descent hội tụ rất chậm → làm MATH lớn hơn - Nếu bạn hiểu rõ hàm số → dùng MATH Trực quan Hình ảnh Hãy tưởng tượng bạn đang đi xuống một ngọn đồi trong bóng tối với đèn pin: - Kích thước bước lớn : \"Tôi nghĩ con đường phía trước mượt mà\" → thực hiện bước dài rủi ro: có thể bước vào hố - Kích thước bước nhỏ : \"Tôi nghĩ con đường phía trước gồ ghề\" → thực hiện bước nhỏ an toàn nhưng chậm Gradient descent làm điều tương tự về mặt toán học! Bức tranh Tổng thể Gradient descent thực sự làm gì: 1. Nhìn vào độ dốc gradient 2. Giả định hàm số có dạng \"bát\" xung quanh bạn 3. Thực hiện một bước về phía đáy của cái bát tưởng tượng đó 4. Lặp lại Tại sao kích thước bước quan trọng: - Quá lớn → bạn vượt quá mục tiêu và nảy qua nảy lại - Quá nhỏ → bạn mất mãi mới đến đích - Vừa phải → hội tụ mượt mà, nhanh chóng Điểm Mấu chốt Kích thước bước không phải ma thuật - nó là phỏng đoán của bạn về độ cong của hàm số : - MATH có nghĩa là \"Tôi nghĩ hàm này rất cong\" - MATH có nghĩa là \"Tôi nghĩ hàm này khá phẳng\" Phỏng đoán càng chính xác, gradient descent hội tụ càng nhanh!",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_01_05_hessian_approximation/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_01_05_hessian_exercises",
    "title": "06-01-05 Bài tập: Hiểu về Kích thước Bước và Độ cong",
    "chapter": "06",
    "order": 7,
    "owner": "AI Assistant",
    "lesson_type": "exercises",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Bài tập 1: Suy luận Xấp xỉ Bậc hai Xét xấp xỉ bậc hai được sử dụng trong gradient descent: MATH Phần A : Chứng minh rằng tối thiểu hóa xấp xỉ này theo MATH cho cập nhật gradient descent MATH . Phần B : Điều gì xảy ra nếu chúng ta thay đổi hệ số thành MATH thay vì MATH ? Điều này ảnh hưởng như thế nào đến kích thước bước? Phần C : Diễn giải số hạng MATH theo hình học. Nó ngăn chặn điều gì? --- Bài tập 2: Kích thước Bước và Độ cong Hàm Xét hai hàm bậc hai: - MATH - MATH Phần A : Tính ma trận Hessian ma trận các đạo hàm riêng bậc hai cho cả hai hàm. Phần B : Nếu chúng ta xấp xỉ cả hai Hessian bằng MATH , giá trị MATH nào cho xấp xỉ tốt nhất cho mỗi hàm? Phần C : Bắt đầu từ điểm MATH , thực hiện 3 lần lặp gradient descent trên cả hai hàm sử dụng kích thước bước tối ưu của bạn. So sánh hành vi hội tụ. --- Bài tập 3: Số Điều kiện và Hội tụ Với hàm MATH với MATH : Phần A : Số điều kiện MATH là gì? Điều này liên quan như thế nào đến \"hình dạng\" của hàm? Phần B : Chứng minh rằng kích thước bước tối ưu cho hội tụ nhanh nhất là MATH . Phần C : So sánh tốc độ hội tụ cho: - MATH MATH - MATH MATH - MATH MATH Điều gì xảy ra khi số điều kiện tăng? --- Bài tập 4: Kích thước Bước theo Tọa độ Thay vì sử dụng cùng kích thước bước cho tất cả tọa độ, xét: MATH MATH Phần A : Với MATH , lựa chọn MATH nào làm cho mỗi tọa độ hội tụ trong đúng một bước? Phần B : Điều này liên quan như thế nào đến việc xấp xỉ Hessian bằng ma trận đường chéo thay vì MATH ? Phần C : Lập trình cách tiếp cận theo tọa độ này và so sánh với gradient descent chuẩn trên hàm bậc hai điều kiện xấu. --- Bài tập 5: Trực quan hóa Chất lượng Xấp xỉ Phần A : Với hàm MATH , vẽ đường đồng mức hàm thực và đường đồng mức của xấp xỉ bậc hai MATH quanh điểm MATH . Phần B : Thử các giá trị MATH khác nhau và quan sát cách chất lượng xấp xỉ thay đổi. Phần C : Giá trị MATH nào làm cho đường đồng mức xấp xỉ giống nhất với đường đồng mức hàm thực? --- Bài tập 6: Chiến lược Chọn Kích thước Bước So sánh ba chiến lược chọn kích thước bước trên hàm MATH với: MATH 1. Bước cố định nhỏ : MATH 2. Bước cố định lớn : MATH 3. Bước thích ứng : MATH với MATH là trị riêng lớn nhất và nhỏ nhất của MATH Phần A : Tính các trị riêng của MATH và xác định kích thước bước thích ứng. Phần B : Bắt đầu từ MATH , chạy gradient descent với mỗi chiến lược trong 20 lần lặp. Phần C : Vẽ đường cong hội tụ và quỹ đạo. Chiến lược nào hoạt động tốt nhất và tại sao? --- Bài tập 7: Hàm Thực vs Xấp xỉ Bậc hai Xét hàm không bậc hai MATH . Phần A : Tính gradient và Hessian của hàm này. Phần B : Tại điểm MATH , so sánh: - Một bước gradient descent với kích thước bước MATH - Một bước sử dụng xấp xỉ bậc hai với Hessian thực - Một bước sử dụng xấp xỉ bậc hai với MATH với MATH Phần C : Xấp xỉ nào cho kết quả gần với hướng tối thiểu thực hơn? --- Bài tập Lập trình Bài tập 8: Lập trình và So sánh Lập trình và so sánh hiệu suất của chúng: python import numpy as np import matplotlib.pyplot as plt def quadratic function x, A : \"\"\"Tính f x = 0.5 x^T A x\"\"\" return 0.5 x.T @ A @ x def gradient x, A : \"\"\"Tính gradient của f x = 0.5 x^T A x\"\"\" return A @ x def standard gd A, x0, step size, max iter=100 : \"\"\"Gradient descent chuẩn\"\"\" x = x0.copy history = x.copy for i in range max iter : grad = gradient x, A x = x - step size grad history.append x.copy if np.linalg.norm grad < 1e-8: break return np.array history def coordinate wise gd A, x0, step sizes, max iter=100 : \"\"\"Gradient descent theo tọa độ\"\"\" x = x0.copy history = x.copy for i in range max iter : grad = gradient x, A Áp dụng kích thước bước khác nhau cho mỗi tọa độ x = x - step sizes grad history.append x.copy if np.linalg.norm grad < 1e-8: break return np.array history Kiểm tra trên các số điều kiện khác nhau condition numbers = 1, 4, 16, 64 x0 = np.array 2.0, 2.0 for kappa in condition numbers: A = np.array kappa, 0 , 0, 1 Kích thước bước tối ưu cho GD chuẩn eigenvals = np.linalg.eigvals A t optimal = 2 / eigenvals.max + eigenvals.min Kích thước bước tối ưu theo tọa độ t coord = 2 / np.diag A Chạy cả hai phương pháp history std = standard gd A, x0, t optimal history coord = coordinate wise gd A, x0, t coord Vẽ kết quả plt.figure figsize= 12, 4 plt.subplot 1, 2, 1 plt.semilogy quadratic function x, A for x in history std , 'b-', label='GD Chuẩn' plt.semilogy quadratic function x, A for x in history coord , 'r--', label='GD Theo tọa độ' plt.xlabel 'Lần lặp' plt.ylabel 'Giá trị Hàm' plt.legend plt.title f'Hội tụ κ = kappa ' plt.subplot 1, 2, 2 plt.plot history std :, 0 , history std :, 1 , 'b-o', label='GD Chuẩn', markersize=3 plt.plot history coord :, 0 , history coord :, 1 , 'r--s', label='GD Theo tọa độ', markersize=3 plt.xlabel 'x₁' plt.ylabel 'x₂' plt.legend plt.title f'Quỹ đạo κ = kappa ' plt.axis 'equal' plt.tight layout plt.show Bài tập 9: Trực quan hóa Tương tác Tạo một biểu đồ tương tác hiển thị: 1. Đường đồng mức hàm thực 2. Đường đồng mức xấp xỉ bậc hai 3. Quỹ đạo gradient descent 4. Thanh trượt để điều chỉnh kích thước bước và xem nó ảnh hưởng như thế nào đến hội tụ Yêu cầu : - Sử dụng matplotlib widgets hoặc plotly cho tính tương tác - Hiển thị cả ví dụ điều kiện tốt và điều kiện xấu - Hiển thị lỗi xấp xỉ khi kích thước bước thay đổi --- Đề cương Lời giải Lời giải Bài tập 1: A : Lấy MATH Giải: MATH B : Kích thước bước hiệu quả trở thành MATH C : Số hạng hoạt động như \"phạt gần\" - nó ngăn không cho thực hiện bước quá xa từ điểm hiện tại Lời giải Bài tập 2: A : - MATH - MATH B : - Với MATH : MATH - Với MATH : MATH tối thiểu hóa MATH Lời giải Bài tập 3: A : MATH đo lường mức độ \"kéo dài\" của đường đồng mức ellip B : Tối thiểu hóa hệ số hội tụ MATH C : Số điều kiện cao hơn → hội tụ chậm hơn, hành vi dao động nhiều hơn Kết quả Học tập Chính: 1. Hiểu biết trực quan : Kích thước bước liên quan đến độ cong giả định 2. Kỹ năng thực tế : Cách chọn kích thước bước cho các bài toán khác nhau 3. Hiểu biết lý thuyết : Kết nối giữa tính chất hàm và hành vi tối ưu hóa 4. Kinh nghiệm lập trình : Coding và so sánh các cách tiếp cận khác nhau Các bài tập này xây dựng hiểu biết mà không yêu cầu các khái niệm nâng cao như phương pháp Newton, thay vào đó tập trung vào mối quan hệ cơ bản giữa kích thước bước, độ cong và hành vi hội tụ.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_01_05_hessian_exercises/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_03_convergence_analysis",
    "title": "06-03 Phân tích hội tụ",
    "chapter": "06",
    "order": 7,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Trong phần này, chúng ta phân tích sự hội tụ của Gradient Descent. Chúng ta sẽ xem xét các cận sai số cho sự hội tụ trong trường hợp kích thước bước cố định và trong trường hợp tìm kiếm lùi. Ngoài ra, chúng ta sẽ phân tích các cận sai số khi điều kiện lồi mạnh được thỏa mãn.\"",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_03_convergence_analysis/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_03_01_convex_function_quadratic_upper_bound",
    "title": "06-03-01 Cận trên bậc hai của hàm lồi",
    "chapter": "06",
    "order": 8,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Giới thiệu Cận trên bậc hai là một tính chất cơ bản của các hàm lồi trơn, cung cấp một công cụ quan trọng để phân tích và thiết kế các thuật toán tối ưu hóa. Tính chất này thiết lập rằng bất kỳ hàm lồi trơn nào cũng có thể được chặn trên bởi một hàm bậc hai, điều này có những ý nghĩa quan trọng cho việc phân tích hội tụ của các phương pháp dựa trên gradient. Động lực Tại sao chúng ta quan tâm đến cận trên bậc hai? 1. Thiết kế thuật toán : Nhiều thuật toán tối ưu hóa như gradient descent dựa vào các xấp xỉ cục bộ của hàm mục tiêu. Cận trên bậc hai cung cấp một cách hệ thống để xây dựng các xấp xỉ này. 2. Phân tích hội tụ : Cận trên bậc hai cho phép chúng ta chứng minh tốc độ hội tụ cho các thuật toán tối ưu hóa bằng cách chặn mức độ thay đổi của hàm. 3. Lựa chọn bước nhảy : Hằng số Lipschitz MATH trong cận trực tiếp xác định bước nhảy an toàn cho gradient descent. Tính chất Cận trên Bậc hai Định lý : Nếu MATH là lồi và MATH liên tục Lipschitz với hằng số MATH , thì MATH thỏa mãn cận trên bậc hai: > MATH \\begin align f y & \\le f x + \\nabla f x ^T y-x + \\frac L 2 \\| y - x \\|^2 2 \\quad \\forall x, y \\end align MATH Diễn giải Hình học Bất đẳng thức này phát biểu rằng: - Xấp xỉ tuyến tính MATH khai triển Taylor bậc nhất ước lượng thấp MATH do tính lồi - Cận trên bậc hai MATH ước lượng cao MATH - Hàm MATH được \"kẹp\" giữa hai cận này Đặc trưng Tương đương Hệ quả : Đối với bất kỳ hàm lồi trơn MATH nào, hàm sau đây là lồi: > MATH \\begin align g x & = \\frac L 2 \\| x \\|^2 2 - f x \\quad \\text với dom g = dom f \\end align MATH Điều này có nghĩa là MATH có thể được viết như hiệu của một hàm bậc hai và một hàm lồi. Chứng minh Chúng ta sẽ chứng minh cả cận trên bậc hai và đặc trưng tương đương. Chứng minh dựa trên hai tính chất chính của các hàm lồi trơn. Kiến thức Cần thiết Định nghĩa 1 Toán tử Đơn điệu : Trong không gian vector MATH , toán tử MATH là đơn điệu nếu: > MATH Tính chất 1 Tính đơn điệu của Gradient : Nếu MATH là lồi và khả vi, thì MATH là toán tử đơn điệu: > MATH Tính chất 2 Liên tục Lipschitz : MATH liên tục Lipschitz với hằng số MATH : > MATH Chứng minh Cận trên Bậc hai Bước 1 : Xét hàm MATH với MATH . Theo định lý cơ bản của giải tích: > MATH \\begin align f y - f x &= h 1 - h 0 = \\int 0^1 h' t dt \\\\ &= \\int 0^1 \\nabla f x + t y-x ^T y-x dt \\end align MATH Bước 2 : Chúng ta có thể viết lại như sau: > MATH \\begin align f y - f x &= \\nabla f x ^T y-x + \\int 0^1 \\nabla f x + t y-x - \\nabla f x ^T y-x dt \\end align MATH Bước 3 : Sử dụng bất đẳng thức Cauchy-Schwarz và tính liên tục Lipschitz: > MATH \\begin align & \\nabla f x + t y-x - \\nabla f x ^T y-x \\\\ &\\le \\|\\nabla f x + t y-x - \\nabla f x \\| \\cdot \\|y-x\\| \\\\ &\\le L \\cdot t\\|y-x\\| \\cdot \\|y-x\\| = Lt\\|y-x\\|^2 \\end align MATH Bước 4 : Tích phân trên MATH : > MATH \\begin align f y - f x &\\le \\nabla f x ^T y-x + \\int 0^1 Lt\\|y-x\\|^2 dt \\\\ &= \\nabla f x ^T y-x + L\\|y-x\\|^2 \\int 0^1 t dt \\\\ &= \\nabla f x ^T y-x + \\frac L 2 \\|y-x\\|^2 \\end align MATH Do đó: MATH Chứng minh Đặc trưng Tương đương Định lý : Hàm MATH là lồi. Chứng minh : Chúng ta cần chỉ ra rằng MATH nửa xác định dương . Vì MATH , ta có: - MATH - MATH Với bất kỳ vector MATH nào, chúng ta cần chỉ ra MATH : > MATH \\begin align v^T \\nabla^2 g x v &= v^T LI - \\nabla^2 f x v \\\\ &= L\\|v\\|^2 - v^T \\nabla^2 f x v \\end align MATH Từ tính liên tục Lipschitz của MATH , chúng ta có thể chỉ ra rằng MATH , có nghĩa là: MATH Do đó: MATH Điều này chứng minh rằng MATH là lồi. MATH Ví dụ Ví dụ 1: Hàm Bậc hai Xét MATH với MATH nửa xác định dương . - MATH - MATH - Nếu MATH , thì MATH Cận trên bậc hai trở thành: MATH Đối với hàm bậc hai, cận này là chặt khi MATH . Ví dụ 2: Hàm Mất mát Logistic Xét hàm mất mát logistic MATH với MATH . - MATH - MATH Vì MATH với mọi MATH , ta có: MATH Do đó, MATH và cận trên bậc hai là: MATH Ví dụ 3: Bình phương Tối thiểu Với MATH trong đó MATH : - MATH - MATH - MATH bình phương giá trị kỳ dị lớn nhất Cận trên bậc hai là: MATH Ứng dụng trong Tối ưu hóa 1. Kích thước Bước nhảy của Gradient Descent Cận trên bậc hai trực tiếp xác định kích thước bước nhảy an toàn tối đa cho gradient descent. Nếu chúng ta sử dụng kích thước bước MATH , thì: MATH Khi MATH , vế phải đơn giản hóa thành: MATH Điều này đảm bảo giảm đủ tại mỗi lần lặp. 2. Phân tích Tốc độ Hội tụ Đối với gradient descent với kích thước bước MATH , cận trên bậc hai cho phép chúng ta chứng minh: MATH trong đó MATH là tham số lồi mạnh. Điều này cho hội tụ tuyến tính với tốc độ MATH . 3. Phương pháp Gradient Gần kề Trong tối ưu hóa tổng hợp MATH với MATH trơn và MATH không trơn, cận trên bậc hai của MATH dẫn đến cập nhật gradient gần kề: MATH trong đó MATH đảm bảo hội tụ. 4. Phương pháp Tăng tốc Các phương pháp tiên tiến như gradient tăng tốc Nesterov và FISTA cũng dựa vào cận trên bậc hai để đạt được tốc độ hội tụ tối ưu MATH cho các hàm lồi trơn. Những Điểm Chính 1. Tính chất Cơ bản : Cận trên bậc hai là nền tảng của lý thuyết tối ưu hóa lồi trơn. 2. Thiết kế Thuật toán : Nó cung cấp cơ sở lý thuyết để chọn kích thước bước trong các phương pháp dựa trên gradient. 3. Phân tích Hội tụ : Nó cho phép chứng minh nghiêm ngặt tốc độ hội tụ của các thuật toán tối ưu hóa. 4. Tác động Thực tế : Hiểu biết về MATH giúp các nhà thực hành điều chỉnh thuật toán hiệu quả. 5. Trực giác Hình học : Nó hình thức hóa ý tưởng rằng các hàm lồi trơn không \"cong quá mức\" - chúng được chặn trên bởi các parabola. Trực quan Tương tác Sơ đồ sau minh họa tính chất cận trên bậc hai: f y | | Cận Trên Bậc Hai | f x + ∇f x ᵀ y-x + L/2 ||y-x||² | / | / | / Hàm thực f y |/ / /| / / | / / | / Xấp xỉ Tuyến tính / | / f x + ∇f x ᵀ y-x / | / / |/ / x y / | → | Những Quan sát Chính : - Xấp xỉ tuyến tính đường tiếp tuyến nằm dưới MATH do tính lồi - Cận trên bậc hai nằm trên MATH - Hàm thực MATH được kẹp giữa hai cận này - Khoảng cách giữa các cận phụ thuộc vào MATH hằng số Lipschitz và MATH Cân nhắc Tính toán Ước lượng Hằng số Lipschitz Trong thực tế, việc tìm hằng số Lipschitz chính xác MATH có thể khó khăn. Các phương pháp phổ biến: 1. Phân tích Lý thuyết : Đối với các lớp hàm cụ thể bậc hai, logistic, v.v. 2. Phương pháp Phổ : MATH khi có Hessian 3. Phương pháp Thích ứng : Bắt đầu với ước lượng và điều chỉnh dựa trên điều kiện giảm đủ 4. Tìm kiếm Đường : Sử dụng backtracking để tìm kích thước bước phù hợp Triển khai Thuật toán Thực tế python def gradient descent with lipschitz f, grad f, x0, L estimate=1.0, max iter=1000 : \"\"\" Gradient descent với ước lượng hằng số Lipschitz thích ứng \"\"\" x = x0 L = L estimate for k in range max iter : grad = grad f x Thử bước với ước lượng L hiện tại alpha = 1.0 / L x new = x - alpha grad Kiểm tra điều kiện giảm đủ if f x new <= f x - 0.5 alpha np.linalg.norm grad 2: x = x new Chấp nhận bước else: L = 2 Tăng ước lượng L và thử lại continue Tùy chọn: giảm L nếu bước quá bảo thủ if k % 10 == 0: L = 0.9 return x Phương pháp thích ứng này đảm bảo hội tụ trong khi tự động điều chỉnh ước lượng hằng số Lipschitz.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_03_01_convex_function_quadratic_upper_bound/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_03_02_convergence_analysis_and_proof",
    "title": "06-03-02 Convergence analysis & Proof",
    "chapter": "06",
    "order": 9,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Suppose MATH is convex and differentiable with MATH , and MATH is Lipschitz continuous with constant MATH : > MATH for any MATH Reference: Wikipedia: Lipschitz continuity https://en.wikipedia.org/wiki/Lipschitz continuity Convergence Theorem Gradient descent with fixed step size MATH satisfies: > MATH \\begin align f x^ k - f^ \\le \\frac \\| x^ 0 - x^ \\|^2 2 2tk \\end align MATH With fixed step size, the convergence rate is MATH . To achieve MATH , MATH iterations are needed. Proof If MATH is Lipschitz continuous and MATH is convex, then MATH has a quadratic upper bound see 06-03-02 % multilang post url contents/chapter06/21-03-20-06 03 02 convex function quadratic upper bound % . > MATH \\begin align f y \\le f x + \\nabla f x ^T y-x + \\frac L 2 \\| y - x \\|^2 2 \\quad \\forall x, y \\end align MATH For gradient descent MATH , substitute MATH : > MATH \\begin align f x^+ & \\le f x - t 1 - \\frac Lt 2 \\| \\nabla f x \\|^2 2 \\\\\\ & \\le f x - \\frac t 2 \\| \\nabla f x \\|^2 2 \\quad \\text if t \\le 1/L \\end align MATH Thus, MATH and gradient descent converges.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_03_02_convergence_analysis_and_proof/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_03_03_convergence_analysis_for_backtracking",
    "title": "06-03-03 Convergence analysis for backtracking",
    "chapter": "06",
    "order": 10,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Suppose MATH is convex and differentiable with MATH , and MATH is Lipschitz continuous with constant MATH : > MATH for any MATH Reference: Wikipedia: Lipschitz continuity https://en.wikipedia.org/wiki/Lipschitz continuity Convergence Theorem Gradient descent with backtracking line search satisfies: > MATH \\begin align f x^ k - f^ \\le \\frac \\| x^ 0 - x^ \\| 2^2 2 t min k , \\quad t min = \\min \\ 1, \\beta/L \\ \\end align MATH The convergence rate for backtracking line search is similar to that for fixed step size, with the step size MATH replaced by MATH . If MATH is not too small, the performance is comparable to fixed step size MATH vs. MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_03_03_convergence_analysis_for_backtracking/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_03_04_convergence_analysis_under_strong_convexity",
    "title": "06-03-04 Convergence analysis under strong convexity",
    "chapter": "06",
    "order": 11,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "If MATH satisfies the following condition, it is strongly convex assuming MATH is twice differentiable and MATH : > MATH \\begin align f y \\ge f x + \\nabla f x ^T y-x + \\frac m 2 \\| y-x \\| 2^2, \\quad \\forall x, y \\end align MATH Here, MATH has a quadratic lower bound, and the constant MATH is determined by the minimum eigenvalue of the Hessian of MATH . For any convex function MATH , MATH is strongly convex if: > MATH \\begin align g x = f x - \\frac m 2 \\| x \\| 2^2 \\quad \\text is convex for all x \\text and m > 0 \\end align MATH Convergence Theorem Given Lipschitz continuity and strong convexity, the following theorem holds where MATH is the Lipschitz constant and MATH is the strong convexity constant : Gradient descent with fixed step size MATH or backtracking line search satisfies: > MATH \\begin align f x^ k - f^ \\le c^k \\frac L 2 \\| x^ 0 - x^ \\| 2^2, \\quad c = 1 - \\frac m L , \\quad 0 MATH \\begin align f x^+ \\le f x - \\frac 1 2L \\| \\nabla f x \\| 2^2 \\end align MATH Subtracting MATH from both sides: > MATH \\begin align f x^+ - f x^ \\le f x - f x^ - \\frac 1 2L \\| \\nabla f x \\| 2^2 \\end align MATH Since Gradient Descent satisfies the condition: > MATH \\begin align f x - f x^ \\le \\frac 1 2m \\| \\nabla f x \\| 2^2 \\end align MATH We can substitute to get: > MATH \\begin align f x^+ - f x^ & \\le f x - f x^ - \\frac m L f x - f x^ \\\\ & = 1 - \\frac m L f x - f x^ \\\\ & = c f x - f x^ \\\\ \\end align MATH Iterating this process gives: > MATH \\begin align f x^ k - f x^ \\le c^k f x^ 0 - f x^ \\\\ \\end align MATH From the Taylor expansion of the function with MATH and MATH : > MATH \\begin align f y \\le f x + \\nabla f x ^T y-x + \\frac L 2 \\lVert y - x \\rVert^2 2 \\space \\space \\forall x, y \\end align MATH And since the function is convex, we have: > MATH \\begin align f x^ 0 & \\le f x^ + \\nabla f x^ ^T x^ 0 - x^ + \\frac L 2 \\lVert x^ 0 - x^ \\rVert^2 2 \\\\\\\\ & = f x^ + \\frac L 2 \\lVert x^ 0 - x^ \\rVert^2 2 \\\\\\\\ \\end align MATH Rearranging gives: > MATH \\begin align f x^ 0 - f x^ & \\le \\frac L 2 \\lVert x^ 0 - x^ \\rVert^2 2 \\\\\\\\ \\end align MATH Substituting this into the previous inequality results in: > MATH \\begin align f x^ k - f x^ & \\le c^k \\frac L 2 \\lVert x^ 0 - x^ \\rVert^2 2 \\\\\\ \\end align MATH This proves the Convergence Theorem for Gradient Descent under Strong Convexity. Linear convergence When MATH is strongly convex, the convergence rate becomes MATH , which is exponential. To achieve MATH , it requires MATH iterations. Without strong convexity, it would require MATH iterations. The convergence rate MATH appears linear on a semi-log plot, as shown below. Fig 1 Linear convergence 1 Here, the constant MATH in MATH is given by MATH and depends on the condition number MATH . A larger condition number results in slower convergence where the condition number is the ratio of the largest eigenvalue to the smallest eigenvalue .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_03_04_convergence_analysis_under_strong_convexity/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_03_05_look_at_the_conditions_and_practicalities",
    "title": "06-03-05 Xem xét điều kiện & Tính thực tiễn",
    "chapter": "06",
    "order": 12,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Điều kiện liên tục Lipschitz & Tính lồi mạnh Hãy xem xét các điều kiện cho tính liên tục Lipschitz và tính lồi mạnh sử dụng MATH làm ví dụ. Tính liên tục Lipschitz của MATH : Điều này có nghĩa là MATH . Vì MATH , chúng ta có MATH . Tính lồi mạnh của MATH : Điều này có nghĩa là MATH . Vì MATH , chúng ta có MATH . Nếu MATH là ma trận MATH và MATH , thì MATH , vậy MATH không thể lồi mạnh. Ngay cả khi MATH , số điều kiện MATH có thể rất lớn. Nếu hàm MATH lồi mạnh và có gradient Lipschitz, thì nó thỏa mãn điều sau. Bạn có thể nghĩ về MATH như được kẹp giữa hai hàm bậc hai. > MATH và MATH Thỏa mãn cả hai điều kiện cho mọi MATH có thể rất mạnh. Tuy nhiên, nếu chúng ta suy nghĩ cẩn thận hơn, chúng ta có thể thấy rằng điều kiện này chỉ cần thiết cho tập mức phụ sau đây. > MATH Tính thực tiễn Tiêu chí dừng cho các thuật toán tối ưu hóa Trong thực tế, các thuật toán tối ưu hóa cần các tiêu chí dừng được định nghĩa rõ ràng để xác định khi nào chấm dứt quá trình lặp. Dưới đây là những điều kiện dừng phổ biến nhất: 1. Độ lớn Gradient gần bằng Không: Đây là điều kiện dừng lý tưởng cho các bài toán tối ưu hóa không ràng buộc, dựa trên thực tế rằng gradient của hàm mục tiêu bằng không tại các cực trị địa phương. MATH \\|\\nabla f \\mathbf x k \\| \\leq \\epsilon 1 MATH trong đó MATH là điểm hiện tại tại lần lặp MATH , và MATH là một ngưỡng dương nhỏ. Nếu MATH là nghiệm, thì MATH . Nếu MATH lồi mạnh, thì: > MATH 2. Thay đổi nhỏ trong giá trị hàm mục tiêu: Thuật toán dừng khi giá trị hàm mục tiêu không còn thay đổi đáng kể giữa các lần lặp liên tiếp. MATH |f \\mathbf x k+1 - f \\mathbf x k | \\leq \\epsilon 2 MATH trong đó MATH là một ngưỡng dương nhỏ. 3. Thay đổi nhỏ trong biến tham số : Thuật toán dừng khi các tham số mô hình không còn thay đổi đáng kể giữa các lần lặp. MATH \\|\\mathbf x k+1 - \\mathbf x k\\| \\leq \\epsilon 3 MATH trong đó MATH là một ngưỡng dương nhỏ. 4. Số lần lặp tối đa: Để ngăn thuật toán chạy vô hạn hoặc quá lâu, một giới hạn trên về số lần lặp được đặt. MATH k \\geq \\text MaxIterations MATH Đây là điều kiện dừng an toàn đảm bảo thuật toán sẽ chấm dứt trong thời gian hợp lý, ngay cả khi nó chưa đạt được sự hội tụ hoàn hảo. 5. Thời gian chạy tối đa: Tương tự như giới hạn lần lặp tối đa, thuật toán có thể được dừng nếu nó đã chạy quá thời gian cho phép. MATH \\text ElapsedTime \\geq \\text MaxTime MATH 6. Điều kiện kết hợp: Trong thực tế, nhiều điều kiện dừng thường được sử dụng kết hợp. Ví dụ, thuật toán dừng nếu bất kỳ điều kiện nào ở trên được thỏa mãn. Điều này giúp cân bằng giữa độ chính xác và hiệu quả tính toán. Tham khảo Quá trình suy dẫn Quá trình suy dẫn cho phương trình trên như sau. Vì MATH thỏa mãn tính lồi mạnh, tồn tại hằng số MATH sao cho: > MATH \\begin align \\nabla^2 f x \\succeq mI \\\\ \\end align MATH Hãy mở rộng hàm MATH bằng chuỗi Taylor bậc hai. > MATH \\begin align f y = f x + \\nabla f x ^T y−x + \\frac 1 2 y−x ^T \\nabla^2 f x y−x , \\space \\forall x, y \\end align MATH Sau đó, theo MATH ở trên, chúng ta có thể sắp xếp số hạng cuối như một điều kiện cận dưới. > MATH \\begin align f y & \\ge f x + \\nabla f x ^T y−x + \\frac m 2 \\lVert y−x \\rVert 2^2, \\space \\forall x, y \\end align MATH Lấy đạo hàm MATH theo MATH cho MATH . Thay MATH vào khai triển Taylor: > MATH \\begin align f y & \\ge f x + \\nabla f x ^T \\tilde y −x + \\frac m 2 \\lVert \\tilde y −x \\rVert 2^2 \\\\ & = f x - \\frac 1 2m \\lVert \\nabla f x \\rVert 2^2 \\end align MATH Do đó, thay MATH bằng MATH cho: > MATH \\begin align f^ \\ge f x - \\frac 1 2m \\lVert \\nabla f x \\rVert 2^2 \\end align MATH Quy tắc dừng trên được suy dẫn như sau: > MATH \\begin align f x - f^ \\le \\frac 1 2m \\lVert \\nabla f x \\rVert^2 2 & \\le \\epsilon \\\\ \\lVert \\nabla f x \\rVert^2 2 & \\le 2m\\epsilon \\\\ \\lVert \\nabla f x \\rVert 2 & \\le \\sqrt 2m\\epsilon \\\\ \\end align MATH Ưu điểm và nhược điểm của Gradient Descent Ưu điểm Thuật toán đơn giản và chi phí mỗi lần lặp thấp. Rất nhanh cho các bài toán lồi mạnh, có điều kiện tốt. Nhược điểm Nói chung chậm vì nhiều bài toán không lồi mạnh hoặc có điều kiện tốt. Không thể xử lý các hàm không khả vi.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_03_05_look_at_the_conditions_and_practicalities/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_03_06_can_we_do_better",
    "title": "06-03-06 Can we do better?",
    "chapter": "06",
    "order": 13,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Gradient descent has a convergence rate of MATH for problems represented by functions that have Lipschitz gradients and are convex and differentiable. Are there first-order methods that are faster than gradient descent? First-order method A first-order method can express changes at the MATH -th iteration as follows. Therefore, the change at the MATH -th iteration is expressed as the span of gradients from the initial position MATH to MATH . > MATH span MATH Theorem Nesterov Nesterov's theorem provides a lower bound for the convergence of first-order methods. > Nesterov Theorem For any MATH and starting point MATH , there exists a function MATH such that any first-order method satisfies the following condition where MATH denotes the dimension : \\begin align f x^ k −f^ \\star ≥ \\frac 3L \\lVert x^ 0 −x^ \\star \\rVert 2^2 32 k + 1 ^2 \\\\\\ \\end align Since Nesterov's theorem has MATH in the denominator of the lower bound, the convergence rate becomes MATH . Furthermore, the number of iterations becomes MATH . We will examine this content in detail later.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_03_06_can_we_do_better/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_04_gradient_boosting",
    "title": "06-04 Gradient boosting",
    "chapter": "06",
    "order": 14,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Gradient boosting Gradient boosting là một phương pháp sử dụng gradient descent để tạo ra các cây một cách tuần tự, đồng thời bù đắp cho các lỗi của các cây trước đó khi cố gắng dự đoán kết quả với một mô hình ensemble bao gồm nhiều cây. Gradient Boosting có thể được sử dụng cho cả hồi quy và phân lớp. Để biết thêm thông tin chi tiết, tham khảo blog Gradient Boosting from scratch https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d Tham khảo Thuật toán functional gradient descent Gradient boosting được giới thiệu như một thuật toán functional gradient descent bởi Llew Mason, Jonathan Baxter, Peter Bartlett và Marcus Frean. Thuật toán functional gradient descent tối ưu hóa hàm mất mát trên không gian hàm bằng cách liên tục lựa chọn các hàm có hướng âm của gradient, do đó thực hiện gradient descent. Để biết thêm thông tin chi tiết, tham khảo Gradient Boosting https://en.wikipedia.org/wiki/Gradient boosting Tham khảo Boosting vs Bagging Boosting là một kỹ thuật ensemble tạo ra các weak learner một cách tuần tự để dự đoán kết quả. Learner giai đoạn tiếp theo học từ dữ liệu mà learner giai đoạn trước đó đã dự đoán sai, và kết quả của các learner được tạo ra tuần tự được kết hợp để tạo ra kết quả cuối cùng. Bagging là một kỹ thuật ensemble tạo ra các weak learner độc lập với nhau để dự đoán kết quả. Do đó, mỗi learner chạy song song và kết quả của chúng được kết hợp để tạo ra kết quả cuối cùng. Để biết thêm thông tin chi tiết, tham khảo blog What is the difference between Bagging and Boosting? https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/ Gradient Boosting Hãy xem xét nền tảng về cách Gradient Boosting được phát triển. Giả sử có một mô hình ensemble bao gồm các cây được sử dụng cho phân lớp. Mô hình này sẽ muốn dự đoán kết quả sao cho tối thiểu hóa lỗi với các giá trị quan sát được. Gọi các giá trị quan sát được là MATH , MATH , dữ liệu đầu vào là MATH , và các giá trị dự đoán là MATH , MATH . Như được hiển thị trong hình dưới đây, mỗi cây thuộc ensemble nhận MATH làm đầu vào và đưa ra kết quả theo các điều kiện phân nhánh trong các nút của cây. MATH Giá trị dự đoán MATH của mô hình ensemble có thể được tính toán bằng tổng có trọng số của kết quả của mỗi cây. Ở đây, MATH là kết quả được đưa ra bởi cây MATH khi nó nhận MATH làm đầu vào. > MATH \\begin equation u i = \\sum j=1 ^M \\beta j T j x i \\end equation MATH Đối với hàm mất mát, nó có thể được định nghĩa là MATH dưới dạng tổng bình phương sai số để tối thiểu hóa lỗi giữa các giá trị quan sát và dự đoán. > MATH \\begin equation \\min \\beta \\sum i=1 ^n L\\left y i, \\sum j=1 ^M \\beta j T j x i \\right \\end equation MATH Thông thường, khi xây dựng cây trong các mô hình ensemble, nhiều cây nhỏ với độ sâu cố định được tạo ra. Điều này là bởi vì việc làm cho cây nhỏ hơn sử dụng ít bộ nhớ hơn và cho phép dự đoán nhanh hơn, và khi số lượng cây tăng lên, hiệu suất của ensemble cải thiện. Thông thường, độ sâu của cây được cố định ở mức 5 hoặc ít hơn. Do đó, trong bài toán này, các điều kiện nút được định nghĩa trong mỗi cây rất đa dạng và kết quả của rất nhiều cây được kết hợp tuyến tính, làm cho không gian cây khá lớn. Vì vậy, có thể nói rằng đây là một bài toán rất khó để tối ưu hóa. Để giải quyết vấn đề này, bài toán tối ưu hóa phải được chuyển đổi thành một bài toán dễ hơn. Bài toán tối ưu hóa ban đầu là tìm MATH trọng số MATH để tối thiểu hóa hàm mất mát. Hãy nghĩ về bài toán này như một bài toán tối thiểu hóa MATH của hàm MATH đối với các giá trị dự đoán MATH . Nếu hàm MATH là hàm mất mát MATH , thì việc tìm MATH để tối thiểu hóa hàm mất mát có thể được coi là một bài toán được định nghĩa lại một cách dễ dàng. Ở đây, MATH là số lượng điểm dữ liệu. Gradient boosting đề cập đến kỹ thuật giải quyết bài toán tối thiểu hóa được định nghĩa lại MATH sử dụng gradient descent. Thuật toán Thuật toán Gradient boosting thực hiện gradient descent theo cách sau để tìm ra nghiệm tối ưu MATH của MATH . 1. Đặt giá trị ban đầu là kết quả của một cây tùy ý: MATH . Sau đó lặp lại các bước 2~4 sau đây. 2. Tính toán gradient âm cho MATH , là giá trị dự đoán gần nhất cho MATH điểm dữ liệu. > MATH \\begin equation d i = - \\left . \\left \\frac \\partial L y i,u i \\partial u i \\right \\right| u i = u i^ k-1 , i=1,\\dots,n \\end equation MATH 3. Tìm cây MATH có kết quả MATH giống nhất với các gradient MATH cho MATH điểm dữ liệu. > MATH \\begin equation \\min \\text trees T \\sum i=1 ^n d i-T x i ^2 \\end equation MATH 4. Tính toán kích thước bước MATH và cập nhật các giá trị dự đoán sử dụng MATH được tìm thấy ở trên. > MATH Thuật toán này tìm gradient MATH đối với MATH để tìm nghiệm tối ưu MATH thông qua gradient descent, tìm MATH gần nhất với MATH , và thay thế MATH thay vì gradient trong phương trình cập nhật để tìm vị trí tiếp theo. Giá trị dự đoán cuối cùng MATH thu được theo cách này có thể được thấy là giống hệt với tổng có trọng số của kết quả cây được định nghĩa trước đó. Tức là, nếu chúng ta mở rộng phương trình cập nhật đệ quy MATH trở lại MATH , chúng ta nhận được MATH , có thể được biến thành dạng tổng có trọng số của kết quả cây.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_04_gradient_boosting/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_05_stochastic_gradient_descent",
    "title": "06-05 Stochastic gradient descent",
    "chapter": "06",
    "order": 15,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Động lực: Thử thách của Big Data Hãy tưởng tượng bạn đang huấn luyện một mô hình machine learning trên hàng triệu điểm dữ liệu. Gradient descent truyền thống yêu cầu tính toán gradient cho tất cả các điểm dữ liệu trước khi thực hiện một lần cập nhật duy nhất. Điều này trở nên tốn kém về mặt tính toán và tiêu tốn bộ nhớ đối với các tập dữ liệu lớn. Câu hỏi : Điều gì sẽ xảy ra nếu chúng ta có thể tiến bộ bằng cách chỉ xem xét một điểm dữ liệu tại một thời điểm? Nền tảng Toán học Xem xét bài toán tối ưu hóa để tối thiểu hóa một tổng các hàm: MATH \\begin equation \\min x f x = \\min x \\sum i=1 ^m f i x \\end equation MATH Diễn giải thực tế : Trong machine learning, MATH thường đại diện cho mất mát trên ví dụ huấn luyện thứ MATH , trong đó MATH là các tham số mô hình. Batch Gradient Descent Phương pháp Truyền thống Gradient của tổng bằng tổng các gradient: MATH Quy tắc cập nhật trở thành: MATH \\begin equation x^ k = x^ k-1 - t k \\cdot \\sum i=1 ^ m \\nabla f i x^ k-1 , \\, k=1,2,3,\\dots \\end equation MATH Chi phí tính toán : MATH lần đánh giá gradient mỗi lần lặp, trong đó MATH là số lượng hàm hoặc điểm dữ liệu . Stochastic Gradient Descent: Giải pháp thay thế hiệu quả Ý tưởng chính : Thay vì tính toán gradient cho tất cả MATH hàm, SGD chỉ sử dụng một hàm tại mỗi lần lặp. MATH \\begin equation x^ k = x^ k-1 - t k \\cdot \\nabla f i k x^ k-1 , \\quad i k \\in \\ 1,2,\\dots,m\\ \\end equation MATH Chi phí tính toán : MATH lần đánh giá gradient mỗi lần lặp - một cải thiện to lớn! Interactive Visualization: GD vs SGD with Step Control Learning Rate: 0.1 Number of Functions m : 5 Animation Speed: 5 Execution Mode: Auto Run Manual Step-by-Step Start Gradient Descent Start SGD Pause Step Forward Reset Gradient Descent Status Ready to start SGD Status Ready to start Gradient Descent Batch Iterations: 0, Cost: 0 Gradient: 0, 0 Stochastic Gradient Descent Iterations: 0, Cost: 0 Selected Function: -, Gradient: 0, 0 Convergence Progress GD Progress: SGD Progress: Các chiến lược lựa chọn cho SGD Chỉ số hàm MATH có thể được chọn bằng các chiến lược khác nhau: 1. Quy tắc vòng tròn Cyclic Rule Mẫu : MATH - Ưu điểm : Có tính quyết định, đảm bảo tất cả các hàm đều được thăm - Nhược điểm : Có thể bị kẹt trong các mẫu tuần hoàn 2. Quy tắc ngẫu nhiên Randomized Rule Mẫu : MATH được chọn ngẫu nhiên đều từ MATH - Ưu điểm : Tránh các mẫu tuần hoàn, đảm bảo lý thuyết tốt hơn - Nhược điểm : Một số hàm có thể được thăm thường xuyên hơn những hàm khác Trong thực tế : Lựa chọn ngẫu nhiên được ưa chuộng hơn do có tính chất hội tụ tốt hơn và khả năng thoát khỏi các mẫu cục bộ. Phân tích hội tụ: Lý thuyết so với Thực tế So sánh Toán học Batch GD một epoch : MATH SGD một epoch với quy tắc vòng tròn : MATH Hiểu công thức quy tắc vòng tròn SGD Hãy phân tích công thức này từng bước để hiểu điều gì xảy ra trong một epoch hoàn chỉnh của SGD với quy tắc vòng tròn: Epoch là gì? Một epoch có nghĩa là chúng ta đã xử lý tất cả MATH hàm đúng một lần. Quy trình quy tắc vòng tròn: - Bắt đầu tại vị trí MATH - Bước 1 : Sử dụng hàm MATH , tính MATH , cập nhật thành MATH - Bước 2 : Sử dụng hàm MATH , tính MATH , cập nhật thành MATH - Bước 3 : Sử dụng hàm MATH , tính MATH , cập nhật thành MATH - ... - Bước m : Sử dụng hàm MATH , tính MATH , cập nhật thành MATH Các cập nhật SGD riêng lẻ: MATH \\begin align x^ k+1 &= x^ k - t k \\nabla f 1 x^ k \\\\ x^ k+2 &= x^ k+1 - t k \\nabla f 2 x^ k+1 \\\\ x^ k+3 &= x^ k+2 - t k \\nabla f 3 x^ k+2 \\\\ &\\vdots \\\\ x^ k+m &= x^ k+m-1 - t k \\nabla f m x^ k+m-1 \\end align MATH Thu gọn các cập nhật: Nếu chúng ta thay thế đệ quy và thu thập tất cả các số hạng, chúng ta được: MATH This can be written compactly as: MATH Ý tưởng chính: Mỗi gradient MATH được đánh giá tại một vị trí khác nhau MATH , không phải tại cùng vị trí bắt đầu MATH . Key difference in update directions : MATH This difference represents how much the SGD path deviates from what batch GD would do. If the functions don't change much locally Lipschitz continuous gradients , this difference is small and SGD behaves similarly to batch GD. Concrete Example with m = 3 Functions Let's illustrate with MATH functions to make this crystal clear: Starting position: MATH SGD Cyclic Rule Process: 1. Use MATH : Compute MATH , update: MATH 2. Use MATH : Compute MATH at the new position, update: MATH 3. Use MATH : Compute MATH at the newest position, update: MATH Final SGD result after one epoch: MATH Compare with Batch GD: MATH The crucial difference: - Batch GD : All gradients evaluated at the same starting point MATH - SGD : Each gradient evaluated at a different point along the optimization path This is why SGD can make faster initial progress it's already \"exploring\" the landscape but can be noisier near the optimum. Convergence Properties Batch Gradient Descent Direction : Always in steepest descent direction Convergence : Smooth, monotonic decrease Speed : Slower per epoch, but stable Memory : Requires full dataset in memory Stochastic Gradient Descent Direction : Noisy, approximate descent direction Convergence : Oscillatory, but faster initial progress Speed : Faster per epoch, especially for large datasets Memory : Processes one sample at a time Theoretical Guarantees Lipschitz Continuity Condition : If MATH is Lipschitz continuous with constant MATH : MATH Then SGD converges to the same optimal solution as batch GD, provided the learning rate satisfies appropriate conditions. Practical Observation : - SGD excels in the exploration phase far from optimum - SGD struggles in the exploitation phase near optimum due to noise Mini-Batch Gradient Descent: The Best of Both Worlds A compromise between batch GD and SGD uses mini-batches of size MATH : MATH where MATH is a mini-batch of MATH randomly selected indices. Comparison: Batch vs Mini-batch vs SGD Method Batch Size Computation/Update Convergence Memory Usage Batch GD MATH full dataset MATH Smooth, stable High Mini-batch GD MATH typically 32-256 MATH Balanced Medium SGD 1 MATH Fast but noisy Low Những điểm chính và Hiểu biết thực tế Khi nào sử dụng SGD 1. Tập dữ liệu lớn hàng triệu mẫu 2. Các tình huống học trực tuyến 3. Môi trường bộ nhớ hạn chế 4. Các giai đoạn huấn luyện đầu để tiến bộ nhanh Khi nào sử dụng Batch GD 1. Tập dữ liệu nhỏ đến trung bình 2. Yêu cầu độ chính xác cao 3. Cần hội tụ ổn định 4. Các giai đoạn tinh chỉnh cuối cùng Thực hành tốt nhất - Lập lịch tốc độ học : Bắt đầu cao, giảm dần theo thời gian - Xáo trộn : Ngẫu nhiên hóa thứ tự dữ liệu mỗi epoch - Mini-batch : Thường là lựa chọn thực tế tốt nhất - Momentum : Giúp SGD vượt qua nhiễu và tăng tốc hội tụ Thực tế hiện đại : Hầu hết các framework deep learning sử dụng mini-batch SGD với các optimizer tinh vi Adam, RMSprop tự động điều chỉnh tốc độ học. document.addEventListener 'DOMContentLoaded', function // Global variables for demos let gdData = , sgdData = ; let gdPosition = 2, 2 , sgdPosition = 2, 2 ; let isRunning = false; let isPaused = false; let isManualMode = false; let animationId; let currentAlgorithm = null; // 'gd' or 'sgd' let algorithmState = gd: iteration: 0, position: 2, 2 , path: , functions: , totalCost: 0, gradient: 0, 0 , sgd: iteration: 0, position: 2, 2 , path: , functions: , totalCost: 0, gradient: 0, 0 , selectedFunc: -1 ; // Initialize sliders const learningRateSlider = document.getElementById 'learning-rate' ; const numFunctionsSlider = document.getElementById 'num-functions' ; const animationSpeedSlider = document.getElementById 'animation-speed' ; const lrValue = document.getElementById 'lr-value' ; const mValue = document.getElementById 'm-value' ; const speedValue = document.getElementById 'speed-value' ; if learningRateSlider learningRateSlider.addEventListener 'input', function lrValue.textContent = this.value; ; if numFunctionsSlider numFunctionsSlider.addEventListener 'input', function mValue.textContent = this.value; ; if animationSpeedSlider animationSpeedSlider.addEventListener 'input', function speedValue.textContent = this.value; ; // Execution mode radio buttons const execModeRadios = document.querySelectorAll 'input name=\"exec-mode\" ' ; execModeRadios.forEach radio => radio.addEventListener 'change', function isManualMode = this.value === 'manual'; updateControlButtons ; ; ; // Simple quadratic functions for demonstration function createFunctions m const functions = ; for let i = 0; i animationId = requestAnimationFrame step ; , delay ; else isRunning = false; updateControlButtons ; const detailedInfoId = algorithm === 'gd' ? 'gd-detailed-info' : 'sgd-detailed-info'; document.getElementById detailedInfoId .textContent = 'Converged!'; step ; // Perform a single step of the algorithm function performSingleStep algorithm const state = algorithmState algorithm ; const lr = parseFloat learningRateSlider.value ; if algorithm === 'gd' return performGDStep state, lr ; else return performSGDStep state, lr ; function performGDStep state, lr // Compute full gradient sum of all function gradients let gradX = 0, gradY = 0; for const func of state.functions const grad = func.gradient state.position 0 , state.position 1 ; gradX += grad 0 ; gradY += grad 1 ; // Average the gradients gradX /= state.functions.length; gradY /= state.functions.length; state.gradient = gradX, gradY ; // Update position state.position 0 -= lr gradX; state.position 1 -= lr gradY; state.path.push state.position.slice ; // Compute total cost state.totalCost = 0; for const func of state.functions state.totalCost += func.value state.position 0 , state.position 1 ; state.totalCost /= state.functions.length; state.iteration++; // Update visualization updateAlgorithmDisplay 'gd' ; // Check convergence const gradientMagnitude = Math.sqrt gradX gradX + gradY gradY ; return state.iteration 0.01; function performSGDStep state, lr // Select random function const funcIndex = Math.floor Math.random state.functions.length ; const func = state.functions funcIndex ; state.selectedFunc = funcIndex; // Compute gradient for selected function only const grad = func.gradient state.position 0 , state.position 1 ; state.gradient = grad; // Update position state.position 0 -= lr grad 0 ; state.position 1 -= lr grad 1 ; state.path.push state.position.slice ; // Compute total cost state.totalCost = 0; for const func of state.functions state.totalCost += func.value state.position 0 , state.position 1 ; state.totalCost /= state.functions.length; state.iteration++; // Update visualization updateAlgorithmDisplay 'sgd' ; // Check convergence SGD needs more iterations return state.iteration 0.01; function updateAlgorithmDisplay algorithm const state = algorithmState algorithm ; const plotId = algorithm === 'gd' ? 'gd-plot' : 'sgd-plot'; const color = algorithm === 'gd' ? 'steelblue' : 'orange'; // Update path visualization const plot = svg: d3.select $ plotId , g: d3.select $ plotId g , xScale: d3.scaleLinear .domain -3, 3 .range 0, 270 , yScale: d3.scaleLinear .domain -3, 3 .range 270, 0 ; if !plot.g.empty updatePath plot, state.path, color ; // Update info displays const infoId = algorithm === 'gd' ? 'gd-info' : 'sgd-info'; const gradientInfoId = algorithm === 'gd' ? 'gd-gradient-info' : 'sgd-gradient-info'; document.getElementById infoId .textContent = Iterations: MATH state.totalCost.toFixed 4 ; if algorithm === 'gd' document.getElementById gradientInfoId .textContent = Gradient: MATH state.gradient 1 .toFixed 3 ; else document.getElementById gradientInfoId .textContent = Selected Function: f MATH state.gradient 0 .toFixed 3 , $ state.gradient 1 .toFixed 3 ; // Update progress bar const progressId = algorithm === 'gd' ? 'gd-progress' : 'sgd-progress'; const maxIterations = algorithm === 'gd' ? 100 : 300; const progress = Math.min state.iteration / maxIterations 100, 100 ; document.getElementById progressId .style.width = $ progress % ; // Update detailed status const detailedInfoId = algorithm === 'gd' ? 'gd-detailed-info' : 'sgd-detailed-info'; const gradMagnitude = Math.sqrt state.gradient 0 2 + state.gradient 1 2 ; document.getElementById detailedInfoId .textContent = Step MATH state.position 0 .toFixed 3 , MATH gradMagnitude.toFixed 4 ; function updatePath plot, path, color const line = d3.line .x d => plot.xScale d 0 .y d => plot.yScale d 1 ; plot.g.selectAll '.path' .remove ; plot.g.append 'path' .datum path .attr 'class', 'path' .attr 'fill', 'none' .attr 'stroke', color .attr 'stroke-width', 2 .attr 'd', line ; // Add current position const current = path path.length - 1 ; plot.g.selectAll '.current-pos' .remove ; plot.g.append 'circle' .attr 'class', 'current-pos' .attr 'cx', plot.xScale current 0 .attr 'cy', plot.yScale current 1 .attr 'r', 5 .attr 'fill', color ; function resetDemo if animationId cancelAnimationFrame animationId ; isRunning = false; isPaused = false; currentAlgorithm = null; // Reset algorithm states algorithmState = gd: iteration: 0, position: 2, 2 , path: , functions: , totalCost: 0, gradient: 0, 0 , sgd: iteration: 0, position: 2, 2 , path: , functions: , totalCost: 0, gradient: 0, 0 , selectedFunc: -1 ; // Clear plots d3.select ' gd-plot' .selectAll \" \" .remove ; d3.select ' sgd-plot' .selectAll \" \" .remove ; // Reset info displays document.getElementById 'gd-info' .textContent = 'Iterations: 0, Cost: 0'; document.getElementById 'sgd-info' .textContent = 'Iterations: 0, Cost: 0'; document.getElementById 'gd-gradient-info' .textContent = 'Gradient: 0, 0 '; document.getElementById 'sgd-gradient-info' .textContent = 'Selected Function: -, Gradient: 0, 0 '; // Reset detailed info document.getElementById 'gd-detailed-info' .textContent = 'Ready to start'; document.getElementById 'sgd-detailed-info' .textContent = 'Ready to start'; // Reset progress bars document.getElementById 'gd-progress' .style.width = '0%'; document.getElementById 'sgd-progress' .style.width = '0%'; // Update control buttons updateControlButtons ; ;",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_05_stochastic_gradient_descent/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_06_gradent_descent_with_momentum",
    "title": "06-06 Gradient descent with momentum",
    "chapter": "06",
    "order": 15,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Vấn đề với Gradient Descent thuần túy Hãy tưởng tượng bạn đang lăn một quả bóng xuống thung lũng. Gradient descent tiêu chuẩn giống như một quả bóng không có trí nhớ - tại mỗi bước, nó chỉ xem xét độ dốc hiện tại và di chuyển tương ứng. Điều này có thể dẫn đến một số vấn đề: 1. Hội tụ chậm trong các khe hẹp : Khi hàm có gradient dốc trong một số hướng và gradient thoải trong các hướng khác 2. Dao động : Thuật toán có thể dao động qua lại trên thung lũng thay vì tiến bộ ổn định 3. Bị kẹt trong các cực tiểu địa phương kém : Không có momentum, thuật toán có thể ổn định ở các nghiệm không tối ưu Câu hỏi : Điều gì sẽ xảy ra nếu quả bóng của chúng ta có thể \"nhớ\" hướng trước đó và duy trì một chút vận tốc? Momentum: Thêm bộ nhớ vào Gradient Descent Gradient descent với momentum được lấy cảm hứng từ vật lý - cụ thể là chuyển động của một quả bóng lăn xuống đồi với ma sát. Ý tưởng chính là tích lũy một vector vận tốc kết hợp gradient hiện tại với momentum trước đó. Thuật toán Momentum Quy tắc cập nhật: MATH \\begin align v^ k &= \\beta v^ k-1 + 1-\\beta \\nabla f x^ k-1 \\\\ x^ k &= x^ k-1 - t v^ k \\end align MATH trong đó: - MATH là momentum vận tốc tại lần lặp MATH - MATH là hệ số momentum thường là 0.9 hoặc 0.99 - MATH là tốc độ học - MATH vận tốc ban đầu bằng không Công thức thay thế kiểu Nesterov Một số triển khai sử dụng dạng hơi khác: MATH \\begin align v^ k &= \\beta v^ k-1 + \\nabla f x^ k-1 \\\\ x^ k &= x^ k-1 - t v^ k \\end align MATH Ý tưởng chính : Số hạng momentum MATH là trung bình động có trọng số mũ của các gradient trong quá khứ. Hiểu hệ số Momentum MATH Hệ số momentum MATH kiểm soát thuật toán có bao nhiều \"bộ nhớ\": - MATH : Không có momentum, giảm về gradient descent tiêu chuẩn - MATH : Momentum trung bình, thường được sử dụng trong thực tế - MATH : Momentum cao, được sử dụng trong một số ứng dụng deep learning - MATH : Momentum tối đa, nhưng có thể gây bất ổn Trung bình động có trọng số mũ Momentum MATH có thể được mở rộng là: MATH Điều này cho thấy momentum cho trọng số giảm mũ cho các gradient cũ hơn. Interactive Visualization: Gradient Descent vs Momentum Learning Rate: 0.1 Momentum β : 0.9 Animation Speed: 5 Start Vanilla GD Start Momentum GD Compare Both Reset Vanilla Gradient Descent Ready to start Momentum Gradient Descent Ready to start document.addEventListener 'DOMContentLoaded', function // Momentum visualization implementation const svg = d3.select \" momentum-svg\" ; const width = 800, height = 500; const margin = top: 20, right: 20, bottom: 40, left: 40 ; // Function to optimize: f x,y = 0.5 x^2 + 5 y^2 elongated bowl function f x, y return 0.5 x x + 5 y y; function gradient x, y return x, 10 y ; // Scale setup const xScale = d3.scaleLinear .domain -6, 6 .range margin.left, width - margin.right ; const yScale = d3.scaleLinear .domain -3, 3 .range height - margin.bottom, margin.top ; // Create contour plot function createContours // Create a simple grid-based contour visualization const gridSize = 20; const contourLevels = 1, 4, 9, 16, 25, 36, 49 ; svg.selectAll \".contour\" .remove ; // Draw contour ellipses for the function f x,y = 0.5 x^2 + 5 y^2 contourLevels.forEach level => // For f x,y = 0.5 x^2 + 5 y^2 = level // This is an ellipse: x^2/ 2 level + y^2/ level/5 = 1 const a = Math.sqrt 2 level ; // semi-major axis in x direction const b = Math.sqrt level / 5 ; // semi-minor axis in y direction if a const grad = gradient x, y ; x -= lr grad 0 ; y -= lr grad 1 ; vanillaPath.push x: x, y: y ; iteration++; updateVisualization ; updateStatus ; // Stop if converged or max iterations reached if Math.abs grad 0 = maxIterations clearInterval vanillaInterval ; vanillaRunning = false; , 1000 / parseFloat document.getElementById 'momentum-speed' .value ; function runMomentumGD const lr = parseFloat document.getElementById 'momentum-lr' .value ; const beta = parseFloat document.getElementById 'momentum-beta' .value ; let x = -4, y = 2; // Starting point let vx = 0, vy = 0; // Initial velocity let iteration = 0; const maxIterations = 500; momentumPath = x: x, y: y ; momentumRunning = true; momentumInterval = setInterval => const grad = gradient x, y ; vx = beta vx + 1 - beta grad 0 ; vy = beta vy + 1 - beta grad 1 ; x -= lr vx; y -= lr vy; momentumPath.push x: x, y: y ; iteration++; updateVisualization ; updateStatus ; // Stop if converged or max iterations reached if Math.abs grad 0 = maxIterations clearInterval momentumInterval ; momentumRunning = false; , 1000 / parseFloat document.getElementById 'momentum-speed' .value ; function updateVisualization // Remove existing paths svg.selectAll \".vanilla-path\" .remove ; svg.selectAll \".momentum-path\" .remove ; svg.selectAll \".vanilla-point\" .remove ; svg.selectAll \".momentum-point\" .remove ; // Draw vanilla GD path if vanillaPath.length > 1 const line = d3.line .x d => xScale d.x .y d => yScale d.y ; svg.append \"path\" .datum vanillaPath .attr \"class\", \"vanilla-path\" .attr \"d\", line .attr \"fill\", \"none\" .attr \"stroke\", \" 4CAF50\" .attr \"stroke-width\", 2 ; // Current point const current = vanillaPath vanillaPath.length - 1 ; svg.append \"circle\" .attr \"class\", \"vanilla-point\" .attr \"cx\", xScale current.x .attr \"cy\", yScale current.y .attr \"r\", 5 .attr \"fill\", \" 4CAF50\" ; // Draw momentum GD path if momentumPath.length > 1 const line = d3.line .x d => xScale d.x .y d => yScale d.y ; svg.append \"path\" .datum momentumPath .attr \"class\", \"momentum-path\" .attr \"d\", line .attr \"fill\", \"none\" .attr \"stroke\", \" FF9800\" .attr \"stroke-width\", 2 ; // Current point const current = momentumPath momentumPath.length - 1 ; svg.append \"circle\" .attr \"class\", \"momentum-point\" .attr \"cx\", xScale current.x .attr \"cy\", yScale current.y .attr \"r\", 5 .attr \"fill\", \" FF9800\" ; function updateStatus // Update vanilla GD status if vanillaPath.length > 0 const current = vanillaPath vanillaPath.length - 1 ; const fValue = f current.x, current.y ; document.getElementById 'vanilla-gd-info' .innerHTML = Iteration: MATH current.x.toFixed 3 , MATH fValue.toFixed 4 ; // Update momentum GD status if momentumPath.length > 0 const current = momentumPath momentumPath.length - 1 ; const fValue = f current.x, current.y ; document.getElementById 'momentum-gd-info' .innerHTML = Iteration: MATH current.x.toFixed 3 , MATH fValue.toFixed 4 ; // Event listeners document.getElementById 'start-vanilla-gd' .addEventListener 'click', => if !vanillaRunning vanillaRunning = true; runVanillaGD ; ; document.getElementById 'start-momentum-gd' .addEventListener 'click', => if !momentumRunning momentumRunning = true; runMomentumGD ; ; document.getElementById 'start-both' .addEventListener 'click', => if !vanillaRunning && !momentumRunning vanillaRunning = true; momentumRunning = true; runVanillaGD ; runMomentumGD ; ; document.getElementById 'reset-momentum' .addEventListener 'click', => clearInterval vanillaInterval ; clearInterval momentumInterval ; vanillaRunning = false; momentumRunning = false; vanillaPath = ; momentumPath = ; updateVisualization ; document.getElementById 'vanilla-gd-info' .innerHTML = 'Ready to start'; document.getElementById 'momentum-gd-info' .innerHTML = 'Ready to start'; ; // Update display values document.getElementById 'momentum-lr' .addEventListener 'input', function document.getElementById 'momentum-lr-value' .textContent = this.value; ; document.getElementById 'momentum-beta' .addEventListener 'input', function document.getElementById 'momentum-beta-value' .textContent = this.value; ; document.getElementById 'momentum-speed' .addEventListener 'input', function document.getElementById 'momentum-speed-value' .textContent = this.value; ; ; Ưu điểm của Momentum 1. Hội tụ nhanh hơn Momentum giúp thuật toán tăng tốc trong các hướng nhất quán, dẫn đến hội tụ nhanh hơn đặc biệt trong: - Các hàm có thung lũng hoặc khe hẹp - Các bài toán có điều kiện kém số điều kiện cao - Các hàm có nhiều cực tiểu địa phương 2. Giảm dao động Trong các hướng mà gradient thường xuyên đổi dấu, momentum giúp làm mượt các dao động bằng cách lấy trung bình các gradient trong quá khứ. 3. Thoát khỏi cực tiểu địa phương Momentum tích lũy có thể giúp thuật toán \"lăn qua\" các cực tiểu địa phương nhỏ và tiếp tục hướng tới các nghiệm tốt hơn. Các biến thể và mở rộng 1. Nesterov Accelerated Gradient NAG Thay vì tính gradient tại vị trí hiện tại, NAG tính nó tại vị trí \"nhìn trước\": MATH \\begin align v^ k &= \\beta v^ k-1 + \\nabla f x^ k-1 - \\beta v^ k-1 \\\\ x^ k &= x^ k-1 - t v^ k \\end align MATH Trực quan : \"Nhìn trước khi nhảy\" - kiểm tra gradient tại nơi momentum sẽ đưa bạn đến. Vấn đề với Momentum thông thường Mặc dù momentum giúp quả bóng vượt qua các cực tiểu địa phương, có một hạn chế mà chúng ta có thể quan sát: khi tiến gần đến mục tiêu, momentum vẫn mất khá nhiều thời gian trước khi dừng lại. Lý do chính xác là do vận tốc tích lũy. Ý tưởng chính Ý tưởng cơ bản là dự đoán hướng tương lai - về cơ bản là nhìn trước một bước! Cụ thể, nếu chúng ta sử dụng số hạng momentum MATH để cập nhật, chúng ta có thể xấp xỉ vị trí tiếp theo là MATH chúng ta không bao gồm số hạng gradient ở đây vì chúng ta sẽ sử dụng nó trong bước cuối . Thay vì sử dụng gradient tại vị trí hiện tại, NAG bước tiến về phía trước và sử dụng gradient tại vị trí dự kiến tiếp theo. Visual Comparison With regular momentum : The update is the sum of two vectors: - Momentum vector from previous step - Gradient at the current position With Nesterov momentum : The update is the sum of two vectors: - Momentum vector from previous step - Gradient at the look-ahead position where momentum would take us This \"look-ahead\" approach allows NAG to make more informed corrections and often leads to faster convergence. 2. Adaptive Moment Estimation Adam Adam combines momentum with adaptive learning rates for each parameter: MATH \\begin align m^ k &= \\beta 1 m^ k-1 + 1-\\beta 1 \\nabla f x^ k-1 \\\\ v^ k &= \\beta 2 v^ k-1 + 1-\\beta 2 \\nabla f x^ k-1 ^2 \\\\ x^ k &= x^ k-1 - t \\frac m^ k \\sqrt v^ k + \\epsilon \\end align MATH Practical Implementation Tips 1. Choosing the Momentum Coefficient - Start with MATH : A good default for most problems - Increase to MATH : For very smooth optimization landscapes - Decrease to MATH : For noisy or non-smooth functions 2. Learning Rate Adjustment When using momentum, you may need to reduce the learning rate compared to vanilla gradient descent, as momentum amplifies the effective step size. 3. Warm-up Period Consider starting with lower momentum and gradually increasing it, as momentum needs time to build up effective velocity. Mathematical Analysis Convergence Properties For strongly convex functions with Lipschitz gradients, momentum gradient descent achieves: - Linear convergence : MATH for some MATH - Improved condition number : Effective condition number can be improved from MATH to MATH Heavy Ball Method Connection Momentum gradient descent is closely related to the heavy ball method from classical mechanics: MATH This differential equation, when discretized, leads to the momentum update rules. Tóm tắt so sánh | Khía cạnh | Vanilla GD | Momentum GD | |--------|------------|-------------| | Bộ nhớ | Không | Có giảm mũ | | Hội tụ | Có thể chậm | Thường nhanh hơn | | Dao động | Dễ xảy ra hơn | Giảm | | Cực tiểu địa phương | Có thể bị kẹt | Thoát tốt hơn | | Siêu tham số | Tốc độ học | Tốc độ học + momentum | | Chi phí tính toán | Thấp | Hơi cao hơn | Những điểm chính 1. Momentum thêm bộ nhớ : Nó nhớ hướng của các bước trước đó 2. Hội tụ nhanh hơn : Đặc biệt hiệu quả cho các hàm có thung lũng hoặc khe hẹp 3. Giảm dao động : Làm mượt hành vi zigzag 4. Được sử dụng rộng rãi : Nền tảng cho nhiều thuật toán tối ưu hóa hiện đại 5. Có thể điều chỉnh : Hệ số momentum MATH cho phép tinh chỉnh cho các bài toán khác nhau Kết luận : Momentum là một cải tiến đơn giản nhưng mạnh mẽ cho gradient descent đã vượt qua thử thách của thời gian và vẫn có liên quan trong các ứng dụng machine learning hiện đại.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_06_gradent_descent_with_momentum/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter06/06_07_regularization_and_loss_functions",
    "title": "06-07 Regularization và Loss Functions",
    "chapter": "06",
    "order": 16,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Giới thiệu: Vấn đề Overfitting trong Machine Learning Trong machine learning, một trong những thử thách lớn nhất là overfitting - hiện tượng mô hình học quá chi tiết từ dữ liệu huấn luyện, dẫn đến hiệu suất kém trên dữ liệu mới. Regularization là kỹ thuật quan trọng để giải quyết vấn đề này. Tại sao cần Regularization? Hãy xem xét bài toán hồi quy tuyến tính cơ bản: MATH Vấn đề : Khi số lượng đặc trưng lớn hoặc dữ liệu ít, mô hình có thể tìm được nghiệm với training error = 0 nhưng generalization kém. Giải pháp : Thêm regularization term để \"phạt\" các trọng số lớn: MATH trong đó: - MATH là regularization parameter - MATH là regularization function Ridge Regression L2 Regularization Định nghĩa Toán học Ridge regression sử dụng L2 norm làm regularization term: MATH Giải thích các thành phần: - Loss term : MATH - đo lường độ lệch giữa dự đoán và thực tế - Regularization term : MATH - phạt các trọng số lớn - Regularization strength : MATH kiểm soát mức độ regularization Nghiệm Giải tích Ridge regression có nghiệm dạng đóng: MATH Ưu điểm của nghiệm này: - Ma trận MATH luôn khả nghịch khi MATH - Giải quyết vấn đề multicollinearity - Tính toán hiệu quả Hiệu ứng của Ridge Regularization Điều khiển Ridge Regularization Lambda λ : 1.0 Noise Level: 0.1 Number of Features: 10 Tạo dữ liệu mới Coefficients Path L2 Norm của coefficients: 0 Training vs Validation Error Optimal λ: 0 Practical Example: Minimizing a Quadratic Function Để hiểu sâu hơn về regularization, hãy xem xét một ví dụ cụ thể với quadratic function. Đây là nền tảng toán học cho nhiều thuật toán machine learning. Bài toán: Portfolio Optimization với Regularization Giả sử chúng ta có bài toán tối ưu hóa danh mục đầu tư: MATH trong đó: - MATH : trọng số đầu tư cho MATH tài sản - MATH : ma trận hiệp phương sai risk matrix - MATH : vector lợi nhuận kỳ vọng - MATH : tham số regularization risk aversion Phân tích Toán học Chi tiết 1. Gradient của Objective Function MATH 2. Hessian Matrix MATH Quan sát quan trọng : - Khi MATH , Hessian luôn positive definite nếu MATH positive semidefinite - Điều này đảm bảo hàm mục tiêu là strongly convex - Nghiệm tối ưu duy nhất tồn tại 3. Nghiệm Tối ưu Đặt gradient bằng 0: MATH MATH Interactive Quadratic Function Explorer Quadratic Function Parameters Regularization λ: 1.0 Condition Number: 10 Dimension: 2 Run Optimization Reset 2D Contour Plot Click to set starting point Convergence Analysis Convergence rate: - Eigenvalue Analysis Original Matrix Q Regularized Matrix Q + λI Analysis: Regularization improves condition number from ∞ to finite value Gradient Descent cho Quadratic Functions Đối với quadratic function, gradient descent có dạng đặc biệt: MATH Phân tích Convergence Rate Eigenvalue decomposition : MATH Convergence rate : MATH trong đó MATH là eigenvalues của MATH . Optimal step size : MATH Convergence factor : MATH trong đó MATH là condition number. Hiệu ứng của Regularization lên Convergence Convergence Rate Analysis Lambda: 0.1 Step Size: 0.1 Optimal Step Size Convergence Comparison ■ No Regularization ■ With Regularization Condition Number vs λ Current κ: ∞ Case Study: Ill-conditioned Problems Vấn đề: Multicollinearity trong Linear Regression Xem xét ma trận thiết kế MATH với các cột gần như phụ thuộc tuyến tính: MATH \\mathbf X = \\begin bmatrix 1 & 1 & 1.001 \\\\ 1 & 2 & 2.001 \\\\ 1 & 3 & 3.001 \\\\ \\vdots & \\vdots & \\vdots \\end bmatrix MATH Normal equations : MATH Vấn đề : MATH có condition number rất lớn → numerical instability Giải pháp: Ridge Regularization MATH Hiệu quả : - Condition number giảm từ MATH xuống MATH - Numerical stability được cải thiện đáng kể - Trade-off: bias tăng nhưng variance giảm Mathematical Insights 1. Bias-Variance Decomposition Đối với Ridge regression: MATH Bias : MATH Variance : MATH 2. Effective Degrees of Freedom MATH trong đó MATH là singular values của MATH . Interpretation : Regularization effectively reduces model complexity. Computational Considerations 1. Direct Solution vs Iterative Methods Direct Cholesky decomposition : - Complexity: MATH - Suitable for MATH p So sánh Ridge và Lasso Regularization Lambda λ : 1.0 Feature Correlation: 0.5 Cập nhật So sánh Ridge Coefficients Shrinkage: Đều, không về 0 Lasso Coefficients Sparsity: Một số về chính xác 0 Regularization Geometry L1: Diamond, L2: Circle Hình học của Regularization Hiểu trực quan tại sao Lasso tạo sparse solutions: 1. L1 constraint : MATH tạo ra diamond shape trong 2D 2. L2 constraint : MATH tạo ra circular shape trong 2D 3. Intersection với loss contours : - L1: Có khả năng cao giao với contour tại các góc sparse solutions - L2: Thường giao tại các điểm smooth non-sparse solutions Elastic Net: Kết hợp Ridge và Lasso Elastic Net kết hợp cả L1 và L2 regularization: MATH Tham số: - MATH : mixing parameter - MATH : Pure Lasso - MATH : Pure Ridge - MATH Loss Functions trong Machine Learning 1. Regression Loss Functions Mean Squared Error MSE MATH Đặc điểm: - Smooth, differentiable everywhere - Sensitive to outliers - Convex optimization problem Mean Absolute Error MAE MATH Đặc điểm: - Robust to outliers - Non-differentiable at zero - Convex but requires subgradient methods Huber Loss MATH L Huber \\mathbf w = \\frac 1 n \\sum i=1 ^n \\begin cases \\frac 1 2 y i - \\mathbf w ^T \\mathbf x i ^2 & \\text if |y i - \\mathbf w ^T \\mathbf x i| \\leq \\delta \\\\ \\delta |y i - \\mathbf w ^T \\mathbf x i| - \\frac 1 2 \\delta^2 & \\text otherwise \\end cases MATH Đặc điểm: - Combines MSE small errors and MAE large errors - Smooth and robust - Parameter MATH controls transition point 2. Classification Loss Functions Logistic Loss Cross-entropy MATH Hinge Loss SVM MATH Interactive Loss Functions Comparison So sánh các Loss Functions Huber Delta δ : 1.0 Error Range: 4.0 Show Derivatives Regression Loss Functions ■ MSE ■ MAE ■ Huber Classification Loss Functions ■ Logistic ■ Hinge ■ 0-1 Loss Regularization Path và Model Selection Cross-Validation cho Regularization Việc chọn MATH tối ưu thường được thực hiện thông qua cross-validation: 1. Chia dữ liệu : Training, validation, test sets 2. Grid search : Thử nhiều giá trị MATH 3. Evaluate : Tính validation error cho mỗi MATH 4. Select : Chọn MATH có validation error thấp nhất Regularization Path Visualization Regularization Path Analysis Method: Ridge Lasso Elastic Net Elastic Net α: 0.5 Animate Path Coefficient Path Current λ: 0, Active features: 0 Cross-Validation Curve Optimal λ: 0, CV Score: 0 Practical Guidelines và Best Practices 1. Khi nào sử dụng Ridge vs Lasso? Sử dụng Ridge khi: Tất cả features đều có ý nghĩa Multicollinearity cao Cần stability trong predictions Dataset nhỏ, nhiều features Không cần feature selection tự động Sử dụng Lasso khi: Cần feature selection tự động Nhiều features không liên quan Muốn mô hình đơn giản, dễ diễn giải Sparse solutions được ưa chuộng High-dimensional data 2. Hyperparameter Tuning Strategy python Pseudo-code cho regularization tuning def tune regularization X train, y train, X val, y val : lambda values = np.logspace -4, 2, 50 Log-spaced values best lambda = None best score = float 'inf' for lambda val in lambda values: model = fit regularized model X train, y train, lambda val val score = evaluate model model, X val, y val if val score document.addEventListener 'DOMContentLoaded', function // Quadratic Function Demo initializeQuadraticFunctionDemo ; // Regularization Convergence Demo initializeRegularizationConvergenceDemo ; // Ridge Effect Demo initializeRidgeEffectDemo ; // Ridge vs Lasso Comparison initializeRidgeLassoComparison ; // Loss Functions Demo initializeLossFunctionsDemo ; // Regularization Path Demo initializeRegularizationPathDemo ; function initializeRidgeEffectDemo const lambdaSlider = document.getElementById 'ridge-lambda' ; const noiseSlider = document.getElementById 'ridge-noise' ; const featuresSlider = document.getElementById 'ridge-features' ; const regenerateBtn = document.getElementById 'ridge-regenerate' ; let currentData = generateRidgeData ; function generateRidgeData const n = 50; // samples const p = parseInt featuresSlider.value ; // features const noise = parseFloat noiseSlider.value ; // Generate true coefficients sparse const trueCoeffs = Array p .fill 0 .map , i => i Array p .fill .map => Math.random 2 - 1 ; // Generate y with noise const y = X.map row => row.reduce sum, x, i => sum + x trueCoeffs i , 0 + Math.random - 0.5 noise 2 ; return X, y, trueCoeffs, n, p ; function updateRidgeDemo const lambda = parseFloat lambdaSlider.value ; document.getElementById 'ridge-lambda-value' .textContent = lambda.toFixed 1 ; // Compute Ridge coefficients for different lambda values const lambdaRange = Array 50 .fill .map , i => i 0.2 ; const coeffPaths = computeRidgeCoefficients currentData, lambdaRange ; // Update visualizations updateRidgeCoefficientsPlot coeffPaths, lambdaRange, lambda ; updateRidgeErrorPlot currentData, lambdaRange ; function computeRidgeCoefficients data, lambdaRange const X, y, p = data; const paths = Array p .fill .map => ; lambdaRange.forEach lambda => const coeffs = solveRidge X, y, lambda ; coeffs.forEach coeff, i => paths i .push coeff ; ; return paths; function solveRidge X, y, lambda // Simplified Ridge solution: w = X'X + λI ^ -1 X'y const p = X 0 .length; const n = X.length; // Compute X'X const XtX = Array p .fill .map => Array p .fill 0 ; for let i = 0; i xScale lambdaRange i .y d => yScale d ; // Draw coefficient paths const colors = d3.schemeCategory10; coeffPaths.forEach path, i => g.append 'path' .datum path .attr 'fill', 'none' .attr 'stroke', colors i % colors.length .attr 'stroke-width', 2 .attr 'd', line ; ; // Current lambda line g.append 'line' .attr 'x1', xScale currentLambda .attr 'x2', xScale currentLambda .attr 'y1', 0 .attr 'y2', height .attr 'stroke', 'red' .attr 'stroke-width', 2 .attr 'stroke-dasharray', '5,5' ; // Update info const currentIndex = Math.round currentLambda / 0.2 ; const currentCoeffs = coeffPaths.map path => path currentIndex || 0 ; const l2Norm = Math.sqrt currentCoeffs.reduce sum, c => sum + c c, 0 ; document.getElementById 'ridge-coeff-info' .textContent = L2 Norm của coefficients: $ l2Norm.toFixed 3 ; function updateRidgeErrorPlot data, lambdaRange // Simplified error computation for demo const svg = d3.select ' ridge-error' ; svg.selectAll ' ' .remove ; const margin = top: 20, right: 20, bottom: 40, left: 50 ; const width = 400 - margin.left - margin.right; const height = 300 - margin.top - margin.bottom; const g = svg.append 'g' .attr 'transform', translate MATH margin.top ; // Generate synthetic error curves const trainErrors = lambdaRange.map lambda => 0.1 + 0.5 lambda + Math.random 0.1 ; const valErrors = lambdaRange.map lambda => 0.3 + 0.2 Math.abs lambda - 2 + Math.random 0.1 ; // Scales const xScale = d3.scaleLinear .domain d3.extent lambdaRange .range 0, width ; const yScale = d3.scaleLinear .domain 0, Math.max ...trainErrors, ...valErrors .nice .range height, 0 ; // Axes g.append 'g' .attr 'transform', translate 0,$ height .call d3.axisBottom xScale ; g.append 'g' .call d3.axisLeft yScale ; // Axis labels g.append 'text' .attr 'transform', translate MATH height + 35 .style 'text-anchor', 'middle' .text 'Lambda λ ' ; g.append 'text' .attr 'transform', 'rotate -90 ' .attr 'y', 0 - margin.left .attr 'x', 0 - height/2 .attr 'dy', '1em' .style 'text-anchor', 'middle' .text 'Error' ; // Line generator const line = d3.line .x d, i => xScale lambdaRange i .y d => yScale d ; // Draw error curves g.append 'path' .datum trainErrors .attr 'fill', 'none' .attr 'stroke', 'blue' .attr 'stroke-width', 2 .attr 'd', line ; g.append 'path' .datum valErrors .attr 'fill', 'none' .attr 'stroke', 'red' .attr 'stroke-width', 2 .attr 'd', line ; // Legend const legend = g.append 'g' .attr 'transform', translate $ width - 100 , 20 ; legend.append 'line' .attr 'x1', 0 .attr 'x2', 20 .attr 'y1', 0 .attr 'y2', 0 .attr 'stroke', 'blue' .attr 'stroke-width', 2 ; legend.append 'text' .attr 'x', 25 .attr 'y', 5 .text 'Training' ; legend.append 'line' .attr 'x1', 0 .attr 'x2', 20 .attr 'y1', 15 .attr 'y2', 15 .attr 'stroke', 'red' .attr 'stroke-width', 2 ; legend.append 'text' .attr 'x', 25 .attr 'y', 20 .text 'Validation' ; // Find optimal lambda const optimalIndex = valErrors.indexOf Math.min ...valErrors ; const optimalLambda = lambdaRange optimalIndex ; document.getElementById 'ridge-error-info' .textContent = Optimal λ: $ optimalLambda.toFixed 2 ; // Event listeners lambdaSlider.addEventListener 'input', updateRidgeDemo ; noiseSlider.addEventListener 'input', function document.getElementById 'ridge-noise-value' .textContent = this.value; ; featuresSlider.addEventListener 'input', function document.getElementById 'ridge-features-value' .textContent = this.value; ; regenerateBtn.addEventListener 'click', function currentData = generateRidgeData ; updateRidgeDemo ; ; // Initial update updateRidgeDemo ; function initializeRidgeLassoComparison const lambdaSlider = document.getElementById 'comparison-lambda' ; const correlationSlider = document.getElementById 'comparison-correlation' ; const updateBtn = document.getElementById 'comparison-update' ; function updateComparison const lambda = parseFloat lambdaSlider.value ; const correlation = parseFloat correlationSlider.value ; document.getElementById 'comparison-lambda-value' .textContent = lambda.toFixed 1 ; document.getElementById 'comparison-correlation-value' .textContent = correlation.toFixed 1 ; // Generate synthetic data with controlled correlation const p = 8; // features const trueCoeffs = 2, -1.5, 1, 0.5, -0.8, 0, 0, 0 ; // Compute Ridge and Lasso coefficients const ridgeCoeffs = computeRidgeCoeffs trueCoeffs, lambda, correlation ; const lassoCoeffs = computeLassoCoeffs trueCoeffs, lambda, correlation ; // Update visualizations updateComparisonPlot 'ridge-comparison', ridgeCoeffs, 'Ridge' ; updateComparisonPlot 'lasso-comparison', lassoCoeffs, 'Lasso' ; updateGeometryPlot lambda ; function computeRidgeCoeffs trueCoeffs, lambda, correlation // Simplified Ridge shrinkage const shrinkageFactor = 1 / 1 + lambda ; return trueCoeffs.map coeff => coeff shrinkageFactor ; function computeLassoCoeffs trueCoeffs, lambda, correlation // Simplified Lasso soft thresholding return trueCoeffs.map coeff => const absCoeff = Math.abs coeff ; if absCoeff w$ i+1 .range 0, width .padding 0.1 ; const yScale = d3.scaleLinear .domain d3.extent coeffs .nice .range height, 0 ; // Axes g.append 'g' .attr 'transform', translate 0,$ height .call d3.axisBottom xScale ; g.append 'g' .call d3.axisLeft yScale ; // Bars const color = title === 'Ridge' ? ' 4CAF50' : ' FF9800'; g.selectAll '.bar' .data coeffs .enter .append 'rect' .attr 'class', 'bar' .attr 'x', d, i => xScale w$ i+1 .attr 'width', xScale.bandwidth .attr 'y', d => d >= 0 ? yScale d : yScale 0 .attr 'height', d => Math.abs yScale d - yScale 0 .attr 'fill', color ; // Zero line g.append 'line' .attr 'x1', 0 .attr 'x2', width .attr 'y1', yScale 0 .attr 'y2', yScale 0 .attr 'stroke', 'black' .attr 'stroke-width', 1 ; function updateGeometryPlot lambda const svg = d3.select ' regularization-geometry' ; svg.selectAll ' ' .remove ; const margin = top: 20, right: 20, bottom: 40, left: 40 ; const width = 300 - margin.left - margin.right; const height = 250 - margin.top - margin.bottom; const g = svg.append 'g' .attr 'transform', translate MATH margin.top ; const centerX = width / 2; const centerY = height / 2; const radius = Math.min width, height / 3; // L2 constraint circle g.append 'circle' .attr 'cx', centerX .attr 'cy', centerY .attr 'r', radius .attr 'fill', 'none' .attr 'stroke', ' 4CAF50' .attr 'stroke-width', 3 .attr 'opacity', 0.7 ; // L1 constraint diamond const diamondPoints = centerX, centerY - radius , centerX + radius, centerY , centerX, centerY + radius , centerX - radius, centerY ; const line = d3.line .x d => d 0 .y d => d 1 ; g.append 'path' .datum ...diamondPoints, diamondPoints 0 .attr 'd', line .attr 'fill', 'none' .attr 'stroke', ' FF9800' .attr 'stroke-width', 3 .attr 'opacity', 0.7 ; // Contour lines ellipses for let i = 1; i 0.5 e e ; const maeLoss = errors.map e => Math.abs e ; const huberLoss = errors.map e => Math.abs e xScale errors i .y d => yScale d ; // Draw loss functions const colors = ' 1f77b4', ' ff7f0e', ' 2ca02c' ; const losses = mseLoss, maeLoss, huberLoss ; const names = 'MSE', 'MAE', 'Huber' ; losses.forEach loss, i => g.append 'path' .datum loss .attr 'fill', 'none' .attr 'stroke', colors i .attr 'stroke-width', 3 .attr 'd', line ; ; // Legend const legend = g.append 'g' .attr 'transform', translate $ width - 80 , 20 ; names.forEach name, i => legend.append 'line' .attr 'x1', 0 .attr 'x2', 20 .attr 'y1', i 20 .attr 'y2', i 20 .attr 'stroke', colors i .attr 'stroke-width', 3 ; legend.append 'text' .attr 'x', 25 .attr 'y', i 20 + 5 .text name ; ; function updateClassificationLosses range, showDerivatives const svg = d3.select ' classification-losses' ; svg.selectAll ' ' .remove ; const margin = top: 20, right: 20, bottom: 40, left: 50 ; const width = 400 - margin.left - margin.right; const height = 300 - margin.top - margin.bottom; const g = svg.append 'g' .attr 'transform', translate MATH margin.top ; // Generate margin values y f x const margins = d3.range -range, range, 0.1 ; // Loss functions const logisticLoss = margins.map m => Math.log 1 + Math.exp -m ; const hingeLoss = margins.map m => Math.max 0, 1 - m ; const zeroOneLoss = margins.map m => m xScale margins i .y d => yScale d ; // Draw loss functions const colors = ' d62728', ' 9467bd', ' 8c564b' ; const losses = logisticLoss, hingeLoss, zeroOneLoss ; const names = 'Logistic', 'Hinge', '0-1 Loss' ; losses.forEach loss, i => g.append 'path' .datum loss .attr 'fill', 'none' .attr 'stroke', colors i .attr 'stroke-width', 3 .attr 'd', line ; ; // Legend const legend = g.append 'g' .attr 'transform', translate $ width - 80 , 20 ; names.forEach name, i => legend.append 'line' .attr 'x1', 0 .attr 'x2', 20 .attr 'y1', i 20 .attr 'y2', i 20 .attr 'stroke', colors i .attr 'stroke-width', 3 ; legend.append 'text' .attr 'x', 25 .attr 'y', i 20 + 5 .text name ; ; // Event listeners deltaSlider.addEventListener 'input', updateLossFunctions ; rangeSlider.addEventListener 'input', updateLossFunctions ; derivativesCheckbox.addEventListener 'change', updateLossFunctions ; // Initial update updateLossFunctions ; function initializeRegularizationPathDemo const methodSelect = document.getElementById 'path-method' ; const alphaSlider = document.getElementById 'path-alpha' ; const animateBtn = document.getElementById 'path-animate' ; let isAnimating = false; let animationId = null; function updateRegularizationPath const method = methodSelect.value; const alpha = parseFloat alphaSlider.value ; document.getElementById 'path-alpha-value' .textContent = alpha.toFixed 1 ; // Generate regularization path const lambdaRange = d3.range 0, 5, 0.1 ; const coeffPaths = generateRegularizationPath method, alpha, lambdaRange ; updateCoefficientPathPlot coeffPaths, lambdaRange, method ; updateCVCurvePlot lambdaRange, method ; function generateRegularizationPath method, alpha, lambdaRange const p = 6; // features const trueCoeffs = 2, -1.5, 1, 0.5, -0.8, 0.3 ; const paths = Array p .fill .map => ; lambdaRange.forEach lambda => let coeffs; if method === 'ridge' coeffs = trueCoeffs.map c => c / 1 + lambda ; else if method === 'lasso' coeffs = trueCoeffs.map c => const abs c = Math.abs c ; return abs c > lambda ? Math.sign c abs c - lambda : 0; ; else // elastic net coeffs = trueCoeffs.map c => const abs c = Math.abs c ; const l1 part = abs c > alpha lambda ? Math.sign c abs c - alpha lambda : 0; return l1 part / 1 + 1 - alpha lambda ; ; coeffs.forEach coeff, i => paths i .push coeff ; ; return paths; function updateCoefficientPathPlot coeffPaths, lambdaRange, method const svg = d3.select ' coefficient-path' ; svg.selectAll ' ' .remove ; const margin = top: 20, right: 20, bottom: 40, left: 50 ; const width = 400 - margin.left - margin.right; const height = 300 - margin.top - margin.bottom; const g = svg.append 'g' .attr 'transform', translate MATH margin.top ; // Scales const xScale = d3.scaleLinear .domain d3.extent lambdaRange .range 0, width ; const allCoeffs = coeffPaths.flat ; const yScale = d3.scaleLinear .domain d3.extent allCoeffs .nice .range height, 0 ; // Axes g.append 'g' .attr 'transform', translate 0,$ height .call d3.axisBottom xScale ; g.append 'g' .call d3.axisLeft yScale ; // Axis labels g.append 'text' .attr 'transform', translate MATH height + 35 .style 'text-anchor', 'middle' .text 'Lambda λ ' ; g.append 'text' .attr 'transform', 'rotate -90 ' .attr 'y', 0 - margin.left .attr 'x', 0 - height/2 .attr 'dy', '1em' .style 'text-anchor', 'middle' .text 'Coefficient Value' ; // Line generator const line = d3.line .x d, i => xScale lambdaRange i .y d => yScale d ; // Draw coefficient paths const colors = d3.schemeCategory10; coeffPaths.forEach path, i => g.append 'path' .datum path .attr 'fill', 'none' .attr 'stroke', colors i % colors.length .attr 'stroke-width', 2 .attr 'd', line ; // Add feature label at the end const lastValue = path path.length - 1 ; if Math.abs lastValue > 0.01 g.append 'text' .attr 'x', width + 5 .attr 'y', yScale lastValue + 3 .attr 'font-size', '10px' .text f$ i+1 ; ; // Update info const currentLambda = 1.0; // example const activeFeatures = coeffPaths.filter path => Math.abs path Math.floor currentLambda 10 > 0.01 .length; document.getElementById 'path-info' .textContent = Current λ: MATH activeFeatures ; function updateCVCurvePlot lambdaRange, method const svg = d3.select ' cv-curve' ; svg.selectAll ' ' .remove ; const margin = top: 20, right: 20, bottom: 40, left: 50 ; const width = 400 - margin.left - margin.right; const height = 300 - margin.top - margin.bottom; const g = svg.append 'g' .attr 'transform', translate MATH margin.top ; // Generate synthetic CV scores const cvScores = lambdaRange.map lambda => const base = 0.2 + 0.1 Math.abs lambda - 1.5 ; return base + Math.random - 0.5 0.05; ; // Scales const xScale = d3.scaleLinear .domain d3.extent lambdaRange .range 0, width ; const yScale = d3.scaleLinear .domain d3.extent cvScores .nice .range height, 0 ; // Axes g.append 'g' .attr 'transform', translate 0,$ height .call d3.axisBottom xScale ; g.append 'g' .call d3.axisLeft yScale ; // Axis labels g.append 'text' .attr 'transform', translate MATH height + 35 .style 'text-anchor', 'middle' .text 'Lambda λ ' ; g.append 'text' .attr 'transform', 'rotate -90 ' .attr 'y', 0 - margin.left .attr 'x', 0 - height/2 .attr 'dy', '1em' .style 'text-anchor', 'middle' .text 'CV Score' ; // Line generator const line = d3.line .x d, i => xScale lambdaRange i .y d => yScale d ; // Draw CV curve g.append 'path' .datum cvScores .attr 'fill', 'none' .attr 'stroke', ' 2196F3' .attr 'stroke-width', 3 .attr 'd', line ; // Find and mark optimal lambda const minIndex = cvScores.indexOf Math.min ...cvScores ; const optimalLambda = lambdaRange minIndex ; g.append 'circle' .attr 'cx', xScale optimalLambda .attr 'cy', yScale cvScores minIndex .attr 'r', 5 .attr 'fill', 'red' ; // Update info document.getElementById 'cv-info' .textContent = Optimal λ: MATH cvScores minIndex .toFixed 3 ; function animatePath if isAnimating // Stop animation isAnimating = false; if animationId clearInterval animationId ; animateBtn.textContent = 'Animate Path'; return; // Start animation isAnimating = true; animateBtn.textContent = 'Stop Animation'; const lambdaRange = d3.range 0, 5, 0.1 ; let currentIndex = 0; animationId = setInterval => if currentIndex >= lambdaRange.length currentIndex = 0; // Update visualization for current lambda const currentLambda = lambdaRange currentIndex ; // Add animation logic here currentIndex++; , 100 ; // Event listeners methodSelect.addEventListener 'change', updateRegularizationPath ; alphaSlider.addEventListener 'input', updateRegularizationPath ; animateBtn.addEventListener 'click', animatePath ; // Initial update updateRegularizationPath ; ;",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter06/06_07_regularization_and_loss_functions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_00_subgradient",
    "title": "07 Gradient dưới (Subgradient)",
    "chapter": "07",
    "order": 1,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Trong chương này, chúng ta giới thiệu khái niệm về gradient dưới subgradient và điều kiện tối ưu gradient dưới, vốn là sự tổng quát hóa của gradient và điều kiện tối ưu bậc một đã thảo luận trước đây. Chúng ta cũng sẽ khám phá một số ứng dụng và ví dụ liên quan đến các khái niệm này.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_00_subgradient/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_01_subgradient",
    "title": "07-01 Gradient dưới (Subgradient)",
    "chapter": "07",
    "order": 2,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Gradient dưới Subgradient Đối với một hàm lồi MATH , gradient dưới tại MATH là bất kỳ vector MATH nào thỏa mãn: > MATH \\begin equation \\label subgradient f y \\geq f x + g^T y-x , \\text với mọi y \\end equation MATH Gradient dưới được định nghĩa ở trên: - Tổng quát hóa gradient cho các hàm lồi trong trường hợp hàm không khả vi. - Đối với các hàm lồi, gradient dưới luôn tồn tại. Nếu MATH khả vi tại MATH , thì MATH là gradient dưới duy nhất. - Đối với các hàm không lồi, gradient dưới có thể được định nghĩa tương tự, nhưng nó có thể không luôn tồn tại tùy thuộc vào hàm. Dưới đây là các ví dụ về gradient dưới cho một số hàm. Ví dụ 1 MATH MATH - Với MATH , MATH phải được thỏa mãn. Tức là, MATH . Nếu MATH , tức là MATH , thì điều kiện này được thỏa mãn với mọi MATH . Do đó, MATH Wikipedia: Hàm dấu https://en.wikipedia.org/wiki/Sign function . - Với MATH , MATH phải được thỏa mãn. Do đó, MATH . Ví dụ 2 MATH MATH Tại một điểm MATH , - Với MATH , vì hàm khả vi tại MATH , ta có MATH - Với MATH , ta có MATH Ví dụ 3 MATH MATH - Với MATH , vì hàm khả vi, ta có MATH - Với MATH , ta có MATH . Do đó, MATH Ví dụ 4 MATH , trong đó MATH đều là các hàm lồi và khả vi. MATH - Với MATH , ta có MATH - Với MATH , ta có MATH - Với MATH , ta có MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_01_subgradient/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_02_subdifferentials",
    "title": "07-02 Vi phân dưới (Sub-differentials)",
    "chapter": "07",
    "order": 3,
    "owner": "Kyeongmin Woo",
    "lesson_type": "required",
    "content": "Vi phân dưới MATH của một hàm lồi MATH tại điểm MATH là tập hợp tất cả các gradient dưới tại MATH : > \\begin equation \\partial f x = \\ g \\in \\mathbb R ^n | \\text g là gradient dưới của f tại x \\ \\end equation Vi phân dưới có các tính chất sau: - MATH luôn là một tập lồi đóng, bất kể MATH có lồi hay không. - Nếu MATH lồi, MATH luôn chứa ít nhất một phần tử; nếu MATH không lồi, nó có thể rỗng. - Nếu MATH khả vi và lồi tại MATH , thì MATH . - Nếu MATH , thì MATH khả vi tại MATH và MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_02_subdifferentials/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_02_01_connection_to_a_convexity_geometry",
    "title": "07-02-01 Liên hệ với hình học tập lồi",
    "chapter": "07",
    "order": 4,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Đối với một tập lồi MATH , xét hàm chỉ thị MATH được định nghĩa như sau: > MATH I C x = I\\ x \\in C \\ = \\begin cases 0 &\\text nếu x \\in C \\\\ \\infty &\\text nếu x \\notin C \\end cases MATH Vi phân dưới của hàm này có ý nghĩa hình học sau: Bổ đề Với MATH , vi phân dưới MATH trùng với nón pháp tuyến MATH của tập MATH tại MATH : > \\begin equation \\mathcal N C x = \\ g \\in \\mathbb R ^n | g^Tx \\geq g^Ty \\text với mọi y \\in C \\ \\end equation Chứng minh Theo định nghĩa, gradient dưới phải thỏa mãn: > \\begin equation I C y \\geq I C x + g^T y-x \\text với mọi y \\end equation Ở đây, MATH và MATH , nên: > \\begin equation I C y \\geq g^T y-x \\text với mọi y \\end equation Thứ nhất, với mọi MATH , ta có: > \\begin equation I C y = 0 \\geq g^T y-x \\end equation Do đó, gradient dưới MATH phải thỏa mãn MATH . Thứ hai, với mọi MATH , MATH , nên bất đẳng thức đúng với mọi giá trị của MATH : > MATH điều này luôn đúng. Đối với hai điều kiện trên, gradient dưới phải thỏa mãn cả hai, do đó gradient dưới của hàm trên là > MATH Hình 1 Nón pháp tuyến 1",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_02_01_connection_to_a_convexity_geometry/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_02_02_subgradient_calculus",
    "title": "07-02-02 Phép tính gradient dưới",
    "chapter": "07",
    "order": 5,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Các quy tắc cơ bản sau đây áp dụng cho vi phân dưới của các hàm lồi: Tỷ lệ > MATH \\eqalign \\text nếu & a>0, \\\\ \\text thì &\\partial af = a\\cdot \\partial f MATH Phép cộng > MATH Ở đây, tổng của hai tập hợp MATH được định nghĩa là tập hợp tất cả các tổng có thể. Hợp thành affine > MATH \\eqalign \\text nếu & g x =f Ax+b , \\\\ \\text thì & \\partial g x = A^T \\partial f Ax+b MATH Maximum điểm hữu hạn > MATH \\eqalign \\text nếu & f x =\\max i=1,\\dots,m f i x , \\\\ \\text thì & \\partial f x = \\text conv \\left \\bigcup i:f i x =f x \\partial f i x \\right MATH Tức là, MATH được định nghĩa là bao lồi của hợp các vi phân dưới của các hàm đạt giá trị MATH tại MATH . Maximum điểm tổng quát > MATH \\eqalign \\text nếu & f x = \\max s \\in S f s x ,\\\\ \\text thì & \\partial f x \\supseteq cl \\left \\ \\text conv \\left \\bigcup s:f s x =f x \\partial f s x \\right \\right\\ MATH Ở đây, MATH có thể là một tập vô hạn, nên hợp của vô số tập hợp có thể không đóng. Do đó, chúng ta lấy bao đóng để đảm bảo vi phân dưới là một tập đóng. Mặt khác, nếu tập hợp MATH compact đóng và bị chặn , và các hàm MATH liên tục theo MATH , thì quan hệ đẳng thức được thiết lập. Ví dụ, đối với hàm p-norm MATH sau đây: > \\begin equation f x = \\vert \\vert x \\vert \\vert \\ p = \\max \\vert \\vert z \\vert \\vert q \\leq 1 z^Tx, \\qquad 1/p + 1/q =1 \\end equation Nếu đặt MATH , thì MATH sao cho MATH thuộc MATH . Mặt khác, vì MATH , nên MATH là hợp của tất cả MATH , do đó MATH . Ở đây, MATH là tập compact, và MATH là tuyến tính, nên theo quy tắc maximum điểm tổng quát, việc lấy bao lồi rồi bao đóng của MATH không thêm phần tử nào mới. Do đó, gradient dưới của hàm MATH như sau: > \\begin equation \\partial f x = \\arg\\max \\vert \\vert z \\vert \\vert q \\leq 1 z^T x \\end equation",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_02_02_subgradient_calculus/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_03_subgradient_optimality_condition",
    "title": "07-03 Điều kiện tối ưu gradient dưới",
    "chapter": "07",
    "order": 6,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Trong phần này, chúng ta xem xét các điều kiện tối ưu sử dụng gradient dưới, và cung cấp một số ví dụ để minh họa ứng dụng và tính hữu ích của chúng.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_03_subgradient_optimality_condition/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_03_01_subgradient_optimality_condition",
    "title": "07-03-01 Điều kiện tối ưu gradient dưới",
    "chapter": "07",
    "order": 7,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Bổ đề Đối với bất kỳ hàm MATH nào, điều kiện MATH là một điểm cực tiểu của MATH và điều kiện MATH là một gradient dưới tại MATH là tương đương: > MATH \\begin equation f x^ = \\min x f x \\Longleftrightarrow 0 \\in \\partial f x^ \\end equation MATH Chứng minh > MATH \\begin align &f x^ = \\min x f x \\\\ \\Longleftrightarrow &f y \\geq f x^ \\text với mọi y\\\\ \\Longleftrightarrow &f y \\geq f x^ + 0^T y-x^ \\\\ \\Longleftrightarrow &0 \\in \\partial f x^ \\end align MATH Lưu ý rằng tính lồi của MATH không được sử dụng trong chứng minh này, nên điều kiện tối ưu này áp dụng ngay cả cho các hàm không lồi.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_03_01_subgradient_optimality_condition/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_03_02_derivation_of_first-order_optimality_condition",
    "title": "07-03-02 Suy dẫn điều kiện tối ưu bậc một",
    "chapter": "07",
    "order": 8,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Nếu MATH lồi và khả vi, điều kiện tối ưu gradient dưới trùng với điều kiện tối ưu bậc một, như được chỉ ra dưới đây. Điều kiện tối ưu bậc một: MATH Chứng minh > MATH \\begin alignat 2 f x^ = \\min x\\in C f x \\quad & \\Longleftrightarrow & & \\quad f x^ = \\min x f x + I C x \\\\ \\quad & \\Longleftrightarrow & &\\quad 0 \\in \\partial f x^ + I C x^ \\\\ \\quad & \\Longleftrightarrow & &\\quad 0 \\in \\ \\nabla f x^ \\ + \\mathcal N C x^ \\\\ \\quad & \\Longleftrightarrow & &\\quad - \\nabla f x^ \\in \\mathcal N C x^ \\\\ \\quad & \\Longleftrightarrow & &\\quad - \\nabla f x^ ^Tx^ \\geq -\\nabla f x^ ^Ty, \\text với mọi y \\in C \\\\ \\quad & \\Longleftrightarrow & &\\quad \\nabla f x^ ^T y-x^ \\geq 0, \\text với mọi y \\in C \\end alignat MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_03_02_derivation_of_first-order_optimality_condition/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_03_03_example_lasso_optimality_condition",
    "title": "07-03-03 Ví dụ: Điều kiện tối ưu Lasso",
    "chapter": "07",
    "order": 9,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Với bài toán lasso được cho dưới đây, > \\begin equation \\min \\beta \\frac 1 2 \\| y-X\\beta \\| 2^2 + \\lambda \\| \\beta \\| 1 \\end equation trong đó MATH , MATH , MATH . Điều kiện tối ưu gradient dưới cho bài toán này có thể được biểu diễn như sau: > MATH \\eqalign 0 \\in \\partial\\left \\frac 1 2 \\| y-X\\beta \\| 2^2 + \\lambda \\| \\beta \\| 1\\right &\\quad \\Longleftrightarrow \\quad 0 \\in - X^T y-X\\beta + \\lambda \\partial \\| \\beta \\| 1 \\\\ &\\quad \\Longleftrightarrow \\quad X^T y-X\\beta = \\lambda v \\\\ & \\quad \\text với v \\in \\partial \\| \\beta \\| 1 \\text nào đó \\\\ MATH Ở đây, đối với một điểm MATH , gradient dưới MATH được cho bởi: MATH v i = \\begin cases 1 &\\text nếu \\beta i > 0 \\\\ -1 &\\text nếu \\beta i \\begin equation X^T y-X\\beta = \\lambda v \\end equation Tức là, đối với MATH tối ưu, các điều kiện sau được thỏa mãn: > MATH \\begin cases X i^T y-X\\beta = \\lambda \\cdot \\text sign \\beta i &\\text nếu \\beta i \\neq 0 \\\\ |X i^T y-X\\beta | \\leq \\lambda &\\text nếu \\beta i = 0 \\end cases MATH Ở đây, MATH ký hiệu cột thứ MATH của ma trận MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_03_03_example_lasso_optimality_condition/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_03_04_example_soft-thresholding",
    "title": "07-03-04 Ví dụ: Ngưỡng mềm (Soft-Thresholding)",
    "chapter": "07",
    "order": 10,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Với bài toán lasso đơn giản hơn với MATH : > \\begin equation \\min \\beta \\frac 1 2 \\| y-\\beta \\| 2^2 + \\lambda \\| \\beta \\| 1 \\end equation Từ ví dụ trước, điều kiện tối ưu gradient dưới là: > MATH \\begin cases y i-\\beta i = \\lambda \\cdot \\text sign \\beta i &\\text nếu \\beta i \\neq 0 \\\\ |y i-\\beta i| \\leq \\lambda &\\text nếu \\beta i = 0 \\end cases MATH Từ điều kiện này, có thể tìm được nghiệm MATH , trong đó > MATH S \\lambda y i = \\begin cases y i - \\lambda &\\text nếu y i > \\lambda \\\\ 0 &\\text nếu -\\lambda \\leq y i \\leq \\lambda, \\quad \\quad i \\in \\ 1,2,\\dots,n \\ \\\\ y i + \\lambda &\\text nếu y i MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_03_04_example_soft-thresholding/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter07/07_03_05_example_distance_to_convex_set",
    "title": "07-03-05 Ví dụ: Khoảng cách đến tập lồi",
    "chapter": "07",
    "order": 11,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Hàm khoảng cách đến một tập lồi đóng MATH được định nghĩa như sau: > \\begin alignat 1 dist x,C & = \\min y \\in C \\| y-x \\| 2 \\\\ & = \\| x-P C x \\| 2 \\\\ & \\geq 0 \\end alignat Ở đây, MATH là phép chiếu của điểm MATH lên tập MATH , tức là điểm gần nhất trong MATH với MATH . Gradient dưới của hàm khoảng cách là: > \\begin equation \\partial dist x,C = \\ \\frac x-P C x \\| x-P C x \\| 2 \\ \\end equation Chứng minh Nếu MATH , thì theo điều kiện tối ưu bậc một, > \\begin equation x-u ^T y-u \\leq 0 \\ \\text với mọi y \\in C \\end equation Do đó, > \\begin equation C \\subseteq H = \\ y: x-u ^T y-u \\leq 0 \\ \\end equation i Với MATH , > \\begin equation x-u ^T y-u \\leq 0 \\end equation Mặt khác, vì MATH , > \\begin equation dist y,C \\geq \\frac x-u ^T y-u \\| x-u \\| 2 \\text với mọi y \\in H \\end equation ii Với MATH , > \\begin equation x-u ^T y-u = \\| x-u \\| 2 \\| y-u \\| 2 \\cos\\theta, \\end equation trong đó MATH là góc giữa MATH và MATH . Khi đó, > MATH \\eqalign dist y,C &\\geq dist y,H \\\\ &= \\| y-u \\| 2 \\cos \\theta \\\\ &= \\frac x-u ^T y-u \\| x-u \\| 2 \\text với mọi y \\notin H MATH Do đó, từ i và ii , với mọi MATH , > MATH \\eqalign dist y,C &\\geq \\frac x-u ^T y-u \\| x-u \\| 2 \\\\ &= \\frac x-u ^T y-x+x-u \\| x-u \\| 2 \\\\ & = \\| x-u \\| 2 + \\left \\frac x-u \\| x-u \\| 2 \\right ^T y-x MATH Kết luận, MATH có gradient dưới sau tại MATH : > MATH Hơn nữa, vi phân dưới MATH chỉ chứa một phần tử, nên MATH khả vi và đạo hàm của nó trùng với gradient dưới.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter07/07_03_05_example_distance_to_convex_set/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_00_subgradient_method",
    "title": "08 Phương pháp Subgradient",
    "chapter": "08",
    "order": 1,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Trong phần này, chúng ta sẽ tìm hiểu về phương pháp subgradient, có thể được áp dụng cho các hàm lồi có thể không khả vi, sử dụng khái niệm subgradient. Chúng ta cũng sẽ khám phá các tính chất hội tụ và tốc độ hội tụ của phương pháp subgradient thông qua các ví dụ.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_00_subgradient_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_01_subgradient_method",
    "title": "08-01 Phương pháp Subgradient",
    "chapter": "08",
    "order": 2,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Giả sử miền của hàm số là MATH và có một hàm lồi MATH có thể không khả vi tại mọi điểm. Phương pháp subgradient được định nghĩa bằng cách thay thế gradient trong phương pháp gradient descent bằng một subgradient. MATH > MATH Ở đây, MATH , tức là MATH là một subgradient của MATH tại MATH . Phương pháp subgradient không phải \"descent\" subgradient Khác với gradient descent, phương pháp subgradient không luôn đảm bảo giảm giá trị hàm số ở mỗi bước do đó tên gọi không phải là \"descent\" subgradient . Vì vậy, khi sử dụng phương pháp subgradient, quan trọng là phải theo dõi kết quả tốt nhất tại mỗi lần lặp. > MATH MATH biểu thị giá trị nhỏ nhất của hàm MATH thu được trong MATH lần lặp của phương pháp subgradient.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_01_subgradient_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_01_01_step_size_choices",
    "title": "08-01-01 Lựa chọn kích thước bước",
    "chapter": "08",
    "order": 3,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Có nhiều cách khác nhau để chọn kích thước bước trong phương pháp subgradient. Hãy xem xét kỹ hơn hai phương pháp sau: - Kích thước bước cố định : MATH , với MATH - Kích thước bước giảm dần : MATH thỏa mãn các điều kiện sau: >\\begin align > \\sum k=1 ^ \\infty t k = \\infty, \\quad \\sum k=1 ^ \\infty t k^ 2 \\end align Ví dụ về kích thước bước giảm dần > MATH \\begin align & t k = \\frac 1 k , k = 1,2,3,... & \\sum k=1 ^ \\infty t k = \\infty \\quad ext Chuỗi điều hòa & \\sum k=1 ^ \\infty t^2 k \\approx 1.644934 < \\infty \\quad ext Bài toán Basel \\end align MATH Một đặc điểm chính của kích thước bước trong phương pháp subgradient là nó phải được thiết lập trước, khác với gradient descent. Nói cách khác, không giống như tìm kiếm đường thẳng backtracking trong gradient descent, kích thước bước trong phương pháp subgradient không thích ứng với độ cong của hàm số.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_01_01_step_size_choices/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_01_02_basic_inequality",
    "title": "08-01-02 Bất đẳng thức cơ bản",
    "chapter": "08",
    "order": 4,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Định lý hội tụ và tốc độ hội tụ của phương pháp subgradient có thể được chứng minh bằng cách sử dụng bất đẳng thức cơ bản sau. Bất đẳng thức cơ bản > MATH \\begin align f best ^ k - f^ \\quad \\le \\quad \\frac R^ 2 +G^ 2 \\sum i=1 ^ k \\alpha i ^ 2 2\\sum i=1 ^ k \\alpha i \\end align MATH Chứng minh Nếu MATH là điểm tối ưu của hàm MATH , thì phương trình sau đây đúng: > MATH \\begin alignat 1 \\Vert x^ k+1 -x^ \\Vert 2^ 2 & \\quad = \\quad \\Vert x^ k -\\alpha k g^ k -x^ \\Vert 2^ 2 \\\\ & \\quad = \\quad \\Vert x^ k -x^ -\\alpha k g^ k \\Vert 2^ 2 \\\\ & \\quad = \\quad \\Vert x^ k -x^ \\Vert 2^2 - 2 \\alpha k g^ k T x^ k -x^ +\\alpha k^2 \\Vert g^ k \\Vert 2^2 \\\\ \\end alignat MATH Từ định nghĩa của subgradient, bất đẳng thức sau đây đúng: > MATH \\begin alignat 1 f x^ \\ge f x^ k + g^ k T x^ -x^ k & \\quad \\Longleftrightarrow \\quad f x^ -f x^ k \\ge g^ k T x^ -x^ k \\\\ & \\quad \\Longleftrightarrow \\quad f x^ k - f x^ \\le g^ k T x^ k -x^ \\\\ & \\quad \\Longleftrightarrow \\quad -2\\alpha k f x^ k - f x^ \\ge -2\\alpha k g^ k T x^ k -x^ \\\\ & \\quad \\Longleftrightarrow \\quad -2\\alpha k g^ k T x^ k -x^ \\le -2\\alpha k f x^ k -f x^ \\\\ \\end alignat MATH Sử dụng các phương trình và bất đẳng thức trên, bất đẳng thức sau có thể được suy ra:",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_01_02_basic_inequality/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_01_03_convergence_analysis",
    "title": "08-01-03 Phân tích hội tụ",
    "chapter": "08",
    "order": 5,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Trong gradient descent, ta giả định rằng MATH liên tục Lipschitz, nhưng trong phương pháp subgradient, ta giả định rằng chính MATH là liên tục Lipschitz. Xem định lý hội tụ cho gradient descent 06-03-01 % multilang post url contents/chapter06/21-03-20-06 03 01 convergence analysis and proof % để tham khảo. Giả sử MATH là lồi, dom MATH , và MATH thỏa mãn điều kiện Lipschitz: >\\begin align > | f x - f y | \\le G \\lVert x - y \\rVert 2 \\text với mọi x, y \\end align Dựa trên các giả định này, công thức hội tụ cho kích thước bước cố định và giảm dần như sau: Định lý hội tụ cho kích thước bước cố định Kích thước bước cố định có tính chất hội tụ sau: >\\begin align > \\lim k\\to\\infty f x^ k best \\le f^ + \\frac G^ 2 t 2 \\end align Định lý hội tụ cho kích thước bước giảm dần Phương pháp kích thước bước giảm dần có tính chất hội tụ sau: >\\begin align \\lim k\\to\\infty f x^ k best = f^ \\end align Chứng minh Chứng minh cho kích thước bước cố định và giảm dần như sau. Chứng minh định lý hội tụ cho kích thước bước cố định Phương pháp kích thước bước cố định sử dụng MATH trong chứng minh. > MATH \\begin align & f best ^ k - f^ \\le \\frac R^ 2 +G^ 2 \\sum i=1 ^ k t i ^ 2 2\\sum i=1 ^ k t i = \\frac R^ 2 +G^ 2 k t^ 2 2kt = \\frac R^ 2 2tk + \\frac G^ 2 t 2 \\\\ & \\lim k→\\infty f^ k best - f^ \\le 0 + \\frac G^ 2 t 2 = \\frac G^ 2 t 2 \\\\ & \\lim k→\\infty f^ k best \\le f^ + \\frac G^ 2 t 2 \\end align MATH Chứng minh định lý hội tụ cho kích thước bước giảm dần Chứng minh cho kích thước bước giảm dần sử dụng các tính chất 1 và 2 sau: > MATH \\begin align \\text 1 \\sum i=1 ^ \\infty t i = \\infty, \\quad \\text 2 \\sum i=1 ^ \\infty t i^ 2 = \\beta MATH \\begin align & f best ^ k - f^ \\le \\frac R^ 2 +G^ 2 \\sum i=1 ^ k t i ^ 2 2\\sum i=1 ^ k t i \\\\ & \\lim k→\\infty f^ k best - f^ \\le \\frac R^ 2 +G^ 2 \\beta 2\\infty = 0 \\\\ & \\lim k→\\infty f^ k best = f^ \\\\ \\end align MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_01_03_convergence_analysis/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_01_04_convergence_rate",
    "title": "08-01-04 Tốc độ hội tụ",
    "chapter": "08",
    "order": 6,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Tốc độ hội tụ mô tả cách số lần lặp cần thiết để đạt đến một điểm MATH -dưới tối ưu phụ thuộc vào MATH , sử dụng ký hiệu Big-O https://en.wikipedia.org/wiki/Big O notation . Ví dụ, nếu MATH và tốc độ hội tụ là MATH , thì cần khoảng MATH lần lặp. Hãy sử dụng 08-01-02 Bất đẳng thức cơ bản % multilang post url contents/chapter08/20-03-29-08 01 02 basic inequality % để suy ra tốc độ hội tụ cho phương pháp subgradient với kích thước bước cố định. > MATH >\\begin align > f^ k best - f^ \\quad \\le \\quad \\frac R^ 2 2kt + \\frac G^ 2 t 2 \\end align Giả sử MATH thỏa mãn MATH và MATH trong đó MATH là khoảng cách dưới tối ưu, MATH là hằng số Lipschitz, và MATH là khoảng cách giữa điểm khởi đầu và điểm tối ưu . Khi đó MATH . Nếu MATH , thì MATH , và MATH dẫn đến MATH . Điều này có nghĩa là số lần lặp cần thiết ít nhất là MATH để đạt được MATH . Tốc độ hội tụ của thuật toán này là MATH , có nghĩa là nó cần nhiều lần lặp hơn đáng kể so với phương pháp gradient descent, có tốc độ MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_01_04_convergence_rate/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_01_05_example_regularized_logistic_regression",
    "title": "08-01-05 Ví dụ: Hồi quy Logistic có Regularization",
    "chapter": "08",
    "order": 7,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Giả sử MATH với MATH . Hàm mất mát hồi quy logistic được định nghĩa như sau: > \\begin align f \\beta = \\sum i=1 ^n\\big -y ix i^T\\beta + \\log 1+\\exp x i^T\\beta \\big \\end align Hàm này là tổng hữu hạn của một hàm tuyến tính và một hàm log-sum-exp, vì vậy nó là một hàm lồi khả vi. Bây giờ, bài toán regularization cho MATH được công thức hóa như sau: > \\begin align \\min \\beta \\text f \\beta + \\lambda \\cdot P \\beta \\end align Ở đây, MATH có thể được định nghĩa là MATH phạt ridge hoặc MATH phạt lasso . Hàm mất mát với phạt ridge vẫn là một hàm lồi khả vi, nhưng hàm mất mát với phạt lasso trở thành một hàm lồi không khả vi. Đối với hai hàm mất mát này, chúng ta có thể áp dụng gradient descent cho ridge và phương pháp subgradient cho lasso, và bằng cách vẽ đồ thị giá trị hàm mục tiêu tại lần lặp MATH , chúng ta có thể quan sát đặc điểm hội tụ của cả hai phương pháp. Fig 1 Gradient descent so với phương pháp Subgradient 3 Thí nghiệm này cho thấy rằng gradient descent hội tụ nhanh hơn nhiều so với phương pháp subgradient.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_01_05_example_regularized_logistic_regression/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_01_06_polyak_step_sizes",
    "title": "08-01-06 Kích thước bước Polyak",
    "chapter": "08",
    "order": 8,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Kích thước bước Polyak là một cách để thiết lập kích thước bước khi giá trị tối ưu được biết. Nếu MATH được biết, kích thước bước Polyak có thể được định nghĩa như sau. Định lý hội tụ cho kích thước bước Polyak > MATH \\begin align t k = \\frac f^ k-1 -f^ \\Vert g^ k-1 \\Vert 2^ 2 , \\quad k = 1,2,3... \\end align MATH Chứng minh định lý hội tụ cho kích thước bước Polyak Chứng minh có thể được suy ra từ bất đẳng thức cơ bản % multilang post url contents/chapter08/20-03-29-08 01 02 basic inequality % và chuỗi bất đẳng thức được sử dụng ở đó. > MATH \\begin align \\Vert x^ k -x^ \\Vert 2^ 2 \\quad \\le \\quad \\Vert x^ k-1 -x^ \\Vert 2^ 2 -2t k f x^ k-1 -f^ +t k^ 2 \\Vert g^ k-1 \\Vert 2^ 2 \\\\ \\end align MATH By differentiating the right-hand side above with respect to MATH and setting it to zero, we obtain the Polyak step size that minimizes the right-hand side. > MATH \\begin align & \\frac \\partial \\partial t k \\Vert x^ k-1 -x^ \\Vert 2^ 2 -2t k f x^ k-1 -f^ +t k^ 2 \\Vert g^ k-1 \\Vert 2^ 2 = 0 \\\\ \\Longleftrightarrow & -2 f x^ k-1 -f^ +2t k \\Vert g^ k-1 \\Vert 2^ 2 = 0 \\\\ \\Longleftrightarrow & f x^ k-1 -f^ = t k \\Vert g^ k-1 \\Vert 2^ 2 \\\\ \\Longleftrightarrow & t k = \\frac f x^ k-1 -f^ \\Vert g^ k-1 \\Vert 2^ 2 \\quad \\text Polyak step size at k \\end align MATH The convergence rate of the Polyak step size can also be derived from the basic inequality % multilang post url contents/chapter08/20-03-29-08 01 02 basic inequality % and the sequence of inequalities used there. Convergence rate for Polyak step-sizes Let’s substitute the Polyak step size MATH into the basic inequality derived in the basic inequality % multilang post url contents/chapter08/20-03-29-08 01 02 basic inequality % . > MATH \\begin align & 2\\sum i=1 ^ k t i f x^ i -f^ \\le R^2 + \\sum i=1 ^kt i^2 \\Vert g^ i \\Vert 2^2 \\\\ \\Longleftrightarrow \\quad & 2\\sum i=1 ^ k \\frac f x^ i -f^ ^2 \\Vert g^ i \\Vert 2^2 \\le R^2 + \\sum i=1 ^k\\frac f x^ i -f^ ^2 \\Vert g^ i \\Vert 2^2 \\\\ \\Longleftrightarrow \\quad & \\sum i=1 ^ k \\frac f x^ i -f^ ^2 \\Vert g^ i \\Vert 2^2 \\le R^2 \\\\ \\end align MATH Assuming that the Lipschitz condition MATH always holds, the above inequality can be rearranged as follows: > MATH \\begin align & \\sum i=1 ^ k f x^ i -f^ ^2 \\le R^2G^2 \\\\ \\Longleftrightarrow \\quad & k ⋅ f x^ i -f^ ^2 \\le R^2G^2 \\\\ \\Longleftrightarrow \\quad & \\sqrt k ⋅ f x^ i -f^ \\le RG \\\\ \\Longleftrightarrow \\quad & f x^ i -f^ \\le \\frac RG \\sqrt k \\\\ \\end align MATH If we let MATH , then MATH , so the number of trials required to reach a suboptimal point with respect to MATH is on the order of MATH . In other words, the convergence rate is MATH , which is the same as other subgradient methods.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_01_06_polyak_step_sizes/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_01_07_example_intersection_of_sets",
    "title": "08-01-07 Ví dụ: Giao của các tập hợp",
    "chapter": "08",
    "order": 9,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Giả sử chúng ta muốn tìm điểm giao của nhiều tập lồi đóng. Đầu tiên, hãy định nghĩa MATH là khoảng cách từ điểm MATH đến tập MATH , và MATH là khoảng cách tối đa từ MATH đến tất cả các tập MATH : > MATH \\begin align f i x & = \\mathbb dist x, C i , i=1,...,m \\\\ f x & = \\max 1,...,m \\text f i x \\end align MATH Sử dụng hai hàm này, bài toán tìm giao của các tập lồi có thể được công thức hóa thành bài toán tối thiểu hóa sau: > MATH \\begin align min x \\text f x \\end align MATH Bài toán tìm điểm giao của các tập lồi tương đương với việc tìm điểm MATH tối thiểu hóa khoảng cách tối đa MATH đến các tập MATH . Trong trường hợp này, hàm mục tiêu MATH là lồi. Nếu tất cả các tập đều có điểm giao chung, thì MATH và điểm tối ưu là MATH . Gradient của hàm khoảng cách Trong phần trước % multilang post url contents/chapter07/21-03-25-07 03 05 example distance to convex set % , chúng ta đã định nghĩa khoảng cách đến một tập lồi là MATH , và thấy rằng gradient của hàm này là: > MATH \\begin align \\partial dist x,C = \\frac x-P C x \\Vert x-P C x \\Vert 2 \\end align MATH Ở đây, MATH là phép chiếu của điểm MATH lên tập MATH . Subdifferential của maximum hữu hạn theo điểm Subdifferential của hàm finite pointwise maximum MATH được định nghĩa như sau. > MATH \\begin align \\partial f x = \\text conv \\left \\bigcup i:f i x =f x \\partial f i x \\right \\end align MATH Tức là, subdifferential của MATH được định nghĩa là convex hull của hợp tất cả các subdifferential MATH tại điểm đó. Nếu MATH và MATH thì MATH . Suy ra các bước cập nhật subgradient Trong chương trước % multilang post url contents/chapter07/21-03-25-07 03 05 example distance to convex set % , MATH có subgradient như sau. > MATH MATH \\begin align g i = \\nabla f i x = \\frac x-P C i x \\Vert x-P C i x \\Vert 2 \\end align MATH Nếu có điểm giao của các tập lồi thì chúng ta có thể biết ngay rằng MATH nên có thể sử dụng kích thước bước Polyak. Nhìn vào công thức subgradient trên, MATH ở dạng chuẩn hóa nên MATH . Cuối cùng, thay các giá trị đã biết vào kích thước bước Polyak MATH , chúng ta có thể suy ra công thức phương pháp subgradient như sau. > MATH \\begin align x^ k & = x^ k-1 - t k ⋅g k-1 \\\\ & = x^ k-1 - \\frac f^ k-1 -f^ \\Vert g^ k-1 \\Vert 2^ 2 \\frac x^ k-1 -P C i x \\Vert x^ k-1 -P C i x \\Vert 2 \\\\ & = x^ k-1 - f x^ k-1 \\frac x^ k-1 -P C i x \\Vert x^ k-1 -P C i x \\Vert 2 \\end align MATH Ở đây kích thước Polyak MATH là MATH nên phương pháp subgradient được tổng kết như sau. > MATH \\begin align x^ k = P C i x^ k-1 \\end align MATH Bài toán này khi biểu diễn bằng hình vẽ có dạng lặp lại phép chiếu lên hàm lồi gần nhất ở mỗi bước. Fig 2 Alternating Projection Algorithm 10",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_01_07_example_intersection_of_sets/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_01_08_projected_subgradient_method",
    "title": "08-01-08 Phương pháp Subgradient có Chiếu",
    "chapter": "08",
    "order": 10,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Phương pháp được mô tả trong ví dụ trước được gọi là phương pháp subgradient có chiếu. Thuật toán này có thể được sử dụng cho các bài toán lồi có ràng buộc. Nếu chúng ta ký hiệu miền thỏa mãn các ràng buộc là tập MATH , thì bài toán lồi có ràng buộc được định nghĩa như sau: > MATH \\begin align \\min x \\text f x \\quad \\text với điều kiện x \\in C \\end align MATH Bằng cách sử dụng phương pháp subgradient có chiếu, các bài toán như vậy có thể được giải tương đối dễ dàng. Phương pháp subgradient có chiếu tương tự như phương pháp subgradient chuẩn, nhưng ở mỗi lần lặp, kết quả được chiếu lên tập MATH . > MATH \\begin align x^ k = P c x^ k-1 - t k \\cdot g^ k-1 , \\quad k = 1,2,3,... \\end align MATH Nếu phép chiếu có thể thực hiện được, phương pháp này có cùng tính chất hội tụ và tốc độ như phương pháp subgradient. Một điều cần lưu ý về phương pháp subgradient có chiếu là ngay cả khi MATH là một tập lồi đơn giản, nếu phép toán chiếu MATH khó thực hiện, thì bài toán tổng thể cũng trở nên khó giải. Thông thường, các tập MATH sau đây tương đối dễ chiếu lên: - Ảnh affine: MATH - Tập nghiệm của hệ tuyến tính: MATH - Trực giao không âm: MATH MATH - Một số quả cầu chuẩn: MATH với MATH - Một số đa diện đơn giản và hình nón đơn giản",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_01_08_projected_subgradient_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_02_stochastic_subgradient_method",
    "title": "08-02 Phương pháp Subgradient Ngẫu nhiên",
    "chapter": "08",
    "order": 11,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Phương pháp subgradient ngẫu nhiên tương tự như stochastic gradient descent, nhưng thay thế gradient bằng subgradient.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_02_stochastic_subgradient_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_02_01_stochastic_subgradient_method",
    "title": "08-02-01 Phương pháp Subgradient Ngẫu nhiên",
    "chapter": "08",
    "order": 12,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Hãy xem xét bài toán tối thiểu hóa tổng các hàm như sau: > MATH \\begin equation \\min x \\sum i=1 ^m f i x \\end equation MATH Nếu chúng ta áp dụng phương pháp subgradient cho bài toán này, chúng ta cần tính subgradient cho mỗi hàm MATH và cộng chúng lại. Điều này tương tự như phương pháp được giới thiệu trong stochastic gradient descent % multilang post url contents/chapter06/21-03-20-06 05 stochastic gradient descent % . Tóm lại, phương pháp subgradient ngẫu nhiên có dạng như sau: > MATH \\begin align x^ k = x^ k-1 - t k \\cdot g i k ^ k-1 , \\quad k = 1, 2, 3, . . . \\end align MATH Ở đây, MATH là chỉ số được chọn tại lần lặp thứ MATH . Như sẽ được thảo luận trong phần tiếp theo về tốc độ hội tụ của phương pháp subgradient ngẫu nhiên, việc lựa chọn phương pháp tuần hoàn hoặc ngẫu nhiên ảnh hưởng đến kết quả. MATH , và hướng cập nhật này khác với phương pháp subgradient % multilang post url contents/chapter08/20-03-29-08 01 subgradient method % thông thường còn được gọi là phương pháp subgradient batch hoặc phương pháp subgradient full batch , nơi sử dụng MATH . Nếu mỗi MATH khả vi, thuật toán này trở thành stochastic gradient descent. Phương pháp subgradient ngẫu nhiên là một dạng tổng quát hơn",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_02_01_stochastic_subgradient_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_02_02_convergence_of_stochastic_methods",
    "title": "08-02-02 Hội tụ của các Phương pháp Ngẫu nhiên",
    "chapter": "08",
    "order": 13,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Giả sử mỗi hàm MATH là lồi và liên tục Lipschitz với hằng số G. Đối với phương pháp subgradient ngẫu nhiên, các tính chất sau đây đúng cho kích thước bước cố định và giảm dần: - Kích thước bước cố định với MATH , MATH > MATH \\text Đối với phương pháp tuần hoàn và ngẫu nhiên với kích thước bước cố định, điều sau đây đúng: \\\\ \\begin align \\lim k\\to\\infty f x best ^ k \\le f^ + 5m^ 2 G^ 2 t/2 \\end align MATH Ở đây, MATH là hằng số Lipschitz của MATH . - Kích thước bước giảm dần > MATH \\text Đối với phương pháp tuần hoàn và ngẫu nhiên với kích thước bước giảm dần, điều sau đây đúng: \\\\ \\begin align \\lim k\\to\\infty f x best ^ k = f^ \\end align MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_02_02_convergence_of_stochastic_methods/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_02_03_convergence_rate_of_stochastic_method",
    "title": "08-02-03 Tốc độ Hội tụ của Phương pháp Ngẫu nhiên",
    "chapter": "08",
    "order": 14,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Có sự khác biệt về tốc độ hội tụ giữa phương pháp tuần hoàn và phương pháp ngẫu nhiên. Tốc độ hội tụ % multilang post url contents/chapter08/20-03-29-08 01 04 convergence rate % của phương pháp subgradient batch là MATH , trong đó MATH là hằng số Lipschitz của MATH . - Phương pháp tuần hoàn : Độ phức tạp lặp của phương pháp tuần hoàn là MATH . Nếu một chu kỳ của phương pháp subgradient ngẫu nhiên tuần hoàn được coi là tương đương với một phương pháp subgradient batch, thì mỗi chu kỳ cần MATH lần lặp. MATH là hằng số Lipschitz của một hàm đơn MATH - Phương pháp ngẫu nhiên : Độ phức tạp lặp của phương pháp ngẫu nhiên là MATH . Tức là, phương pháp ngẫu nhiên cần MATH lần lặp, nhanh hơn MATH lần so với phương pháp batch và tuần hoàn với MATH . Về mặt ký hiệu Big-O, nếu MATH lớn, phương pháp ngẫu nhiên có tốc độ hội tụ nhanh hơn. Mặc dù các cận Big-O cho phương pháp ngẫu nhiên và tuần hoàn khác nhau một hệ số MATH , lưu ý rằng cận Big-O của phương pháp tuần hoàn là trường hợp xấu nhất, trong khi của phương pháp ngẫu nhiên là trường hợp trung bình. Trong thực tế, sự khác biệt có thể không lớn như ký hiệu Big-O gợi ý.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_02_03_convergence_rate_of_stochastic_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_02_04_batch_vs_stochastic_methods",
    "title": "08-02-04 So sánh Phương pháp Batch và Ngẫu nhiên",
    "chapter": "08",
    "order": 15,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Tính chất hội tụ của phương pháp batch và ngẫu nhiên như sau: Nói chung, phương pháp ngẫu nhiên tiếp cận điểm tối ưu nhanh chóng trong giai đoạn đầu, nhưng có thể không hội tụ tốt gần điểm tối ưu. Ngược lại, phương pháp batch hội tụ chậm hơn nhưng tiếp cận điểm tối ưu chính xác hơn. Hình dưới đây so sánh sự hội tụ của phương pháp batch và ngẫu nhiên cho hồi quy logistic https://en.wikipedia.org/wiki/Logistic regression không có regularization : Fig 3 So sánh Batch vs Stochastic Gradient Descent 2",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_02_04_batch_vs_stochastic_methods/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter08/08_03_improving_on_the_subgradient_method",
    "title": "08-03 Cải tiến Phương pháp Subgradient",
    "chapter": "08",
    "order": 16,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Phương pháp subgradient có lợi thế vì có thể được sử dụng cho các hàm lồi không khả vi, làm cho nó tổng quát hơn. Tuy nhiên, tốc độ hội tụ của nó là MATH , chậm hơn nhiều so với tốc độ hội tụ của gradient descent là MATH . Có cách nào để kết hợp điểm mạnh của gradient descent và phương pháp subgradient không? Trong phần tiếp theo, chúng ta sẽ tìm hiểu về phương pháp proximal gradient descent, kết hợp ưu điểm của cả hai thuật toán.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter08/08_03_improving_on_the_subgradient_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter09/09_proximal_gradient_descent_and_acceleration",
    "title": "Phương pháp gradient gần kề và tăng tốc",
    "chapter": "09",
    "order": 1,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Phương pháp gradient gần kề và tăng tốc Chương này giới thiệu phương pháp gradient gần kề và các kỹ thuật tăng tốc cho các bài toán tối ưu liên quan đến các hàm tổng hợp. Tổng quan - Phương pháp gradient gần kề được sử dụng cho các bài toán trong đó hàm mục tiêu có thể được tách thành một phần khả vi và một phần không khả vi. - Các phương pháp tăng tốc, chẳng hạn như tăng tốc của Nesterov và FISTA, có thể cải thiện tốc độ hội tụ. Cấu trúc - Phần 1: Phương pháp gradient gần kề - Phần 2: Phân tích hội tụ - Phần 3: Ví dụ hoàn thiện ma trận - Phần 4: Các trường hợp đặc biệt - Phần 5: Các phương pháp tăng tốc Tham khảo từng phần để biết chi tiết và các công thức toán học.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter09/09_proximal_gradient_descent_and_acceleration/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter09/09_01_proximal_gradient_descent",
    "title": "09-01 Phương pháp gradient gần kề",
    "chapter": "09",
    "order": 2,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Phương pháp gradient gần kề Proximal gradient descent Phương pháp gradient gần kề là một phương pháp tìm điểm tối ưu bằng cách phân tách hàm mục tiêu thành một phần khả vi và một phần không khả vi. Trong phần này, chúng ta sẽ tìm hiểu cách định nghĩa các hàm và tìm điểm tối ưu trong phương pháp gradient gần kề. Hàm có thể phân tách Giả sử hàm mục tiêu MATH có thể được phân tách thành hai hàm MATH và MATH . > MATH Ở đây, hai hàm MATH và MATH có các tính chất sau: MATH là hàm lồi và khả vi. dom MATH MATH là hàm lồi và không khả vi. Nếu MATH khả vi, bạn có thể tìm vị trí tiếp theo bằng phương pháp gradient descent: > MATH Ghi chú Trong gradient descent, hàm MATH được xấp xỉ gần MATH bằng khai triển Taylor bậc hai, và ma trận Hessian MATH được thay thế bởi MATH . Điểm cực tiểu của xấp xỉ này được chọn làm vị trí tiếp theo. Xem Chi tiết trong Chương 6 Gradient descent > \\begin align x^+ = \\underset z \\text argmin \\underbrace f x + \\nabla f x ^T z - x + \\frac 1 2t \\parallel z - x \\parallel 2 ^2 \\tilde f t z \\end align Tuy nhiên, nếu MATH không khả vi, bạn không thể sử dụng gradient descent. Nhưng nếu MATH được cấu thành như MATH , liệu chúng ta có thể xấp xỉ phần khả vi MATH bằng một hàm bậc hai không? Ý tưởng này dẫn đến Phương pháp gradient gần kề . Trong phương pháp này, bạn điều chỉnh đến vị trí tốt nhất gần với vị trí được dự đoán bởi gradient descent cho MATH và cũng làm cho hàm không khả vi MATH nhỏ. Quá trình này có thể được biểu diễn như sau: > MATH \\begin align x^+ & = \\underset z \\text argmin \\tilde g t z + h z \\\\ & = \\underset z \\text argmin \\ g x + \\nabla g x ^T z - x + \\frac 1 2t \\parallel z - x \\parallel 2 ^2 + h z \\\\ & = \\underset z \\text argmin \\nabla g x ^T z - x + \\frac 1 2t \\parallel z - x \\parallel 2 ^2 + \\frac t 2 \\parallel \\nabla g x \\parallel 2 ^2 + h z \\\\ & = \\underset z \\text argmin \\frac 1 2t \\left 2t \\nabla g x ^T z - x + \\parallel z - x \\parallel 2 ^2 + t^2 \\parallel \\nabla g x \\parallel 2 ^2 \\right + h z \\\\ & = \\underset z \\text argmin \\frac 1 2t \\left \\parallel z - x \\parallel 2 ^2 + 2t \\nabla g x ^T z - x + t^2 \\parallel \\nabla g x \\parallel 2 ^2 \\right + h z \\\\ & = \\underset z \\text argmin \\frac 1 2t \\parallel z - x - t \\nabla g x \\parallel 2 ^2 + h z \\\\ \\end align MATH Khi chuyển từ dòng thứ 2 sang dòng thứ 3, số hạng MATH được loại bỏ như một số hạng hằng số đối với z, và số hạng MATH được thêm vào. Trong phương trình cuối cùng, số hạng đầu tiên MATH là số hạng đưa nó gần hơn với vị trí cập nhật gradient của MATH , và số hạng thứ hai MATH là số hạng làm giảm MATH . Phương pháp gradient gần kề Phương pháp gradient gần kề bắt đầu từ một điểm ban đầu MATH và lặp lại việc áp dụng cập nhật sau: > MATH , MATH Ở đây, MATH được định nghĩa là ánh xạ gần kề proximal mapping : > \\begin align \\text prox t x = \\underset z \\arg \\min \\frac 1 2t \\parallel x - z \\parallel 2^2 + h z \\end align Nếu chúng ta viết lại điều này dưới dạng cập nhật mà chúng ta đã thấy cho đến nay, nó trở thành: > \\begin align x^ k = x^ k-1 - t k \\cdot G t k x^ k-1 , \\space \\space \\text trong đó \\space G t x = \\frac x-\\text prox t x - t \\nabla g x t \\\\ \\end align Điều này có lợi ích gì? Lợi ích của việc làm này là gì? Có phải chỉ là thay đổi bài toán thành một dạng bài toán tối ưu khác không? Điểm quan trọng là đối với hầu hết các hàm MATH chính, MATH có thể được tính toán một cách giải tích. Nói cách khác, nó có thể được tính toán như sau: Hàm ánh xạ MATH chỉ phụ thuộc vào MATH , không phụ thuộc vào MATH . Hàm MATH có thể rất phức tạp, nhưng ở đây chúng ta chỉ cần tính gradient MATH . Phân tích hội tụ sẽ được thực hiện liên quan đến số lần lặp của thuật toán. Lưu ý rằng trong mỗi lần lặp, việc tính toán MATH có thể khác nhau về chi phí tính toán tùy thuộc vào MATH . Ví dụ: ISTA Hãy xem một ví dụ về phương pháp gradient gần kề. Trong chương trước, tiêu chí lasso được định nghĩa như sau khi MATH và MATH : > \\begin align f \\beta = \\frac 1 2 \\parallel y - X\\beta \\parallel 2^2 + \\lambda \\parallel \\beta \\parallel 1 \\\\ \\end align Ở đây, MATH và MATH . Trong trường hợp này, ánh xạ gần kề được định nghĩa là: > MATH \\begin align \\text prox t \\beta & = \\underset z \\text argmin \\frac 1 2t \\parallel \\beta - z \\parallel 2^2 + \\lambda \\parallel z \\parallel 1 \\\\ & = S \\lambda t \\beta \\\\ \\end align MATH MATH là toán tử ngưỡng mềm soft-thresholding operator , được định nghĩa như sau. Để biết thêm chi tiết, xem Chương 7 Subgradient > MATH \\begin align S \\lambda t \\beta i = \\begin cases \\beta i - \\lambda & \\mbox nếu \\beta i \\gt \\lambda \\\\ 0 & \\mbox nếu -\\lambda \\le \\beta i \\le \\lambda, i = 1, ..., n \\\\ \\beta i + \\lambda & \\mbox nếu \\beta i \\lt -\\lambda \\\\ \\end cases \\\\ \\end align MATH Vì gradient của MATH là MATH , cập nhật gradient gần kề được định nghĩa là: > MATH Thuật toán này là một thuật toán rất đơn giản được gọi là thuật toán ngưỡng mềm lặp iterative soft-thresholding algorithm - ISTA . Beck và Teboulle 2008 , \"A fast iterative shrinkage-thresholding algorithm for linear inverse problems\" Trong hình dưới đây, bạn có thể thấy rõ sự khác biệt về hiệu suất giữa phương pháp subgradient và phương pháp gradient gần kề. Về mặt số lần lặp, hiệu suất của phương pháp gradient gần kề có thể so sánh với gradient descent. Hình 1 Ví dụ về tốc độ hội tụ của gradient gần kề ISTA so với phương pháp subgradient 3",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter09/09_01_proximal_gradient_descent/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter09/09_02_convergence_analysis",
    "title": "09-02 Phân tích hội tụ",
    "chapter": "09",
    "order": 3,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Phân tích hội tụ Trong phần này, chúng ta phân tích sự hội tụ của phương pháp gradient gần kề. Phân tích hội tụ Đối với hàm mục tiêu MATH , chúng ta giả định như sau: MATH là hàm lồi, khả vi, và dom MATH , và MATH liên tục Lipschitz MATH . MATH là hàm lồi, và MATH cần được tính toán. Định lý hội tụ > Phương pháp gradient gần kề thỏa mãn phương trình sau với kích thước bước cố định MATH : >\\begin align f x^ k - f^ \\ \\le \\frac \\lVert x^ 0 - x^ \\ \\rVert^2 2 2tk \\end align Phương pháp gradient gần kề có tốc độ hội tụ MATH hoặc MATH , đây là hiệu suất tương tự như gradient descent. Tuy nhiên, hiệu suất này dựa trên số lần lặp, không phải số phép toán. Số phép toán có thể thay đổi tùy thuộc vào hàm MATH . Tìm kiếm đường thẳng lùi Backtracking line search Phương pháp tìm kiếm đường thẳng lùi của gradient gần kề tương tự như gradient descent nhưng chỉ hoạt động trên phần trơn MATH , không phải hàm MATH . Đầu tiên, đặt tham số MATH 0 \\begin align g x - tG t x > g x - t \\nabla g x ^T G t x + \\frac t 2 \\parallel G t x \\parallel 2 ^2 \\end align Điều kiện lùi này có nghĩa là giá trị của hàm MATH tại vị trí bước tiếp theo MATH lớn hơn giá trị của xấp xỉ Taylor bậc hai của hàm MATH . Nếu MATH trong phương trình này, chúng ta có thể thấy rằng MATH , điều này trở nên giống hệt với điều kiện lùi của gradient descent. Ghi chú: Để biết thêm chi tiết về backtracking của gradient descent, tham khảo 06-02-02 backtracking line search % multilang post url contents/chapter06/21-03-20-06 02 02 backtracking line search % . Thuật toán tìm kiếm đường thẳng lùi Nếu chúng ta tóm tắt điều này trong một thuật toán, nó như sau. Tuy nhiên, MATH 1. Khởi tạo các tham số. MATH , MATH 2. Trong mỗi lần lặp, khởi tạo MATH . MATH 3. Nếu điều kiện MATH được thỏa mãn, giảm MATH . Lặp lại bước 3 trong khi điều kiện này được thỏa mãn. 4. Thực hiện cập nhật gradient descent MATH . 5. Nếu điều kiện dừng không được thỏa mãn, quay lại bước 2. Khi lùi trong gradient gần kề, vì MATH được tính toán lặp đi lặp lại, ánh xạ gần kề được bao gồm trong MATH cũng được tính toán lặp đi lặp lại. Vì ánh xạ gần kề rất tốn kém để tính toán, chi phí tính toán tổng thể của backtracking có thể cao. Định lý hội tụ Dưới các giả định tương tự như trên, phương pháp tìm kiếm đường thẳng lùi cũng thỏa mãn hiệu suất tương tự. > Phương pháp gradient gần kề thỏa mãn phương trình sau cho tìm kiếm đường thẳng lùi. Kích thước bước là MATH . > MATH f x^ k −f^ \\star ≤ \\frac \\lVert x^ 0 − x^ \\star \\rVert 2 ^ 2 2 t min k , \\space t \\text min = \\text min \\ 1, \\beta / L \\ \\\\ MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter09/09_02_convergence_analysis/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter09/09_03_example_matrix_completion",
    "title": "09-03 Ví dụ: hoàn thiện ma trận",
    "chapter": "09",
    "order": 4,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Ví dụ: hoàn thiện ma trận Matrix completion Trong nhiều ứng dụng, dữ liệu đo được thường được biểu diễn dưới dạng ma trận. Trong những trường hợp này, hầu hết các phần tử trong ma trận có thể trống, chỉ có một vài phần tử chứa dữ liệu quan sát được, dẫn đến một ma trận thưa. Thách thức điền vào các phần tử bị thiếu trong ma trận như vậy được gọi là bài toán hoàn thiện ma trận . Ví dụ, vấn đề này có thể xảy ra trong các hệ thống gợi ý khi đề xuất sản phẩm hoặc dịch vụ cho khách hàng chưa từng mua hàng. Bài toán hoàn thiện ma trận Bài toán hoàn thiện ma trận có thể được phát biểu như sau: Gọi ma trận MATH biểu diễn dữ liệu quan sát được, và MATH ký hiệu các phần tử chứa dữ liệu quan sát được. Ma trận MATH là ma trận ước lượng được sử dụng để dự đoán các phần tử bị thiếu. > MATH Số hạng đầu tiên trong hàm mục tiêu nhằm tối thiểu hóa lỗi giữa ma trận MATH và dữ liệu quan sát được, trong khi số hạng thứ hai khuyến khích ma trận MATH có hạng thấp. Giả định rằng ma trận B nằm trên một đa tạp chiều thấp. Do đó, ma trận MATH điền vào các phần tử bị thiếu với các giá trị chiều thấp nhất phù hợp với dữ liệu quan sát được. Tham khảo Chuẩn vết Trace Norm Chuẩn vết của một ma trận được định nghĩa là tổng các giá trị kỳ dị của nó. > MATH Ở đây, MATH là nửa xác định dương, và các giá trị kỳ dị được sắp xếp theo thứ tự MATH . Tham khảo Bộ chính quy hóa chuẩn L1 so với Bộ chính quy hóa chuẩn vết Bài toán này có thể được hiểu như ngưỡng mềm ma trận, trong đó vector trong ngưỡng mềm ban đầu được thay thế bằng ma trận. Trong số hạng chính quy hóa, bộ chính quy hóa chuẩn L1 cho vector MATH được thay thế bằng bộ chính quy hóa chuẩn vết MATH cho ma trận, và thực sự, chức năng của hai bộ chính quy hóa này là tương tự. Bộ chính quy hóa chuẩn L1 tạo ra tính thưa trong vector, trong khi bộ chính quy hóa chuẩn vết tương tự tạo ra tính thưa trong vector giá trị kỳ dị của ma trận. Khi ma trận là đường chéo, các phần tử đường chéo có thể được xem như vector giá trị kỳ dị, và bộ chính quy hóa chuẩn vết tối thiểu hóa tổng các giá trị kỳ dị, thúc đẩy tính thưa trong vector giá trị kỳ dị. Trong bối cảnh này, chuẩn vết MATH đóng vai trò như một xấp xỉ cho MATH . Phương pháp gradient gần kề Khi bài toán này được đóng khung bằng toán tử chiếu, phương pháp gradient gần kề có thể được sử dụng hiệu quả. Toán tử chiếu Hãy định nghĩa toán tử chiếu MATH cho các giá trị quan sát được như sau: > MATH P \\Omega B ij = > \\begin cases B ij , & i,j ∈ \\Omega \\\\\\ 0, & i,j \\notin \\Omega > \\end cases MATH Hàm mục tiêu Sử dụng toán tử chiếu, hàm mục tiêu được định nghĩa là: > MATH Bây giờ, hàm MATH bao gồm một phần khả vi MATH và một phần không khả vi MATH . Ánh xạ gần kề Để áp dụng phương pháp gradient gần kề, chúng ta cần tính gradient của hàm MATH và định nghĩa ánh xạ gần kề. Gradient của MATH : MATH Ánh xạ gần kề: > MATH \\begin align \\text prox t B = \\underset Z \\text argmin \\frac 1 2t \\Vert B−Z \\Vert F^2 + \\lambda \\Vert Z \\Vert tr \\end align MATH SVD ma trận & Ngưỡng mềm Ánh xạ gần kề tương ứng với ngưỡng mềm ma trận ở mức MATH : MATH . Thông thường, ma trận MATH có kích thước lớn, vì vậy Phân tích Giá trị Kỳ dị SVD được sử dụng để tối thiểu hóa tải tính toán. Nếu chúng ta thực hiện SVD sao cho MATH , thì MATH có thể được định nghĩa là: > MATH Ở đây, MATH là một ma trận đường chéo được định nghĩa như sau: > MATH Reference MATH inducement How is this expression derived? Assuming MATH , we have: Differentiating the right-hand side of MATH with respect to Z yields the following result. > MATH Rearranging this expression gives: > MATH \\begin align Z & = B - \\lambda t \\cdot \\partial \\lVert Z \\rVert tr \\\\ & = U \\Sigma V^T - \\lambda t \\cdot UV^T + W \\\\ & = U \\Sigma - \\lambda t V^T - \\lambda t W \\\\ & = U \\Sigma - \\lambda V^T \\\\ \\end align MATH The final expression can be obtained when the Lipschitz constant is MATH and MATH is 0. Thus, we have MATH , leading to the derivation of the following expression: > MATH Reference Derivative of Trace Norm If MATH , the derivative of the trace norm is given by: > MATH Here, MATH represents the operator norm, with the largest singular value being less than 1. Additionally, MATH is orthogonal to both MATH and MATH . For proof, refer to Derivative of the nuclear norm with respect to its argument https://math.stackexchange.com/questions/701062/derivative-of-the-nuclear-norm-with-respect-to-its-argument Proximal gradient update Now, let's define the proximal gradient update equation. > MATH When MATH , MATH is Lipschitz continuous, allowing us to choose a fixed step size of MATH . Consequently, the update equation simplifies to: > MATH Ở đây, MATH biểu diễn phép chiếu lên các giá trị không quan sát được, thỏa mãn phương trình MATH . Trong phương trình này, MATH biểu thị phần quan sát được, trong khi MATH biểu thị phần bị thiếu. Hàm MATH rất đơn giản để tính toán, vì nó chỉ yêu cầu thực hiện SVD và tính toán MATH . Thuật toán Soft-Impute Thuật toán này được biết đến với tên Soft-Impute và cung cấp một giải pháp đơn giản nhưng hiệu quả cho bài toán hoàn thiện ma trận. Khi xử lý các ma trận lớn, chi phí tính toán của SVD có thể cao. Tuy nhiên, do tính thưa của MATH và hạng thấp của MATH trong thuật toán này, SVD có thể được thực hiện một cách hiệu quả. Để biết thêm thông tin chi tiết, vui lòng tham khảo bài báo: Mazumder et al. 2011 , \"Spectral regularization algorithms for learning large incomplete matrices\"",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter09/09_03_example_matrix_completion/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter09/09_04_special_cases",
    "title": "09-04 Các trường hợp đặc biệt",
    "chapter": "09",
    "order": 5,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Các trường hợp đặc biệt Phương pháp gradient gần kề cũng được gọi là gradient descent tổng hợp hoặc gradient descent tổng quát. Tại sao nó được gọi là \"tổng quát\" ? Lý do là phương pháp gradient gần kề bao gồm tất cả các trường hợp đặc biệt sau: - MATH gradient descent - MATH projected gradient descent - MATH thuật toán tối ưu gần kề Do đó, tất cả các thuật toán này đều có tốc độ hội tụ MATH . Projected gradient descent Khi MATH là hàm chỉ thị của một tập lồi đóng MATH , bài toán tối thiểu hóa MATH trên tập MATH có thể được đổi dạng như sau. Lưu ý: MATH phải là một tập đóng để phép chiếu được định nghĩa rõ ràng. > MATH > > MATH I C x = >\\begin cases >0, & x \\in C \\\\ >\\infty, & x \\notin C >\\end cases MATH Lúc này, ánh xạ gần kề được định nghĩa như sau. > MATH >\\begin align >\\text prox t x >&= \\underset z \\text argmin \\frac 1 2t \\lVert x−z \\rVert 2^2 + I C z \\\\ >& = \\underset z \\in C \\text argmin \\lVert x−z \\rVert 2^2 >\\end align MATH Kết quả là, ánh xạ gần kề MATH là toán tử chiếu lên MATH . Bước cập nhật gradient gần kề là: MATH . Nói cách khác, sau khi thực hiện cập nhật gradient descent, bạn chiếu lên MATH . Trong hình dưới đây, hình chữ nhật màu hồng là tập khả thi MATH , và vị trí hiện tại là điểm trên của hai điểm dưới hình chữ nhật. Sau khi thực hiện một bước gradient descent, bạn di chuyển ra ngoài MATH , vì vậy bạn chiếu ngược lại lên MATH để trở về bên trong tập khả thi. Hình 1 Projected Gradient Descent 3 Thuật toán tối ưu gần kề Xem xét bài toán tối thiểu hóa một hàm lồi MATH như sau. Ở đây, MATH không cần khả vi và MATH . > \\begin align \\min x h x \\end align Ánh xạ gần kề được định nghĩa là: > MATH \\begin align x^ k &= \\text prox t k \\big x^ k-1 - t k \\nabla g x^ k-1 \\big , \\qquad k = 1, 2, 3, ... \\\\ &= \\text prox t k \\big x^ k-1 \\big , \\qquad \\qquad \\qquad \\qquad \\; k = 1, 2, 3, ... \\\\ \\end align MATH Do đó, bước cập nhật gradient gần kề là: > MATH Phương pháp gradient gần kề này, chỉ được định nghĩa bởi MATH với MATH , được gọi là thuật toán tối ưu gần kề PMA . Phương pháp này nhanh hơn các phương pháp subgradient, nhưng nếu ánh xạ gần kề không có dạng đóng, nó không thể được triển khai. Điều gì xảy ra nếu chúng ta không thể tính prox? Về mặt lý thuyết, khi áp dụng gradient gần kề cho MATH , giả định rằng hàm prox có thể được tính toán chính xác. Tức là, giả định rằng điểm cực tiểu có thể được tìm thấy chính xác thông qua ánh xạ gần kề. > MATH Nói chung, không rõ điều gì xảy ra nếu điểm cực tiểu chỉ được xấp xỉ. Tuy nhiên, nếu lỗi trong việc xấp xỉ toán tử prox có thể được kiểm soát chính xác, đã được chứng minh rằng tốc độ hội tụ ban đầu có thể được duy trì. Schmidt et al. 2011 , Convergence rates of inexact proximal-gradient methods for convex optimization Trong thực tế, nếu prox có thể được tính toán xấp xỉ, nó sẽ được thực hiện với độ chính xác cao.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter09/09_04_special_cases/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter09/09_05_acceleration",
    "title": "09-05 Tăng tốc",
    "chapter": "09",
    "order": 6,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Tăng tốc Các kỹ thuật tăng tốc được sử dụng để tăng tốc sự hội tụ của các thuật toán tối ưu. Trong bối cảnh của các phương pháp gradient gần kề, tăng tốc có thể cải thiện đáng kể tốc độ tìm ra giải pháp. Tăng tốc của Nesterov Tăng tốc của Nesterov là một kỹ thuật phổ biến giới thiệu động lượng vào các bước cập nhật, cho phép thuật toán di chuyển nhanh hơn về phía điểm tối ưu. FISTA FISTA Thuật toán Ngưỡng-Co lặp Nhanh là một phương pháp gradient gần kề tăng tốc đạt được tốc độ hội tụ MATH . Cân nhắc thực tế Mặc dù tăng tốc có thể cải thiện hội tụ, nó cũng có thể gây ra mất ổn định hoặc dao động trong một số trường hợp. Quan trọng là giám sát hành vi của thuật toán và điều chỉnh các tham số khi cần thiết.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter09/09_05_acceleration/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter09/09_05_01_accelerated_proximal_gradient_method",
    "title": "09-05-01 Phương pháp gradient gần kề tăng tốc",
    "chapter": "09",
    "order": 7,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Phương pháp gradient gần kề tăng tốc Nếu phương pháp gradient gần kề được tăng tốc, nó có thể đạt được tốc độ hội tụ tối ưu MATH . Nesterov đã đề xuất bốn phương pháp, trong đó ba phương pháp là các phương pháp tăng tốc: - 1983: Phương pháp tăng tốc ban đầu cho các hàm trơn - 1988: Một phương pháp tăng tốc khác cho các hàm trơn - 2005: Kỹ thuật làm trơn các hàm không trơn cùng với phương pháp tăng tốc ban đầu - 2007: Phương pháp tăng tốc cho các hàm tổng hợp Bây giờ, hãy xem xét phương pháp của Beck và Teboulle 2008 , mở rộng phương pháp của Nesterov 1983 cho các hàm tổng hợp. Phương pháp gradient gần kề tăng tốc Như trước, giả sử MATH là hàm lồi và khả vi, và MATH là hàm lồi. Bài toán được định nghĩa là: > \\begin align \\min x g x + h x \\end align Phương pháp gradient gần kề tăng tốc xem xét hướng mà MATH đang di chuyển để hướng không thay đổi đột ngột khi di chuyển đến vị trí tiếp theo. Nói cách khác, nó tạo động lượng cho hướng tiến triển, tạo quán tính để tiếp tục di chuyển theo cùng hướng như trước. Giá trị ban đầu của thuật toán được đặt là MATH . Sau đó, sau khi tính toán vị trí MATH xem xét động lượng, gradient gần kề được thực hiện. > MATH \\begin align v & = x^ k-1 + \\frac k-2 k + 1 x^ k-1 −x^ k-2 \\\\ x^ k & = \\text prox t k v − t k \\nabla g v , k = 1,2,3,... \\\\ \\end align MATH - Trong bước đầu tiên MATH , MATH bằng không, vì vậy nó giống như cập nhật gradient gần kề. - Trong các bước tiếp theo, MATH có động lượng theo hướng trước đó MATH . Khi MATH tăng, trọng số động lượng tăng và hội tụ về 1. - Khi MATH , điều này giống như phương pháp gradient tăng tốc . Hình dưới đây cho thấy cách trọng số động lượng thay đổi khi MATH thay đổi. Trong hình này, giá trị âm khi k = 0, nhưng vì số hạng động lượng bằng không vào thời điểm đó, nên nó không gây ra vấn đề gì. Khi k tăng, trọng số tiến gần 1, vì vậy giá trị được cập nhật nhiều hơn và giúp hội tụ nhanh hơn. Hình 1 Trọng số động lượng 3 Ví dụ Lasso Nếu chúng ta áp dụng gradient gần kề tăng tốc cho ví dụ Lasso đã thấy trước đó, chúng ta sẽ nhận được kết quả như được hiển thị trong hình dưới đây. Có thể thấy rằng gradient gần kề tăng tốc có hiệu suất nhanh hơn nhiều so với các phương pháp subgradient hoặc gradient gần kề. Có một phần ở giữa đồ thị nhảy lên, được gọi là \"gợn sóng Nesterov\". Do đó, gradient gần kề tăng tốc không giảm đơn điệu và không phải là phương pháp giảm. Hình 2 Gradient Gần kề Tăng tốc 3",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter09/09_05_01_accelerated_proximal_gradient_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter09/09_05_02_convergence_analysis",
    "title": "09-05-02 Phân tích hội tụ",
    "chapter": "09",
    "order": 8,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Phân tích hội tụ Trong phần này, chúng ta phân tích sự hội tụ của phương pháp gradient gần kề tăng tốc. Định lý hội tụ Giả sử MATH là hàm lồi và khả vi, MATH là hàm lồi, và MATH liên tục Lipschitz với hằng số MATH . Khi đó, phương pháp gradient gần kề tăng tốc với kích thước bước cố định MATH thỏa mãn: > MATH Điều này có nghĩa là tốc độ hội tụ là MATH , nhanh hơn phương pháp gradient gần kề tiêu chuẩn. Tìm kiếm đường thẳng lùi Tìm kiếm đường thẳng lùi cho phương pháp gradient gần kề tăng tốc tương tự như đối với phương pháp gradient gần kề tiêu chuẩn, nhưng kích thước bước được chọn một cách thích ứng. Để biết thêm chi tiết, tham khảo Beck và Teboulle 2009 , \"A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems\" FISTA .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter09/09_05_02_convergence_analysis/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter09/09_05_03_example_FISTA",
    "title": "09-05-03 Ví dụ: FISTA",
    "chapter": "09",
    "order": 9,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Ví dụ: FISTA Trong phần này, chúng ta giới thiệu một ví dụ về Thuật toán Ngưỡng-Co lặp Nhanh FISTA , đây là một phương pháp gradient gần kề tăng tốc. Thuật toán FISTA Thuật toán FISTA giải quyết các bài toán có dạng: > MATH trong đó MATH là hàm lồi và khả vi, và MATH là hàm lồi. Các bước cập nhật là: 1. Khởi tạo MATH , MATH . 2. Với MATH : - MATH - MATH - MATH Ứng dụng cho Lasso FISTA có thể được áp dụng cho hồi quy Lasso, bao gồm việc tối thiểu hóa hàm mất mát bình phương tối thiểu với số hạng chính quy hóa MATH . FISTA đạt được hội tụ nhanh hơn so với các phương pháp gradient gần kề tiêu chuẩn.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter09/09_05_03_example_FISTA/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter09/09_05_04_is_acceleration_always_useful",
    "title": "09-05-04 Tăng tốc có luôn hữu ích không?",
    "chapter": "09",
    "order": 10,
    "owner": "Kyeongmin Woo",
    "lesson_type": "",
    "content": "Tăng tốc có luôn hữu ích không? Các phương pháp tăng tốc như FISTA có thể đạt được tốc độ hội tụ nhanh hơn về mặt lý thuyết, nhưng trong thực tế, tăng tốc không luôn có lợi. Khi nào tăng tốc có thể không giúp được - Nếu bài toán có điều kiện xấu, tăng tốc có thể gây dao động hoặc mất ổn định. - Đối với một số bài toán không trơn, tăng tốc có thể không cải thiện hội tụ. - Hiện tượng \"gợn sóng Nesterov\" có thể gây ra hành vi không đơn điệu trong giá trị hàm mục tiêu. Lời khuyên thực tế - Sử dụng các phương pháp tăng tốc khi bài toán có điều kiện tốt và trơn. - Giám sát hội tụ và ổn định khi áp dụng tăng tốc. - Nếu xảy ra mất ổn định, hãy xem xét chuyển sang các phương pháp gradient gần kề tiêu chuẩn.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter09/09_05_04_is_acceleration_always_useful/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter10/10_Duality_in_Linear_Programs",
    "title": "10 Duality in Linear Programs",
    "chapter": "10",
    "order": 1,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Starting from this chapter, we will examine duality, which plays a significant role in optimization theory. From an optimization perspective, duality can be simply described as the concept that a single optimization problem can be viewed from two perspectives: the primal problem and the dual problem. In this chapter, we specifically explore duality in linear programs. Rather than directly applying it to general convex problems, we will derive the dual problem from the primal problem by applying it to linear programs, and organize how the relationship between these two problems is established and what properties they have under specific conditions.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter10/10_Duality_in_Linear_Programs/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter10/10_01_Lower_Bounds_in_Linear_Programs",
    "title": "10-01 Cận dưới trong Chương trình Tuyến tính",
    "chapter": "10",
    "order": 2,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Ví dụ 1: Dạng mà ràng buộc chứa hàm mục tiêu Giả sử chúng ta muốn tìm giá trị cận dưới B của giá trị tối ưu cho một bài toán lồi cho trước. > MATH >\\begin align >B \\leq \\min x f x . >\\end align > MATH Hãy xét cụ thể cận dưới của các chương trình tuyến tính. Chúng ta sẽ xem xét các trường hợp từ đơn giản đến dạng tổng quát theo thứ tự. Đầu tiên, lấy dạng đơn giản nhất của bài toán LP làm ví dụ > MATH >\\begin align >&\\min x, y >& & x+y \\\\\\\\ >&\\text với điều kiện >& & x + y \\geq 2 \\\\\\\\ >& & & x, y \\geq 0. \\\\\\\\ >\\end align > MATH Bài toán trên đã bao gồm cận dưới của hàm mục tiêu trong ràng buộc, vì vậy chúng ta có thể dễ dàng thấy rằng MATH . Hơn nữa, hãy xem xét trường hợp mà ràng buộc không bao gồm cận dưới. Ví dụ 2: Dạng mà hàm mục tiêu có thể được biểu diễn như tổ hợp tuyến tính của các ràng buộc 1 > MATH >\\begin align >&\\min x, y >& & x+3y \\\\\\\\ >&\\text với điều kiện >& & x + y \\geq 2 \\\\\\\\ >& & & x, y \\geq 0. \\\\\\\\ >\\end align > MATH Nếu MATH là khả thi, thì việc nhân ba ràng buộc với các giá trị vô hướng và cộng hoặc trừ chúng vẫn thỏa mãn cả ba ràng buộc. Do đó, đối với bài toán LP như vậy, quá trình nhân các ràng buộc với các giá trị vô hướng và cộng hoặc trừ chúng, tức là biểu diễn hàm mục tiêu như tổ hợp tuyến tính của các ràng buộc, là có thể, và kết quả là chúng ta có thể tìm MATH . > MATH >\\begin align >& & x + y \\geq 2 \\\\\\\\ >& + & 0x \\geq 0 \\\\\\\\ >& + & 2y \\geq 0 \\\\\\\\ >& = & x + 3y \\geq 2 \\\\\\\\ > >& & \\text Cận dưới \\ B = 2. >\\end align > MATH Tổng quát hóa hơn nữa bằng cách áp dụng các biến tùy ý để biểu diễn hàm mục tiêu, chúng ta có được như sau: > MATH >\\begin align >&\\min x, y >& & px+qy \\\\\\\\ >&\\text với điều kiện >& & x + y \\geq 2 \\\\\\\\ >& & & x, y \\geq 0. \\\\\\\\ >\\end align > MATH Tương tự như ví dụ thứ hai, bằng cách nhân các ràng buộc với các giá trị vô hướng a, b, c tương ứng, hàm mục tiêu có thể được biểu diễn như tổ hợp tuyến tính của ba ràng buộc này. > MATH >\\begin align >& & a x+y \\geq 2a \\\\\\\\ >& + & bx \\geq 0 \\\\\\\\ >& + & cy \\geq 0 \\\\\\\\ >& = & a+b x+ a+c y \\geq 2a \\\\\\\\ >&&\\text Cận dưới \\ B=2a, \\\\ >&&\\text với bất kỳ a,b,c thỏa mãn điều kiện dưới đây \\\\\\\\ >& & a + b = p \\\\\\\\ >& & a + c = q \\\\\\\\ >& & a,b,c \\geq 0. \\\\\\\\ >\\end align > MATH Để cận dưới thỏa mãn là 2a như trên, vì dấu bất đẳng thức sẽ bị đảo ngược trong quá trình nhân với các giá trị vô hướng và điều này sẽ không thỏa mãn, các điều kiện MATH phải dương và tổng các giá trị vô hướng phải bằng hàm mục tiêu, tức là các điều kiện MATH và MATH phải được thỏa mãn. Một bài toán tối ưu mới có thể được định nghĩa bằng cách tối đa hóa kết quả cận dưới thu được như trên. Trong trường hợp này, các điều kiện thỏa mãn cận dưới trở thành các ràng buộc trong bài toán này. > MATH >\\begin align >&\\max a, b, c >& & 2a \\\\\\\\ >&\\text với điều kiện >& & a + b = p \\\\\\\\ >& & & a + c = q \\\\\\\\ >& & & a, b, c \\geq 0 \\\\\\\\ >\\end align > MATH Bài toán LP ban đầu ở trên được gọi là LP nguyên thủy, và dạng định nghĩa lại bài toán tối ưu bằng cách tối đa hóa cận dưới trong LP nguyên thủy được gọi là LP đối ngẫu. Lưu ý rằng số lượng biến tối ưu trong bài toán đối ngẫu bằng số lượng ràng buộc trong bài toán nguyên thủy. > MATH >\\begin align >\\text LP Nguyên thủy \\qquad >&\\qquad \\min x, y & px+qy \\\\\\\\ >&\\qquad \\text với điều kiện & x + y \\geq 2 \\\\\\\\ >&\\qquad & x, y \\geq 0 \\\\\\\\ >\\\\\\\\ >\\\\\\\\ >\\text LP Đối ngẫu \\qquad >&\\qquad \\max a, b, c & 2a \\\\\\\\ >&\\qquad \\text với điều kiện & a + b = p \\\\\\\\ >&\\qquad & a + c = q \\\\\\\\ >&\\qquad & a, b, c \\geq 0 \\\\\\\\ >\\end align > MATH Ví dụ 3: Dạng mà hàm mục tiêu có thể được biểu diễn như tổ hợp tuyến tính của các ràng buộc 2 Như một ví dụ cuối cùng, hãy xem xét một dạng mà các dấu bất đẳng thức trong ràng buộc bị đảo ngược và bao gồm các ràng buộc đẳng thức. > MATH >\\begin align >&\\min x, y & px+qy \\\\\\\\ >&\\text với điều kiện & x \\geq 0 \\\\\\\\ >& & y \\leq 1 \\\\\\\\ >& & 3x + y = 2 \\\\\\\\ >\\\\\\\\ >& & ax \\geq 0 \\\\\\\\ >& + & -by \\geq -b \\\\\\\\ >& + & 3cx + cy = 2c \\\\\\\\ >& = & a+3c x+ -b+c y \\geq 2c-b >\\\\\\\\ >\\\\\\\\ >&& \\text Cận dưới \\ B=2c-b, \\\\ >&& \\text với bất kỳ a,b,c thỏa mãn điều kiện dưới đây \\\\\\\\ >& & a + 3c = p \\\\\\\\ >& & -b + c = q \\\\\\\\ >& & a,b \\geq 0 \\\\\\\\ >\\end align > MATH Ở đây, c là giá trị vô hướng được nhân với cả hai vế của đẳng thức, vì vậy bất kỳ giá trị nào cũng có thể được nhân mà không có hạn chế. Do đó, LP đối ngẫu có thể được định nghĩa như sau. > MATH >\\begin align >&\\qquad \\max a, b, c & 2c-b \\\\\\\\ >&\\qquad \\text với điều kiện & a + 3c = p \\\\\\\\ >&\\qquad & -b + c = q \\\\\\\\ >&\\qquad & a, b \\geq 0 \\\\\\\\ >\\end align > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter10/10_01_Lower_Bounds_in_Linear_Programs/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter10/10_02_Duality_in_general_LPs",
    "title": "10-02 Tính đối ngẫu trong LP tổng quát",
    "chapter": "10",
    "order": 3,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Trong 10-01 % multilang post url contents/chapter10/21-03-22-10 01 Lower Bounds in Linear Programs % , chúng ta đã xem xét nguyên thủy và đối ngẫu của các bài toán LP với các biến một chiều. Trong 10-02, chúng ta muốn xem xét đối ngẫu cho LP ở dạng tổng quát. Dạng tổng quát của LP như sau: Cho MATH , > MATH >\\begin align >&\\min x &&c^ T x\\\\\\\\ >&\\text với điều kiện &&Ax = b\\\\\\\\ >& &&Gx \\leq h.\\\\\\\\ >\\end align > MATH Tương tự như ví dụ trong 10-01, chúng ta định nghĩa các biến đối ngẫu MATH có số lượng bằng số lượng ràng buộc, và có thể định nghĩa hàm mục tiêu của bài toán đối ngẫu và các ràng buộc như tổng của các tích của ràng buộc và mỗi biến đối ngẫu. > MATH >\\begin align >& &u^ T Ax-b = 0\\\\\\\\ >& + &v^ T Gx-h \\leq 0\\\\\\\\ >& = &u^ T Ax-b + v^ T Gx-h \\leq 0.\\\\\\\\ >\\end align > MATH Nhớ rằng biến đối ngẫu MATH cho đẳng thức không có ràng buộc, trong khi MATH là biến đối ngẫu cho bất đẳng thức và do đó có ràng buộc bổ sung là phải dương. Bằng cách sắp xếp phương trình cuối để biểu diễn hàm mục tiêu của LP nguyên thủy, chúng ta có được LP đối ngẫu. > MATH >\\begin align >u^ T Ax-b + v^ T Gx-h \\leq 0 \\\\\\\\ >\\underbrace -A^ T u-G^ T v ^ T =c^ T x\\geq-b^ T u-h^ T v \\\\\\\\ >\\text Cận dưới là -b^ T u-h^ T v \\\\\\\\ >\\text với x \\text khả thi nguyên thủy, và bất kỳ u, v thỏa mãn, \\\\\\\\ >c = -A^ T u-G^ T v \\\\\\\\ >v\\geq 0. \\\\\\\\ >\\end align > MATH Tức là, khi MATH , giá trị tối ưu của nguyên thủy có cận dưới là MATH . Do đó, LP đối ngẫu có thể được định nghĩa như sau. > MATH >\\begin align >&\\max u,v &&-b^ T u-h^ T v \\\\\\\\ >&\\text với điều kiện &&c = -A^ T u-G^ T v \\\\\\\\ >& &&v\\geq 0. >\\end align > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter10/10_02_Duality_in_general_LPs/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter10/10_03_Max_flow_and_min_cut",
    "title": "10-03 Luồng cực đại và cắt cực tiểu",
    "chapter": "10",
    "order": 4,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Như một ví dụ về tính đối ngẫu trong chương trình tuyến tính, chúng ta muốn xem xét bài toán luồng cực đại cắt cực tiểu. Đồ thị có hướng, Điều kiện của luồng Hình 1 Đồ thị có hướng 3 Có một đồ thị có hướng MATH như được hiển thị ở trên, và đặt cạnh nối đỉnh i và đỉnh j, MATH , tức là luồng từ i đến j, là MATH . Mỗi cạnh có một công suất, tức là luồng tối đa có thể chảy qua nó. Đặt đây là MATH . Như một ví dụ đơn giản, điều này có thể được hiểu như một biểu diễn đồ thị của một luồng nào đó từ một nguồn s chảy ra đến một đích t . Đây là một dạng đồ thị có thể được áp dụng cho nhiều bài toán khác nhau như quy hoạch thoát nước đô thị/truyền tải điện, vận chuyển vật liệu, v.v. Ở đây, luồng thỏa mãn ba điều kiện. 1. MATH luôn là một số dương lớn hơn hoặc bằng 0: MATH 2. MATH phải nhỏ hơn luồng tối đa được xác định cho cạnh, tức là công suất giới hạn công suất MATH : MATH >\\begin align >\\text Giá trị luồng cực đại &\\leq \\text LP đối ngẫu của luồng cực đại \\\\ >&= \\text Giá trị tối ưu cho cắt cực tiểu nới lỏng LP \\\\ >&\\leq \\text Công suất của cắt cực tiểu \\\\ >\\end align > MATH Trong trang này, chúng ta sẽ chỉ ra mối quan hệ bất đẳng thức bằng quá trình ngược của đối ngẫu và nới lỏng thêm ràng buộc vào bài toán LP để chuyển đổi nó thành chương trình nguyên . Mặc dù không được đề cập ở đây, trên thực tế, cả ba kết quả đều bằng nhau. Điều này được gọi là định lý luồng cực đại cắt cực tiểu, nói rằng luồng tối đa trong một mạng bằng công suất tối thiểu của một cắt. Tổng quát hơn, dưới một số điều kiện nhất định, các giá trị tối ưu của các bài toán nguyên thủy và đối ngẫu bằng nhau, điều này được gọi là tính đối ngẫu mạnh. Trong các bài toán LP, ngoại trừ trường hợp mà cả bài toán nguyên thủy và đối ngẫu đều không khả thi, tính đối ngẫu mạnh được giữ. Điều này sẽ được thảo luận trong Chương 11. Đầu tiên, hãy xem xét hai bài toán, suy ra đối ngẫu từ bài toán luồng cực đại, và chỉ ra rằng bằng cách thêm các điều kiện cụ thể vào bài toán đối ngẫu ngược lại của nới lỏng , nó biến đổi thành bài toán cắt cực tiểu. Bài toán luồng cực đại Bài toán luồng cực đại là tìm luồng tối đa từ s đến t trong một đồ thị thỏa mãn các điều kiện trên. > MATH >\\begin align >&\\max f\\in \\mathbb R ^ |E| && \\sum s,j \\in E f sj \\\\ >&\\text với điều kiện && f ij \\geq 0,\\,f ij \\leq c i,j \\,\\, \\text với mọi i, j \\in E \\\\ >&&& \\sum i, k \\in E f ik =\\sum k,j \\in E f kj \\,\\, \\text với mọi k\\in V \\backslash \\ s,t\\ .\\\\ >\\end align > MATH Bài toán cắt cực tiểu Hình 2 Ví dụ Cắt Đồ thị 3 Bài toán cắt cực tiểu chia tất cả các đỉnh của đồ thị thành hai tập hợp: vùng có bóng và vùng không có bóng, như được hiển thị trong hình. Một tập hợp chứa nguồn, và tập hợp khác chứa đích, trong khi các đỉnh còn lại được gán tùy ý vào một trong hai tập hợp ở đây, tập hợp chứa nguồn được gọi là A, và tập hợp chứa đích được gọi là B . Tổng các công suất của các cạnh đi từ tập hợp A đến tập hợp B được định nghĩa là cắt. Nói cách khác, một cắt là một phân hoạch các đỉnh của đồ thị sao cho nguồn và đích ở các phân hoạch khác nhau. Bài toán cắt cực tiểu là tìm giá trị tối thiểu của cắt này cho một đồ thị cho trước. Trong định nghĩa tổng quát của bài toán cắt cực tiểu, vì nó được định nghĩa trên một đồ thị có hướng, nó luôn thỏa mãn nguồn MATH , đích MATH . Phần này được bỏ qua trong định nghĩa bài toán dưới đây. > MATH >\\begin align >&\\min b\\in \\mathbb R ^ |E| ,\\, x \\in \\mathbb R ^ |V| && \\sum i,j \\in E b ij c ij \\\\ >&\\text với điều kiện && b ij \\geq x i -x j \\\\ >&&& b ij ,\\,x i ,\\,x j \\,\\in \\ 0,1 \\ \\\\ >&&&\\text với mọi i, j.\\\\ >\\end align > MATH Trực quan, bài toán luồng cực đại là tìm luồng tối đa từ nguồn, và bài toán cắt cực tiểu là tìm tổng công suất tối thiểu có thể được gửi từ tập nguồn đến tập đích, vì vậy rõ ràng rằng hai bài toán này có liên quan chặt chẽ. Đối ngẫu của bài toán Luồng cực đại Hãy suy ra đối ngẫu cho bài toán tối ưu luồng cực đại. Đầu tiên, định nghĩa các biến đối ngẫu cho các ràng buộc theo thứ tự là MATH . Trong đối ngẫu của bài toán max, cận trên sẽ được tối thiểu hóa, vì vậy dạng được tổ chức phải ở dạng mục tiêu nguyên thủy MATH một cái gì đó. Do đó, tổ chức phương trình để tìm cận trên của MATH cho các ràng buộc. Điều này có thể được tổ chức như sau. > MATH >\\begin align >\\sum i,j \\in E \\Big -a ij f ij +b ij f ij -c ij \\Big + \\sum k \\in V\\backslash \\ s,t\\ x k \\Big \\sum i,k \\in E f ik - \\sum k,j \\in E f kj \\Big \\leq 0\\\\ >\\text với bất kỳ a ij , b ij \\geq 0, i, j \\in E, \\text và x k , k\\in V \\backslash \\ s,t\\ . >\\end align > MATH Tổ chức các số hạng MATH liên quan đến hàm mục tiêu LP nguyên thủy ở bên trái, và phần còn lại ở bên phải. Tiếp theo, vì chúng ta muốn cận trên của LP nguyên thủy, tìm phương trình sao cho các số hạng được nhân với MATH ở bên trái khớp với hàm mục tiêu LP nguyên thủy. Điều kiện thỏa mãn phương trình này trở thành ràng buộc trong LP đối ngẫu. Tức là, tổ chức phương trình sao cho số hạng MATH chỉ là 1 trong MATH và 0 ở nơi khác. This process is detailed as follows. > MATH >\\begin align >\\sum i,j \\in E \\Big b ij -a ij f ij \\Big +\\sum k\\in V\\backslash \\ s,t\\ x k \\Big \\sum i,k \\in E f ik -\\sum k,j \\in E f kj \\Big \\leq \\sum i,j \\in E b ij c ij . >\\end align > MATH Here, our goal is to make the result of the left side when MATH be MATH and 0 for other cases. The k in the x term of the second sigma does not include the source and sink, and can be divided into three cases: when MATH , when MATH , and when MATH . Case 1. MATH For the term multiplied by MATH , it is eliminated by the third condition of flow except for the case of MATH . Therefore, the sigma for the x term of the second term can be organized as follows. > MATH >\\begin align >&=\\sum s,j \\in E \\Big b sj -a sj f sj \\Big +x j \\sum s,j \\in E f sj +\\sum k\\in V\\backslash \\\\ s,t,j\\\\ x k \\Big \\underbrace \\sum s,k \\in E f sk -\\sum k,j \\in E f kj =0 \\Big \\\\\\\\ >&=\\sum s,j \\in E \\Big b sj -a sj +x j \\Big f sj , \\ j \\in V \\backslash \\ s,t\\ ,\\\\\\\\ >\\end align > MATH Case 2. MATH For the term multiplied by MATH , it is eliminated by the third condition of flow except for the case of MATH . Therefore, the sigma for the x term of the second term can be organized as follows. > MATH >\\begin align >&=\\sum i,t \\in E \\Big b it -a it f it \\Big -x i \\sum i,t \\in E f it +\\sum k\\in V\\backslash \\ s,t,i\\ x k \\Big \\underbrace \\sum i,k \\in E f ik -\\sum k,t \\in E f kt =0 \\Big \\\\\\\\ >&=\\sum i,t \\in E \\Big b it -a it -x i \\Big f it , \\ i \\in V\\backslash \\ s,t\\ ,\\\\\\\\ >\\end align > MATH Case 3. MATH For the term multiplied by MATH , it is eliminated by the third condition of flow except for the cases of MATH and MATH . Therefore, the sigma for the x term of the second term can be organized as follows. > MATH >\\begin align >&=\\sum i,j \\in E \\Big b ij -a ij f ij \\Big +x j \\sum i,j \\in E f ij -x i \\sum i,j \\in E f ij +\\sum k\\in V\\backslash \\ s,t,i,j\\ x k \\Big \\underbrace \\sum i,k \\in E f ik -\\sum k,j \\in E f kj =0 \\Big \\\\\\\\ >&=\\sum i,j \\in E \\Big b ij -a ij +x j -x i \\Big f ij , \\ i, j \\in V \\backslash \\ s,t\\ . \\\\\\\\ >\\end align > MATH The objective function of the primal LP matches with the case 1 of the above, where the term is 1 in MATH , and for the other cases, it makes the multiplied term 0, completing the form of left side being the objective function and the right side being the upper bound. > MATH >\\begin align >&b sj -a sj +x j = 1\\\\\\\\ >&b it -a it -x i = 0\\\\\\\\ >&b ij -a ij +x j -x i = 0\\\\\\\\ >&\\text Result in, \\\\\\\\ >&\\sum s,j \\in E f sj \\leq \\sum i,j \\in E b ij c ij . >\\end align > MATH Therefore, the dual problem is to find the minimum value of the upper bound objective function of dual LP for the dual variables MATH , and this minimum value becomes the best upper bound. A dummy variable MATH is eliminated while maintaining the conditions. Additionally, by adding the condition that flow occurs from source to sink in the directed graph, the equation becomes: > MATH >\\begin align >&\\min b\\in \\mathbb R ^ |E| ,\\, x\\in \\mathbb R ^ |V| && \\sum i,j \\in E b ij c ij \\\\\\\\ >&\\text subject to && b ij +x j -x i \\geq 0 \\,\\, \\text for all i,j \\in E \\\\\\\\ >&&& b\\geq 0, x s =1,x t =0 .\\\\\\\\ >\\end align > MATH Dual LP to Integer program Now, we want to show that this dual LP is the same as the LP relaxation of the min cut problem. Therefore, we will go through the process of converting it to an integer program by adding conditions to the above dual LP problem. The variable MATH is not defined for vertices other than s and t. Therefore, to narrow the scope of the problem, let's add a condition that the remaining vertices except s and t belong to either group s or t. In other words, let's assume that all vertices belong to either group 0 or 1. This is equivalent to determining the vertex partition for the min cut. > MATH >\\begin align >x i \\in \\ 0,1 \\ \\ \\ \\text for all i\\in V. >\\end align > MATH Let's define the group that belongs to 1 as set A, and the group that belongs to 0 as set B. Also, let's define that the source s belongs to A, and the sink t belongs to B. With the above definitions, MATH acts as an on/off switch, being 1 for edges going from set A to set B, and 0 otherwise. This can be organized as follows. > MATH >\\begin align >&\\text Let A= \\ i:x i =1 \\ ,\\, B= \\ i:x i =0 \\ \\\\\\\\ >&\\text note that s \\in A, \\,t \\in B, \\text and b ij \\geq x i -x j \\,\\,\\,\\, \\text for \\, i,j \\in E, \\,\\, b\\geq 0,\\\\\\\\ >\\end align > MATH > MATH >\\begin align >\\text Simply say, \\qquad \\begin cases b ij =1 \\qquad \\text if i\\in A, j\\in B\\\\\\\\ >0 \\qquad\\qquad \\text otherwise .\\end cases >\\end align > MATH The above result is the same as the formulation of the min cut problem. Relationship between Max flow and Min cut problem 2 That is, the dual problem of the max flow problem is the result of removing the condition that the vertices except s and t in the min cut problem are included in 0 or 1 relaxation . The optimal value of max flow MATH dual LP upper bound , and this relaxation expands the domain scope of the optimization variable, so the optimal value LP relaxed min cut MATH capacity of min cut. Summarizing these three results, we get the following result. > MATH >\\begin align >\\text Value of max flow &\\leq \\text Dual LP of max flow \\\\\\\\ >&= \\text Optimal value for LP relaxed min cut \\\\\\\\ >&\\leq \\text Capacity of min cut \\\\\\\\ >\\end align > MATH For the equality of these three results, refer to the max-flow min-cut theorem 11 , and for a representative algorithm for solving the max flow min cut problem, refer to the Ford-Fulkerson algorithm 12 .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter10/10_03_Max_flow_and_min_cut/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter10/10_04_Another_Perspective_on_LP_duality",
    "title": "10-04 Another Perspective on LP duality",
    "chapter": "10",
    "order": 5,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; In the case of duality discussed earlier, for LP, we multiplied the constraints of the primal problem by dual variables, obtained their linear combination, and then organized it to separate out the primal's objective function to obtain a bound. The separated remaining terms something in the formula below served as the bound for the primal problem. That is, they became the objective function of the dual problem, and the conditions created during the formula development process became the constraints of the dual problem. Writing this partial process the part of the above content that separates out the primal objective function to obtain a bound as a formula, it looks like this: > MATH >\\begin align >&\\min x &&f x \\\\\\\\ >&\\text subject to &&Ax = b\\\\\\\\ >& &&Gx \\leq h\\\\\\\\ >\\end align > MATH > MATH >\\begin align >& &\\text for any u,\\, v\\geq 0,\\\\\\\\ >& &u^ T Ax-b = 0\\\\\\\\ >& + &v^ T Gx-h \\leq 0\\\\\\\\ >& = &u^ T Ax-b + v^ T Gx-h \\leq 0\\\\\\\\ >& \\approx &f x +\\text something . \\\\\\\\ >\\end align > MATH However, for optimization problems that are not linear programs, most cannot express the objective function as a linear combination of constraints. In this chapter, we examine the perspective of duality that is applicable to more universally common problems all convex, most non-convex . We will find the duality of LP using this method called Lagrangian, and examine more detailed discussions in Chapter 11. Looking at the equations up to the linear combination form for the primal LP problem described above, we can understand the following relationship: > MATH >\\begin align >c^ T x\\geq c^ T x+\\overbrace u^ T \\underbrace Ax-b =0 +\\underbrace v^ T \\geq 0 \\underbrace Gx-h \\leq 0 ^ \\leq 0 := L x,u,v . >\\end align > MATH The right side of the inequality has a value less than or equal to the left side according to the conditions. Also, we define this expression as a function MATH for x, u, v. Here, if we call the set satisfying the constraints of the primal LP primal feasible set C, we can understand the following relationship: > MATH >\\begin align >C = \\ x: Ax=b, Gx\\leq h \\ , >\\end align > MATH > MATH >\\begin align >f^ =\\min x\\in C f x \\geq \\min x\\in C L x,u,v \\geq \\min x L x,u,v :=g u,v .\\\\\\\\ >\\end align > MATH In other words, MATH becomes a lower bound of MATH for any u or MATH satisfying MATH . Let's examine the lower bound value determined by MATH . > MATH >\\begin align g u,v = min x c^ T x+u^ T Ax-b + v^ T Gx-h \\\\\\\\ = \\min x c+A^ T u+G^ T v ^ T x - b^ T u-h^ T v \\\\\\\\ \\begin cases = -b^ T u-h^ T v \\qquad &\\text if \\ c = -A^ T u-G^ T v \\\\\\\\ -\\infty \\qquad &\\text otherwise . \\end cases >\\end align > MATH As can be seen from the equation, when MATH is not satisfied, it has a value of MATH due to the MATH term. Since we want to find the lower bound closest to MATH , we want to find the value that maximizes MATH . This is MATH , the value when MATH is satisfied, and this matches the Dual LP we obtained with the first method. > MATH >\\begin align >f^ \\geq g u,v , \\qquad \\text provided v \\geq 0\\\\\\\\ >\\text find the biggest lowerbound g u,v \\\\\\\\ >\\max u,v g u,v \\\\\\\\ >\\text s.t. v \\geq 0. >\\end align > MATH This method is also applicable to other types of optimization problems that are not in LP form.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter10/10_04_Another_Perspective_on_LP_duality/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter10/10_05_Matrix_Games",
    "title": "10-05 Matrix Games",
    "chapter": "10",
    "order": 6,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; In this chapter, we examine mixed strategies for matrix games, which is an example of primal LP and dual LP in game theory. The setup assumes two players, J and R, and a payout matrix MATH . Game Setup Fig 1 Game Setup 3 The payout matrix is the amount of reward J must give to R when J chooses strategy MATH row and R chooses strategy MATH column MATH . However, if this value is positive, J gives R a reward equal to the size of the corresponding matrix, and if negative, R gives J a reward equal to the size of the corresponding matrix. This setting is also called a zero-sum setting, where if the reward R will receive or must pay is MATH and J's reward is MATH , then in each game the result of the rewards is MATH , and the total sum of the two rewards is always 0. Also, we assume that both players use mixed strategies. Mixed strategies is the assumption that each player's choice follows a specific probability distribution or is sampled from a specific probability distribution . > MATH >\\begin align >x : P \\text J chooses i = x i , \\qquad i=1,...m\\\\\\\\ >y : P \\text R chooses j = y j , \\qquad j=1,...n.\\\\\\\\ >\\end align > MATH If they know each other's mixed strategy, i.e., probability distribution, each player can calculate the payout they expect to get, i.e., the expected payout. > MATH >\\begin align >\\sum i=1 ^ m \\sum j=1 ^ n x i y j P ij = x^ T Py.\\\\\\\\ >\\end align > MATH Considering that the sign of the payout matrix is defined as the amount J gives to R, J will try to minimize this expected payout because J wants to give as little as possible to R, and R will try to maximize this expected payout because R wants to receive as much as possible from J. 이제 두 player의 입장에서 각자가 상대의 mixed strategy를 고려하여, 이 expected payout을 최대화 R의 입장 혹은 최소화 J의 입장 하려는 관점을 살펴보고, 서로가 서로를 optimal하게 행동하는 전제하에, 두 입장에서 유도되는 optimal strategy를 구하고, 결과적으론 Von Neumman's minimax theorem에 의해 두 결과가 같다는 것을 확인할 것이다. Minimizing Expected Payout : J's Perspective 먼저 R이 J의 strategy MATH 를 알고 있다고 가정하자. R은 expected payout MATH 를 maximize하고자 할 것이다. > MATH >\\begin align >\\max\\ x^ T Py : y\\geq0, 1^ T y = 1\\ = \\max i=1,...n P^ T x i .\\\\\\\\ >\\end align > MATH 이때 R은 식의 내용처럼 MATH 중 가장 큰 값을 갖는 i row index 를 찾게되고, 이 i에 대응되는 MATH 를 1로 가지고 나머지의 row index에 대해선 0을 가지는 strategy가 R에게 있어서 expected payout을 maximize하는 strategy일 것이다. R이 위처럼 최적으로 행동할 것을 알고 있을 때, J의 최적의 strategy는 밑의 식을 만족하는 distribution MATH 일 것이다. > MATH >\\begin align >& \\min x >& &\\max i=1,...n P^ T x i \\\\\\\\ >& \\text subject to >& & x\\geq 0, 1^ T x =1.\\\\\\\\ >\\end align > MATH Convex function의 maximization 또한 convex function이 된다. 이를 첫 번째 관점의 문제 정의라고 칭할 것이다. 또한 이 최적화 문제의 해를 optimal expected payout MATH 이라고 정하자. 또 하나 유념할 점은 게임참가자, 즉 player들이 모두 최적으로 행동한다는 가정이 기본적인 형태의 게임이론 formulation에서 가정이 된다. Maximizing Expected Payout : R's Perspective 두 번째 관점으로 J가 R의 strategy MATH 를 알고 있다고 가정하자. J는 expected payout을 minimize하고자 할 것이다. > MATH >\\begin align >\\min \\ x^ T Py : x\\geq0, 1^ T x = 1\\ = \\min j=1,...n Py j .\\\\\\\\ >\\end align > MATH 같은 논리로, J가 위처럼 최적으로 행동할 것을 알고 있을 때 R의 최적의 strategy는 밑의 식을 만족하는 distribution MATH 이다. > MATH >\\begin align >& \\max y >& & \\min j=1,...m Py j \\\\\\\\ >&\\text subject to >& &y\\geq 0, 1^ T y =1.\\\\\\\\ >\\end align > MATH 위와 마찬가지로 이를 두 번째 관점의 문제 정의라고 칭하고, 이 최적화 문제의 해를 MATH 라고 하자. player R이 이 expected payout을 maximize하고자 하기 때문에, 첫 번째, 즉, R이 J의 strategy를 미리 알고 있다는 가정 하에 결정되는 expected payout MATH 이 두 번째 가정보다 더 크거나 같은 값을 가질 것이라 쉽게 예상할 수 있다. MATH Von Neumann's minimax theorem 하지만, Von Neumann's minimax theorem에 따르면 MATH 가 된다. 실제 minimax theorem은 다음과 같다. > MATH >\\begin align >&\\text Let X\\subset \\mathbb R ^ N \\text and Y\\subset \\mathbb R ^ m \\text be compact convex sets. \\\\\\\\ > &\\text If f:X\\times Y\\rightarrow \\mathbb R \\text is a continuous function that is convex-concave, i.e. \\\\\\\\ > &\\qquad f \\cdot, y : X\\rightarrow\\mathbb R \\text is convex for fixed y, \\text and \\\\\\\\ > &\\qquad f x, \\cdot : Y\\rightarrow\\mathbb R \\text is concave for fixed x.\\\\\\\\ > &\\text Then we have that \\\\\\\\ >&\\min x\\in X \\max y\\in Y f x,y = \\max y\\in Y \\min x\\in X f x,y .\\\\\\\\ >\\end align > MATH 해당 내용의 증명은 생략한다. Proof of each perspective having Primal and Dual relationship 이제 위 두 가지 관점의 경우에 대한 expected payout이 LP 문제로써 서로 primal, dual 관계이고, Von Neumman's minimax theorem에 의하여 두 결과가 같다는 점을 이용하여, strong duality를 만족함을 보이고자 한다. 먼저 첫 번째 관점의 문제를 다음과 같이 reformulate 할 수 있다. > MATH >\\begin align >& \\min x \\max i=1,...m >& & P^ T x i \\\\\\\\ >&\\text subject to >& &x\\geq 0, 1^ T x = 1\\\\\\\\ >\\end align > MATH > > MATH >\\begin align >\\Leftrightarrow \\\\\\\\ >& \\min x,t >& & t \\\\\\\\ >&\\text subject to >& &x\\geq0, 1^ T x = 1, P^ T x \\preceq t. \\\\\\\\ >\\end align > MATH MATH 를 MATH 의 항들 중 가장 큰 값과 같게 만들어주는 문제로 reformulate 하였다. 이제 여기에 앞서 배운 duality의 두 번째 방법인 Lagrangian을 구하고, Lagrange dual function MATH 를 구하면, > MATH >\\begin align >&L x, t, u, v, y &&= t-u^ T x+v 1-1^ T x +y^ T P^ T x-t1 \\\\\\\\ >&g u, v, y &&= \\min x,t \\quad L x, t, u, v, y \\\\\\\\ >&&&= \\begin cases v \\qquad &\\text if 1-1^ T y = 0, Py-u-v1=0\\\\\\\\ -\\infty \\qquad &\\text otherwise. \\end cases >\\end align > MATH MATH 는 slack variable이므로, 이를 제거하고 식을 정리하면 다음과 같다. > MATH >\\begin align >&\\max y,v \\qquad \\quad && v\\\\\\\\ >&\\text subject to \\quad && y\\geq0, 1^ T y = 1\\\\\\\\ >&&& Py\\geq v. >\\end align > MATH 이는 두 번째 관점의 문제의 primal LP이다. 따라서 두 관점은 dual 관계에 있고 두 문제의 optimal value는 같으므로, strong duality가 성립한다. 일반적으로 LP문제에서는, 향 후의 내용에서 다루지만, primal과 dual 중 하나만 feasible하다면 strong duality가 성립한다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter10/10_05_Matrix_Games/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter11/11_00_Duality_in_General_Programs",
    "title": "11 Tính đối ngẫu trong chương trình tổng quát",
    "chapter": "11",
    "order": 1,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "Ôn tập: Tính đối ngẫu trong quy hoạch tuyến tính Cho MATH , MATH , MATH , MATH , MATH , Bài toán gốc Primal LP : > MATH \\begin alignat 1 \\min x & \\quad c^T x \\\\\\\\ s.t. & \\quad Ax = b \\\\\\\\ & \\quad Gx \\leq h \\end alignat MATH Bài toán đối ngẫu Dual LP : > MATH \\begin alignat 1 \\max u,v & \\quad -b^T u - h^T v \\\\\\\\ s.t. & \\quad - A^T u - G^T v = c \\\\\\\\ & \\quad v \\geq 0 \\end alignat MATH Giải thích 1: Với mọi MATH và MATH , và với bất kỳ MATH khả thi của bài toán gốc nào, ta có: > MATH \\begin equation u^T Ax-b + v^T Gx-h \\leq 0 \\end equation MATH Tức là, > MATH \\begin equation -A^Tu - G^Tv ^T x \\geq -b^Tu - h^T v \\end equation MATH Từ mối quan hệ này, nếu MATH , ta thu được một cận dưới cho giá trị tối ưu của bài toán gốc. Giải thích 2: Với mọi MATH và MATH , và với bất kỳ MATH khả thi của bài toán gốc nào, > MATH \\begin equation c^T x \\geq c^T x + u^T Ax-b + v^T Gx -h := L x,u,v \\end equation MATH Do đó, nếu MATH là tập khả thi của bài toán gốc và MATH là giá trị tối ưu của bài toán gốc, thì > MATH \\begin equation f^ \\geq \\min x \\in C L x,u,v \\geq \\min x L x,u,v := g u,v \\end equation MATH Nói cách khác, MATH là một cận dưới của MATH . > MATH g u,v = \\begin cases -b^T u - h^T v & \\text nếu MATH \\\\\\\\ -\\infty & \\text trường hợp khác \\end cases MATH Giải thích thứ hai cho ra cùng một bài toán đối ngẫu như giải thích thứ nhất, nhưng nó hoàn toàn tổng quát và áp dụng được cho các bài toán tối ưu bất kỳ bao gồm cả những bài toán không lồi .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter11/11_00_Duality_in_General_Programs/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter11/11_01_Lagrangian",
    "title": "11-1 Hàm Lagrangian",
    "chapter": "11",
    "order": 2,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "Bây giờ chúng ta sẽ xem xét dạng Lagrangian cho bài toán tối ưu sau đây. Ở đây, bài toán tối ưu không nhất thiết phải là lồi. > MATH \\begin alignat 1 \\min x & \\quad f x \\\\\\ s.t. & \\quad h i x \\leq 0, i = 1,\\dots,m \\\\\\ & \\quad l j x = 0, j=1,\\dots,r \\end alignat MATH Hàm Lagrangian được định nghĩa như sau: > MATH \\begin equation L x,u,v = f x + \\sum i=1 ^m u i h i x + \\sum j=1 ^r v j l j x \\end equation MATH Ở đây, MATH , MATH , MATH ngầm định rằng MATH khi MATH u MATH \\begin equation L x,u,v = f x + \\sum i=1 ^ m u i \\underbrace h i x \\leq 0 + \\sum j=1 ^r v j \\underbrace l j x =0 \\leq f x \\end equation MATH Nói cách khác, hàm Lagrangian có tính chất quan trọng sau: > Với mọi MATH , MATH , ta có MATH Ví dụ, trong hình dưới đây: Hình 1 Ví dụ về hàm Lagrangian 1 Đường liền nét biểu thị hàm MATH . Đường đứt nét biểu thị hàm MATH . Ở đây, tập khả thi xấp xỉ là MATH . Mỗi đường chấm biểu thị hàm MATH với MATH , MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter11/11_01_Lagrangian/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter11/11_02_Lagrange_dual_function",
    "title": "11-2 Hàm đối ngẫu Lagrange",
    "chapter": "11",
    "order": 3,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "Gọi MATH là tập khả thi của bài toán gốc và MATH là giá trị tối ưu của bài toán gốc. Tối thiểu hóa MATH trên tất cả MATH cho ta cận dưới sau đây. > MATH \\begin equation f^ \\geq \\min x \\in C L x,u,v \\geq \\min x L x,u,v := g u,v \\end equation MATH Ở đây, MATH được gọi là hàm đối ngẫu Lagrange và cung cấp một cận dưới cho MATH với bất kỳ MATH , MATH khả thi đối ngẫu nào. Ví dụ, trong hình dưới đây Hình 2 Ví dụ về hàm đối ngẫu Lagrangian 1 Đường nằm ngang đứt nét biểu thị hàm MATH . Biến đối ngẫu là MATH . Đường liền nét biểu thị MATH . Ví dụ: Chương trình bậc hai 1 Xác định dương MATH Xem xét bài toán bậc hai sau đây ở đây MATH > MATH \\begin alignat 1 \\min x & \\quad \\frac 1 2 x^T Q x + c^T x \\\\\\\\ s.t. & \\quad Ax = b, \\\\\\\\ & \\quad x \\geq 0 \\end alignat MATH Khi đó, Hàm Lagrangian: > MATH \\begin equation L x,u,v = \\frac 1 2 x^T Q x + c^T x - u^Tx + v^T Ax-b \\end equation MATH Hàm đối ngẫu Lagrangian: Từ biểu thức trên, để tối thiểu hóa hàm Lagrangian, ta lấy đạo hàm theo MATH và tìm MATH sao cho đạo hàm bằng không. \\begin equation Qx - c-u+A^T v = 0, \\end equation Tức là, \\begin equation Qx = c-u+A^T v \\end equation Lúc này, vì MATH là positive definite nên tồn tại ma trận nghịch đảo, do đó khi tìm MATH , ta có MATH . Vậy nên, khi thay MATH vào hàm Lagrangian, ta được kết quả dưới đây. MATH \\begin alignat 1 & c - u + A^T v ^T Q^ -1 ^T Q Q^ -1 c - u + A^T v - c - u + A^T v ^T Q^ -1 c - u + A^T v - b^T v \\\\\\ = & c - u + A^T v ^T Q^ -1 c - u + A^T v - c - u + A^T v ^T Q^ -1 c - u + A^T v - b^T v \\\\\\ = & -\\frac 1 2 c-u+A^Tv ^T Q^ -1 c-u+A^T v - b^T v \\end alignat MATH Do đó, > MATH \\begin equation g u,v = \\min x L x,u,v = -\\frac 1 2 c-u+A^Tv ^T Q^ -1 c-u+A^T v - b^T v \\end equation MATH Với mọi MATH và MATH , điều này tương ứng với một cận dưới của giá trị tối ưu gốc MATH . 2 Nửa xác định dương MATH Cùng bài toán như trên, nhưng lần này nếu MATH , Hàm Lagrangian: > MATH \\begin equation L x,u,v = \\frac 1 2 x^T Q x + c^T x - u^Tx + v^T Ax-b \\end equation MATH Hàm đối ngẫu Lagrangian: Giống như khi MATH là positive definite, ta cần tìm MATH thỏa mãn phương trình dưới đây. MATH \\begin equation Qx = c-u+A^T v \\end equation MATH Lúc này, vì MATH là positive semi-definite nên có thể không tồn tại ma trận nghịch đảo. Do đó, ta cần xem xét hai trường hợp sau: 1 MATH . Trong trường hợp này, tồn tại MATH thỏa mãn MATH , có thể tìm được bằng cách sử dụng nghịch đảo tổng quát MATH nghịch đảo giả Moore-Penrose, MATH . 2 MATH . Trong trường hợp này, không tồn tại MATH thỏa mãn MATH , nghĩa là không có MATH nào tối thiểu hóa MATH , và giá trị tối thiểu của MATH là MATH . Từ hai trường hợp này, hàm đối ngẫu Lagrangian có thể được tóm tắt như sau: > MATH g u,v = \\begin cases -\\frac 1 2 c-u+A^T v ^T Q^ + c - u + A^T v - b^T v & \\text if MATH \\\\\\\\ -\\infty & \\text otherwise \\end cases MATH Với mọi MATH , MATH thỏa mãn MATH , MATH là một cận dưới không tầm thường của MATH . Ví dụ: Chương trình bậc hai trong 2D Ví dụ, trong hình sau đây, MATH là một hàm bậc hai trên các biến lớn hơn 0 MATH , và hàm đối ngẫu MATH là một hàm bậc hai trên các biến lớn hơn 0 MATH . Hình 3 Ví dụ về chương trình bậc hai trong 2D Điểm màu xanh là giá trị tối ưu đối ngẫu, và điểm màu đỏ là giá trị tối ưu gốc. Với mọi MATH , hàm đối ngẫu MATH cung cấp một cận dưới cho MATH . Giá trị tối đa của hàm đối ngẫu MATH trùng khớp chính xác với giá trị MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter11/11_02_Lagrange_dual_function/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter11/11_03_Lagrange_dual_problem",
    "title": "11-3 Bài toán đối ngẫu Lagrange",
    "chapter": "11",
    "order": 4,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "Xem xét bài toán tối ưu sau đây: > MATH \\begin alignat 1 \\min x & \\quad f x \\\\ s.t. & \\quad h i x \\leq 0, i=1,\\dots,m \\\\ & \\quad l j x = 0, j=1,\\dots,r \\end alignat MATH Hàm đối ngẫu MATH thỏa mãn MATH với mọi MATH và MATH . Do đó, chúng ta có thể thu được cận dưới tốt nhất bằng cách tối đa hóa MATH trên tất cả MATH và MATH khả thi. Điều này được gọi là bài toán đối ngẫu Lagrange. > MATH \\begin alignat 1 \\max u,v & \\quad g u,v \\\\ s.t. & \\quad u \\geq 0 \\end alignat MATH Ở đây, nếu ta ký hiệu giá trị tối ưu đối ngẫu là MATH , thì MATH . Điều này được gọi là tính đối ngẫu yếu. Tính chất này luôn đúng ngay cả khi bài toán gốc không lồi. Hơn nữa, bài toán đối ngẫu luôn là một bài toán tối ưu lồi, ngay cả khi bài toán gốc không lồi. Theo định nghĩa, MATH là hàm lõm theo MATH , và MATH là một ràng buộc lồi. Do đó, bài toán đối ngẫu tương ứng với một bài toán tối đa hóa hàm lõm. > \\begin alignat 1 g u,v & = \\min x \\ f x + \\sum i=1 ^m u i h i x + \\sum j=1 ^r v j l j x \\ \\\\ & = - \\underbrace \\max x \\ -f x - \\sum i=1 ^m u i h i x - \\sum j=1 ^r v j l j x \\ \\text pointwise maximum of convex functions in MATH \\end alignat Ví dụ: Tối thiểu hóa hàm bậc bốn không lồi Hãy tối thiểu hóa hàm MATH với điều kiện MATH . Hình 4 Ví dụ về tối thiểu hóa hàm bậc bốn không lồi Trong trường hợp này, hàm đối ngẫu MATH như sau: > MATH \\begin equation g u = \\min i=1,2,3 \\ F i^4 u - 50 F i^2 u + 100 F i u \\ \\end equation MATH where, for MATH , > MATH \\begin alignat 1 F i u = & \\frac - a i 12\\cdot 2^ 1/3 \\left 432 100-u - 432^2 100-u ^2 - 4\\cdot 1200^3 ^ 1/2 \\right ^ 1/3 \\\\ & - 100 \\cdot 2^ 1/3 \\frac 1 \\left 432 100-u - 432^2 100-u ^2 - 4\\cdot 1200^3 ^ 1/2 \\right ^ 1/3 \\end alignat MATH và MATH . Mặc dù khó xác định liệu MATH có lõm hay không chỉ bằng cách nhìn vào hàm số, nhưng chúng ta có thể biết rằng MATH là hàm lõm dưới tính chất lồi của tính đối ngẫu.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter11/11_03_Lagrange_dual_problem/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter11/11_04_Strong_duality",
    "title": "11-4 Tính đối ngẫu mạnh",
    "chapter": "11",
    "order": 5,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "Khi một bài toán thỏa mãn MATH , điều này được gọi là tính đối ngẫu mạnh . Điều kiện Slater là một điều kiện đủ cho tính đối ngẫu mạnh. Điều kiện Slater: Nếu bài toán gốc là lồi và tồn tại ít nhất một MATH khả thi nghiêm ngặt, thì tính đối ngẫu mạnh xảy ra. > MATH \\begin equation h 1 x MATH \\begin alignat 1 \\min \\beta, \\beta 0, \\xi & \\quad \\frac 1 2 \\parallel\\beta\\parallel 2^2 + C \\sum i=1 ^n \\xi i \\\\\\\\ s.t. & \\quad \\xi i \\geq 0, i=1,\\dots,n \\\\\\\\ & \\quad y i x i^T \\beta + \\beta o \\geq 1 - \\xi i, i=1,\\dots,n \\end alignat MATH Sử dụng các biến đối ngẫu MATH , hãy định nghĩa hàm Lagrangian: > \\begin equation L \\beta,\\beta 0,\\xi,v,w = \\frac 1 2 \\parallel\\beta\\parallel\\ 2^2 + C\\sum i=1 ^n \\xi i - \\sum i=1 ^n v i \\xi i + \\sum i=1 ^n w i 1-\\xi i - y i x i^T\\beta + \\beta o \\end equation Tối thiểu hóa theo MATH , ta có thể tìm được hàm đối ngẫu Lagrangian như sau: > MATH g v,w = \\begin cases -\\frac 1 2 w^T\\tilde X \\tilde X ^T w + 1^Tw, &\\text if MATH \\\\\\\\ -\\infty, &\\text otherwise \\end cases MATH Ở đây MATH . Do đó, bài toán đối ngẫu SVM sau khi loại bỏ biến slack MATH trở thành: > MATH \\begin alignat 1 \\max w & \\quad -\\frac 1 2 w^T\\tilde X \\tilde X ^T w + 1^Tw \\\\\\\\ s.t. & \\quad 0 \\leq w \\leq C1, w^Ty = 0 \\end alignat MATH Vì bài toán gốc thỏa mãn điều kiện Slater, tính đối ngẫu mạnh xảy ra. Đó là, hàm mục tiêu là lồi và các ràng buộc bất đẳng thức là affine theo MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter11/11_04_Strong_duality/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter11/11_05_Duality_gap",
    "title": "11-5 Khoảng cách đối ngẫu",
    "chapter": "11",
    "order": 6,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Nếu bài toán gốc có giá trị MATH tại MATH , và bài toán đối ngẫu có giá trị MATH tại MATH , thì hiệu số MATH được gọi là khoảng cách đối ngẫu. Trong khi đó, các giá trị khả thi này luôn thỏa mãn mối quan hệ sau > MATH \\begin equation f x - f^ \\leq f x - g u,v , \\end equation MATH Nếu khoảng cách đối ngẫu bằng MATH , thì MATH là một nghiệm tối ưu của bài toán gốc và MATH là tối ưu cho bài toán đối ngẫu. Ngoài ra, nếu khoảng cách đối ngẫu thỏa mãn MATH , điều này ngụ ý MATH , vì vậy các thuật toán giải bài toán một cách lặp có thể sử dụng khoảng cách đối ngẫu làm tiêu chí dừng.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter11/11_05_Duality_gap/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter12/12_00_KKT_conditions",
    "title": "12 KKT Conditions",
    "chapter": "12",
    "order": 1,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Khi bài toán nguyên thủy là lồi, các điều kiện Karush–Kuhn–Tucker KKT trở thành điều kiện đủ cho các điểm tối ưu nguyên thủy & đối ngẫu với độ lệch đối ngẫu bằng không. Ngoài ra, khi hàm mục tiêu và các hàm ràng buộc của bài toán nguyên thủy khả vi và thỏa mãn tính đối ngẫu mạnh, các điểm tối ưu nguyên thủy & đối ngẫu luôn thỏa mãn các điều kiện KKT. Các điều kiện KKT giữ một vị trí rất quan trọng trong tối ưu hóa. Những điều kiện này cho phép một số bài toán đặc biệt được giải một cách giải tích, và nhiều thuật toán tối ưu hóa lồi có thể được hiểu như các phương pháp để giải các điều kiện KKT 1 . Trong chương này, chúng ta sẽ tìm hiểu về định nghĩa và tính chất của các điều kiện KKT và xem xét một số ví dụ dựa trên chúng. Như một ghi chú bên lề , các điều kiện KKT ban đầu được Harold W. Kuhn và Albert W. Tucker giới thiệu với thế giới vào năm 1951, và vào thời điểm đó chúng được gọi là điều kiện KT Kuhn-Tucker . Sau đó, các học giả phát hiện ra rằng các điều kiện cần thiết cho bài toán này đã được William Karush đề cập trong luận văn thạc sĩ của ông vào năm 1939, và từ đó trở đi, tên của Karush được bao gồm và chúng được biết đến như các điều kiện KKT Karush–Kuhn–Tucker 3 .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter12/12_00_KKT_conditions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter12/12_01_Karush_Kuhn_Tucker_conditions",
    "title": "12-01 Điều kiện Karush-Kuhn-Tucker",
    "chapter": "12",
    "order": 2,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Hãy xem xét bài toán tối ưu hóa tổng quát sau đây. > MATH >\\begin align > &\\min x && f x \\\\\\\\ > &\\text với điều kiện && h i x \\le 0, \\text i=1,\\dots,m \\\\\\\\ > & && l j x = 0, \\text j=1,\\dots,r .\\\\\\\\ >\\end align > MATH Điều kiện Karush–Kuhn–Tucker KKT hoặc điều kiện KKT bao gồm các điều kiện sau 3 . MATH Tính dừng : Khi MATH được cố định, subdifferential theo MATH chứa 0. MATH Bù yếu : Ít nhất một trong MATH và MATH có giá trị 0. MATH Tính khả thi Nguyên thủy : Chỉ ra liệu các ràng buộc của bài toán nguyên thủy có được thỏa mãn hay không. MATH Tính khả thi Đối ngẫu : Chỉ ra liệu các ràng buộc của bài toán đối ngẫu có được thỏa mãn hay không. Tính đủ Đối với một bài toán nguyên thủy lồi, khi tồn tại MATH thỏa mãn các điều kiện KKT, quá trình sau đây chỉ ra rằng MATH là nghiệm nguyên thủy & đối ngẫu với độ lệch đối ngẫu bằng không. > MATH >\\begin align > g \\lambda^\\star, \\nu^\\star &= \\min x L x, \\lambda^\\star, \\nu^\\star \\\\\\\\ > &= L x^\\star, \\lambda^\\star, \\nu^\\star \\\\\\\\ > &= f x^\\star + \\sum i=1 ^m \\lambda i^\\star h i x^\\star + \\sum j=1 ^r \\nu j^\\star l j x^\\star \\\\\\\\ > &= f x^\\star >\\end align > MATH 1. MATH là một hàm lồi. tổng của các hàm lồi 2. MATH do đó MATH . 3. Bởi bù yếu và tính khả thi nguyên thủy, MATH . Tính cần thiết Khi MATH là nghiệm nguyên thủy & đối ngẫu với độ lệch đối ngẫu bằng không ví dụ, thỏa mãn điều kiện Slater , tất cả các bất đẳng thức dưới đây trở thành đẳng thức, vì vậy trong bài toán này MATH thỏa mãn các điều kiện KKT. > MATH >\\begin align > f x^\\star &= g \\lambda^\\star, \\nu^\\star \\\\\\\\ > &= \\min x \\big f x + \\sum i=1 ^ m \\lambda i^\\star h i x + \\sum j=1 ^ r \\nu j^\\star l j x \\big \\\\\\\\ > &\\le f x^\\star + \\sum i=1 ^m \\lambda i^\\star h i x^\\star + \\sum j=1 ^r \\nu j^\\star l j x^\\star \\\\\\\\ > &\\le f x^\\star >\\end align > MATH 1. MATH có nghĩa là độ lệch đối ngẫu bằng không. 2. Để thỏa mãn MATH , bù yếu và tính khả thi nguyên thủy phải được thỏa mãn. 3. Nếu MATH được thỏa mãn, tất cả các bất đẳng thức trong suy dẫn trên trở thành đẳng thức. Tổng hợp Tóm lại, các điều kiện KKT là: Điều kiện đủ cho nghiệm nguyên thủy & đối ngẫu với độ lệch đối ngẫu bằng không. Nếu tính đối ngẫu mạnh được giữ, chúng trở thành điều kiện cần thiết cho nghiệm nguyên thủy & đối ngẫu. Tức là, đối với các bài toán thỏa mãn tính đối ngẫu mạnh, mối quan hệ sau được giữ. > MATH >\\begin align > x^\\star, \\lambda^\\star, \\nu^\\star \\text là nghiệm nguyên thủy và đối ngẫu \\\\\\\\ > \\Leftrightarrow x^\\star, \\lambda^\\star, \\nu^\\star \\text thỏa mãn các điều kiện KKT \\\\\\\\ >\\end align > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter12/12_01_Karush_Kuhn_Tucker_conditions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter12/12_02_Example_quadratic_with_equality_constraints",
    "title": "12-02 Ví dụ bài toán bậc hai với ràng buộc đẳng thức",
    "chapter": "12",
    "order": 3,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Một chương trình bậc hai chỉ với các ràng buộc đẳng thức như sau. > MATH >\\begin align > &\\min x && 1/2 x^T P x + q^T x + r \\\\\\\\ > &\\text với điều kiện && Ax = b ,\\\\\\\\ >&\\text trong đó &&P \\in \\mathbb S + ^n \\text và A \\in \\mathbb R ^ \\text p x n . >\\end align > MATH Bài toán này là lồi và không có ràng buộc bất đẳng thức, vì vậy nó thỏa mãn điều kiện Slater Tính đối ngẫu mạnh . Nếu các nghiệm nguyên thủy & đối ngẫu là MATH , thì theo các điều kiện KKT, chúng thỏa mãn các điều kiện sau 1 . Tính dừng: MATH Bù yếu: Vì không có ràng buộc bất đẳng thức, điều này không cần được xem xét. Tính khả thi nguyên thủy & đối ngẫu: MATH Những điều kiện này có thể được biểu diễn một cách ngắn gọn bằng cách sử dụng ma trận khối, được gọi là ma trận KKT 3 . > MATH > \\begin bmatrix > P & A^T \\\\\\\\ > A & 0 \\\\\\\\ > \\end bmatrix > \\begin bmatrix > x^\\star \\\\\\\\ > \\nu^\\star \\\\\\\\ > \\end bmatrix > = > \\begin bmatrix > -q \\\\\\\\ > b \\\\\\\\ > \\end bmatrix > MATH Giải phương trình ma trận này cho ta các nghiệm nguyên thủy & đối ngẫu cho bài toán đã cho. Một sự thật thú vị là bài toán này cũng có thể được xem như việc tính toán bước Newton cho một bài toán có ràng buộc đẳng thức 3 . Đối với bài toán MATH , nếu chúng ta đặt P, q, r như sau, thì hàm mục tiêu của chương trình bậc hai trở nên giống hệt với khai triển Taylor bậc hai của MATH . > MATH , MATH , MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter12/12_02_Example_quadratic_with_equality_constraints/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter12/12_03_Example_water_filling",
    "title": "12-03 Ví dụ thuật toán water-filling",
    "chapter": "12",
    "order": 4,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Giả sử chúng ta có bài toán tối ưu hóa lồi sau đây. > MATH >\\begin align > &\\min x && - \\sum i=1 ^n \\log \\alpha i + x i \\\\\\\\ > &\\text với điều kiện && x \\succeq 0, 1^Tx = 1 ,\\\\\\\\ >&\\text trong đó \\alpha i > 0. >\\end align > MATH Bài toán này liên quan đến việc phân bổ công suất cho n kênh truyền thông và xuất hiện trong lý thuyết thông tin. Biến MATH biểu diễn công suất đầu ra của máy phát được phân bổ cho kênh thứ i, và MATH biểu diễn dung lượng hoặc tốc độ truyền thông của kênh đó. Tức là, bài toán này là xác định bao nhiêu công suất nên được phân bổ cho mỗi kênh để tối đa hóa tổng tốc độ truyền thông 1 . Gọi các nhân tử Lagrange cho ràng buộc bất đẳng thức MATH và ràng buộc đẳng thức MATH lần lượt là MATH và MATH . Các điều kiện KKT cho bài toán đã cho như sau. > MATH >\\begin align >x^\\star \\succeq 0, \\\\\\\\ >1^Tx^\\star = 1, \\\\\\\\ >\\lambda^\\star \\succeq 0, \\\\\\\\ >\\lambda i^\\star x i^\\star = 0, \\text i = 1, \\dots, n, \\\\\\\\ > -1 / \\alpha i + x i^\\star - \\lambda i^\\star + \\nu^\\star = 0, \\text i= 1, \\dots, n. >\\end align > MATH Sử dụng các phương trình thu được từ các điều kiện KKT, chúng ta có thể tìm MATH một cách giải tích. Đầu tiên, chúng ta loại bỏ MATH khỏi các phương trình bằng cách sử dụng nó như một biến slack. > MATH >\\begin align >x^\\star \\succeq 0, \\\\\\\\ >1^Tx^\\star = 1, \\\\\\\\ >x i^\\star \\nu^\\star - 1 / \\alpha i + x i^\\star = 0, \\text i = 1, \\dots, n, \\\\\\\\ > \\nu^\\star \\ge 1/ \\alpha i + x i^\\star , \\text i= 1, \\dots, n. >\\end align > MATH Điều này được sắp xếp như sau bởi tính dừng và bù yếu. > MATH > x i^\\star = > \\begin cases > 1 / \\nu^\\star - \\alpha i &\\nu^\\star 0 &\\nu^\\star \\ge 1/\\alpha i\\\\\\\\ > \\end cases > = \\max\\ 0, 1/\\nu^\\star - \\alpha i \\ , \\quad i = 1, \\dots, n. > MATH Cũng vậy, theo điều kiện MATH , MATH có tổng bằng 1. > MATH > \\sum i=1 ^n \\max\\ 0, 1/\\nu^\\star - \\alpha i \\ = 1. > MATH Vế trái của phương trình là một hàm tuyến tính từng khoảng tăng của MATH , vì vậy phương trình này có một nghiệm duy nhất cho MATH cố định. Phương pháp giải này được gọi là water-filling đổ nước . Khi MATH là mức độ nền cho vùng MATH , bài toán này có thể được nghĩ như việc đổ nước vào mỗi vùng sao cho mực nước trở thành MATH như được hiển thị trong hình dưới đây. Chúng ta đổ nước cho đến khi tổng lượng nước trở thành 1. Fig1 Minh họa thuật toán water-filling 1",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter12/12_03_Example_water_filling/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter12/12_04_Example_support_vector_machines",
    "title": "12-04 Ví dụ máy vector hỗ trợ",
    "chapter": "12",
    "order": 5,
    "owner": "Wontak Ryu",
    "lesson_type": "required",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Bài toán máy vector hỗ trợ cho các tập không tách được như sau. > MATH >\\begin align > &\\min \\beta, \\beta-0, \\xi && \\frac 1 2 \\rVert\\beta\\rVert 2^2 + C\\sum i=1 ^n \\xi i \\\\\\\\ > &\\text với điều kiện && \\xi i \\ge 0, \\quad i = 1, \\dots, n \\\\\\\\ > & && y i x i^T \\beta + \\beta-0 \\ge 1 - \\xi i, \\quad i = 1, \\dots, n,\\\\\\\\ >&&&\\text cho trước y \\in \\ -1, 1\\ ^n \\text và X \\in \\mathbb R ^ n \\times p . >\\end align > MATH Khi các nhân tử Lagrange cho hai ràng buộc bất đẳng thức của bài toán đã cho lần lượt là MATH , hàm Lagrangian như sau. > MATH Sử dụng hàm Lagrangian ở trên, chúng ta có thể tìm các điều kiện sau đây làm cho bài toán này thỏa mãn điều kiện tính dừng KKT. Suy ra các điều kiện mà hàm Lagrangian trở thành 0 khi đạo hàm theo MATH tương ứng > MATH >0 = \\sum i=1 ^n w i^\\star y i, \\quad \\beta = \\sum i=1 ^n w i^\\star y i x i, \\quad w^\\star = C \\cdot 1 - v^\\star > MATH Cũng vậy, bù yếu cho hai ràng buộc bất đẳng thức như sau. > MATH > v i^\\star \\xi i = 0, \\quad w i^\\star 1 - \\xi i - y i x i^T \\beta + \\beta-0 =0, \\quad i = 1, \\dots, n. > MATH Tức là, tại điểm tối ưu, MATH được thỏa mãn, và khi MATH , MATH trở thành khác không, và điểm i như vậy được gọi là điểm hỗ trợ . Đối với điểm hỗ trợ i mà MATH , MATH nằm trên siêu phẳng và MATH . Đối với điểm hỗ trợ i mà MATH , MATH nằm ở phía đối diện của siêu phẳng và MATH . MATH Trước khi tối ưu hóa bài toán SVM, chúng ta có thể sử dụng phương pháp trên để lọc ra các điểm không hỗ trợ bằng cách lọc ra các điểm không hỗ trợ, chúng ta có thể tăng hiệu quả tính toán . Thực tế, các điều kiện KKT không đóng vai trò trực tiếp trong việc đưa ra nghiệm của bài toán này, nhưng chúng ta có thể thu được trực giác để hiểu rõ hơn về bài toán SVM thông qua chúng 3 .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter12/12_04_Example_support_vector_machines/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter12/12_05_Constrained_and_Lagrange_forms",
    "title": "12-05 Dạng ràng buộc và dạng Lagrange",
    "chapter": "12",
    "order": 6,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Trong thống kê và học máy, chúng ta thường chuyển đổi giữa dạng ràng buộc và dạng Lagrange . Hãy định nghĩa dạng ràng buộc và dạng Lagrangian như sau. Dạng Ràng buộc C sau đây > MATH >\\min x \\: f x \\quad \\text với điều kiện h x \\le t,\\\\\\\\ >\\text trong đó t \\in \\mathbb R \\text là tham số điều chỉnh. > MATH Dạng Lagrange L sau đây > MATH >\\min x \\: f x + \\lambda \\cdot h x ,\\\\\\\\ >\\text trong đó \\lambda \\ge 0 \\text là tham số điều chỉnh. > MATH Khi MATH là lồi, hãy xem xét các trường hợp mà hai bài toán cho cùng một nghiệm. 1. C đến L : Khi C là khả thi chặt chẽ thỏa mãn điều kiện Slater và thỏa mãn tính đối ngẫu mạnh, nếu tồn tại một nghiệm đối ngẫu MATH tối thiểu hóa hàm mục tiêu sau đây cho nghiệm MATH của C , thì MATH cũng là nghiệm của L . MATH 2. L đến C : Nếu MATH là nghiệm của L và C với MATH thỏa mãn các điều kiện KKT, thì MATH cũng là nghiệm của C . Điều này là vì MATH thỏa mãn các điều kiện KKT của L cũng thỏa mãn các điều kiện KKT của C với MATH . > MATH L 의 KKT conditions: > > MATH > \\begin align > \\nabla x f x^\\star + \\lambda^\\star \\nabla x h x^\\star &= 0\\\\\\\\ > \\lambda^\\star &\\ge 0\\\\\\\\ > \\end align > MATH > > > MATH MATH 인 C 의 KKT conditions: > > MATH > \\begin align > \\nabla x f x^\\star + \\lambda^\\star \\nabla x h x^\\star &= 0\\\\\\\\ > \\lambda^\\star &\\ge 0\\\\\\\\ > \\lambda^\\star \\underbrace h x^\\star - h x^\\star =0 &= 0 > \\end align > MATH Tóm lại, 1 và 2 lần lượt cho thấy các mối quan hệ sau. Fig1 Kết luận 3 Vậy, trong những hoàn cảnh nào C và L thể hiện sự tương đương hoàn hảo? Ví dụ, khi MATH như chuẩn , MATH , và MATH , sự tương đương hoàn hảo được thể hiện. Do các điều kiện đã cho, ràng buộc trong C trở thành MATH , và bằng cách đặt MATH thành MATH , L cũng áp đặt cùng một ràng buộc MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter12/12_05_Constrained_and_Lagrange_forms/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter12/12_06_Uniqueness_in_L1_penalized_problems",
    "title": "12-06 Tính duy nhất trong các bài toán phạt L1",
    "chapter": "12",
    "order": 7,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Bài toán hồi quy tuyến tính có phạt MATH sau đây cũng được biết đến rộng rãi như bài toán lasso. > MATH >\\begin align >&&&\\hat \\beta \\in \\text argmin \\beta \\in \\mathbb R ^p \\frac 1 2 \\| y - X\\beta \\|^2 2 + \\lambda \\|\\beta\\| 1, \\qquad \\\\\\\\ >&& \\text --- 1 &\\text cho trước y \\in \\mathbb R ^n, \\\\\\\\ >&&& \\text một ma trận X \\in \\mathbb R ^ n \\text x p \\ \\text của các biến dự đoán, \\\\\\\\ >&&& \\text và tham số điều chỉnh \\lambda \\ge 0. >\\end align > MATH Bài toán Lasso ở trên có một nghiệm duy nhất khi nó là lồi chặt chẽ, tức là, khi MATH . Mặt khác, khi MATH rank X Thú vị là, trong một số trường hợp đặc biệt, bài toán Lasso được đảm bảo có một nghiệm duy nhất bất kể chiều của MATH 13 . > Định lý: Khi hàm MATH khả vi và lồi chặt chẽ, MATH , và MATH tuân theo một phân phối xác suất liên tục nào đó trên MATH , bài toán tối ưu hóa sau luôn có một nghiệm duy nhất. Hơn nữa, nghiệm bao gồm nhiều nhất MATH thành phần khác không. Không có hạn chế nào về chiều của MATH . Tức là, nó hợp lệ ngay cả khi p >> n Các sự thật cơ bản và các điều kiện KKT > Bổ đề 1. Đối với MATH tùy ý, bài toán lasso 1 có các tính chất sau. > > 1. Nó có hoặc một nghiệm duy nhất hoặc vô số nghiệm. > 2. Tất cả các nghiệm lasso MATH có cùng giá trị MATH . >3. Khi MATH , tất cả các nghiệm lasso MATH có cùng chuẩn MATH MATH . MATH > Chứng minh. > 1. Nếu 1 có hai nghiệm MATH , MATH , thì với bất kỳ MATH 0 > 2. & 3. Giả sử có hai nghiệm MATH , MATH . Gọi giá trị tối ưu là MATH . Khi đó với bất kỳ nghiệm MATH MATH 0 > MATH >\\begin align > &\\frac 1 2 \\| y - X \\alpha \\hat \\beta ^ 1 + 1 - \\alpha \\hat \\beta ^ 2 \\| 2^2 + \\lambda \\| \\alpha \\hat \\beta ^ 1 + 1 - \\alpha \\hat \\beta ^ 2 \\| 1 \\\\ > & = \\alpha c^\\star + 1-\\alpha c^\\star = c^\\star >\\end align > MATH > > Để thỏa mãn đẳng thức này, MATH phải luôn có cùng giá trị cho bất kỳ nghiệm MATH , và khi MATH , MATH cũng phải luôn giống nhau. Trở lại ban đầu, các điều kiện KKT cho bài toán lasso 1 như sau. > MATH >\\begin align >&&X^T y - X\\hat \\beta = \\lambda \\gamma, \\qquad \\text --- 2 \\\\\\\\ >&&\\gamma i \\in > \\begin cases > \\ sign \\hat \\beta i \\ & \\text nếu \\hat \\beta i \\neq 0 \\\\\\\\ > -1, 1 & \\text nếu \\hat \\beta i = 0, > \\end cases \\\\\\\\ > &&\\text với i = 1, \\dots, p. \\text --- 3 \\\\\\\\ > &&\\text Ở đây \\gamma \\in \\mathbb R ^p \\text được gọi là subgradient của hàm \\\\ > &&f x = \\| x \\| 1 \\text được đánh giá tại x = \\hat \\beta . >\\end align > MATH Tức là, nghiệm MATH của 1 thỏa mãn 2 và 3 cho một MATH nào đó. 위에서 얻은 KKT conditions를 이용하여 lasso solution에 대한 조건을 좀 더 명시적인 형태로 변환해보도록 하자. 이후의 진행에서는 유도의 간결함을 위해 MATH 를 가정하도록 한다. 우선 equicorrelation set MATH 을 다음과 같이 정의한다. MATH 는 MATH 인 모든 인덱스 MATH 와 MATH 이면서 MATH 인 모든 인덱스 MATH 를 원소로 가진 집합이다. MATH \\mathcal E = \\ i \\in \\ 1, \\dots, p \\ : \\vert X i^T y - X\\hat \\beta \\vert = \\lambda \\ . \\qquad \\text --- 4 MATH 또한 equicorrelation sign MATH 를 다음과 같이 정의한다. 여기서 MATH 는 행렬 X에서 MATH 인 column MATH 외의 모든 column을 0 벡터로 교체한 행렬을 의미한다. MATH s = sign X^T \\mathcal E y -X\\hat \\beta . \\qquad \\text --- 5 MATH 여기서 MATH 는 MATH 에 대해 다음과 같이 표현할 수 있다: MATH and MATH . 또한 Lemma1-2에 의해 MATH 는 유일한 값을 가지므로 이는 MATH , MATH 이 유일함을 암시한다. 3 의 subgradient MATH 에 대한 정의에 의해 모든 lasso solution MATH 에 대해 MATH 임을 알 수 있다. 그러므로 2 를 MATH 블록에 대해 표현하면 다음과 같다. MATH X^T \\mathcal E y - X \\mathcal E \\hat \\beta \\mathcal E = \\lambda \\gamma \\mathcal E = \\lambda s. \\qquad \\text --- 6 MATH 6 의 양변에 MATH 를 곱하면 다음과 같이 정리된다 MATH 는 MATH 의 pseudoinverse matrix . MATH \\begin align & X^T \\mathcal E X \\mathcal E \\hat \\beta \\mathcal E = X^T \\mathcal E y - X^T \\mathcal E ^+ \\lambda s \\\\\\\\ \\Leftrightarrow & X \\mathcal E \\hat \\beta \\mathcal E = X^T \\mathcal E X^T \\mathcal E ^+ y - X^T \\mathcal E ^+ \\lambda s . \\end align MATH MATH 이므로 위 등식은 곧 아래와 같다. MATH X \\hat \\beta = X^T \\mathcal E X^T \\mathcal E ^+ y - X^T \\mathcal E ^+ \\lambda s , \\qquad \\text --- 7 MATH 그리고 임의의 lasso solution MATH 는 다음과 같다. MATH \\begin align & \\hat \\beta -\\mathcal E = 0 \\text and \\hat \\beta \\mathcal E = X^T \\mathcal E ^+ y - X^T \\mathcal E + b, \\qquad \\text --- 8 \\\\\\\\ & \\text where b \\in null X \\mathcal E . \\end align MATH Sufficient conditions for uniqueness 8 의 MATH 의 유일함이 보장되기 위해서는 MATH 이 되어야 한다 MATH 은 유일하기 때문에 . MATH 이어야 함을 주지하고 8 의 등식을 변형하면 다음의 결론을 얻게 된다. > Lemma 2. 임의의 MATH 에 대해, 만약 MATH , 또는 MATH 참고 https://www.quora.com/When-the-null-space-of-a-matrix-is-the-zero-vector-the-matrix-is-in\\vertible-Why/answer/Alexander-Farrugia ,이면 lasso solution은 유일 unique 해지며, 이는 곧 다음과도 같다. > MATH >\\begin align >&& \\hat \\beta -\\mathcal E = 0 \\text and \\hat \\beta \\mathcal E = X^T \\mathcal E X^T \\mathcal E ^ -1 X^T \\mathcal E y - \\lambda s , \\qquad \\text --- 9 \\\\\\\\ >&& \\text where \\mathcal E \\text and s \\text are the equicorrelation set and signs as defined in 4 and 5 . >\\end align > MATH 참고로 이 solution은 많아 봐야 MATH 의 nonzero components로 구성된다. 그렇다면 MATH 을 암시하는 MATH 에 대한 좀 더 자연스러운 조건에 대해 알아보도록 하자. 이를 알아보기에 앞서 우선 MATH 이라 가정해보겠다. 이 경우, 어떤 MATH 에 대해 다음과 같은 등식을 만족한다. MATH X i = \\sum j \\in \\mathcal E \\backslash \\ i\\ c j X j,\\\\\\\\ \\text where c j \\in \\mathbb R , j \\in \\mathcal E . MATH 위 등식의 양변에 MATH 를 곱해주고, 우항에 MATH 을 곱해준다. MATH s i X i = \\sum j \\in \\mathcal E \\backslash \\ i\\ s i s j c j \\cdot s j X j . \\qquad \\text --- 10 MATH MATH 로 r lasso residual 을 정의하면 임의의 MATH 에 대해 MATH 를 만족한다. r을 위 10 의 양변에 곱해주면 MATH 에 대한 부등식을 얻을 수 있다. MATH 이라 가정 MATH \\lambda = \\sum j \\in \\mathcal E \\backslash \\ i\\ s i s j c j \\lambda \\quad \\text and \\quad \\sum j \\in \\mathcal E \\backslash \\ i\\ s i s j c j = 1. MATH 즉, MATH 이면, 어떤 MATH 에 대해 다음 등식이 성립한다. MATH s iX i = \\sum j \\in \\mathcal E \\backslash \\ i\\ a j \\cdot s j X j, \\text with \\sum j \\in \\mathcal E \\backslash \\ i\\ a j = 1. MATH 위 등식은 MATH 이 MATH 의 affine span 위에 존재한다는 의미와도 같다. 또한 이는 어떤 k+2개의 원소를 포함한 subset으로는 최대 k dimensional affine space만을 표현할 수 있다는 것과도 같다. Fig 1 4 elements on 2-dimensional affine space 3 우리가 원하는 것은 행렬 MATH 가 MATH 을 만족하는 것이며, 이는 곧 행렬 MATH 의 column들이 general position https://en.wikipedia.org/wiki/General position 에 있는 것과도 같다. 바꿔말하면, 그 어떤 k-dimensional affine subspace도 set 안의 k+1개보다 더 많은 element를 포함하지 않는다는 것이다. > Lemma 3. 만약 행렬 MATH 의 column들이 general position에 있으면, 임의의 MATH 와 MATH 에 대한 lasso solution은 유일 unique 하며 또한 이 solution은 9 를 만족한다. 그렇다면 어떤 행렬 MATH 가 항상 위 조건을 만족할 수 있을까? 결론부터 말하자면 다음과 같다. > Lemma 4. 행렬 MATH 의 모든 원소가 MATH 상의 continuous probability distribution을 따른다면, 임의의 MATH 와 MATH 에 대해 lasso solution은 unique하고 항상 9 를 만족한다. 왜냐하면 continuous probability distribution을 따를때, 모든 column vector들은 linearly independent하기 때문이다. 참고 https://math.stackexchange.com/questions/432447/probability-that-n-vectors-drawn-randomly-from-mathbbrn-are-linearly-ind?rq=1 General convex loss functions 좀 더 일반적인 lasso problem에 대해서도 같은 내용을 적용할 수 있다 13 . MATH \\hat \\beta \\in \\text argmin \\beta \\in \\mathbb R ^p f X\\beta + \\lambda \\|\\beta\\| 1, \\qquad \\text --- 11 MATH > Lemma 5. 만약 행렬 MATH 의 모든 원소가 MATH 상의 continuous probability distribution을 따를때, 미분 가능하고 strictly convex인 임의의 함수 MATH 는 임의의 MATH 에 대해 11 의 문제에서 항상 유일 unique 한 solution을 보장한다. 이 solution은 많아봐야 MATH 개의 nonzero components로 구성된다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter12/12_06_Uniqueness_in_L1_penalized_problems/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter13/13_Duality_uses_and_correspondences",
    "title": "13 Ứng dụng của đối ngẫu và các tương ứng",
    "chapter": "13",
    "order": 1,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Trong chương này, chúng ta sẽ học về các ứng dụng của Đối ngẫu Duality và các tương ứng liên quan thông qua các ví dụ. Lưu ý Trong chương này, nghiệm tối ưu MATH và hàm liên hợp MATH của MATH được phân biệt và ký hiệu như vậy.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter13/13_Duality_uses_and_correspondences/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter13/13_01_Uses_of_duality",
    "title": "13-01 Ứng dụng của đối ngẫu",
    "chapter": "13",
    "order": 2,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Hai ứng dụng chính của đối ngẫu Hãy cùng xem lại hai đặc điểm chính của đối ngẫu đã được đề cập trong Chương 11. • Khi MATH là khả thi nguyên thủy và MATH là khả thi đối ngẫu, hiệu số giữa bài toán nguyên thủy MATH và bài toán đối ngẫu MATH được gọi là khoảng cách đối ngẫu duality gap giữa MATH và MATH . > MATH Khi khoảng cách đối ngẫu bằng 0, điều này được gọi là khoảng cách đối ngẫu bằng không, có nghĩa là nghiệm của bài toán đối ngẫu là tối ưu. Ngoài ra, cận trên MATH luôn nhỏ hơn hoặc bằng giá trị tối ưu MATH . Để biết lý do chi tiết, vui lòng tham khảo nội dung trong Chương 11 % multilang post url contents/chapter11/21-03-24-11 00 Duality in General Programs % . Do đó, có thể thực hiện suy luận sau đây. Chứng minh > MATH \\begin align > f^ \\star &\\ge g u, v \\\\ > -f^ \\star &\\le -g u, v \\\\ > f x -f^ \\star &\\le \\underbrace f x -g u, v \\text khoảng cách đối ngẫu \\\\ > g^ \\star -g x &\\le \\underbrace f x -g u, v \\text khoảng cách đối ngẫu \\\\ > \\end align MATH Hơn nữa, khoảng cách đối ngẫu có thể được sử dụng làm tiêu chí dừng cho các thuật toán. • Khi nghiệm đối ngẫu tối ưu MATH được cho, trong điều kiện đối ngẫu mạnh, nghiệm nguyên thủy tối thiểu hóa Lagrangian MATH cho tất cả MATH tức là thỏa mãn điều kiện dừng . Điều này có thể được sử dụng để tính toán nghiệm nguyên thủy.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter13/13_01_Uses_of_duality/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter13/13_02_Solving_the_primal_via_the_dual",
    "title": "13-02 Giải bài toán nguyên thủy thông qua đối ngẫu",
    "chapter": "13",
    "order": 3,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Một hệ quả quan trọng của điều kiện dừng Trong điều kiện đối ngẫu mạnh, khi nghiệm đối ngẫu MATH được cho, nghiệm nguyên thủy MATH có thể được tìm bằng cách giải Lagrangian sau: > MATH Thông thường, nghiệm của các bài toán không ràng buộc như vậy có thể được biểu diễn bằng cách thể hiện rõ ràng các đặc điểm của nghiệm nguyên thủy thông qua nghiệm đối ngẫu. Hơn nữa, nếu nghiệm của bài toán này là duy nhất, nghiệm đối ngẫu trở thành nghiệm nguyên thủy MATH . Điều này rất hữu ích khi việc giải bài toán đối ngẫu dễ dàng hơn việc giải trực tiếp bài toán nguyên thủy. Ví dụ từ B & V trang 249: > MATH > MATH \\begin align > g v &= \\min x \\sum i=1 ^n f i x i + v b−a^Tx \\\\\\ > &= bv + \\min x \\sum i=1 ^n f i x i −va^Tx \\\\\\ > &= bv + \\min x \\sum i=1 ^n f i x i −v \\sum i=1 ^n a ix i \\\\\\ > &= bv + \\sum i=1 ^n \\underbrace \\min x i \\ f i x i − a ivx i \\ -f^ i a iv \\\\\\ > &= bv − \\sum i=1 ^n f^ i a iv > \\end align MATH Ở đây MATH biểu thị hàm liên hợp của MATH . Do đó, bài toán đối ngẫu có thể được biểu diễn như sau: > MATH Ngoài ra, bằng cách nhân với dấu âm - , bài toán cực đại có thể được biểu diễn thành bài toán cực tiểu sau: > MATH Đây là một bài toán tối ưu hóa lồi với các biến vô hướng có thể được giải dễ dàng hơn nhiều so với bài toán nguyên thủy. Khi MATH được cho, nghiệm nguyên thủy MATH có thể được giải như sau: > MATH Tính lồi chặt của mỗi MATH có nghĩa là bài toán này có nghiệm duy nhất. Tức là, MATH được thu được thông qua tính toán MATH cho mỗi MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter13/13_02_Solving_the_primal_via_the_dual/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter13/13_03_Dual_norms",
    "title": "13-03 Chuẩn đối ngẫu",
    "chapter": "13",
    "order": 4,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Hãy xem xét một chuẩn tùy ý MATH : > MATH > > MATH Chuẩn đối ngẫu của chuẩn MATH được ký hiệu là MATH và được định nghĩa như sau: > MATH Giả sử tồn tại một MATH tùy ý nào đó. Khi đó khi ta đặt MATH , ta có MATH . Ngoài ra, MATH đúng, do đó một dạng tương tự như bất đẳng thức Cauchy-Schwartz MATH được thiết lập. Hãy xem xét các ví dụ về chuẩn đối ngẫu trong các điều kiện cụ thể: > MATH > > MATH Chứng minh > Hãy chứng minh rằng điều sau đây đúng cho đối ngẫu chuẩn MATH : > > MATH > > Chứng minh > > MATH > > Trong khi đó, theo bất đẳng thức Holder, điều sau đây đúng: > > MATH > > Từ 1 ở trên, mối quan hệ sau đây đúng: > > MATH > > Do đó, nếu ta tìm được MATH sao cho MATH và MATH thỏa mãn MATH , ta có thể thấy rằng MATH đúng. > > Trong khi đó, nếu ta đặt MATH và MATH , thì MATH > thỏa mãn MATH , và ta có thể xác nhận rằng MATH . > > Do đó, điều sau đây đúng: > > MATH Chuẩn đối ngẫu của chuẩn đối ngẫu trở thành chuẩn gốc. > MATH Hãy xem xét bài toán sau: > MATH Khi giá trị tối ưu là MATH , Lagrangian được biểu diễn như sau: > MATH Khi biểu diễn theo chuẩn đối ngẫu MATH , nó trở thành: > MATH > > MATH Note > MATH > > MATH > > MATH > > MATH > > MATH MATH with MATH > > MATH MATH > > MATH > > MATH > > MATH > > dual problem > > MATH Do đó, bài toán đối ngẫu Lagrange như sau: > MATH Vì không có ràng buộc bất đẳng thức, điều kiện Slater được thỏa mãn, và theo đối ngẫu mạnh, MATH . Tức là, MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter13/13_03_Dual_norms/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter13/13_04_Conjugate_function",
    "title": "13-04 Hàm liên hợp",
    "chapter": "13",
    "order": 5,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Với một hàm cho trước MATH , hàm liên hợp MATH được định nghĩa như sau: > MATH Fig1 Illustration of conjugate function 1 Lưu ý MATH luôn là hàm lồi vì nó là cực đại điểm của các hàm lồi affine MATH . Ở đây, MATH không nhất thiết phải là hàm lồi. MATH là khoảng cách cực đại giữa hàm tuyến tính MATH và MATH . Từ B & V trang 91 Phép liên hợp cho MATH khả vi được gọi là biến đổi Legendre. Tính chất: • Bất đẳng thức Fenchel: với mọi MATH > MATH > MATH • Hàm liên hợp của hàm liên hợp là MATH , do đó MATH luôn đúng. • Nếu MATH đóng và lồi, thì MATH . • Nếu MATH đóng và lồi, thì với mọi MATH , điều sau đây đúng: > MATH \\begin align > x ∈ ∂f^ ∗ y &\\iff y ∈ ∂f x \\\\\\ > &\\iff f x + f^ ∗ y = x^Ty \\\\\\ > \\end align MATH • Nếu MATH , thì MATH đúng. Ví dụ: • Hãy xem xét trường hợp MATH là một hàm bậc hai đơn giản như sau: > MATH , trong đó MATH Khi đó MATH là hàm lõm chặt theo MATH và đạt cực đại tại MATH . Tức là, MATH . Chứng minh > MATH \\begin align > f^ y & = \\max x \\left y^Tx -\\frac 1 2 x^TQx \\right \\\\\\ > & = -\\min x \\left \\frac 1 2 x^TQx- y^Tx \\right , x^ \\star = Q^ -1 y \\\\\\ > & = -\\frac 1 2 y^TQ^ -1 QQ^ -1 y + y^TQ^ -1 y \\\\\\ > & = \\frac 1 2 y^TQ^ -1 y \\\\\\ > \\end align MATH > Bất đẳng thức Fenchel: với mọi MATH > MATH • Hàm chỉ thị: Nếu MATH , thì hàm liên hợp của nó như sau: > MATH được gọi là hàm hỗ trợ của MATH • Chuẩn: Nếu MATH , thì hàm liên hợp của nó như sau: > MATH trong đó MATH là chuẩn đối ngẫu của MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter13/13_04_Conjugate_function/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter13/13_04_01_Example_lasso_dual",
    "title": "13-04-01 Ví dỡ đối ngẫu lasso",
    "chapter": "13",
    "order": 6,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Hãy xem xét bài toán lasso với MATH : > MATH > > MATH > > MATH > > MATH Hàm đối ngẫu của bài toán trên là hằng số = MATH . Do đó, chúng ta có thể biến đổi bài toán nguyên thủy như sau: > MATH Hàm đối ngẫu của bài toán đã biến đổi là: > MATH \\begin align > g u &= \\min \\beta,z \\frac 1 2 \\| y-z \\|^2 2 + \\lambda \\| \\beta \\| 1 + u^T z-X\\beta \\\\ > &= \\frac 1 2 \\| y \\|^2 2 - \\frac 1 2 \\| y-u \\|^2 2 - I \\ v : \\| v \\| \\infty \\leq 1 \\ X^Tu/\\lambda \\\\ > \\end align MATH > Chứng minh > MATH \\begin align > g u &= \\min \\beta,z \\frac 1 2 \\| y-z \\|^2 2 + \\lambda \\| \\beta \\| 1 + u^T z-X\\beta \\\\ > &= \\underbrace \\left \\min z \\frac 1 2 \\| y - z \\|^2 2 + u^Tz \\right 1 + \\underbrace \\left \\min \\beta \\lambda \\| \\beta \\| 1 + u^TX\\beta \\right 2 \\\\ > \\end align MATH > > MATH > > MATH \\begin align > 1 \\cdots \\left \\min z \\frac 1 2 \\| y - z \\|^2 2 + u^Tz \\right > &= \\frac 1 2 \\| u \\|^2 2 + u^T y - u \\\\ > &= -\\frac 1 2 \\| y - u \\|^2 2 + \\frac 1 2 \\| y \\|^2 2 \\\\ > \\end align MATH > MATH \\begin align > 2 \\cdots \\left \\min \\beta \\lambda \\| \\beta \\| 1 + u^TX\\beta \\right > &= - \\lambda \\max \\beta \\frac u^Tx \\lambda \\beta - \\| \\beta \\| 2 \\\\ > &= - \\lambda \\left \\| \\frac u^Tx \\lambda \\| \\infty \\leq 1 \\right \\\\ > &= - \\lambda \\left \\| u^Tx \\| \\infty \\leq \\lambda \\right \\\\ > \\end align MATH > \\therefore g u = -\\frac 1 2 \\| y - u \\|^2 2 + \\frac 1 2 \\| y \\|^2 2 + - \\lambda \\left \\| u^Tx \\| \\infty \\leq \\lambda \\right > = \\frac 1 2 \\| y \\|^2 2 - \\frac 1 2 \\| y-u \\|^2 2 - I \\ v : \\| v \\| \\infty \\leq 1 \\ X^Tu/\\lambda Do đó, bài toán đối ngẫu lasso là: > MATH Điều này tương đương với: > MATH Kiểm tra Điều kiện Slater được thỏa mãn, do đó đối ngẫu mạnh đúng. > MATH > > MATH Lưu ý Giá trị tối ưu trong bài toán trước không phải là giá trị mục tiêu lasso tối ưu. Tuy nhiên, nghiệm đối ngẫu MATH và nghiệm lasso MATH thỏa mãn MATH . Điều này được thỏa mãn bởi điều kiện dừng KKT MATH tức là, MATH . Do đó, lasso thỏa mãn phần dư đối ngẫu. Fig2 Lasso Dual 1",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter13/13_04_01_Example_lasso_dual/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter13/13_04_02_Conjugates_and_dual_problems",
    "title": "13-04-02 Hàm liên hợp và bài toán đối ngẫu",
    "chapter": "13",
    "order": 7,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Hàm liên hợp thường có thể được biểu diễn thông qua việc suy dẫn các bài toán đối ngẫu cho các bài toán tối thiểu hóa Lagrangian như sau: > MATH Ví dụ, hãy xem xét biểu thức sau: > MATH Biểu thức sau đây có thêm ràng buộc vào biểu thức trên và tương đương với nó: > MATH Chuyển đổi điều này thành hàm đối ngẫu Lagrange cho: > MATH Do đó, bài toán đối ngẫu của biểu thức gốc có thể được định nghĩa như sau: > MATH Ví dụ • Hàm chỉ thị: Đối ngẫu của MATH như sau: > MATH > > trong đó MATH là hàm hỗ trợ của MATH • Chuẩn: Đối ngẫu của MATH như sau: MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter13/13_04_02_Conjugates_and_dual_problems/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter13/13_04_03_Shifting_linear_transformations",
    "title": "13-04-03 Dịch chuyển biến đổi tuyến tính",
    "chapter": "13",
    "order": 8,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Công thức đối ngẫu giúp dịch chuyển các biến đổi tuyến tính giữa các phần của hàm mục tiêu và các miền khác. Hãy xem xét điều sau: > MATH Biểu thức sau tương đương: > MATH Điều này dẫn đến quá trình đối ngẫu sau: > MATH > MATH > MATH Và đối ngẫu là: > MATH Ví dụ Chuẩn và chuẩn đối ngẫu của chúng có mối quan hệ như sau: MATH , các bài toán > MATH > > MATH Biểu thức đầu tiên là nguyên thủy, và biểu thức thứ hai là đối ngẫu, có thể được giải trực tiếp.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter13/13_04_03_Shifting_linear_transformations/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter13/13_05_Dual_cones",
    "title": "13-05 Nón đối ngẫu",
    "chapter": "13",
    "order": 9,
    "owner": "",
    "lesson_type": "",
    "content": "Nón đối ngẫu Tồn tại một nón MATH . Nhắc lại nội dung đã đề cập trước đó trong 02-06-01 % multilang post url contents/chapter02/21-02-11-02 06 01 Dual cones % , điều này có nghĩa là MATH . > MATH Điều này được gọi là nón đối ngẫu , và nó luôn là một nón lồi ngay cả khi MATH không lồi . Fig3 Dual Cones 1 Lưu ý MATH Từ B & V trang 52 Một tính chất quan trọng ở đây là nếu MATH đóng và là nón lồi, thì MATH . Ví dụ: • Nón đối ngẫu của không gian con tuyến tính MATH là MATH , tức là phần bù trực giao. Ví dụ, MATH • Nón đối ngẫu của nón chuẩn MATH là nón chuẩn của chuẩn đối ngẫu của nó MATH . • Nón nửa xác định dương MATH là một nón lồi tự đối ngẫu, có nghĩa là MATH . Tại sao lại như vậy? Hãy xác minh: > MATH Phân tích trị riêng của MATH Nón đối ngẫu và bài toán đối ngẫu Xem xét bài toán có ràng buộc nón: > MATH Khi MATH là hàm hỗ trợ của MATH , bài toán đối ngẫu của biểu thức trên như sau: > MATH Khi MATH là một nón, điều này có thể được định nghĩa dễ dàng như sau: > MATH Ở đây MATH là nón đối ngẫu của MATH . vì MATH Điều này khá hữu ích vì nhiều loại ràng buộc khác nhau có thể xuất hiện dưới dạng ràng buộc nón.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter13/13_05_Dual_cones/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter13/13_06_Dual_subtleties_Double_dual",
    "title": "13-06 Tinh tế đối ngẫu & Đối ngẫu kép",
    "chapter": "13",
    "order": 10,
    "owner": "Wontak Ryu",
    "lesson_type": "",
    "content": "Tinh tế đối ngẫu • Đôi khi chúng ta có thể biến đổi các bài toán đối ngẫu thành các bài toán tương đương và vẫn gọi chúng là bài toán đối ngẫu. Ngoài ra, trong đối ngẫu mạnh, chúng ta có thể sử dụng nghiệm của các bài toán đối ngẫu đã biến đổi để phân tích hoặc tính toán các đặc trưng của nghiệm nguyên thủy. Lưu ý Giá trị tối ưu của một bài toán đối ngẫu đã biến đổi không nhất thiết là giá trị tối ưu của nguyên thủy. • Một cách phổ biến để suy dẫn các bài toán đối ngẫu cho các bài toán không ràng buộc là đầu tiên biến đổi nguyên thủy bằng cách thêm các biến giả và ràng buộc đẳng thức. Nói chung, cách thực hiện điều này là mơ hồ. Các lựa chọn khác nhau có thể dẫn đến các bài toán đối ngẫu khác nhau. Đối ngẫu kép Hãy xem xét một bài toán tối thiểu hóa tổng quát với ràng buộc tuyến tính: > MATH Lagrangian như sau: > MATH Do đó, bài toán đối ngẫu như sau: > MATH Nhắc lại tính chất Nếu MATH đóng và lồi, chúng ta đã giải thích trước đó rằng đối ngẫu của đối ngẫu là nguyên thủy trong trường hợp này MATH . Trên thực tế, mối liên hệ giữa đối ngẫu và liên hợp đối ngẫu đi sâu hơn nhiều ngoài các ràng buộc tuyến tính. Xem xét điều sau: > MATH >\\begin align > & \\min x && f x \\\\ > &\\text với điều kiện && h i x ≤ 0, i = 1,...m \\\\ > &&&l j x = 0, j = 1,...r >\\end align MATH Nếu MATH và MATH đóng và lồi, và MATH là affine, thì đối ngẫu của đối ngẫu là nguyên thủy. Điều này được cung cấp như một bài toán tối thiểu hóa từ góc độ của các hàm hai biến. để biết thêm, đọc Chương 29 và 30 của Rockafellar",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter13/13_06_Dual_subtleties_Double_dual/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_newton_method",
    "title": "14 Phương pháp Newton",
    "chapter": "14",
    "order": 1,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Trong chương này, chúng ta sẽ tìm hiểu về Phương pháp Newton. Phương pháp Newton là một cách tiếp cận để tìm giá trị nhỏ nhất của một hàm số có đạo hàm bậc hai bằng cách sử dụng khai triển Taylor bậc hai. Phương pháp này tìm giá trị tối ưu bằng cách xấp xỉ hàm số và cập nhật nghiệm một cách lặp đi lặp lại. Gần điểm tối ưu, nó đạt được sự hội tụ bậc hai và nhanh hơn nhiều so với phương pháp gradient descent. Tài liệu tham khảo và đọc thêm S. Boyd and L. Vandenberghe 2004 , \"Convex optimization\", Chapter 9 and 10 Y. Nesterov 1998 , \"Introductory lectures on convex optimization: a basic course\", Chapter 2 Y. Nesterov and A. Nemirovskii 1994 , \"Interior-point polynomial methods in convex programming\", Chapter 2 J. Nocedal and S. Wright 2006 , \"Numerical optimization\", Chapters 6 and 7 L. Vandenberghe, Lecture notes for EE 236C, UCLA, Spring 2011-2012",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_newton_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_01_newton_method",
    "title": "14-01 Phương pháp Newton",
    "chapter": "14",
    "order": 2,
    "owner": "Minjoo Lee",
    "lesson_type": "required",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Các phương pháp gradient descent mà chúng ta đã thảo luận được gọi là phương pháp bậc nhất vì các nghiệm dựa trên đạo hàm bậc nhất của hàm số. Phương pháp Newton là một phương pháp bậc hai , có nghĩa là nghiệm yêu cầu tính toán đạo hàm bậc hai. Hãy xem xét một bài toán tối ưu hóa cho hàm số MATH không có ràng buộc, khả vi hai lần, lồi, và có dom MATH = MATH . > MATH >\\begin align >\\min x f x >\\end align > MATH Trong Gradient descent % multilang post url contents/chapter06/21-03-20-06 00 gradient descent % , chúng ta đã thực hiện quy trình sau đây cho hàm số MATH : 1. Thực hiện xấp xỉ Taylor bậc hai 2. Giả sử ma trận Hessian tương ứng với số hạng đạo hàm bậc hai là MATH , tức là ma trận đơn vị chia cho t kích thước bước 3. Thực hiện xấp xỉ bậc hai để tiến hành bước cập nhật Quy trình chi tiết được giải thích trong bước cập nhật gradient descent ở trang tiếp theo. Công thức bước cập nhật tại mỗi lần lặp như sau: > MATH >\\begin align >&\\text chọn giá trị khởi tạo x^ 0 \\in \\mathbb R ^ n ,\\\\\\\\ >&x^ k = x^ k-1 - t k \\cdot \\nabla f x^ k-1 , \\qquad k = 1,2,3,... >\\end align > MATH Phương pháp Newton phương pháp Newton thuần túy thực sự tính toán số hạng đạo hàm bậc hai mà được giả sử là MATH trong gradient descent, thực hiện xấp xỉ bậc hai, và tiến hành bước cập nhật. Quy trình này cũng được giải thích trong bước cập nhật phương pháp Newton ở trang tiếp theo. Công thức bước cập nhật tại mỗi lần lặp như sau: > MATH >\\begin align >&\\text chọn giá trị khởi tạo x^ 0 \\in \\mathbb R ^ n ,\\\\\\\\ >&x^ k = x^ k-1 - \\Big \\nabla^ 2 f x^ k-1 \\Big ^ -1 \\nabla f x^ k-1 , \\qquad k = 1,2,3,... >\\end align > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_01_newton_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_02_interpretation_and_properties",
    "title": "14-02 Giải thích và Tính chất",
    "chapter": "14",
    "order": 4,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Trong chương này, trước khi xem xét các tính chất của phương pháp Newton, chúng ta tìm hiểu về việc áp dụng phương pháp Newton vào các bài toán tìm nghiệm của các hàm mục tiêu. Tiếp theo, chúng ta sẽ xem xét hai tính chất quan trọng của phương pháp Newton: Bất biến affine và Hội tụ cục bộ.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_02_interpretation_and_properties/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_02_01_root_finding",
    "title": "14-02-01 Tìm nghiệm",
    "chapter": "14",
    "order": 5,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Trong chương này, chúng ta áp dụng phương pháp Newton vào bài toán tìm nghiệm. Phương pháp Newton được sử dụng trong các bài toán tối ưu hóa có một số khác biệt, được giải thích ở đây. Newton's method in optimization https://en.wikipedia.org/wiki/Newton%27s method in optimization Newton's method in root finding https://en.wikipedia.org/wiki/Newton%27s method Phương pháp Newton cho tìm nghiệm Giả sử chúng ta có một hàm vector MATH . Bài toán tìm nghiệm là tìm MATH sao cho MATH . > MATH >\\begin align >F x = 0. >\\end align > MATH Bài toán này được giải quyết bằng cách chọn một giá trị khởi tạo MATH và áp dụng phương pháp Newton một cách lặp đi lặp lại: > MATH >\\begin align >&\\text chọn giá trị khởi tạo x^ 0 \\in \\mathbb R ^ n ,\\\\\\\\ >&x^ k =x^ k-1 -\\nabla F x^ k-1 ^ -1 F x^ k-1 , \\qquad k=1,2,3,...\\\\\\\\ >\\end align > MATH Ở đây, MATH là ma trận Jacobian của MATH tại MATH . Bước Newton MATH có thể được dẫn xuất bằng cách sử dụng xấp xỉ tuyến tính của MATH : > MATH >\\begin align >F y \\approx F x + F^ ' x y-x = 0\\\\\\\\ >y = x^ + =x-F^ ' x ^ -1 F x . >\\end align > MATH Phương pháp Newton cho bài toán tối ưu hóa Giả sử chúng ta áp dụng phương pháp Newton vào một bài toán tối ưu hóa được công thức hóa như sau: > MATH >\\begin align >\\min x F x >\\end align > MATH Điều này tương đương với việc áp dụng phương pháp Newton vào bài toán tìm nghiệm cho gradient MATH của hàm mục tiêu MATH . Tóm lại, không giống như bài toán tìm nghiệm của đạo hàm của một hàm cho trước MATH bằng phương pháp Newton trong các bài toán tối ưu hóa, bài toán tìm nghiệm yêu cầu tìm nghiệm của chính giá trị hàm MATH bằng phương pháp Newton. Điều này dẫn đến sự khác biệt một bậc trong số hạng đạo hàm trong công thức cập nhật cho MATH trong phương pháp Newton cho mỗi bài toán. Ví dụ tìm nghiệm Xem xét một hàm MATH được định nghĩa như sau: > MATH >\\begin align >F x =x^ 2 -2 >\\end align > MATH Bắt đầu với một giá trị khởi tạo MATH , chúng ta áp dụng phương pháp Newton thuần túy, thu được các kết quả sau: Hình 1 Phương pháp Newton được áp dụng trên ví dụ 3 Khi số lần lặp MATH tăng lên, chúng ta có thể thấy rằng giá trị của MATH tiến gần đến nghiệm MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_02_01_root_finding/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_02_02_affine_invariance_of_newton_method",
    "title": "14-02-02 Tính bất biến affine của phương pháp Newton",
    "chapter": "14",
    "order": 6,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Một trong những tính chất quan trọng của phương pháp Newton là nó bất biến affine. Điều này có nghĩa là hướng của việc cập nhật không phụ thuộc vào các phép biến đổi affine của hệ tọa độ. Ví dụ, gradient descent biến thiên theo các phép biến đổi affine, do đó tốc độ hội tụ khác nhau tùy thuộc vào không gian tọa độ. Trang này dẫn xuất tính chất bất biến affine. Tính bất biến affine : chứng minh Cho MATH khả vi hai lần, và cho MATH không suy biến. Cũng định nghĩa MATH là MATH . MATH . Điều này có nghĩa là một hàm MATH nào đó nhận MATH làm đầu vào có cùng đầu ra như hàm MATH nhận MATH biến đổi affine bởi MATH đối với MATH làm đầu vào. Để giảm thiểu sự nhầm lẫn về ký hiệu và đối số gradient, chúng ta định nghĩa MATH . Sử dụng quy tắc chuỗi để lấy đạo hàm cả hai vế một lần và hai lần, chúng ta nhận được các kết quả sau: > MATH >\\begin align >\\nabla g y &= A^ T \\nabla f x \\\\\\\\ >\\nabla^ 2 g y &= A^ T \\nabla^ 2 f x A, >\\end align > MATH Bước Newton của MATH đối với MATH như sau: > MATH >\\begin align >y^ + = y- \\nabla^ 2 g y ^ -1 \\nabla g y . >\\end align > MATH Ở đây, thay vì hàm MATH , nếu chúng ta biến đổi và sắp xếp nó theo hàm MATH đối với MATH , chúng ta có thể dẫn xuất bước Newton cho MATH và MATH . > MATH >\\begin align >y^ + &= y- A^ T \\nabla^ 2 f x A ^ -1 A^ T \\nabla f x \\\\\\\\ >\\Leftrightarrow y^ + &= y-A^ -1 \\nabla^ 2 f x ^ -1 A^ T ^ -1 A^ T \\nabla f x \\\\\\\\ >\\Leftrightarrow Ay^ + &= Ay- \\nabla^ 2 f x ^ -1 \\nabla f x \\\\\\\\ >\\Leftrightarrow x^ + &= x - \\nabla^ 2 f x ^ -1 \\nabla f x . >\\end align > MATH Điều này có nghĩa là bước Newton là bất biến affine, tức là, các cập nhật trong các hệ tọa độ được biến đổi bởi các phép biến đổi affine được biểu diễn bởi các ma trận không suy biến là giống hệt nhau. Sử dụng cùng phương pháp để kiểm tra tính bất biến affine của gradient descent bằng cách dẫn xuất cập nhật bước, chúng ta có thể thu được kết quả sau: > MATH >\\begin align >y^ + &= y-t k \\cdot \\nabla g y \\\\\\\\ >\\Leftrightarrow y^ + &= y-t k \\cdot \\nabla f x A^ T \\\\\\\\ >\\Leftrightarrow x^ + &= x - t k \\cdot A\\nabla f x A^ T . >\\end align > MATH Trong trường hợp của gradient descent, vì ma trận Hessian được xấp xỉ là MATH cho các cập nhật, chúng ta có thể thấy rằng hướng của cập nhật thay đổi đối với các tọa độ được biến đổi affine.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_02_02_affine_invariance_of_newton_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_03_newton_decrement",
    "title": "14-03 Newton decrement",
    "chapter": "14",
    "order": 7,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Trong chương này, chúng ta định nghĩa Newton decrement và xem xét ý nghĩa của nó. Đối với bài toán tối ưu hóa dưới đây, Newton decrement tại MATH được định nghĩa là MATH : >\\begin align >\\min x \\quad f x ,\\\\\\\\ >\\end align >\\begin align >\\lambda x = \\nabla f x ^ T \\nabla^ 2 f x ^ -1 \\nabla f x ^ 1/2 . >\\end align Đặc điểm của Newton decrement Thứ nhất, Newton decrement liên quan đến sự khác biệt giữa hàm MATH và giá trị tối thiểu của xấp xỉ bậc hai của nó. Tính toán sự khác biệt này cho: > MATH \\begin align >f x -&\\min y \\big f x +\\nabla f x ^ T y-x +\\frac 1 2 y-x ^ T \\nabla^ 2 f x y-x \\big ,\\\\\\\\ >f x -&\\bigg f x + \\nabla^ T f x \\big - \\nabla^ 2 f x ^ -1 \\nabla f x \\big + \\frac 1 2 \\big - \\nabla^ 2 f x ^ -1 \\nabla f x \\big ^ T \\nabla ^ 2 f x \\big - \\nabla^ 2 f x ^ -1 \\nabla f x \\big \\bigg \\\\\\\\ >&= \\frac 1 2 \\nabla f x ^ T \\nabla^ 2 f x ^ -1 \\nabla f x = \\frac 1 2 \\lambda x ^ 2 . >\\end align MATH Do đó, MATH có thể được coi là một cận xấp xỉ cho khoảng cách tối ưu MATH . Thứ hai, hướng Newton trong phương pháp Newton cho mỗi lần lặp là MATH , và Newton decrement là độ dài của bước Newton trong chuẩn được định nghĩa bởi Hessian MATH . Ngoài ra, điều này có thể được xem là một loại khoảng cách Mahalanobis Wikipedia https://en.wikipedia.org/wiki/Mahalanobis distance , trong đó bước mới MATH là quan sát, vị trí hiện tại MATH là giá trị trung bình, và Hessian của MATH là hiệp phương sai. Khoảng cách Mahalanobis đo khoảng cách từ một điểm đến giá trị trung bình theo hướng của hiệp phương sai của phân phối. Nếu chúng ta xem xét định nghĩa khoảng cách Mahalanobis là khoảng cách giữa một điểm và giá trị trung bình của một phân phối chia cho độ lệch chuẩn theo hướng đó, Newton decrement biểu diễn khoảng cách của bước mới từ vị trí hiện tại, với Hessian đóng vai trò là hiệp phương sai của phân phối. Thứ ba, Newton decrement có thể được biểu diễn theo số gia và Hessian. Bắt đầu từ cập nhật bước trong phương pháp Newton, chúng ta có: >\\begin align >x^ + &= x-\\big \\nabla^ 2 f x \\big ^ -1 \\nabla f x &\\\\ >\\end align >\\begin align >\\Delta x nt &= -\\big \\nabla^ 2 f x \\big ^ -1 \\nabla f x &\\\\ >\\end align >\\begin align >\\nabla f x ^ T \\Delta x nt &= -\\lambda x ^ 2 >\\end align Sử dụng các mối quan hệ này, Newton decrement cũng có thể được biểu diễn là: >\\begin align >\\lambda x = \\Delta x nt ^ T \\nabla^ 2 f x \\Delta x nt ^ 1/2 . >\\end align Cuối cùng, giống như bước Newton, Newton decrement cũng bất biến affine. Nói cách khác, đối với bất kỳ ma trận không suy biến nào, nếu hàm MATH được định nghĩa, thì tại MATH , ta có MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_03_newton_decrement/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_04_backtracking_line_search",
    "title": "14-04 Tìm kiếm đường backtracking",
    "chapter": "14",
    "order": 8,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Cho đến nay, chúng ta đã xem xét phương pháp Newton thuần túy. Tuy nhiên, phương pháp này không đảm bảo hội tụ, vì vậy chúng ta sử dụng tìm kiếm đường backtracking để đảm bảo hội tụ trong phương pháp Newton có giảm chấn. Phương pháp Newton có giảm chấn Phương pháp Newton thuần túy áp dụng lặp đi lặp lại cập nhật sau ở đây MATH : >\\begin align >x^ + = x -t \\nabla^ 2 f x ^ -1 \\nabla f x . >\\end align Phương pháp Newton có giảm chấn sử dụng tìm kiếm đường backtracking. Nếu giá trị hàm tại vị trí được cập nhật lớn hơn xấp xỉ bậc hai, chúng ta thu nhỏ kích thước bước MATH : > MATH \\begin align >&\\text với các tham số 0 &\\text trong khi f x+tv >f x +\\alpha t \\nabla f x ^ T v\\\\ >&\\text thu nhỏ t=\\beta t >\\end align MATH Here, MATH and MATH . Ví dụ: hồi quy logistic Làm ví dụ, đối với hồi quy logistic với n = 500, p = 100, chúng ta so sánh tốc độ hội tụ của gradient descent và phương pháp Newton với tìm kiếm đường backtracking. Hình 1 Hồi quy logistic 3 Phương pháp Newton cho thấy tốc độ hội tụ nhanh hơn nhiều so với gradient descent. Từ chương tiếp theo, chúng ta sẽ xem xét tốc độ hội tụ này.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_04_backtracking_line_search/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_05_convergence_analysis",
    "title": "14-05 Phân tích hội tụ",
    "chapter": "14",
    "order": 9,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Cho đến nay, chúng ta đã xem xét phương pháp Newton thuần túy, chỉ có tính chất hội tụ cục bộ, và phương pháp Newton có giảm chấn phương pháp Newton với tìm kiếm đường backtracking , áp dụng tìm kiếm đường backtracking để đảm bảo hội tụ toàn cục khi lồi. Trong chương này, chúng ta phân tích tốc độ hội tụ của phương pháp Newton có giảm chấn. Đối với phương pháp Newton có giảm chấn, chúng ta xem xét các cận hội tụ được chia thành hai giai đoạn: giai đoạn mà backtracking được áp dụng giai đoạn giảm chấn: tiến bộ chậm và giai đoạn hội tụ cục bộ mà backtracking không còn cần thiết giai đoạn thuần túy: hội tụ bậc hai . Conditions of MATH for convergence analysis Assume that MATH is convex, twice differentiable, has MATH , and satisfies the following three conditions: 1. MATH is Lipschitz continuous with parameter L. > MATH \\begin align >\\|\\nabla f x - \\nabla f y \\| 2 \\leq L\\|x-y\\| 2 \\quad \\forall x,y. >\\end align MATH 2. MATH is strongly convex with parameter m. Relationship between upper bound MATH and Lipschitz continuous: source https://xingyuzhou.org/blog/notes/strong-convexity , this book: 06-03-05 % multilang post url contents/chapter06/21-03-20-06 03 05 look at the conditions and practicalities % > MATH \\begin align >mI\\preceq\\nabla^ 2 f x \\preceq LI. >\\end align MATH 3. MATH is Lipschitz continuous with parameter M. > MATH \\begin align >\\|\\nabla^ 2 f x -\\nabla^ 2 f y \\| 2 \\leq M\\|x-y\\| 2 \\quad \\forall x,y. >\\end align MATH Convergence analysis If the above three conditions are satisfied, for MATH satisfying MATH , the convergence for each phase can be obtained as follows: >Phase I : \"Damped\" phase, MATH , > > MATH \\begin align >f x^ k+1 -f x^ k \\leq -\\gamma >\\end align MATH > >Phase 2 : \"Pure\" phase, MATH \\|\\nabla f x^ k \\| 2 > MATH \\begin align >\\frac M 2m^ 2 \\|\\nabla f x^ k+1 \\| 2 \\leq \\bigg \\frac M 2m^ 2 \\|\\nabla f x^ k \\| 2 \\bigg ^ 2 . >\\end align MATH Note that once the Pure phase is reached when MATH \\begin align >\\require cancel >& &\\cancel f x^ 1 -f x^ 0 \\leq -\\gamma \\\\\\\\ >& &\\cancel f x^ 2 -\\cancel f x^ 1 \\leq -\\gamma \\\\\\\\ >& &\\vdots \\\\\\\\ >&+ &f x^ k -\\cancel f x^ k-1 \\leq -\\gamma \\\\\\\\ >&= &f x^ k -f x^ 0 \\leq -k\\gamma. >\\end align MATH Subtracting MATH from both sides, we can obtain the following result. Let MATH be the first MATH that satisfies MATH \\begin align >f x^ k -f^ \\star \\geq f x^ 0 -f^ \\star -\\gamma k \\qquad \\text if k \\geq k 0 >\\end align MATH For Phase 2, assume that iteration starts from MATH and proceeds for MATH steps. Also, using MATH \\begin align >& &\\frac M 2m^ 2 \\|\\nabla f^ k 0 +1 \\| 2 \\leq \\big \\frac M 2m^ 2 \\|\\nabla f^ k 0 \\| 2 \\big ^ 2 .\\\\\\\\ >&\\Leftrightarrow &\\frac M 2m^ 2 \\|\\nabla f^ k 0 + k-k 0 \\| 2 \\leq \\bigg \\big \\frac M 2m^ 2 \\|\\nabla f^ k 0 +1 \\| 2 \\big ^ 2 \\bigg ^ k-k 0 \\leq \\frac 1 2 ^ 2^ k-k 0 .\\\\\\\\ >&\\Leftrightarrow &f y \\geq f x +\\nabla f x ^ T y-x +\\frac m 2 \\|y-x\\|^ 2 2 \\geq f x -\\frac 1 2m \\|\\nabla f x \\|^ 2 2 , \\text for all y,\\\\\\\\ >&\\Leftrightarrow &f x^ k -f^ \\star \\leq \\frac 1 2m \\|\\nabla f x^ k \\| 2 ^ 2 \\leq \\frac 2m^ 3 M^ 2 \\frac 1 2 ^ 2^ k-k 0 +1 . >\\end align MATH Therefore, we can organize the convergence according to steps with the MATH -th iteration as the branch point as follows: >Theorem: Newton's method using backtracking line search has two-stage convergence bounds. > MATH \\begin align >&f x^ k -f^ \\star \\leq \\begin cases f x^ 0 -f^ \\star -\\gamma k \\qquad &\\text if k\\leq k 0 \\\\ \\frac 2m^ 3 M^ 2 \\frac 1 2 ^ 2^ k-k 0 +1 \\qquad &\\text if k>k 0 . \\end cases >\\end align MATH >Here, MATH , MATH , and MATH is the step where MATH y=x+t\\Delta x nt MATH f MATH and apply the upper bound of the Lipschitz condition. > > MATH \\begin align >f x+t\\Delta x nt \\leq f x +t\\nabla f x ^ T \\Delta x nt + \\frac L \\|\\Delta x nt \\|^ 2 2 2 t^ 2 , >\\end align MATH > Newton decrement, 증분과 hessian matrix와의 관계와 Strong convexity의 관계를 이용하여 다음과 같이 전개할 수 있다. > > MATH \\begin align >&\\text Since, \\lambda x ^ 2 =\\Delta x nt ^ T \\nabla^ 2 f x \\geq m\\|\\Delta x nt \\|^ 2 2 ,\\\\\\\\ >&f x +t\\nabla f x ^ T \\Delta x nt + \\frac L \\|\\Delta x nt \\|^ 2 2 2 t^ 2 \\leq f x -t\\lambda x ^ 2 + \\frac L 2m t^ 2 \\lambda x ^ 2 , >\\end align MATH > >이 때, backtracking line search의 조건을 만족하기 위해서는 아래를 만족해야 한다. > > MATH \\begin align >f x+t\\Delta x nt \\leq f x - 1-\\frac L 2m t t \\lambda x ^ 2 , \\qquad \\text where, 0 \\end align MATH > >위를 만족하는 t의 최소값을 MATH 라 할 때, MATH 이 되고, 이를 원 식에 대입하면 다음과 같다. > > MATH \\begin align >f x+\\hat t \\Delta x nt \\leq f x -\\frac m 2L \\lambda x ^ 2 \\leq f x -\\alpha \\hat t \\lambda x ^ 2 , >\\end align MATH > >backtracking line search에서 MATH 0 > MATH \\begin align >f x^ + -f x &\\leq -\\alpha t \\lambda x ^ 2 \\\\ > &\\leq -\\alpha\\beta \\frac m L \\lambda x ^ 2 \\\\ > &\\leq -\\alpha\\beta \\frac m L^ 2 \\|\\nabla f x \\|^ 2 2 \\\\ > &\\leq -\\alpha\\beta \\eta^ 2 \\frac m L^ 2 ,\\\\ > &\\gamma = \\alpha\\beta \\eta^ 2 \\frac m L^ 2 . >\\end align MATH Proof 2. Pure phase 이제 MATH \\|\\nabla f x \\| 2 Backtracking line search로 부터 다음과 같은 식이 유도된다. > > MATH \\begin align >\\eta \\leq 3 1-2\\alpha \\frac m^ 2 M . >\\end align MATH > >또한, Lipschitz condition에 따라 MATH 에 대하여, 다음 조건을 만족한다. > > MATH \\begin align >\\|\\nabla^ 2 f x+t\\Delta x nt -\\nabla^ 2 f x \\| 2 \\leq tM \\|\\Delta x nt \\| 2 ,\\\\ >| \\Delta x nt ^ T \\big \\nabla^ 2 f x+t\\Delta x nt -\\nabla^ 2 f x \\big \\Delta x nt | \\leq tM \\|\\Delta x nt \\| 2 ^ 3 . >\\end align MATH > > MATH 라 두면, MATH 이고, 이를 대입한다. > > MATH \\begin align >\\tilde f '' t \\leq \\tilde f '' 0 +tM\\|\\Delta x nt \\|^ 3 2 \\leq tM\\|\\Delta x nt \\|^ 3 2 >\\end align MATH > > MATH 이고, MATH 임을 이용하고, 부등식을 합친다. MATH 이므로 다음과 같이 정리할 수 있다. > > MATH \\begin align >\\tilde f '' t &\\leq \\tilde f '' 0 + tM \\| \\Delta x nt \\| ^ 3 2 \\leq \\lambda x ^ 2 + t\\frac M m^ 3/2 \\lambda x ^ 3 , \\\\ >\\tilde f ' t &\\leq \\tilde f ' 0 +t\\lambda x ^ 2 +t^ 2 \\frac M 2m^ 3/2 \\lambda x ^ 3 ,\\\\ >&= -\\lambda x ^ 2 +t\\lambda x ^ 2 + t^ 2 \\frac L 2m^ 3/2 \\lambda x ^ 3 . >\\end align MATH > >이제 양변을 적분한다. > > MATH \\begin align >\\tilde f t \\leq \\tilde f 0 - t\\lambda x ^ 2 + t^ 2 \\frac 1 2 \\lambda x ^ 2 + t^ 3 \\frac M 6m^ 3/2 \\lambda x ^ 3 . >\\end align MATH > >t = 1로 두면, 아래와 같은 결과를 얻을 수 있다. > > MATH \\begin align >f x+\\Delta x nt \\leq f x -\\frac 1 2 \\lambda x ^ 2 + \\frac M 6m^ 3/2 \\lambda x ^ 3 . >\\end align MATH > >이제 MATH 이라 가정하면, strong convexity 조건에 의해 MATH 이다. 이를 위에 부등식에 대입하면 아래와 같은 결과를 유도할 수 있다. > > MATH \\begin align >f x+\\Delta x nt &\\leq f x - \\lambda x ^ 2 \\frac 1 2 - \\frac M\\lambda x 6m^ 3/2 \\\\ > &\\leq f x -\\alpha \\lambda x ^ 2 \\\\ > &= f x + \\alpha \\nabla f x ^ T \\Delta x nt , >\\end align MATH > >이 결과는 MATH 일때 backtracking line search를 수행하더라도 항상 조건을 만족하기 때문에, MATH 를 감소시키지 않음을 의미한다. 이제 우리는 수렴속도가 quadratic하게 줄어듬을 증명해본다. > MATH 임을 이용한 뒤, 적분의 성질 중 하나인 MATH 를 이용하여 정리하고, Hessian의 Lipschitz 조건을 적분식에 적용하고 정리한다. 마지막으로 strong convexity 조건을 적용하면 증명이 완료된다. 과정을 수식으로 나타내면 아래와 같다. > > MATH \\begin align >\\| \\nabla f x^ + \\| 2 &= \\| \\nabla f x+\\Delta x nt - \\nabla f x - \\nabla^ 2 f x \\Delta x nt \\| 2 \\\\\\\\ >&=\\| \\int^ 1 0 \\big \\nabla^ 2 f x+t\\Delta x nt -\\nabla^ 2 f x \\big \\Delta x nt dt \\| 2 \\\\\\\\ > & \\leq \\frac M 2 \\|\\Delta x nt \\|^ 2 2 \\\\\\\\ > & = \\frac M 2 \\|\\nabla^ 2 f x ^ -1 \\nabla f x \\|^ 2 2 \\\\\\\\ > & \\leq \\frac M 2m^ 2 \\|\\nabla f x \\|^ 2 2 . >\\end align MATH 결론을 다시 정리하면, MATH 일 때, MATH \\begin align >\\frac f x^ 0 -p^ \\star \\gamma . >\\end align MATH pure Newton phase에서의 iteration 횟수의 bound 또한 계산할 수 있다. 위의 식을 MATH , MATH 로 두고, iteration 횟수로 식을 정리하면 다음과 같은 값을 계산할 수 있다. > MATH \\begin align >& &\\epsilon = \\epsilon 0 \\frac 1 2 ^ 2^ k-k 0 +1 \\\\\\\\ >&\\Leftrightarrow &\\frac \\epsilon 0 \\epsilon = 2^ 2^ k-k 0 +1 \\\\\\\\ >&\\Leftrightarrow &k-k 0 +1 = log 2 log 2 \\frac \\epsilon 0 \\epsilon >\\end align MATH 따라서 pure Newton phase에서 iteration 횟수는 MATH 로 bound 된다. 이 두 결과를 더하면, Newton method를 통하여 원하는 정밀도의 해를 얻는데 필요한 iteration 횟수의 upper bound를 정의할 수 있다. > MATH \\begin align >\\frac f x^ 0 -p^ \\star \\gamma + \\log \\log \\frac \\epsilon 0 \\epsilon . >\\end align MATH 문제를 해결할때 요구되는 정밀도 MATH 의 변화에 비해 우변의 두번째 항은 매우 작은 변화를 보이므로, 실제 응용에서는 이를 상수로 두고 추정을 하게 된다. 일반적으로 6번의 iteration은 MATH 의 정밀도를 보인다고 알려져 있다. 일반적으로 말해서, 목적함수 MATH 를 최소화하는데 있어서 필요한 iteration 횟수는 다음과 같다. > MATH \\begin align >\\frac f x^ 0 -p^ \\star \\gamma + 6. >\\end align MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_05_convergence_analysis/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_06_self_concordance",
    "title": "14-06 Tự hài hòa (Self concordance)",
    "chapter": "14",
    "order": 10,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Trong phân tích hội tụ trước đây của phương pháp Newton, có hai vấn đề chính. 1 Thứ nhất, trong các bài toán thực tế, rất khó tìm hằng số Lipschitz L, các cận dưới và trên của tính lồi mạnh m, M, v.v., được bao gồm trong các công thức. Vì điều này, trong khi chúng ta có thể quan sát sự hội tụ và tốc độ hội tụ, việc phân tích cần bao nhiêu bước Newton trong thực tế là gần như bất khả thi. Thứ hai, mặc dù bản thân phương pháp Newton là bất biến affine, nhưng phân tích hội tụ của phương pháp Newton không bất biến affine. Đối với các hàm tổng quát, giá trị của hằng số Lipschitz hoặc các cận tính lồi mạnh thay đổi tùy thuộc vào phép biến đổi tọa độ. Do đó, trong chương này, chúng ta giới thiệu các hàm tự hài hòa, giải quyết hai vấn đề trên. Các hàm tự hài hòa quan trọng và có ý nghĩa vì ba lý do chính: 1. Các hàm rào cản logarit được sử dụng trong các phương pháp điểm nội là các hàm tự hài hòa. 2. Trong phân tích phương pháp Newton cho các hàm tự hài hòa, các số hạng liên quan đến hằng số không xuất hiện. 3. Tính tự hài hòa là bất biến affine. Tức là, số lần lặp Newton cần thiết không phụ thuộc vào các phép biến đổi affine của hệ tọa độ.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_06_self_concordance/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_06_01_definition_of_self_concordant_functions",
    "title": "14-06-01 Định nghĩa các hàm tự hài hòa",
    "chapter": "14",
    "order": 11,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Tự hài hòa trên MATH Một hàm lồi MATH được định nghĩa là tự hài hòa khi nó thỏa mãn phương trình sau: > MATH \\begin align >\\|f^ ''' x \\| \\leq 2f^ '' x ^ 3/2 \\qquad \\text for all x\\in \\text dom f. >\\end align MATH Làm ví dụ đơn giản, các hàm tuyến tính MATH và các hàm bậc hai lồi là tự hài hòa vì giá trị đạo hàm bậc ba của chúng là 0. Tự hài hòa trên MATH Một hàm MATH được định nghĩa là tự hài hòa khi nó tự hài hòa cho bất kỳ đoạn thẳng nào trong miền, tức là, cho tất cả các đoạn thẳng được bao gồm trong miền. Ví dụ, đối với tất cả MATH và tất cả MATH , khi MATH được định nghĩa, nếu MATH là tự hài hòa, thì f được định nghĩa là một hàm tự hài hòa trong miền của MATH . Ví dụ về hàm tự hài hòa 1 MATH , MATH . Có thể dễ dàng xác minh rằng MATH . Hơn nữa, tổng của các hàm tự hài hòa cũng là tự hài hòa. Khi có các hàm tự hài hòa MATH , tổng của các hàm tự hài hòa cũng là tự hài hòa như được hiển thị dưới đây. 3 > MATH \\begin align >|f 1 ^ ''' x +f 2 ^ ''' x | \\leq & |f^ ''' 1 x |+|f^ ''' 2 x |\\\\\\\\ > \\leq &2\\big f^ '' 1 x ^ 3/2 +f^ '' 2 x ^ 3/2 \\big \\\\\\\\ >\\leq &2\\big f^ '' 1 x +f^ '' 2 x \\big ^ 3/2 . >\\end align MATH Bước cuối sử dụng tính chất sau: > MATH \\begin align > u^ 3/2 +v^ 3/2 ^ 2/3 \\leq u+v, \\qquad u, v \\geq 0. >\\end align MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_06_01_definition_of_self_concordant_functions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_06_02_convergence_analysis_for_self_concordant_functions",
    "title": "14-06-02 Phân tích hội tụ cho các hàm tự hài hòa",
    "chapter": "14",
    "order": 12,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Đối với các hàm tự hài hòa, kết quả phân tích hội tụ như sau: >Định lý Nesterov và Nemirovskii : Phương pháp Newton với tìm kiếm đường backtracking yêu cầu số lần lặp sau để đạt được MATH : >\\begin align >C \\alpha, \\beta \\big f x^ 0 -f^ \\star \\big + \\log\\log 1/\\epsilon , >\\end align >trong đó MATH là một hằng số phụ thuộc vào MATH . Chứng minh trên tương tự như phân tích hội tụ cho phương pháp Newton, nhưng sử dụng các tính chất của các hàm tự hài hòa để sắp xếp các bước. Xem 1 , tr.503",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_06_02_convergence_analysis_for_self_concordant_functions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_07_comparison_to_first_order_method",
    "title": "14-07 So sánh với phương pháp bậc nhất",
    "chapter": "14",
    "order": 13,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Trong chương này, chúng ta so sánh phương pháp Newton và gradient descent từ góc nhìn tổng quát. Giả sử chiều của miền là MATH . | Item | Newton's method | Gradient descent | | -------- | -------- | -------- | | Memory | MATH storage for MATH Hessian matrix | MATH storage for MATH -dimensional gradient | | Computation | MATH flops computation for MATH linear system | MATH flops computation for MATH -dimensional vector addition | | Backtracking | MATH | MATH | | Conditioning | Affine invariant, less affected by conditioning | Can be strongly affected by conditioning | | Fragility | Sensitive to bugs or numerical errors | More robust than Newton's method | Example Fig 1 Logistic regression 3 Figure 1 above is a logistic regression example discussed in 14-04 % multilang post url contents/chapter14/2021-03-26-14 04 backtracking line search % . If you plot the x-axis as actual computation time, you see the following. In convergence analysis, Newton's method has two phases. In practice, after a certain time, you can observe fast convergence quadratic convergence . In the initial damped phase of Newton's method, the convergence rate is similar to gradient descent. However, since MATH computation is required, the actual computation time may be slower. After backtracking line search is no longer needed, you observe quadratic convergence and very fast progress.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_07_comparison_to_first_order_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_08_special_cases",
    "title": "14-08 Các trường hợp đặc biệt",
    "chapter": "14",
    "order": 14,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Các bài toán thưa, có cấu trúc Nếu ma trận hệ tuyến tính trong bài toán là thưa và có cấu trúc, và Hessian có thể được tính toán hiệu quả, chúng ta có thể giải quyết bài toán hiệu quả hơn. For example, if MATH is sparse and structured for all MATH , such as a band matrix https://en.wikipedia.org/wiki/Band matrix , Newton's method can achieve MATH performance in memory and computation. A band matrix is a matrix where nonzero entries are only near the diagonal. Let's look at two typical examples of functions with structured Hessians: If MATH , then MATH . If MATH is a structured predictor matrix and MATH the Hessian of MATH is diagonal, then MATH is also structured. If MATH is diagonal and MATH is non-smooth, consider minimizing MATH , where MATH is a structured penalty matrix. The Lagrange dual is MATH . In general, MATH is also structured. Phương pháp Newton với ràng buộc đẳng thức Now let's look at optimization problems with equality constraints. Generally, we can approach this problem in three ways: > MATH \\begin align >&\\min x f x & \\text subject to Ax=b. >\\end align MATH 1 Reduced-space approach: Restrict the domain to the space satisfying the equality constraint. For the above problem, express MATH as MATH , where MATH spans the null space of MATH and MATH . Then solve for MATH . 2 Equality-constrained Newton's method: Similar to unconstrained Newton's method, but with two differences. First, the initial value must be feasible MATH and MATH . Second, the Newton step MATH must satisfy MATH . See below for details. 3 Dual approach: The Fenchel dual is MATH , and strong duality holds. 16-03 % multilang post url contents/chapter16/21-03-31-16 03 fenchel duality % covers this in detail. Use the conjugate function to solve the dual problem. Here, MATH is the conjugate of MATH . > MATH \\begin align >g v &= -b^ T v + \\min x f x +v^ T Ax \\\\\\\\ > &= -b^ T v - \\max x \\big -A^ T v ^ T x - f x \\big \\\\\\\\ > &= -b^ T v - f^ -A^ T v , >\\end align MATH This leads to the following dual problem: > MATH \\begin align >\\max -b^ T v-f^ -A^ T v . >\\end align MATH Assuming the optimal value exists, this problem is strictly feasible and satisfies Slater's condition. Therefore, as mentioned earlier, strong duality holds, and there exists a MATH such that MATH . 1, p.525 Now, let's examine the second method. To derive a feasible Newton step MATH , we replace the objective function in the original problem with a quadratic approximation around MATH . This can be expressed as: > MATH \\begin align >\\text minimize \\quad &\\hat f x+v = f x + \\nabla f x ^ T v + \\frac 1 2 v^ T \\nabla^ 2 f x v\\\\\\\\ >\\text subject to \\quad &A x+v = b, >\\end align MATH This can also be expressed as: > MATH \\begin align >x^ + = x + tv,\\,\\, \\text where \\\\\\\\ >v = \\underset A x+z =b \\operatorname argmin \\big f x +\\nabla f x ^ T z+\\frac 1 2 z^ T \\nabla^ 2 f x z \\big \\\\\\\\ >\\end align MATH Since MATH , the solution MATH remains within the constraint in the subsequent steps of the iteration. The KKT conditions for this problem can be expressed as follows, and by solving the linear system below, we can obtain the solution. Recall that MATH is the Newton step MATH . > MATH \\begin align >\\begin bmatrix > \\nabla^ 2 f x & A^ T \\\\\\\\ > A & 0 >\\end bmatrix >\\begin bmatrix >v\\\\\\\\ >w >\\end bmatrix >=- >\\begin bmatrix >\\nabla f x \\\\\\\\ >Ax-b >\\end bmatrix >\\end align MATH Here, MATH is the optimal dual variable for the above quadratic problem.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_08_special_cases/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter14/14_09_quasi_newton_methods",
    "title": "14-09 Các phương pháp Quasi-Newton",
    "chapter": "14",
    "order": 15,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Nếu việc tính toán Hessian quá đắt hoặc Hessian là suy biến, chúng ta sử dụng các phương pháp quasi-Newton để xấp xỉ ma trận Hessian, tức là, MATH được thay thế bởi MATH , và chúng ta sử dụng MATH cho cập nhật: >\\begin align >x^ + = x - tH^ -1 \\nabla f x >\\end align Một số đặc điểm của các phương pháp quasi-Newton như sau. Để biết thêm chi tiết, xem Chương 18 % multilang post url contents/chapter18/21-03-23-18 00 Quasi Newton methods % . Hessian xấp xỉ MATH được cập nhật ở mỗi bước. Mục tiêu là sử dụng tính toán tương đối rẻ cho MATH . Tốc độ hội tụ là siêu tuyến tính, nhưng không nhanh bằng phương pháp Newton. Thông thường, MATH bước của quasi-Newton tương đương với một bước của Newton về tiến bộ. Nhiều phương pháp quasi-Newton cập nhật MATH ở mỗi lần lặp sử dụng các kỹ thuật truyền.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter14/14_09_quasi_newton_methods/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter15/15_01_barrier_method_and_log_barrier_function",
    "title": "15-01 Barrier method and log barrier function",
    "chapter": "15",
    "order": 2,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; In the previous chapter, we explored how to solve an equality constrained smooth problem using Newton's method. In this chapter, we will look at methods for solving inequality and equality constrained smooth problems . The basic idea is to transform the problem into an equality constrained smooth problem and solve it using Newton's method. This approach is called the interior method , and in this chapter, we will focus on one type of interior method: the barrier method .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter15/15_01_barrier_method_and_log_barrier_function/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter15/15_01_01_inequality_constrained_minimization_problems",
    "title": "15-01-01 Inequality constrained minimization problems",
    "chapter": "15",
    "order": 3,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Let's consider the following convex optimization problem. > MATH \\begin align &\\min x && f x \\\\ &\\text subject to && Ax = b \\\\ &&& h i x \\leq 0, i = 1, \\dotsc, m \\end align MATH In problems that include inequalities like this, it is difficult to distinguish between binding and non-binding constraints, especially at the boundary of the feasible region. Binding constraints refer to the constraints that affect the solution. Therefore, the interior method is an approach that tries to solve the problem from the interior of the feasible region, not at the boundary. Background of interior method The interior method for general problems was proposed in the 1960s by Anthony V. Fiacco and Garth P. McCormick. At the time, it was overshadowed by popular methods like sequential quadratic programming and the active set method, and only gained attention in the 1980s. The active set method is a theory for determining which constraints affect the optimization result. In the active set method, a constraint is considered active if it is zero, and such constraints are called the active set. However, to find the active set, you need to compute the boundary of the feasible region, and as the number of constraints increases, the computational cost increases. Recognizing these issues, the interior point method was developed to solve problems from the interior rather than the boundary. For example, in LP, if there are MATH constraints, calculating the boundary requires MATH computations, but with the interior method, even for large MATH , the solution can be found within 20–30 Newton steps. More details on performance will be discussed later. Reference: Interior point method https://en.wikipedia.org/wiki/Interior-point method Reference: Active set method https://en.wikipedia.org/wiki/Active set method Reducing equality constrained minimization problem The above problem can be rewritten as MATH . Inequality constraints can be included in the objective function as an indicator function. > MATH \\begin align &\\min x \\ && f x + I C x \\\\ &\\text subject to \\ && Ax = b \\\\ \\end align MATH In this way, the problem can be transformed into an equality constrained minimization problem. However, since the indicator function still includes the boundary, it still has the difficulty of boundary computation from the original problem, and since it is not differentiable, it is difficult to apply Newton's method. What if we approximate the indicator function MATH with a barrier function ? In that case, the boundary would not be included and since it is differentiable, Newton's method can be applied. The method of solving problems redefined with barrier functions in this way is called the barrier method, which is introduced in detail in the next section.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter15/15_01_01_inequality_constrained_minimization_problems/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter15/15_01_02_log_barrier_function_and_barrier_method",
    "title": "15-01-02 Log barrier function & barrier method",
    "chapter": "15",
    "order": 4,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Before introducing the barrier method, let's first see how the indicator function can be approximated by a barrier function. Approximation of indicator function In the following figure, you can see the indicator function and the barrier function. The dotted line is the indicator function MATH , and the solid lines are the barrier function MATH for MATH . The barrier function smoothly approximates the indicator function, and when MATH , it provides the best approximation. MATH Logarithmic barrier function Suppose MATH are convex and twice differentiable. For the set MATH , the following function is called the logarithmic barrier function. > \\begin align \\phi x = - \\sum i=1 ^ m \\log -h i x \\end align Here, the set is assumed to be the interior of the feasible set MATH and is non-empty. Barrier method Using the barrier function, the original problem can be approximated as follows. Here, MATH . > MATH \\begin align &\\min x && f x + \\frac 1 t \\phi x & \\qquad & \\min x && tf x + \\phi x \\\\ &\\text subject to && Ax = b & \\iff \\qquad & \\text subject to && Ax = b \\\\ \\end align MATH The method of solving the problem defined in this way using Newton's method is called the barrier method .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter15/15_01_02_log_barrier_function_and_barrier_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter15/15_02_central_path",
    "title": "15-02 Central path",
    "chapter": "15",
    "order": 6,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "If we denote the solution to the following barrier problem MATH as MATH , then the central path is the set MATH . > MATH \\begin align > &\\min x \\ && tf x + \\phi x \\\\ > &\\text subject to \\ && Ax = b \\\\ > \\end align MATH Given suitable conditions, the central path set forms a smooth path in MATH , and as MATH , MATH , where MATH is the solution to the original problem. The central path is a set of solutions obtained by gradually redefining the problem for new values of MATH , moving from the interior toward the boundary when it is difficult to find the optimal solution at the boundary directly. Example: central path for an LP Let's find the central path for the following LP problem. > MATH \\begin align >&\\min x \\ && c^Tx \\\\ >&\\text subject to \\ && a i^Tx \\le b i^T, i = 1, \\cdots , 6 \\\\ >\\end align MATH In the following figure, the dotted line represents the logarithmic barrier function MATH . Fig 1 Central path 1 You can see that as MATH , the central path converges to the optimal MATH . At this point, the hyperplane MATH is the tangent to the level curve of MATH passing through MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter15/15_02_central_path/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter16/16_01_lagrangian_duality_revisited",
    "title": "16-01 Tính đối ngẫu Lagrangian - nhìn lại",
    "chapter": "16",
    "order": 2,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Trong phần này, chúng ta sẽ cho thấy rằng các bài toán nguyên thủy và đối ngẫu có thể được định nghĩa bằng cách sử dụng Lagrangian, và sử dụng định nghĩa này để suy ra các bài toán đối ngẫu cho quy hoạch tuyến tính dạng chuẩn và quy hoạch bậc hai. Hơn nữa, chúng ta sẽ suy ra bài toán đối ngẫu cho quy hoạch tuyến tính với bài toán barrier được áp dụng, cho thấy rằng dạng của nó giống với bài toán barrier cho bài toán đối ngẫu của quy hoạch tuyến tính. Đầu tiên, hãy định nghĩa bài toán nguyên thủy và Lagrangian như sau. Bài toán nguyên thủy > MATH >\\begin align > \\mathop \\text minimize x &\\quad f x \\\\\\\\ > \\text subject to &\\quad h i x \\leq 0, i = 1, \\ldots, m \\\\\\\\ > &\\quad l j x = 0, j = 1, \\ldots, r >\\end align > MATH Lagrangian > MATH >L x,u,v = f x + \\sum i=1 ^m u i h i x + \\sum j=1 ^r v j l j x > MATH Tại thời điểm này, bài toán nguyên thủy và bài toán đối ngẫu có thể được định nghĩa lại thành các bài toán liên quan đến Lagrangian. Bài toán nguyên thủy được viết lại > MATH >\\min x \\mathop \\max u,v u \\geq 0 L x,u,v > MATH Bài toán nguyên thủy được định nghĩa lại không nêu rõ ràng các ràng buộc, nhưng nó có tác dụng như một hàm chỉ thị cho bất kỳ MATH không khả thi nào vi phạm các ràng buộc. 1. Nếu MATH cho một số MATH , thì MATH là một điểm không khả thi. Trong trường hợp này, MATH phân kỳ về MATH do MATH , vì vậy nó hoạt động như một hàm chỉ thị cho bất kỳ MATH nào vi phạm ràng buộc bất đẳng thức. 2. Nếu MATH cho một số MATH , thì MATH là một điểm không khả thi. Trong trường hợp này, MATH phân kỳ về MATH do MATH , vì vậy nó hoạt động như một hàm chỉ thị cho bất kỳ MATH nào vi phạm ràng buộc đẳng thức. Bài toán đối ngẫu được viết lại > MATH >\\mathop \\max u,v u \\geq 0 \\min x L x,u,v > MATH Trong bài toán đối ngẫu, việc nới lỏng miền là cần thiết, vì vậy nó không nên hoạt động như một hàm chỉ thị cho các ràng buộc của bài toán nguyên thủy. Vì việc lấy MATH cho MATH cố định không thể thực thi các ràng buộc của bài toán nguyên thủy, bài toán đối ngẫu được định nghĩa lại cũng có tác dụng nới lỏng miền. Tham khảo: 11-02 Hàm đối ngẫu Lagrange % multilang post url contents/chapter11/21-03-24-11 02 Lagrange dual function % Tính đối ngẫu yếu và mạnh Hãy xem xét lại tính đối ngẫu yếu và tính đối ngẫu mạnh. Định lý: tính đối ngẫu yếu Khi MATH và MATH là các giá trị tối ưu cho bài toán nguyên thủy và bài toán đối ngẫu tương ứng, điều sau luôn được thỏa mãn: MATH p \\ge d MATH Định lý: tính đối ngẫu mạnh điều kiện Slater được làm tế Đối với tập miền MATH , giả sử rằng MATH là lồi và MATH là affine. Nếu tồn tại MATH thỏa mãn điều sau: > MATH \\begin align >h i \\hat x \\ & \\lt 0, \\ && i=1, \\dots, p \\\\ >h i \\hat x \\ & \\le 0, \\ && i=p+1, \\dots, m \\\\ >l j \\hat x \\ & = 0, \\ && j = 1, \\dots, r \\end align MATH thì MATH được đảm bảo cho các giá trị tối ưu MATH của bài toán nguyên thủy và bài toán đối ngẫu. Ví dụ: quy hoạch tuyến tính Hãy suy ra bài toán đối ngẫu của quy hoạch tuyến tính bằng cách sử dụng bài toán đối ngẫu đã định nghĩa trước đó. Bài toán nguyên thủy của LP dạng chuẩn > MATH >\\begin align > \\mathop \\text minimize x &\\quad c^Tx \\\\\\\\ > \\text subject to &\\quad Ax = b \\\\\\\\ > &\\quad x \\ge 0 >\\end align > MATH Theo định nghĩa trước đó, bài toán đối ngẫu của bài toán trên như sau: MATH Chúng ta thay thế mối quan hệ MATH thu được bằng cách giải MATH vào bài toán đối ngẫu. MATH Điều này có thể được tổ chức như sau: Bài toán đối ngẫu của LP > MATH >\\begin align > \\mathop \\text maximize s,y &\\quad b^Ty \\\\\\\\ > \\text subject to &\\quad A^Ty + s = c \\\\\\\\ > &\\quad s \\ge 0 >\\end align > MATH Ví dụ: quy hoạch bậc hai lồi Bây giờ hãy suy ra bài toán đối ngẫu của quy hoạch bậc hai bằng cách sử dụng bài toán đối ngẫu đã định nghĩa trước đó. Bài toán nguyên thủy của QP dạng chuẩn > MATH >\\begin align > \\mathop \\text minimize x &\\quad \\frac 1 2 x^T Q x + c^Tx \\\\ > \\text subject to &\\quad Ax = b \\\\ > &\\quad x \\ge 0, \\\\ > >\\end align MATH > > MATH Theo định nghĩa trước đó, bài toán đối ngẫu của bài toán trên như sau: MATH Chúng ta thay thế mối quan hệ MATH thu được bằng cách giải MATH vào bài toán đối ngẫu. MATH \\begin align &\\mathop \\max s,y,x s\\ge0 \\: \\frac 1 2 x^T A^Ty +s - c + c^Tx - s^Tx + b-Ax ^T y \\quad \\text s.t. Qx = A^Ty +s - c\\\\\\\\ &= \\mathop \\max s,y,x s\\ge0 \\: x^T A^Ty +s - c + c^Tx - s^Tx + b-Ax ^T y - \\frac 1 2 x^T A^Ty +s - c \\quad \\text s.t. Qx = A^Ty +s - c\\\\\\\\ &= \\mathop \\max s,y,x s\\ge0 \\: b^Ty - \\frac 1 2 x^T A^Ty +s - c \\quad \\text s.t. Qx = A^Ty +s - c\\\\\\\\ &= \\mathop \\max s,y,x s\\ge0 \\: b^Ty - \\frac 1 2 x^T Q x \\quad \\text s.t. Qx = A^Ty +s - c \\end align MATH Điều này có thể được tổ chức như sau: Bài toán đối ngẫu của QP > MATH >\\begin align > \\mathop \\text maximize s,y,x &\\quad b^Ty - \\frac 1 2 x^T Q x\\\\\\\\ > \\text subject to &\\quad A^Ty + s - c = Qx \\\\\\\\ > &\\quad s \\ge 0 >\\end align > MATH Bài toán đối ngẫu của một bài toán bậc hai cũng là một bài toán bậc hai. Ví dụ: bài toán barrier cho quy hoạch tuyến tính Bài toán barrier cho quy hoạch tuyến tính được định nghĩa như sau: Bài toán barrier cho LP > MATH >\\begin align > \\mathop \\text minimize x &\\quad c^Tx - \\tau \\sum i=1 ^n \\log x i \\\\ > \\text subject to &\\quad Ax = b, \\\\ >\\end align MATH > > MATH Theo định nghĩa trước đó, bài toán đối ngẫu của bài toán trên như sau: MATH \\begin align \\max y \\min x \\: L x,y &= \\max y \\min x \\: c^Tx - \\tau \\sum i=1 ^n \\log x i + b-Ax ^T y\\\\\\\\ &= \\max y \\min x \\: \\underbrace c-A^Ty s \\doteq c-A^Ty x - \\tau \\sum i=1 ^n \\log x i + b^Ty\\\\\\\\ &= \\max y \\min x \\: \\sum i=1 ^n \\big s i^Tx i - \\tau \\log x i \\big + b^Ty \\quad \\text s.t. A^Ty +s = c \\end align MATH Ở đây, MATH sẽ được tối thiểu hóa khi MATH . Do đó, hãy thay thế MATH cho MATH trong bài toán đối ngẫu. MATH \\begin align &\\max s,y \\: b^Ty + n\\tau - \\tau \\sum i=1 ^n log \\frac \\tau s i \\quad \\text s.t. A^Ty +s = c\\\\\\\\ &= \\max s,y \\: b^Ty + \\tau \\sum i=1 ^n log s i + n\\tau - n\\tau\\log \\tau \\quad \\text s.t. A^Ty +s = c\\\\\\\\ \\end align MATH Vì MATH có thể được bỏ qua khỏi bài toán, bài toán đối ngẫu có thể được tổ chức như sau: Bài toán đối ngẫu của bài toán Barrier cho LP > MATH >\\begin align > \\mathop \\text maximize s,y &\\quad b^Ty + \\tau \\sum i=1 ^n log s i \\\\\\\\ > \\text subject to &\\quad A^Ty + s = c \\\\\\\\ >\\end align > MATH Chúng ta có thể thấy rằng bài toán này giống hệt với bài toán barrier cho bài toán đối ngẫu của quy hoạch tuyến tính.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter16/16_01_lagrangian_duality_revisited/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter16/16_02_optimality_conditions",
    "title": "16-02 Điều kiện tối ưu",
    "chapter": "16",
    "order": 3,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Trong phần này, chúng ta sẽ xem xét các điều kiện tối ưu KKT cho các bài toán nguyên thủy và các bài toán barrier tương ứng, và sau đó so sánh sự khác biệt của chúng. Điều kiện tối ưu KKT Hãy xem lại các điều kiện KKT mà chúng ta đã đề cập trong Chương 12. Điều kiện KKT được sử dụng như các điều kiện để xác định tính tối ưu. Bài toán nguyên thủy > MATH >\\begin align > \\mathop \\text minimize x &\\quad f x \\\\\\\\ > \\text subject to &\\quad h i x \\leq 0, i = 1, \\ldots, m \\\\\\\\ > &\\quad l j x = 0, j = 1, \\ldots, r >\\end align > MATH Khi bài toán nguyên thủy đã cho là lồi, các điều kiện KKT trở thành điều kiện đủ cho tính tối ưu nguyên thủy & đối ngẫu. Có nghĩa là, khi MATH là lồi và MATH là affine, nếu MATH thỏa mãn các điều kiện KKT sau, thì MATH và MATH là tối ưu nguyên thủy & đối ngẫu với khoảng cách đối ngẫu bằng không. Chúng ta giả sử rằng MATH có thể vi phân. Tham khảo: 12-01 Điều kiện KKT % multilang post url contents/chapter12/21-04-02-12 00 KKT conditions % Điều kiện KKT cho bài toán nguyên thủy đã cho > MATH >\\begin align >l i &= 0, \\quad i=1, \\dots, r\\\\\\\\ >u i^\\star, -h i x^\\star &\\ge 0, \\quad i=1, \\dots, m\\\\\\\\ >u i^\\star h i x^\\star &= 0, \\quad i=1, \\dots, m\\\\\\\\ >\\nabla f x^\\star + \\sum i=1 ^m \\nabla h i x^\\star u^\\star i + \\sum i=1 ^r \\nabla l i x^\\star v i^\\star &= 0.\\\\\\\\ >\\end align > MATH Phương trình đường dẫn trung tâm Hãy cũng xem xét các điều kiện để xác định tính tối ưu của các bài toán barrier. Bài toán barrier > MATH \\begin align \\mathop \\text minimize x &\\quad f x + \\tau \\phi x \\\\\\\\ &\\quad l j x = 0, j = 1, \\ldots, r \\\\\\\\ \\end align MATH > > MATH Bằng cách tổ chức các điều kiện KKT cho các bài toán barrier, chúng ta có thể suy ra các điều kiện tối ưu sau. Lưu ý sự khác biệt trong ràng buộc bất đẳng thức và các điều kiện bổ sung so với các điều kiện tối ưu KKT cho các bài toán nguyên thủy đã xem xét trước đó. Tham khảo: 15-03-01 Điều kiện KKT bị nhiễu % multilang post url contents/chapter15/21-03-28-15 03 01 perturbed kkt conditions % Điều kiện tối ưu cho bài toán barrier và đối ngẫu của nó > MATH \\begin align l i &= 0, \\quad i=1, \\dots, r\\\\\\\\ u i t , -h i x^\\star t &\\gt 0, \\quad i=1, \\dots, m\\\\\\\\ u i t h i x^\\star t &= -\\tau, \\quad i=1, \\dots, m\\\\\\\\ \\nabla f x^\\star t + \\sum i=1 ^m \\nabla h i x^\\star t u i t + \\sum i=1 ^r \\nabla l i x^\\star t \\hat v i^\\star &= 0,\\\\\\\\ \\end align \\\\\\\\ MATH > > MATH Trường hợp đặc biệt: quy hoạch tuyến tính Nhắc lại: Bài toán nguyên thủy của LP dạng chuẩn > MATH >\\begin align > \\mathop \\text minimize x &\\quad c^Tx \\\\\\\\ > \\text subject to &\\quad Ax = b \\\\\\\\ > &\\quad x \\ge 0 >\\end align > MATH Nhắc lại: Bài toán đối ngẫu của LP > MATH >\\begin align > \\mathop \\text maximize s,y &\\quad b^Ty \\\\\\\\ > \\text subject to &\\quad A^Ty + s = c \\\\\\\\ > &\\quad s \\ge 0 >\\end align > MATH Quy hoạch tuyến tính có tính chất tốt là luôn thỏa mãn tính đối ngẫu mạnh do điều kiện Slater được làm tế, vì các ràng buộc bất đẳng thức là affine. Các điều kiện tối ưu cho LP như sau: > MATH >\\begin align >A^T y^\\star + s^\\star &= c\\\\\\\\ >Ax^\\star &= b\\\\\\\\ >X S \\mathbb 1 &= 0\\\\\\\\ >x^\\star, s^\\star &\\ge 0,\\\\\\\\ >\\end align MATH > > MATH Lưu ý rằng MATH tương đương với MATH . Chúng ta sử dụng ký hiệu MATH để thuận tiện trong các thuật toán sẽ được giới thiệu sau này. Thuật toán cho quy hoạch tuyến tính Chúng ta giới thiệu hai phương pháp đại diện để giải LP bằng cách sử dụng các điều kiện tối ưu. 1. Simplex: Một phương pháp duy trì các điều kiện 1, 2, và 3 trong khi dần dần thỏa mãn điều kiện 4. 2. Phương pháp điểm trong: Một phương pháp duy trì điều kiện 4 trong khi dần dần thỏa mãn các điều kiện 1, 2, và 3. Điều này sẽ được đề cập trong chương tiếp theo. Đường dẫn trung tâm cho quy hoạch tuyến tính Nhắc lại: Bài toán barrier cho LP > MATH \\begin align \\mathop \\text minimize x &\\quad c^Tx - \\tau \\sum i=1 ^n \\log x i \\\\\\\\ \\text subject to &\\quad Ax = b, \\\\\\\\ \\text trong đó &\\quad \\tau > 0 \\end align MATH Nhắc lại: Bài toán đối ngẫu của bài toán Barrier cho LP > MATH >\\begin align > \\mathop \\text maximize s,y &\\quad b^Ty + \\tau \\sum i=1 ^n log s i \\\\\\\\ > \\text subject to &\\quad A^Ty + s = c \\\\\\\\ >\\end align > MATH Các điều kiện tối ưu cho bài toán barrier của LP như sau: > MATH \\begin align A^T y^\\star + s^\\star &= c\\\\\\\\ Ax^\\star &= b\\\\\\\\ X S \\mathbb 1 &= \\tau \\mathbb 1 \\\\\\\\ x^\\star, s^\\star &\\gt 0,\\\\\\\\ \\text trong đó &\\quad X = Diag x^\\star , S = Diag s^\\star \\end align MATH Các điều kiện 3 và 4 cho thấy sự khác biệt so với các điều kiện KKT của LP nguyên thủy.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter16/16_02_optimality_conditions/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter16/16_03_fenchel_duality",
    "title": "16-03 Tính đối ngẫu Fenchel",
    "chapter": "16",
    "order": 4,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "MathJax.Hub.Config displayAlign: \"center\" ; Trong 13-04 Hàm liên hợp % multilang post url contents/chapter13/21-04-05-13 04 Conjugate function % , chúng ta đã học cách suy ra các bài toán đối ngẫu bằng cách sử dụng các hàm liên hợp. Tính đối ngẫu Fenchel đề cập đến các bài toán đối ngẫu được suy ra từ các hàm liên hợp có dạng sau: MATH \\max v -f^ A^Tv - g^ -v MATH Hãy khám phá xem dạng bài toán này được suy ra từ đâu. Bài toán nguyên thủy > MATH > \\min x \\quad f x + g Ax > MATH Bài toán đã cho có thể được định nghĩa lại với một ràng buộc đẳng thức được thêm vào. Bài toán nguyên thủy được viết lại > MATH \\begin align &\\min x,z \\ && f x + g z \\\\ &\\text subject to \\ && Ax = z. \\end align MATH Hãy suy ra bài toán đối ngẫu của bài toán nguyên thủy được định nghĩa lại bằng cách sử dụng các hàm liên hợp. Nhắc lại: MATH MATH \\begin align &\\max v \\min x, z \\quad L x,z,v \\\\\\\\ = &\\max v \\min x, z \\quad f x + g z + v^T z - Ax \\\\\\\\ = &\\max v \\min x, z \\quad v^Tz + g z - A^Tv ^Tx + f x \\\\\\\\ = &\\max v \\quad -f^ A^Tv - g^ -v \\\\\\\\ \\end align MATH Tính đối ngẫu Fenchel > MATH > \\max v -f^ A^Tv - g^ -v > MATH Tính chất tốt: Nếu MATH là lồi và đóng, đối ngẫu của đối ngẫu lại trở thành nguyên thủy. Đối xứng Ví dụ: quy hoạch cônic Bài toán nguyên thủy của CP dạng chuẩn > MATH \\begin align \\mathop \\text minimize x &\\quad c^Tx \\\\\\\\ \\text subject to &\\quad Ax = b \\\\\\\\ &\\quad x \\in K \\end align MATH Bài toán trên có thể được định nghĩa lại bằng cách sử dụng hai hàm MATH và MATH . Lưu ý: MATH \\begin equation f x + g Ax = \\begin cases 0, & \\text nếu \\ Ax=b, x \\in K \\\\\\\\ \\infty, & \\text trường hợp khác \\end cases \\end equation MATH Bài toán nguyên thủy của CP được viết lại > MATH > \\begin align > &\\min x, z \\ && f x + g z \\\\\\ > &\\text subject to \\ && z =Ax \\\\\\ > \\end align > MATH Suy ra bài toán đối ngẫu của CP Hãy suy ra bài toán đối ngẫu từ bài toán nguyên thủy CP được định nghĩa lại. Đầu tiên, mở rộng các hàm MATH và MATH cho chúng ta: > MATH > \\begin align > & \\min x, z && \\; c^Tx + I K x + I \\ b\\ z \\\\\\ > &\\text subject to && \\; z =Ax \\\\ > \\end align > MATH Hãy mở rộng bài toán bằng cách sử dụng các hàm liên hợp từ định nghĩa của bài toán đối ngẫu. > MATH > \\begin align > & \\max y \\; \\min x, z \\; L x, z, y \\\\\\ > = \\; & \\max y \\; \\min x, z \\; c^Tx + I K x + I \\ b\\ z + y^T z-Ax \\\\\\ > = \\; & \\max y \\;\\min x, z \\; c - A^Ty ^Tx + I K x \\;+ \\; y^Tz + I \\ b\\ z \\\\\\ > = \\; & \\max y \\; \\min x, z \\; - A^Ty - c ^Tx - I K x \\; - \\; - y^Tz - I \\ b\\ z \\\\\\ > = \\; & \\max y \\; - I K^ A^Ty - c - I \\ b\\ ^ -y \\\\\\ > = \\; & \\max y \\; - I -K^ A^Ty - c - I \\ b\\ ^ -y \\\\ > \\end align > MATH MATH có thể được biểu diễn như một ràng buộc. > MATH > \\begin align > A^Ty - c & = -s, \\; -s \\in -K^ \\\\\\ > \\Leftrightarrow A^Ty + s & = c, \\; s \\in K^ \\\\\\ > \\end align > MATH Vì MATH , bài toán có thể được tổ chức như sau: > MATH > \\begin align > &\\max y, s \\ && - -b^Ty - I \\ b\\ b \\\\\\ > &\\text subject to \\ && y^TA + s = c \\\\\\ > & \\; s \\in K^ \\\\ > \\end align > MATH Vì MATH , nó có thể được loại bỏ khỏi bài toán. Bài toán đối ngẫu của CP > MATH > \\begin align > &\\max y, s \\ && \\; b^Ty \\\\\\ > &\\text subject to \\ && y^TA + s = c \\\\\\ > & \\; s \\in K^ \\\\ > \\end align > MATH Nếu bài toán nguyên thủy hoặc bài toán đối ngẫu khả thi nghiêm ngặt, thì tính đối ngẫu mạnh được thỏa mãn. Nếu cả bài toán nguyên thủy và bài toán đối ngẫu đều khả thi nghiêm ngặt, thì tính đối ngẫu mạnh được thỏa mãn và tồn tại nghiệm tối ưu nguyên thủy & đối ngẫu. Ví dụ: quy hoạch nửa xác định Hãy xem xét các dạng của bài toán nguyên thủy & đối ngẫu cho SDP và các bài toán nguyên thủy & đối ngẫu cho bài toán barrier của SDP. Bài toán nguyên thủy của SDP > MATH >\\begin align > &\\mathop \\text minimize X && tr CX \\\\\\\\ > &\\text subject to && tr A iX = b i, \\phantom 5 i=1,\\dotsc,p \\\\\\\\ > & && X \\succeq 0 ,\\\\\\\\ >\\end align MATH > > MATH Nhắc lại: MATH Lưu ý: Không giống như LP, SDP không luôn thỏa mãn tính đối ngẫu mạnh. Bài toán đối ngẫu của SDP > MATH >\\begin align > &\\mathop \\text maximize y && b^Ty \\\\\\\\ > &\\text subject to && \\sum i=1 ^m y i A i + S = C \\\\\\\\ > & && S \\succeq 0 .\\\\\\\\ >\\end align > MATH Lưu ý: Nón nửa xác định dương là một nón tự đối ngẫu. MATH Bài toán nguyên thủy của bài toán Barrier cho SDP > MATH >\\begin align > &\\mathop \\text minimize X && tr CX - \\tau \\log \\big det X \\big \\\\\\\\ > &\\text subject to && tr A iX = b i, \\phantom 5 i=1,\\dotsc,p \\\\\\\\ >\\end align MATH > > MATH Bài toán đối ngẫu của bài toán Barrier cho SDP > MATH >\\begin align > &\\mathop \\text maximize y, S && b^Ty + \\tau \\log \\big det S \\big \\\\\\\\ > &\\text subject to && \\sum i=1 ^m y i A i + S = C . >\\end align > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter16/16_03_fenchel_duality/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter17/17_primal_dual_interior_point_method",
    "title": "17 Primal-Dual Interior-Point Methods",
    "chapter": "17",
    "order": 1,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "In this chapter, we will examine the Primal-Dual Interior-Point Method , which improves performance by reducing the centering step of the Barrier method we learned earlier to a single step. The Primal-Dual Interior-Point Method relaxes the constraint that the centering step must be feasible and uses the root finding version of Newton's Method to approximate nonlinear equations with linear equations to find solutions, making it faster and more accurate than the Barrier method. References and further readings S. Boyd and L. Vandenberghe 2004 , “Convex optimization,” Chapter 11 S. Wright 1997 , “Primal-dual interior-point methods,” Chapters 5 and 6 J. Renegar 2001 , “A mathematical view of interior-point methods” Y. Nesterov and M. Todd 1998 , “Primal-dual interior-point methods for self-scaled cones.” SIAM J. Optim.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter17/17_primal_dual_interior_point_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter17/17_01_barrier_method_duality_optimality_revisited",
    "title": "17-01 Barrier method & duality & optimality revisited",
    "chapter": "17",
    "order": 2,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "In Chapter 15, we examined the barrier method, and in Chapters 13 and 16, we looked at duality. Before covering the content of this chapter, we want to briefly review the barrier method and duality. Barrier method When the following primal problem is convex and MATH are differentiable, > MATH \\begin align > &\\min x && f x \\\\ > &\\text subject to &&h i x \\leq 0, i = 1, \\dotsc, m \\\\ > &&& Ax = b \\\\ > \\end align MATH Using the log barrier function, the primal problem can be transformed into a barrier problem as follows: > MATH \\begin align > & \\min x && f x + \\frac 1 t \\phi x & \\qquad & \\min x && tf x + \\phi x \\\\ > & \\text subject to && Ax = b & \\iff \\qquad & \\text subject to && Ax = b \\\\ > & \\text where && \\phi x = - \\sum i=1 ^ m \\log -h i x > \\end align MATH The algorithm starts with MATH satisfying MATH and increases until MATH becomes less than or equal to MATH . At this time, Newton's method is used to find MATH for the initial value MATH , and the process of finding MATH at each step for MATH is repeated. The algorithm can be briefly summarized as follows: 1. Choose MATH and MATH . 2. Solve the barrier problem at MATH to find MATH . 3. While MATH 3-1. Update MATH where MATH 3-2. Initialize Newton's method with MATH warm start Solve the barrier problem at MATH to find MATH . end while For detailed information, see 15-01-02 Log barrier function & barrier method % multilang post url contents/chapter15/21-03-28-15 01 02 log barrier function and barrier method % Duality When the following primal problem is given: > MATH >\\begin align > \\mathop \\text minimize x &\\quad f x \\\\\\\\ > \\text subject to &\\quad f Ax = b \\\\\\\\ > &\\quad h x \\le 0 >\\end align > MATH This can be transformed into Lagrangian form as follows: > MATH >L x,u,v = f x + u^Th x + v^T Ax - b > MATH Using the Lagrangian defined in this way, primal and dual problems can be redefined in the following form. Please refer to Chapter 16 for detailed information. Primal Problem > MATH >\\min x \\mathop \\max u,v u \\geq 0 L x,u,v > MATH Dual problem > MATH >\\mathop \\max u,v u \\geq 0 \\min x L x,u,v > MATH Optimality conditions When MATH are convex and differentiable, and the given problem satisfies strong duality, the KKT optimality conditions for this problem are as follows: > MATH > \\begin array rcl > ∇f x +∇h x u + A^Tv & = & 0 & \\text Stationarity \\\\\\ > Uh x & = & 0 & \\text Complementary Slackness \\\\\\ > Ax & = & b & \\text Primal Feasibility \\\\\\ > u,−h x & ≥ & 0 & \\text Dual Feasibility > \\end array > MATH Here, MATH means MATH , and MATH means MATH . For detailed information, see Chapter 12 KKT conditions % multilang post url contents/chapter12/21-04-02-12 00 KKT conditions % Central path equations The function MATH can be redefined as a barrier problem as follows. In the equation below, MATH is MATH , and by making MATH gradually approach 0 and iteratively finding solutions, we ultimately obtain the solution to the original problem. > MATH >\\begin align >&\\min x && f x + τ\\phi x \\\\\\\\ >& && Ax = b \\\\\\ >& \\text where && \\phi x = −\\sum i=1 ^m \\log −h i x . >\\end align > MATH That is, in the above equation, differences from the primal problem occur depending on MATH , and the trajectory generated according to MATH , i.e., the set of solutions to the barrier problem, is called the central path. And the optimality conditions for this barrier problem are as follows: > MATH > \\begin array rcl > ∇f x +∇h x u + A^Tv & = & 0 \\\\\\ > Uh x & = & −τ\\mathbb 1 \\\\\\ > Ax & = & b \\\\\\ > u,−h x & > & 0 > \\end array > MATH For detailed information, see 16-02 Optimality conditions % multilang post url contents/chapter16/21-03-31-16 02 optimality conditions % The Primal-Dual interior point method introduced in this chapter is a method that defines the first three equations above as residuals and finds solutions by reducing them to MATH . Useful fact The solution MATH has a duality gap of size MATH , i.e., MATH , as follows: > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter17/17_01_barrier_method_duality_optimality_revisited/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter17/17_02_primal_dual_interior_point_method",
    "title": "17-02 Primal-dual interior-point method",
    "chapter": "17",
    "order": 3,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Like the barrier method, the primal-dual interior-point method also aims to approximately compute points on the central path. However, the two methods have several differences. Differences between Primal-dual interior-point method and barrier method Generally performs one Newton step per iteration. That is, there is no additional loop for the centering step. Does not necessarily need to be feasible . Pushes toward feasible regions through backtracking line search. Generally more effective . Particularly shows superior performance compared to linear convergence under appropriate conditions. Somewhat less intuitive compared to the barrier method.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter17/17_02_primal_dual_interior_point_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter17/17_02_01_central_path_equations_and_newton_step",
    "title": "17-02-01 Central path equations and Newton step",
    "chapter": "17",
    "order": 4,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "The Primal-dual interior-point method is a method that finds solutions by finding the central path, similar to the barrier method. To do this, it defines perturbed KKT conditions as residual functions and finds solutions that make them zero. This section aims to explain this approach. Central path equations By moving the right-hand side to the left-hand side in the central path equations explained in the previous 17-01 Optimality conditions % multilang post url contents/chapter17/21-05-01-17 01 barrier method duality optimality revisited % , we can organize them as follows. The optimality conditions of central path equations are also called perturbed KKT conditions. > MATH > \\begin array rcl > ∇f x +∇h x u + A^Tv & = & 0 \\\\\\ > Uh x + \\tau\\mathbb 1 & = & 0 \\\\\\ > Ax−b & = & 0 \\\\\\ > u,−h x & > & 0 > \\end array > MATH Note that the complementary slackness and inequality constraints in the KKT conditions for the original problem differ from those in the perturbed KKT conditions. For the original problem, MATH and MATH , but in the perturbed KKT conditions, MATH and MATH . These organized nonlinear equations, the perturbed KKT conditions, can be solved by approximating them as linear equations using the root finding version of Newton's method. Newton step Now let's learn about the method of finding solutions by linearly approximating the perturbed KKT conditions. The perturbed KKT conditions equation can be defined as the following residual function MATH . The reason for naming it residual is that these values must be 0 to be optimal. > MATH r x,u,v := > \\begin bmatrix > ∇f x +∇h x u + A^Tv \\\\\\ > Uh x + τ\\mathbb 1 \\\\\\ > Ax−b > \\end bmatrix , H x = \\text Diag h x MATH To find the roots of the function, approximating MATH with a first-order Taylor expansion gives us the following. This process approximates non-linear equations to linear equations. For detailed information, see 14-02-01 Root finding % multilang post url contents/chapter14/2021-03-26-14 01 newton method % > MATH \\begin align 0 & = r x + \\Delta x, u + \\Delta u, r + \\Delta v \\\\\\\\ & \\approx r x, u, v + \\nabla r x, u, v \\begin pmatrix \\Delta x \\\\\\\\ \\Delta u \\\\\\\\ \\Delta v \\\\\\\\ \\end pmatrix \\\\\\\\ \\end align MATH Accordingly, the function MATH can be organized as follows. > MATH \\begin align \\nabla r x, u, v \\begin pmatrix \\Delta x \\\\\\\\ \\Delta u \\\\\\\\ \\Delta v \\\\\\\\ \\end pmatrix = -r x, u, v \\\\\\\\ \\end align MATH By differentiating MATH with respect to MATH to obtain the Jacobian matrix MATH and substituting the above equation, we get the following. > MATH \\begin bmatrix > \\nabla^2f x + \\sum i u i \\nabla^2h i x & \\nabla h x & A^T \\\\\\ > U \\nabla h x ^T & H x & 0 \\\\\\ > A & 0 & 0 > \\end bmatrix > \\begin bmatrix > \\Delta x \\\\\\ > \\Delta u \\\\\\ > \\Delta v > \\end bmatrix = −r x,u,v MATH > where > MATH r x,u,v := > \\begin bmatrix > \\nabla f x +\\nabla h x u + A^Tv \\\\\\ > Uh x + τ\\mathbb 1 \\\\\\ > Ax−b > \\end bmatrix , H x = \\text Diag h x MATH The solution MATH to this equation is the update direction for the primal and dual variables. The reason why the method introduced in this chapter is called the Primal-Dual interior point method is that it simultaneously updates primal and dual variables using residual functions.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter17/17_02_01_central_path_equations_and_newton_step/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter17/17_02_02_surrogate_duality_gap_residuals",
    "title": "17-02-02 Surrogate duality gap, residuals",
    "chapter": "17",
    "order": 5,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "To define the Primal-Dual algorithm, let's first define three types of residuals and the surrogate duality gap. Residuals and surrogate duality gap are the objectives to be minimized in the Primal-Dual algorithm. Residuals The dual, central, and primal residuals at MATH are defined as follows. > MATH > MATH > MATH These correspond to each row of the function MATH . The Primal-dual interior point method executes in the direction of satisfying 0 rather than continuously making these three residuals equal to 0. This means that it is not necessary to be feasible during the execution process. The reason MATH is called the dual residual is that, as shown in the equation below, if MATH , it guarantees that MATH are in the domain of MATH , which means dual feasible. > MATH \\begin align & r dual = \\nabla f x +\\nabla h x u + A^Tv = 0 \\\\\\\\ & \\iff \\min x L x,u.v = g u,v \\\\\\\\ \\end align MATH Similarly, satisfying MATH means primal feasible, so MATH is called the primal residual. Surrogate duality gap While the barrier method has a duality gap because it is feasible, the primal-dual interior-point method uses surrogate duality gap because it doesn't necessarily need to be feasible. Surrogate duality gap is defined by the following equation. > MATH If MATH and MATH , then the surrogate duality gap becomes the true duality gap. In other words, if primal and dual feasible, the surrogate duality gap becomes equal to the actual duality gap MATH . Reference Perturbed KKT conditions and parameter t In the perturbed KKT conditions, the parameter t is MATH . For detailed information, see 15-03-01 Perturbed KKT conditions % multilang post url contents/chapter15/21-03-28-15 03 01 perturbed kkt conditions % and 15-03-02 Suboptimality gap % multilang post url contents/chapter15/21-03-28-15 03 02 suboptimality gap % Furthermore, if MATH r x,u,v = 0 MATH \\tau = -\\frac h x ^Tu m MATH In other words, the residual is 0 at points existing on the central path.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter17/17_02_02_surrogate_duality_gap_residuals/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter17/17_02_03_primal_dual_algorithm",
    "title": "17-02-03 Primal-Dual Algorithm",
    "chapter": "17",
    "order": 6,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "To define the Primal-Dual algorithm, let's first define MATH as follows > MATH For reference, MATH and MATH in the Barrier method are redefined and denoted as MATH and MATH in the Primal-Dual algorithm. > MATH Primal-Dual Algorithm The Primal-Dual algorithm is as follows. > 1. Choose MATH MATH > 2. Choose MATH MATH > 3. Repeat the following steps MATH > MATH Calculate Newton step : > MATH > MATH 계산 > MATH 에 대해 MATH 계산 > MATH Select step length MATH with Backtracking > MATH Primal-Dual update : > MATH > 4. Termination condition : Stop if the conditions MATH and MATH are satisfied The algorithm calculates MATH by executing Newton step at each stage and obtains MATH by performing Primal-Dual updates. However, MATH is selected through Backtracking line search so that the Primal-Dual variables become feasible. The algorithm terminates when the surrogate duality gap and primal and dual residuals become smaller than MATH . Backtracking line search Since the Primal-Dual algorithm executes Newton step only once, it can be viewed as finding the direction of the solution rather than finding the exact solution. Therefore, an appropriate step length must be found so that moving in that direction can enter the feasible set. That is, at each step of the algorithm, MATH is obtained to update the primal-dual variables. > MATH This process has two main objectives. Maintaining the condition MATH Decreasing MATH For this purpose, multi-stage backtracking line search is used. Stage 1: dual feasibility MATH Initially, we start with the largest step MATH that satisfies MATH . > MATH \\begin align &u + \\theta \\Delta u && \\ge 0 \\\\\\\\ \\Leftrightarrow \\quad &u && \\ge -\\theta \\Delta u \\\\\\\\ \\Leftrightarrow \\quad &- u/\\Delta u && \\ge \\theta \\quad \\text such that -\\Delta u \\gt 0 \\\\\\\\ \\end align MATH This is the process of making MATH feasible. Stage 2: primal feasibility MATH Next, with parameters MATH and MATH set to MATH , the following update is performed. Update MATH until MATH h i x^+ This is the process of making MATH feasible. Stage 3 : reduce MATH Update MATH until MATH is satisfied The update equation in Stage 3 is the same as the existing backtracking line search algorithm. The right-hand side of the above equation can be derived as follows. First, we obtain the following result from Newton's method. > MATH \\begin align \\Delta w = \\Delta x, \\Delta u, \\Delta v &\\approx -r^ ' w ^ -1 r w \\\\\\\\ \\Leftrightarrow r w &\\approx -r^ ' w \\Delta w \\\\\\\\ \\end align MATH Since MATH in the above equation, we substitute this into the first-order Taylor approximation below. > MATH \\begin align r w + \\theta \\Delta w & \\approx r w + r^ ' w \\theta \\Delta w \\\\\\\\ &\\approx 1-\\theta r w \\\\\\\\ \\end align MATH As a result, we get MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter17/17_02_03_primal_dual_algorithm/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter17/17_03_some_history",
    "title": "17-03 Some history",
    "chapter": "17",
    "order": 7,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "Generally, modern state-of-the-art LP Solvers use both Simplex method and interior-point method. Dantzig 1940s : Simplex method, the first method to solve the general form of LP, obtaining exact solutions without iteration. It remains one of the best-known and most studied algorithms for LP to this day. Klee and Minty 1972 : A pathological LP with MATH variables and MATH constraints. Solving with the Simplex method requires MATH iterations. Khachiyan 1979 : A polynomial-time algorithm for LP based on the ellipsoid method of Nemirovski and Yudin 1976 , which is theoretically strong but not so in practice. Karmarkar 1984 : An interior-point polynomial-time LP method that is quite effective and became a breakthrough research. US Patent 4,744,026, expired in 2006 . Renegar 1988 : Newton-based interior-point algorithm for LP. It had the theoretically best computational complexity until the latest research by Lee-Sidford emerged.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter17/17_03_some_history/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter17/17_04_special_case_linear_programming",
    "title": "17-04 Special case, linear programming",
    "chapter": "17",
    "order": 8,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "In this section, let's look at an example of the Primal-Dual method for LP linear programming problems. Linear programming Consider the following primal LP problem. > MATH >\\begin align > &\\min x && c^Tx \\\\\\\\ > &\\text subject to && Ax = b \\\\\\\\ > & && x ≥ 0 \\\\\\ >\\end align > MATH > > MATH The dual problem of the above primal LP problem is as follows. > MATH >\\begin align > &\\max y,s && b^Ty \\\\\\\\ > &\\text subject to && A^Ty + s = c \\\\\\\\ > & && s ≥ 0 \\\\\\ >\\end align > MATH Optimality conditions and central path equations The following shows the optimality conditions KKT Conditions for the primal-dual problem of the previous LP. > MATH > \\begin array rcl > A^Ty + s & = & c \\\\\\ > Ax & = & b \\\\\\ > XS\\mathbb 1 & = & 0 \\\\\\ > x,s & \\succeq & 0 > \\end array > MATH Central path equations > MATH > \\begin array rcl > A^Ty + s & = & c \\\\\\ > Ax & = & b \\\\\\ > XS\\mathbb 1 & = & τ\\mathbb 1 \\\\\\ > x,s & > & 0 > \\end array > MATH Primal-dual method vs. barrier method Newton steps for primer-dual method The following is the Newton equation for the primal-dual method for LP problems. > MATH \\begin bmatrix 0 & A^T & I \\\\\\ A & 0 & 0 \\\\\\ S & 0 & X \\end bmatrix \\begin bmatrix ∆x \\\\\\ ∆y \\\\\\ ∆s \\end bmatrix = − \\begin bmatrix A^Ty + s−c \\\\\\ Ax−b \\\\\\ XS\\mathbb 1 −τ\\mathbb 1 \\end bmatrix MATH From the optimal condition, we can know the following relationship. MATH Accordingly, we can obtain optimal conditions for the primal barrier problem by removing MATH , or obtain optimal conditions for the dual barrier problem by removing MATH . Newton steps for barrier problems The following are the primal and dual central path equations for the barrier problem. Left is primal, right is dual > MATH > \\begin array rcr > A^Ty + τX^ −1 1 & = & c & \\qquad \\qquad & A^Ty + s & = & c \\\\\\ > Ax & = & b & \\qquad \\qquad & τAS^ −1 \\mathbb 1 & = & b\\\\\\ > x & > & 0 & \\qquad \\qquad & s & > & 0 > \\end array > MATH > Using the above central path equations, the Newton steps for primal and dual are as follows. Primal Newton step > MATH \\begin bmatrix τX^ −2 & A^T \\\\\\ A & 0 \\end bmatrix \\begin bmatrix ∆x \\\\\\ ∆y \\end bmatrix = − \\begin bmatrix A^Ty + τX^ −1 \\mathbb 1 −c \\\\\\ Ax−b \\end bmatrix MATH Dual Newton step > MATH \\begin bmatrix A^T & I \\\\\\ 0 & τAS^ −2 \\end bmatrix \\begin bmatrix ∆y \\\\\\ ∆s \\end bmatrix = − \\begin bmatrix A^Ty + s −c \\\\\\ τAS^ −1 \\mathbb 1 −b \\end bmatrix MATH Example: barrier versus primal-dual Standard LP : MATH , MATH To verify the performance of the Primal-dual method, let's look at an example of a standard LP problem with MATH variables and MATH equality constraints. Example from B & V 11.3.2 and 11.7.4 The Barrier method used various MATH values 2, 50, 150 while the primal-dual method fixed MATH at 10. Both methods used MATH . Fig1 Duality gap Barrier vs. Primal-dual 1 As can be seen from the graph, primal-dual converges quickly while showing high accuracy. Sequence of problem : MATH and MATH growing. Now let's look at the performance for a series of problems where MATH and MATH gradually increases. The Barrier method used MATH and the outer loop was performed only about 2 times. The duality gap was reduced to MATH The Primal-dual method used MATH and stopped execution when the duality gap and feasibility gap were approximately MATH . Fig2 Newton iteration Barrier vs. Primal-dual 1 As can be seen from the above figure, the Primal-dual method finds solutions with higher accuracy but requires some additional iterations.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter17/17_04_special_case_linear_programming/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter17/17_05_optimality_conditions_for_semidefinite_programming",
    "title": "17-05 Optimality conditions for semidefinite programming",
    "chapter": "17",
    "order": 9,
    "owner": "Minjoo Lee",
    "lesson_type": "",
    "content": "In this section, we want to look at an example of the Primal-Dual method for SDP semidefinite programming problems. SDP semidefinite programming The primal problem of SDP is defined as follows. > MATH >\\begin align > &\\min x && C \\cdot X \\\\\\\\ > &\\text subject to && A i \\cdot X = b i, i = 1,...,m \\\\\\\\ > & && X \\succeq 0 >\\end align > MATH The dual problem of SDP is defined as follows. > MATH >\\begin align > &\\max y && b^Ty \\\\\\\\ > &\\text subject to && \\sum^m X i=1 y iA i + S = C \\\\\\\\ > & && S \\succeq 0 >\\end align > MATH For reference, the trace inner product of MATH is denoted as follows. > MATH Optimality conditions for SDP The primal and dual problems of SDP can be defined using linear maps as follows. > MATH >\\begin align > &\\min x && C \\cdot X & \\qquad \\qquad \\qquad & \\max y,S && b^Ty \\\\\\\\ > &\\text subject to && \\mathcal A X = b & \\qquad \\qquad \\qquad & \\text subject to && \\mathcal A ^ ∗ y + S = C \\\\\\\\\\ > & && X \\succeq 0 & \\qquad \\qquad \\qquad & && S \\succeq 0 >\\end align > MATH Here MATH means a linear map. Assuming strong duality is satisfied, MATH and MATH where MATH is a solution are optimal solutions for primal and dual, and vice versa. > MATH > \\begin array rcl > \\mathcal A ^∗ y + S & = & C \\\\\\ > \\mathcal A X & = & b \\\\\\ > XS & = & 0 \\\\\\ > X,S & \\succeq & 0 > \\end array > MATH Central path for SDP Primal barrier problem > MATH >\\begin align > &\\min x && C \\cdot X−τ \\log det X \\\\\\\\ > &\\text subject to && A X = b >\\end align > MATH Dual barrier problem > MATH >\\begin align > &\\max y, S && b^Ty + τ \\log det S \\\\\\\\ > &\\text subject to && \\mathcal A ^∗ y + S = C >\\end align > MATH Primal & dual을 위한 Optimality conditions > MATH > \\begin array rcl > \\mathcal A ^∗ y + S & = & C \\\\\\ > \\mathcal A X & = & b \\\\\\ > XS & = & τI \\\\\\ > X,S & \\succ & 0 > \\end array > MATH Newton step Primal central path equations > MATH > \\begin array rcl > \\mathcal A ^∗ y + \\tau X^ −1 & = & C \\\\\\ > \\mathcal A X & = & b \\\\\\ > X & \\succ & 0 > \\end array > MATH Newton equations > MATH > MATH The central path equation and Newton equation for the dual are similarly defined including MATH . Primal-dual Newton step Primal central path equations > MATH \\begin bmatrix \\mathcal A ^∗ y + S - C \\\\\\ \\mathcal A X - b \\\\\\ XS \\end bmatrix = \\begin bmatrix 0 \\\\\\ 0 \\\\\\ τI \\end bmatrix , X, S \\succ 0 MATH Newton step: > MATH \\begin bmatrix 0 & \\mathcal A ^∗ & I \\\\\\ \\mathcal A & 0 & 0 \\\\\\ S & 0 & X \\end bmatrix \\begin bmatrix \\Delta X \\\\\\ \\Delta y \\\\\\ \\Delta S \\end bmatrix = − \\begin bmatrix \\mathcal A ^∗ y + s−c \\\\\\ \\mathcal A x − b \\\\\\ XS − \\tau I \\end bmatrix MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter17/17_05_optimality_conditions_for_semidefinite_programming/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter18/18_00_Quasi_Newton_methods",
    "title": "18-00 Quasi-Newton methods",
    "chapter": "18",
    "order": 1,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "In the mid-1950s, physicist W.C. Davidon, who was working at Argonne National Laboratory, was solving optimization problems with large computational requirements using coordinate descent methods. Unfortunately, due to the instability of computers at the time, system crashes frequently occurred before computations could be completed, and frustrated by this, Davidon decided to find methods that could improve computational speed. This led to the birth of the first Quasi-Newton algorithm. This became a catalyst for dramatic progress in nonlinear optimization, and subsequently, various follow-up studies on this method emerged over the next 20 years. Ironically, Davidon's research http://www.math.mcgill.ca/dstephens/680/Papers/Davidon91.pdf was not published at the time and remained as a technical report for more than 30 years. It was finally published in the first issue of SIAM Journal on Optimization https://epubs.siam.org/toc/sjope8/1/1 in 1991. Quasi-Newton methods require only the gradient of the objective function at each iteration. This has much less computational burden than Newton methods that require second derivatives, and moreover shows superlinear convergence, making it a sufficiently attractive method 14 . Motivation for Quasi-Newton methods Consider the following unconstrained, smooth optimization problem: > MATH > \\min x \\: f x , \\\\\\\\ > \\text where f \\text is twice differentiable, and dom \\; f = \\mathbb R ^n. > MATH The update methods for x in Gradient descent method and Newton's method for the above problem are as follows: > Gradient descent method: > MATH >x^+ = x - t \\nabla f x > MATH > Newton's method: > MATH >x^+ = x - t \\nabla^2 f x ^ -1 \\nabla f x > MATH Newton's method has the advantage of showing quadratic convergence rate MATH , but there are problems with significantly high computational costs in the following two processes: Computing the Hessian MATH : Computing and storing the Hessian matrix requires MATH memory. This is not suitable performance for handling high-dimensional functions. reference: Hessian matrix https://en.wikipedia.org/wiki/Hessian matrix Use in optimization in Wikipedia Solving the equation MATH : To solve this equation, we must compute the inverse matrix of the Hessian MATH . reference: Computational complexity of Matrix algebra https://en.wikipedia.org/wiki/Computational complexity of mathematical operations Matrix algebra in Wikipedia Quasi-Newton methods use an approximation MATH instead of MATH . > Quasi-Newton method: > MATH >x^+ = x + tp \\\\\\\\ >\\text where Bp = -\\nabla f x . > MATH Here, B should be easy to compute, and it should also be easy to solve the equation MATH . Quasi-Newton Algorithm The Quasi-Newton algorithm is as follows: Pick initial MATH and MATH For MATH Solve MATH Pick MATH and let MATH Update MATH to MATH End for A major characteristic of this method is updating MATH so that we can gradually approach the optimal point. That is, the method of obtaining the next step MATH from MATH will be the main topic of discussion in this chapter. Note: For convenience, we will use the two notations MATH and MATH interchangeably.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter18/18_00_Quasi_Newton_methods/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter18/18_01_Secant_Equation_and_Curvature_Condition",
    "title": "18-01 Secant Equation and Curvature Condition",
    "chapter": "18",
    "order": 2,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Secant Equation As mentioned earlier, MATH is a matrix that approximates MATH . For matrix MATH to have similar properties to the Hessian MATH , it must satisfy a condition called the secant equation. When MATH and MATH is twice differentiable, the first-order Taylor expansion of MATH shows that the true Hessian has the following property. > MATH Here, we call the approximation matrix of MATH as MATH . This matrix satisfies the following equation. > MATH If MATH , then the above equation can be rearranged as follows, and this is called the secant equation. > MATH >B^ k+1 s^k = y^k > MATH The Intuition of Secant Equation MATH axis은 MATH 를, MATH axis은 MATH 를 나타낸다고 할when, MATH 은 MATH and, MATH 를 통and,하는 직선의 기울기and, 같다. Fig1 The intuition of secant equation Conditions to Determine MATH matrix MATH 를 basis,with, computation된 MATH 는 다음의 3가지 condition,을 만족solution야한다. 1. MATH is symmetric: Because it is an approximation of the Hessian. 2. MATH close to MATH : A condition to determine a unique MATH . Since MATH already contains useful information, we choose the matrix closest to MATH among those MATH that satisfy the secant equation. 3. MATH is positive definite MATH is positive definite: To guarantee global optimum, we maintain the convexity of the problem. reference: Analyzing the hessian https://web.stanford.edu/group/sisl/k12/optimization/MO-unit4-pdfs/4.10applicationsofhessians.pdf Curvature Condition The fact that MATH is positive definite and MATH implies the following fact. > MATH reference: positive definite in WikiPedia https://en.wikipedia.org/wiki/Positive-definite matrix Here, MATH is called the curvature condition. If the curvature condition is satisfied, the secant equation MATH always has a solution MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter18/18_01_Secant_Equation_and_Curvature_Condition/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter18/18_02_Symmetric_Rank_One_Update_(SR1)",
    "title": "18-02 Symmetric Rank-One Update (SR1)",
    "chapter": "18",
    "order": 3,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "The SR1 update is a method that updates MATH with a rank-1 symmetric matrix so that MATH maintains symmetry and continues to satisfy the secant equation. If a rank-1 symmetric matrix is decomposed as a product of MATH and MATH , the update form would be as follows. > MATH Key Observation MATH and MATH must be chosen so that MATH satisfies the secant equation. Thus, let's substitute the update form introduced above into the secant equation MATH . > MATH Since MATH is a scalar, MATH can also be expressed as a product of MATH and an arbitrary scalar MATH MATH . Let's substitute MATH in 1 with MATH . > MATH The parameters MATH and MATH that satisfy the above equation are as follows. > MATH The Only SR1 Updating Formula Using the information obtained from the key observation, we can derive the unique form of SR1 update 14 section 6.2 . MATH and substituting 2 into MATH . MATH > MATH >B^+ = B + \\frac y-Bs y-Bs ^T y-Bs ^Ts . > MATH > The Update Formula for the Inverse Hessian Approximation To find MATH , we need to compute MATH . > MATH If we can update MATH instead of MATH , wouldn't we be able to reduce the cost of computing MATH every time? Using the Sherman–Morrison formula https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison formula , we can see through the derivation process that MATH can also be updated in the same form. MATH > MATH >H^+ = H + \\frac s-Hy s-Hy ^T s-Hy ^Ty . > MATH Shortcomings of SR1 SR1 has the advantage of being very simple, but it has two critical shortcomings. 1. The update can fail when MATH approaches 0. 2. It cannot maintain the positive definiteness of MATH and MATH . The following sections introduce methods that complement the shortcomings of SR1.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter18/18_02_Symmetric_Rank_One_Update_(SR1)/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter18/18_03_Davidon_Fletcher_Powell_(DFP)_Update",
    "title": "18-03 Davidon-Fletcher-Powell (DFP) Update",
    "chapter": "18",
    "order": 4,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "The DFP update is a method that updates MATH with a rank-2 symmetric matrix. > MATH If MATH computed through the DFP update satisfies the secant equation, then MATH can be expressed as a linear combination of MATH and MATH . reference: by the secant equation, MATH > MATH > > MATH Setting MATH and solving for MATH and MATH , we derive the updating formula for MATH . > MATH > H^+ = H - \\frac Hyy^TH y^THy + \\frac ss^T y^Ts > MATH Similar to the SR1 update, we can derive the updating formula for MATH using the Sherman–Morrison formula https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison formula . > MATH >\\begin align >B^+ &= B + \\frac y-Bs y^T y^Ts + \\frac y y-Bs ^T y^Ts - \\frac y-Bs ^Ts y^Ts ^2 yy^T\\\\\\\\ > &= \\big I - \\frac ys^T y^Ts \\big B \\big I - \\frac sy^T y^Ts \\big + \\frac yy^T y^Ts >\\end align > MATH If MATH is positive definite, then MATH becomes positive semidefinite. In this case, if MATH is positive definite, then MATH is guaranteed to be positive definite. This solves the problem of maintaining positive definiteness that was raised with SR1. DFP Update - Alternate Derivation Recall: if the curvature condition MATH is satisfied, then there exists a symmetric positive definite matrix that satisfies the secant equation. The DFP update can also be derived by solving the problem of minimizing the weighted Frobenius norm between matrix MATH and MATH where MATH 1. satisfies symmetry and 2. satisfies the secant equation. Each different matrix norm corresponds to each different Quasi-Newton method. Among them, the norm that makes it easy to solve this problem while also making it work as a scale-invariant optimization method is the weighted Frobenius norm. >Solve > MATH >\\begin align >& \\min B^+ \\: \\: && \\|W^ 1/2 B^+ - B W^ 1/2 \\| F \\\\\\\\ >& \\text subject to && B^+ = B^+ ^T \\\\\\\\ > &&& B^+s = y \\\\\\\\ >& \\text where && W \\in \\mathbb R ^ n \\; \\times \\;n \\text is nonsingular and such that Wy k = s k. >\\end align \\\\\\\\ > MATH reference : Frobenius norm: The Frobenius norm of matrix MATH is defined as follows. MATH \\| A \\| F \\doteq \\sum i,j A i,j ^2 ^ 1/2 MATH Weighted Frobenius norm: The weighted Frobenius norm of matrix MATH with weight matrix MATH is defined as follows. MATH \\|A\\| W \\doteq \\| W^ 1/2 A W^ 1/2 \\| F MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter18/18_03_Davidon_Fletcher_Powell_(DFP)_Update/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter18/18_04_Broyden_Fletcher_Goldfarb_Shanno_(BFGS)_update",
    "title": "18-04 Broyden-Fletcher-Goldfarb-Shanno (BFGS) update",
    "chapter": "18",
    "order": 5,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "The idea of BFGS is the same as DFP. The only difference is that the roles of B and H are reversed. BFGS is derived by solving the following problem. >Solve > MATH >\\begin align >& \\min H^+ \\: \\: && \\|W^ 1/2 H^+ - H W^ 1/2 \\| F \\\\\\\\ >& \\text subject to && H^+ = H^+ ^T \\\\\\\\ >&&& H^+s = y \\\\\\\\ >& \\text where && W \\in \\mathbb R ^ n \\; \\times \\;n \\text is nonsingular and such that Ws k = y k. >\\end align \\\\\\\\ > MATH The derived updating formulas for MATH and MATH are as follows. > MATH > B^+ = B - \\frac Bss^TB s^TBs + \\frac yy^T y^Ts > MATH and > MATH >\\begin align >H^+ &= H + \\frac s-Hy s^T y^Ts + \\frac s s-Hy ^T y^Ts - \\frac s-Hy ^Ty y^Ts ^2 ss^T\\\\\\\\ > &= \\big I - \\frac sy^T y^Ts \\big H \\big I - \\frac ys^T y^Ts \\big + \\frac ss^T y^Ts >\\end align > MATH BFGS also, DFP처럼 positive definiteness를 유지한다. if, MATH 가 positive definite이고 MATH 이면 MATH 는 positive definite이다. BFGS의 특장점은 self-correcting property를 지니고 있다는 것이다. if, matrix MATH 가 부정확하게 추정되어 iteration의 속도가 느려지게 되면 Hessian approximation이 단 몇 step 만to, 이를 바to,잡는 경향성을 보인다. 반면 DFP는 잘못된 Hessian approximation의 추정about, effect,적with, 바to,잡지 못하므to, 실전at,는 usually, BFGS의 성능이 더 좋은 편이다 14 .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter18/18_04_Broyden_Fletcher_Goldfarb_Shanno_(BFGS)_update/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter18/18_05_The_Broyden_Class",
    "title": "18-05 The Broyden Class",
    "chapter": "18",
    "order": 6,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "The Broyden class generalizes BFGS, DFP, and SR1 with the following formula. Note: MATH and, MATH 는 각각 BFGSand, DFPby, 유도되는 MATH 다. > MATH >B^+ = 1 - \\phi B^+ \\text BFGS + \\phi B^+ \\text DFP , \\text for \\phi \\in \\mathbb R . > MATH MATH 를 MATH to, 정의하면 위 공식은 아래and, 같이 정리된다. > MATH >B^+ = B - \\frac Bss^TB s^TBs + \\frac yy^T y^Ts + \\phi s^TBs vv^T. > MATH Observe: MATH 일when,, 위 update는 BFGSand, 동일solution진다. MATH 일when,, 위 update는 DFPand, 동일solution진다. MATH 일when,, 위 update는 SR1and, 동일solution진다. reference : MATH 의 범위를 MATH to, 제한한 특수한 case,를 restricted Broyden class라 부른다 14 .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter18/18_05_The_Broyden_Class/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter18/18_06_Superlinear_convergence",
    "title": "18-06 Superlinear convergence",
    "chapter": "18",
    "order": 7,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Assumption1: > The Hessian matrix MATH is Lipschitz continuous at MATH , that is, > MATH > for all MATH near MATH , where MATH is a positive constant. Assumption2: Wolfe conditions > Assume MATH is chosen via backtracking so that > MATH > and > MATH > for MATH >\\lim k \\rightarrow \\infty \\frac \\| x^ k+1 - x^\\ast \\| \\| x^k - x^\\ast \\| = 0. > MATH Theorem Dennis-Moré 다음은 Quasi-Newton method의 search direction이 Newton direction을 충분히 잘 approximation하고 있을when,, solutionwith, convergence하는 processat, step length가 Wolfe conditions를 만족함을 보인다. Superlinear convergence를 보이기 for, search direction이 만족solution야하는 condition,이라고도 할 수 있다 14 . > MATH 가 두 번 미분 가능하고 MATH s.t. MATH 이며 MATH 가 positive definite이라고 let's assume. > > MATH > >if, search direction MATH 가 위 condition,을 만족하면, 다음 두 가지 항목을 만족하는 MATH 가 존재한다. > > 1. MATH about, step length MATH 은 Wolfe conditions를 만족한다. > 2. if, MATH about, MATH 이면 MATH 는 superlinear convergence를 보인다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter18/18_06_Superlinear_convergence/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter18/18_07_Limited_Memory_BFGS_(LBFGS)",
    "title": "18-07 Limited Memory BFGS (LBFGS)",
    "chapter": "18",
    "order": 8,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Introduction LBFGS is an example of Limited-memory quasi-Newton methods, and is useful when the cost of computing or storing the Hessian matrix is not reasonable. This method estimates approximates the Hessian matrix by maintaining only a few MATH -dimensional vectors instead of storing a dense MATH Hessian matrix. The LBFGS algorithm is based on BFGS, as its name suggests. The main idea is to use curvature information from the most recent iterations to estimate the Hessian. On the other hand, curvature information from older iterations is not used to save storage space, as it may be somewhat distant from the behavior shown by the Hessian of the current iteration. As a side note, limited-memory versions of other quasi-Newton algorithms e.g., SR1 can also be derived using the same technique 14 . LBFGS LBFGS를 본격적with, 설명하기to, 앞서 BFGS methodabout, 다시 let's look at. 각 stepat, BFGS는 as follows: MATH 를 업데이트 한다. > MATH >x^+ = x - t H \\nabla f, \\\\\\\\ >\\text where t \\text is the step length and H \\text is updated at every iteration by means of the formula, \\\\\\\\ >\\text \\\\\\\\ >H^+ = \\big I - \\frac sy^T y^Ts \\big H \\big I - \\frac ys^T y^Ts \\big + \\frac ss^T y^Ts .\\\\\\\\ > MATH MATH to, about, 업데이트 식을 이용하면 MATH 를 임의의 scalar MATH and, 임의의 vector MATH 를 using, 표현할 수 있다. > MATH >\\begin align >H^+q &= \\big I - \\frac sy^T y^Ts \\big H \\big I - \\frac ys^T y^Ts \\big q + \\frac ss^Tq y^Ts \\\\\\\\ > &= \\big I - \\frac sy^T y^Ts \\big \\underbrace H \\\\big q - \\frac s^T q y^Ts y \\big p + \\underbrace \\frac s^Tq y^Ts \\alpha s\\\\\\\\ > &= \\big I - \\frac sy^T y^Ts \\big p + \\alpha s\\\\\\\\ > &= p - \\underbrace \\frac y^Tp y^Ts \\beta s + \\alpha s \\\\\\\\ > &= p + \\alpha - \\beta s,\\\\\\\\ >& \\text where \\alpha = \\frac s^Tq y^Ts , q^+ = q - \\alpha y, p = Hq, \\beta = \\frac y^Tp y^Ts . >\\end align \\\\\\\\ > MATH MATH 가 k번의 BFGS update를 through, 얻이진다고 할when,, MATH 는 length k의 iteration문 2개to, computation할 수 있다 아래 algorithm reference . 단, 메모리의 효율적인 사용을 for, 가장 최근 MATH 개 iterationsat,의 curvature information만을 이용한다. MATH Algorithm Fig1 The algorithm of LBFGS 3 usually, inverse Hessian approximation MATH 는 dense하며, variable의 개수가 많은 case, 저장 및 operation 비용이 매우 높아지게 된다. 반면 LBFGS는 MATH 을 연속한 vectorsumand, vectorproductwith, obtaining,냄with,써 MATH 의 computation 및 유지를 위한 비용problem를 완화시킬 수 있다. 뿐만 아니라 이 computationto, 사용되는 initial Hessian approximation MATH 는 usually, 실전at, 매우 effect,적with, 작동한다고 검증된 identity matrixto, 어떤 constant를 product한 형태 MATH 를 띄기 because of, 유지 및 computationto, 그다지 큰 비용이 발생하지 않는다 14 의 7.2 . > MATH > H^ 0,k = \\gamma k I, \\\\\\\\ > \\text where \\: \\gamma k = \\frac s^T k-1 y k-1 y^T k-1 y k-1 . > MATH Note: MATH 는 매 iteration마다 다르게 선택될 수 있다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter18/18_07_Limited_Memory_BFGS_(LBFGS)/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_00_Proximal_Newton_Method",
    "title": "19 Proximal Newton Method",
    "chapter": "19",
    "order": 1,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "In this chapter, we will examine Proximal Newton Method , Proximal quasi-Newton method , and Projected Newton method . Reference Papers Proximal Newton method: J. Friedman and T. Hastie and R. Tibshirani 2009 , \"Regularization paths for generalized linear models via coordinate descent\" C.J. Hsiesh and M.A. Sustik and I. Dhillon and P. Ravikumar 2011 , \"Sparse inverse covariance matrix estimation using quadratic approximation\" M. Patriksson 1998 , \"Cost approximation: a unified framework of descent algorithms for nonlinear programs\" J. Lee and Y. Sun and M. Saunders 2014 , \"Proximal Newton-type methods for minimizing composite functions\" P. Tseng and S. Yun 2009 , \"A coordinate gradient descent method for nonsmooth separable minimization\" Projected Newton method: A. Barbero and S. Sra 2011 , \"Fast Newton-type methods for total variation regularization\" D. Bertsekas 1982 , \"Projected Newton methods for optimization problems with simple constraints\" D. Kim and S. Sra. and I. Dhillon 2010 , \"Tackling box-constrained optimization via a new projected quasi-Newton approach\" M. Schmidt and D. Kim and S. Sra 2011 , \"Projected Newton-type methods in machine learning\"",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_00_Proximal_Newton_Method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_01_00_Proximal_Newton_method",
    "title": "19-01 Proximal Newton method",
    "chapter": "19",
    "order": 2,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "In this section, we will review the proximal gradient method and examine how the proximal newton method emerged from it. We will also examine the definition of the proximal newton method and the scaled proximal map that has good properties such as uniqueness and non-expansiveness compared to the general proximal map.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_01_00_Proximal_Newton_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_01_01_Reminder:_proximal_gradient_descent",
    "title": "19-01-01 Reminder - proximal gradient descent",
    "chapter": "19",
    "order": 3,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Before examining the Proximal newton method that we will learn in this chapter, let's first review Proximal gradient descent . For detailed information, see 09 Proximal Gradient Descent and Acceleration % multilang post url contents/chapter09/20-01-08-09 proximal gradient descent and acceleration % see. Proximal gradient descent Proximal gradient descent works on the following problem. > MATH MATH is convex and differentiable. dom MATH MATH is convex and non-differentiable and \"simple\". Algorithm Proximal gradient descent는 시작점 MATH at, 시작solution서 다음 process을 iteration한다. > MATH 여기서 MATH 는 MATH and, association,된 proximal operator 이다. > \\begin align \\text prox t x = \\underset z \\text argmin \\frac 1 2t \\parallel x - z \\parallel 2^2 + h z \\end align Update 식은 generalized gradient MATH 를 using,서 표준화된 형태to, 표현할 수도 있다. > \\begin align > x^ k = x^ k-1 - t k \\cdot G t k x^ k-1 , \\space \\space \\text where \\space G t x = \\frac x-\\text prox t x - t \\nabla g x t \\\\\\\\ > \\end align Performance Proximal gradient descent 의 성능은 MATH according to, 달라질 수 있다. if,, MATH 가 복잡한 function이고 particularly, closed form이 아니라면 minimize할 when, computation을 많이 solution야 하므to, 성능이 매우 떨어질 수 있다. also,, MATH function의 convergence rateand, 같은 convergence 속도를 갖는다. 단, iteration할 when,마다 prox operator를 실행하기 because of, prox computation이 효율적인 case,to,만 유용하다. Motivation Proximal gradient descent at,는 미분 가능한 function MATH 를 Taylor 2difference식with, approximation하고 여기to, 미분이 되지 않는 function인 MATH 를 더하여 목적 functionto, 정의한 후 이를 iteration적with, minimization한다. therefore,, as follows: 2difference 식with, 정리solution 볼 수 있다. 식to, 전개되는 자세한 process은 09-01 Proximal gradient descent % multilang post url contents/chapter09/20-01-08-09 01 proximal gradient descent % reference. > MATH > \\begin align x^+ & = \\underset z \\text argmin \\, \\frac 1 2t \\parallel x - t \\nabla g x - z \\parallel 2 ^2 + h z \\\\\\\\ > & = \\underset z \\text argmin \\ \\nabla g x ^T z - x + \\frac 1 2t \\parallel z - x \\parallel 2 ^2 + h z \\\\\\\\ > \\end align > MATH 두번째 식의 1항and, 2항은 MATH 의 Taylor 2difference approximation식with, from, 유도할 수 있는데, first, constant항 MATH 은 제거하고 gradient descentat,and, 마찬가지to, Hessian MATH 을 MATH spherical curvature to, 대체solution서 구할 수 있다. 다음 그림at,는 proximal gradient descent의 update stepat, MATH 를 2difference approximation식with, minimization 하는 process을 showing,주고 있다. Fig 1 Proximal gradient descent updates 3 Gradient descentand, newton's method의 difference이점는 2difference approximation를 할 when, function의 local hessian인 MATH 를 사용하는지 여부이다. 그렇다면, 위의 식at, MATH instead, MATH 를 사용하면 어떻게 될까? 이것이 바to, 다음 절at, 설명하게 될 proximal newton method 가 나오게 된 background,이다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_01_01_Reminder-_proximal_gradient_descent/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_01_02_Proximal_Newton_method",
    "title": "19-01-02 Proximal Newton method",
    "chapter": "19",
    "order": 4,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "In the previous section, we explained that the proximal newton method is a method that wants to use the local hessian MATH instead of the spherical curvature MATH in the proximal gradient descent formula. The proximal newton method is an old idea that is being studied in statistics under the term local score. Now let's look at how the proximal newton method can be formulated. Algorithm The Proximal gradient descent algorithm consists of the process of finding the direction MATH of the next step and then optimizing the step size MATH . Step 1: Starting from the starting point MATH , iterate the following process. MATH Step 2: Find the direction MATH of the next step. > \\begin align v^ k & = \\underset v \\text argmin \\ \\nabla g x^ k-1 ^T v + \\frac 1 2 v^T H^ k-1 v + h x^ k-1 + v \\end align 여기서 MATH 은 MATH at,의 Hessian이다. 3step : MATH directionwith, step을 이동하기 for, step size를 optimization한다. > \\begin align x^ k & =x^ k-1 + t k v^ k \\end align MATH 는 step sizeto, MATH 이면 pure proximal Newton method이다. Backtracking line search를 through, step size를 optimization하는 process이 있다는 점은 proximal gradient descent methodand, 다른 점이다. Next position view 위의 식을 direction MATH 이 아닌 다음 position인 MATH 의 관점at, 표현하면 as follows:. > MATH > \\begin align > z^ k & = \\underset z \\text argmin \\ \\nabla g x^ k-1 ^T z - x^ k-1 ^T + \\frac 1 2 z - x^ k-1 ^T H^ k-1 z - x^ k-1 + h z \\\\\\\\ > x^ k & =x^ k-1 + t k z^ k - x^ k-1 > \\end align > MATH 직관적with, 첫번째 stepat, 목적 function를 minimization 하는 surrogate point인 MATH 를 구한다. 그런 다음, MATH at, MATH 의 directionwith, 이동but, always, MATH to, 이동하게 되는 것은 아니다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_01_02_Proximal_Newton_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_01_03_Scaled_proximal_map",
    "title": "19-01-03 Scaled proximal map",
    "chapter": "19",
    "order": 5,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Proximal newton method 를 proximal gradient descent and, 같은 형식with, 다시 작성solution 볼 수 있다. Scaled proximal map if, MATH 라고 하면 scaled proximal map 은 as follows: 정의된다. > \\begin align \\text prox t x = \\underset z \\text argmin \\frac 1 2 \\parallel x - z \\parallel H^2 + h z \\end align 여기서 MATH with, MATH 이다. MATH 일 when, 일반적인 unscaled proximal map 이 된다. generally, scaled proximal map 는 usually,의 prox보다 좋은 성질을 갖고 있다. uniqueness : solution가 하나만 존재하는 성질 MATH 이므to, strictly convex optimization problem이기 because of, 만족된다. non-expansiveness : 팽창하지 않는 성질 scaled proximal map이 non-expansive 성질을 갖는 projection operator의 일반화이기 because of, 만족된다. reference Projection operator의 non-expansiveness 두 점 MATH , MATH and, convex set MATH to, about, projection operator MATH about, non-expansiveness란 MATH 를 만족한다는 것을 의미한다. that is,, MATH 는 Lipschitz-1을 만족하며 MATH 가 convex일 case,to,만 만족한다. Fig 1 Projection onto a convex set C 3 Proximal newton update Scaled proximal map 을 using,서 Proximal newton update를 다시 expressing,보면 as follows:. > MATH > \\begin align > z^ + & = \\underset z \\text argmin \\nabla g x ^T z - x ^T v + \\frac 1 2 z - x ^T H z - x + h z \\\\\\\\ > & =\\underset z \\text argmin \\ \\frac 1 2 \\parallel x - H^ -1 \\nabla g x - z \\parallel H^2 + h z > \\end align > MATH 다르게 표현하면 as follows:. > MATH > \\begin align > z^ k & = \\text prox H^ k-1 x^ k-1 - H^ k-1 ^ -1 \\nabla g x^ k-1 \\\\\\\\ > x^ k & =x^ k-1 + t k z^ k - x^ k-1 > \\end align > MATH 직관적with, MATH about,서 newton step을 수행하고, MATH about, scaled prox operator를 applying,서 그 directionwith, 이동한다는 것을 의미한다. 이from, 다음and, 같은 사항을 알 수 있다. MATH 일when, proximal operator는 identity function가 되여 일반적인 Newton update가 된다. MATH 를 MATH to, 대체하고 MATH to, 두면 step size MATH about, proximal gradient update를 구할 수 있다. Prox의 어려움은 MATH 뿐만 아니라 MATH 의 hessian의 구조according to, 달라진다. for example, MATH 가 diagonal이거나 banded이면 dense한 MATH 일 case,to, 비solution problem가 매우 쉬워진다. therefore,, proximal Newton method는 proximal gradient descentand, Newton's method를 둘 다 일반화한 것임을 알 수 있다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_01_03_Scaled_proximal_map/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_02_Backtracking_line_search",
    "title": "19-02 Backtracking line search",
    "chapter": "19",
    "order": 6,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Proximal newton method may not converge in cases with pure step size MATH like newton's method. Therefore, we need to optimize the step size through backtracking line search. Backtracking line search algorithm 1. Initialize parameters. MATH 2. At each iteration, compute the Proximal newton direction as MATH . 3. Initialize MATH . 4. If the condition MATH is satisfied, reduce MATH . Iterate step 4 while this condition is satisfied. MATH 5. Execute the Proximal newton update MATH . 6. If the termination condition is not satisfied, go to step 2. Intuitively, we find a step size MATH such that we move along direction MATH to a position where the linear approximation of function MATH at MATH is reduced by a factor of MATH . Since the MATH part of MATH is not differentiable, we use the discrete derivative MATH . Efficiency of algorithm There are many methods for performing backtracking line search, and here we have introduced one of them. In this method, when computing MATH , the prox operator is computed only once. In the case of proximal gradient descent, the prox operator had to be computed iteratively in the inner loop, which is a distinctly different characteristic. Therefore, this method can perform backtracking line search very efficiently when the computation of the prox operator is complex. reference Method 별 backtracking line search Gradient descent 06-02-02 Backtracking line search % multilang post url contents/chapter06/21-03-20-06 02 02 backtracking line search % Proximal gradient descent 09-02 Convergence analysis % multilang post url contents/chapter09/20-01-08-09 02 convergence analysis % Newton's method 14-04 Backtracking line search % multilang post url contents/chapter14/2021-03-26-14 04 backtracking line search %",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_02_Backtracking_line_search/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_03_When_would_we_use_proximal_Newton",
    "title": "19-03 When would we use proximal Newton?",
    "chapter": "19",
    "order": 7,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "When should we use the proximal newton method? To understand the usefulness of the proximal newton method, let's compare the proximal newton method and proximal gradient descent on the following problem. Problem : MATH Proximal gradient descent vs. proximal newton | Proximal gradient descent | Proximal Newton | | -------- | -------- | | MATH minimization | MATH minimization | | Prox operator가 대부분 closed formwith, 정의됨 | Prox operator가 대부분 closed formwith, 정의되지 않음 | iteration이 저렴 | iteration이 아주 비쌈 newton method보다 비쌈 | | Gradient descent convergence 속도 MATH | Newton's method convergence 속도 MATH | 두 method은 비슷solution 보이지만 실제 매우 다른 일을 한다. therefore,, proximal newton method는 아주 적은 iteration을 기대할 수 있는 scaled prox operator quadratic + MATH to, about, 빠른 inner optimizer를 가질 when, 사용할 수 있다. MATH 가 separable function일 when, inner optimizerto, 가장 많이 사용되는 method이 coordinate descent이다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_03_When_would_we_use_proximal_Newton/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_04_Convergence_analysis",
    "title": "19-04 Convergence analysis",
    "chapter": "19",
    "order": 8,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "To analyze the convergence of the Proximal Newton method, we will follow the proof from Lee 2014 1 . 1 J. Lee and Y. Sun and M. Saunders 2014 , Proximal Newton-type methods for minimizing To prove convergence, we make the following assumptions: MATH , MATH and MATH are convex and MATH is twice differentiable smooth MATH . MATH is Lipschitz with constant MATH MATH can be computed exactly The above three assumptions imply that the function is strictly convex, and assuming that MATH can be computed exactly is because this is not easy to achieve in practice. Convergence Theorem > Proximal Newton method converges globally using backtracking line search. > \\begin align \\parallel x^ k - x^ \\star \\parallel 2 \\le \\frac M 2m \\parallel x^ k-1 - x^ \\star \\parallel 2^2 \\end align This is called local quadratic convergence . After MATH , to satisfy MATH , MATH iterations are needed. However, each iteration uses a scaled prox. Proof sketch To show global convergence , we can show that at any step, the backtracking exit condition for step size MATH is satisfied as follows. > \\begin align t \\le \\min \\left\\\\ 1, \\frac 2m L 1-\\alpha \\right\\\\ \\\\\\\\ \\end align With this equation, we can show that when the global minimum is reached, the update direction converges to 0. To show local quadratic convergence , after sufficiently many iterations, the pure Newton step MATH satisfies the backtracking exit conditions, and the following equation holds. > MATH > \\begin align > \\parallel x^ + - x^ \\star \\parallel 2 & \\le \\frac 1 \\sqrt m \\parallel x^ + - x^ \\star \\parallel H \\\\\\\\ > & = \\frac 1 \\sqrt m \\parallel \\text prox H x - H^ -1 \\nabla g x - \\text prox H x^ \\star - H^ -1 \\nabla g x^ \\star \\parallel H \\\\\\\\ > & \\le \\frac M 2m \\parallel x - x^ \\star \\parallel 2^2 \\\\\\\\ > \\end align > MATH Summarizing this, we get the following: > \\begin align \\parallel x^ + - x^ \\star \\parallel 2 \\ \\le \\ \\frac 1 \\sqrt m \\parallel x^ + - x^ \\star \\parallel H \\ \\le \\ \\frac M 2m \\parallel x - x^ \\star \\parallel 2^2 \\end align The first inequality holds due to the lowest eigenvalue bound, and the equality holds by the fact that MATH becomes the identity at the definition of MATH and global minimum MATH . The second inequality holds due to the nonexpansiveness of the proximal operator, the Lipschitz assumption, and the largest eigenvalue bound.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_04_Convergence_analysis/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_05_Notable_examples",
    "title": "19-05 Notable examples",
    "chapter": "19",
    "order": 9,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Glmnet and QUIC Proximal newton method의 매우 유명한 패키지가 두 가지가 있다. glmnet Friedman et al., 2009 : MATH penalized generalized linear modelsto, about, prox Newton를 구현한 패키지. Coordinate descent를 using,서 inner problem을 푼다. QUIC Hsiesh et al., 2011 : graphical lasso problemto, about, prox Newton을 구현한 패키지. Factorization trick을 사용하고 coordinate descent를 using,서 inner problem을 푼다. 두 구현 패키지는 각자의 용도to, 맞춰서 매우 광범위하게 사용되고 있으며 state-of-the-art라고 할 수 있다. Proximal Newton method는 proximal gradient보다 MATH 의 gradient을 덜 자주 computation한다. therefore,, computation 비용이 커질수록 proximal newton이 유리하다. also,, inner solver를 신중하게 선택할수록 좋은 성능을 얻을 수 있다. Example: lasso logistic regression Lee et al. 2012 논문at, 제시된 예제를 let's look at. MATH regularized logistic regressionto,대solution 다음 세가지 methodabout,서 성능을 평가하였다. 1.FISTA : accelerated prox grad 2. spaRSA : spectral projected gradient method 3. PN : proximal Newton Dense hessian X n=5000, p=6000 예시 데이터 수 n = 5000, feature 개수 p = 6000인 dense feature matrix MATH 를 갖는 problemabout, 다음and, 같은 성능을 보였다. Hessian이 dense하기 because of, 매우 challenging한 problem라고 할 수 있다. Fig 1 Dense hessian X n=5000, p=6000 2 오른쪽은 function 호출 기준with,, 왼쪽은 시간 기준with, 평가한 것with,서, function 호출 기준with, 봤을 when,가 PN의 성능이 매우 우세함을 알 수 있다. 여기서 비용은 MATH and, MATH 를 computation하는 시간이 대부분이며 particularly, MATH and, MATH function를 computation하는 시간이 많이 들었다. Sparse hessian X n=542,000, p=47,000 예시 다음의 case,는 MATH 가 sparse하기 because of, MATH and, MATH 를 computation하는 시간이 덜 들었다. Fig 2 Sparse hessian X n=542,000, p=47,000 2 Inexact prox evaluations Proximal Newton methodat, proximal operation을 computation할 when, prox operator가 closed form이 아니기 because of, 정확히 computation하지 못한다. 그럼to,도 불구하고, 매우 높은 정확도를 갖는다면 매우 좋은 성질이 될 수 있다. Lee 2014 at,는 global convergenceand, local superlinear convergence를 보장하는 inner problem의 stopping rule을 제안했다. Three stopping rules Graphical lasso estimation problemto, inner optimizations을 위한 세 가지 stopping rules을 비교하였다. 이when,, 데이터 개수는 n = 72이고 feature 개수는 p = 1255이다. Fig 3 Three stopping rules 2 세 가지 stopping rule은 adaptive, maxiter = 10, exact이다. Maxiter는 inner iteration을 최대 10번to,만 하는 방식이고 exact는 정확한 solution를 구할 when,to, iteration하는 방식이다. Proximal newton method가 quadratic convergence를 만족하므to, exact는 quadratic convergence를 만족한다고 볼 수 있다. Maxiter=10의 case, 최대 10번의 inner iterationwith,는 quadratic convergence를 만족하지 못but, adaptive의 case, quadratic convergence를 만족하며 세 가지 방식 중 가장 빠르다. Stopping rule of usual newton method 일반적인 newton's methodat,는 inner problem은 MATH 의 MATH to, about, quadratic approximation인 MATH 를 minimization한다. and,, MATH 를 choosing,서 다음 condition,을 만족할 when, 중지한다. 이를 forcing sequence라고 한다. > \\begin align \\parallel \\nabla \\tilde g k-1 x^ k \\parallel 2 & \\le \\eta k \\parallel \\nabla g x^ k-1 \\parallel 2 \\\\\\\\ \\end align 이 condition,은 다음 positionat,의 gradient가 현재 positionat,의 gradient보다 MATH 배 만큼 작다는 것을 의미한다. 이when,, Quadratic approximation은 MATH 이다. Stopping rule of proximal gradient method Lee et al. 2012 at,는 proximal gradientat,는 gradient instead, generalized gradient를 사용하는 방식을 제안하였다. > MATH > \\begin align \\parallel G \\tilde f k-1 /M x^ k \\parallel 2 & \\le \\eta k \\parallel G f/M x^ k-1 \\parallel 2 \\end align > MATH 여기서 MATH 이고 MATH 이다. and,, as follows: MATH 를 설정하여 inexact proximal newton이 local superlinear rate를 갖는다는 것을 증명하였다. > MATH > \\begin align > \\eta k \\le \\min \\left\\ \\frac m 2 , \\frac \\parallel G \\tilde f k-2 /M x^ k-1 - G f/M x^ k-1 \\parallel 2 \\parallel G f/M x^ k-2 \\parallel 2 \\right\\ > \\end align > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_05_Notable_examples/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_06_Proximal_quasi_Newton_methods",
    "title": "19-06 Proximal quasi-Newton methods",
    "chapter": "19",
    "order": 10,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "problem가 커질수록 Hessian의 computation 비용이 매우 높아진다. Proximal quasi-Newton method 는 각 stepat, Hessian MATH 를 computation하지 않는 방식with, superlinear or, linear convergence의 convergence 속도를 제공한다. Proximal quasi-Newton method Lee 2014 는 Hessian을 BFGS-styleto, update하는 방식을 제안했다. 이 method은 매우 잘 실행되며 local superlinear convergence의 convergence 속도를 갖는다. Tseng and Yun 2009 은 Hessian을 blockwiseto, approximation하는 방식을 제안했다. 이 method은 MATH at, MATH 가 일부 optimization variableto, 의존하는 부분with, 나뉠 수 있을 when,만 작동한다. Hessian을 blockwiseto, computation하면 computation이 매우 빨라진다. 이 method은 linear convergence의 convergence 속도를 갖는다. Quasi-Newton은 Hessian computation이 힘들when, 뿐 아니라 Hessian이 singular이거나 near singular인 ill-conditionat,도 유용하다. reference 논문 J. Lee and Y. Sun and M. Saunders 2014 , \"Proximal Newton-type methods for minimizing composite functions\" P. Tseng and S. Yun 2009 , \"A coordinate gradient descent method for nonsmooth separable minimization\"",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_06_Proximal_quasi_Newton_methods/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter19/19_07_Projected_Newton_method",
    "title": "19-07 Projected Newton method",
    "chapter": "19",
    "order": 11,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "What's wrong with projected Newton? When MATH is the indicator function MATH of convex set MATH , the problem can be defined as follows: > MATH Therefore, if MATH , then proximal gradient descent becomes projected gradient descent . That is, projected gradient descent is a special case of proximal gradient descent. What about the case of proximal Newton when MATH ? In this case, the update equation is defined as follows: > MATH > \\begin align > z^ + & =\\underset z \\in C \\text argmin \\ \\frac 1 2 \\parallel x - H^ -1 \\nabla g x - z \\parallel H^2 \\\\\\\\ > &= \\underset z \\in C \\text argmin \\ \\nabla g x ^T z - x + \\frac 1 2 z - x ^T H z - x \\\\\\\\ > \\end align > MATH If MATH , then this becomes the result of projecting MATH onto set MATH , but for general MATH , it is not a projection. If MATH , it would be the MATH -norm, so if it were the MATH -norm instead of the H-norm, it would be a projection. Therefore, the projected Newton method is not a special case of the proximal Newton method. Projected Newton for box constraints For the special case of problems with box constraints, projected Newton can be applied. Bertsekas, 1982; Kim et al., 2010; Schmidt et al., 2011 . Let the problem be as follows: > MATH Starting with the initial point MATH of the Projected Newton method and a small constant MATH , we iterate the following steps MATH . step1: Binding set을 정의한다. > \\begin align B k-1 & = \\\\ i : x i^ k-1 \\le l i + \\epsilon \\quad \\text and \\quad \\nabla i g x^ k-1 \\gt 0 \\\\ \\quad \\cup \\quad \\\\ i : x i^ k-1 \\ge u i - \\epsilon \\quad \\text and \\quad \\nabla i g x^ k-1 \\lt 0 \\\\ \\end align optimization stepat, 이 variable들을 box constraint의 경계to, 밀어낸다. 이들을 점점 더 많이 밀어낼수록 목적 function는 줄어든다. step2: Free set MATH 을 정의한다. step3: Free variable을 therefore, Hessian의 주요 submatrix의 inverse를 정의한다. > MATH step4: Fee variable을 따라 Newton step을 실행하고 projection을 한다. > MATH > \\begin align > x k = P l, u \\left x^ k-1 - t k \\begin bmatrix S^ k-1 & 0 \\\\ > 0 & I \\end bmatrix > \\begin bmatrix \\nabla F k-1 g x^ k-1 \\\\ \\nabla B k-1 g x^ k-1 \\end bmatrix > \\right > \\end align > MATH 여기서 MATH 는 MATH to,의 projection이다. matrix식을 보면 free variableabout,서는 Newton step을 실행but, binding variable의 case, 변하지 않는 것을 알 수 있다. also,, projection은 box 범위 밖to, 있는 점들about,서 각 coordinateabout, 적절한 MATH or, MATH 를 지정solution주는 간단한 작업이다. 이 method은 problem가 매우 크고 ex, difference원이 큰 case, 대부분의 variable이 boundary 근처to, 있어서 free set이 매우 작을 when, optimization를 하는 method이다. 어떤 종류의 problem가 box constraint를 갖는가? as follows: 이런 종류의 problem는 매우 많은 것with, informing,져 있다. Nonnegative least squares Support vector machine dual Graphical lasso dual Fused lasso total variation denoising dual Convergence properties Bertsekas 1982 는 적절한 가정하to, projected Newtonwith, 유한번 iteration을 하면 적절한 binding constraints를 찾을 수 있다는 것을 보였다. 그러면, free variableabout, Newton's methodand, 같아진다. Bertsekas 1982 는 also, superlinear convergence를 증명하였다. Kim et al. 2010 , Schmidt et al. 2011 은 BFGS-style update를 사용한 projected quasi-Newton method를 제안했다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter19/19_07_Projected_Newton_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_00_Dual_Methods",
    "title": "20 Dual Methods",
    "chapter": "20",
    "order": 1,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "In this chapter, we will examine methods for solving problems using duality, including dual subgradient method, dual decomposition method, augmented Lagrangian method, and briefly introduce the concept of Alternating Direction Method of Multipliers ADMM . First, we will briefly review the previously learned content on Proximal Newton method and Conjugate function. Review: proximal Newton method Consider the following problem. >\\begin equation \\min x g x + h x \\end equation Here, functions MATH and MATH are convex functions, where MATH is twice differentiable and MATH is simple. The Proximal Newton method starts with initial MATH and finds the optimal vector direction that is good for both functions MATH and MATH as follows >\\begin alignat 1 v^ k & = \\arg \\min v g x^ k-1 ^T v + \\frac 1 2 v^T \\nabla^2 g x^ k-1 v + h x^ k-1 + v \\end alignat Using the direction found above, we update the next MATH as follows. >\\begin equation x^ k = x^ k-1 + t k v^ k , k=1,2,3,\\dots \\end equation Here, MATH is the step size determined by backtracking. We execute the above two processes iteratively. > The above iteration is very expensive computing MATH is generally very difficult However, under appropriate conditions, very few iterations are required to converge, and it has a convergence rate of local quadratic convergence Review: conjugate function For MATH , the conjugate function is defined as follows. >\\begin equation f^ y = \\max x y^Tx - f x \\end equation 1 The conjugate function can be written as follows, and this is a form that frequently appears in dual problems. >\\begin equation -f^ \\ast y = \\min x f x - y^Tx \\end equation 2 If MATH is closed and convex, then MATH . Also, >\\begin equation x \\in \\partial f^ \\ast y \\Longleftrightarrow y \\in \\partial f x \\Longleftrightarrow x \\in \\arg\\min z f z - y^Tz \\end equation Proof first,, MATH 을 증명한다. 1step : MATH > MATH 를 let's assume. 그러면, MATH 는 MATH 를 최대to, 하게 하는 MATH 들의 set MATH to, 속하게 된다, that is, MATH . however,, MATH 이고, MATH . therefore,, MATH 2step : MATH > 위at, 보인것and, 같이, if,, MATH 이면, MATH . 여기서, MATH 이므to, MATH . 위 1, 2 step를 through,, MATH 이 증명되었다. 3step : MATH > 한편, MATH 은 subgradient의 정의from, 자명한 in fact,이다. therefore,, 위 두 증명을 through,, MATH 임이 증명되었다. 3 if, MATH 가 strictly convex이면, > MATH > \\begin equation > \\nabla f^ \\ast y = \\arg\\min z f z - y^T z > \\end equation > MATH Proof > MATH 가 strictly convex이면, MATH 는 최소값을 갖는 유일한 MATH 가 존재하며, >이것은 위 2 to, about, 증명으from, MATH 이어야 한다. 다시 말하면 MATH 가 strictly convex이면 MATH 의 subgradient는 1개이며 gradient가 된다. therefore,, MATH 는 differentiable한 function이다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_00_Dual_Methods/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_01_00_Dual_(sub)gradient_methods",
    "title": "20-01 Dual (sub)gradient methods",
    "chapter": "20",
    "order": 2,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Even in cases where we cannot find a dual conjugate in closed-form, we can use subgradient or gradient methods based on the dual. For example, consider the following problem. >\\begin equation \\min x f x \\text subject to Ax = b \\end equation The dual problem of the above problem is as follows. Here MATH is the conjugate of MATH . >\\begin equation \\max u -f^ \\ast -A^T u - b^T u \\end equation In this case, if we define MATH as MATH , then the subgradient of MATH is as follows. >\\begin equation \\partial g u = A \\partial f^ \\ast -A^Tu - b \\end equation In the above expression, MATH can be expressed in terms of MATH as follows. >\\begin equation \\partial g u = Ax-b \\quad \\text where \\quad x \\in \\arg\\min z f z + u^T A z \\end equation Dual subgradient method Dual subgradient method 는 dual problem의 목적식을 maximization하기 for, 시작점 MATH at, 시작solution서 MATH about, 다음 step를 iteration한다. > MATH > \\begin alignat 1 > x^ k & \\in \\arg \\min x f x + u^ k-1 ^T A x \\\\ > u^ k & = u^ k-1 + t k A x^ k - b > \\end alignat > MATH 여기서 step size MATH 는 표준적인 방식with, 선택된다. Strictly Convex인 case, if, MATH 가 strictly convex라면 MATH 는 미분가능solution진다. therefore,, algorithm은 MATH about, 다음 step를 iteration하는 dual gradient ascent 가 된다. > MATH > \\begin alignat 1 > x^ k & = \\arg \\min x f x + u^ k-1 ^T A x \\\\ > u^ k & = u^ k-1 + t k A x^ k -b > \\end alignat > MATH before, 방식and, 다른 점은 MATH 가 유일하다는 것이다. MATH and,의 relationship,가 MATH relationship,임을 confirming,보라. 여기서 step size MATH 도 표준적인 방식with, 선택되며 MATH 을 수행할 when, proximal gradient나 acceleration도 평소처럼 적용할 수 있다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_01_00_Dual_(sub)gradient_methods/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_01_01_Convergence_Analysis",
    "title": "20-01-01 Convergence Analysis",
    "chapter": "20",
    "order": 3,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Lipschitz gradients and strong convexity Let's assume MATH is a closed convex function. Then the following equivalence relationship holds. >\\begin equation \\text MATH is strongly convex with parameter MATH MATH Lipschitz with parameter MATH . \\end equation Proof if, MATH 가 strongly convex하고 MATH at, minimize된다고 하면 다음 relationship,가 성립한다. >\\begin equation g y \\geq g x + \\frac d 2 \\lVert y-x \\rVert 2^2, \\text for all y \\end equation 우선, MATH 를 minimization하는 MATH and, MATH 를 minimization하는 MATH 가 있다고 하자. 그러면, 위 식으from, 다음 두 부등식을 얻을 수 있다. > MATH > \\begin alignat 1 > f x v - u^Tx v \\geq f x u - u^T x u + \\frac d 2 \\lVert x u - x v \\rVert 2^2 \\\\ > f x u - v^Tx u \\geq f x v - v^T x v + \\frac d 2 \\lVert x u - x v \\rVert 2^2 > \\end alignat > MATH 위 두 식을 더하면 다음and, 같은 식을 얻을 수 있다. >\\begin equation f x v - u^Tx v + f x u - v^Tx u \\geq f x u - u^T x u + f x v - v^T x v + d \\lVert x u - x v \\rVert 2^2. \\end equation 이 식을 재정렬 후 Cauchy-Schwartz를 적용하면 as follows: 정리된다. > MATH > \\begin align > d \\lVert x u - x v \\rVert 2^2 & \\leq - u^Tx v - v^Tx u + u^T x u + v^T x v \\\\\\\\ > & = u-v ^T x u - x v \\\\\\\\ > & \\leq \\lVert u-v \\rVert 2 \\lVert x u - x v \\rVert 2 > \\end align > MATH therefore,, 다음and, 같은 relationship,를 확인할 수 있다. > MATH 이to,써 MATH Lipschitz with parameter MATH 이 증명되었다. Convergence guarantees 위 result,and, gradient descent를 combining,, dual objective의 optimal solutionto,의 convergence성을 as follows: 설명할 수 있다. if, MATH 가 파라미터 MATH to, strongly convex 하면, step size MATH about,서, dual gradient ascent는 MATH with, converge한다. if, MATH 가 파라미터 MATH to, strongly convex 하고, MATH 는 파라미터 MATH to, Lipschitz하면, step size MATH MATH about,서, dual gradient ascent는 MATH with, converge한다. linear convergence",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_01_01_Convergence_Analysis/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_02_00_Dual_Decomposition",
    "title": "20-02 Dual Decomposition",
    "chapter": "20",
    "order": 4,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "In this section, we examine techniques for decomposing problems using duality.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_02_00_Dual_Decomposition/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_02_01_Dual_Decomposition_with_Equality_Constraint",
    "title": "20-02-01 Dual Decomposition with Equality Constraint",
    "chapter": "20",
    "order": 5,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "다음의 problem를 보자. >\\begin equation \\min x \\sum i=1 ^B f i x i \\quad \\text subject to \\quad Ax = b \\end equation if,, variable MATH 를 MATH 개의 블록with, 분할하고, MATH , matrix MATH 역시 MATH 개의 sub-matrix 블록with, as follows: 분할하면, MATH , 위 minimization problem는 as follows: MATH 개의 분리된 problemto, 분solution될 수 있다. > MATH > \\begin alignat 1 > & \\quad x^+ \\in \\arg\\min x \\sum i=1 ^B f i x i + u^T Ax \\\\ > \\Longleftrightarrow & \\quad x i^+ \\in \\arg\\min x i f i x i + u^T A ix i, \\quad i=1,\\dots, B > \\end alignat > MATH Dual decomposition algorithm: > MATH > \\begin alignat 1 > x i^ k & \\in \\arg \\min x i f i x i + u^ k-1 ^T A i x i, \\quad i=1,\\dots,B \\\\ > u^ k & = u^ k-1 + t k \\left \\sum i=1 ^B A i x i^ k - b \\right > \\end alignat > MATH 위 두 step는 아래and, 같이 solution석할 수 있다. > 첫번째 수식은 broadcast stepto,서, MATH 개의 프to,세서의 각각to,게 MATH 를 보낸다. and,, 프to,세서 각각은 병렬to, 자신의 최적 MATH 를 찾는다. 두번째 수식은 gather stepto,서, 각 프to,세서from, MATH 를 모은다. and, global dual variable MATH 를 업데이트 한다. 위 두 step는 MATH about, 계속 iteration한다. Fig 1 Broadcast and Gather",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_02_01_Dual_Decomposition_with_Equality_Constraint/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_02_02_Dual_Decomposition_with_Inequality_Constraint",
    "title": "20-02-02 Dual Decomposition with Inequality Constraint",
    "chapter": "20",
    "order": 6,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "다음의 problem를 생각solution 보자. 앞의 problemand, 다른점은 제약식이 부등식의 relationship,를 갖는 것이다. > MATH > \\begin equation > \\min x \\sum i=1 ^B f i x i \\quad \\text subject to \\quad \\sum i=1 ^B A i x i \\leq b > \\end equation > MATH Dual decomposition projected subgradient method 위 problemat,는 dual variable가 always, MATH 보다 같거나 커야 한다, that is, MATH . therefore,, 다음 스텝의 MATH 값을 computation할 when,, MATH 보다 큰 범위안with, projection을 시켜서 업데이트를 한다. > MATH > \\begin alignat 1 > x i^ k & \\in \\arg \\min x i f i x i + u^ k-1 ^T A i x i, \\quad i=1,\\dots,B \\\\ > u^ k & = u^ k-1 + t k \\left \\sum i=1 ^B A i x i^ k - b \\right + > \\end alignat > MATH 여기서, MATH 는 0보다 큰 MATH 를 의미한다, that is,, MATH . 위 process을 MATH about,서 iteration한다. Price coordination interpretation generally, dual decomposition problem들은 price coordination 관점at, as follows: solution석될 수 있다. Vandenberghe > MATH 개의 독립적인 유닛이 있고, 각 유닛은 자신의 결정 variable MATH 를 결정한다. > 각 constraint은 MATH 개의 유닛이 공유하고 있는 자원to, about, 제약을 의미하며, dual variable MATH 는 자원 MATH 의 가격을 의미한다. > Dual variable는 아래and, 같이 업데이트되며 \\begin equation u j^ + = u j - t s j + , \\quad j=1,\\dots,m \\end equation > > MATH 여기서, MATH 는 슬랙 variableto,써 \\\\ > MATH - MATH \\qquad MATH s j > 0 MATH j MATH u j MATH 를 감소시킨다 \\\\ > MATH - price는 향image 음수가 되지 않도록 한다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_02_02_Dual_Decomposition_with_Inequality_Constraint/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_03_Augmented_Lagrangians",
    "title": "20-03 Augmented Lagrangians",
    "chapter": "20",
    "order": 7,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Dual ascent의 단점은 convergence을 보장하기 for, 강한 condition,이 필요하다는 것이다. convergence을 보장하려면 MATH 가 strongly convexsolution야 했다. 이런 단점은 Augmented Lagrangian method or, Method of multipliers by, 개선될 수 있다. Primal problem를 아래and, 같이 transformation한다. >\\begin equation \\min x f x + \\frac \\rho 2 \\lVert Ax - b \\rVert 2^2 \\quad \\text subject to \\quad Ax = b \\end equation 여기서 MATH 이다. MATH 가 full column rank를 갖는다면 목적식은 strongly convex하다. 이는 원래의 problemand, 정확히 동일한 problem가 된다. Augmented term인 MATH 는 0이 되기 because,이다. Augmented Lagrangian Method Dual gradient ascent : MATH about, 다음을 iteration한다. > MATH > \\begin alignat 1 > x^ k & \\in \\arg\\min x f x + u^ k-1 ^T A x + \\frac \\rho 2 \\lVert Ax - b \\rVert 2^2 \\\\ > u^ k & = u^ k-1 + \\rho A x^ k - b > \\end alignat > MATH 위 dual algorithmat, MATH 는 step size 역할을 한다, that is, MATH 이다. 이것은 next,서 그 reason,를 알 수 있다. MATH 가 step size일 when, optimality 증명 MATH 는 MATH 를 minimization하므to,, 원래 primal problemto, about, stationary condition,according to,, MATH at, 목적식의 subgradient가 아래and, 같이 MATH 을 포함solution야 한다. > MATH > \\begin alignat 1 > 0 & \\in \\partial f x^ k + A^T u^ k-1 + \\rho A x^ k -b \\\\ > & = \\partial f x^ k + A^T u^ k > \\end alignat > MATH 위식at,, MATH to, 동작하게 되면, 적당한 condition,하at, MATH 가 MATH with, 가까워지면서 feasible한 solution를 제공하기 시작하고, 궁극적with, KKT condition,이 만족되고, MATH and, MATH 가 optimalityto, 근접함을 보일 수 있다. Augmented Lagrangian method 의 장점은 훨씬 좋은 convergence성을 갖는다는 것이고, 단점은 problem를 분solution할 수 있는 decomposability를 잃는다는 것이다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_03_Augmented_Lagrangians/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_04_00_A_peak_at_ADMM",
    "title": "20-04 A peak at ADMM",
    "chapter": "20",
    "order": 8,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Lipschitz gradients and strong convexity In this section, we examine an overview of the Alternating Direction Method of Multipliers ADMM technique. While the augmented Lagrangian method previously did not provide decomposability, ADMM is a method that provides decomposability along with convergence properties.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_04_00_A_peak_at_ADMM/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_04_01_ADMM",
    "title": "20-04-01 ADMM",
    "chapter": "20",
    "order": 9,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Alternating Direction Method of Multipliers ADMM The Alternating Direction Method of Multipliers ADMM is a powerful optimization algorithm that combines the benefits of dual decomposition and the method of multipliers. It is particularly effective for solving convex optimization problems that can be decomposed into smaller, more manageable subproblems. Consider the following problem: >\\begin equation \\min x,z f x + g z \\quad \\text subject to \\quad Ax + Bz = c \\end equation As before, we can augment the objective function as follows: >\\begin equation \\min x,z f x + g z + \\frac \\rho 2 \\lVert Ax + Bz - c \\rVert 2^2 \\quad \\text subject to \\quad Ax + Bz = c \\end equation where MATH is the penalty parameter. Augmented Lagrangian The augmented Lagrangian can be defined as: >\\begin equation L \\rho x,z,u = f x + g z + u^T Ax + Bz - c + \\frac \\rho 2 \\lVert Ax + Bz - c \\rVert 2^2 \\end equation ADMM Algorithm ADMM performs the following iterative steps for MATH : > MATH > \\begin alignat 1 > x^ k & = \\arg\\min x L \\rho x,z^ k-1 ,u^ k-1 \\\\ > z^ k & = \\arg\\min z L \\rho x^ k ,z,u^ k-1 \\\\ > u^ k & = u^ k-1 + \\rho Ax^ k + Bz^ k - c > \\end alignat > MATH Key Point: It is crucial that MATH obtained from the first step is used in the second step to compute MATH . This alternating update structure is essential for convergence. Comparison with Method of Multipliers Note that in the general Method of Multipliers , the first two steps are replaced by the following joint minimization: >\\begin equation x^ k , z^ k = \\arg\\min x,z L \\rho x,z,u^ k-1 \\end equation The key advantage of ADMM is that it decomposes this joint minimization into two separate, simpler subproblems that can often be solved more efficiently or even in closed form.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_04_01_ADMM/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_04_02_Converegence_Guarantee",
    "title": "20-04-02 Convergence Guarantee",
    "chapter": "20",
    "order": 10,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Convergence Guarantee for ADMM Under appropriate conditions on MATH and MATH note that MATH and MATH do not need to be full rank , ADMM satisfies the following for all MATH : Residual convergence : As MATH , MATH , meaning the primal iterates approach feasibility. Objective convergence : MATH , where MATH is the optimal primal objective value. Dual convergence : MATH , where MATH is the dual solution. The exact convergence rate is not yet fully understood, and much research is currently ongoing in this area. Roughly speaking, ADMM performs similarly to or slightly better than first-order methods.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_04_02_Converegence_Guarantee/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_04_03_ADMM_in_Scaled_Form",
    "title": "20-04-03 ADMM in Scaled Form",
    "chapter": "20",
    "order": 11,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "ADMM in Scaled Form ADMM can be expressed in scaled form by substituting the dual variable MATH with MATH . The ADMM steps can then be written as follows: > MATH > \\begin alignat 1 > x^ k & = \\arg\\min x f x + \\frac \\rho 2 \\lVert Ax + Bz^ k-1 - c + w^ k-1 \\rVert 2^2 \\\\ > z^ k & = \\arg\\min z g x + \\frac \\rho 2 \\lVert Ax^ k + Bz - c + w^ k-1 \\rVert 2^2 \\\\ > w^ k & = w^ k-1 + Ax^ k + Bz^ k - c > \\end alignat > MATH Equivalence to Original Form We can show that the above equations are equivalent to the original form through the following process: > MATH > \\begin align > x^ k & = \\arg\\min x f x + \\frac \\rho 2 \\lVert Ax + Bz^ k-1 - c + w^ k-1 \\rVert 2^2 \\\\ > & = \\arg\\min x f x + \\frac \\rho 2 \\lVert Ax + Bz^ k-1 - c \\rVert 2^2 + \\rho w^ k-1 T Ax + Bz^ k-1 - c + \\frac \\rho 2 \\lVert w^ k-1 \\rVert 2^2 \\\\ > & = \\arg\\min x f x + \\frac \\rho 2 \\lVert Ax + Bz^ k-1 - c \\rVert 2^2 + u^ k-1 T Ax + Bz^ k-1 - c \\\\ > \\end align > MATH where we used MATH and dropped the constant term. Interpretation of Scaled Variable Here, MATH can be viewed as the sum of residuals up to iteration MATH : > MATH > \\begin equation > w^ k = w^ 0 + \\sum i=1 ^k Ax^ i + Bz^ i - c > \\end equation > MATH This scaled form is often more convenient for implementation and analysis.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_04_03_ADMM_in_Scaled_Form/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_04_04_Example:_Alternating_Projection",
    "title": "20-04-04 Example - Alternating Projection",
    "chapter": "20",
    "order": 12,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Example: Alternating Projection Consider the problem of finding a point in the intersection of convex sets MATH : >\\begin equation \\min x I C x + I D x \\end equation where MATH and MATH are indicator functions for sets MATH and MATH respectively. To reformulate this problem in ADMM form, we express it as follows: > MATH > \\begin equation > \\min x,z I C x + I D x \\quad \\text subject to \\quad x - z = 0 > \\end equation > MATH ADMM Algorithm for Alternating Projection Each ADMM cycle involves two projections: > MATH > \\begin alignat 1 > x^ k & = P C \\left z^ k-1 - w^ k-1 \\right \\\\ > z^ k & = P D \\left x^ k + w^ k-1 \\right \\\\ > w^ k & = w^ k-1 + x^ k - z^ k > \\end alignat > MATH where MATH and MATH denote the projection operators onto sets MATH and MATH respectively. Derivation The update for MATH is derived as follows: > MATH > \\begin alignat 1 > x^ k & = \\arg\\min x I C x + \\frac \\rho 2 \\lVert x - z^ k-1 + w^ k-1 \\rVert 2^2 \\\\ > & = P C \\left z^ k-1 - w^ k-1 \\right > \\end alignat > MATH Similarly, the update for MATH is derived as: > MATH > \\begin alignat 1 > z^ k & = \\arg\\min z I D z + \\frac \\rho 2 \\lVert x^ k - z + w^ k-1 \\rVert 2^2 \\\\ > & = P D \\left x^ k + w^ k-1 \\right > \\end alignat > MATH Comparison with Classical Method This method is similar to the classical alternating projection method but is often more efficient and robust in practice.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_04_04_Example-_Alternating_Projection/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter20/20_05_References",
    "title": "20-05 References",
    "chapter": "20",
    "order": 13,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "References S. Boyd, N. Parikh, E. Chu, B. Peleato and J. Eckstein 2010 , \"Distributed optimization and statistical learning via the alternating direction method of multipliers\" W. Deng and W. Yin 2012 , \"On the global and linear convergence of the generalized alternating direction method of multipliers\" M. Hong and Z. Luo 2012 , \"On the linear convergence of the alternating direction method of multipliers\" F. lutzeler, P. Bianchi, Ph. Ciblat, and W. Hachem 2014 , \"Linear convergence rate for distributed optimization with the alternating direction method of multipliers\" R. Nishihara, L. Lessard, B. Recht, A. Packard, and M. Jordan 2015 , \"A general analysis of the convergence of ADMM\" L. Vandenberghe, Lecture Notes for EE 236C, UCLA, Spring 2011-2012",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter20/20_05_References/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter21/21_00_Alternating_Direction_Method_of_Multipliers",
    "title": "21 Alternating Direction Method of Multipliers",
    "chapter": "21",
    "order": 1,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "This chapter aims to examine ADMM, which was covered in Chapter 20 % multilang post url contents/chapter20/21-03-27-20 00 Dual Methods % , in more detail. The basic concepts are not significantly different in depth from what was covered in Chapter 20, and we will mainly look at application cases. Reference Papers Boyd, Stephen, et al. BPCPE11 \"Distributed optimization and statistical learning via the alternating direction method of multipliers.\" Foundations and Trends® in Machine learning 3.1 2011 : 1-122. Hong, Mingyi, and Zhi-Quan Luo. HL12 \"On the linear convergence of the alternating direction method of multipliers.\" Mathematical Programming 162.1-2 2017 : 165-199. Deng, Wei, and Wotao Yin. DY16 \"On the global and linear convergence of the generalized alternating direction method of multipliers.\" Journal of Scientific Computing 66.3 2016 : 889-916. Iutzeler, Franck, et al. IBCH14 \"Linear convergence rate for distributed optimization with the alternating direction method of multipliers.\" 53rd IEEE Conference on Decision and Control. IEEE, 2014. Nishihara, Robert, et al. NLRPJ15 \"A general analysis of the convergence of ADMM.\" arXiv preprint arXiv:1502.02009 2015 . Parikh, Neal, and Stephen Boyd. NB13 \"Proximal algorithms.\" Foundations and Trends® in Optimization 1.3 2014 : 127-239. Vu, Vincent Q., et al. VCLR13 \"Fantope projection and selection: A near-optimal convex relaxation of sparse PCA.\" Advances in neural information processing systems. 2013. Candès, Emmanuel J., et al. CLMW09 \"Robust principal component analysis?.\" Journal of the ACM JACM 58.3 2011 : 11. Ramdas, Aaditya, and Ryan J. Tibshirani. RT16 \"Fast and flexible ADMM algorithms for trend filtering.\" Journal of Computational and Graphical Statistics 25.3 2016 : 839-858. Wytock, Matt, Suvrit Sra, and Jeremy Z. Kolter. WSK14 \"Fast Newton methods for the group fused lasso.\" UAI. 2014. Barbero, Alvaro, and Suvrit Sra. BS14 \"Modular proximal optimization for multidimensional total-variation regularization.\" arXiv preprint arXiv:1411.0589 2014 . ADMM convergence relation, : BPCPE11 , HL12 , DY16 , IBCH14 , NLRPJ15 Sparse subspace estimation : VCLR13 Sparse plus low rank decomposition : CLMW09 Consensus ADMM : BPCPE11 , NB13 Subprogram parameterization : RT16 , WSK14 , BS14",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter21/21_00_Alternating_Direction_Method_of_Multipliers/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter21/21_01_Last_time_Dual_method,_Augmented_Lagrangian_method,_ADMM,_ADMM_in_scaled_form",
    "title": "21-01 Last time - Dual method, Augmented Lagrangian method, ADMM, ADMM in scaled form",
    "chapter": "21",
    "order": 2,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "before, 20장at, 우리는 Dual methods, ADMMabout, 살펴보았다. 여기선 ADMM의 응용을 살펴보기to, 앞서, Dual methodsand, Augmented Lagrangian method, ADMM, ADMM in scaled formabout, 정리하고자 한다. Dual method 아래의 problem를 let's look at. > MATH >\\begin align >&\\min x &&f x \\\\\\\\ >&\\text subject to &&Ax = b >\\end align > MATH 여기서 MATH 는 strictly convex하고 닫혀있다고 하자. 이 problem의 Lagrangian은 아래and, 같다. > MATH >\\begin align >L x,u = f x +u^ T Ax-b >\\end align > MATH 위 problem의 dual problem는 아래and, 같다. > MATH >\\begin equation >\\max u -f^ \\ast -A^T u - b^T u >\\end equation > MATH 여기at,의 u는 dual variable이다. 이 식to, about, dual gradient ascent는 아래의 식을 iteration적with, computation한다. MATH > MATH >\\begin align >x^ k &=\\underset x \\operatorname argmin L x,u^ k-1 \\\\\\\\ >u^ k &= u^ k-1 +t k Ax^ k -b >\\end align > MATH MATH 는 k번째 iteration의 step size이다. 이 dual methodat,는, primal variable MATH 는 첫번째 식처럼 before, 스텝at, 주어진 MATH at,의 Lagrangian을 minimization하는 MATH 값with, 업데이트되고, dual variable MATH 는 MATH 이 gradient direction인 gradient ascent의 형태to, 업데이트가 된다. 이 method의 장점은 MATH 가 B개의 problemto, 분할이 가능할 when, decomposable , MATH also, B개의 블록with, 분할하고 MATH , matrix A also, B개의 sub-matrix 블록with, decompose가 가능solution서 MATH , 쉽게 병렬화 or, 확장이 가능하여 computation이 용이하다. but, 단점은 convergence성를 보장하기 for, 까다to,운 condition,이 필요하다 ; primal의 feasible을 보장하기 for,, MATH 가 strongly convex하다는 condition,이 필요하다. 20-01-01 % multilang post url contents/chapter20/21-03-27-20 01 01 Convergence Analysis % Augmented Lagrangian method Method of multipliers라고도 불리는 Augmented Lagrangian method는 primal problemto, 추가 항을 더하여 computation한다. 이렇게 하면 iteration을 iteration되면서 점difference KKT의 conditions을 만족하게 된다. Dual methodand, comparing, convergence성to, about, condition, f가 strongly convex 을 완화시킨다. instead of, problem의 분solution decompose 가 불가능solution지는 단점이 있다. Primal problem의 정의는 as follows:. > MATH >\\begin align >&\\min x &&f x +\\frac \\rho 2 ||Ax-b|| 2 ^ 2 &\\\\\\\\ >&\\text subject to &&Ax=b >\\end align > MATH 여기서 MATH 이다. 이 problem의 Lagrangian은 아래and, 같다. > MATH >\\begin align >L \\rho x,u =f x +u^ T Ax-b +\\frac \\rho 2 ||Ax-b|| 2 ^ 2 . >\\end align > MATH Dual gradient ascent는 다음을 iteration한다. MATH > MATH >\\begin align >x^ k &=\\underset x \\operatorname argmin L \\rho x,u^ k-1 \\\\\\\\ >u^ k &= u^ k-1 +\\rho Ax^ k -b >\\end align > MATH 이 method의 장점은 위at, 언급하였듯, dual methodto, 비하여 더 나은 convergence condition,을 가진다. 단점은 제product 항이 추가되는 탓to, 분solution가능한 성질 decomposability 을 잃게 된다. Alternating direction method of multipliers ADMM ADMM은 dual methodand, augmented Lagrangian method의 장점을 섞은 method이다. problem가 아래의 형태to, 정의 되어있다고 하자. > MATH >\\begin align >\\min x f x +g z \\qquad \\text subject to Ax+Bz=c >\\end align > MATH 이 식to, MATH 인 augmented Lagrangian을 정의할 수 있다. > MATH >\\begin align >&L \\rho x,z,u = f x +g z +u^ T Ax+Bz-c +\\frac \\rho 2 ||Ax+Bz-c|| 2 ^ 2 \\\\\\\\ >\\end align > MATH 이어서 아래를 iteration하여 variable를 업데이트한다. > MATH >\\begin align >&\\text for k = 1,2,3,... \\\\\\\\ >&x^ k =\\underset x \\operatorname argmin L \\rho x,z^ k-1 ,u^ k-1 \\\\\\\\ >&z^ k =\\underset z \\operatorname argmin L \\rho x^ k ,z,u^ k-1 \\\\\\\\ >&u^ k =u^ k-1 +\\rho Ax^ k +Bz^ k -c >\\end align > MATH ADMMat,는 primal variable인 MATH 를 함께 업데이트하지 않고, 순difference적with, 각각 업데이트 한다. and, 순difference적with, 업데이트할 when,는 다른 variable는 가장 최근의 값을 이용한다. that is,, k번째 iterationat, MATH 를 업데이트 할when,to,는 before, iteration의 값 MATH 이 아닌 MATH 를 이용하고, u를 업데이트 할when, also, 현재 iterationat, 구한 primal variable MATH 를 바to, 이용한다. Alternating direction method of multipliers ADMM ADMM은 제약식 내의 Aand, B가 full rank라는 가정 없이, MATH and, MATH to, about, 큰 제약 없이 under modeset assumption 모든 MATH about, 다음을 만족한다. Residual convergence: MATH 가 MATH to, 갈 when,, MATH , that is, primal iteration이 feasibilityto, 접근한다. Objective convergence: MATH , 여기서 MATH 는 최적의 primal objective 값이다. Dual convergence: MATH , 여기서 MATH 는 dual solution 이다. Convergence rateabout,서는 아직 generally, informing,지진 않았고, 연구가 이루어지고있다. Convergenceto, about, reference문헌은 21장 소개파트 % multilang post url contents/chapter21/21-03-29-21 00 Alternating Direction Method of Multipliers % to, 서술되어있다. ADMM in scaled form We can express ADMM in scaled form by changing the dual variable MATH to the scaled variable MATH . In summary, the ADMM steps can be represented as follows: > MATH >\\begin align &x^ k = \\underset x \\operatorname argmin f x + \\frac \\rho 2 ||Ax + Bz^ k-1 - c + w^ k-1 || 2^2 \\\\\\\\ &z^ k = \\arg\\min z g x + \\frac \\rho 2 || Ax^ k + Bz - c + w^ k-1 || 2^2 \\\\\\\\ &w^ k = w^ k-1 + Ax^ k + Bz^ k - c \\end align > MATH Here, MATH can also be expressed as the sum of residuals up to the MATH -th iteration as shown below. > MATH >\\begin align w^ k = w^ 0 + \\sum i=1 ^k Ax^ i + Bz^ i - c \\end align > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter21/21_01_Last_time_Dual_method,_Augmented_Lagrangian_method,_ADMM,_ADMM_in_scaled_form/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter21/21_02_Connection_to_proximal_operators",
    "title": "21-02 Connection to proximal operators",
    "chapter": "21",
    "order": 3,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Connection to Proximal Operators Consider an optimization problem with a single variable that separates into two functions: > MATH >\\begin align >\\min x f x +g x >\\end align > MATH This can also be expressed by adding a constraint: > MATH >\\begin align >\\min x, z f x +g z \\qquad \\text subject to x=z >\\end align > MATH ADMM Steps in Proximal Form The ADMM steps for this problem are: > MATH >\\begin align >&x^ k = \\operatorname prox f,\\frac 1 \\rho z^ k-1 -w^ k-1 \\\\\\\\ >&z^ k = \\operatorname prox g,\\frac 1 \\rho x^ k +w^ k-1 \\\\\\\\ >&w^ k =w^ k-1 +x^ k -z^ k >\\end align > MATH where MATH and MATH are the proximal operators of MATH and MATH respectively, with parameter MATH . Proximal Operator Definition Recall that for a convex function MATH , the proximal operator % multilang post url contents/chapter19/21-03-24-19 01 01 Reminder: proximal gradient descent % is defined as: > MATH >\\begin align > \\operatorname prox f, \\lambda v = \\underset x \\operatorname argmin \\left f x +\\frac 1 2\\lambda ||x-v|| 2 ^ 2 \\right . >\\end align > MATH Derivation of Proximal Updates The process of deriving ADMM updates in terms of proximal operators is as follows. Let MATH be the updated values of MATH after one step. Update for x: > MATH >\\begin align >x^ + & = \\underset x \\operatorname argmin f x +\\frac \\rho 2 ||x-z+w||^ 2 2 \\\\\\\\ >& =\\underset x \\operatorname argmin \\frac 1 2\\cdot\\frac 1 \\rho || z-w -x||^ 2 2 +f x \\\\\\\\ >& = \\operatorname prox f,\\frac 1 \\rho z-w >\\end align > MATH Update for z: > MATH >\\begin align >z^ + & = \\underset z \\operatorname argmin g z +\\frac \\rho 2 ||x^ + -z+w||^ 2 2 \\\\\\\\ >& =\\underset z \\operatorname argmin \\frac 1 2\\cdot\\frac 1 \\rho || x^ + +w -z||^ 2 2 +g z \\\\\\\\ >& = \\operatorname prox g,\\frac 1 \\rho x^ + +w >\\end align > MATH Key Insight The original ADMM constraint is MATH , while here the constraint is MATH . That is, when the linear transformation relationship between MATH and MATH is the identity, we can transform the original ADMM updates into proximal updates.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter21/21_02_Connection_to_proximal_operators/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter21/21_03_Example_:_Lasso_regression_and_group_lasso_Regression",
    "title": "21-03 Example - Lasso regression and group lasso Regression",
    "chapter": "21",
    "order": 4,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Lasso regression Let's solve the Lasso regression problem using ADMM. Given MATH , the Lasso problem is: > MATH >\\begin align >\\min \\beta \\frac 1 2 ||y-X\\beta||^ 2 2 +\\lambda||\\beta|| 1 >\\end align > MATH In previous chapters, we have solved the Lasso problem using various methods, including proximal gradient descent ISTA % multilang post url contents/chapter09/20-01-08-09 01 proximal gradient descent % , accelerated proximal gradient descent FISTA % multilang post url contents/chapter09/20-01-08-09 05 03 example FISTA % , barrier method % multilang post url contents/chapter15/21-03-28-15 barrier method % , and primal-dual interior-point method % multilang post url contents/chapter17/21-05-01-17 primal dual interior point method % . As with deriving the dual formulation, the performance of the ADMM algorithm depends on how we set up the auxiliary variables. Among many ways to set auxiliary variables, the following form is known to be one of the most effective: > MATH >\\begin align >&\\min \\beta, \\alpha &&||y-X\\beta||^ 2 2 +\\lambda||\\alpha|| 1 \\\\\\\\ >&\\text subject to &&\\beta-\\alpha= 0. >\\end align > MATH ADMM Updates The ADMM updates for this formulation are derived as follows. The MATH update involves a quadratic function, so we can find the minimum by differentiation. The MATH update is similar to the problem covered in Chapter 7 07-03-04 % multilang post url contents/chapter07/21-03-25-07 03 04 example soft-thresholding % , which has a soft-thresholding solution. > MATH >\\begin align >\\beta^ + &= \\underset \\beta \\operatorname argmin \\frac 1 2 ||y-X\\beta||^ 2 2 +\\frac \\rho 2 ||\\beta-\\alpha+w||^ 2 2 \\\\\\\\ >&= X^ T X+\\rho I ^ -1 X^ T y+\\rho \\alpha-w \\\\\\\\ >\\alpha^ + &= \\underset \\alpha \\operatorname argmin \\lambda||\\alpha|| 1 +\\frac \\rho 2 ||\\beta^ + -\\alpha+w||^ 2 2 \\\\\\\\ >&= S \\frac \\lambda \\rho \\beta^ + +w \\\\\\\\ >w^ + &=w+\\beta^ + -\\alpha^ + >\\end align > MATH Key Properties This result has the following characteristics: The matrix MATH is always invertible regardless of MATH since MATH . If we precompute the factorization typically Cholesky factorization in MATH flops, then the MATH update takes MATH flops. The MATH update applies the soft-thresholding operator MATH , which is identical to the content in 07-03-04 % multilang post url contents/chapter07/21-03-25-07 03 04 example soft-thresholding % . The ADMM steps are \"almost\" equivalent to repeatedly soft-thresholding ridge regression coefficients. Different values of MATH produce different results. Fig 1 Comparison of various algorithms for lasso regression 50 instances with n = 100, p = 20 3 Performance Comparison Fig 1 compares the convergence of various algorithms for the Lasso regression problem. All algorithms have the same computational complexity per iteration. As can be seen from the convergence speed in the graph, ADMM has similar convergence speed to proximal gradient descent black . Accelerated proximal gradient descent red has \"Nesterov ripples\" but shows slightly faster convergence speed. We can also confirm that ADMM shows different convergence speeds according to the MATH value. Coordinate descent green , which will be discussed later in Chapter 23 % multilang post url contents/chapter23/21-03-28-23 Coordinate Descent % , uses more information about the problem and therefore has faster convergence speed compared to other methods. The disadvantage of coordinate descent is that there are conditions required for its application. If the MATH value is set too large, the weight of minimizing the objective function MATH becomes small, and if the MATH value is set too small, feasibility decreases. Therefore, setting an appropriate MATH value is important. For detailed information, see BPCPE discussed in the Chapter 21 reference papers % multilang post url contents/chapter21/21-03-29-21 00 Alternating Direction Method of Multipliers % . Group Lasso Regression Similarly, let's examine solving the Group Lasso regression problem with ADMM. The Group Lasso regression problem is defined as follows for MATH : > MATH >\\begin align >\\min \\beta \\frac 1 2 ||y-X\\beta||^ 2 2 +\\lambda\\sum^ G g=1 c g ||\\beta g || 2 . >\\end align > MATH As with Lasso regression, we can reformulate the problem: > MATH >\\begin align >&\\min \\beta,\\alpha &&\\frac 1 2 ||y-X\\beta||^ 2 2 +\\lambda\\sum^ G g=1 c g ||\\alpha g || 2 \\\\\\\\ >&\\text subject to &&\\beta-\\alpha=0. >\\end align > MATH The ADMM steps are as follows: > MATH >\\begin align >\\beta^ + &= X^ T X+\\rho I ^ -1 X^ T y+\\rho \\alpha-w \\\\\\\\ >\\alpha^ + &= R c g \\frac \\lambda \\rho \\beta^ + g +w g \\qquad \\text g = 1,...G \\\\\\\\ >w^ + &=w+\\beta^ + -\\alpha^ + >\\end align > MATH Properties of Group Lasso ADMM This result has the following characteristics: The matrix MATH is always invertible regardless of MATH since MATH . If we precompute the factorization typically Cholesky factorization in MATH flops, then the MATH update takes MATH flops. The MATH update applies the group soft-thresholding operator MATH , which is defined as follows: >\\begin align >R t x = 1-\\frac x \\lVert x \\rVert 2 + x >\\end align",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter21/21_03_Example_-_Lasso_regression_and_group_lasso_Regression/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter21/21_04_Example_:_Sparse_subspace_estimation_and_sparse_plus_low_rank_decomposition",
    "title": "21-04 Example - Sparse subspace estimation and sparse plus low rank decomposition",
    "chapter": "21",
    "order": 5,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Example: Sparse Subspace Estimation and Sparse Plus Low Rank Decomposition Sparse Subspace Estimation Given MATH , consider the problem of finding a projection that minimizes the Frobenius norm distance between the original MATH and the projected MATH : > MATH >\\begin align >&\\min P &&||X-XP||^ 2 F \\\\\\\\ >&\\text subject to &&\\text rank P =k where P is a projection matrix >\\end align > MATH This problem is non-convex because the set of projection matrices is not a convex set. However, it is known to be equivalent to the following convex problem VCLR13 % multilang post url contents/chapter21/21-03-29-21 00 Alternating Direction Method of Multipliers % . This is also called the subspace estimation problem. > MATH >\\begin align >&\\max Y &&tr SY \\\\\\\\ >&\\text subject to &&Y\\in F k = \\left\\ Y\\in \\mathbb S ^ p : 0 \\preceq Y \\preceq I, tr Y = k \\right\\ >\\end align > MATH VCLR13 discusses solving the sparse version with added L1 norm of the subspace estimation problem. For detailed derivation, please refer to the corresponding paper. > MATH >\\begin align >&\\max Y &&tr SY -\\lambda ||Y|| 1 \\\\\\\\ >&\\text subject to &&Y\\in F k >\\end align > MATH where MATH is the Fantope of order k, as defined in the equation above. When MATH , the above problem is equivalent to standard PCA. This problem has an SDP form and can be solved using interior point methods. However, this approach is complex to implement and becomes very slow as the problem size increases. ADMM Formulation To solve this problem with ADMM, we reformulate it as follows: > MATH >\\begin align >&\\min Y,Z &&-tr SY +I F k Y + \\lambda||Z|| 1 \\\\\\\\ >&\\text subject to &&Y = Z. >\\end align > MATH ADMM Algorithm Summarizing the problem, the ADMM steps are as follows: > MATH >\\begin align >Y^ + &= \\underset Y \\operatorname argmin -tr SY + I F k Y +\\frac \\rho 2 ||Y-Z+W||^ 2 F \\\\\\\\ >&=\\underset Y\\in F k \\operatorname argmin \\frac 1 2 ||Y-Z+W-\\frac S \\rho ||^ 2 F \\\\\\\\ >&=P F k Z-W+\\frac S \\rho \\\\\\\\ >Z^ + & = \\underset Z \\operatorname argmin \\lambda||Z|| 1 +\\frac \\rho 2 ||Y^ + -Z+W||^ 2 F \\\\\\\\ >&=S \\frac \\lambda \\rho Y^ + +W \\\\\\\\ >W^ + &=W+Y^ + -Z^ + . >\\end align > MATH where MATH is the fantope projection operator. This is defined by clipping the eigendecomposition MATH VCLR13 % multilang post url contents/chapter21/21-03-29-21 00 Alternating Direction Method of Multipliers % : > MATH >\\begin align >P F k A = U\\Sigma \\theta U^ T , \\: \\Sigma \\theta = diag \\sigma 1 \\theta ,...\\sigma p \\theta >\\end align > MATH where each MATH and MATH . Sparse plus low rank decomposition Given MATH , the sparse plus low rank decomposition problem is as follows CLMW09 % multilang post url contents/chapter21/21-03-29-21 00 Alternating Direction Method of Multipliers % : > MATH >\\begin align >&\\min L,S &&||L|| tr +\\lambda||S|| 1 \\\\\\\\ >&\\text subject to &&L+S=M >\\end align > MATH Problem Description The goal of this problem is to decompose the observed matrix MATH into a low rank matrix MATH and a sparse matrix MATH . The first term of the objective function is the trace penalty of MATH , which minimizes the sum of singular values of MATH . The second term uses the MATH norm on matrix MATH to induce sparsity in MATH . MATH is a tuning parameter that balances these two terms. Both the trace norm and MATH norm are non-smooth, and generally the trace norm is known to be difficult to optimize. Like the sparse subspace estimation problem, this problem has an SDP form and can be solved using interior point methods, but this is also complex and slow. For this problem, ADMM provides somewhat easier update steps. > MATH >\\begin align >L^ + &= S^ tr \\frac 1 \\rho M-S+W \\\\\\\\ >S^ + &= S^ l 1 \\frac \\lambda \\rho M-L^ + +W \\\\\\\\ >W^ + &= W+M-L^ + -S^ + >\\end align > MATH where MATH is matrix soft-thresholding and MATH is elementwise soft-thresholding. Fig 1 Example of sparse plue low rank decomposition on surveliance camera 3 Application Example Fig 1 shows an example of applying sparse plus low rank decomposition to surveillance camera video analysis. From surveillance cameras that film a fixed area for a long time, we can easily separate the low rank part that shares most frames, and the sparse part extracts characteristic parts from specific frames. For example, in Fig 1 , the middle column represents the low rank part and the right column represents the sparse part. As can be confirmed, the low rank part contains background information that appears in almost all frames, and the sparse part contains only characteristic parts that appear only in specific frames.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter21/21_04_Example_-_Sparse_subspace_estimation_and_sparse_plus_low_rank_decomposition/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter21/21_05_Consensus_ADMM",
    "title": "21-05 Consensus ADMM",
    "chapter": "21",
    "order": 6,
    "owner": "Hooncheol Shin",
    "lesson_type": "",
    "content": "Consensus ADMM Basic Consensus ADMM Consider the following problem: > MATH >\\begin align >\\min x \\sum^ B i=1 f i x >\\end align > MATH To solve this problem with ADMM, we need to introduce constraints. Here, we want to transform the equation into a form that is easy to operate in parallel. This approach, called consensus ADMM, reparametrizes the equation as follows: > MATH >\\begin align >&\\min x 1 ,...,x B ,x &&\\sum^ B i=1 f i x i \\\\\\\\ >&\\text subject to &&x i =x, i = 1,...B >\\end align > MATH ADMM Algorithm This allows us to compute decomposable ADMM steps: > MATH >\\begin align >x^ k i &= \\underset x i \\operatorname argmin f i x i +\\frac \\rho 2 ||x i -x^ k-1 +w i ^ k-1 || 2 ^ 2 , i=1,...B\\\\\\\\ >x^ k &=\\frac 1 B \\sum i=1 ^ B x i ^ k +w i ^ k-1 \\\\\\\\ >w i ^ k &=w i ^ k-1 +x i ^ k -x^ k , i=1,...,B >\\end align > MATH Simplified Form Additionally, we can define MATH . With this, we can easily verify that MATH for iterations MATH , and the second equation of the ADMM update simplifies to MATH . Therefore, we can simplify the ADMM update equations as follows: > MATH >\\begin align >x^ k i &= \\underset x i \\operatorname argmin f i x i +\\frac \\rho 2 ||x i -\\overline x ^ k-1 +w i ^ k-1 || 2 ^ 2 , i=1,...B\\\\\\\\ >w i ^ k &=w i ^ k-1 +x i ^ k -\\overline x ^ k , i=1,...,B. >\\end align > MATH Intuition The MATH updates for MATH can be computed in parallel. From the simplified equations, we can gain intuition about consensus ADMM. Each MATH update tries to minimize MATH while simultaneously using MATH regularization to align each MATH with the average MATH . If MATH becomes larger than the average, MATH increases. Therefore, the regularization in the next step will reduce the enlarged MATH . General consensus ADMM General Consensus ADMM Consensus ADMM can be generalized to a more general form. Let's look at the form of problems with affine transformations of MATH and arbitrary function MATH : > MATH >\\begin align >\\min x \\sum i=1 ^ B f i a^ T i x+b i +g x >\\end align > MATH For this equation as well, we reparameterize by adding constraints: > MATH >\\begin align >&\\min x 1 ,..x B ,x &&\\sum^ B i=1 f i a i ^ T x+b +g x \\\\\\\\ >&\\text subject to &&x i = x, i=1,...B >\\end align > MATH We can then derive decomposable ADMM updates: > MATH >\\begin align >x i ^ k &= \\underset x i \\operatorname argmin f i a i ^ T x+b i +\\frac \\rho 2 ||x i -x^ k-1 +w i ^ k-1 ||^ 2 2 +g x \\\\\\\\ >x^ k &=\\underset x \\operatorname argmin \\frac B\\rho 2 ||x-\\overline x ^ k -\\overline w ^ k-1 ||^ 2 2 +g x \\\\\\\\ >w i ^ k &=w i ^ k-1 +x i ^ k -x^ k , i=1,...B >\\end align > MATH Key Differences The differences between generalized consensus ADMM and the consensus ADMM derived above can be summarized as follows: Because the ADMM step equations do not simplify, MATH is no longer satisfied. MATH can be updated in parallel. Each MATH update can be thought of as minimizing the corresponding partial loss with MATH regularization. The MATH update is a proximal operation for the arbitrary function MATH generally a regularizer . Different ADMM algorithms are derived depending on how the reparameterization is done. For more detailed information, see the reference papers % multilang post url contents/chapter21/21-03-29-21 00 Alternating Direction Method of Multipliers % .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter21/21_05_Consensus_ADMM/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter21/21_06_Faster_convergence_with_subprogram_parametrization_:_example_of_the_2d_fused_lasso_problem",
    "title": "21-06 Faster convergence with subprogram parametrization - example of the 2d fused lasso problem",
    "chapter": "21",
    "order": 7,
    "owner": "Hooncheol Shin",
    "lesson_type": "optional",
    "content": "Faster Convergence with Subprogram Parametrization Introduction One very interesting property of ADMM is that when solving problems, if we parametrize the small subproblems in a special way, it can show much faster convergence performance than general methods. In the previous consensus ADMM example, the updates optimize over blocks of variables, which is similar to block coordinate descent. Therefore, ADMM can also achieve fast convergence by updating blocks of variables in nearly orthogonal directions. 2D Fused Lasso Example In this section, we will demonstrate the above concepts through examples, designing auxiliary constraints so that the primal updates are in de-correlated directions. For detailed information, see RT16 , WSK14 , BS14 . Let's examine the 2D fused lasso or 2D total variation denoising problem, which was one of the examples we looked at in Chapter 1 % multilang post url contents/chapter01/21-01-07-01 01 optimization problems % . Given an image MATH , the problem is defined as follows: > MATH >\\begin align >\\min \\Theta \\frac 1 2 ||Y-\\Theta||^ 2 F +\\lambda \\sum i,j |\\Theta i,j -\\Theta i+1,j |+|\\Theta i,j -\\Theta \\Theta i,j+1 | . >\\end align > MATH In this problem, there is a parameter for each pixel of the image, and this parameter matrix is MATH . Fig 1 Interpretation of the penalty term in 2d fussed lasso 3 Fig 1 visually shows the penalty term, which is the second term of the objective function. As can be seen from the defined problem, it aims to reduce the differences between a pixel and its adjacent horizontal and vertical pixels. That is, this penalty term makes the values of neighboring adjacent pixels similar. Vector Form Summarizing the penalty term as an operator, the problem becomes: > MATH >\\begin align >\\min \\theta \\frac 1 2 ||y-\\theta||^ 2 F + \\lambda||D\\theta|| 1 . >\\end align > MATH where MATH is the 2D difference operator corresponding to the original equation. Forms of ADMM updates for the 2d fused lasso problem Forms of ADMM Updates for the 2D Fused Lasso Problem Now we want to create ADMM steps in two ways by applying auxiliary constraints. The first approach is to derive ADMM from the vector form created through the 2D difference operator. > MATH >\\begin align >\\min \\theta, z \\frac 1 2 ||y-\\theta||^ 2 2 +\\lambda||z|| 1 \\qquad \\text subject to z = D\\theta, >\\end align > MATH The ADMM steps are then derived as follows: > MATH >\\begin align >\\theta^ k &= I+\\rho D^ T D ^ -1 y+\\rho D^ T z^ k-1 +w^ k-1 \\\\\\\\ >z^ k &= S \\frac \\lambda \\rho D\\theta^ k -w^ k-1 \\\\\\\\ >w^ k &= w^ k-1 +z^ k-1 -D\\theta ^ k . >\\end align > MATH Computational Complexity - Vector Form Solving for MATH is equivalent to solving the linear system MATH . Here, MATH becomes the Laplacian matrix MATH of the 2D grid, which can be solved in MATH operations. The MATH update also requires MATH operations since it involves applying the soft thresholding operator MATH . Therefore, solving ADMM in vector form takes MATH time. Matrix Form ADMM The second approach is to derive ADMM in matrix form, identical to the original problem definition. > MATH >\\begin align >&\\min \\Theta, Z &&\\frac 1 2 ||Y-\\Theta||^ 2 F +\\lambda\\sum i,j |\\Theta i,j -\\Theta i+1,j +|Z i+1,j -Z i,j+1 | \\\\\\\\ >&\\text subject to &&\\Theta = Z >\\end align > MATH The ADMM steps are as follows: > MATH >\\begin align >\\Theta \\cdot \\\\ , j ^ k &= FL^ 1d \\frac \\lambda 1+\\rho \\bigg \\frac Y+\\rho Z^ k-1 \\cdot \\\\ , j -W \\cdot \\\\ ,j ^ k-1 1+\\rho \\bigg ,\\qquad j=1,...,d\\\\\\\\ >Z i, \\cdot ^ k &= FL^ 1d \\frac \\lambda \\rho \\bigg \\Theta i, \\cdot ^ k + W i, \\cdot ^ k-1 \\bigg , \\qquad j=1,...,d\\\\\\\\ >W^ k &= W^ k-1 + \\Theta^ k - Z^ k \\\\\\\\ >\\end align > MATH where MATH is the 1D fused lasso defined as MATH . Computational Complexity - Matrix Form The matrix form ADMM can also be performed with MATH time complexity. Both MATH and MATH are in the form of 1D fused lasso, which has MATH time complexity. Fig 2 shows how the original penalty term is separated into 1D fused lasso problems. Fig 2 Interpretation of the matrix form ADMM updates for 2d fused lasso 3 Image denoising experiments Image Denoising Experiments Now let's revisit the image denoising problem we examined in Chapter 1. Fig 3 shows the data and denoised images. Fig 4 shows a comparison of the two ADMM methods. The \"specialized\" ADMM in matrix form, which defines constraints by decomposing in vertical/horizontal directions, shows much faster convergence performance than the \"standard ADMM\" derived in vector form. Fig 5 shows the image quality according to ADMM iterations. Fig 3 Data, exact solution image 300x200 image : n = 60,000 . left : original image before denoising, right : the exact solution of denoised image 3 Fig 4 Convergence curves of two ADMM algorithms. black : standard vector form , red : specialized matrix form 3 Fig 5 ADMM iterates visualized after k = 10, 30, 50, 100 iterations 3",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter21/21_06_Faster_convergence_with_subprogram_parametrization_-_example_of_the_2d_fused_lasso_problem/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter22/22_Conditional_Gradient_Method",
    "title": "22 Conditional Gradient (Frank-Wolfe) Method",
    "chapter": "22",
    "order": 1,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "This chapter will examine the Frank-Wolfe algorithm proposed by Marguerite Frank and Philip Wolfe in 1956. The Frank-Wolfe algorithm is an iterative first-order optimization algorithm for constrained convex optimization, also called the conditional gradient method, reduced gradient method, and convex combination algorithm. This method was originally proposed by Marguerite Frank and Philip Wolfe in 1956. The Frank-Wolfe algorithm considers a linear approximation of the objective function at each iteration and moves toward the minimizer of this linear function. 15 Wikipedia. Frank–Wolfe algorithm https://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe algorithm",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter22/22_Conditional_Gradient_Method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter22/22_01_Last_time_ADMM",
    "title": "22-01 Last time: ADMM",
    "chapter": "22",
    "order": 2,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Last time: ADMM Let's consider the following optimization problem > MATH \\begin align > &\\min x,z &&f x + g z \\\\\\\\ > &\\text subject to &&Ax + Bz = c > \\end align MATH Converting this to Augmented Lagrangian form gives us the following. for some MATH > MATH The above equation becomes Strongly Convex with the addition of MATH , and this can be transformed into a form useful for parallel processing as shown in the following equation. For detailed proof, please refer to the content of the previous chapter. ADMM: for MATH > MATH > MATH > MATH ADMM in scaled form Let's change the dual variable MATH to the scaled variable MATH . Here, the ADMM step can be computed as follows. > MATH > MATH > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter22/22_01_Last_time_ADMM/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter22/22_02_Conditional_gradient_method",
    "title": "22-02 Conditional gradient method",
    "chapter": "22",
    "order": 3,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Projected Gradient Descent Let's consider a problem with the following constraints. > MATH We previously saw that if MATH is convex and smooth, and MATH is also convex, we can use the projected gradient descent method. When MATH is the projection operator for set MATH , for the chosen initial value MATH and MATH , the following equation holds. > MATH Projected Gradient Descent can also be represented as a special case of proximal gradient descent, which is essentially motivated by the fact that the MATH value in the local quadratic expansion 2nd Taylor Expansion becomes the next MATH . > MATH For more detailed information about Projected Gradient Descent, please reference 9-4 % multilang post url contents/chapter09/20-01-08-09 04 special cases % . Conditional gradient Frank-Wolfe method Instead of minimizing the quadratic approximation here, let's try something simpler. First, let's examine the point where the value is minimized when we take the inner product of set MATH with MATH . Fundamentally, instead of projection, we can solve problems more conveniently and effectively by minimizing linear functions at points within set MATH . Here, we proceed by applying a line search method using convex combinations between the current point and the minimum point. Let's look at the following formalized method. Choose initial value MATH . MATH > MATH \\begin array rcl > s^ k−1 & ∈ & \\arg\\min s ∈ C ∇f x^ k−1 ^Ts \\\\\\ > x^ k & = & 1 − γ k x^ k−1 + γ ks^ k−1 > \\end array MATH reference > MATH > MATH > MATH 여기서, before,and, 다르게 Projection process을 거치지 않고 업데이트를 할 떄, 제약 condition, set MATH to, 있는 점을 using, problem를 풀어나간다. 기본적with, step size는 MATH with, 설정된다. 임의의 MATH at, convexityby, MATH 임을 보인다. also, 다음and, 같은 식with, 업데이트가 진행되기도 한다. > MATH that is,, algorithm 수행됨according to, 선형 minimizer directionwith, 점difference적with, 조금씩 덜 이동하게 된다. 대부분의 case,, co-ordinate descent의 스페셜 케이스인 Ball L1about,서 sub gradient 방식을 사용하는 것이 projection 방식을 사용하는 것 보다 problem를 solution결하기 더 쉽다. reference 흥미to,운 in fact,은, Frankand, Wolfe는 Tuckerand, 함께 일하던 post-doc 였다고 informing,져 있으며. 그들은 first, 첫번째to, 이 algorithm을 2 difference functionto, 제안했다고 한다. and, 그 algorithm은 1956년to, 출판되고, 후to, 논문with,도 발표되었다. and, 이 후to, 오랫during, 더 이image 이to, about, 후속 논문은 전혀 나오지 못했다. however, 지난 몇년 during, Jaggi의 통찰력to, 힘임어 세imageto, 소개되면서 다시 주목을 받게 되었다. Fig 1 Conditional Gradient Frank-Wolfe method From Jaggi 2011 3 Norm constraints norm MATH about, MATH 일 when, 무슨일이 발생할까? 다음을 let's look at > MATH \\begin align > s &∈ \\arg\\min \\|s\\|≤t ∇f x^ k−1 ^Ts \\\\\\ > &= −t · \\arg\\max \\|s\\|≤1 ∇f x^ k−1 ^Ts \\\\\\ > &= −t · ∂ \\| ∇f x^ k−1 \\| ∗ > \\end align MATH 여기서 MATH 는 dual norm을 의마한다. 다시 말solution, dual norm의 subgradient를 computation하는 method을 안다면, Frank-Wolfe step를 쉽게 수행 할 수 있다는 뜻이다. Frank-Wolfe의 핵심은 MATH to, projection method을 사용하는 것보다 더 간단하거나 낮은 비용with, 구할 수 있으며, also, when,to,는 MATH 의 prox operator보다도 간단하거나 더 낮은 비용을 요한다는 것이다. Example: MATH regularization 다음은 MATH -regularized 이다. > MATH 앞선 공식대to, 전개하면, MATH 를 얻을 수 있다. Frank-Wolfe method은 다음의 process을 through, 업데이트 된다. > MATH \\begin array rcl > i k−1 & ∈ & \\arg\\max i=1,...p ∇ i f x^ k−1 \\\\\\ > x^ k & = & 1 − γ k x^ k−1 − γ kt · sign ∇ i k−1 f x^ k−1 · e i k−1 > \\end array MATH 이것은 coordinate descent의 일종이다 coordinate descentabout,서는 나중to, 자세히 let's look at . Note : 두 가지 모두 MATH 의 복잡도가 필요but, MATH ballto, projection 하는 것보다 훨씬 간단하다. Example: MATH regularization 다음은 MATH -regularized problem다. > MATH MATH at, p가 q의 dual일 when, MATH 이다. that is,, MATH 이다. that is, as follows: 선택할 수 있다. > MATH 여기서 MATH 는 MATH and, 같은 constant이고, Frank-Wolfe 업데이트도 동일하다. Note: 일반 MATH 의 case, p Ballto, Projection 하는 것보다 훨씬 간단하다. 특별한 case, MATH 를 제외하고 이러한 projection은 직접 computation할 수 없다 optimizationto, 처리되어야 함 . Example: trace norm regularization trace-regularized problem를 let's look at > MATH MATH 이다. as follows: MATH 를 선택할 수 있다. > MATH 여기서 MATH 는 MATH 의 왼쪽, 오른쪽 singular vector이고, Frank-Wolfe 업데이트는 평소and, 같다. Note: 이 method은 특이 값 분solution SVD 가 가능하면, trace norm ballto, projection 하는 것보다 훨씬 간단하고 효율적with, solution를 구할 수 있는 method이다. Constrained and Lagrange forms 제약 condition,이 있는 problem의 solution을 다시 한번 image기solution보자 > MATH 다음의 Lagrange problem는 위 식and, equivalence이다. > MATH 튜닝 파라미터 MATH and, MATH 는 0,∞ 구간at, 변한다. also, MATH 의 Frank-Wolfe 업데이트를 MATH 의 proximal 오퍼레이터and, comparing,야 한다. • MATH norm : Frank-Wolfe method은 gradient의 최댓값을 스캔하여 업데이트 한다. proximal operator soft-threshold를 진행하면서 업데이트 한다. 두 step 모두 MATH flops을 사용 한다. • MATH norm : 프랭크-울프 Frank-Wolfe 업데이트는 gradient의 각 항목마다 제product하고 모두 sum산하여 MATH flopwith, 증가시킨다. proximal operator는 generally, 직접 computation할 수 없다. • Trace norm : 프랭크-울프 Frank-Wolfe 업데이트는 gradient의 image단 왼쪽 및 오른쪽 singular vector를 computation한다. proximal operatorat,는 soft-thresholds gradient step을 진행하며, 특이값 분solution SVD 를 필요to, 한다. 다른 많은 regularizer들이 효율적인 Frank-Wolfe update를 도출하였다. 예를 들면, special polyhedra or, cone constraints, sum-of-norms group-based regularization, atomic norms. 같은 것들이다. Constrained Lassoto, about, projected gradient techniqueand, conditional gradient technique을 활용했을 when, 성능을 비교하면 as follows:. 여기서 MATH Fig 2 Comparing projected and conditional gradient for constrained lasso problem 3 프랭크-울프 Frank-Wolfe method이 first-order method의 convergence율and, 비슷한 양image을 띠고 있는 것을 확인할 수 있을 것이다. however, actually,는 높은 정확도to, convergence하기 for,서는 속도가 더 느려질 수 있다. reference: 여기서 fixed step size를 사용but,, line search를 using, convergence 속도를 향image시킬 수도 있다. Duality gap 프랭크-울프 Frank-Wolfe iteration processat, 자연스럽게 duality gap 이 발생되며, 이는 actually, suboptimality gap을 의미한다. > MATH 이것은 MATH 의 upper bound 이다. Proof convexity의 first-order condition을 using, 증명할 수 있다. > MATH 모든 MATH about, 양쪽을 minimization 한다. > MATH 최종적with,, 다시 정리하여 다음 식은 duality gap이 upper bound임을 showing, 준다. > MATH Note therefore, 이 quantity는 Frank-Wolfe 업데이트at, 직접 나온 것이다. 왜 우리는 이를 “duality gap”이라 부를까? original problem을 다시 써보면 아래and, 같이 쓸 수있다. > MATH 여기서 MATH 는 MATH 의 indicator function을 의미한다. dual problem는 아래and, 같다. > MATH MATH 가 MATH 의 support function을 의미한다. Indicator function의 conjugate는 support function 이 됨을 앞서 살펴보았다. Recall > MATH > I C X = > \\begin cases > +& \\infty &if &x &\\notin; C \\\\\\ > & 0 &if &x &\\in; C > \\end cases > MATH > MATH > \\begin align > I C^ &= \\max x \\ - I C x \\ \\\\ > &= \\max x \\in C \\\\ > &= \\text Support function of C \\text at S > \\end align > MATH MATH 일 when,, MATH at, 발생하는 duality gap은 as follows:. 13-04 Fenchel's inequality % multilang post url contents/chapter13/21-04-05-13 04 Conjugate function % from, 유도되기도 한다. > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter22/22_02_Conditional_gradient_method/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter22/22_03_Convergence_analysis",
    "title": "22-03 Convergence analysis",
    "chapter": "22",
    "order": 4,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Convergence analysis To find out the convergence characteristics of the Frank-Wolfe method, it is necessary to define the curvature constant of MATH for MATH as follows. Jaggi 2011 > MATH > MATH M을 through,서 actually, function가 선형 approximation linear approximation from, 얼마나 먼 경향을 가지고 있는지를 측정할 수도 있다. 여기서 MATH 은 MATH 가 선형임을 나타낸다. MATH 는 MATH by, 정의 된 Bregman divergence 라 부른다. > Theorem: 고정 스텝 사이즈 MATH 를 이용한 condition,부 그레디언드 method conditional gradient method 은 다음을 만족한다. > MATH MATH 를 만족하기 for, 필요한 iteration 횟수는 MATH 이다. 이제 이 이론은 귀납법with, proving,보고자 한다. however, 바to, 증명with, 넘어가기전 짚고 넘어가야 할 개념을 하나 소개하고자 한다. Basic inequality Frank-Wolfe convergence 속도를 증명하는 데 사용되는 key inequality 는 as follows:. > MATH 여기서 MATH 는 앞서 논의한 duality gap 을 의미하며, 귀납법according to, 이 비율은 inequality를 따르게 된다. Proof Basic inequality를 증명하기 for, MATH 를 지정한다. and, as follows: 정리한다. > MATH \\begin align > f x^+ &= f\\bigl x + γ s − x \\bigr \\\\\\ > &≤ f x + γ∇f x ^T s − x + \\frac γ^2 2 M \\\\\\ > &= f x − γg x + \\frac γ^2 2 M > \\end align MATH 위 수식at, 두 번째 줄은 MATH 의 정의를 사용했고, 세 번째 줄은 MATH 의 정의를 사용하였다. 이제, basic inequality를 using,, 우리는 convergence rate theorem을 증명하기 for, 귀납법을 사용한다. MATH 의 case,, theorem이 만족함을 쉽게 확인할 수 있다. and, 임의의 MATH 일 case,, MATH 를 만족함을 가정한다. 앞서 언급한 duality gap MATH 를 다시 떠올려 보자. > MATH > MATH and, 이제 basic inequalityto, applying, 보자. > MATH > MATH > MATH 이 증명 된 convergence 속도는 ∇f가 립시츠 Lipschitz 일 when, projected gradient descent의 informing,진 속helping, 일치한다. 이제 이 가정 들을 comparing, 보자. in fact, if, MATH 가 constant MATH 을 가지는 Lipschitz라면 MATH 일 when, MATH 이다. 이를 확인하기 for, constant MATH 을 가지는 MATH Lipschitz 아래and, 같다는 것을 image기할 필요가 있다. > MATH 모든 MATH 를 maximizing, MATH 를 product하면 as follows:. > MATH M의 경계가 결정되었다. 기본적with, 경계가 있는 곡률이 proximal gradientabout, 가정한 곡률보다 크지 않다고 가정한다. Affine invariance 앞서 배운 개념들을 다시 생각solution 보자. Gradient Descent: MATH Pure Newton’s Method: MATH Gradient descent는 affine invariant하지 않다. that is,, coordinate들을 스케일링 함with, gradient descent의 성능은 향image 된다. 반면, Newton’s method는 affine invariant하다. that is,, 이 algorithm은 variable의 모든 affine transformationat, 동일하게 동작한다. and, Conditional gradient method는 gradient descentand, 비슷but, affine invariant 하다. Frank-Wolfe의 중요한 속성 : 업데이트는 affine invariant 하다. Nonsingular MATH 가 주어지면, MATH 를 정의할 수 있다. 그러면 MATH at,의 Frank-Wolfe는 아래and, 같이 computation 가능하다. > MATH \\begin array rcl > s' & = & \\arg\\min z∈A^ −1 C ∇h x' ^Tz \\\\\\ > x' ^+ & = & 1 − γ x' + γs' > \\end array MATH MATH to, product하면 MATH at, 수행되는 것and, 동일한 Frank-Wolfe 업데이트가 나타난다. 심지어 convergence analysis은 affine invariant이다. MATH 의 곡률 constant MATH 은 as follows:. > MATH MATH 이기 because of, MATH and, 일치한다. however,, affine invariance는 M의 경계at, 직관적이지 않다. > MATH 주어진 C의 diameter이 affine invariance이 아니라면, 이것은 고민solution 볼 가치가 있다. Inexact updates 정확하지 않은 Frank-Wolfe 업데이트를 분석하였다. Jaggi 2011 MATH 를 선택한다. > MATH MATH 는 부정확한 파라미터이다. 이를 using, 기본적with, 다음and, 같은 비율을 얻게 된다. > Theorem: 고정 스텝 magnitude MATH 및 부정확한 파라미터 δ≥0을 이용한 Conditional gradient method을 using,, 다음을 만족한다. > MATH Note: MATH step의 optimization 오difference는 MATH 이다. 여기서 MATH 이므to, 시간이 지날수록 오difference가 사라지는 것을 의도to, 한다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter22/22_03_Convergence_analysis/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter22/22_04_Properties_and_variants",
    "title": "22-04 Properties and variants",
    "chapter": "22",
    "order": 5,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Some variants Let's look at some variant conditional gradient methods: • Line search : Instead of fixing MATH , we use exact line search for the step size at each MATH . > MATH Backtracking can also be used. • Fully corrective : Direct update according to the following equation. > MATH This method can achieve much better progress, but the cost is high. Fig 3 Away step motivation 3 Another variant: away steps For a faster solution, let's look at the minimization problem in Fig 3 . Here, the optimal solution is 0,0 . The conditional descent method becomes difficult to move from the initial point 0,1 . However, due to away step movement, conditional gradient descent not only moves to promising points but also moves away from unpromising points. Let's assume a convex hull MATH for atoms set MATH We can explicitly represent MATH as a convex combination of elements belonging to MATH . > MATH Conditional gradient with away steps: \\\\ MATH \\\\ MATH \\\\ MATH MATH MATH MATH \\\\ MATH Linear convergence Let's consider the following unconstrained problem. > MATH Here, MATH is µ-strongly convex and MATH is L-Lipschitz. By iterating gradient descent MATH with MATH , the following is satisfied. > MATH Now let's also consider the following constrained problem. > MATH Theorem Lacoste-Julien & Jaggi 2013 Assume that MATH is µ-strongly convex, MATH is L-Lipschitz, and MATH is finite. With appropriate MATH , the iteration steps generated by the conditional gradient algorithm always satisfy the following. > MATH > MATH If the polytope is planar, MATH is small and the algorithm converges slowly. Path following Let's look at the following given norm constrained problem > MATH The Frank-Wolfe algorithm can be used for path following . In other words, it means that it can generate a approximate solution path MATH . Starting with MATH and MATH , fix parameters MATH and then iterate for MATH . Compute MATH and set MATH for all MATH . At MATH , execute Frank-Wolfe to compute MATH and terminate when the duality gap is MATH . This is a method that simplifies existing strategies. Giesen et al. 2012 Through this path following strategy, we can guarantee the following for all visited MATH : > MATH That is, it generates a case of suboptimality gap that is uniformly bounded by MATH for all MATH . As shown in the equation below, the Frank-Wolfe duality gap can be redefined as follows: > MATH This is a linear function with respect to MATH . Therefore, if MATH , we can increase MATH to MATH using the following equation. > MATH That is, the duality gap is maintained at MATH between MATH and MATH for the same MATH .",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter22/22_04_Properties_and_variants/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter23/23_Coordinate_Descent",
    "title": "23 Coordinate Descent",
    "chapter": "23",
    "order": 1,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Coordinate descent is an optimization algorithm that iteratively moves along each coordinate axis to find the minimum of the objective function. At each iteration, according to a coordinate selection rule, it determines a coordinate axis coordinate or coordinate block, then minimizes the function along the direction of that axis while keeping the unselected coordinate axes or coordinate blocks fixed exactly or inexactly . Coordinate descent can be utilized not only with gradient-based methods but also with gradient-free methods. Additionally, depending on the case, line search can be used to determine appropriate step sizes for each axis 16 . Coordinate descent is very simple and easy to implement, and shows very good performance when carefully implemented for appropriate problems. Examples: lasso regression, lasso GLMs under proximal Newton , SVMs, group lasso, graphical lasso applied to the dual , additive modeling, matrix completion, regression with nonconvex penalties References and Further readings Early coordinate descent in optimization: D. Bertsekas and J. Tsitsiklis 1989 , “Parallel and distributed domputation: numerical methods” Z. Luo and P. Tseng 1992 , “On the convergence of the coordinate descent method for convex differentiable minimization” J. Ortega and W. Rheinboldt 1970 , “Iterative solution of nonlinear equations in several variables” P. Tseng 2001 , “Convergence of a block coordinate descent method for nondifferentiable minimization” 35 Early coordinate descent references in statistics and ML: I. Daubechies and M. Defrise and C. De Mol 2004 , “An iterative thresholding algorithm for linear inverse problems with a sparsity constraint” J. Friedman and T. Hastie and H. Hoefling and R. Tibshirani 2007 , “Pathwise coordinate optimization” W. Fu 1998 , “Penalized regressions: the bridge versus the lasso” T. Wu and K. Lange 2008 , “Coordinate descent algorithms for lasso penalized regression” A. van der Kooij 2007 , “Prediction accuracy and stability of regresssion with optimal scaling transformations” Coordinate descent의 응용: O. Banerjee and L. Ghaoui and A. d’Aspremont 2007 , “Model selection through sparse maximum likelihood estimation” J. Friedman and T. Hastie and R. Tibshirani 2007 , “Sparse inverse covariance estimation with the graphical lasso” J. Friedman and T. Hastie and R. Tibshirani 2009 , “Regularization paths for generalized linear models via coordinate descent” C.J. Hsiesh and K.W. Chang and C.J. Lin and S. Keerthi and S. Sundararajan 2008 , “A dual coordinate descent method for large-scale linear SVM” R. Mazumder and J. Friedman and T. Hastie 2011 , “SparseNet: coordinate descent with non-convex penalties” J. Platt 1998 , “Sequential minimal optimization: a fast algorithm for training support vector machines” 37 Recent theory for coordinate descent: A. Beck and L. Tetruashvili 2013 , “On the convergence of block coordinate descent type methods” Y. Nesterov 2010 , “Efficiency of coordinate descent methods on huge-scale optimization problems” J. Nutini, M. Schmidt, I. Laradji, M. Friedlander, H. Koepke 2015 , “Coordinate descent converges faster with the Gauss- Southwell rule than random selection” A. Ramdas 2014 , “Rows vs columns for linear systems of equations—randomized Kaczmarz or coordinate descent?” P. Richtarik and M. Takac 2011 , “Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function” A. Saha and A. Tewari 2013 , “On the nonasymptotic convergence of cyclic coordinate descent methods” S. Wright 2015 , “Coordinate descent algorithms” 38 Screening rules and graphical lasso references: L. El Ghaoui and V. Viallon and T. Rabbani 2010 , “Safe feature elimination in sparse supervised learning” R. Tibshirani, J. Bien, J. Friedman, T. Hastie, N. Simon, J. Taylor, and R. J. Tibshirani 2011 , “Strong rules for discarding predictors in lasso-type problems” R. Mazumder and T. Hastie 2011 , “The graphical lasso: new insights and alternatives” R. Mazumder and T. Hastie 2011 , “Exact covariance thresholding into connected components for large-scale graphical lasso” J. Wang, P. Wonka, and J. Ye 2015 , “Lasso screening rules via dual polytope projection” D. Witten and J. Friedman and N. Simon 2011 , “New insights and faster computations for the graphical lasso” Convergence analysis: Coordinate descent의 convergence analysisto, about, 연구 흐름을 간략히 소개하겠다. Convergence of coordinatewise minimization for solving linear systems, the Gauss-Seidel method, is a classic topic. E.g., see Golub and van Loan 1996 , or Ramdas 2014 for a modern twist that looks at randomized coordinate descent Nesterov 2010 considers randomized coordinate descent for smooth functions and shows that it achieves a rate O 1/ε under a Lipschitz gradient condition, and a rate O log 1/ε under strong convexity Richtarik and Takac 2011 extend and simplify these results, considering smooth plus separable functions, where now each coordinate descent update applies a prox operation Saha and Tewari 2013 consider minimizing l1 regularized functions of the form g β + λ∥β∥1, for smooth g, and study both cyclic coordinate descent and cyclic coordinatewise min. Under very strange conditions on g, they show both methods dominate proximal gradient descent in iteration progress Beck and Tetruashvili 2013 study cyclic coordinate descent for smooth functions in general. They show that it achieves a rate O 1/ε under a Lipschitz gradient condition, and a rate O log 1/ε under strong convexity. They also extend these results to a constrained setting with projections Nutini et al. 2015 analyze greedy coordinate descent called Gauss-Southwell rule , and show it achieves a faster rate than randomized coordinate descent for certain problems Wright 2015 provides some unification and a great summary. Also covers parallel versions even asynchronous ones General theory is still not complete; still unanswered questions e.g., are descent and minimization strategies the same?",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter23/23_Coordinate_Descent/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter23/23_01_Coordinate_descent",
    "title": "23-01 Coordinate Descent",
    "chapter": "23",
    "order": 2,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "In this chapter, we introduce a method called coordinate descent that is extremely simple, efficient, and highly scalable. First, let's start with some simple questions and answers. Q1. When function MATH is convex and differentiable, if the point where MATH is minimized along each coordinate axis is MATH , is this MATH a global minimizer? A1: Yes. Since MATH , MATH is a global minimizer of MATH . The above question is equivalent to asking whether MATH is satisfied for all MATH when MATH is the MATH -th standard basis vector. That is, since we cannot make MATH smaller by moving in any coordinate axis direction from MATH , the partial derivatives in all axis directions become 0. MATH \\nabla f x = \\big \\frac \\partial f \\partial x 1 x , \\dots, \\frac \\partial f \\partial x n x \\big = 0, \\dots, 0 = 0 MATH MATH Q2. Then, when MATH is convex but 'non-differentiable' function, is the point MATH where MATH is minimized along each coordinate axis always a global minimizer? A2: No. In this case, we cannot assert that MATH is a global minimizer of MATH . Counterexample: Fig2 below Looking at the contour lines on the right side of the counterexample below, we can see that although the marked point is not the global minimum, MATH cannot be made smaller by moving in any coordinate axis direction. To make MATH smaller, one must be able to move inside the contour lines. This is because at this position, all inner regions of the contour lines are contained within the two tangent lines parallel to the coordinate axes. On the other hand, when MATH is a differentiable convex function, only one tangent line exists at any point on the contour lines, so this phenomenon does not occur. MATH Q3. When MATH can be expressed as the sum of a differentiable convex function MATH and a convex function MATH , is the point MATH where MATH is minimized along each coordinate axis always a global minimizer? That is, MATH A3. Yes. This is because it satisfies the following for any MATH . MATH \\begin align f y - f x &\\ge \\nabla g x ^T y-x + \\sum i=1 ^ n \\big h i y i - h i x i \\big \\\\\\\\ &= \\sum i=1 ^ n \\big \\underbrace \\nabla i g x y i - x i + h i y i - h i x i \\ge 0 \\big \\ge 0 \\end align MATH Proof: >Let MATH . MATH means viewing only the MATH -th element of MATH as a variable, and the rest as fixed values. > > MATH > \\begin align > & \\: 0 \\in \\partial F i x i \\\\\\\\ > \\Leftrightarrow & \\: 0 \\in \\ \\nabla i g x \\ + \\partial h i x i \\\\\\\\ > \\Leftrightarrow & \\: - \\nabla i g x \\in \\partial h i x\\ i > \\end align > MATH By the definition of subgradient % multilang post url contents/chapter07/21-03-25-07 01 subgradient % , > MATH > \\begin align > & h i y i \\ge h i x i - \\nabla i g x y i - x i \\\\\\\\ > \\Leftrightarrow & \\nabla i g x y i - x i + h i y i - h i x i \\ge 0. > \\end align > MATH MATH Conclusion The minimizer of MATH with MATH convex, differentiable and MATH convex can be found using coordinate descent . Coordinate descent iterates the following cycle. Assume that an appropriate initial value MATH is set. > Coordinate Descent: > MATH For MATH , > > MATH >\\begin align >x 1^ k &\\in \\text arg \\min x 1 \\: f x 1, x 2^ k-1 , x 3^ k-1 , \\dots, x n^ k-1 \\\\\\\\ >x 2^ k &\\in \\text arg \\min x 2 \\: f x 1^ k , x 2, x 3^ k-1 , \\dots, x n^ k-1 \\\\\\\\ >x 3^ k &\\in \\text arg \\min x 3 \\: f x 1^ k , x 2^ k , x 3, \\dots, x n^ k-1 \\\\\\\\ >& \\dots\\\\\\\\ >x n^ k &\\in \\text arg \\min x n \\: f x 1^ k , x 2^ k , x 3^ k , \\dots, x n >\\end align > MATH Notes: The process of obtaining MATH uses the newly obtained MATH in the MATH -th cycle. The order of coordinate axes in the cycle can be arbitrarily specified. Two or more coordinate axes can be grouped together and processed as blocks. The coordinate descent introduced above corresponds to exact coordinatewise minimization. Another approach is inexact coordinatewise minimization using gradients. Assuming MATH is a differentiable convex function > Coordinate Descent inexact coordinatewise minimization : > MATH For MATH , > > MATH >\\begin align >x 1^ k &= x 1^ k-1 - t k,1 \\cdot \\nabla 1 f x 1^ k-1 , x 2^ k-1 , x 3^ k-1 , \\dots, x n^ k-1 \\\\\\\\ >x 2^ k &= x 2^ k-1 - t k,2 \\cdot \\nabla 2 f x 1^ k , x 2^ k-1 , x 3^ k-1 , \\dots, x n^ k-1 \\\\\\\\ >x 3^ k &= x 3^ k-1 - t k,3 \\cdot \\nabla 3 f x 1^ k , x 2^ k , x 3^ k-1 , \\dots, x n^ k-1 \\\\\\\\ >& \\dots\\\\\\\\ >x n^ k &= x n^ k-1 - t k,n \\cdot \\nabla n f x 1^ k , x 2^ k , x 3^ k , \\dots, x n^ k-1 >\\end align > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter23/23_01_Coordinate_descent/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter23/23_02_Example_linear_regression",
    "title": "23-02 Example: linear regression",
    "chapter": "23",
    "order": 3,
    "owner": "Jinwoo Park",
    "lesson_type": "",
    "content": "Let's define the linear regression problem as follows. > MATH > MATH When MATH are fixed values, let's find MATH that minimizes the given objective function. MATH means the remaining terms excluding MATH . - In the case of MATH , the remaining columns excluding the MATH -th column. MATH \\begin align 0 &= \\nabla i f \\beta \\\\\\\\ &= X i^T X\\beta - y \\\\\\\\ &= X i^T X i \\beta i + X -i \\beta -i - y \\\\\\\\ \\Rightarrow\\\\\\\\ &\\beta i = \\frac X i^T y - X -i \\beta -i X i^T X i \\end align MATH Through coordinate descent, we iterate and update MATH for MATH . Experiment: Convergence speed comparison - GD vs AGD vs CD The graph below shows the convergence speeds of coordinate descent, gradient descent, and accelerated gradient descent for a linear regression problem with MATH . The k on the horizontal axis represents one step GD, AGD or one cycle CD . Fig1 GD vs AGD vs CD 3 According to the above results, coordinate descent shows significantly better convergence speed than AGD, which is optimal among first-order methods. Why can this phenomenon occur? To conclude, coordinate descent can achieve performance that far surpasses AGD because it utilizes more information than first-order methods. This is because coordinate descent uses the latest information updated in the previous step at each step within one cycle. That is, CD is not a first-order method. Q. Then, is it fair to compare one cycle of CD with one step of GD in the above experiment? A. Yes. The CD update formula introduced earlier can be modified to have a time complexity of MATH per step. Then, the time complexity of one cycle for CD becomes MATH , which has the same time complexity as one step of GD. Gradient descent update: MATH , the time complexity of the MATH operation becomes MATH flops.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter23/23_02_Example_linear_regression/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter23/23_03_Example_lasso_regression",
    "title": "23-03 Example: lasso regression",
    "chapter": "23",
    "order": 4,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Lasso regression problem를 아래and, 같이 nonsmooth part가 분리되어있는 objective function의 형태to, 정by,보겠다. > MATH > \\min \\beta \\frac 1 2 \\| y - X\\beta \\| 2^2 + \\lambda \\|\\beta\\| 1 > MATH Note: MATH MATH 가 고정된 값일when,, 주어진 objective function를 minimization시키는 MATH 를 let's find. MATH \\begin align &0 = \\nabla i f \\beta = X i^T X i \\beta i + X i^T X -i \\beta -i - y + \\lambda s i,\\\\\\\\ &\\text where s i \\in \\partial |\\beta i| \\Rightarrow \\beta i = S \\lambda / \\|X i\\| 2^2 \\big \\frac X i^T y-X -i \\beta -i X i^TX i \\big \\end align MATH Solution은 thresholding level이 MATH 인 soft-thresholding functionand,도 같다. Coordinate descent를 through, MATH for MATH 를 iteration하며 업데이트 한다. 실험: convergence속도 비교 - PG vs AGD vs CD 아래 그래프는 MATH 인 lasso regression problemabout, proximal gradient descent, accelerated gradient descent, coordinate descent의 convergence속도를 comparing, showing,준다. 가to,axis의 k는 한 step PD, AGD or, 한 cycle CD 을 나타낸다. Fig1 PD vs AGD vs CD 3 Linear regression의 예시 % multilang post url contents/chapter23/21-03-28-23 02 Example linear regression % at,and, 마찬가지to, lasso regression problemat,도 coordinate descent는 월등한 convergence속도를 보인다. First-order method보다 더 많은 정보를 활용한다. Note: 위 실험at,의 모든 methods는 각 iteration당 MATH flops의 시간복잡도를 보인다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter23/23_03_Example_lasso_regression/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter23/23_04_Example_pathwise_coordinate",
    "title": "23-04 Example: Pathwise coordinate descent for lasso",
    "chapter": "23",
    "order": 5,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "In this section, Pathwise coordinate descent for lassoto, about, 개요를 간단히 소개하도록 한다 Friedman et al. 2007 https://arxiv.org/pdf/0708.1485.pdf Friedman et al. 2009 https://www.jstatsoft.org/article/view/v033i01/v33i01.pdf . > Lasso regression problem: > MATH > \\min \\beta \\frac 1 2 \\| y - X\\beta \\| 2^2 + \\lambda \\|\\beta\\| 1 > MATH 07-03-03 Example: Lasso Optimality Condition % multilang post url contents/chapter07/21-03-25-07 03 03 example lasso optimality condition % at, lasso regression problemto, about, optimality condition을 유도solution 보았다. 위 problemto, about, optimal solution는 다음의 condition,을 만족한다. > > MATH > \\begin align > X 1^T y-X\\beta &= \\lambda v 1\\\\ > X 2^T y-X\\beta &= \\lambda v 2\\\\ > \\dots\\\\ > X p^T y-X\\beta &= \\lambda v p > \\end align > MATH Note: MATH 는 주어진 matrix MATH 의 MATH 번째 열 column 데이터를 의미한다. 여기서 MATH 는 MATH to, about, subgradient다. > MATH v i, i \\in \\ 1,2,\\dots,p \\ = \\begin cases \\ 1 \\ &\\text if MATH \\\\ \\ -1 \\ &\\text if MATH $의 순서를 따라 optimal solution를 computation한다. Tuning parameter MATH at, computation된 result,를 MATH to, about, coordinate descent algorithm을 초기화하는데 사용한다. warm start Inner loop active set strategy : 하나 or, 적은 수의 coordinate cycle을 시행한다. and, 0이 아닌 MATH 의 element를 active set MATH to, 기록한다. MATH to, 기록된 element들about,서만 convergence할 when,to, coordinate cycle을 시행한다. MATH 의 모든 element들about, optimality condition을 확인한다. condition,을 만족하지 않는 element가 있으면 MATH to, 추가하고 step 1with, 다시 돌아간다. Notes 통image적with, pathwise strategy는 problemat, 주어진 MATH to, about, solution를 바to, 구하는 것보다 훨씬 효율적with, 동작한다. Active set strategy는 sparsityabout, 이점이 있다. 이 because of, coordinate descent는 ridge regression보다 lasso regressionat, 훨씬 더 빠르게 동작한다. reference: ridge regressionand, lasso regression의 경향성 분석 https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/ Pathwise coordinate descent for lasso는 lasso regression problemabout, 가장 빠르다고 informing,진 다른 algorithm들to, 비견될만큼 빠르게 동작한다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter23/23_04_Example_pathwise_coordinate/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter24/24_Mixed_integer_programming",
    "title": "24 Mixed Integer Programming (part I)",
    "chapter": "24",
    "order": 1,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "This chapter introduces the definition, relationships, and examples of Mixed Integer Programming, and presents methods for finding optimal solutions by indirectly utilizing relaxation to find solutions for Integer programming.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter24/24_Mixed_integer_programming/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter24/24_01_Definition",
    "title": "24-01 Definition",
    "chapter": "24",
    "order": 2,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "This section aims to explain the basic concepts for solving optimization problems through the mixed integer program approach. Problem definition When some variables in an optimization model have the constraint of being integers, this is called an integer program. > MATH > \\begin align > &\\min x && f x \\\\\\\\ > &\\text subject to && x \\in C \\\\\\\\ > &&&x j \\in \\mathbb Z , j \\in J > \\end align > MATH > MATH > \\begin align > \\text where f: \\mathbb R ^ n \\rightarrow \\mathbb R , \\quad C \\subseteq \\mathbb R ^ n \\quad and \\quad J \\subseteq 1, \\dotsc, n . > \\end align > MATH In the above expression, if MATH satisfies the following, it is called a pure integer program. > MATH \\ MATH \\ Let us assume that both MATH and MATH discussed in this section are convex. Binary variables Looking at some representative examples of integer programs, we can mention yes/no decision problems or logical values. In this case, we define the problem using binary variables and solve the problem to find values of 0 or 1 for the conditions. The combinatorial optimization to be introduced next is directly associated with integer programming. This is because by utilizing binary variables, we can transform existing problems and solve them as new problems. Combinatorial optimization problems are defined using the triple MATH representation. > MATH is a finite ground set MATH is the set of feasible solutions MATH is the cost function The ultimate goal is to solve the following equation through the triple MATH . > MATH > \\begin align \\quad \\min S \\in \\mathcal F & \\sum i \\in S c i \\\\ > \\end align > MATH 많은 결sum optimization combinatorial optimization problem는 binary integer program들to, being used,질 수있다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter24/24_01_Definition/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter24/24_02_Example_of_integer_programs",
    "title": "24-02 Examples of integer programs",
    "chapter": "24",
    "order": 3,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "In this section, let's examine various examples corresponding to Integer programming and learn how they are utilized. Knapsack problem The Knapsack problem is a traditional combinatorial optimization problem where the volume that can be put into the knapsack is limited, constraining the total magnitude of items that can fit inside the knapsack. When this constraint exists, the problem aims to select items with maximum value. This problem can be expressed using binary variables MATH , where MATH takes a value of 0 or 1 depending on whether the MATH -th item is selected or not. > MATH > \\begin align > &\\max x && c^\\intercal x \\\\\\\\ > &\\text subject to && a^\\intercal x \\leq b \\\\\\\\ > &&&x j \\in 0, 1 , j = 1, \\dotsc , n > \\end align > MATH MATH represent the value and magnitude volume of the MATH -th item, respectively. Assignment problem Let's assume there are MATH people and MATH tasks. Each person can be assigned to exactly one task. Here, MATH represents the cost required for person MATH to perform task MATH . The Assignment problem aims to assign MATH people to MATH tasks with the minimum cost. To optimize these conditions, the mathematical formulation is as follows: > MATH > \\begin align > &\\min x &&\\sum i = 1 ^ n \\sum j = 1 ^ n c ij x ij \\\\\\\\ > &\\text subject to &&\\sum i = 1 ^ n x ij = 1, j = 1 \\dotsc n \\\\\\\\ > &&&\\sum j = 1 ^ n x ij = 1, i = 1 \\dotsc n \\\\\\\\ > &&&x ij \\in \\lbrace 0, 1\\rbrace \\quad i = 1 \\dotsc n, \\quad j = 1 \\dotsc n > \\end align > MATH Facility location problem The Facility location problem aims to minimize transportation costs from specific facilities to customers. Let's assume there are depots MATH and customers MATH . The fixed cost MATH is associated with using depot MATH . The transportation cost MATH is the cost incurred when goods delivered to customer MATH are transported from depot MATH . The decisions to be made here are which depots should be operational and which customers should receive deliveries from each depot, with the goal of minimizing both fixed costs and transportation costs by deriving and solving the mathematical formulation. > MATH > \\begin align > &\\min x, y && \\sum i = 1 ^ n f j y j + \\sum i = 1 ^ m \\sum j = 1 ^ n c ij x ij \\\\ > &\\text subject to && \\sum j = 1 ^ n x ij = 1, \\quad i = 1 \\dotsc m \\\\ > &&& x ij \\leq y j , \\quad i = 1 \\dotsc m, \\quad j = 1 \\dotsc n \\\\ > &&& x ij \\in \\lbrace 0, 1\\rbrace \\quad i = 1 \\dotsc m, \\quad j = 1 \\dotsc n \\\\ > &&& y j \\in \\lbrace 0, 1\\rbrace \\quad j = 1 \\dotsc n \\\\ > \\end align > MATH The first constraint means that each customer can receive goods from one depot. The second constraint states that depot MATH must be operational for customer MATH to receive goods from there. Since both MATH and MATH are binary, we can consider MATH constraints. This can also be expressed in a \"marginalized\" form as the following constraint: > MATH Reflecting this, it can be replaced with the following mathematical formulation: > MATH > \\begin align > &\\min x, y &&\\sum i = 1 ^ n f j y j + \\sum i = 1 ^ m \\sum j = 1 ^ n c ij x ij \\\\ > &\\text subject to &&\\sum j = 1 ^ n x ij = 1, \\quad i = 1 \\dotsc n \\\\ > &&& \\sum i = 1 ^ n x ij \\leq m y j , \\quad j = 1 \\dotsc n \\\\ > &&& x ij \\in \\lbrace 0, 1\\rbrace \\quad i = 1 \\dotsc n, \\quad j = 1 \\dotsc n \\\\ > &&& y j \\in \\lbrace 0, 1\\rbrace \\quad j = 1 \\dotsc n \\\\ > \\end align > MATH K-means and K-medoids clustering Clustering is the process of dividing data into similar groups. The K-means algorithm aims to find K clusters by finding MATH center values centroids that minimize the average distance between data points within clusters. The goal is to find a partition MATH for the given data. In this case, the following formula is minimized: MATH where MATH , MATH represents the centroid of cluster MATH . A method that is more robust to outliers than computing centroids by averaging K-means is K-medoids clustering, which sets the center value as the data point closest to the cluster center instead of computing the center values of K clusters using arithmetic mean. That is, K-medoids clustering is a method that considers each data point MATH as a center point and designates the data point that yields the minimum value when computed as the centroid. > MATH > MATH This problem can be transformed and represented as an integer program. First, we define MATH and define the following two binary variables: MATH \\begin align &w i =\\begin cases 1 && \\text if choose x^ i \\text as a centroid \\\\\\\\ 0 && \\text otherwise. \\end cases \\\\\\\\ &z ji =\\begin cases 1 && \\text if x^ j \\text in the cluster with centroid x^ i \\\\\\\\ 0 && \\text otherwise. \\end cases \\end align MATH The K-medoids problem can be defined as an optimization problem as follows: > MATH > \\begin align > &\\min w, z && \\sum i = 1 ^ n \\sum j = 1 ^ n d ij z ji \\\\\\\\ > &\\text subject to && z ji \\leq w i \\\\\\\\ > &&& \\sum i = 1 ^ n w i = k \\\\\\\\ > &&& w ij \\in 0, 1 \\quad i = 1 \\dotsc n \\\\\\\\ > &&& z ji \\in 0, 1 \\quad j, i = 1 \\dotsc n > \\end align > MATH The first constraint means that after the centroid is first determined, we will determine whether MATH belongs to MATH or not. Best subset selection When the conditions MATH are given, the Best subset selection problem is as follows: > MATH > \\begin align > &\\min \\beta &&\\frac 1 2 \\| y - X\\beta \\|^ 2 \\\\\\\\ > &\\text subject to &&\\| \\beta \\| \\leq k\\\\\\\\ > \\end align MATH > MATH \\begin align > \\text where \\| \\beta \\| 0 : = \\text the number of nonzero entries of \\beta. > \\end align > MATH Since MATH is a non-convex constraint, the problem can be solved more easily by transforming it using Integer programming. > MATH > \\begin align > &\\min \\beta, z && \\frac 1 2 \\| y - X\\beta \\|^ 2 \\\\\\\\ > &\\text subject to && | \\beta i | \\leq Mz i \\quad i = 1 \\dotsc n \\\\\\\\ > &&&z ji \\in \\lbrace 0, 1 \\rbrace \\quad i = 1 \\dotsc n \\\\\\\\ > &&&\\sum i = 1 ^ p z i \\leq k > \\end align > MATH Least median of squares regression When the conditions MATH , and MATH are given, if we define MATH , the Least median of squares regression problem is as follows: > MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter24/24_02_Example_of_integer_programs/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter24/24_03_Solving_integer_programs",
    "title": "24-03 Solving integer programs",
    "chapter": "24",
    "order": 4,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "After transforming the mathematical formulation of Integer programming, techniques such as relaxation are needed to solve the problem. Let's examine the constraints that appear in integer programs and what approaches are taken to address the problem. Hardness of integer programs Solving Integer program problems is much more difficult than solving convex optimization problems. General Integer programming is NP-hard https://en.wikipedia.org/wiki/NP-hardness , requiring at least polynomial time without even knowing the possibility of solvability. In this case, by removing constraints on integer constraints and performing convex relaxation, we can obtain a lower bound that approaches the optimal value. When solving problems using convex relaxation, the following limitations may occur: Finding a feasible integer solution can become difficult. The optimal solution obtained under relaxation conditions may be distant from the optimal solution obtained with integer programming. The value after approximation rounding may differ from the optimal value. Algorithmic template for solving integer programs When MATH is convex and includes integrality constraints, the integer program is as follows: > MATH Unlike convex optimization, there are no direct \"optimality conditions\" that prove a feasible point MATH is optimal. Instead, we can use a method that finds approximations of the optimal by finding lower bound MATH and upper bound MATH while approaching MATH . Algorithmic template Observing the decreasing sequence of upper bounds, > MATH Observing the increasing sequence of lower bounds, > MATH For any MATH , the value of MATH is determined within the range where MATH . Primal bounds According to the previous MATH formula, for any feasible MATH , MATH always holds, and in this case, MATH is an upper bound. However, since we cannot always find a feasible MATH , if the MATH value is included in the corresponding set, the problem can be solved easily, but this may not always be the case. Dual bounds Usually also called lower bounds, their values are found through relaxation. Detailed explanations are added in the next section.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter24/24_03_Solving_integer_programs/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter24/24_04_Relaxations",
    "title": "24-04 Relaxations",
    "chapter": "24",
    "order": 5,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "For relaxation, specific conditions must be satisfied, and Convex relaxation and Lagrangian relaxation methods can be utilized. Let's examine the detailed content. Conditions for Relaxations If a general optimization problem is defined as follows: > MATH The relaxation of this problem is defined as follows when represented as an arbitrary optimization problem: > MATH \\begin align > &\\min x \\in Y \\: g x \\\\\\\\ > &\\text such that \\\\\\\\ > &\\text ① X \\subset Y \\quad \\text and \\\\\\\\ > &\\text ② g x \\leq f x \\text for all x \\in X > \\end align MATH If the objective functions MATH and MATH are different, both conditions must be satisfied, and if they are the same, only condition ① needs to be satisfied. By these two conditions, the optimal value of the relaxation becomes a lower bound of the optimal value of the original problem. Convex relaxations When the given problem is as follows: > MATH > \\begin align > &\\min x &&f x \\\\\\\\ > &\\text subject to && x \\in C \\\\\\\\ > &&&x j \\in \\mathbb Z , \\quad j \\in J \\\\\\\\ >\\end align MATH > MATH \\begin align > \\text where f is convex f : \\mathbb R ^ n \\rightarrow \\mathbb R , \\quad C \\in \\mathbb R ^n > \\quad \\text and \\quad J \\in \\lbrace 1 \\dotsc n \\rbrace \\\\ > \\end align > MATH convex relaxation can be expressed as follows: > MATH > \\begin align > &\\min x && f x \\\\\\\\ > &\\text subject to && x \\in C \\\\\\\\ >\\end align MATH > MATH \\begin align >\\text where f is convex f: \\mathbb R ^ n \\rightarrow \\mathbb R , \\quad C \\in \\mathbb R ^n >\\text and \\quad J \\in \\lbrace 1 \\dotsc n \\rbrace \\\\ >\\end align > MATH Lagrangian relaxations MATH 가 convex and, integer constraints를 모두 포함할 when,, as follows: problem를 정의 할 수 있다. > MATH > \\begin align > &\\min x &&f x \\\\\\\\ > &\\text subject to &&Ax \\leq b \\\\\\\\ > &&& x j \\in \\mathbb Z \\quad x \\in X > \\end align > MATH 이 when,, constraints를 objectiveto, 더하여, 어떤 MATH to, about, Lagrangian relaxation을 하면, as follows:. > MATH > \\begin align > L u = &\\min x &&f x + u^ \\top Ax-b \\\\\\\\ > &\\text subject to &&x \\in X > \\end align > MATH Lagrangian form을 through,서 constraint set이 확장되었고, feasible MATH about, MATH 을 만족하므to,, always, MATH 이 성립한다. therefore, MATH 는 임의의 MATH about,서 lower bound이고, 최선의 lower bound는 dual problem MATH 을 solution결함with,써 obtaining,낼 수 있다. MATH 는 convex function의 point-wise minimization이기 because of, concave optimization problem이 된다는 것을 기억하자. 앞서 언급되었던 Facility location problemto, Lagrangian relaxation을 applying, 보면, unconstrained MATH about, 다음 식을 푸는 problemto, 변형된다. > MATH > \\begin align > L u = &\\min x && \\sum i = 1 ^ n f j y j + \\sum i = 1 ^ m \\sum j = 1 ^ n c ij - v i x ij + \\sum i = 1 ^ m v i \\\\\\\\ > &\\text subject to && x ij \\leq y j \\quad i = 1 \\dotsc m, \\quad j = 1 \\dotsc n \\\\\\\\ > &&& x ij , y j \\in \\lbrace 0, 1 \\rbrace \\quad i = 1 \\dotsc m, \\quad j = 1 \\dotsc n > \\end align > MATH 각각의 MATH about, Lagrange relaxation MATH 는 쉽게 풀릴 수 있다 : > MATH > MATH 이는 lower bound MATH and, heuristic primal solution을 도출 할 수 있도록 한다. also, MATH 의 부분미분 subdifferential 을 사용한다면 computation도 쉬워진다. subgradient method를 using, MATH 를 MATH to, transformation시켜서 problem를 풀어갈 수 있다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter24/24_04_Relaxations/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter24/24_05_Branch_and_bound_algorithm",
    "title": "24-05 Branch and bound algorithm (B&B)",
    "chapter": "24",
    "order": 6,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Let's find out the method of solving Integer programs through Branch and bound algorithm and Convex relaxation. Definition and properties Branch and bound algorithm is the most common method for solving integer programs. It is mainly a divide and conquer approach that breaks the original problem into several smaller problems sub-problems to approach the correct answer. When the constraint set MATH is a union of partitions consisting of each MATH , > MATH We can find the optimal solution by partitioning the region and finding the minimum. Any feasible solution of a sub-problem can be set as the upper bound MATH . To obtain the lower bound, we find the lower bound MATH of each sub-problem. Then, if MATH , we exclude the sub-problem MATH corresponding to this part. The Integer Programming problem IP is defined as follows: > MATH > \\begin align > &\\min x &&f x \\\\\\\\ > &\\text subject to && x \\in C \\\\\\\\ > &&&x j \\in \\mathbb Z , \\quad j \\in J \\\\\\\\ > \\end align MATH > MATH \\begin align > \\text where f is convex f : \\mathbb R ^ n \\rightarrow \\mathbb R , \\quad C \\in \\mathbb R ^n \\quad \\text and \\quad J \\in \\lbrace 1 \\dotsc n \\rbrace \\\\ > \\end align > MATH And when the Convex Relaxation CR problem is as follows: > MATH > \\begin align > &\\min x &&f x \\\\\\\\ > &\\text subject to &&x \\in C \\\\\\\\ > \\end align MATH > MATH \\begin align > \\text where f is convex f : \\mathbb R ^ n \\rightarrow \\mathbb R , \\quad C \\in \\mathbb R ^n \\quad \\text and \\quad J \\in \\lbrace 1 \\dotsc n \\rbrace \\\\ > \\end align > MATH The problem is solved recursively. If the constraint set is trivial, solve the CR problem. If the solution is less than the current upper bound, update the upper bound. Stop. If CR is infeasible, then IP is also infeasible. Stop. If the solution MATH of CR is also feasible for IP , then MATH becomes the solution. Stop. Find the lower bound of the problem. If the solution MATH of CR is infeasible for IP , update the lower bound of IP . If the lower bound is greater than the current upper bound, Stop. Split the constraint set and solve each sub-problem recursively. After branching After branching, solve each subproblem. If the lower bound of a subproblem is greater than the current upper bound, there is no need to consider the subproblems below it. The most reliable method for computing the lower bound is through convex relaxation, but other methods e.g., Lagrangian relaxation are also used.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter24/24_05_Branch_and_bound_algorithm/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter25/25_Mixed_integer_programming",
    "title": "25 Mixed Integer Programming (part II)",
    "chapter": "25",
    "order": 1,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "This chapter examines the cutting plane algorithm, which can be considered the most core algorithm in Integer Programming IP , and the branch and cut algorithm, which is its practical implementation. We will also examine examples of Integer Programming such as best subset selection and Least mean squares. Reference Belotti, Kirches, Ley er, Linderoth, Luedke, and Mahajan 2012 , \"Mixed-integer nonlinear optimization\" Bertsimas and Mazumder 2016 , \"Best subset selection via a modern optimization lens\" Bertsimas, King, and Mazumder 2014 , \"Least quantile regression via modern optimization\" Conforti, Cornuejols, and Zambelli 2014 , \"Integer programming\" Wolsey 1998 , \"Integer programming\"",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter25/25_Mixed_integer_programming/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter25/25_01_Cutting_planes",
    "title": "25-01 Cutting Planes",
    "chapter": "25",
    "order": 2,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "The cutting plane method is an approach that changes an integer linear program to a convex problem and finds a solution. If this solution is not included in the original feasible set, it uses cuts to progressively guide the newly obtained solution to be included in the original feasible set by cutting out the region where the solution exists. Here, a cut is a line or hyperplane that cuts the feasible set, also called a cutting plane. Concept of cutting plane Conceptually, it can be thought of as a method that draws a line between the original feasible set and the feasible set to cut out regions that are not part of the original feasible set, as shown in the figure below. Fig1 Cutting Plane Red region: feasible set of the original integer linear program Blue region: feasible set of the convex relaxation problem Green line: cutting plane the cutting plane exists between the blue and red regions The detailed algorithm will be introduced again in the main text. A bit of history on cutting planes It took a very long time for the cutting plane method to develop from theory to a practical method. In 1954, Dantzig, Fulkerson, and Johnson first proposed the cutting plane method to solve the TSP traveling salesman problem , and in 1958, mathematician Gomory proposed a general cutting plane method that could solve arbitrary integer linear programs. However, for about 30 years after that, Gomory cuts remained buried in an impractical state for solving real problems. In 1990, Sebastian Ceria at CMU successfully implemented the cutting plane method using the branch and bound algorithm, which is called branch and cut. Since then, cutting planes have become a core component of commercial optimization solvers.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter25/25_01_Cutting_planes/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter25/25_01_01_Convexification",
    "title": "25-01-01 Convexification",
    "chapter": "25",
    "order": 3,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Transforming an integer program into an equivalent convex problem is called convexification. When convexification is performed, the feasible set becomes a polyhedron, making it easy to find valid cutting planes for the cutting plane algorithm. Convexification To convexify an integer program, the objective function must be linear. In this case, the constraints of the integer program consist of a convex set MATH and an integer set MATH . > MATH > \\begin align > \\min x & \\quad c^ T x \\\\ > \\text subject to & \\quad x \\in C \\\\ > & \\quad x j \\in \\mathbb Z , \\quad j \\in J \\\\ > \\end align > MATH In this case, the feasible set can be redefined as the convex hull MATH . Using the feasible set defined by this convex hull MATH , we can define a convex problem equivalent to the original problem as follows. This process is called convexification. > MATH > \\begin align > \\min x & \\quad c^ T x \\\\ > \\text subject to & \\quad x \\in S \\\\ > \\end align > MATH In the figure below, the blue region is MATH , the red points are MATH , and the convex hull MATH formed by these two sets is the red region. Fig1 Cutting Plane 출처: https://commons.wikimedia.org/wiki/File:Cutting plane algorithm2.png The reason these two formulations are equivalent is because the objective function is linear. Special case: integer linear programs Let's apply the above convexification process to the following integer linear program. > MATH > \\begin align > \\min x & \\quad c^ T x \\\\ > \\text subject to & \\quad Ax \\le b \\\\ > & \\quad x j \\in \\mathbb Z , \\quad j \\in J \\\\ > \\end align > MATH The convex hull MATH of the integer linear program is defined as follows: > Theorem : If MATH are rational numbers, then the following set is a polygon. MATH So is an integer linear program a linear program? Of course it is. However, in this case, the polyhedron MATH can become a very complex polygon with an exponentially large number of inequalities. Therefore, generally, we need to solve the problem using different methods than those used to solve linear programs.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter25/25_01_01_Convexification/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter25/25_01_02_Cutting_plane_algorithm",
    "title": "25-01-02 Cutting plane algorithm",
    "chapter": "25",
    "order": 4,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "In this section, we will examine the cutting plane algorithm that can solve integer linear programs. Valid Inequality To define cutting planes, let's first look at what valid inequalities are. An inequality MATH is said to be valid for set MATH if it satisfies the following condition. That is, if a set MATH is contained in the halfspace defined by the inequality MATH , then this inequality can be considered valid for MATH . > MATH for all MATH An inequality must be valid to become a cutting plane. Cutting plane algorithm 이제 다음and, 같은 integer programming이 있을 when, cutting plane algorithm을 let's examine. > MATH > \\begin align > \\min x & \\quad c^ T x \\\\ > \\text subject to & \\quad x \\in C \\\\ > & \\quad x j \\in \\mathbb Z , \\quad j \\in J \\\\ > \\end align > MATH MATH 이다. Cutting plane algorithm 다음 algorithmat, Convex Problem은 CPto, Integer Program은 IPto, 표기한다. 1. MATH with, 두고 MATH 를 computation 2. for MATH MATH if MATH 가 IP feasible이면 MATH 는 optimal solution이므to, Stop함 MATH else MATH MATH about, valid하면서 MATH 를 잘라내는 부등식 MATH , MATH 을 찾음 MATH MATH MATH MATH MATH end if end for 이and, 같은 valid inequality를 cutting plane or, cut 이라고 한다. algorithm의 1step는 convex relaxation을 하여 CP problem를 푸는 step이다. 이떄 feasible set은 MATH 이다. algorithm 2stepat,는 구한 solution가 IPat, feasible하다면 이를 solutionto, 본다. if, feasible하지 않다면 solution인 MATH and, set MATH 를 나누는 valid inequality를 finding, MATH 의 범위를 줄인다. and,, MATH to, 재정의된 CP problem를 풀고 algorithm 2step를 iteration하게 된다. 아래 그림at, polygon은 set MATH 를 representing,며 CP의 solution는 검정색 점with, 표시되어 있다. 이when,, valid inequality는 solution를 잘라내서 set MATH 의 범위를 줄이게 된다. Fig1 Valid Inequality 3 이and, 같이 set MATH 의 범위를 계속solution서 reducing,나가면 IP problem의 convex hull feasible set인 set MATH and, 만나게 되어 IPto, feasible한 solution를 구할 수 있게 된다.",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter25/25_01_02_Cutting_plane_algorithm/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter25/25_01_03_Gomory_cuts",
    "title": "25-01-03 Gomory cuts (1958)",
    "chapter": "25",
    "order": 5,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Mathematician Gomory devised a method to easily find valid inequalities based on the following fact: > if MATH and MATH is an integer then MATH . That is, if a is an integer, then even if b is rounded down, the relationship that a is less than or equal to b is maintained. Gomory fractional cut Let's say that the feasible set MATH defined by the convex hull of the IP problem mentioned earlier is as follows: MATH In this case, the Gomory fractional cut is defined as follows: MATH There are many ideas that extend this concept. For example, there are Chvatal cuts, split cuts, lift-and-project cuts, etc. The derivation process of Gomory fractional cut is detailed on Wikipedia, so please refer to it. For detailed information, see Cutting-plane method https://en.wikipedia.org/wiki/Cutting-plane method",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter25/25_01_03_Gomory_cuts/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter25/25_01_04_Branch_and_cut_algorithm",
    "title": "25-01-04 Branch and cut algorithm",
    "chapter": "25",
    "order": 6,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "In 1990, Sebastian Ceria at CMU successfully implemented the cutting plane method using the branch and bound algorithm, which is called branch and cut. Since then, cutting planes have become a core component of commercial optimization solvers. Branch and cut algorithm 다음and, 같은 integer programming problem가 있다고 하자. 이when, MATH 이고 MATH 는 convex이며 MATH 이다. > MATH > \\begin align > \\min x & \\quad f x \\\\ > \\text subject to & \\quad x \\in C \\\\ > & \\quad x j \\in \\mathbb Z , \\quad j \\in J \\\\ > \\end align > MATH Branch and cut algorithm algorithmat, Convex Problem은 CPto, Integer Program은 IPto, 표기한다. 1. 다음 convex relaxation problem를 푼다. > MATH > \\begin align > \\min x & \\quad f x \\\\ > \\text subject to & \\quad x \\in C \\\\ > & \\quad x j \\in \\mathbb Z , \\quad j \\in J \\\\ > \\end align > MATH 2. CR infeasible MATH IP infeasible 3. CR 의 solution MATH 이 IP feasible MATH MATH 는 IP 의 solution 4. CR 의 solution MATH 이 IP infeasible하면 다음 두 가지 중to, 선택 MATH 4.1 cut을 추가하고 step 1to, 간다. MATH 4.2 branchsolution서 iteration적with, subproblem을 푼다. Branch and cut algorithm은 branch and bound and, cutting plane method를 결sum한 algorithmwith,서, step 4at, branch-and-bound를 할지, cut을 할지 선택할 수 있다. Integer programming technology Gurobi, CPLEX, FICOand, 같은 state-of-the-art solver들은 매우 효율적인 simplex, interior-point method 등의 algorithm 구현을 포함하고 있다. particularly,, mixed integer optimization의 case, 대부분의 solver들은 branch and cut algorithm을 사용하고 있으며 이들은 convex relaxationand, warm start의 이점을 많이 활용하고 있다. 약 30년 전to, 비하면 Integer programming의 성능 향image은 매우 비약적이다. therefore,, 그during, 풀지 못했던 실생활의 많은 problem들이 최근to, Integer programming을 through, solution결되고 있으며 computing power가 향image됨according to, 더욱 적극적with, 활용될 전망이다. Algorithmat,의 속도 향image 1990-2016 : over MATH Hardwareat,의 속도 향image 1990-2016 : over MATH Total speedup over MATH billion = MATH",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter25/25_01_04_Branch_and_cut_algorithm/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter25/25_02_Two_extended_examples",
    "title": "25-02 Two extended examples",
    "chapter": "25",
    "order": 7,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "In this section, we will present two examples of Mixed Integer Programming. Best subset selection Least mean squares",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter25/25_02_Two_extended_examples/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter25/25_02_01_Best_subset_selection",
    "title": "25-02-01 Best subset selection",
    "chapter": "25",
    "order": 8,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "Best subset selection, one of the representative examples of Integer Programming, is a problem of selecting k entries from MATH entries. Best subset selection When MATH and MATH , the best subset selection problem is as follows: > MATH > \\begin align > \\min \\beta & \\quad \\frac 1 2 \\parallel y - X\\beta \\parallel^ 2 \\\\ > \\text subject to & \\quad \\parallel \\beta \\parallel 0 \\ \\leq k \\\\ > \\end align > MATH Here, MATH is the number of nonzero entries in MATH . Previously in earlier chapters, we defined this type of problem as a Lasso problem and made MATH sparse using the MATH norm. In this problem, it is defined as a problem that constrains the number of non-zero entries using the MATH norm, but since the constraint condition MATH is non-convex, the problem cannot be solved with the convex optimization techniques we have learned so far. Integer programming formulation Then let's reformulate this problem with Integer programming. > MATH > \\begin align > \\min \\beta, z & \\quad \\frac 1 2 \\parallel y - X\\beta \\parallel^ 2 \\\\ > \\text subject to & \\quad \\left\\vert \\beta i \\right\\vert \\leq M i \\cdot z i \\quad i = 1 \\dotsc p \\\\ > & \\quad \\sum i = 1 ^ p z i \\leq k \\\\ > & \\quad z ji \\in \\lbrace 0, 1 \\rbrace \\quad i = 1 \\dotsc p \\\\ > \\end align > MATH Binary variable MATH 를 introducing,서 MATH 의 sum이 MATH 보다 작게 만듦with,써 위의 problemand, 동일solution지게 만들었다. MATH 는 사전to, 알고 있는 MATH 의 image한 값with, MATH and, MATH 를 사전processing,서 computation할 수 있는 값이다. 이제 problem를 Integer Programmingwith, 정의했으므to, 지금from, Integer Programming techniquewith, 풀 수 있다. A clever way to get good feasible solutions problem를 generalizing,서 algorithm을 explaining,보자. Objective function MATH 이 smooth convex이고 MATH 가 L-Lipschitz이라고 하자. > MATH Best subset selection의 case, MATH 이다. Observation as follows: 정의된 MATH function를 through, MATH at, 가장 큰 k개 entry를 구할 수 있다. > MATH 이when,, MATH function는 hard thresholding을 한다. also,, MATH 를 set MATH to, projection한 것with, 볼 수도 있다. Discrete first-order algorithm 이제 gradient descentand, function MATH 를 using,서 algorithm을 정by,보자. 1. MATH with, 시작 2. for MATH MATH end for 위의 process을 iteration하면 MATH to, convergence하게 된다. 이는 위의 minimization problemto, about, local solution이라고 할 수 있다. > MATH result,적with, 이 algorithm은 proximal gradient algorithmwith, 볼 수 있다. 왜냐하면 function MATH 가 proximal operator 역할을 하고 있기 because,이다. Computational results Mixed integer programming gap 아래 그림at, Subset selection problem의 실험 result,를 let's look at. 왼쪽 그래프at, upper bound는 바to, optimal이 되었지만 lower bound는 천천히 올라오다가 upper boundand, 만나는 지점at,야 optimal임을 알게 된다. 왜냐하면 linear programat,는 solution이 optimal인지 체크할 method이 없으며 upper boundand, lower bound가 같아졌을 when, optimal임을 알 수 있게 된다. referenceto, upper boundand, lower bound의 difference를 mixed integer programming gap이라고 한다. 오른쪽 그림은 동일한 실험 result,를 mixed integer programming gap을 작아지는 모습with, showing,주고 있다. 주황색 그래프는 upper boundand, lower bound의 difference이인 mixed integer programming gap을 representing,며 점점 줄어들고 있다. MATH Cold and Warm Starts 다음 그림at, warm start가 cold start보다 전체적with, 성능이 매우 우수함을 showing,주고 있다. Fig2 Cold and Warm Starts 3 Sparsity Detection 다음 그림at,는 MIP Mixed Integer Programming and, Lasso, Step regression, Sparsenet의 sparsity를 비교하고 있다. result,적with, MIP가 가장 sparse한 result,내고 있음을 알 수 있다. Fig3 Sparsity Detection synthetic database 3",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter25/25_02_01_Best_subset_selection/",
    "lang": "vi"
  },
  {
    "id": "/contents/vi/chapter25/25_02_02_Least_mean_squares",
    "title": "25-02-02 Least mean squares",
    "chapter": "25",
    "order": 9,
    "owner": "YoungJae Choung",
    "lesson_type": "",
    "content": "So far, we have solved regression problems by minimizing the MATH norm or MATH norm of residuals. Is there a more robust method than these methods? When performing regression to minimize the median of residuals, we can achieve more robust regression. This is called Least Median of Squares , and it is robust enough that the estimator does not get corrupted even if about 50% of the data is corrupted. However, this problem is also an NP-Hard problem! This section introduces how to solve the Least Quantile of Squares problem, which generalizes the Least Median of Squares problem, using Integer programming. Least mean squares Let MATH and MATH . And when MATH , let MATH . Observe Least squares LS : MATH Least absolute deviation LAD : MATH Least Median of Squares LMS > MATH Least quantile regression Least Median of Squares problem를 일반화한 Least Quantile of Squareproblem는 as follows: 정의할 수 있다. 여기서 MATH 는 MATH 번째 ordered absolute residual이다. Least Quantile of Squares LQS > MATH Key step in the formulation 이제 Least Quantile of Squareproblem를 Integer Programmingwith, 재정by,보자. 이when,, MATH 의 각 entry MATH about, 다음and, 같은 binary variable을 사용한다. > MATH Integer programming formulation MATH and, MATH 은 thresholdto, 각각의 개수는 MATH 개, MATH 개이다. > MATH > \\begin align > \\min \\beta, \\mu, \\bar \\mu , z, \\gamma & \\quad \\gamma \\\\ > \\text subject to & \\quad \\gamma \\le \\lvert r i \\rvert + \\bar \\mu i , \\quad i = 1, ..., n \\\\ > & \\quad \\gamma \\le \\lvert r i \\rvert - \\mu i , \\quad i = 1, ..., n \\\\ > & \\quad \\bar \\mu i \\le M \\cdot z i , \\quad i = 1, ..., n \\\\ > & \\quad \\mu i \\le M \\cdot 1-z i , \\quad i = 1, ..., n \\\\ > & \\quad \\sum^ p i=1 z i = q \\\\ > & \\quad \\mu i , \\bar \\mu i \\ge 0, \\quad i = 1, ..., n \\\\ > & \\quad z i \\in \\ 0, 1\\ , \\quad i = 1, ..., n \\\\ > \\end align > MATH 이 problemat, 첫번째and, 두번쨰 constraint을 보면 residual의 절대값 MATH 이 포함되어 있어서 convex relaxationwith, 풀 수가 없다. therefore,, 첫번째and, 두번쨰 constraint을 convex functionwith, converting, 주어야 한다. First-order algorithm MATH 는 다음and, 같은 형태to, convex function MATH to, 재정의할 수 있다. > MATH 이when, MATH 는 as follows: 정의된다. > MATH > \\begin align > H q \\beta = \\sum^ n i=q \\lvert y i - x^ T i \\beta \\rvert = & > \\max w \\sum^ n i=1 w i \\lvert y i - x^ T i \\beta \\rvert \\\\ > & \\text subject to \\sum^ n i=1 w i = n − q + 1 \\\\ > &0 \\le w i \\le 1, i = 1, ..., n \\\\ > \\end align > MATH MATH 는 앞서 정의된 MATH 을 작은것from, 큰 순with, 나열할 when,, MATH 번째 이image의 모든 residual의 sum이다. therefore,, MATH 번째 이image의 residual의 sumat, MATH 번째 이image의 residual의 sum을 빼면 MATH 번째의 residual 된다는 것을 알 수 있다. Subgradient algorithmwith, MATH 의 local minimum을 구할 수 있다. For detailed information, see 논문 LEAST QUANTILE REGRESSION VIA MODERN OPTIMIZATION https://arxiv.org/pdf/1310.8625.pdf see Computational results 위의 논문at, Least Quantile of Squareproblem를 실험한 result,는 다음 그래프at, 볼 수 있다. Mixed integer programming gap Fig1 Mixed integer programming gap 3 Cold vs Warm Starts Fig2 Cold vs Warm Starts 3",
    "url": "/optimization-for-data-science-iuh-2025/vi/contents/vi/chapter25/25_02_02_Least_mean_squares/",
    "lang": "vi"
  }
]